[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04874v1",
            "title": "A Framework for Programmability in Digital Currency",
            "updated": "2023-11-08T18:21:14Z",
            "published": "2023-11-08T18:21:14Z",
            "summary": "Programmable money, enabled by digital currencies, facilitates outcomes\nbeyond simple payments by allowing users to attach conditions to the movement\nof funds through code. However, there is a lack of clarity on defining\nprogrammable money, where programmability can be implemented, and the resulting\ntradeoffs. This paper provides a definition of programmable money with four key\ncomponents: a format for representing value, a set of programmable\ninstructions, an execution environment providing a coherence guarantee, and\nrules around permissioning. We discuss programmability primitives, categorizing\nthem into levels based on expressiveness. We outline four locations\nprogrammability could be offered - hardcoded into system rules, via\nclient-supplied programs/smart contracts, in client code, or via intermediaries\n- analyzing benefits and risks of each. For policymakers evaluating central\nbank digital currencies, we recommend considering these aspects holistically\nand their interplay with regulation in system design. Our framework and\nvocabulary enable more nuanced analysis of implementing programmability.",
            "author": [
                "Nikhil George",
                "Thaddeus Dryja",
                "Neha Narula"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04874v1",
                "http://arxiv.org/pdf/2311.04874v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04872v1",
            "title": "Computing with Residue Numbers in High-Dimensional Representation",
            "updated": "2023-11-08T18:19:45Z",
            "published": "2023-11-08T18:19:45Z",
            "summary": "We introduce Residue Hyperdimensional Computing, a computing framework that\nunifies residue number systems with an algebra defined over random,\nhigh-dimensional vectors. We show how residue numbers can be represented as\nhigh-dimensional vectors in a manner that allows algebraic operations to be\nperformed with component-wise, parallelizable operations on the vector\nelements. The resulting framework, when combined with an efficient method for\nfactorizing high-dimensional vectors, can represent and operate on numerical\nvalues over a large dynamic range using vastly fewer resources than previous\nmethods, and it exhibits impressive robustness to noise. We demonstrate the\npotential for this framework to solve computationally difficult problems in\nvisual perception and combinatorial optimization, showing improvement over\nbaseline methods. More broadly, the framework provides a possible account for\nthe computational operations of grid cells in the brain, and it suggests new\nmachine learning architectures for representing and manipulating numerical\ndata.",
            "author": [
                "Christopher J. Kymn",
                "Denis Kleyko",
                "E. Paxon Frady",
                "Connor Bybee",
                "Pentti Kanerva",
                "Friedrich T. Sommer",
                "Bruno A. Olshausen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04872v1",
                "http://arxiv.org/pdf/2311.04872v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04871v2",
            "title": "Integration of Summary Information from External Studies for\n  Semiparametric Models",
            "updated": "2023-11-09T23:43:50Z",
            "published": "2023-11-08T18:19:33Z",
            "summary": "With the development of biomedical science, researchers have increasing\naccess to an abundance of studies focusing on similar research questions. There\nis a growing interest in the integration of summary information from those\nstudies to enhance the efficiency of estimation in their own internal studies.\nIn this work, we present a comprehensive framework on integration of summary\ninformation from external studies when the data are modeled by semiparametric\nmodels. Our novel framework offers straightforward estimators that update\nconventional estimations with auxiliary information. It addresses computational\nchallenges by capitalizing on the intricate mathematical structure inherent to\nthe problem. We demonstrate the conditions when the proposed estimators are\ntheoretically more efficient than initial estimate based solely on internal\ndata. Several special cases such as proportional hazards model in survival\nanalysis are provided with numerical examples.",
            "author": [
                "Jianxuan Zang",
                "K. C. G. Chan",
                "Fei Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04871v2",
                "http://arxiv.org/pdf/2311.04871v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04865v1",
            "title": "Computing the $5$-Edge-Connected Components in Linear Time",
            "updated": "2023-11-08T18:05:30Z",
            "published": "2023-11-08T18:05:30Z",
            "summary": "We provide a deterministic algorithm for computing the $5$-edge-connected\ncomponents of an undirected multigraph in linear time. There were probably good\nindications that this computation can be performed in linear time, but no such\nalgorithm was actually known prior to this work. Thus, our paper answers a\ntheoretical question, and sheds light on the possibility that a solution may\nexist for general $k$. A key component in our algorithm is an oracle for\nanswering connectivity queries for pairs of vertices in the presence of at most\nfour edge-failures. Specifically, the oracle has size $O(n)$, it can be\nconstructed in linear time, and it answers connectivity queries in the presence\nof at most four edge-failures in worst-case constant time, where $n$ denotes\nthe number of vertices of the graph. We note that this is a result of\nindependent interest. Our paper can be considered as a follow-up of recent work\non computing the $4$-edge-connected components in linear time. However, in\ndealing with the computation of the $5$-edge-connected components, we are faced\nwith unique challenges that do not appear when dealing with lower connectivity.\nThe problem is that the $4$-edge cuts in $3$-edge-connected graphs are\nentangled in various complicated ways, that make it difficult to organize them\nin a compact way. Here we provide a novel analysis of those cuts, that reveals\nthe existence of various interesting structures. These can be exploited so that\nwe can disentangle and collect only those cuts that are essential in computing\nthe $5$-edge-connected components. This analysis may provide a clue for a\ngeneral solution for the $k$-edge-connected components, or other related graph\nconnectivity problems.",
            "author": [
                "Evangelos Kosinas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04865v1",
                "http://arxiv.org/pdf/2311.04865v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04864v1",
            "title": "Realization of programmable Ising models in a trapped-ion quantum\n  simulator",
            "updated": "2023-11-08T18:02:47Z",
            "published": "2023-11-08T18:02:47Z",
            "summary": "A promising paradigm of quantum computing for achieving practical quantum\nadvantages is quantum annealing or quantum approximate optimization algorithm,\nwhere the classical problems are encoded in Ising interactions. However, it is\nchallenging to build a quantum system that can efficiently map any structured\nproblems. Here, we present a programmable trapped-ion quantum simulator of an\nIsing model with all-to-all connectivity with up to four spins. We implement\nthe spin-spin interactions by using the coupling of trapped ions to multiple\ncollective motional modes and realize the programmability through phase\nmodulation of the Raman laser beams that are individually addressed on ions. As\nan example, we realize several Ising lattices with different interaction\nconnectivities, where the interactions can be ferromagnetic or\nanti-ferromagnetic. We confirm the programmed interaction geometry by observing\nthe ground states of the corresponding models through quantum state tomography.\nOur experimental demonstrations serve as an important basis for realizing\npractical quantum advantages with trapped ions.",
            "author": [
                "Yao Lu",
                "Wentao Chen",
                "Shuaining Zhang",
                "Kuan Zhang",
                "Jialiang Zhang",
                "Jing-Ning Zhang",
                "Kihwan Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04864v1",
                "http://arxiv.org/pdf/2311.04864v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.atom-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04862v1",
            "title": "A Possible Correlation between Metallicity and Near-IR Color for Late-M\n  and L Dwarfs",
            "updated": "2023-11-08T18:00:04Z",
            "published": "2023-11-08T18:00:04Z",
            "summary": "We examine the relationship between metallicity and $J-K$ color for 64\nbenchmark late-M and L dwarfs, all of which are wide companions to higher mass\nstars, and 6 of which are new discoveries. We assess the correlation between\nthe $\\Delta(J-K)$ color anomaly (the difference of an object's $J-K$ color with\nthe median color for field objects of the same spectral type) and the host star\nmetallicity to investigate how metallicity affects ultracool photospheres.\nUsing Spearman's rank correlation test and Student's t test, the late-M dwarf\n(L dwarf) sample's $\\Delta(J-K)$ and metallicity show a positive correlation\nwith 95\\% (90\\%) confidence level. A linear fit to color anomaly as a function\nof metallicity finds a slope of $0.17\\pm0.07$ for the late-M dwarfs and a slope\nof $0.20^{+0.07}_{-0.08}$ for the L dwarfs. We also computed the $\\Delta(J-K)$\nversus metallicity relationship predicted by multi-metallicity model spectra\ngenerated using Drift-Phoenix. The modeled late-M dwarfs show a slope of\n0.202$\\pm$0.03, which is close to our observational results, but the modeled L\ndwarfs show a slope of 0.493$\\pm$0.02, steeper than our observational results.\nBoth our empirical results and the models indicate that more metal-rich objects\nshould appear redder photometrically. We speculate that higher metallicity\ndrives more condensate formation in these atmospheres, thus making these\nultracool dwarfs appear redder.",
            "author": [
                "Ruihan Zhang",
                "Michael C. Liu",
                "Zhoujian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04862v1",
                "http://arxiv.org/pdf/2311.04862v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05772v1",
            "title": "ADaPT: As-Needed Decomposition and Planning with Language Models",
            "updated": "2023-11-08T17:59:15Z",
            "published": "2023-11-08T17:59:15Z",
            "summary": "Large Language Models (LLMs) are increasingly being used for interactive\ndecision-making tasks requiring planning and adapting to the environment.\nRecent works employ LLMs-as-agents in broadly two ways: iteratively determining\nthe next action (iterative executors) or generating plans and executing\nsub-tasks using LLMs (plan-and-execute). However, these methods struggle with\ntask complexity, as the inability to execute any sub-task may lead to task\nfailure. To address these shortcomings, we introduce As-Needed Decomposition\nand Planning for complex Tasks (ADaPT), an approach that explicitly plans and\ndecomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute\nthem. ADaPT recursively decomposes sub-tasks to adapt to both task complexity\nand LLM capability. Our results demonstrate that ADaPT substantially\noutperforms established strong baselines, achieving success rates up to 28.3%\nhigher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel\ncompositional dataset that we introduce. Through extensive analysis, we\nillustrate the importance of multilevel decomposition and establish that ADaPT\ndynamically adjusts to the capabilities of the executor LLM as well as to task\ncomplexity.",
            "author": [
                "Archiki Prasad",
                "Alexander Koller",
                "Mareike Hartmann",
                "Peter Clark",
                "Ashish Sabharwal",
                "Mohit Bansal",
                "Tushar Khot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05772v1",
                "http://arxiv.org/pdf/2311.05772v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04858v1",
            "title": "Scalable Fault-Tolerant Quantum Technologies with Silicon Colour Centres",
            "updated": "2023-11-08T17:52:57Z",
            "published": "2023-11-08T17:52:57Z",
            "summary": "The scaling barriers currently faced by both quantum networking and quantum\ncomputing technologies ultimately amount to the same core challenge of\ndistributing high-quality entanglement at scale. In this Perspective, a novel\nquantum information processing architecture based on optically active spins in\nsilicon is proposed that offers a combined single technological platform for\nscalable fault-tolerant quantum computing and networking. The architecture is\noptimized for overall entanglement distribution and leverages colour centre\nspins in silicon (T centres) for their manufacturability, photonic interface,\nand high fidelity information processing properties. Silicon nanophotonic\noptical circuits allow for photonic links between T centres, which are\nnetworked via telecom-band optical photons in a highly-connected graph. This\nhigh connectivity unlocks the use of low-overhead quantum error correction\ncodes, significantly accelerating the timeline for modular, scalable\nfault-tolerant quantum repeaters and quantum processors.",
            "author": [
                "Stephanie Simmons"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04858v1",
                "http://arxiv.org/pdf/2311.04858v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04850v2",
            "title": "Rethinking Benchmark and Contamination for Language Models with\n  Rephrased Samples",
            "updated": "2023-11-11T05:11:18Z",
            "published": "2023-11-08T17:35:20Z",
            "summary": "Large language models are increasingly trained on all the data ever produced\nby humans. Many have raised concerns about the trustworthiness of public\nbenchmarks due to potential contamination in pre-training or fine-tuning\ndatasets. While most data decontamination efforts apply string matching (e.g.,\nn-gram overlap) to remove benchmark data, we show that these methods are\ninsufficient, and simple variations of test data (e.g., paraphrasing,\ntranslation) can easily bypass these decontamination measures. Furthermore, we\ndemonstrate that if such variation of test data is not eliminated, a 13B model\ncan easily overfit a test benchmark and achieve drastically high performance,\non par with GPT-4. We validate such observations in widely used benchmarks such\nas MMLU, GSK8k, and HumanEval. To address this growing risk, we propose a\nstronger LLM-based decontamination method and apply it to widely used\npre-training and fine-tuning datasets, revealing significant previously unknown\ntest overlap. For example, in pre-training sets such as RedPajama-Data-1T and\nStarCoder-Data, we identified that 8-18\\% of the HumanEval benchmark overlaps.\nInterestingly, we also find such contamination in synthetic dataset generated\nby GPT-3.5/4, suggesting a potential risk of unintentional contamination. We\nurge the community to adopt stronger decontamination approaches when using\npublic benchmarks. Moreover, we call for the community to actively develop\nfresh one-time exams to evaluate models accurately. Our decontamination tool is\npublicly available at https://github.com/lm-sys/llm-decontaminator.",
            "author": [
                "Shuo Yang",
                "Wei-Lin Chiang",
                "Lianmin Zheng",
                "Joseph E. Gonzalez",
                "Ion Stoica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04850v2",
                "http://arxiv.org/pdf/2311.04850v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04849v1",
            "title": "AdlerPy: A Python Package for the Perturbative Adler Function",
            "updated": "2023-11-08T17:35:11Z",
            "published": "2023-11-08T17:35:11Z",
            "summary": "In this letter, I give availability to the source code AdlerPy which will\nallow to easily use the Adler function. As an application, I use the\nmass-dependent perturbative expression for the Adler function to compute\nseveral observables and relevant Standard Model parameters.",
            "author": [
                "Rodolfo Ferro Hern\u00e1ndez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04849v1",
                "http://arxiv.org/pdf/2311.04849v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04847v1",
            "title": "Are foundation models efficient for medical image segmentation?",
            "updated": "2023-11-08T17:33:09Z",
            "published": "2023-11-08T17:33:09Z",
            "summary": "Foundation models are experiencing a surge in popularity. The Segment\nAnything model (SAM) asserts an ability to segment a wide spectrum of objects\nbut required supervised training at unprecedented scale. We compared SAM's\nperformance (against clinical ground truth) and resources (labeling time,\ncompute) to a modality-specific, label-free self-supervised learning (SSL)\nmethod on 25 measurements for 100 cardiac ultrasounds. SAM performed poorly and\nrequired significantly more labeling and computing resources, demonstrating\nworse efficiency than SSL.",
            "author": [
                "Danielle Ferreira",
                "Rima Arnaout"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04847v1",
                "http://arxiv.org/pdf/2311.04847v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04838v1",
            "title": "Toward Rapid, Optimal, and Feasible Power Dispatch through Generalized\n  Neural Mapping",
            "updated": "2023-11-08T17:02:53Z",
            "published": "2023-11-08T17:02:53Z",
            "summary": "The evolution towards a more distributed and interconnected grid necessitates\nlarge-scale decision-making within strict temporal constraints. Machine\nlearning (ML) paradigms have demonstrated significant potential in improving\nthe efficacy of optimization processes. However, the feasibility of solutions\nderived from ML models continues to pose challenges. It's imperative that ML\nmodels produce solutions that are attainable and realistic within the given\nsystem constraints of power systems. To address the feasibility issue and\nexpedite the solution search process, we proposed LOOP-LC 2.0(Learning to\nOptimize the Optimization Process with Linear Constraints version 2.0) as a\nlearning-based approach for solving the power dispatch problem. A notable\nadvantage of the LOOP-LC 2.0 framework is its ability to ensure near-optimality\nand strict feasibility of solutions without depending on computationally\nintensive post-processing procedures, thus eliminating the need for iterative\nprocesses. At the heart of the LOOP-LC 2.0 model lies the newly proposed\ngeneralized gauge map method, capable of mapping any infeasible solution to a\nfeasible point within the linearly-constrained domain. The proposed generalized\ngauge map method improves the traditional gauge map by exhibiting reduced\nsensitivity to input variances while increasing search speeds significantly.\nUtilizing the IEEE-200 test case as a benchmark, we demonstrate the\neffectiveness of the LOOP-LC 2.0 methodology, confirming its superior\nperformance in terms of training speed, computational time, optimality, and\nsolution feasibility compared to existing methodologies.",
            "author": [
                "Meiyi Li",
                "Javad Mohammadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04838v1",
                "http://arxiv.org/pdf/2311.04838v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04834v1",
            "title": "Self-Supervised Learning for Visual Relationship Detection through\n  Masked Bounding Box Reconstruction",
            "updated": "2023-11-08T16:59:26Z",
            "published": "2023-11-08T16:59:26Z",
            "summary": "We present a novel self-supervised approach for representation learning,\nparticularly for the task of Visual Relationship Detection (VRD). Motivated by\nthe effectiveness of Masked Image Modeling (MIM), we propose Masked Bounding\nBox Reconstruction (MBBR), a variation of MIM where a percentage of the\nentities/objects within a scene are masked and subsequently reconstructed based\non the unmasked objects. The core idea is that, through object-level masked\nmodeling, the network learns context-aware representations that capture the\ninteraction of objects within a scene and thus are highly predictive of visual\nobject relationships. We extensively evaluate learned representations, both\nqualitatively and quantitatively, in a few-shot setting and demonstrate the\nefficacy of MBBR for learning robust visual representations, particularly\ntailored for VRD. The proposed method is able to surpass state-of-the-art VRD\nmethods on the Predicate Detection (PredDet) evaluation setting, using only a\nfew annotated samples. We make our code available at\nhttps://github.com/deeplab-ai/SelfSupervisedVRD.",
            "author": [
                "Zacharias Anastasakis",
                "Dimitrios Mallis",
                "Markos Diomataris",
                "George Alexandridis",
                "Stefanos Kollias",
                "Vassilis Pitsikalis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04834v1",
                "http://arxiv.org/pdf/2311.04834v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04833v1",
            "title": "Anonymizing medical case-based explanations through disentanglement",
            "updated": "2023-11-08T16:58:58Z",
            "published": "2023-11-08T16:58:58Z",
            "summary": "Case-based explanations are an intuitive method to gain insight into the\ndecision-making process of deep learning models in clinical contexts. However,\nmedical images cannot be shared as explanations due to privacy concerns. To\naddress this problem, we propose a novel method for disentangling identity and\nmedical characteristics of images and apply it to anonymize medical images. The\ndisentanglement mechanism replaces some feature vectors in an image while\nensuring that the remaining features are preserved, obtaining independent\nfeature vectors that encode the images' identity and medical characteristics.\nWe also propose a model to manufacture synthetic privacy-preserving identities\nto replace the original image's identity and achieve anonymization. The models\nare applied to medical and biometric datasets, demonstrating their capacity to\ngenerate realistic-looking anonymized images that preserve their original\nmedical content. Additionally, the experiments show the network's inherent\ncapacity to generate counterfactual images through the replacement of medical\nfeatures.",
            "author": [
                "Helena Montenegro",
                "Jaime S. Cardoso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04833v1",
                "http://arxiv.org/pdf/2311.04833v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "68T45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04830v1",
            "title": "Real-Time Recurrent Reinforcement Learning",
            "updated": "2023-11-08T16:56:16Z",
            "published": "2023-11-08T16:56:16Z",
            "summary": "Recent advances in reinforcement learning, for partially-observable Markov\ndecision processes (POMDPs), rely on the biologically implausible\nbackpropagation through time algorithm (BPTT) to perform gradient-descent\noptimisation. In this paper we propose a novel reinforcement learning algorithm\nthat makes use of random feedback local online learning (RFLO), a biologically\nplausible approximation of realtime recurrent learning (RTRL) to compute the\ngradients of the parameters of a recurrent neural network in an online manner.\nBy combining it with TD($\\lambda$), a variant of temporaldifference\nreinforcement learning with eligibility traces, we create a biologically\nplausible, recurrent actor-critic algorithm, capable of solving discrete and\ncontinuous control tasks in POMDPs. We compare BPTT, RTRL and RFLO as well as\ndifferent network architectures, and find that RFLO can perform just as well as\nRTRL while exceeding even BPTT in terms of complexity. The proposed method,\ncalled real-time recurrent reinforcement learning (RTRRL), serves as a model of\nlearning in biological neural networks mimicking reward pathways in the\nmammalian brain.",
            "author": [
                "Julian Lemmel",
                "Radu Grosu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04830v1",
                "http://arxiv.org/pdf/2311.04830v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04829v1",
            "title": "Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor\n  Data",
            "updated": "2023-11-08T16:54:23Z",
            "published": "2023-11-08T16:54:23Z",
            "summary": "Tucker decomposition is a powerful tensor model to handle multi-aspect data.\nIt demonstrates the low-rank property by decomposing the grid-structured data\nas interactions between a core tensor and a set of object representations\n(factors). A fundamental assumption of such decomposition is that there were\nfinite objects in each aspect or mode, corresponding to discrete indexes of\ndata entries. However, many real-world data are not naturally posed in the\nsetting. For example, geographic data is represented as continuous indexes of\nlatitude and longitude coordinates, and cannot fit tensor models directly. To\ngeneralize Tucker decomposition to such scenarios, we propose Functional\nBayesian Tucker Decomposition (FunBaT). We treat the continuous-indexed data as\nthe interaction between the Tucker core and a group of latent functions. We use\nGaussian processes (GP) as functional priors to model the latent functions, and\nthen convert the GPs into a state-space prior by constructing an equivalent\nstochastic differential equation (SDE) to reduce computational cost. An\nefficient inference algorithm is further developed for scalable posterior\napproximation based on advanced message-passing techniques. The advantage of\nour method is shown in both synthetic data and several real-world applications.",
            "author": [
                "Shikai Fang",
                "Xin Yu",
                "Zheng Wang",
                "Shibo Li",
                "Mike Kirby",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04829v1",
                "http://arxiv.org/pdf/2311.04829v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04828v2",
            "title": "SODAWideNet -- Salient Object Detection with an Attention augmented Wide\n  Encoder Decoder network without ImageNet pre-training",
            "updated": "2023-11-09T01:49:28Z",
            "published": "2023-11-08T16:53:44Z",
            "summary": "Developing a new Salient Object Detection (SOD) model involves selecting an\nImageNet pre-trained backbone and creating novel feature refinement modules to\nuse backbone features. However, adding new components to a pre-trained backbone\nneeds retraining the whole network on the ImageNet dataset, which requires\nsignificant time. Hence, we explore developing a neural network from scratch\ndirectly trained on SOD without ImageNet pre-training. Such a formulation\noffers full autonomy to design task-specific components. To that end, we\npropose SODAWideNet, an encoder-decoder-style network for Salient Object\nDetection. We deviate from the commonly practiced paradigm of narrow and deep\nconvolutional models to a wide and shallow architecture, resulting in a\nparameter-efficient deep neural network. To achieve a shallower network, we\nincrease the receptive field from the beginning of the network using a\ncombination of dilated convolutions and self-attention. Therefore, we propose\nMulti Receptive Field Feature Aggregation Module (MRFFAM) that efficiently\nobtains discriminative features from farther regions at higher resolutions\nusing dilated convolutions. Next, we propose Multi-Scale Attention (MSA), which\ncreates a feature pyramid and efficiently computes attention across multiple\nresolutions to extract global features from larger feature maps. Finally, we\npropose two variants, SODAWideNet-S (3.03M) and SODAWideNet (9.03M), that\nachieve competitive performance against state-of-the-art models on five\ndatasets.",
            "author": [
                "Rohit Venkata Sai Dulam",
                "Chandra Kambhamettu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04828v2",
                "http://arxiv.org/pdf/2311.04828v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04825v1",
            "title": "Resource-Robust Valid Inequalities for Vehicle Routing and Related\n  Problems",
            "updated": "2023-11-08T16:51:49Z",
            "published": "2023-11-08T16:51:49Z",
            "summary": "State-of-the-art exact methods for vehicle routing problems (VRPs) often use\na branch-price-and-cut framework. Valid inequalities are 'non-robust' if they\ncomplicate the pricing subproblem and 'robust' if they do not. We introduce\n'resource-robust' as an in-between class. Such valid inequalities are robust\nwhen specific resources are present in the subproblem. For ng-route resources,\nwe introduce resource-robust variants of the capacity cuts, k-path cuts, strong\ndegree constraints, and subset-row inequalities. Computational experiments show\nthe ng-capacity cuts' potential in solving the capacitated VRP.",
            "author": [
                "Ymro N. Hoogendoorn",
                "Kevin Dalmeijer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04825v1",
                "http://arxiv.org/pdf/2311.04825v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04824v1",
            "title": "Bilevel Relations and Their Applications to Data Insights",
            "updated": "2023-11-08T16:50:15Z",
            "published": "2023-11-08T16:50:15Z",
            "summary": "Many data-insight analytic tasks in anomaly detection, metric attribution,\nand experimentation analysis can be modeled as searching in a large space of\ntables and finding important ones, where the notion of importance is defined in\nsome adhoc manner. While various frameworks have been proposed (e.g., DIFF,\nVLDB 2019), a systematic and general treatment is lacking. This paper describes\nbilevel relations and operators. While a relation (i.e., table) models a set of\ntuples, a bilevel relation is a dictionary that explicitly models a set of\ntables, where each ``value'' table is identified by a ``key'' of a (region,\nfeatures) pair, where region specifies key attributes of the table, and\nfeatures specify columns of the table. Bilevel relational operators are\nBilevelRelation-to-BilevelRelation transformations and directly analyze a set\nof tables. Bilevel relations and operators provide higher level abstractions\nfor creating and manipulating a set of tables, and are compatible with the\nclassic relational algebra. Together, they allow us to construct bilevel\nqueries, which can express succinctly a range of insight-analytical questions\nwith ``search+eval'' character. We have implemented and deployed a query engine\nfor bilevel queries as a service, which is a first of its kind. Bilevel queries\npose a rich algorithm and system design space, such as query optimization and\ndata format, in order to evaluate them efficiently. We describe our current\ndesigns and lessons, and report empirical evaluations. Bilevel queries have\nfound many useful applications, and have attracted more than 30 internal teams\nto build data-insight applications with it.",
            "author": [
                "Xi Wu",
                "Xiangyao Yu",
                "Shaleen Deep",
                "Ahmed Mahmood",
                "Uyeong Jang",
                "Stratis Viglas",
                "Somesh Jha",
                "John Cieslewicz",
                "Jeffrey F. Naughton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04824v1",
                "http://arxiv.org/pdf/2311.04824v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DC",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04823v1",
            "title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling",
            "updated": "2023-11-08T16:50:05Z",
            "published": "2023-11-08T16:50:05Z",
            "summary": "Transformers have surpassed RNNs in popularity due to their superior\nabilities in parallel training and long-term dependency modeling. Recently,\nthere has been a renewed interest in using linear RNNs for efficient sequence\nmodeling. These linear RNNs often employ gating mechanisms in the output of the\nlinear recurrence layer while ignoring the significance of using forget gates\nwithin the recurrence. In this paper, we propose a gated linear RNN model\ndubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes\nforget gates that are lower bounded by a learnable value. The lower bound\nincreases monotonically when moving up layers. This allows the upper layers to\nmodel long-term dependencies and the lower layers to model more local,\nshort-term dependencies. Experiments on language modeling, image\nclassification, and long-range arena benchmarks showcase the efficiency and\neffectiveness of our proposed model. The source code is available at\nhttps://github.com/OpenNLPLab/HGRN.",
            "author": [
                "Zhen Qin",
                "Songlin Yang",
                "Yiran Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04823v1",
                "http://arxiv.org/pdf/2311.04823v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04818v2",
            "title": "Cross-Silo Federated Learning Across Divergent Domains with Iterative\n  Parameter Alignment",
            "updated": "2023-11-14T21:59:36Z",
            "published": "2023-11-08T16:42:14Z",
            "summary": "Learning from the collective knowledge of data dispersed across private\nsources can provide neural networks with enhanced generalization capabilities.\nFederated learning, a method for collaboratively training a machine learning\nmodel across remote clients, achieves this by combining client models via the\norchestration of a central server. However, current approaches face two\ncritical limitations: i) they struggle to converge when client domains are\nsufficiently different, and ii) current aggregation techniques produce an\nidentical global model for each client. In this work, we address these issues\nby reformulating the typical federated learning setup: rather than learning a\nsingle global model, we learn N models each optimized for a common objective.\nTo achieve this, we apply a weighted distance minimization to model parameters\nshared in a peer-to-peer topology. The resulting framework, Iterative Parameter\nAlignment, applies naturally to the cross-silo setting, and has the following\nproperties: (i) a unique solution for each participant, with the option to\nglobally converge each model in the federation, and (ii) an optional\nearly-stopping mechanism to elicit fairness among peers in collaborative\nlearning settings. These characteristics jointly provide a flexible new\nframework for iteratively learning from peer models trained on disparate\ndatasets. We find that the technique achieves competitive results on a variety\nof data partitions compared to state-of-the-art approaches. Further, we show\nthat the method is robust to divergent domains (i.e. disjoint classes across\npeers) where existing approaches struggle.",
            "author": [
                "Matt Gorbett",
                "Hossein Shirazi",
                "Indrakshi Ray"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04818v2",
                "http://arxiv.org/pdf/2311.04818v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04816v1",
            "title": "MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over\n  Time-Involved Document",
            "updated": "2023-11-08T16:41:37Z",
            "published": "2023-11-08T16:41:37Z",
            "summary": "The facts and time in the document are intricately intertwined, making\ntemporal reasoning over documents challenging. Previous work models time\nimplicitly, making it difficult to handle such complex relationships. To\naddress this issue, we propose MTGER, a novel Multi-view Temporal Graph\nEnhanced Temporal Reasoning framework for temporal reasoning over time-involved\ndocuments. Concretely, MTGER explicitly models the temporal relationships among\nfacts by multi-view temporal graphs. On the one hand, the heterogeneous\ntemporal graphs explicitly model the temporal and discourse relationships among\nfacts; on the other hand, the multi-view mechanism captures both time-focused\nand fact-focused information, allowing the two views to complement each other\nthrough adaptive fusion. To further improve the implicit reasoning capability\nof the model, we design a self-supervised time-comparing objective. Extensive\nexperimental results demonstrate the effectiveness of our method on the TimeQA\nand SituatedQA datasets. Furthermore, MTGER gives more consistent answers under\nquestion perturbations.",
            "author": [
                "Zheng Chu",
                "Zekun Wang",
                "Jiafeng Liang",
                "Ming Liu",
                "Bing Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04816v1",
                "http://arxiv.org/pdf/2311.04816v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04815v1",
            "title": "Domain Adaptive Object Detection via Balancing Between Self-Training and\n  Adversarial Learning",
            "updated": "2023-11-08T16:40:53Z",
            "published": "2023-11-08T16:40:53Z",
            "summary": "Deep learning based object detectors struggle generalizing to a new target\ndomain bearing significant variations in object and background. Most current\nmethods align domains by using image or instance-level adversarial feature\nalignment. This often suffers due to unwanted background and lacks\nclass-specific alignment. A straightforward approach to promote class-level\nalignment is to use high confidence predictions on unlabeled domain as\npseudo-labels. These predictions are often noisy since model is poorly\ncalibrated under domain shift. In this paper, we propose to leverage model's\npredictive uncertainty to strike the right balance between adversarial feature\nalignment and class-level alignment. We develop a technique to quantify\npredictive uncertainty on class assignments and bounding-box predictions. Model\npredictions with low uncertainty are used to generate pseudo-labels for\nself-training, whereas the ones with higher uncertainty are used to generate\ntiles for adversarial feature alignment. This synergy between tiling around\nuncertain object regions and generating pseudo-labels from highly certain\nobject regions allows capturing both image and instance-level context during\nthe model adaptation. We report thorough ablation study to reveal the impact of\ndifferent components in our approach. Results on five diverse and challenging\nadaptation scenarios show that our approach outperforms existing\nstate-of-the-art methods with noticeable margins.",
            "author": [
                "Muhammad Akhtar Munir",
                "Muhammad Haris Khan",
                "M. Saquib Sarfraz",
                "Mohsen Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04815v1",
                "http://arxiv.org/pdf/2311.04815v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04813v1",
            "title": "Be Careful When Evaluating Explanations Regarding Ground Truth",
            "updated": "2023-11-08T16:39:13Z",
            "published": "2023-11-08T16:39:13Z",
            "summary": "Evaluating explanations of image classifiers regarding ground truth, e.g.\nsegmentation masks defined by human perception, primarily evaluates the quality\nof the models under consideration rather than the explanation methods\nthemselves. Driven by this observation, we propose a framework for\n$\\textit{jointly}$ evaluating the robustness of safety-critical systems that\n$\\textit{combine}$ a deep neural network with an explanation method. These are\nincreasingly used in real-world applications like medical image analysis or\nrobotics. We introduce a fine-tuning procedure to (mis)align\nmodel$\\unicode{x2013}$explanation pipelines with ground truth and use it to\nquantify the potential discrepancy between worst and best-case scenarios of\nhuman alignment. Experiments across various model architectures and post-hoc\nlocal interpretation methods provide insights into the robustness of vision\ntransformers and the overall vulnerability of such AI systems to potential\nadversarial attacks.",
            "author": [
                "Hubert Baniecki",
                "Maciej Chrabaszcz",
                "Andreas Holzinger",
                "Bastian Pfeifer",
                "Anna Saranti",
                "Przemyslaw Biecek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04813v1",
                "http://arxiv.org/pdf/2311.04813v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04812v1",
            "title": "Is it possible to obtain reliable estimates for the prevalence of anemia\n  and childhood stunting among children under 5 in the poorest districts in\n  Peru?",
            "updated": "2023-11-08T16:36:03Z",
            "published": "2023-11-08T16:36:03Z",
            "summary": "In this article we describe and apply the Fay-Herriot model with spatially\ncorrelated random area effects (Pratesi, M., & Salvati, N. (2008)), in order to\npredict the prevalence of anemia and childhood stunting in Peruvian districts,\nbased on the data from the Demographic and Family Health Survey of the year\n2019, which collects data about anemia and childhood stunting for children\nunder the age of 12 years, and the National Census carried out in 2017. Our\nmain objective is to produce reliable predictions for the districts, where\nsample sizes are too small to provide good direct estimates, and for the\ndistricts, which were not included in the sample. The basic Fay-Herriot model\n(Fay & Herriot, 1979) tackles this problem by incorporating auxiliary\ninformation, which is generally available from administrative or census\nrecords. The Fay-Herriot model with spatially correlated random area effects,\nin addition to auxiliary information, incorporates geographic information about\nthe areas, such as latitude and longitude. This permits modeling spatial\nautocorrelations, which are not unusual in socioeconomic and health surveys. To\nevaluate the mean square error of the above-mentioned predictors, we use the\nparametric bootstrap procedure, developed in Molina et al. (2009).",
            "author": [
                "Anna Sikov",
                "Jos\u00e9 Cerda-Hern\u00e1ndez",
                "Eduardo Haro"
            ],
            "link": [
                "http://dx.doi.org/10.21678/apuntes.95.1811",
                "http://arxiv.org/abs/2311.04812v1",
                "http://arxiv.org/pdf/2311.04812v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.CO",
                "62P25, 62F40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04811v1",
            "title": "Image-Based Virtual Try-On: A Survey",
            "updated": "2023-11-08T16:34:18Z",
            "published": "2023-11-08T16:34:18Z",
            "summary": "Image-based virtual try-on aims to synthesize a naturally dressed person\nimage with a clothing image, which revolutionizes online shopping and inspires\nrelated topics within image generation, showing both research significance and\ncommercial potentials. However, there is a great gap between current research\nprogress and commercial applications and an absence of comprehensive overview\ntowards this field to accelerate the development. In this survey, we provide a\ncomprehensive analysis of the state-of-the-art techniques and methodologies in\naspects of pipeline architecture, person representation and key modules such as\ntry-on indication, clothing warping and try-on stage. We propose a new semantic\ncriteria with CLIP, and evaluate representative methods with uniformly\nimplemented evaluation metrics on the same dataset. In addition to quantitative\nand qualitative evaluation of current open-source methods, we also utilize\nControlNet to fine-tune a recent large image generation model (PBE) to show\nfuture potentials of large-scale models on image-based virtual try-on task.\nFinally, unresolved issues are revealed and future research directions are\nprospected to identify key trends and inspire further exploration. The\nuniformly implemented evaluation metrics, dataset and collected methods will be\nmade public available at\nhttps://github.com/little-misfit/Survey-Of-Virtual-Try-On.",
            "author": [
                "Dan Song",
                "Xuanpu Zhang",
                "Juan Zhou",
                "Weizhi Nie",
                "Ruofeng Tong",
                "An-An Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04811v1",
                "http://arxiv.org/pdf/2311.04811v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04810v1",
            "title": "Finite Element Methods for the Stretching and Bending of Thin Structures\n  with Folding",
            "updated": "2023-11-08T16:33:42Z",
            "published": "2023-11-08T16:33:42Z",
            "summary": "In [Bonito et al., J. Comput. Phys. (2022)], a local discontinous Galerkin\nmethod was proposed for approximating the large bending of prestrained plates,\nand in [Bonito et al., IMA J. Numer. Anal. (2023)] the numerical properties of\nthis method were explored. These works considered deformations driven\npredominantly by bending. Thus, a bending energy with a metric constraint was\nconsidered. We extend these results to the case of an energy with both a\nbending component and a nonconvex stretching component, and we also consider\nfolding across a crease. The proposed discretization of this energy features a\ncontinuous finite element space, as well as a discrete Hessian operator. We\nestablish the $\\Gamma$-convergence of the discrete to the continuous energy and\nalso present an energy-decreasing gradient flow for finding critical points of\nthe discrete energy. Finally, we provide numerical simulations illustrating the\nconvergence of minimizers and the capabilities of the model.",
            "author": [
                "Andrea Bonito",
                "Diane Guignard",
                "Angelique Morvant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04810v1",
                "http://arxiv.org/pdf/2311.04810v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N12, 65N30, 74K20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04807v1",
            "title": "In vivo impact on rabbit subchondral bone of viscosupplementation with a\n  hyaluronic acid antioxidant conjugate",
            "updated": "2023-11-08T16:30:19Z",
            "published": "2023-11-08T16:30:19Z",
            "summary": "To assess the impact of an antioxidant-conjugated Hyaluronic Acid (HA) on\narticular cartilage and subchondral bone in the context of osteoarthritis (OA),\nwe conducted a study using a hydrogel composed of HA-4-aminoresorcinol (HA4AR)\nand compared it to a commercially available high molecular weight HA\nformulation in a rabbit model of OA. Eighteen rabbits underwent unilateral\nanterior cruciate ligament transection (ACLT) and were categorized into three\ngroups of six rabbits (Saline-group, HA-group and HA4AR-group) depending on the\nintra-articular injection compound. Eight contralateral knees were used as\nnon-operated reference points (Contralateral-group). Iodine-enhanced\nmicro-computed tomography imaging was performed six weeks post-surgery to study\nthe articular cartilage volume and thickness as well as the subchondral bone\nmicroarchitectural parameters and mineral density. In the HA and HA4AR groups,\nthe mean cartilage thickness was found to be similar to that of the\nContralateral-group. However, when we compared the HA-group to the HA4AR-group,\nwe observed a significant reduction in subchondral bone plate tissue mineral\ndensity (p<0.05). In contrast, when we compared the HA4AR-group to the\nSaline-group, no significant differences were noted in trabecular subchondral\nbone microarchitectural parameters and subchondral bone plate and trabecular\nbone mineral densities. Additionally, when the HA-group was compared to the\nSaline-group, a notable decrease in subchondral bone plate tissue mineral\ndensity was evident (p<0.01). Notably, the HA4AR hydrogel, comprising\nHA-antioxidant conjugate, effectively preserved subchondral bone plate tissue\nmineral density when compared to HA alone. Nevertheless, other aspects of bone\nmicroarchitectural parameters remained unaltered, resulting in subchondral bone\nmineral loss six weeks after surgery in the rabbit model.",
            "author": [
                "Romain Rieger",
                "Sema Kaderli",
                "Caroline Boulocher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04807v1",
                "http://arxiv.org/pdf/2311.04807v1"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04806v1",
            "title": "The PetShop Dataset -- Finding Causes of Performance Issues across\n  Microservices",
            "updated": "2023-11-08T16:30:12Z",
            "published": "2023-11-08T16:30:12Z",
            "summary": "Identifying root causes for unexpected or undesirable behavior in complex\nsystems is a prevalent challenge. This issue becomes especially crucial in\nmodern cloud applications that employ numerous microservices. Although the\nmachine learning and systems research communities have proposed various\ntechniques to tackle this problem, there is currently a lack of standardized\ndatasets for quantitative benchmarking. Consequently, research groups are\ncompelled to create their own datasets for experimentation. This paper\nintroduces a dataset specifically designed for evaluating root cause analyses\nin microservice-based applications. The dataset encompasses latency, requests,\nand availability metrics emitted in 5-minute intervals from a distributed\napplication. In addition to normal operation metrics, the dataset includes 68\ninjected performance issues, which increase latency and reduce availability\nthroughout the system. We showcase how this dataset can be used to evaluate the\naccuracy of a variety of methods spanning different causal and non-causal\ncharacterisations of the root cause analysis problem. We hope the new dataset,\navailable at https://github.com/amazon-science/petshop-root-cause-analysis/\nenables further development of techniques in this important area.",
            "author": [
                "Michaela Hardt",
                "William Orchard",
                "Patrick Bl\u00f6baum",
                "Shiva Kasiviswanathan",
                "Elke Kirschbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04806v1",
                "http://arxiv.org/pdf/2311.04806v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG",
                "E.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04802v1",
            "title": "Time evolution of natural orbitals in ab initio molecular dynamics",
            "updated": "2023-11-08T16:22:52Z",
            "published": "2023-11-08T16:22:52Z",
            "summary": "This work combines for the first time ab initio molecular dynamics (AIMD)\nwithin the Born-Oppenheimer approximation, with a global natural orbital\nfunctional (GNOF), an approximate functional of the one-particle reduced\ndensity matrix. The most prominent feature of GNOF-AIMD is the ability to\ndisplay the real-time evolution of natural orbitals, providing detailed\ninformation on the time-dependent electronic structure of complex systems and\nprocesses, including reactive collisions. The quartet ground-state reaction\nN($^4$S) + H$_2$($^1\\Sigma$) $\\rightarrow$ NH($^3\\Sigma$) + H($^2$S) is taken\nas validation test. Collision energy influences on integral cross sections for\ndifferent initial ro-vibrational states of H$_2$ and rotational-state\ndistributions of NH product are discussed, showing a good agreement with\nprevious high-quality theoretical results.",
            "author": [
                "Alejandro Rivero Santamar\u00eda",
                "Mario Piris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04802v1",
                "http://arxiv.org/pdf/2311.04802v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04799v1",
            "title": "DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert\n  Pretraining",
            "updated": "2023-11-08T16:18:32Z",
            "published": "2023-11-08T16:18:32Z",
            "summary": "Building on the cost-efficient pretraining advancements brought about by\nCrammed BERT, we enhance its performance and interpretability further by\nintroducing a novel pretrained model Dependency Agreement Crammed BERT\n(DACBERT) and its two-stage pretraining framework - Dependency Agreement\nPretraining. This framework, grounded by linguistic theories, seamlessly weaves\nsyntax and semantic information into the pretraining process. The first stage\nemploys four dedicated submodels to capture representative dependency\nagreements at the chunk level, effectively converting these agreements into\nembeddings. The second stage uses these refined embeddings, in tandem with\nconventional BERT embeddings, to guide the pretraining of the rest of the\nmodel. Evaluated on the GLUE benchmark, our DACBERT demonstrates notable\nimprovement across various tasks, surpassing Crammed BERT by 3.13% in the RTE\ntask and by 2.26% in the MRPC task. Furthermore, our method boosts the average\nGLUE score by 0.83%, underscoring its significant potential. The pretraining\nprocess can be efficiently executed on a single GPU within a 24-hour cycle,\nnecessitating no supplementary computational resources or extending the\npretraining duration compared with the Crammed BERT. Extensive studies further\nilluminate our approach's instrumental role in bolstering the interpretability\nof pretrained language models for natural language understanding tasks.",
            "author": [
                "Martin Kuo",
                "Jianyi Zhang",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04799v1",
                "http://arxiv.org/pdf/2311.04799v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04797v2",
            "title": "CloverLeaf on Intel Multi-Core CPUs: A Case Study in Write-Allocate\n  Evasion",
            "updated": "2023-11-09T15:13:37Z",
            "published": "2023-11-08T16:16:44Z",
            "summary": "In this paper we analyze the MPI-only version of the CloverLeaf code from the\nSPEChpc 2021 benchmark suite on recent Intel Xeon \"Ice Lake\" and \"Sapphire\nRapids\" server CPUs. We observe peculiar breakdowns in performance when the\nnumber of processes is prime. Investigating this effect, we create\nfirst-principles data traffic models for each of the stencil-like hotspot\nloops. With application measurements and microbenchmarks to study memory data\ntraffic behavior, we can connect the breakdowns to SpecI2M, a new\nwrite-allocate evasion feature in current Intel CPUs. We identify conditions\nunder which SpecI2M works as intended and where it fails to avoid\nwrite-allocate transfers. Write-allocate evasion works best if large arrays are\nwritten consecutively; in the CloverLeaf code, non-temporal stores can be\nemployed on top for best results. For serial and full-node cases we are able to\npredict the memory data volume analytically with an error of a few percent. We\nfind that if the number of processes is prime, SpecI2M fails to work properly,\nwhich we can attribute to short inner loops emerging from the one-dimensional\ndomain decomposition in this case. We can also rule out other possible causes\nof the prime number effect, such as breaking layer conditions, MPI\ncommunication overhead, and load imbalance.",
            "author": [
                "Jan Laukemann",
                "Thomas Gruber",
                "Georg Hager",
                "Dossay Oryspayev",
                "Gerhard Wellein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04797v2",
                "http://arxiv.org/pdf/2311.04797v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04793v1",
            "title": "A Surface Acoustic Wave based Single Photon Shifter for Solid-state\n  Sources",
            "updated": "2023-11-08T16:13:53Z",
            "published": "2023-11-08T16:13:53Z",
            "summary": "Controlling the frequency of nonclassical light is indispensable for\nimplementing quantum computation, communication and bridging various quantum\nsystems. However, frequency-shift devices for solid state single-photon sources\nthat are easy to integrate are practically absent. Here, we propose an\nintegrated single-photon frequency shifter based on acousto-optic modulation.\nThe device consists of two Interdigital Transducers (IDTs) for surface acoustic\nwave (SAW) generation and a silicon waveguide periodically placed at the nodes\nthe SAW to increase the interaction length. The V{\\pi}*L of the device is\n1.2v.cm. Under 133.2MHz driving frequency and 10 volt driving voltage, a shift\nup to 65.7GHz is achieved with near unity conversion efficiency. Our results\ndemonstrate the feasibility of on-chip deterministic quantum spectral control\nin constructing hybrid quantum networks.",
            "author": [
                "Jiaxing Guo",
                "Huijun Zhao",
                "Kaili Xiong",
                "Pingxing Chen",
                "Yang Zhang",
                "Yan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04793v1",
                "http://arxiv.org/pdf/2311.04793v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04791v1",
            "title": "Integrated Distributed Semantic Communication and Over-the-air\n  Computation for Cooperative Spectrum Sensing",
            "updated": "2023-11-08T16:12:31Z",
            "published": "2023-11-08T16:12:31Z",
            "summary": "Cooperative spectrum sensing (CSS) is a promising approach to improve the\ndetection of primary users (PUs) using multiple sensors. However, there are\nseveral challenges for existing combination methods, i.e., performance\ndegradation and ceiling effect for hard-decision fusion (HDF), as well as\nsignificant uploading latency and non-robustness to noise in the reporting\nchannel for soft-data fusion (SDF). To address these issues, in this paper, we\npropose a novel framework for CSS that integrates communication and\ncomputation, namely ICC. Specifically, distributed semantic communication (DSC)\njointly optimizes multiple sensors and the fusion center to minimize the\ntransmitted data without degrading detection performance. Moreover,\nover-the-air computation (AirComp) is utilized to further reduce spectrum\noccupation in the reporting channel, taking advantage of the characteristics of\nthe wireless channel to enable data aggregation. Under the ICC framework, a\nparticular system, namely ICC-CSS, is designed and implemented, which is\ntheoretically proved to be equivalent to the optimal estimator-correlator (E-C)\ndetector with equal gain SDF when the PU signal samples are independent and\nidentically distributed. Extensive simulations verify the superiority of\nICC-CSS compared with various conventional CSS schemes in terms of detection\nperformance, robustness to SNR variations in both the sensing and reporting\nchannels, as well as scalability with respect to the number of samples and\nsensors.",
            "author": [
                "Peng Yi",
                "Yang Cao",
                "Xin Kang",
                "Ying-Chang Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04791v1",
                "http://arxiv.org/pdf/2311.04791v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04789v1",
            "title": "Determination of toxic comments and unintended model bias minimization\n  using Deep learning approach",
            "updated": "2023-11-08T16:10:28Z",
            "published": "2023-11-08T16:10:28Z",
            "summary": "Online conversations can be toxic and subjected to threats, abuse, or\nharassment. To identify toxic text comments, several deep learning and machine\nlearning models have been proposed throughout the years. However, recent\nstudies demonstrate that because of the imbalances in the training data, some\nmodels are more likely to show unintended biases including gender bias and\nidentity bias. In this research, our aim is to detect toxic comment and reduce\nthe unintended bias concerning identity features such as race, gender, sex,\nreligion by fine-tuning an attention based model called BERT(Bidirectional\nEncoder Representation from Transformers). We apply weighted loss to address\nthe issue of unbalanced data and compare the performance of a fine-tuned BERT\nmodel with a traditional Logistic Regression model in terms of classification\nand bias minimization. The Logistic Regression model with the TFIDF vectorizer\nachieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is\navailable at\nhttps://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git",
            "author": [
                "Md Azim Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04789v1",
                "http://arxiv.org/pdf/2311.04789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04787v1",
            "title": "Why Do Clinical Probabilistic Models Fail To Transport Between Sites?",
            "updated": "2023-11-08T16:09:25Z",
            "published": "2023-11-08T16:09:25Z",
            "summary": "The rising popularity of artificial intelligence in healthcare is\nhighlighting the problem that a computational model achieving super-human\nclinical performance at its training sites may perform substantially worse at\nnew sites. In this perspective, we present common sources for this failure to\ntransport, which we divide into sources under the control of the experimenter\nand sources inherent to the clinical data-generating process. Of the inherent\nsources we look a little deeper into site-specific clinical practices that can\naffect the data distribution, and propose a potential solution intended to\nisolate the imprint of those practices on the data from the patterns of disease\ncause and effect that are the usual target of clinical models.",
            "author": [
                "Thomas A. Lasko",
                "Eric V. Strobl",
                "William W. Stead"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04787v1",
                "http://arxiv.org/pdf/2311.04787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PF",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04786v1",
            "title": "Counting $\\mathcal{N} = 8$ Black Holes as Algebraic Varieties",
            "updated": "2023-11-08T16:07:03Z",
            "published": "2023-11-08T16:07:03Z",
            "summary": "We calculate the helicity trace index $B_{14}$ for $\\mathcal{N} = 8$ pure\nD-brane black holes using various techniques of computational algebraic\ngeometry and find perfect agreement with the existing results in the\nliterature. For these black holes, microstate counting is equivalent to finding\nthe number of supersymmetric vacua of a multi-variable supersymmetric quantum\nmechanics which in turn is equivalent to solving a set of multi-variable\npolynomial equations with syzygies. We explore four different techniques to\nsolve a set of polynomial equations, namely Newton Polytopes, Homotopy\ncontinuation, Monodromy and Hilbert series. Unlike other schemes, these methods\nare almost exact with very high success rate for finding all solutions. A gauge\ninvariant analysis is also possible using the symbolic Hilbert series.\nFurthermore, exploiting various exchange symmetries, we show the non-existence\nof a quartic and(or) higher order terms in the potential which if present would\nhave spoiled the counting. Incorporating recent developments in mathematics,\nalgorithms and multi-threading, we have extended the scope of one of the\nauthors previous works to other charges and presented a new perspective for the\nmicrostate counting problem. This further establishes the pure D-brane system\nas a consistent model, bringing us a step closer to $\\mathcal{N} = 2$ black\nhole counting.",
            "author": [
                "Sourav Maji",
                "Abhishek Chowdhury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04786v1",
                "http://arxiv.org/pdf/2311.04786v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math-ph",
                "math.AG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04785v1",
            "title": "The length spectrum of random hyperbolic 3-manifolds",
            "updated": "2023-11-08T16:03:31Z",
            "published": "2023-11-08T16:03:31Z",
            "summary": "We study the length spectrum of a model of random hyperbolic 3-manifolds\nintroduced by Petri and Raimbault. These are compact manifolds with boundary\nconstructed by randomly gluing truncated tetrahedra along their faces. We prove\nthat, as the volume tends to infinity, their length spectrum converge in\ndistribution to a Poisson point process on $\\mathbb{R}_{\\geq0}$, with\ncomputable intensity $\\lambda$.",
            "author": [
                "Anna Roig-Sanchis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04785v1",
                "http://arxiv.org/pdf/2311.04785v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.DG",
                "math.PR",
                "57K32, 57K31, 60C05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04783v1",
            "title": "VioLA: Aligning Videos to 2D LiDAR Scans",
            "updated": "2023-11-08T16:01:15Z",
            "published": "2023-11-08T16:01:15Z",
            "summary": "We study the problem of aligning a video that captures a local portion of an\nenvironment to the 2D LiDAR scan of the entire environment. We introduce a\nmethod (VioLA) that starts with building a semantic map of the local scene from\nthe image sequence, then extracts points at a fixed height for registering to\nthe LiDAR map. Due to reconstruction errors or partial coverage of the camera\nscan, the reconstructed semantic map may not contain sufficient information for\nregistration. To address this problem, VioLA makes use of a pre-trained\ntext-to-image inpainting model paired with a depth completion model for filling\nin the missing scene content in a geometrically consistent fashion to support\npose registration. We evaluate VioLA on two real-world RGB-D benchmarks, as\nwell as a self-captured dataset of a large office scene. Notably, our proposed\nscene completion module improves the pose registration performance by up to\n20%.",
            "author": [
                "Jun-Jee Chao",
                "Selim Engin",
                "Nikhil Chavan-Dafle",
                "Bhoram Lee",
                "Volkan Isler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04783v1",
                "http://arxiv.org/pdf/2311.04783v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04777v1",
            "title": "Lidar Annotation Is All You Need",
            "updated": "2023-11-08T15:55:18Z",
            "published": "2023-11-08T15:55:18Z",
            "summary": "In recent years, computer vision has transformed fields such as medical\nimaging, object recognition, and geospatial analytics. One of the fundamental\ntasks in computer vision is semantic image segmentation, which is vital for\nprecise object delineation. Autonomous driving represents one of the key areas\nwhere computer vision algorithms are applied. The task of road surface\nsegmentation is crucial in self-driving systems, but it requires a\nlabor-intensive annotation process in several data domains. The work described\nin this paper aims to improve the efficiency of image segmentation using a\nconvolutional neural network in a multi-sensor setup. This approach leverages\nlidar (Light Detection and Ranging) annotations to directly train image\nsegmentation models on RGB images. Lidar supplements the images by emitting\nlaser pulses and measuring reflections to provide depth information. However,\nlidar's sparse point clouds often create difficulties for accurate object\nsegmentation. Segmentation of point clouds requires time-consuming preliminary\ndata preparation and a large amount of computational resources. The key\ninnovation of our approach is the masked loss, addressing sparse ground-truth\nmasks from point clouds. By calculating loss exclusively where lidar points\nexist, the model learns road segmentation on images by using lidar points as\nground truth. This approach allows for blending of different ground-truth data\ntypes during model training. Experimental validation of the approach on\nbenchmark datasets shows comparable performance to a high-quality image\nsegmentation model. Incorporating lidar reduces the load on annotations and\nenables training of image-segmentation models without loss of segmentation\nquality. The methodology is tested on diverse datasets, both publicly available\nand proprietary. The strengths and weaknesses of the proposed method are also\ndiscussed in the paper.",
            "author": [
                "Dinar Sharafutdinov",
                "Stanislav Kuskov",
                "Saian Protasov",
                "Alexey Voropaev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04777v1",
                "http://arxiv.org/pdf/2311.04777v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO",
                "I.4.6; I.2.10; I.2.9"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04772v1",
            "title": "GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using\n  Self-Attention with Domain Knowledge Integration",
            "updated": "2023-11-08T15:51:12Z",
            "published": "2023-11-08T15:51:12Z",
            "summary": "Intracerebral Hemorrhage (ICH) is a severe condition resulting from damaged\nbrain blood vessel ruptures, often leading to complications and fatalities.\nTimely and accurate prognosis and management are essential due to its high\nmortality rate. However, conventional methods heavily rely on subjective\nclinician expertise, which can lead to inaccurate diagnoses and delays in\ntreatment. Artificial intelligence (AI) models have been explored to assist\nclinicians, but many prior studies focused on model modification without\nconsidering domain knowledge. This paper introduces a novel deep learning\nalgorithm, GCS-ICHNet, which integrates multimodal brain CT image data and the\nGlasgow Coma Scale (GCS) score to improve ICH prognosis. The algorithm utilizes\na transformer-based fusion module for assessment. GCS-ICHNet demonstrates high\nsensitivity 81.03% and specificity 91.59%, outperforming average clinicians and\nother state-of-the-art methods.",
            "author": [
                "Xuhao Shan",
                "Xinyang Li",
                "Ruiquan Ge",
                "Shibin Wu",
                "Ahmed Elazab",
                "Jichao Zhu",
                "Lingyan Zhang",
                "Gangyong Jia",
                "Qingying Xiao",
                "Xiang Wan",
                "Changmiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04772v1",
                "http://arxiv.org/pdf/2311.04772v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04771v1",
            "title": "Computing $H^2$-conforming finite element approximations without having\n  to implement $C^1$-elements",
            "updated": "2023-11-08T15:50:25Z",
            "published": "2023-11-08T15:50:25Z",
            "summary": "We develop a method to compute the $H^2$-conforming finite element\napproximation to planar fourth order elliptic problems without having to\nimplement $C^1$ elements. The algorithm consists of replacing the original\n$H^2$-conforming scheme with pre-processing and post-processing steps that\nrequire only an $H^1$-conforming Poisson type solve and an inner Stokes-like\nproblem that again only requires at most $H^1$-conformity. We then demonstrate\nthe method applied to the Morgan-Scott elements with three numerical examples.",
            "author": [
                "Mark Ainsworth",
                "Charles Parker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04771v1",
                "http://arxiv.org/pdf/2311.04771v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N30, 65N12"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04769v1",
            "title": "An attention-based deep learning network for predicting Platinum\n  resistance in ovarian cancer",
            "updated": "2023-11-08T15:47:31Z",
            "published": "2023-11-08T15:47:31Z",
            "summary": "Background: Ovarian cancer is among the three most frequent gynecologic\ncancers globally. High-grade serous ovarian cancer (HGSOC) is the most common\nand aggressive histological type. Guided treatment for HGSOC typically involves\nplatinum-based combination chemotherapy, necessitating an assessment of whether\nthe patient is platinum-resistant. The purpose of this study is to propose a\ndeep learning-based method to determine whether a patient is platinum-resistant\nusing multimodal positron emission tomography/computed tomography (PET/CT)\nimages. Methods: 289 patients with HGSOC were included in this study. An\nend-to-end SE-SPP-DenseNet model was built by adding Squeeze-Excitation Block\n(SE Block) and Spatial Pyramid Pooling Layer (SPPLayer) to Dense Convolutional\nNetwork (DenseNet). Multimodal data from PET/CT images of the regions of\ninterest (ROI) were used to predict platinum resistance in patients. Results:\nThrough five-fold cross-validation, SE-SPP-DenseNet achieved a high accuracy\nrate and an area under the curve (AUC) in predicting platinum resistance in\npatients, which were 92.6% and 0.93, respectively. The importance of\nincorporating SE Block and SPPLayer into the deep learning model, and\nconsidering multimodal data was substantiated by carrying out ablation studies\nand experiments with single modality data. Conclusions: The obtained\nclassification results indicate that our proposed deep learning framework\nperforms better in predicting platinum resistance in patients, which can help\ngynecologists make better treatment decisions. Keywords: PET/CT, CNN, SE Block,\nSPP Layer, Platinum resistance, Ovarian cancer",
            "author": [
                "Haoming Zhuang",
                "Beibei Li",
                "Jingtong Ma",
                "Patrice Monkam",
                "Shouliang Qi",
                "Wei Qian",
                "Dianning He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04769v1",
                "http://arxiv.org/pdf/2311.04769v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04766v2",
            "title": "DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D\n  Facial Animation",
            "updated": "2023-11-13T02:39:59Z",
            "published": "2023-11-08T15:39:56Z",
            "summary": "In recent years, audio-driven 3D facial animation has gained significant\nattention, particularly in applications such as virtual reality, gaming, and\nvideo conferencing. However, accurately modeling the intricate and subtle\ndynamics of facial expressions remains a challenge. Most existing studies\napproach the facial animation task as a single regression problem, which often\nfail to capture the intrinsic inter-modal relationship between speech signals\nand 3D facial animation and overlook their inherent consistency. Moreover, due\nto the limited availability of 3D-audio-visual datasets, approaches learning\nwith small-size samples have poor generalizability that decreases the\nperformance. To address these issues, in this study, we propose a cross-modal\ndual-learning framework, termed DualTalker, aiming at improving data usage\nefficiency as well as relating cross-modal dependencies. The framework is\ntrained jointly with the primary task (audio-driven facial animation) and its\ndual task (lip reading) and shares common audio/motion encoder components. Our\njoint training framework facilitates more efficient data usage by leveraging\ninformation from both tasks and explicitly capitalizing on the complementary\nrelationship between facial motion and audio to improve performance.\nFurthermore, we introduce an auxiliary cross-modal consistency loss to mitigate\nthe potential over-smoothing underlying the cross-modal complementary\nrepresentations, enhancing the mapping of subtle facial expression dynamics.\nThrough extensive experiments and a perceptual user study conducted on the VOCA\nand BIWI datasets, we demonstrate that our approach outperforms current\nstate-of-the-art methods both qualitatively and quantitatively. We have made\nour code and video demonstrations available at\nhttps://github.com/sabrina-su/iadf.git.",
            "author": [
                "Guinan Su",
                "Yanwu Yang",
                "Zhifeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04766v2",
                "http://arxiv.org/pdf/2311.04766v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04763v1",
            "title": "The relevance of structural variability in the time-domain for\n  computational reflection anisotropy spectroscopy at solid-liquid interfaces",
            "updated": "2023-11-08T15:34:35Z",
            "published": "2023-11-08T15:34:35Z",
            "summary": "In electrochemistry, reactions and charge-transfer are to a large extent\ndetermined by the atomistic structure of the solid-liquid interface. Yet due to\nthe presence of the liquid electrolyte, many surface-science methods cannot be\napplied here. Hence, the exact microscopic structure that is present under\noperating conditions often remains unknown. Reflection anisotropy spectroscopy\n(RAS) is one of the few techniques that allow for an in operando investigation\nof the structure of solid-liquid interfaces. However, an interpretation of RAS\ndata on the atomistic scale can only be obtained by comparison to computational\nspectroscopy. While the number of computational RAS studies related to\nelectrochemical systems is currently still limited, those studies so far have\nnot taken into account the dynamic nature of the solid-liquid interface. In\nthis work, we investigate the temporal evolution of the spectroscopic response\nof the Au(110) missing row reconstruction in contact with water by combining ab\ninitio molecular dynamics with computational spectroscopy. Our results show\nsignificant changes in the time evolution of the RA spectra, in particular\nproviding an explanation for the typically observed differences in intensity\nwhen comparing theory and experiment. Moreover, these findings point to the\nimportance of structural surface/interface variability while at the same time\nemphasising the potential of RAS for probing these dynamic interfaces.",
            "author": [
                "Justus Leist",
                "Jongmin Kim",
                "Holger Euchner",
                "Matthias M. May"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04763v1",
                "http://arxiv.org/pdf/2311.04763v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04759v1",
            "title": "Dark Energy Constraints from Pantheon+ Ia Supernovae Data",
            "updated": "2023-11-08T15:32:07Z",
            "published": "2023-11-08T15:32:07Z",
            "summary": "Measurements of the current expansion rate of the Universe, $H_0$, using\nstandard candles, disagree with those derived from observations of the Cosmic\nMicrowave Background (CMB). This discrepancy, known as the \\emph{Hubble\ntension}, is substantial and suggests the possibility of revisions to the\nstandard cosmological model (Cosmological constant $\\Lambda$ and cold dark\nmatter - LCDM). Dynamic dark energy (DE) models that introduce deviations in\nthe expansion history relative to LCDM could potentially explain this tension.\nWe used Type Ia supernovae (SNe) data to test a dynamic DE model consisting of\nan equation of state that varies linearly with the cosmological scale factor\n$a$. To evaluate this model, we developed a new statistic (the \\ta\\ statistic)\nused in conjunction with an optimization code that minimizes its value to\nobtain model parameters. The \\ta\\ statistic reduces bias errors (in comparison\nto the $\\chi^2$ statistic) because it retains the sign of the residuals, which\nis meaningful in testing the dynamic DE model as the deviations in the\nexpansion history introduced by this model act asymmetrically in redshift\nspace. The DE model fits the SNe data reasonably well, but the available SNe\ndata lacks the statistical power to discriminate between LCDM and alternative\nmodels. To further assess the model using CMB data, we computed the distance to\nthe last scattering surface and compared the results with that derived from the\n\\emph{Planck} observations. Although the simple dynamic DE model tested does\nnot completely resolve the tension, it is not ruled out by the data and could\nstill play a role alongside other physical effects.",
            "author": [
                "Sergio Torres-Arzayus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04759v1",
                "http://arxiv.org/pdf/2311.04759v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04746v1",
            "title": "NLO Analysis of Small-$k_T$ Region in Drell-Yan Production with Parton\n  Branching",
            "updated": "2023-11-08T15:15:10Z",
            "published": "2023-11-08T15:15:10Z",
            "summary": "The Parton-Branching Method (PB) facilitates the determination of Transverse\nMomentum Dependent (TMD) parton densities across a wide \\kt\\ range, spanning\nsmall to large transverse momentum scales. In the small $k_T$ region, both\nintrinsic parton motion and resummed ultra-soft gluons are significant\ncontributors. Our analysis highlights their crucial role in shaping integrated\nand TMD parton densities.\n  Using PB-derived TMD parton densities and a NLO calculation in MC@NLO style,\nwe compute the transverse momentum spectrum of Drell-Yan pairs across a broad\nmass range. The spectrum's sensitivity to the intrinsic $k_T$ distribution\nallows us to fine-tune parametric parameters. Starting from the\nPB-NLO-HERAI+II-2018 set2 TMD parton distributions, we determine the intrinsic\n$k_T$ distribution width, resulting in a slightly wider profile than the\ndefault set. Importantly, this width remains independent of Drell-Yan pair mass\nand center-of-mass energy ($\\sqrt{s}$), distinguishing our approach.",
            "author": [
                "S. Taheri Monfared"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04746v1",
                "http://arxiv.org/pdf/2311.04746v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04745v1",
            "title": "On the Origin of Force Sensitivity in Delocalised Mechanical Systems",
            "updated": "2023-11-08T15:14:50Z",
            "published": "2023-11-08T15:14:50Z",
            "summary": "The detection of the quantum nature of gravity in the low-energy limit hinges\non achieving an unprecedented degree of force sensitivity with mechanical\nsystems. Against this background, we explore the relationship between the\nsensitivity of mechanical systems to external forces and the properties of the\nquantum states they are prepared in. We establish that the main determinant of\nthe force sensitivity in pure quantum states is their spatial delocalisation\nand we link the force sensitivity to the rate at which two mechanical systems\nbecome entangled under a quantum force. We exemplify this at the hand of two\ncommonly considered configurations. One that involves gravitationally\ninteracting objects prepared in non-Gaussian states such as Schr\\\"odinger-cat\nstates, where the generation of entanglement is typically ascribed to the\naccumulation of a dynamical phase between components in superposition. The\nother prepares particles in Gaussian states that are strongly squeezed in\nmomentum and delocalised in position where entanglement generation is\nattributed to accelerations. We offer a unified description of these two\narrangements using the phase-space representation and link their entangling\nrate to their force sensitivity, showing that both configurations get entangled\nat the same rate provided that they are equally delocalised in space. Our\ndescription in phase space and the established relation between force\nsensitivity and entanglement sheds light on the intricacies of why the\nequivalence between these two configurations holds, something that is not\nalways evident in the literature, due to the distinct physical and analytical\nmethods employed to study each of them. Notably, we demonstrate that while the\nconventional computation of entanglement via the dynamical phase remains\naccurate for Schr\\\"odinger-cat states, it yields erroneous estimations for\nsystems in squeezed cat states.",
            "author": [
                "Julen S. Pedernales",
                "Martin B. Plenio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04745v1",
                "http://arxiv.org/pdf/2311.04745v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04742v2",
            "title": "Using large language models to study human memory for meaningful\n  narratives",
            "updated": "2023-11-28T05:25:45Z",
            "published": "2023-11-08T15:11:57Z",
            "summary": "One of the most impressive achievements of the AI revolution is the\ndevelopment of large language models that can generate meaningful text and\nrespond to instructions in plain English with no additional training necessary.\nHere we show that language models can be used as a scientific instrument for\nstudying human memory for meaningful material. We developed a pipeline for\ndesigning large scale memory experiments and analyzing the obtained results. We\nperformed online memory experiments with a large number of participants and\ncollected recognition and recall data for narratives of different lengths. We\nfound that both recall and recognition performance scale linearly with\nnarrative length. Furthermore, in order to investigate the role of narrative\ncomprehension in memory, we repeated these experiments using scrambled versions\nof the presented stories. We found that even though recall performance declined\nsignificantly, recognition remained largely unaffected. Interestingly, recalls\nin this condition seem to follow the original narrative order rather than the\nscrambled presentation, pointing to a contextual reconstruction of the story in\nmemory.",
            "author": [
                "Antonios Georgiou",
                "Tankut Can",
                "Mikhail Katkov",
                "Misha Tsodyks"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04742v2",
                "http://arxiv.org/pdf/2311.04742v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04741v1",
            "title": "Collective photon emission in solid state environments: Concatenating\n  non-markovian and markovian dynamics",
            "updated": "2023-11-08T15:09:48Z",
            "published": "2023-11-08T15:09:48Z",
            "summary": "Collective light emission and multi-qubit dynamics of solid-state quantum\nemitters are affected both by their coupling to the light field and to lattice\nvibrations. The effect of phonons on quantum emitters is twofold: polaron\nformation is described by ultrafast non-markovian dynamics, while slower\ndephasing is well described by exponential decay. Both temperature-dependent\nprocesses will affect collective emission and entanglement, but they are\nusually not modeled, probably due to a lack of efficient methods especially for\nmore than two emitters. So here we propose and compare two methods: the first\nmethod concatenates the fast and slow phonon dynamics, and the second is the\npolaron method. For a single quantum emitter, we show that the dynamical\nequations are identical in both methods, while predictions for two or more\nemitters also agree very well. Both of our methods incorporate non-markovian\ndynamics due to phonons demonstrating the temperature sensitivity of the\ncollective photon emission. Utilizing a simplified markovian model instead may\nnot be accurate enough especially for quantum information applications: for\nexample, we show how the markovian model may considerably overestimate the\ntwo-emitter concurrence, except at very low temperatures. Our concatenation and\npolaron methods can be applied to an arbitrary number and type of quantum\nemitters, and beyond the bulk GaAs environment that we consider here.\nEspecially the concatenation method can take phonon effects into account at the\nsame computational cost as modelling the emitter-photon interaction alone.\nFinally, we present approximate analytical expressions for the collective\nemission spectrum for N emitters on a one-dimensional chain.",
            "author": [
                "Devashish Pandey",
                "Martijn Wubs"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04741v1",
                "http://arxiv.org/pdf/2311.04741v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04736v1",
            "title": "Transverse Mode Control in Quantum Enhanced Interferometers: A Review\n  and Recommendations for a New Generation",
            "updated": "2023-11-08T15:00:37Z",
            "published": "2023-11-08T15:00:37Z",
            "summary": "Adaptive optics has made significant advancement over the past decade,\nbecoming the essential technology in a wide variety of applications,\nparticularly in the realm of quantum optics. One key area of impact is\ngravitational-wave detection, where quantum correlations are distributed over\nkilometer-long distances by beams with hundreds of kilowatts of optical power.\nDecades of development were required to develop robust and stable techniques to\nsense mismatches between the Gaussian beams and the resonators, all while\nmaintaining the quantum correlations. Here we summarize the crucial\nadvancements in transverse mode control required for gravitational-wave\ndetection. As we look towards the advanced designs of future detectors, we\nhighlight key challenges and offer recommendations for the design of these\ninstruments. We conclude the review with a discussion of the broader\napplication of adaptive optics in quantum technologies: communication,\ncomputation, imaging and sensing.",
            "author": [
                "Aaron W. Goodwin-Jones",
                "Ricardo Cabrita",
                "Mikhail Korobko",
                "Martin van Beuzekom",
                "Daniel D. Brown",
                "Viviana Fafone",
                "Joris van Heijningen",
                "Alessio Rocchi",
                "Mitchell G. Schiworski",
                "Matteo Tacca"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04736v1",
                "http://arxiv.org/pdf/2311.04736v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.ins-det",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04733v2",
            "title": "The High Energy X-ray Probe (HEX-P): Studying Extreme Accretion with\n  Ultraluminous X-ray Sources",
            "updated": "2023-11-10T09:51:49Z",
            "published": "2023-11-08T15:00:04Z",
            "summary": "Ultraluminous X-ray sources (ULXs) represent an extreme class of accreting\ncompact objects: from the identification of some of the accretors as neutron\nstars to the detection of powerful winds travelling at 0.1-0.2 c, the\nincreasing evidence points towards ULXs harbouring stellar-mass compact objects\nundergoing highly super-Eddington accretion. Measuring their intrinsic\nproperties, such as the accretion rate onto the compact object, the outflow\nrate, the masses of accretor/companion -- hence their progenitors, lifetimes,\nand future evolution -- is challenging due to ULXs being mostly extragalactic\nand in crowded fields. Yet ULXs represent our best opportunity to understand\nsuper-Eddington accretion physics and the paths through binary evolution to\neventual double compact object binaries and gravitational wave sources. Through\na combination of end-to-end and single-source simulations, we investigate the\nability of HEX-P to study ULXs in the context of their host galaxies and\ncompare it to XMM-Newton and NuSTAR, the current instruments with the most\nsimilar capabilities. HEX-P's higher sensitivity, which is driven by its narrow\npoint-spread function and low background, allows it to detect pulsations and\nbroad spectral features from ULXs better than XMM-Newton and NuSTAR. We\ndescribe the value of HEX-P in understanding ULXs and their associated key\nphysics, through a combination of broadband sensitivity, timing resolution, and\nangular resolution, which make the mission ideal for pulsation detection and\nlow-background, broadband spectral studies.",
            "author": [
                "Matteo Bachetti",
                "Matthew J. Middleton",
                "Ciro Pinto",
                "Andr\u00e9s G\u00farpide",
                "Dominic J. Walton",
                "Murray Brightman",
                "Bret Lehmer",
                "Timothy P. Roberts",
                "Georgios Vasilopoulos",
                "Jason Alford",
                "Roberta Amato",
                "Elena Ambrosi",
                "Lixin Dai",
                "Hannah P. Earnshaw",
                "Hamza El Byad",
                "Javier A. Garc\u00eda",
                "Gian Luca Israel",
                "Amruta Jaodand",
                "Kristin Madsen",
                "Chandreyee Maitra",
                "Shifra Mandel",
                "Kaya Mori",
                "Fabio Pintore",
                "Ken Ohsuga",
                "Maura Pilia",
                "Daniel Stern",
                "George Younes",
                "Anna Wolter"
            ],
            "link": [
                "http://dx.doi.org/10.3389/fspas.2023.1289432",
                "http://arxiv.org/abs/2311.04733v2",
                "http://arxiv.org/pdf/2311.04733v2"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04732v1",
            "title": "General-purpose machine-learned potential for 16 elemental metals and\n  their alloys",
            "updated": "2023-11-08T14:59:27Z",
            "published": "2023-11-08T14:59:27Z",
            "summary": "Machine-learned potentials (MLPs) trained against quantum-mechanical\nreference data have demonstrated remarkable accuracy, surpassing empirical\npotentials. However, the absence of readily available general-purpose MLPs\nencompassing a broad spectrum of elements and their alloys hampers the\napplications of MLPs in materials science. In this study, we present a feasible\napproach for constructing a unified general-purpose MLP for numerous elements\nand showcase its capability by developing a model (UNEP-v1) for 16 elemental\nmetals (Ag, Al, Au, Cr, Cu, Mg, Mo, Ni, Pb, Pd, Pt, Ta, Ti, V, W, Zr) and their\ndiverse alloys. To achieve a complete representation of the chemical space, we\ndemonstrate that employing 16 one-component and 120 two-component systems\nsuffices, thereby avoiding the enumeration of all 65 535 possible combinations\nfor training data generation. Furthermore, we illustrate that systems with more\ncomponents can be adequately represented as interpolation points in the\ndescriptor space. Our unified MLP exhibits superior performance across various\nphysical properties as compared to the embedded-atom method potential, while\nmaintaining computational efficiency. It achieves a remarkable computational\nspeed of $1.5 \\times 10^8$ atom step / second in molecular dynamics simulations\nusing eight 80-gigabyte A100 graphics cards, enabling simulations up to 100\nmillion atoms. We demonstrate the generality and high efficiency of the MLP in\nstudying plasticity and primary radiation damage in the MoTaVW refractory\nhigh-entropy alloys, showcasing its potential in unraveling complex materials\nbehavior. This work represents a significant leap towards the construction of a\nunified general-purpose MLP encompassing the periodic table, with profound\nimplications for materials research and computational science.",
            "author": [
                "Keke Song",
                "Rui Zhao",
                "Jiahui Liu",
                "Yanzhou Wang",
                "Eric Lindgren",
                "Yong Wang",
                "Shunda Chen",
                "Ke Xu",
                "Ting Liang",
                "Penghua Ying",
                "Nan Xu",
                "Zhiqiang Zhao",
                "Jiuyang Shi",
                "Junjie Wang",
                "Shuang Lyu",
                "Zezhu Zeng",
                "Shirong Liang",
                "Haikuan Dong",
                "Ligang Sun",
                "Yue Chen",
                "Zhuhua Zhang",
                "Wanlin Guo",
                "Ping Qian",
                "Jian Sun",
                "Paul Erhart",
                "Tapio Ala-Nissila",
                "Yanjing Su",
                "Zheyong Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04732v1",
                "http://arxiv.org/pdf/2311.04732v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04726v1",
            "title": "Social Motion Prediction with Cognitive Hierarchies",
            "updated": "2023-11-08T14:51:17Z",
            "published": "2023-11-08T14:51:17Z",
            "summary": "Humans exhibit a remarkable capacity for anticipating the actions of others\nand planning their own actions accordingly. In this study, we strive to\nreplicate this ability by addressing the social motion prediction problem. We\nintroduce a new benchmark, a novel formulation, and a cognition-inspired\nframework. We present Wusi, a 3D multi-person motion dataset under the context\nof team sports, which features intense and strategic human interactions and\ndiverse pose distributions. By reformulating the problem from a multi-agent\nreinforcement learning perspective, we incorporate behavioral cloning and\ngenerative adversarial imitation learning to boost learning efficiency and\ngeneralization. Furthermore, we take into account the cognitive aspects of the\nhuman social action planning process and develop a cognitive hierarchy\nframework to predict strategic human social interactions. We conduct\ncomprehensive experiments to validate the effectiveness of our proposed dataset\nand approach. Code and data are available at\nhttps://walter0807.github.io/Social-CH/.",
            "author": [
                "Wentao Zhu",
                "Jason Qin",
                "Yuke Lou",
                "Hang Ye",
                "Xiaoxuan Ma",
                "Hai Ci",
                "Yizhou Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04726v1",
                "http://arxiv.org/pdf/2311.04726v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12867v1",
            "title": "Amplitude-Ensemble Quantum-Inspired Tabu Search Algorithm for Solving\n  0/1 Knapsack Problems",
            "updated": "2023-11-08T14:45:25Z",
            "published": "2023-11-08T14:45:25Z",
            "summary": "In this paper, we introduce an enhanced version of the \"Quantum-inspired Tabu\nSearch Algorithm\" (QTS), termed \"amplitude-ensemble\" QTS (AE-QTS). By utilizing\npopulation information, we bring QTS closer to the quantum algorithm -- Glover\nSearch Algorithm, maintaining algorithmic simplicity. AE-QTS is validated\nagainst the 0/1 knapsack problem, showing at least a 20% performance boost\nacross all problems and over a 30% efficiency increase in some cases compared\nto the original QTS. Even with increasingly complex problems, this method\nconsistently outperforms the original QTS.",
            "author": [
                "Kuo-Chun Tseng",
                "Wei-Chieh Lai",
                "I-Chia Chen",
                "Yun-Hsiang Hsiao",
                "Jr-Yu Chiue",
                "Wei-Chun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12867v1",
                "http://arxiv.org/pdf/2311.12867v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04711v1",
            "title": "Training CLIP models on Data from Scientific Papers",
            "updated": "2023-11-08T14:38:10Z",
            "published": "2023-11-08T14:38:10Z",
            "summary": "Contrastive Language-Image Pretraining (CLIP) models are able to capture the\nsemantic relationship of images and texts and have enabled a wide range of\napplications, from image retrieval to classification. These models are trained\nwith datasets extracted from web crawls, which are of large quantity but\nlimited quality. This paper explores whether limited amounts higher quality\ndata in a specific domain improve the general performance of CLIP models. To\nthis purpose, we extract text-image data from scientific papers hosted in the\narXiv and PubMed Central repositories. Experiments on small-scale CLIP models\n(ViT B/32) show that model performance increases on average, but only\nmoderately. This result indicates that using the data sources considered in the\npaper to train large-scale CLIP models is a worthwile research direction.",
            "author": [
                "Calvin Metzger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04711v1",
                "http://arxiv.org/pdf/2311.04711v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04709v1",
            "title": "Forecasting and predicting stochastic agent-based models of cell\n  migration with biologically-informed neural networks",
            "updated": "2023-11-08T14:36:51Z",
            "published": "2023-11-08T14:36:51Z",
            "summary": "Collective migration, or the coordinated movement of many individuals, is an\nimportant component of many biological processes, including wound healing,\ntumorigenesis, and embryo development. Spatial agent-based models (ABMs) are\noften used to model collective migration, but it is challenging to thoroughly\nstudy these models' behavior due to their random and computational nature.\nModelers often overcome these obstacles by coarse-graining discrete ABM rules\ninto continuous mean-field partial differential equation (PDE) models. These\nmodels are advantageous because they are fast to simulate; unfortunately, these\nPDE models can poorly predict ABM behavior (or even be ill-posed) at certain\nparameter values. In this work, we describe how biologically-informed neural\nnetworks (BINNs) can be used to learn BINN-guided PDE models that are capable\nof accurately predicting ABM behavior. In particular, we show that BINN-guided\nPDE simulations can forecast future ABM data not seen during model training.\nAdditionally, we demonstrate how to predict ABM data at previously-unexplored\nparameter values by combining BINN-guided PDE simulations with multivariate\ninterpolation. We highlight these results using three separate ABMs that\nconsist of rules on agent pulling and/or adhesion. Surprisingly, BINN-guided\nPDEs can accurately forecast and predict ABM data with a one-compartment PDE\nwhen the mean-field PDE is ill-posed or requires two compartments. While we\nfocus our presentation on the biological applications, this work is broadly\napplicable to studying many systems that exhibit the collective migration of\nindividuals.",
            "author": [
                "John T. Nardini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04709v1",
                "http://arxiv.org/pdf/2311.04709v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04705v1",
            "title": "Negotiation Strategies in Ubiquitous Human-Computer Interaction: A Novel\n  Storyboards Scale & Field Study",
            "updated": "2023-11-08T14:22:12Z",
            "published": "2023-11-08T14:22:12Z",
            "summary": "In today's connected society, self-tracking technologies (STTs), such as\nwearables and mobile fitness apps, empower humans to improve their health and\nwell-being through ubiquitous physical activity monitoring, with several\npersonal and societal benefits. Despite the advances in such technologies'\nhardware, low user engagement and decreased effectiveness limitations demand\nmore informed and theoretically-founded Human-Computer Interaction designs. To\naddress these challenges, we build upon the previously unexplored Leisure\nConstraints Negotiation Model and the Transtheoretical Model to systematically\ndefine and assess the effectiveness of STTs' features that acknowledge users'\ncontextual constraints and establish human-negotiated STTs narratives.\nSpecifically, we introduce and validate a human-centric scale, StoryWear, which\nexploits and explores eleven dimensions of negotiation strategies that humans\nutilize to overcome constraints regarding exercise participation, captured\nthrough an inclusive storyboards format. Based on our preliminary studies,\nStoryWear shows high reliability, rendering it suitable for future work in\nubiquitous computing. Our results indicate that negotiation strategies vary in\nperceived effectiveness and have higher appeal for existing STTs' users, with\nself-motivation, commitment, and understanding of the negative impact of\nnon-exercise placed at the top. Finally, we give actionable guidelines for\nreal-world implementation and a commentary on the future of personalized\ntraining.",
            "author": [
                "Sofia Yfantidou",
                "Georgia Yfantidou",
                "Panagiota Balaska",
                "Athena Vakali"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04705v1",
                "http://arxiv.org/pdf/2311.04705v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04700v1",
            "title": "A self-synthesized origin of heavy metals in hot subdwarf stars?",
            "updated": "2023-11-08T14:11:52Z",
            "published": "2023-11-08T14:11:52Z",
            "summary": "Some He-rich hot subdwarf stars (He-sdOBs) present high abundances of\ntrans-iron elements, such as Sr, Y, Zr and Pb. Diffusion processes are\nimportant in hot subdwarf stars, and it is thought that the high abundances of\nheavy elements in these stars are due to the action of radiative levitation.\nHowever, during the formation of He-sdOBs, hydrogen can be ingested into the\nconvective zone driven by the He-core flash. It is known that episodes in which\nprotons are being ingested into He-burning convective zones can lead to\nneutron-capture processes and the formation of heavy elements. In this work we\naim to explore for the first time if neutron-capture processes can occur in\nlate He-core flashes happening in the cores of the progenitors of He-sdOBs. We\ncompute a detailed evolutionary model of a stripped red-giant star with a\nstellar evolution code with a nuclear network comprising 32 isotopes. Then we\npost-process the stellar models in the phase of He and H burning with a\npost-processing nucleosynthesis code with a nuclear network of 1190 species\nthat allows us to follow the neutron-capture processes in detail. We find the\noccurrence of neutron-capture processes in our model, with neutron densities\nreaching a value of $\\sim5\\times10^{12}\\,{\\rm cm}^{-3}$. We find that the\ntrans-iron elements are enhanced in the surface by 1 to 2 dex as compared to\ninitial compositions. Moreover, the relative abundance pattern $[{\\rm\nX}_i/\\rm{Fe}]$ produced by neutron-capture processes closely resembles those\nobserved in some He-sdOBs, hinting at a possible self-synthesized origin of the\nheavy elements in these stars. We conclude that intermediate neutron-capture\nprocesses can occur during a proton ingestion event in the He-core flash of\nstripped red-giant stars. This mechanism offers a natural channel to produce\nthe heavy elements observed in some of the He-sdOBs.",
            "author": [
                "T. Battich",
                "M. M. Miller Bertolami",
                "A. M. Serenelli",
                "S. Justham",
                "A. Weiss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04700v1",
                "http://arxiv.org/pdf/2311.04700v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04699v1",
            "title": "3D Pose Estimation of Tomato Peduncle Nodes using Deep Keypoint\n  Detection and Point Cloud",
            "updated": "2023-11-08T14:10:46Z",
            "published": "2023-11-08T14:10:46Z",
            "summary": "Greenhouse production of fruits and vegetables in developed countries is\nchallenged by labor 12 scarcity and high labor costs. Robots offer a good\nsolution for sustainable and cost-effective 13 production. Acquiring accurate\nspatial information about relevant plant parts is vital for 14 successful robot\noperation. Robot perception in greenhouses is challenging due to variations in\n15 plant appearance, viewpoints, and illumination. This paper proposes a\nkeypoint-detection-based 16 method using data from an RGB-D camera to estimate\nthe 3D pose of peduncle nodes, which 17 provides essential information to\nharvest the tomato bunches. 18 19 Specifically, this paper proposes a method\nthat detects four anatomical landmarks in the color 20 image and then\nintegrates 3D point-cloud information to determine the 3D pose. A 21\ncomprehensive evaluation was conducted in a commercial greenhouse to gain\ninsight into the 22 performance of different parts of the method. The results\nshowed: (1) high accuracy in object 23 detection, achieving an Average\nPrecision (AP) of AP@0.5=0.96; (2) an average Percentage of 24 Detected Joints\n(PDJ) of the keypoints of PhDJ@0.2=94.31%; and (3) 3D pose estimation 25\naccuracy with mean absolute errors (MAE) of 11.38o and 9.93o for the relative\nupper and lower 26 angles between the peduncle and main stem, respectively.\nFurthermore, the capability to handle 27 variations in viewpoint was\ninvestigated, demonstrating the method was robust to view changes. 28 However,\ncanonical and higher views resulted in slightly higher performance compared to\nother 29 views. Although tomato was selected as a use case, the proposed method\nis also applicable to 30 other greenhouse crops like pepper.",
            "author": [
                "Jianchao Ci",
                "Xin Wang",
                "David Rapado-Rinc\u00f3n",
                "Akshay K. Burusa",
                "Gert Kootstra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04699v1",
                "http://arxiv.org/pdf/2311.04699v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04698v2",
            "title": "Challenging Common Assumptions in Multi-task Learning",
            "updated": "2023-11-10T16:19:45Z",
            "published": "2023-11-08T14:10:19Z",
            "summary": "While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we challenge common assumptions in\nMTL in the context of STL: First, the choice of optimizer has only been mildly\ninvestigated in MTL. We show the pivotal role of common STL tools such as the\nAdam optimizer in MTL. We deduce the effectiveness of Adam to its partial\nloss-scale invariance. Second, the notion of gradient conflicts has often been\nphrased as a specific problem in MTL. We delve into the role of gradient\nconflicts in MTL and compare it to STL. For angular gradient alignment we find\nno evidence that this is a unique problem in MTL. We emphasize differences in\ngradient magnitude as the main distinguishing factor. Lastly, we compare the\ntransferability of features learned through MTL and STL on common image\ncorruptions, and find no conclusive evidence that MTL leads to superior\ntransferability. Overall, we find surprising similarities between STL and MTL\nsuggesting to consider methods from both fields in a broader context.",
            "author": [
                "Cathrin Elich",
                "Lukas Kirchdorfer",
                "Jan M. K\u00f6hler",
                "Lukas Schott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04698v2",
                "http://arxiv.org/pdf/2311.04698v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04694v1",
            "title": "Evaluating Generative Ad Hoc Information Retrieval",
            "updated": "2023-11-08T14:05:00Z",
            "published": "2023-11-08T14:05:00Z",
            "summary": "Recent advances in large language models have enabled the development of\nviable generative information retrieval systems. A generative retrieval system\nreturns a grounded generated text in response to an information need instead of\nthe traditional document ranking. Quantifying the utility of these types of\nresponses is essential for evaluating generative retrieval systems. As the\nestablished evaluation methodology for ranking-based ad hoc retrieval may seem\nunsuitable for generative retrieval, new approaches for reliable, repeatable,\nand reproducible experimentation are required. In this paper, we survey the\nrelevant information retrieval and natural language processing literature,\nidentify search tasks and system architectures in generative retrieval, develop\na corresponding user model, and study its operationalization. This theoretical\nanalysis provides a foundation and new insights for the evaluation of\ngenerative ad hoc retrieval systems.",
            "author": [
                "Lukas Gienapp",
                "Harrisen Scells",
                "Niklas Deckers",
                "Janek Bevendorff",
                "Shuai Wang",
                "Johannes Kiesel",
                "Shahbaz Syed",
                "Maik Fr\u00f6be",
                "Guido Zuccon",
                "Benno Stein",
                "Matthias Hagen",
                "Martin Potthast"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04694v1",
                "http://arxiv.org/pdf/2311.04694v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04691v1",
            "title": "Sustainable Collaborative Strategy in Pharmaceutical Refrigerated\n  Logistics Routing Problem",
            "updated": "2023-11-08T13:57:38Z",
            "published": "2023-11-08T13:57:38Z",
            "summary": "The rapid growth of pharmaceutical refrigerated logistics poses\nsustainability challenges, including elevated costs, energy consumption, and\nresource inefficiency. Collaborating multiple depots can enhance logistics\nefficiency when standalone distribution centers have limited transport\nresources, i.e., refrigerated vehicles. However, the sustainable benefits and\nperformance across different strategies remain unexplored. This study fills\nthis research gap by addressing a refrigerated pharmaceutical routing problem.\nWhile many collaborative strategies prioritize economic and environmental\nbenefits, our approach highlights a vital social indicator: maintaining vehicle\nflow equilibrium at each depot during collaboration. This ensures the stability\nof transport resources for all stakeholders, promoting sustainable\ncollaborative logistics. The problem is formulated as a multi-depot vehicle\nrouting problem with time windows (MDVRPTW). Three collaborative strategies\nusing Clustering VRP (CLUVRP) and improved Open VRP (OVRP) are proposed and\ncompared. We develop two approaches to address traditional OVRP limitations in\nensuring vehicle flow equilibrium at each depot. Our models consider perishable\npharmaceuticals and time-dependent travel speeds. Three hybrid heuristics based\non Simulated Annealing and Variable Neighborhood Search (SAVNS) are proposed\nand evaluated for efficacy. Computational experiments and a case study\ndemonstrate distinct sustainable benefits across various strategies, offering\nvaluable insights for decision-makers in the refrigerated logistics market.",
            "author": [
                "Tingting Chen",
                "Feng Chu",
                "Jiantong Zhang",
                "Jiaqing Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04691v1",
                "http://arxiv.org/pdf/2311.04691v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04690v1",
            "title": "Learning Quantum Phase Estimation by Variational Quantum Circuits",
            "updated": "2023-11-08T13:57:24Z",
            "published": "2023-11-08T13:57:24Z",
            "summary": "Quantum Phase Estimation (QPE) stands as a pivotal quantum computing\nsubroutine that necessitates an inverse Quantum Fourier Transform (QFT).\nHowever, it is imperative to recognize that enhancing the precision of the\nestimation inevitably results in a significantly deeper circuit. We developed a\nvariational quantum circuit (VQC) approximation to reduce the depth of the QPE\ncircuit, yielding enhanced performance in noisy simulations and real hardware.\nOur experiments demonstrated that the VQC outperformed both Noisy QPE and\nstandard QPE on real hardware by reducing circuit noise. This VQC integration\ninto quantum compilers as an intermediate step between input and transpiled\ncircuits holds significant promise for quantum algorithms with deep circuits.\nFuture research will explore its potential applicability across various quantum\ncomputing hardware architectures.",
            "author": [
                "Chen-Yu Liu",
                "Chu-Hsuan Abraham Lin",
                "Kuan-Cheng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04690v1",
                "http://arxiv.org/pdf/2311.04690v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04688v2",
            "title": "Single Server Private Information Retrieval Protocols With Codes Over\n  Rings",
            "updated": "2023-11-10T08:57:01Z",
            "published": "2023-11-08T13:51:03Z",
            "summary": "A Private Information Retrieval (PIR) protocol based on coding theory for a\nsingle server is proposed. It provides computational security against linear\nalgebra attacks, addressing the main drawback of previous PIR proposals based\non coding theory. The approach involves two types of codes each one over a\ndifferent ring, an inner non-free linear code that will be used as a\ndistinguisher of some elements added to the query matrix, and an outer code\nthat will be used for generating the query matrix. Moreover, it only uses\nmodular arithmetic at the server level and the recovering stage if the base\nring chosen for the inner code is $\\mathbb Z_m$.",
            "author": [
                "\u015eeyma Bodur",
                "Edgar Mart\u00ednez-Moro",
                "Diego Ruano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04688v2",
                "http://arxiv.org/pdf/2311.04688v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04686v1",
            "title": "Robust and Communication-Efficient Federated Domain Adaptation via\n  Random Features",
            "updated": "2023-11-08T13:46:58Z",
            "published": "2023-11-08T13:46:58Z",
            "summary": "Modern machine learning (ML) models have grown to a scale where training them\non a single machine becomes impractical. As a result, there is a growing trend\nto leverage federated learning (FL) techniques to train large ML models in a\ndistributed and collaborative manner. These models, however, when deployed on\nnew devices, might struggle to generalize well due to domain shifts. In this\ncontext, federated domain adaptation (FDA) emerges as a powerful approach to\naddress this challenge.\n  Most existing FDA approaches typically focus on aligning the distributions\nbetween source and target domains by minimizing their (e.g., MMD) distance.\nSuch strategies, however, inevitably introduce high communication overheads and\ncan be highly sensitive to network reliability.\n  In this paper, we introduce RF-TCA, an enhancement to the standard Transfer\nComponent Analysis approach that significantly accelerates computation without\ncompromising theoretical and empirical performance. Leveraging the\ncomputational advantage of RF-TCA, we further extend it to FDA setting with\nFedRF-TCA. The proposed FedRF-TCA protocol boasts communication complexity that\nis \\emph{independent} of the sample size, while maintaining performance that is\neither comparable to or even surpasses state-of-the-art FDA methods. We present\nextensive experiments to showcase the superior performance and robustness (to\nnetwork condition) of FedRF-TCA.",
            "author": [
                "Zhanbo Feng",
                "Yuanjie Wang",
                "Jie Li",
                "Fan Yang",
                "Jiong Lou",
                "Tiebin Mi",
                "Robert. C. Qiu",
                "Zhenyu Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04686v1",
                "http://arxiv.org/pdf/2311.04686v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04685v1",
            "title": "An End-Cloud Computing Enabled Surveillance Video Transmission System",
            "updated": "2023-11-08T13:45:06Z",
            "published": "2023-11-08T13:45:06Z",
            "summary": "The enormous data volume of video poses a significant burden on the network.\nParticularly, transferring high-definition surveillance videos to the cloud\nconsumes a significant amount of spectrum resources. To address these issues,\nwe propose a surveillance video transmission system enabled by end-cloud\ncomputing. Specifically, the cameras actively down-sample the original video\nand then a redundant frame elimination module is employed to further reduce the\ndata volume of surveillance videos. Then we develop a key-frame assisted video\nsuper-resolution model to reconstruct the high-quality video at the cloud side.\nMoreover, we propose a strategy of extracting key frames from source videos for\nbetter reconstruction performance by utilizing the peak signal-to-noise ratio\n(PSNR) of adjacent frames to measure the propagation distance of key frame\ninformation. Simulation results show that the developed system can effectively\nreduce the data volume by the end-cloud collaboration and outperforms existing\nvideo super-resolution models significantly in terms of PSNR and structural\nsimilarity index (SSIM).",
            "author": [
                "Dingxi Yang",
                "Zhijin Qin",
                "Liting Wang",
                "Xiaoming Tao",
                "Fang Cui",
                "Hengjiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04685v1",
                "http://arxiv.org/pdf/2311.04685v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04681v1",
            "title": "Efficiently stable presentations from error-correcting codes",
            "updated": "2023-11-08T13:40:13Z",
            "published": "2023-11-08T13:40:13Z",
            "summary": "We introduce a notion of \\emph{efficient stability} for finite presentations\nof groups. Informally, a finite presentation using generators $S$ and relations\n$R$ is \\emph{stable} if any map from $S$ to unitaries that approximately\nsatisfies the relations (in the tracial norm) is close to the restriction of a\nrepresentation of $G$ to the subset $S$. This notion and variants thereof have\nbeen extensively studied in recent years, in part motivated by connections to\nproperty testing in computer science. The novelty in our work is the focus on\n\\emph{efficiency}, which, informally, places an onus on small presentations --\nin the sense of encoding length. The goal in this setup is to achieve\nnon-trivial tradeoffs between the presentation length and its modulus of\nstability.\n  With this goal in mind we analyze various natural examples of presentations.\nWe provide a general method for constructing presentations of $\\mathbb{Z}_2^k$\nfrom linear error-correcting codes. We observe that the resulting presentation\nhas a weak form of stability exactly when the code is \\emph{testable}. This\nraises the question of whether testable codes give rise to genuinely stable\npresentations using this method. While we cannot show that this is the case in\ngeneral, we leverage recent results in the study of non-local games in quantum\ninformation theory (Ji et al., Discrete Analysis 2021) to show that a specific\ninstantiation of our construction, based on the Reed-Muller family of codes,\nleads to a stable presentation of $\\mathbb{Z}_2^k$ of size polylog$(k)$ only.\nAs an application, we combine this result with recent work of de la Salle\n(arXiv:2204.07084) to re-derive the quantum low-degree test of Natarajan and\nVidick (IEEE FOCS'18), which is a key building block in the recent refutation\nof Connes' Embedding Problem via complexity theory (Ji et al.,\narXiv:2001.04383).",
            "author": [
                "Michael Chapman",
                "Thomas Vidick",
                "Henry Yuen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04681v1",
                "http://arxiv.org/pdf/2311.04681v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04678v2",
            "title": "Weakly supervised cross-modal learning in high-content screening",
            "updated": "2023-11-12T13:31:14Z",
            "published": "2023-11-08T13:35:08Z",
            "summary": "With the surge in available data from various modalities, there is a growing\nneed to bridge the gap between different data types. In this work, we introduce\na novel approach to learn cross-modal representations between image data and\nmolecular representations for drug discovery. We propose EMM and IMM, two\ninnovative loss functions built on top of CLIP that leverage weak supervision\nand cross sites replicates in High-Content Screening. Evaluating our model\nagainst known baseline on cross-modal retrieval, we show that our proposed\napproach allows to learn better representations and mitigate batch effect. In\naddition, we also present a preprocessing method for the JUMP-CP dataset that\neffectively reduce the required space from 85Tb to a mere usable 7Tb size,\nstill retaining all perturbations and most of the information content.",
            "author": [
                "Watkinson Gabriel",
                "Cohen Ethan",
                "Bourriez Nicolas",
                "Bendidi Ihab",
                "Bollot Guillaume",
                "Genovesio Auguste"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04678v2",
                "http://arxiv.org/pdf/2311.04678v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04666v2",
            "title": "Pre-training LLMs using human-like development data corpus",
            "updated": "2023-11-18T22:14:48Z",
            "published": "2023-11-08T13:13:23Z",
            "summary": "Pre-trained Large Language Models (LLMs) have shown success in a diverse set\nof language inference and understanding tasks. The pre-training stage of LLMs\nlooks at a large corpus of raw textual data. The BabyLM shared task compares\nLLM pre-training to human language acquisition, where the number of tokens seen\nby 13-year-old kids is magnitudes smaller than the number of tokens seen by\nLLMs. In this work, we pre-train and evaluate LLMs on their ability to learn\ncontextual word representations using roughly the same number of tokens as seen\nby children. We provide a strong set of baselines; with different\narchitectures, evaluation of changes in performance across epochs, and reported\npre-training metrics for the strict small and strict tracks of the task. We\nalso try to loosely replicate the RoBERTa baseline given by the task organizers\nto observe the training robustness to hyperparameter selection and\nreplicability. We provide the submission details to the strict and strict-small\ntracks in this report.",
            "author": [
                "Khushi Bhardwaj",
                "Raj Sanjay Shah",
                "Sashank Varma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04666v2",
                "http://arxiv.org/pdf/2311.04666v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04664v1",
            "title": "Speech language models lack important brain-relevant semantics",
            "updated": "2023-11-08T13:11:48Z",
            "published": "2023-11-08T13:11:48Z",
            "summary": "Despite known differences between reading and listening in the brain, recent\nwork has shown that text-based language models predict both text-evoked and\nspeech-evoked brain activity to an impressive degree. This poses the question\nof what types of information language models truly predict in the brain. We\ninvestigate this question via a direct approach, in which we eliminate\ninformation related to specific low-level stimulus features (textual, speech,\nand visual) in the language model representations, and observe how this\nintervention affects the alignment with fMRI brain recordings acquired while\nparticipants read versus listened to the same naturalistic stories. We further\ncontrast our findings with speech-based language models, which would be\nexpected to predict speech-evoked brain activity better, provided they model\nlanguage processing in the brain well. Using our direct approach, we find that\nboth text-based and speech-based language models align well with early sensory\nregions due to shared low-level features. Text-based models continue to align\nwell with later language regions even after removing these features, while,\nsurprisingly, speech-based models lose most of their alignment. These findings\nsuggest that speech-based models can be further improved to better reflect\nbrain-like language processing.",
            "author": [
                "Subba Reddy Oota",
                "Emin \u00c7elik",
                "Fatma Deniz",
                "Mariya Toneva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04664v1",
                "http://arxiv.org/pdf/2311.04664v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04661v2",
            "title": "Massive Editing for Large Language Models via Meta Learning",
            "updated": "2023-11-09T11:07:15Z",
            "published": "2023-11-08T13:03:06Z",
            "summary": "While large language models (LLMs) have enabled learning knowledge from the\npre-training corpora, the acquired knowledge may be fundamentally incorrect or\noutdated over time, which necessitates rectifying the knowledge of the language\nmodel (LM) after the training. A promising approach involves employing a\nhyper-network to generate parameter shift, whereas existing hyper-networks\nsuffer from inferior scalability in synchronous editing operation amount. To\nmitigate the problem, we propose the MAssive Language Model Editing Network\n(MALMEN), which formulates the parameter shift aggregation as the least square\nproblem, subsequently updating the LM parameters using the normal equation. To\naccommodate editing multiple facts simultaneously with limited memory budgets,\nwe separate the computation on the hyper-network and LM, enabling arbitrary\nbatch size on both neural networks. Our method is evaluated by editing up to\nthousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2,\nT5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks,\ni.e., closed book fact-checking and question answering. Remarkably, MALMEN is\ncapable of editing hundreds of times more facts than strong baselines with the\nidentical hyper-network architecture and outperforms editor specifically\ndesigned for GPT. Our code is available at\nhttps://github.com/ChenmienTan/malmen.",
            "author": [
                "Chenmien Tan",
                "Ge Zhang",
                "Jie Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04661v2",
                "http://arxiv.org/pdf/2311.04661v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04950v2",
            "title": "Lightweight Diffusion Models with Distillation-Based Block Neural\n  Architecture Search",
            "updated": "2023-11-15T07:37:28Z",
            "published": "2023-11-08T12:56:59Z",
            "summary": "Diffusion models have recently shown remarkable generation ability, achieving\nstate-of-the-art performance in many tasks. However, the high computational\ncost is still a troubling problem for diffusion models. To tackle this problem,\nwe propose to automatically remove the structural redundancy in diffusion\nmodels with our proposed Diffusion Distillation-based Block-wise Neural\nArchitecture Search (DiffNAS). Specifically, given a larger pretrained teacher,\nwe leverage DiffNAS to search for the smallest architecture which can achieve\non-par or even better performance than the teacher. Considering current\ndiffusion models are based on UNet which naturally has a block-wise structure,\nwe perform neural architecture search independently in each block, which\nlargely reduces the search space. Different from previous block-wise NAS\nmethods, DiffNAS contains a block-wise local search strategy and a retraining\nstrategy with a joint dynamic loss. Concretely, during the search process, we\nblock-wisely select the best subnet to avoid the unfairness brought by the\nglobal search strategy used in previous works. When retraining the searched\narchitecture, we adopt a dynamic joint loss to maintain the consistency between\nsupernet training and subnet retraining, which also provides informative\nobjectives for each block and shortens the paths of gradient propagation. We\ndemonstrate this joint loss can effectively improve model performance. We also\nprove the necessity of the dynamic adjustment of this loss. The experiments\nshow that our method can achieve significant computational reduction,\nespecially on latent diffusion models with about 50\\% MACs and Parameter\nreduction.",
            "author": [
                "Siao Tang",
                "Xin Wang",
                "Hong Chen",
                "Chaoyu Guan",
                "Yansong Tang",
                "Wenwu zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04950v2",
                "http://arxiv.org/pdf/2311.04950v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04656v1",
            "title": "Computing pivot-minors",
            "updated": "2023-11-08T12:55:32Z",
            "published": "2023-11-08T12:55:32Z",
            "summary": "A graph $G$ contains a graph $H$ as a pivot-minor if $H$ can be obtained from\n$G$ by applying a sequence of vertex deletions and edge pivots. Pivot-minors\nplay an important role in the study of rank-width. Pivot-minors have mainly\nbeen studied from a structural perspective. In this paper we perform the first\nsystematic computational complexity study of pivot-minors. We first prove that\nthe Pivot-Minor problem, which asks if a given graph $G$ contains a pivot-minor\nisomorphic to a given graph $H$, is NP-complete. If $H$ is not part of the\ninput, we denote the problem by $H$-Pivot-Minor. We give a certifying\npolynomial-time algorithm for $H$-Pivot-Minor when (1) $H$ is an induced\nsubgraph of $P_3+tP_1$ for some integer $t\\geq 0$, (2) $H=K_{1,t}$ for some\ninteger $t\\geq 1$, or (3) $|V(H)|\\leq 4$ except when $H \\in \\{K_4,C_3+ P_1\\}$.\nLet ${\\cal F}_H$ be the set of induced-subgraph-minimal graphs that contain a\npivot-minor isomorphic to $H$. To prove the above statement, we either show\nthat there is an integer $c_H$ such that all graphs in ${\\cal F}_H$ have at\nmost $c_H$ vertices, or we determine ${\\cal F}_H$ precisely, for each of the\nabove cases.",
            "author": [
                "Konrad K. Dabrowski",
                "Fran\u00e7ois Dross",
                "Jisu Jeong",
                "Mamadou Moustapha Kant\u00e9",
                "O-joung Kwon",
                "Sang-il Oum",
                "Dani\u00ebl Paulusma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04656v1",
                "http://arxiv.org/pdf/2311.04656v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04655v1",
            "title": "Two new algorithms for solving M\u00fcller games and their applications",
            "updated": "2023-11-08T12:54:23Z",
            "published": "2023-11-08T12:54:23Z",
            "summary": "M\\\"uller games form a well-established class of games for model checking and\nverification. These games are played on directed graphs $\\mathcal G$ where\nPlayer 0 and Player 1 play by generating an infinite path through the graph.\nThe winner is determined by the set $X$ consisting of all vertices in the path\nthat occur infinitely often. If $X$ belongs to $\\Omega$, a specified collection\nof subsets of $\\mathcal G$, then Player 0 wins. Otherwise, Player 1 claims the\nwin. These games are determined, enabling the partitioning of $\\mathcal G$ into\ntwo sets $W_0$ and $W_1$ of winning positions for Player 0 and Player 1,\nrespectively. Numerous algorithms exist that decide M\\\"uller games $\\mathcal G$\nby computing the sets $W_0$ and $W_1$. In this paper, we introduce two novel\nalgorithms that outperform all previously known methods for deciding explicitly\ngiven M\\\"uller games, especially in the worst-case scenarios. The previously\nknown algorithms either reduce M\\\"uller games to other known games (e.g. safety\ngames) or recursively change the underlying graph $\\mathcal G$ and the\ncollection of sets in $\\Omega$. In contrast, our approach does not employ these\ntechniques but instead leverages subgames, the sets within $\\Omega$, and their\ninteractions. This distinct methodology sets our algorithms apart from prior\napproaches for deciding M\\\"uller games. Additionally, our algorithms offer\nenhanced clarity and ease of comprehension. Importantly, our techniques are\napplicable not only to M\\\"uller games but also to improving the performance of\nexisting algorithms that handle other game classes, including coloured M\\\"uller\ngames, McNaughton games, Rabin games, and Streett games.",
            "author": [
                "Zihui Liang",
                "Bakh Khoussainov",
                "Mingyu Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04655v1",
                "http://arxiv.org/pdf/2311.04655v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04651v1",
            "title": "Higher-Order Bayesian Networks, Exactly (Extended version)",
            "updated": "2023-11-08T12:51:47Z",
            "published": "2023-11-08T12:51:47Z",
            "summary": "Bayesian networks (BNs) are graphical \\emph{first-order} probabilistic models\nthat allow for a compact representation of large probability distributions, and\nfor efficient inference, both exact and approximate. We introduce a\n\\emph{higher-order} programming language -- in the idealized form of a\n$\\lambda$-calculus -- which we prove \\emph{sound and complete} w.r.t. BNs: each\nBN can be encoded as a term, and conversely each (possibly higher-order and\nrecursive) program of ground type \\emph{compiles} into a BN. The language\nallows for the specification of recursive probability models and hierarchical\nstructures. Moreover, we provide a \\emph{compositional} and \\emph{cost-aware}\nsemantics which is based on factors, the standard mathematical tool used in\nBayesian inference. Our results rely on advanced techniques rooted into linear\nlogic, intersection types, rewriting theory, and Girard's geometry of\ninteraction, which are here combined in a novel way.",
            "author": [
                "Claudia Faggian",
                "Daniele Pautasso",
                "Gabriele Vanoni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04651v1",
                "http://arxiv.org/pdf/2311.04651v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04649v1",
            "title": "AIRIC: Orchestration of Virtualized Radio Access Networks with Noisy\n  Neighbours",
            "updated": "2023-11-08T12:49:09Z",
            "published": "2023-11-08T12:49:09Z",
            "summary": "Radio Access Networks virtualization (vRAN) is on its way becoming a reality\ndriven by the new requirements in mobile networks, such as scalability and cost\nreduction. Unfortunately, there is no free lunch but a high price to be paid in\nterms of computing overhead introduced by noisy neighbors problem when multiple\nvirtualized base station instances share computing platforms. In this paper,\nfirst, we thoroughly dissect the multiple sources of computing overhead in a\nvRAN, quantifying their different contributions to the overall performance\ndegradation. Second, we design an AI-driven Radio Intelligent Controller\n(AIRIC) to orchestrate vRAN computing resources. AIRIC relies upon a hybrid\nneural network architecture combining a relation network (RN) and a deep\nQ-Network (DQN) such that: (i) the demand of concurrent virtual base stations\nis satisfied considering the overhead posed by the noisy neighbors problem\nwhile the operating costs of the vRAN infrastructure is minimized; and (ii)\ndynamically changing contexts in terms of network demand, signal-to-noise ratio\n(SNR) and the number of base station instances are efficiently supported. Our\nresults show that AIRIC performs very closely to an offline optimal oracle,\nattaining up to 30% resource savings, and substantially outperforms existing\nbenchmarks in service guarantees.",
            "author": [
                "J. Xavier Salvat Lozano",
                "Andres Garcia-Saavedra",
                "Xi Li",
                "Xavier Costa-Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04649v1",
                "http://arxiv.org/pdf/2311.04649v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04648v2",
            "title": "Chrono DEM-Engine: A Discrete Element Method dual-GPU simulator with\n  customizable contact forces and element shape",
            "updated": "2023-11-09T13:57:50Z",
            "published": "2023-11-08T12:48:35Z",
            "summary": "This paper introduces DEM-Engine, a new submodule of Project Chrono, that is\ndesigned to carry out Discrete Element Method (DEM) simulations. Based on\nspherical primitive shapes, DEM-Engine can simulate polydisperse granular\nmaterials and handle complex shapes generated as assemblies of primitives,\nreferred to as clumps. DEM-Engine has a multi-tier parallelized structure that\nis optimized to operate simultaneously on two GPUs. The code uses\ncustom-defined data types to reduce memory footprint and increase bandwidth. A\nnovel \"delayed contact detection\" algorithm allows the decoupling of the\ncontact detection and force computation, thus splitting the workload into two\nasynchronous GPU streams. DEM-Engine uses just-in-time compilation to support\nuser-defined contact force models. This paper discusses its C++ and Python\ninterfaces and presents a variety of numerical tests, in which impact forces,\ncomplex-shaped particle flows, and a custom force model are validated\nconsidering well-known benchmark cases. Additionally, the full potential of the\nsimulator is demonstrated for the investigation of extraterrestrial rover\nmobility on granular terrain. The chosen case study demonstrates that\nlarge-scale co-simulations (comprising 11 million elements) spanning 15\nseconds, in conjunction with an external multi-body dynamics system, can be\nefficiently executed within a day. Lastly, a performance test suggests that\nDEM-Engine displays linear scaling up to 150 million elements on two NVIDIA\nA100 GPUs.",
            "author": [
                "Ruochun Zhang",
                "Bonaventura Tagliafierro",
                "Colin Vanden Heuvel",
                "Shlok Sabarwal",
                "Luning Bakke",
                "Yulong Yue",
                "Xin Wei",
                "Radu Serban",
                "Dan Negrut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04648v2",
                "http://arxiv.org/pdf/2311.04648v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.NA",
                "cs.SE",
                "math.NA",
                "J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04645v1",
            "title": "SKU-Patch: Towards Efficient Instance Segmentation for Unseen Objects in\n  Auto-Store",
            "updated": "2023-11-08T12:44:38Z",
            "published": "2023-11-08T12:44:38Z",
            "summary": "In large-scale storehouses, precise instance masks are crucial for robotic\nbin picking but are challenging to obtain. Existing instance segmentation\nmethods typically rely on a tedious process of scene collection, mask\nannotation, and network fine-tuning for every single Stock Keeping Unit (SKU).\nThis paper presents SKU-Patch, a new patch-guided instance segmentation\nsolution, leveraging only a few image patches for each incoming new SKU to\npredict accurate and robust masks, without tedious manual effort and model\nre-training. Technical-wise, we design a novel transformer-based network with\n(i) a patch-image correlation encoder to capture multi-level image features\ncalibrated by patch information and (ii) a patch-aware transformer decoder with\nparallel task heads to generate instance masks. Extensive experiments on four\nstorehouse benchmarks manifest that SKU-Patch is able to achieve the best\nperformance over the state-of-the-art methods. Also, SKU-Patch yields an\naverage of nearly 100% grasping success rate on more than 50 unseen SKUs in a\nrobot-aided auto-store logistic pipeline, showing its effectiveness and\npracticality.",
            "author": [
                "Biqi Yang",
                "Weiliang Tang",
                "Xiaojie Gao",
                "Xianzhi Li",
                "Yun-Hui Liu",
                "Chi-Wing Fu",
                "Pheng-Ann Heng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04645v1",
                "http://arxiv.org/pdf/2311.04645v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04640v1",
            "title": "Object-Centric Learning with Slot Mixture Module",
            "updated": "2023-11-08T12:34:36Z",
            "published": "2023-11-08T12:34:36Z",
            "summary": "Object-centric architectures usually apply a differentiable module to the\nentire feature map to decompose it into sets of entity representations called\nslots. Some of these methods structurally resemble clustering algorithms, where\nthe cluster's center in latent space serves as a slot representation. Slot\nAttention is an example of such a method, acting as a learnable analog of the\nsoft k-means algorithm. Our work employs a learnable clustering method based on\nthe Gaussian Mixture Model. Unlike other approaches, we represent slots not\nonly as centers of clusters but also incorporate information about the distance\nbetween clusters and assigned vectors, leading to more expressive slot\nrepresentations. Our experiments demonstrate that using this approach instead\nof Slot Attention improves performance in object-centric scenarios, achieving\nstate-of-the-art results in the set property prediction task.",
            "author": [
                "Daniil Kirilenko",
                "Vitaliy Vorobyov",
                "Alexey K. Kovalev",
                "Aleksandr I. Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04640v1",
                "http://arxiv.org/pdf/2311.04640v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04634v1",
            "title": "VET: Visual Error Tomography for Point Cloud Completion and High-Quality\n  Neural Rendering",
            "updated": "2023-11-08T12:23:57Z",
            "published": "2023-11-08T12:23:57Z",
            "summary": "In the last few years, deep neural networks opened the doors for big advances\nin novel view synthesis. Many of these approaches are based on a (coarse) proxy\ngeometry obtained by structure from motion algorithms. Small deficiencies in\nthis proxy can be fixed by neural rendering, but larger holes or missing parts,\nas they commonly appear for thin structures or for glossy regions, still lead\nto distracting artifacts and temporal instability. In this paper, we present a\nnovel neural-rendering-based approach to detect and fix such deficiencies. As a\nproxy, we use a point cloud, which allows us to easily remove outlier geometry\nand to fill in missing geometry without complicated topological operations.\nKeys to our approach are (i) a differentiable, blending point-based renderer\nthat can blend out redundant points, as well as (ii) the concept of Visual\nError Tomography (VET), which allows us to lift 2D error maps to identify\n3D-regions lacking geometry and to spawn novel points accordingly. Furthermore,\n(iii) by adding points as nested environment maps, our approach allows us to\ngenerate high-quality renderings of the surroundings in the same pipeline. In\nour results, we show that our approach can improve the quality of a point cloud\nobtained by structure from motion and thus increase novel view synthesis\nquality significantly. In contrast to point growing techniques, the approach\ncan also fix large-scale holes and missing thin structures effectively.\nRendering quality outperforms state-of-the-art methods and temporal stability\nis significantly improved, while rendering is possible at real-time frame\nrates.",
            "author": [
                "Linus Franke",
                "Darius R\u00fcckert",
                "Laura Fink",
                "Matthias Innmann",
                "Marc Stamminger"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618212",
                "http://arxiv.org/abs/2311.04634v1",
                "http://arxiv.org/pdf/2311.04634v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "I.3; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04633v1",
            "title": "General Framework to Evaluate Unlinkability in Biometric Template\n  Protection Systems",
            "updated": "2023-11-08T12:22:57Z",
            "published": "2023-11-08T12:22:57Z",
            "summary": "The wide deployment of biometric recognition systems in the last two decades\nhas raised privacy concerns regarding the storage and use of biometric data. As\na consequence, the ISO/IEC 24745 international standard on biometric\ninformation protection has established two main requirements for protecting\nbiometric templates: irreversibility and unlinkability. Numerous efforts have\nbeen directed to the development and analysis of irreversible templates.\nHowever, there is still no systematic quantitative manner to analyse the\nunlinkability of such templates. In this paper we address this shortcoming by\nproposing a new general framework for the evaluation of biometric templates'\nunlinkability. To illustrate the potential of the approach, it is applied to\nassess the unlinkability of four state-of-the-art techniques for biometric\ntemplate protection: biometric salting, Bloom filters, Homomorphic Encryption\nand block re-mapping. For the last technique, the proposed framework is\ncompared with other existing metrics to show its advantages.",
            "author": [
                "Marta Gomez-Barrero",
                "Javier Galbally",
                "Christian Rathgeb",
                "Christoph Busch"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIFS.2017.2788000",
                "http://arxiv.org/abs/2311.04633v1",
                "http://arxiv.org/pdf/2311.04633v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04948v1",
            "title": "Explained anomaly detection in text reviews: Can subjective scenarios be\n  correctly evaluated?",
            "updated": "2023-11-08T11:51:47Z",
            "published": "2023-11-08T11:51:47Z",
            "summary": "This paper presents a pipeline to detect and explain anomalous reviews in\nonline platforms. The pipeline is made up of three modules and allows the\ndetection of reviews that do not generate value for users due to either\nworthless or malicious composition. The classifications are accompanied by a\nnormality score and an explanation that justifies the decision made. The\npipeline's ability to solve the anomaly detection task was evaluated using\ndifferent datasets created from a large Amazon database. Additionally, a study\ncomparing three explainability techniques involving 241 participants was\nconducted to assess the explainability module. The study aimed to measure the\nimpact of explanations on the respondents' ability to reproduce the\nclassification model and their perceived usefulness. This work can be useful to\nautomate tasks in review online platforms, such as those for electronic\ncommerce, and offers inspiration for addressing similar problems in the field\nof anomaly detection in textual data. We also consider it interesting to have\ncarried out a human evaluation of the capacity of different explainability\ntechniques in a real and infrequent scenario such as the detection of anomalous\nreviews, as well as to reflect on whether it is possible to explain tasks as\nhumanly subjective as this one.",
            "author": [
                "David Novoa-Paradela",
                "Oscar Fontenla-Romero",
                "Bertha Guijarro-Berdi\u00f1as"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04948v1",
                "http://arxiv.org/pdf/2311.04948v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04617v1",
            "title": "Image Patch-Matching with Graph-Based Learning in Street Scenes",
            "updated": "2023-11-08T11:35:43Z",
            "published": "2023-11-08T11:35:43Z",
            "summary": "Matching landmark patches from a real-time image captured by an on-vehicle\ncamera with landmark patches in an image database plays an important role in\nvarious computer perception tasks for autonomous driving. Current methods focus\non local matching for regions of interest and do not take into account spatial\nneighborhood relationships among the image patches, which typically correspond\nto objects in the environment. In this paper, we construct a spatial graph with\nthe graph vertices corresponding to patches and edges capturing the spatial\nneighborhood information. We propose a joint feature and metric learning model\nwith graph-based learning. We provide a theoretical basis for the graph-based\nloss by showing that the information distance between the distributions\nconditioned on matched and unmatched pairs is maximized under our framework. We\nevaluate our model using several street-scene datasets and demonstrate that our\napproach achieves state-of-the-art matching results.",
            "author": [
                "Rui She",
                "Qiyu Kang",
                "Sijie Wang",
                "Wee Peng Tay",
                "Yong Liang Guan",
                "Diego Navarro Navarro",
                "Andreas Hartmannsgruber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04617v1",
                "http://arxiv.org/pdf/2311.04617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04614v1",
            "title": "LuminanceL1Loss: A loss function which measures percieved brightness and\n  colour differences",
            "updated": "2023-11-08T11:30:05Z",
            "published": "2023-11-08T11:30:05Z",
            "summary": "We introduce LuminanceL1Loss, a novel loss function designed to enhance the\nperformance of image restoration tasks. We demonstrate its superiority over MSE\nwhen applied to the Retinexformer, BUIFD and DnCNN architectures. Our proposed\nLuminanceL1Loss leverages a unique approach by transforming images into\ngrayscale and subsequently computing the MSE loss for both grayscale and color\nchannels. Experimental results demonstrate that this innovative loss function\nconsistently outperforms traditional methods, showcasing its potential in image\ndenoising and other related tasks in image reconstruction. It demonstrates\ngains up to 4.7dB. The results presented in this study highlight the efficacy\nof LuminanceL1Loss for various image restoration tasks.",
            "author": [
                "Dominic De Jonge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04614v1",
                "http://arxiv.org/pdf/2311.04614v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04607v1",
            "title": "Finite-size versus finite-temperature effects in the critical long-range\n  $O(N)$ model",
            "updated": "2023-11-08T11:14:32Z",
            "published": "2023-11-08T11:14:32Z",
            "summary": "In this paper we consider classical and quantum versions of the critical\nlong-range $O(N)$ model, for which we study finite-size and finite-temperature\neffects, respectively, at large $N$. First, we consider the classical\n(isotropic) model, which is conformally invariant at criticality, and we\nintroduce one compact spatial direction. We show that the finite size\ndynamically induces an effective mass and we compute the one-point functions\nfor bilinear primary operators with arbitrary spin and twist. Second, we study\nthe quantum model, mapped to a Euclidean anisotropic field theory, local in\nEuclidean time and long-range in space, which we dub \\emph{fractional Lifshitz\nfield theory}. We show that this model admits a fixed point at zero\ntemperature, where it displays anisotropic Lifshitz scaling, and show that at\nfinite temperature a thermal mass is induced. We then compute the one-point\nfunctions for an infinite family of bilinear scaling operators. In both the\nclassical and quantum model, we find that, as previously noted for the\nshort-range $O(N)$ model in [arXiv:1802.10266], the large-$N$ two-point\nfunction contains information about the one-point functions, not only of the\nbilinear operators, but also of operators that appear in the operator product\nexpansion of two fundamental fields only at subleading order in $1/N$, namely\npowers of the Hubbard-Stratonovich intermediate field.",
            "author": [
                "Dario Benedetti",
                "Razvan Gurau",
                "Sabine Harribey",
                "Davide Lettera"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04607v1",
                "http://arxiv.org/pdf/2311.04607v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04603v1",
            "title": "Navigating Resource Conflicts: Co-opetition and Fairness",
            "updated": "2023-11-08T11:11:05Z",
            "published": "2023-11-08T11:11:05Z",
            "summary": "In today's dynamic and interconnected world, resource constraints pose\nsignificant challenges across various domains, ranging from networks, logistics\nand manufacturing to project management and optimization, etc.\nResource-constrained problems (RCPs) represent a class of complex computational\nproblems that require efficient allocation and utilization of limited resources\nto achieve optimal outcomes. This thesis aims to delve into such problems\ninvolving multiple agents, where agents aim to enhance their own payoffs, or a\nneutral moderator aims to maximise the system revenue while distributing the\nresources appropriately among all agents. In the former type of problems,\nagents may seek collaboration to achieve higher individual shares, resulting in\na cooperative game with competition, i.e., co-opetition. Cooperative and\nnon-cooperative game theory tools are utilized to analyze such games. On the\nother hand, for the latter kind of problems, we use tools from optimization and\nMarkov decision processes.",
            "author": [
                "Shiksha Singhal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04603v1",
                "http://arxiv.org/pdf/2311.04603v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04599v2",
            "title": "Explainable artificial intelligence model for identifying Market Value\n  in Professional Soccer Players",
            "updated": "2023-11-23T08:31:55Z",
            "published": "2023-11-08T11:01:32Z",
            "summary": "This study introduces an advanced machine learning method for predicting\nsoccer players' market values, combining ensemble models and the Shapley\nAdditive Explanations (SHAP) for interpretability. Utilizing data from about\n12,000 players from Sofifa, the Boruta algorithm streamlined feature selection.\nThe Gradient Boosting Decision Tree (GBDT) model excelled in predictive\naccuracy, with an R-squared of 0.901 and a Root Mean Squared Error (RMSE) of\n3,221,632.175. Player attributes in skills, fitness, and cognitive areas\nsignificantly influenced market value. These insights aid sports industry\nstakeholders in player valuation. However, the study has limitations, like\nunderestimating superstar players' values and needing larger datasets. Future\nresearch directions include enhancing the model's applicability and exploring\nvalue prediction in various contexts.",
            "author": [
                "Chunyang Huang",
                "Shaoliang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04599v2",
                "http://arxiv.org/pdf/2311.04599v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04597v1",
            "title": "A quantum Monte Carlo based density functional for Dysprosium dipolar\n  system",
            "updated": "2023-11-08T10:59:12Z",
            "published": "2023-11-08T10:59:12Z",
            "summary": "We present a quantum Monte Carlo based density functional to describe droplet\nformation and supersolidity in dipolar systems. The usual Lee-Huang-Yang term,\naccounting for quantum correlations in the conventional extended\nGross-Pitaievskii equation (eGPE), has been substituted by the correlation\nenergy evaluated with Quantum Monte Carlo. We demonstrate the ability of the\nnew functional to reproduce existing experimental data for the minimum critical\nnumber of atoms $N_\\mathrm{c}$ required for droplet formation. $N_\\mathrm{c}$\nis a challenging quantity for theoretical predictions, and the eGPE provides\nonly a qualitative description of it, mainly when it is applied to Dysprosium.\nWe also use the new approach to characterize the BEC-supersolid transition. The\nquantum Monte Carlo based functional can be easily implemented in any existing\neGPE code, improving the description of dipolar systems without increasing the\ncomputational cost.",
            "author": [
                "Ra\u00fal Bomb\u00edn",
                "Viktor Cikojevi\u0107",
                "Ferran Mazzanti",
                "Jordi Boronat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04597v1",
                "http://arxiv.org/pdf/2311.04597v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04594v1",
            "title": "Fully-heavy baryons $QQQ$ in vacuum and hot QCD medium",
            "updated": "2023-11-08T10:49:44Z",
            "published": "2023-11-08T10:49:44Z",
            "summary": "We study the properties of fully-heavy baryons in the vacuum and the hot QCD\nmedium, which is created in relativistic heavy-ion collisions. Masses and wave\nfunctions of $\\Omega_{ccc}$, $\\Omega_{ccb}$, $\\Omega_{bbc}$, and $\\Omega_{bbb}$\nup to the second radial excited states are obtained by solving the three-body\nSchr\\\"odinger equation with Hyperspherical Harmonics method. With parameters\ncompletely fixed by fitting quarkonium boundstates in vacuum, we predicted the\nmasses for $1S$, $2S$, and $3S$ states of fully-heavy baryons. We also computed\nthe temperature dependence of baryon masses and the thermal widths in a hot QCD\nmedium. These properties are important to precise study of fully-heavy baryon\nproduction in heavy ion collisions.",
            "author": [
                "Jiaxing Zhao",
                "Shuzhe Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04594v1",
                "http://arxiv.org/pdf/2311.04594v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04592v2",
            "title": "On Characterizing the Evolution of Embedding Space of Neural Networks\n  using Algebraic Topology",
            "updated": "2023-11-09T15:29:49Z",
            "published": "2023-11-08T10:45:12Z",
            "summary": "We study how the topology of feature embedding space changes as it passes\nthrough the layers of a well-trained deep neural network (DNN) through Betti\nnumbers. Motivated by existing studies using simplicial complexes on shallow\nfully connected networks (FCN), we present an extended analysis using Cubical\nhomology instead, with a variety of popular deep architectures and real image\ndatasets. We demonstrate that as depth increases, a topologically complicated\ndataset is transformed into a simple one, resulting in Betti numbers attaining\ntheir lowest possible value. The rate of decay in topological complexity (as a\nmetric) helps quantify the impact of architectural choices on the\ngeneralization ability. Interestingly from a representation learning\nperspective, we highlight several invariances such as topological invariance of\n(1) an architecture on similar datasets; (2) embedding space of a dataset for\narchitectures of variable depth; (3) embedding space to input resolution/size,\nand (4) data sub-sampling. In order to further demonstrate the link between\nexpressivity \\& the generalization capability of a network, we consider the\ntask of ranking pre-trained models for downstream classification task (transfer\nlearning). Compared to existing approaches, the proposed metric has a better\ncorrelation to the actually achievable accuracy via fine-tuning the pre-trained\nmodel.",
            "author": [
                "Suryaka Suresh",
                "Bishshoy Das",
                "Vinayak Abrol",
                "Sumantra Dutta Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04592v2",
                "http://arxiv.org/pdf/2311.04592v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04591v3",
            "title": "Rethinking Event-based Human Pose Estimation with 3D Event\n  Representations",
            "updated": "2023-12-01T07:26:35Z",
            "published": "2023-11-08T10:45:09Z",
            "summary": "Human pose estimation is a fundamental and appealing task in computer vision.\nTraditional frame-based cameras and videos are commonly applied, yet, they\nbecome less reliable in scenarios under high dynamic range or heavy motion\nblur. In contrast, event cameras offer a robust solution for navigating these\nchallenging contexts. Predominant methodologies incorporate event cameras into\nlearning frameworks by accumulating events into event frames. However, such\nmethods tend to marginalize the intrinsic asynchronous and high temporal\nresolution characteristics of events. This disregard leads to a loss in\nessential temporal dimension data, crucial for discerning distinct actions. To\naddress this issue and to unlock the 3D potential of event information, we\nintroduce two 3D event representations: the Rasterized Event Point Cloud\n(RasEPC) and the Decoupled Event Voxel (DEV). The RasEPC collates events within\nconcise temporal slices at identical positions, preserving 3D attributes with\nstatistical cues and markedly mitigating memory and computational demands.\nMeanwhile, the DEV representation discretizes events into voxels and projects\nthem across three orthogonal planes, utilizing decoupled event attention to\nretrieve 3D cues from the 2D planes. Furthermore, we develop and release\nEV-3DPW, a synthetic event-based dataset crafted to facilitate training and\nquantitative analysis in outdoor scenes. On the public real-world DHP19\ndataset, our event point cloud technique excels in real-time mobile\npredictions, while the decoupled event voxel method achieves the highest\naccuracy. Experiments on EV-3DPW demonstrate that the robustness of our\nproposed 3D representation methods compared to traditional RGB images and event\nframe techniques under the same backbones. Our code and dataset have been made\npublicly available at https://github.com/MasterHow/EventPointPose.",
            "author": [
                "Xiaoting Yin",
                "Hao Shi",
                "Jiaan Chen",
                "Ze Wang",
                "Yaozu Ye",
                "Huajian Ni",
                "Kailun Yang",
                "Kaiwei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04591v3",
                "http://arxiv.org/pdf/2311.04591v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "cs.RO",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04589v2",
            "title": "TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models",
            "updated": "2023-11-14T11:58:48Z",
            "published": "2023-11-08T10:34:16Z",
            "summary": "Despite Multi-modal Large Language Models (MM-LLMs) have made exciting\nstrides recently, they are still struggling to efficiently model the\ninteractions among multi-modal inputs and the generation in non-textual\nmodalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an\napproach to treat the input from any modality as a token sequence and learn a\njoint embedding space for all modalities. Specifically, for the input from any\nmodality, TEAL first discretizes it into a token sequence with the\noff-the-shelf tokenizer and embeds the token sequence into a joint embedding\nspace with a learnable embedding matrix. MM-LLMs just need to predict the\nmulti-modal tokens autoregressively as the textual LLMs do. Finally, the\ncorresponding de-tokenizer is applied to generate the output in each modality\nbased on the predicted token sequence. With the joint embedding space, TEAL\nenables the frozen LLMs to perform both understanding and generation tasks\ninvolving non-textual modalities, such as image and audio. Thus, the textual\nLLM can just work as an interface and maintain its high performance in textual\nunderstanding and generation. Experiments show that TEAL achieves substantial\nimprovements in multi-modal understanding, and implements a simple scheme for\nmulti-modal generations.",
            "author": [
                "Zhen Yang",
                "Yingxue Zhang",
                "Fandong Meng",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04589v2",
                "http://arxiv.org/pdf/2311.04589v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04588v1",
            "title": "Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based\n  sample selection",
            "updated": "2023-11-08T10:31:29Z",
            "published": "2023-11-08T10:31:29Z",
            "summary": "Machine Learning (ML) models become vulnerable to Model Stealing Attacks\n(MSA) when they are deployed as a service. In such attacks, the deployed model\nis queried repeatedly to build a labelled dataset. This dataset allows the\nattacker to train a thief model that mimics the original model. To maximize\nquery efficiency, the attacker has to select the most informative subset of\ndata points from the pool of available data. Existing attack strategies utilize\napproaches like Active Learning and Semi-Supervised learning to minimize costs.\nHowever, in the black-box setting, these approaches may select sub-optimal\nsamples as they train only one thief model. Depending on the thief model's\ncapacity and the data it was pretrained on, the model might even select noisy\nsamples that harm the learning process. In this work, we explore the usage of\nan ensemble of deep learning models as our thief model. We call our attack Army\nof Thieves(AOT) as we train multiple models with varying complexities to\nleverage the crowd's wisdom. Based on the ensemble's collective decision,\nuncertain samples are selected for querying, while the most confident samples\nare directly included in the training data. Our approach is the first one to\nutilize an ensemble of thief models to perform model extraction. We outperform\nthe base approaches of existing state-of-the-art methods by at least 3% and\nachieve a 21% higher adversarial sample transferability than previous work for\nmodels trained on the CIFAR-10 dataset.",
            "author": [
                "Akshit Jindal",
                "Vikram Goyal",
                "Saket Anand",
                "Chetan Arora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04588v1",
                "http://arxiv.org/pdf/2311.04588v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04584v2",
            "title": "Weakly-supervised deepfake localization in diffusion-generated images",
            "updated": "2023-11-13T08:32:51Z",
            "published": "2023-11-08T10:27:36Z",
            "summary": "The remarkable generative capabilities of denoising diffusion models have\nraised new concerns regarding the authenticity of the images we see every day\non the Internet. However, the vast majority of existing deepfake detection\nmodels are tested against previous generative approaches (e.g. GAN) and usually\nprovide only a \"fake\" or \"real\" label per image. We believe a more informative\noutput would be to augment the per-image label with a localization map\nindicating which regions of the input have been manipulated. To this end, we\nframe this task as a weakly-supervised localization problem and identify three\nmain categories of methods (based on either explanations, local scores or\nattention), which we compare on an equal footing by using the Xception network\nas the common backbone architecture. We provide a careful analysis of all the\nmain factors that parameterize the design space: choice of method, type of\nsupervision, dataset and generator used in the creation of manipulated images;\nour study is enabled by constructing datasets in which only one of the\ncomponents is varied. Our results show that weakly-supervised localization is\nattainable, with the best performing detection method (based on local scores)\nbeing less sensitive to the looser supervision than to the mismatch in terms of\ndataset or generator.",
            "author": [
                "Dragos Tantaru",
                "Elisabeta Oneata",
                "Dan Oneata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04584v2",
                "http://arxiv.org/pdf/2311.04584v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04581v1",
            "title": "KiD: A Hardware Design Framework Targeting Unified NTT Multiplication\n  for CRYSTALS-Kyber and CRYSTALS-Dilithium on FPGA",
            "updated": "2023-11-08T10:26:13Z",
            "published": "2023-11-08T10:26:13Z",
            "summary": "Large-degree polynomial multiplication is an integral component of\npost-quantum secure lattice-based cryptographic algorithms like CRYSTALS-Kyber\nand Dilithium. The computational complexity of large-degree polynomial\nmultiplication can be reduced significantly through Number Theoretic\nTransformation (NTT). In this paper, we aim to develop a unified and shared NTT\narchitecture that can support polynomial multiplication for both CRYSTALS-Kyber\nand Dilithium. More specifically, in this paper, we have proposed three\ndifferent unified architectures for NTT multiplication in CRYSTALS-Kyber and\nDilithium with varying numbers of configurable radix-2 butterfly units.\nAdditionally, the developed implementation is coupled with a conflict-free\nmemory mapping scheme that allows the architecture to be fully pipelined. We\nhave validated our implementation on Artix-7, Zynq-7000 and Zynq Ultrascale+\nFPGAs. Our standalone implementations for NTT multiplication for CRYSTALS-Kyber\nand Dilithium perform better than the existing works, and our unified\narchitecture shows excellent area and timing performance compared to both\nstandalone and existing unified implementations. This architecture can\npotentially be used for compact and efficient implementation for CRYSTALS-Kyber\nand Dilithium.",
            "author": [
                "Suraj Mandal",
                "Debapriya Basu Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04581v1",
                "http://arxiv.org/pdf/2311.04581v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04580v1",
            "title": "Efficient computation of Lipschitz constants for MPC with symmetries",
            "updated": "2023-11-08T10:24:38Z",
            "published": "2023-11-08T10:24:38Z",
            "summary": "Lipschitz constants for linear MPC are useful for certifying inherent\nrobustness against unmodeled disturbances or robustness for neural\nnetwork-based approximations of the control law. In both cases, knowing the\nminimum Lipschitz constant leads to less conservative certifications. Computing\nthis minimum Lipschitz constant is trivial given the explicit MPC. However, the\ncomputation of the explicit MPC may be intractable for complex systems. The\npaper discusses a method for efficiently computing the minimum Lipschitz\nconstant without using the explicit control law. The proposed method simplifies\na recently presented mixed-integer linear program (MILP) that computes the\nminimum Lipschitz constant. The simplification is obtained by exploiting\nsaturation and symmetries of the control law and irrelevant constraints of the\noptimal control problem.",
            "author": [
                "Dieter Teichrib",
                "Moritz Schulze Darup"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04580v1",
                "http://arxiv.org/pdf/2311.04580v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04579v1",
            "title": "Text Finder Application for Android",
            "updated": "2023-11-08T10:23:56Z",
            "published": "2023-11-08T10:23:56Z",
            "summary": "A Text Finder, an android application that utilizes Optical Character\nRecognition (OCR) technology with the help of Google Cloud Vision API to\nextract text from images taken with the device camera or from existing images\nin the users phone. The extracted text can be saved to the device storage where\nall previous extracts can be easily accessed on a user-friendly interface. The\napplication also features editing, deletion and sharing options for the\nextracted text. The user interface is user-friendly, making the application\naccessible to students, professional and organizations for a variety of\npurposes, including document scanning, data entry, and information retrieval.\nManual extraction of text by typing or writing from images can be very\ntime-consuming and can be prone to errors. This application is an efficient and\nsimple solution for extracted texts and organizing important information from\nthe photos. This paper describes the technical details of the OCR technology\nand Googles ML Kit Text Recognition API used in the application, as well as the\ndesign, implementation and evaluation of the application in terms of\nperformance and accuracy. The research also explores the key objectives and\nbenefits of Text Finder, such as reducing the time and effort required and\nincreasing the efficiency of document-based tasks.",
            "author": [
                "Dr. Milind Godase",
                "Dr. Chandrani Singh",
                "Kunal Dhongadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04579v1",
                "http://arxiv.org/pdf/2311.04579v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "sinhgad.org",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04575v1",
            "title": "Deep learning as a tool for quantum error reduction in quantum image\n  processing",
            "updated": "2023-11-08T10:14:50Z",
            "published": "2023-11-08T10:14:50Z",
            "summary": "Despite the limited availability and quantum volume of quantum computers,\nquantum image representation is a widely researched area. Currently developed\nmethods use quantum entanglement to encode information about pixel positions.\nThese methods range from using the angle parameter of the rotation gate (e.g.,\nthe Flexible Representation of Quantum Images, FRQI), sequences of qubits\n(e.g., Novel Enhanced Quantum Representation, NEQR), or the angle parameter of\nthe phase shift gates (e.g., Local Phase Image Quantum Encoding, LPIQE) for\nstoring color information. All these methods are significantly affected by\ndecoherence and other forms of quantum noise, which is an inseparable part of\nquantum computing in the noisy intermediate-scale quantum era. These phenomena\ncan highly influence the measurements and result in extracted images that are\nvisually dissimilar to the originals. Because this process is at its foundation\nquantum, the computational reversal of this process is possible. There are many\nmethods for error correction, mitigation, and reduction, but all of them use\nquantum computer time or additional qubits to achieve the desired result. We\nreport the successful use of a generative adversarial network trained for\nimage-to-image translation, in conjunction with Phase Distortion Unraveling\nerror reduction method, for reducing overall error in images encoded using\nLPIQE.",
            "author": [
                "Krzysztof Werner",
                "Kamil Wereszczy\u0144ski",
                "Rafa\u0142 Potempa",
                "Krzysztof Cyran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04575v1",
                "http://arxiv.org/pdf/2311.04575v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04572v1",
            "title": "Structure and polymerization of liquid sulfur across the\n  $\u03bb$-transition",
            "updated": "2023-11-08T10:12:47Z",
            "published": "2023-11-08T10:12:47Z",
            "summary": "The anomalous $\\lambda$-transition of liquid sulfur, which is supposed to be\nrelated to the transformation of eight-membered sulfur rings into long\npolymeric chains, has attracted considerable attention. However, a detailed\ndescription of the underlying dynamical polymerization process is still\nmissing. Here, we study the structures and the mechanism of the polymerization\nprocesses of liquid sulfur across the $\\lambda$-transition as well as its\nreverse process of formation of the rings. We do so by performing\nab-initio-quality molecular dynamics simulations thanks to a combination of\nmachine learning potentials and state-of-the-art enhanced sampling techniques.\nWith our approach, we obtain structural results that are in good agreement with\nthe experiments and we report precious dynamical insights into the mechanisms\ninvolved in the process.",
            "author": [
                "Manyi Yang",
                "Enrico Trizio",
                "Michele Parrinello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04572v1",
                "http://arxiv.org/pdf/2311.04572v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04571v1",
            "title": "Restoring symmetries in quantum computing using Classical Shadows",
            "updated": "2023-11-08T10:11:01Z",
            "published": "2023-11-08T10:11:01Z",
            "summary": "We introduce a method to enforce some symmetries starting from a trial\nwave-function prepared on quantum computers that might not respect these\nsymmetries. The technique eliminates the necessity for performing the\nprojection on the quantum computer itself. Instead, this task is conducted as a\npost-processing step on the system's \"Classical Shadow\". Illustrations of the\napproach are given for the parity, particle number, and spin projectors that\nare of particular interest in interacting many-body systems. We compare the\nmethod with another classical post-processing technique based on direct\nmeasurements of the quantum register. We show that the present scheme can be\ncompetitive to predict observables on symmetry-restored states once\noptimization through derandomization is employed. The technique is illustrated\nthrough its application to compute the projected energy for the pairing model\nHamiltonian.",
            "author": [
                "Edgar Andres Ruiz Guzman",
                "Denis Lacroix"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04571v1",
                "http://arxiv.org/pdf/2311.04571v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.str-el",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04569v1",
            "title": "GResilience: Trading Off Between the Greenness and the Resilience of\n  Collaborative AI Systems",
            "updated": "2023-11-08T10:01:39Z",
            "published": "2023-11-08T10:01:39Z",
            "summary": "A Collaborative Artificial Intelligence System (CAIS) works with humans in a\nshared environment to achieve a common goal. To recover from a disruptive event\nthat degrades its performance and ensures its resilience, a CAIS may then need\nto perform a set of actions either by the system, by the humans, or\ncollaboratively together. As for any other system, recovery actions may cause\nenergy adverse effects due to the additional required energy. Therefore, it is\nof paramount importance to understand which of the above actions can better\ntrade-off between resilience and greenness. In this in-progress work, we\npropose an approach to automatically evaluate CAIS recovery actions for their\nability to trade-off between the resilience and greenness of the system. We\nhave also designed an experiment protocol and its application to a real CAIS\ndemonstrator. Our approach aims to attack the problem from two perspectives: as\na one-agent decision problem through optimization, which takes the decision\nbased on the score of resilience and greenness, and as a two-agent decision\nproblem through game theory, which takes the decision based on the payoff\ncomputed for resilience and greenness as two players of a cooperative game.",
            "author": [
                "Diaeddin Rimawi",
                "Antonio Liotta",
                "Marco Todescato",
                "Barbara Russo"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43240-8_18",
                "http://arxiv.org/abs/2311.04569v1",
                "http://arxiv.org/pdf/2311.04569v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04567v2",
            "title": "CellPhoneDB v5: inferring cell-cell communication from single-cell\n  multiomics data",
            "updated": "2023-11-13T13:41:51Z",
            "published": "2023-11-08T09:59:03Z",
            "summary": "Cell-cell communication is essential for tissue development, regeneration and\nfunction, and its disruption can lead to diseases and developmental\nabnormalities. The revolution of single-cell genomics technologies offers\nunprecedented insights into cellular identities, opening new avenues to resolve\nthe intricate cellular interactions present in tissue niches. CellPhoneDB is a\nbioinformatics toolkit designed to infer cell-cell communication by combining a\ncurated repository of bona fide ligand-receptor interactions with a set of\ncomputational and statistical methods to integrate them with single-cell\ngenomics data. Importantly, CellPhoneDB captures the multimeric nature of\nmolecular complexes, thus representing cell-cell communication biology\nfaithfully. Here we present CellPhoneDB v5, an updated version of the tool,\nwhich offers several new features. Firstly, the repository has been expanded by\none-third with the addition of new interactions. These encompass interactions\nmediated by non-protein ligands such as endocrine hormones and GPCR ligands.\nSecondly, it includes a differentially expression-based methodology for more\ntailored interaction queries. Thirdly, it incorporates novel computational\nmethods to prioritise specific cell-cell interactions, leveraging other\nsingle-cell modalities, such as spatial information or TF activities (i.e.\nCellSign module). Finally, we provide CellPhoneDBViz, a module to interactively\nvisualise and share results amongst users. Altogether, CellPhoneDB v5 elevates\nthe precision of cell-cell communication inference, ushering in new\nperspectives to comprehend tissue biology in both healthy and pathological\nstates.",
            "author": [
                "Kevin Troul\u00e9",
                "Robert Petryszak",
                "Martin Prete",
                "James Cranley",
                "Alicia Harasty",
                "Zewen Kelvin Tuong",
                "Sarah A Teichmann",
                "Luz Garcia-Alonso",
                "Roser Vento-Tormo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04567v2",
                "http://arxiv.org/pdf/2311.04567v2"
            ],
            "primary_category": "q-bio.CB",
            "category": [
                "q-bio.CB",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04563v1",
            "title": "Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case\n  Study on the Abstractness-Concreteness Continuum",
            "updated": "2023-11-08T09:52:58Z",
            "published": "2023-11-08T09:52:58Z",
            "summary": "Humans tend to strongly agree on ratings on a scale for extreme cases (e.g.,\na CAT is judged as very concrete), but judgements on mid-scale words exhibit\nmore disagreement. Yet, collected rating norms are heavily exploited across\ndisciplines. Our study focuses on concreteness ratings and (i) implements\ncorrelations and supervised classification to identify salient multi-modal\ncharacteristics of mid-scale words, and (ii) applies a hard clustering to\nidentify patterns of systematic disagreement across raters. Our results suggest\nto either fine-tune or filter mid-scale target words before utilising them.",
            "author": [
                "Urban Knuple\u0161",
                "Diego Frassinelli",
                "Sabine Schulte im Walde"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04563v1",
                "http://arxiv.org/pdf/2311.04563v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04559v1",
            "title": "Individual and gender inequality in computer science: A career study of\n  cohorts from 1970 to 2000",
            "updated": "2023-11-08T09:42:09Z",
            "published": "2023-11-08T09:42:09Z",
            "summary": "Inequality prevails in science. Individual inequality means that most perish\nquickly and only a few are successful, while gender inequality implies that\nthere are differences in achievements for women and men. Using large-scale\nbibliographic data and following a computational approach, we study the\nevolution of individual and gender inequality for cohorts from 1970 to 2000 in\nthe whole field of computer science as it grows and becomes a team-based\nscience. We find that individual inequality in productivity (publications)\nincreases over a scholar's career but is historically invariant, while\nindividual inequality in impact (citations), albeit larger, is stable across\ncohorts and careers. Gender inequality prevails regarding productivity, but\nthere is no evidence for differences in impact. The Matthew Effect is shown to\naccumulate advantages to early achievements and to become stronger over the\ndecades, indicating the rise of a \"publish or perish\" imperative. Only some\nauthors manage to reap the benefits that publishing in teams promises. The\nMatthew Effect then amplifies initial differences and propagates the gender\ngap. Women continue to fall behind because they continue to be at a higher risk\nof dropping out for reasons that have nothing to do with early-career\nachievements or social support. Our findings suggest that mentoring programs\nfor women to improve their social-networking skills can help to reduce gender\ninequality.",
            "author": [
                "Haiko Lietz",
                "Mohsen Jadidi",
                "Daniel Kostic",
                "Milena Tsvetkova",
                "Claudia Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04559v1",
                "http://arxiv.org/pdf/2311.04559v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "K.4.3; K.7.0; J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04558v1",
            "title": "Free-Space Optical Spiking Neural Network",
            "updated": "2023-11-08T09:41:14Z",
            "published": "2023-11-08T09:41:14Z",
            "summary": "Neuromorphic engineering has emerged as a promising avenue for developing\nbrain-inspired computational systems. However, conventional electronic AI-based\nprocessors often encounter challenges related to processing speed and thermal\ndissipation. As an alternative, optical implementations of such processors have\nbeen proposed, capitalizing on the intrinsic information-processing\ncapabilities of light. Within the realm of optical neuromorphic engineering,\nvarious optical neural networks (ONNs) have been explored. Among these, Spiking\nNeural Networks (SNNs) have exhibited notable success in emulating the\ncomputational principles of the human brain. Nevertheless, the integration of\noptical SNN processors has presented formidable obstacles, mainly when dealing\nwith the computational demands of large datasets. In response to these\nchallenges, we introduce a pioneering concept: the Free-space Optical deep\nSpiking Convolutional Neural Network (OSCNN). This novel approach draws\ninspiration from computational models of the human eye. We have meticulously\ndesigned various optical components within the OSCNN to tackle object detection\ntasks across prominent benchmark datasets, including MNIST, ETH 80, and\nCaltech. Our results demonstrate promising performance with minimal latency and\npower consumption compared to their electronic ONN counterparts. Additionally,\nwe conducted several pertinent simulations, such as optical intensity\nto-latency conversion and synchronization. Of particular significance is the\nevaluation of the feature extraction layer, employing a Gabor filter bank,\nwhich stands to impact the practical deployment of diverse ONN architectures\nsignificantly.",
            "author": [
                "Reyhane Ahmadi",
                "Amirreza Ahmadnejad",
                "Somayyeh Koohi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04558v1",
                "http://arxiv.org/pdf/2311.04558v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04557v1",
            "title": "Efficient Zero-Order Robust Optimization for Real-Time Model Predictive\n  Control with acados",
            "updated": "2023-11-08T09:39:10Z",
            "published": "2023-11-08T09:39:10Z",
            "summary": "Robust and stochastic optimal control problem (OCP) formulations allow a\nsystematic treatment of uncertainty, but are typically associated with a high\ncomputational cost. The recently proposed zero-order robust optimization (zoRO)\nalgorithm mitigates the computational cost of uncertainty-aware MPC by\npropagating the uncertainties outside of the MPC problem. This paper details\nthe combination of zoRO with the real-time iteration (RTI) scheme and presents\nan efficient open-source implementation in acados, utilizing BLASFEO for the\nlinear algebra operations. In addition to the scaling advantages posed by the\nzoRO algorithm, the efficient implementation drastically reduces the\ncomputational overhead, and, combined with an RTI scheme, enables the use of\ntube-based MPC for a wider range of applications. The flexibility, usability\nand effectiveness of the proposed implementation is demonstrated on two\nexamples. On the practical example of a differential drive robot, the proposed\nimplementation results in a tenfold reduction of computation time with respect\nto the previously available zoRO implementation.",
            "author": [
                "Jonathan Frey",
                "Yunfan Gao",
                "Florian Messerer",
                "Amon Lahr",
                "Melanie Zeilinger",
                "Moritz Diehl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04557v1",
                "http://arxiv.org/pdf/2311.04557v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04556v1",
            "title": "A GPR-Based Emulator for Semi-numerical Reionization Code SCRIPT:\n  Parameter Inference from 21 cm Data",
            "updated": "2023-11-08T09:38:42Z",
            "published": "2023-11-08T09:38:42Z",
            "summary": "Semi-numerical models of reionization typically involve a large number of\nunknown parameters whose values are constrained by comparing with observations.\nIncreasingly often, exploring this parameter space using semi-numerical\nsimulations can become computationally intensive, thus necessitating the use of\nemulators. In this work, we present a likelihood emulator based on Gaussian\nProcess Regression (GPR) for our semi-numerical reionization code, SCRIPT, and\nuse it for parameter inference using mock 21 cm power spectrum data and\nBayesian MCMC analysis. A unique aspect of our methodology is the utilization\nof coarse resolution simulations to identify high-probability regions within\nthe parameter space, employing only a moderate amount of computational time.\nSamples drawn from these high-probability regions are used to construct the\ntraining set for the emulator. The subsequent MCMC using this GPR-trained\nemulator is found to provide parameter posteriors that agree reasonably well\nwith those obtained using conventional MCMC. The computing time for the\nanalysis, which includes both generation of training sets and training the\nemulator, is reduced by approximately an order of magnitude. This methodology\nis particularly advantageous in scenarios where one wants to use different\nparametrizations of reionization models and/or needs to start with broad prior\ndistributions on the parameters, offering an efficient and effective means of\nparameter inference.",
            "author": [
                "T. Roy Choudhury",
                "A. Paranjape",
                "B. Maity"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04556v1",
                "http://arxiv.org/pdf/2311.04556v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04554v1",
            "title": "Assessing Distractors in Multiple-Choice Tests",
            "updated": "2023-11-08T09:37:09Z",
            "published": "2023-11-08T09:37:09Z",
            "summary": "Multiple-choice tests are a common approach for assessing candidates'\ncomprehension skills. Standard multiple-choice reading comprehension exams\nrequire candidates to select the correct answer option from a discrete set\nbased on a question in relation to a contextual passage. For appropriate\nassessment, the distractor answer options must by definition be incorrect but\nplausible and diverse. However, generating good quality distractors satisfying\nthese criteria is a challenging task for content creators. We propose automated\nassessment metrics for the quality of distractors in multiple-choice reading\ncomprehension tests. Specifically, we define quality in terms of the\nincorrectness, plausibility and diversity of the distractor options. We assess\nincorrectness using the classification ability of a binary multiple-choice\nreading comprehension system. Plausibility is assessed by considering the\ndistractor confidence - the probability mass associated with the distractor\noptions for a standard multi-class multiple-choice reading comprehension\nsystem. Diversity is assessed by pairwise comparison of an embedding-based\nequivalence metric between the distractors of a question. To further validate\nthe plausibility metric we compare against candidate distributions over\nmultiple-choice questions and agreement with a ChatGPT model's interpretation\nof distractor plausibility and diversity.",
            "author": [
                "Vatsal Raina",
                "Adian Liusie",
                "Mark Gales"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04554v1",
                "http://arxiv.org/pdf/2311.04554v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04553v1",
            "title": "Geometric and bond frustration in transverse field Ising clusters",
            "updated": "2023-11-08T09:36:49Z",
            "published": "2023-11-08T09:36:49Z",
            "summary": "The Ising model, often seen as the paradigmatic spin model, has been heavily\nstudied for its mathematical description of ferromagnetism in statistical\nmechanics. We explore a quantum version of this model, the transverse field\nIsing model, and investigate how the quantum property of magnetization\nfluctuates with geometrical frustration, a phenomenon arising from the geometry\nof a spin system's ground state. We introduce a general measure for frustration\nand then implement a computational model built in Python that translates spin\nlattices into adjacency matrices, solves the spectrum of the transverse field\nIsing model, calculates the expected magnetization of the ground state, plots\nthe variable over randomly generated spin systems with controllable degrees of\ngeometrical frustration, and compares the evolution of these plots over an\nincreasing transverse field. Our finite-size studies exhibit an expected\ndecrease in magnetization with increasing frustration and suggest the\npossibility of robust phases in the large N limit over finite ranges of\nfrustration, which may be precursors to spin liquids or spin glasses.",
            "author": [
                "Abhiraj Jalagekar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04553v1",
                "http://arxiv.org/pdf/2311.04553v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04552v1",
            "title": "A 3D generative model of pathological multi-modal MR images and\n  segmentations",
            "updated": "2023-11-08T09:36:37Z",
            "published": "2023-11-08T09:36:37Z",
            "summary": "Generative modelling and synthetic data can be a surrogate for real medical\nimaging datasets, whose scarcity and difficulty to share can be a nuisance when\ndelivering accurate deep learning models for healthcare applications. In recent\nyears, there has been an increased interest in using these models for data\naugmentation and synthetic data sharing, using architectures such as generative\nadversarial networks (GANs) or diffusion models (DMs). Nonetheless, the\napplication of synthetic data to tasks such as 3D magnetic resonance imaging\n(MRI) segmentation remains limited due to the lack of labels associated with\nthe generated images. Moreover, many of the proposed generative MRI models lack\nthe ability to generate arbitrary modalities due to the absence of explicit\ncontrast conditioning. These limitations prevent the user from adjusting the\ncontrast and content of the images and obtaining more generalisable data for\ntraining task-specific models. In this work, we propose brainSPADE3D, a 3D\ngenerative model for brain MRI and associated segmentations, where the user can\ncondition on specific pathological phenotypes and contrasts. The proposed joint\nimaging-segmentation generative model is shown to generate high-fidelity\nsynthetic images and associated segmentations, with the ability to combine\npathologies. We demonstrate how the model can alleviate issues with\nsegmentation model performance when unexpected pathologies are present in the\ndata.",
            "author": [
                "Virginia Fernandez",
                "Walter Hugo Lopez Pinaya",
                "Pedro Borges",
                "Mark S. Graham",
                "Tom Vercauteren",
                "M. Jorge Cardoso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04552v1",
                "http://arxiv.org/pdf/2311.04552v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04551v1",
            "title": "Assessing crop diversity across scales using high-resolution remote\n  sensing over the European Union: first insights for agro-environmental\n  policies",
            "updated": "2023-11-08T09:35:38Z",
            "published": "2023-11-08T09:35:38Z",
            "summary": "Understanding crop diversity is crucial for resilience in farming, ecosystem\nservices, and effective agro-environmental policies. We utilize a novel EU-wide\nsatellite product (2018, 10 m resolution) to assess crop diversity across\ndifferent scales. We define local crop diversity ($\\alpha$-diversity) at 1 km\nscale, which in the EU is proportional to the area covered by large farms or\nclusters of small-to-medium sized farms. We also compute $\\gamma$-diversity,\ncovering landscape, regional, and national levels crop diversity.\n$\\beta$-diversity ($\\gamma$/$\\alpha$) provides a measure of between\nagroecosystems diversity. National $\\alpha$, $\\gamma$, and $\\beta$ diversity\nvaries greatly ($\\alpha$: 2.1-3.9, $\\gamma$: 3.5-7.5, $\\beta$: 1.22-2.27).\nEU-wide $\\gamma$-diversity increases logarithmically with spatial aggregation\n(1 km: 2.85, 100 km: 4.27). We categorize EU Member States (MS) into four\ngroups for crop diversification policy recommendations. Compared to the USA,\nthe EU exhibits higher diversity related to differences in farm structure and\npractices. High local $\\alpha$-diversity is only found for MS with small farms\n(<25 ha), but their presence doesn't always guarantee high local diversity.\nThis study aids CAP implementation in the EU, with potential for annual\ncontinental Copernicus crop type maps and ecosystem co-variates exploration for\na deeper understanding of agro-ecosystem services.",
            "author": [
                "Melissande Machefer",
                "Matteo Zampieri",
                "Marijn van der Velde",
                "Frank Dentener",
                "Martin Claverie",
                "Raphael d Andrimont"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04551v1",
                "http://arxiv.org/pdf/2311.04551v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04547v1",
            "title": "Large GPT-like Models are Bad Babies: A Closer Look at the Relationship\n  between Linguistic Competence and Psycholinguistic Measures",
            "updated": "2023-11-08T09:26:27Z",
            "published": "2023-11-08T09:26:27Z",
            "summary": "Research on the cognitive plausibility of language models (LMs) has so far\nmostly concentrated on modelling psycholinguistic response variables such as\nreading times, gaze durations and N400/P600 EEG signals, while mostly leaving\nout the dimension of what Mahowald et al. (2023) described as formal and\nfunctional linguistic competence, and developmental plausibility. We address\nthis gap by training a series of GPT-like language models of different sizes on\nthe strict version of the BabyLM pretraining corpus, evaluating on the\nchallenge tasks (BLiMP, GLUE, MSGS) and an additional reading time prediction\ntask. We find a positive correlation between LM size and performance on all\nthree challenge tasks, with different preferences for model width and depth in\neach of the tasks. In contrast, a negative correlation was found between LM\nsize and reading time fit of linear mixed-effects models using LM surprisal as\na predictor, with the second-smallest LM achieving the largest log-likelihood\nreduction over a baseline model without surprisal. This suggests that modelling\nprocessing effort and linguistic competence may require an approach different\nfrom training GPT-like LMs on a developmentally plausible corpus.",
            "author": [
                "Julius Steuer",
                "Marius Mosbach",
                "Dietrich Klakow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04547v1",
                "http://arxiv.org/pdf/2311.04547v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04546v1",
            "title": "Discerning and Enhancing the Weighted Sum-Rate Maximization Algorithms\n  in Communications",
            "updated": "2023-11-08T09:24:41Z",
            "published": "2023-11-08T09:24:41Z",
            "summary": "Weighted sum-rate (WSR) maximization plays a critical role in communication\nsystem design. This paper examines three optimization methods for WSR\nmaximization, which ensure convergence to stationary points: two block\ncoordinate ascent (BCA) algorithms, namely, weighted sum-minimum mean-square\nerror (WMMSE) and WSR maximization via fractional programming (WSR-FP), along\nwith a minorization-maximization (MM) algorithm, WSR maximization via MM\n(WSR-MM). Our contributions are threefold. Firstly, we delineate the exact\nrelationships among WMMSE, WSR-FP, and WSR-MM, which, despite their extensive\nuse in the literature, lack a comprehensive comparative study. By probing the\ntheoretical underpinnings linking the BCA and MM algorithmic frameworks, we\nreveal the direct correlations between the equivalent transformation\ntechniques, essential to the development of WMMSE and WSR-FP, and the surrogate\nfunctions pivotal to WSR-MM. Secondly, we propose a novel algorithm, WSR-MM+,\nharnessing the flexibility of selecting surrogate functions in MM framework. By\ncircumventing the repeated matrix inversions in the search for optimal Lagrange\nmultipliers in existing algorithms, WSR-MM+ significantly reduces the\ncomputational load per iteration and accelerates convergence. Thirdly, we\nreconceptualize WSR-MM+ within the BCA framework, introducing a new equivalent\ntransform, which gives rise to an enhanced version of WSR-FP, named as WSR-FP+.\nWe further demonstrate that WSR-MM+ can be construed as the basic gradient\nprojection method. This perspective yields a deeper understanding into its\ncomputational intricacies. Numerical simulations corroborate the connections\nbetween WMMSE, WSR-FP, and WSR-MM and confirm the efficacy of the proposed\nWSR-MM+ and WSR-FP+ algorithms.",
            "author": [
                "Zepeng Zhang",
                "Ziping Zhao",
                "Kaiming Shen",
                "Daniel P. Palomar",
                "Wei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04546v1",
                "http://arxiv.org/pdf/2311.04546v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04538v1",
            "title": "Faster Maximal Exact Matches with Lazy LCP Evaluation",
            "updated": "2023-11-08T08:56:29Z",
            "published": "2023-11-08T08:56:29Z",
            "summary": "MONI (Rossi et al., {\\it JCB} 2022) is a BWT-based compressed index for\ncomputing the matching statistics and maximal exact matches (MEMs) of a pattern\n(usually a DNA read) with respect to a highly repetitive text (usually a\ndatabase of genomes) using two operations: LF-steps and longest common\nextension (LCE) queries on a grammar-compressed representation of the text. In\npractice, most of the operations are constant-time LF-steps but most of the\ntime is spent evaluating LCE queries. In this paper we show how (a variant of)\nthe latter can be evaluated lazily, so as to bound the total time MONI needs to\nprocess the pattern in terms of the number of MEMs between the pattern and the\ntext, while maintaining logarithmic latency.",
            "author": [
                "Adri\u00e1n Goga",
                "Lore Depuydt",
                "Nathaniel K. Brown",
                "Jan Fostier",
                "Travis Gagie",
                "Gonzalo Navarro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04538v1",
                "http://arxiv.org/pdf/2311.04538v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04536v1",
            "title": "Distributed Uniform Partitioning of a Region using Opaque ASYNC Luminous\n  Mobile Robots",
            "updated": "2023-11-08T08:50:02Z",
            "published": "2023-11-08T08:50:02Z",
            "summary": "We are given $N$ autonomous mobile robots inside a bounded region. The robots\nare opaque which means that three collinear robots are unable to see each other\nas one of the robots acts as an obstruction for the other two. They operate in\nclassical \\emph{Look-Compute-Move} (LCM) activation cycles. Moreover, the\nrobots are oblivious except for a persistent light (which is why they are\ncalled \\emph{Luminous robots}) that can determine a color from a fixed color\nset. Obliviousness does not allow the robots to remember any information from\npast activation cycles. The Uniform Partitioning problem requires the robots to\npartition the whole region into sub-regions of equal area, each of which\ncontains exactly one robot. Due to application-oriented motivation, we, in this\npaper consider the region to be well-known geometric shapes such as rectangle,\nsquare and circle. We investigate the problem in \\emph{asynchronous} setting\nwhere there is no notion of common time and any robot gets activated at any\ntime with a fair assumption that every robot needs to get activated infinitely\noften. To the best of our knowledge, this is the first attempt to study the\nUniform Partitioning problem using oblivious opaque robots working under\nasynchronous settings. We propose three algorithms considering three different\nregions: rectangle, square and circle. Robots partition the region in a\ndistributed way and reach their respective positions in the partitions. The\nalgorithms proposed for rectangular and square regions run in $O(N)$ epochs\nwhereas the algorithm for circular regions runs in $O(N^2)$ epochs, where an\nepoch is the smallest unit of time in which all robots are activated at least\nonce and execute their LCM cycles.",
            "author": [
                "Subhajit Pramanick",
                "Saswata Jana",
                "Adri Bhattacharya",
                "Partha Sarathi Mandal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04536v1",
                "http://arxiv.org/pdf/2311.04536v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04535v1",
            "title": "RankAug: Augmented data ranking for text classification",
            "updated": "2023-11-08T08:47:49Z",
            "published": "2023-11-08T08:47:49Z",
            "summary": "Research on data generation and augmentation has been focused majorly on\nenhancing generation models, leaving a notable gap in the exploration and\nrefinement of methods for evaluating synthetic data. There are several text\nsimilarity metrics within the context of generated data filtering which can\nimpact the performance of specific Natural Language Understanding (NLU) tasks,\nspecifically focusing on intent and sentiment classification. In this study, we\npropose RankAug, a text-ranking approach that detects and filters out the top\naugmented texts in terms of being most similar in meaning with lexical and\nsyntactical diversity. Through experiments conducted on multiple datasets, we\ndemonstrate that the judicious selection of filtering techniques can yield a\nsubstantial improvement of up to 35% in classification accuracy for\nunder-represented classes.",
            "author": [
                "Tiasa Singha Roy",
                "Priyam Basu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04535v1",
                "http://arxiv.org/pdf/2311.04535v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04534v1",
            "title": "Loss Masking Is Not Needed in Decoder-only Transformer for\n  Discrete-token Based ASR",
            "updated": "2023-11-08T08:45:14Z",
            "published": "2023-11-08T08:45:14Z",
            "summary": "Recently, unified speech-text models, such as SpeechGPT, VioLA, and\nAudioPaLM, have achieved remarkable performance on speech tasks. These models\nconvert continuous speech signals into discrete tokens (speech discretization)\nand merge text and speech tokens into a shared vocabulary. Then they train a\nsingle decoder-only Transformer on a mixture of speech tasks. Specifically, all\nthese models utilize Loss Masking on the input speech tokens for the ASR task,\nwhich means that these models do not explicitly model the dependency between\nthe speech tokens. In this paper, we attempt to model the sequence of speech\ntokens in an autoregressive manner like text. However, we find that applying\nthe conventional cross-entropy loss on input speech tokens does not\nconsistently improve the ASR performance over Loss Masking. Therefore, we\npropose a novel approach denoted Smoothed Label Distillation (SLD), which\nintroduces a KL divergence loss with smoothed labels on the input speech tokens\nto effectively model speech tokens. Experiments demonstrate that our SLD\napproach alleviates the limitations of the cross-entropy loss and consistently\noutperforms Loss Masking for decoder-only Transformer based ASR using different\nspeech discretization methods.",
            "author": [
                "Qian Chen",
                "Wen Wang",
                "Qinglin Zhang",
                "Siqi Zheng",
                "Shiliang Zhang",
                "Chong Deng",
                "Yukun Ma",
                "Hai Yu",
                "Jiaqing Liu",
                "Chong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04534v1",
                "http://arxiv.org/pdf/2311.04534v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04525v1",
            "title": "Motion of microswimmers in cylindrical microchannels",
            "updated": "2023-11-08T08:27:19Z",
            "published": "2023-11-08T08:27:19Z",
            "summary": "Biological and artificial microswimmers often have to propel through a\nvariety of environments, ranging from heterogeneous suspending media to strong\ngeometrical confinement. Under confinement, local flow fields generated by\nmicroswimmers, and steric and hydrodynamic interactions with their environment\ndetermine the locomotion. We propose a squirmer-like model to describe the\nmotion of microswimmers in cylindrical microchannels, where propulsion is\ngenerated by a fixed surface slip velocity. The model is studied analytically\nfor cylindrical swimmer shapes, and by numerical hydrodynamics simulations for\nspherical and spheroidal shapes. For the numerical simulations, we employ the\ndissipative particle dynamics method for modelling fluid flow. Both the\nanalytical model and simulations show that the propulsion force increases with\nincreasing confinement. However, the swimming velocity under confinement\nremains lower than the swimmer speed without confinement for all investigated\nconditions. In simulations, different swimming modes (i.e. pusher, neutral,\npuller) are investigated, and found to play a significant role in the\ngeneration of propulsion force when a swimmer approaches a dead end of a\ncapillary. Propulsion generation in confined systems is local, such that the\ngenerated flow field generally vanishes beyond the characteristic size of the\nswimmer. These results contribute to a better understanding of microswimmer\nforce generation and propulsion under strong confinement, including the motion\nin porous media and in narrow channels.",
            "author": [
                "Florian A. Overberg",
                "Gerhard Gompper",
                "Dmitry A. Fedosov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04525v1",
                "http://arxiv.org/pdf/2311.04525v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.comp-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04521v1",
            "title": "Learning Robust Multi-Scale Representation for Neural Radiance Fields\n  from Unposed Images",
            "updated": "2023-11-08T08:18:23Z",
            "published": "2023-11-08T08:18:23Z",
            "summary": "We introduce an improved solution to the neural image-based rendering problem\nin computer vision. Given a set of images taken from a freely moving camera at\ntrain time, the proposed approach could synthesize a realistic image of the\nscene from a novel viewpoint at test time. The key ideas presented in this\npaper are (i) Recovering accurate camera parameters via a robust pipeline from\nunposed day-to-day images is equally crucial in neural novel view synthesis\nproblem; (ii) It is rather more practical to model object's content at\ndifferent resolutions since dramatic camera motion is highly likely in\nday-to-day unposed images. To incorporate the key ideas, we leverage the\nfundamentals of scene rigidity, multi-scale neural scene representation, and\nsingle-image depth prediction. Concretely, the proposed approach makes the\ncamera parameters as learnable in a neural fields-based modeling framework. By\nassuming per view depth prediction is given up to scale, we constrain the\nrelative pose between successive frames. From the relative poses, absolute\ncamera pose estimation is modeled via a graph-neural network-based multiple\nmotion averaging within the multi-scale neural-fields network, leading to a\nsingle loss function. Optimizing the introduced loss function provides camera\nintrinsic, extrinsic, and image rendering from unposed images. We demonstrate,\nwith examples, that for a unified framework to accurately model multiscale\nneural scene representation from day-to-day acquired unposed multi-view images,\nit is equally essential to have precise camera-pose estimates within the scene\nrepresentation framework. Without considering robustness measures in the camera\npose estimation pipeline, modeling for multi-scale aliasing artifacts can be\ncounterproductive. We present extensive experiments on several benchmark\ndatasets to demonstrate the suitability of our approach.",
            "author": [
                "Nishant Jain",
                "Suryansh Kumar",
                "Luc Van Gool"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04521v1",
                "http://arxiv.org/pdf/2311.04521v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04519v1",
            "title": "Synergy Among Flexible Demands: Forming a Coalition to Earn More from\n  Reserve Market",
            "updated": "2023-11-08T08:05:11Z",
            "published": "2023-11-08T08:05:11Z",
            "summary": "We address potential synergy among flexible demands and how they may earn\nmore collectively than individually by forming a coalition and bidding to the\nreserve market. We consider frequency-supporting ancillary service markets,\nparticularly the manual Frequency Restoration Reserve (mFRR) market. The\ncoalition of flexible demands provides more reliable mFRR services, where in\ncomparison to individual demands, is penalized less for their potential failure\nand is paid more for their successful activation. This synergy effect is\nquantified as a function of the number of homogeneous assets in the coalition.\nA subsequent payment allocation mechanism using Shapley values is proposed to\ndistribute the total earnings of the coalition among demands, while\nincentivizing them to remain in the coalition. For our numerical study, we use\nreal price data from the Danish mFRR market in 2022.",
            "author": [
                "Peter A. V. Gade",
                "Trygve Skj\u00f8tskift",
                "Henrik Bindner",
                "Jalal Kazempour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04519v1",
                "http://arxiv.org/pdf/2311.04519v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.GT",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04518v1",
            "title": "Towards Democratizing AI: A Comparative Analysis of AI as a Service\n  Platforms and the Open Space for Machine Learning Approach",
            "updated": "2023-11-08T08:02:59Z",
            "published": "2023-11-08T08:02:59Z",
            "summary": "Recent AI research has significantly reduced the barriers to apply AI, but\nthe process of setting up the necessary tools and frameworks can still be a\nchallenge. While AI-as-a-Service platforms have emerged to simplify the\ntraining and deployment of AI models, they still fall short of achieving true\ndemocratization of AI. In this paper, we aim to address this gap by comparing\nseveral popular AI-as-a-Service platforms and identifying the key requirements\nfor a platform that can achieve true democratization of AI. Our analysis\nhighlights the need for self-hosting options, high scalability, and openness.\nTo address these requirements, we propose our approach: the \"Open Space for\nMachine Learning\" platform. Our platform is built on cutting-edge technologies\nsuch as Kubernetes, Kubeflow Pipelines, and Ludwig, enabling us to overcome the\nchallenges of democratizing AI. We argue that our approach is more\ncomprehensive and effective in meeting the requirements of democratizing AI\nthan existing AI-as-a-Service platforms.",
            "author": [
                "Dennis Rall",
                "Bernhard Bauer",
                "Thomas Fraunholz"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3616131.3616136",
                "http://arxiv.org/abs/2311.04518v1",
                "http://arxiv.org/pdf/2311.04518v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04517v2",
            "title": "Strategies for Parallelizing the Big-Means Algorithm: A Comprehensive\n  Tutorial for Effective Big Data Clustering",
            "updated": "2023-11-23T07:40:51Z",
            "published": "2023-11-08T08:02:52Z",
            "summary": "This study focuses on the optimization of the Big-means algorithm for\nclustering large-scale datasets, exploring four distinct parallelization\nstrategies. We conducted extensive experiments to assess the computational\nefficiency, scalability, and clustering performance of each approach, revealing\ntheir benefits and limitations. The paper also delves into the trade-offs\nbetween computational efficiency and clustering quality, examining the impacts\nof various factors. Our insights provide practical guidance on selecting the\nbest parallelization strategy based on available resources and dataset\ncharacteristics, contributing to a deeper understanding of parallelization\ntechniques for the Big-means algorithm.",
            "author": [
                "Ravil Mussabayev",
                "Rustam Mussabayev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04517v2",
                "http://arxiv.org/pdf/2311.04517v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04513v1",
            "title": "On the Validity of Credit-Based Shaper Delay Guarantees in Decentralized\n  Reservation Protocols",
            "updated": "2023-11-08T07:59:15Z",
            "published": "2023-11-08T07:59:15Z",
            "summary": "Resource reservation is a fundamental mechanism for ensuring quality of\nservice in time-sensitive networks, which can be decentralized by using\nreservation protocols. In the Ethernet technology Time-Sensitive Networking,\nthis has been proposed in conjunction with the Credit-Based Shaper. For the\nreservation, the standards assume a maximum worst-case latency bound at each\nhop. However, we will show through formal analysis and simulation that these\nworst-case latency bounds are not safe. To face this, we propose an extension\nto the current standards to allow the reservation of time-sensitive traffic\nwith reliable latency guarantees. The effectiveness of our approach is\ndemonstrated through simulations of both synthetic and industrial networks.\nFinally, by providing additional information about neighboring devices, we\ncould further increase the maximum reservable traffic by up to 20% in our test\ncases.",
            "author": [
                "Lisa Maile",
                "Dominik Voitlein",
                "Alexej Grigorjew",
                "Kai-Steffen J. Hielscher",
                "Reinhard German"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3575757.3593644",
                "http://arxiv.org/abs/2311.04513v1",
                "http://arxiv.org/pdf/2311.04513v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04512v1",
            "title": "FFINet: Future Feedback Interaction Network for Motion Forecasting",
            "updated": "2023-11-08T07:57:29Z",
            "published": "2023-11-08T07:57:29Z",
            "summary": "Motion forecasting plays a crucial role in autonomous driving, with the aim\nof predicting the future reasonable motions of traffic agents. Most existing\nmethods mainly model the historical interactions between agents and the\nenvironment, and predict multi-modal trajectories in a feedforward process,\nignoring potential trajectory changes caused by future interactions between\nagents. In this paper, we propose a novel Future Feedback Interaction Network\n(FFINet) to aggregate features the current observations and potential future\ninteractions for trajectory prediction. Firstly, we employ different\nspatial-temporal encoders to embed the decomposed position vectors and the\ncurrent position of each scene, providing rich features for the subsequent\ncross-temporal aggregation. Secondly, the relative interaction and\ncross-temporal aggregation strategies are sequentially adopted to integrate\nfeatures in the current fusion module, observation interaction module, future\nfeedback module and global fusion module, in which the future feedback module\ncan enable the understanding of pre-action by feeding the influence of preview\ninformation to feedforward prediction. Thirdly, the comprehensive interaction\nfeatures are further fed into final predictor to generate the joint predicted\ntrajectories of multiple agents. Extensive experimental results show that our\nFFINet achieves the state-of-the-art performance on Argoverse 1 and Argoverse 2\nmotion forecasting benchmarks.",
            "author": [
                "Miao Kang",
                "Shengqi Wang",
                "Sanping Zhou",
                "Ke Ye",
                "Jingjing Jiang",
                "Nanning Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04512v1",
                "http://arxiv.org/pdf/2311.04512v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04509v1",
            "title": "Learning Discriminative Features for Crowd Counting",
            "updated": "2023-11-08T07:54:20Z",
            "published": "2023-11-08T07:54:20Z",
            "summary": "Crowd counting models in highly congested areas confront two main challenges:\nweak localization ability and difficulty in differentiating between foreground\nand background, leading to inaccurate estimations. The reason is that objects\nin highly congested areas are normally small and high-level features extracted\nby convolutional neural networks are less discriminative to represent small\nobjects. To address these problems, we propose a learning discriminative\nfeatures framework for crowd counting, which is composed of a masked feature\nprediction module (MPM) and a supervised pixel-level contrastive learning\nmodule (CLM). The MPM randomly masks feature vectors in the feature map and\nthen reconstructs them, allowing the model to learn about what is present in\nthe masked regions and improving the model's ability to localize objects in\nhigh-density regions. The CLM pulls targets close to each other and pushes them\nfar away from background in the feature space, enabling the model to\ndiscriminate foreground objects from background. Additionally, the proposed\nmodules can be beneficial in various computer vision tasks, such as crowd\ncounting and object detection, where dense scenes or cluttered environments\npose challenges to accurate localization. The proposed two modules are\nplug-and-play, incorporating the proposed modules into existing models can\npotentially boost their performance in these scenarios.",
            "author": [
                "Yuehai Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04509v1",
                "http://arxiv.org/pdf/2311.04509v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04508v1",
            "title": "Moduli Spaces of Instantons in Flag Manifold Sigma Models -- Vortices in\n  Quiver Gauge Theories",
            "updated": "2023-11-08T07:49:01Z",
            "published": "2023-11-08T07:49:01Z",
            "summary": "In this paper, we discuss lumps (sigma model instantons) in flag manifold\nsigma models. In particular, we focus on the moduli space of BPS lumps in\ngeneral K\\\"ahler flag manifold sigma models. Such a K\\\"ahler flag manifold,\nwhich takes the form $\\frac{U(n_1+\\cdots+ n_{L+1})}{U(n_1) \\times \\cdots \\times\nU(n_{L+1})}$, can be realized as a vacuum moduli space of a $U(N_1) \\times\n\\cdots \\times U(N_L)$ quiver gauged linear sigma model. When the gauge coupling\nconstants are finite, the gauged linear sigma model admits BPS vortex\nconfigurations, which reduce to BPS lumps in the low energy effective sigma\nmodel in the large gauge coupling limit. We derive an ADHM-like quotient\nconstruction of the moduli space of BPS vortices and lumps by generalizing the\nquotient construction in $U(N)$ gauge theories by Hanany and Tong. As an\napplication, we check the dualities of the 2d models by computing the vortex\npartition functions using the quotient construction.",
            "author": [
                "Toshiaki Fujimori",
                "Muneto Nitta",
                "Keisuke Ohashi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04508v1",
                "http://arxiv.org/pdf/2311.04508v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04507v1",
            "title": "Conversation Understanding using Relational Temporal Graph Neural\n  Networks with Auxiliary Cross-Modality Interaction",
            "updated": "2023-11-08T07:46:25Z",
            "published": "2023-11-08T07:46:25Z",
            "summary": "Emotion recognition is a crucial task for human conversation understanding.\nIt becomes more challenging with the notion of multimodal data, e.g., language,\nvoice, and facial expressions. As a typical solution, the global- and the local\ncontext information are exploited to predict the emotional label for every\nsingle sentence, i.e., utterance, in the dialogue. Specifically, the global\nrepresentation could be captured via modeling of cross-modal interactions at\nthe conversation level. The local one is often inferred using the temporal\ninformation of speakers or emotional shifts, which neglects vital factors at\nthe utterance level. Additionally, most existing approaches take fused features\nof multiple modalities in an unified input without leveraging modality-specific\nrepresentations. Motivating from these problems, we propose the Relational\nTemporal Graph Neural Network with Auxiliary Cross-Modality Interaction\n(CORECT), an novel neural network framework that effectively captures\nconversation-level cross-modality interactions and utterance-level temporal\ndependencies with the modality-specific manner for conversation understanding.\nExtensive experiments demonstrate the effectiveness of CORECT via its\nstate-of-the-art results on the IEMOCAP and CMU-MOSEI datasets for the\nmultimodal ERC task.",
            "author": [
                "Cam-Van Thi Nguyen",
                "Anh-Tuan Mai",
                "The-Son Le",
                "Hai-Dang Kieu",
                "Duc-Trong Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04507v1",
                "http://arxiv.org/pdf/2311.04507v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04505v1",
            "title": "NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision\n  Interaction",
            "updated": "2023-11-08T07:42:31Z",
            "published": "2023-11-08T07:42:31Z",
            "summary": "Eye contact is a crucial non-verbal interaction modality and plays an\nimportant role in our everyday social life. While humans are very sensitive to\neye contact, the capabilities of machines to capture a person's gaze are still\nmediocre. We tackle this challenge and present NITEC, a hand-annotated eye\ncontact dataset for ego-vision interaction. NITEC exceeds existing datasets for\nego-vision eye contact in size and variety of demographics, social contexts,\nand lighting conditions, making it a valuable resource for advancing\nego-vision-based eye contact research. Our extensive evaluations on NITEC\ndemonstrate strong cross-dataset performance, emphasizing its effectiveness and\nadaptability in various scenarios, that allows seamless utilization to the\nfields of computer vision, human-computer interaction, and social robotics. We\nmake our NITEC dataset publicly available to foster reproducibility and further\nexploration in the field of ego-vision interaction.\nhttps://github.com/thohemp/nitec",
            "author": [
                "Thorsten Hempel",
                "Magnus Jung",
                "Ahmed A. Abdelrahman",
                "Ayoub Al-Hamadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04505v1",
                "http://arxiv.org/pdf/2311.04505v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04503v1",
            "title": "Constrained Adaptive Attacks: Realistic Evaluation of Adversarial\n  Examples and Robust Training of Deep Neural Networks for Tabular Data",
            "updated": "2023-11-08T07:35:28Z",
            "published": "2023-11-08T07:35:28Z",
            "summary": "State-of-the-art deep learning models for tabular data have recently achieved\nacceptable performance to be deployed in industrial settings. However, the\nrobustness of these models remains scarcely explored. Contrary to computer\nvision, there is to date no realistic protocol to properly evaluate the\nadversarial robustness of deep tabular models due to intrinsic properties of\ntabular data such as categorical features, immutability, and feature\nrelationship constraints. To fill this gap, we propose CAA, the first efficient\nevasion attack for constrained tabular deep learning models. CAA is an\niterative parameter-free attack that combines gradient and search attacks to\ngenerate adversarial examples under constraints. We leverage CAA to build a\nbenchmark of deep tabular models across three popular use cases: credit\nscoring, phishing and botnet attacks detection. Our benchmark supports ten\nthreat models with increasing capabilities of the attacker, and reflects\nreal-world attack scenarios for each use case. Overall, our results demonstrate\nhow domain knowledge, adversarial training, and attack budgets impact the\nrobustness assessment of deep tabular models and provide security practitioners\nwith a set of recommendations to improve the robustness of deep tabular models\nagainst various evasion attack scenarios.",
            "author": [
                "Thibault Simonetto",
                "Salah Ghamizi",
                "Antoine Desjardins",
                "Maxime Cordy",
                "Yves Le Traon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04503v1",
                "http://arxiv.org/pdf/2311.04503v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04502v2",
            "title": "TADA: Making Node-link Diagrams Accessible to Blind and Low-Vision\n  People",
            "updated": "2023-11-09T03:53:49Z",
            "published": "2023-11-08T07:29:42Z",
            "summary": "Diagrams often appear as node-link representations in many contexts, such as\ntaxonomies, mind maps and networks in textbooks. Despite their pervasiveness,\nthey present significant accessibility challenges for blind and low-vision\npeople. To address this challenge, we introduce Touch-and-Audio-based Diagram\nAccess (TADA), a tablet-based interactive system that makes diagram exploration\naccessible through musical tones and speech. We designed and developed TADA\ninformed by insights gained from an interview study with 15 participants who\nshared their challenges and strategies for accessing diagrams. TADA enables\npeople to access a diagram by: i) engaging in open-ended touch-based\nexplorations, ii) allowing searching of specific nodes, iii) navigating from\none node to another and iv) filtering information. We evaluated TADA with 25\nparticipants and found that it can be a useful tool for gaining different\nperspectives about the diagram and participants could complete several\ndiagram-related tasks.",
            "author": [
                "Yichun Zhao",
                "Miguel A. Nacenta",
                "Mahadeo A. Sukhai",
                "Sowmya Somanath"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04502v2",
                "http://arxiv.org/pdf/2311.04502v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04501v1",
            "title": "PRED: Pre-training via Semantic Rendering on LiDAR Point Clouds",
            "updated": "2023-11-08T07:26:09Z",
            "published": "2023-11-08T07:26:09Z",
            "summary": "Pre-training is crucial in 3D-related fields such as autonomous driving where\npoint cloud annotation is costly and challenging. Many recent studies on point\ncloud pre-training, however, have overlooked the issue of incompleteness, where\nonly a fraction of the points are captured by LiDAR, leading to ambiguity\nduring the training phase. On the other hand, images offer more comprehensive\ninformation and richer semantics that can bolster point cloud encoders in\naddressing the incompleteness issue inherent in point clouds. Yet,\nincorporating images into point cloud pre-training presents its own challenges\ndue to occlusions, potentially causing misalignments between points and pixels.\nIn this work, we propose PRED, a novel image-assisted pre-training framework\nfor outdoor point clouds in an occlusion-aware manner. The main ingredient of\nour framework is a Birds-Eye-View (BEV) feature map conditioned semantic\nrendering, leveraging the semantics of images for supervision through neural\nrendering. We further enhance our model's performance by incorporating\npoint-wise masking with a high mask ratio (95%). Extensive experiments\ndemonstrate PRED's superiority over prior point cloud pre-training methods,\nproviding significant improvements on various large-scale datasets for 3D\nperception tasks. Codes will be available at https://github.com/PRED4pc/PRED.",
            "author": [
                "Hao Yang",
                "Haiyang Wang",
                "Di Dai",
                "Liwei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04501v1",
                "http://arxiv.org/pdf/2311.04501v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04499v1",
            "title": "Near-Linear Scaling Data Parallel Training with Overlapping-Aware\n  Gradient Compression",
            "updated": "2023-11-08T07:17:41Z",
            "published": "2023-11-08T07:17:41Z",
            "summary": "Existing Data Parallel (DP) trainings for deep neural networks (DNNs) often\nexperience limited scalability in speedup due to substantial communication\noverheads. While Overlapping technique can mitigate such problem by paralleling\ncommunication and computation in DP, its effectiveness is constrained by the\nhigh communication-to-computation ratios (CCR) of DP training tasks. Gradient\ncompression (GC) is a promising technique to obtain lower CCR by reducing\ncommunication volume directly. However, it is challenging to obtain real\nperformance improvement by applying GC into Overlapping because of (1) severe\nperformance penalties in traditional GCs caused by high compression overhead\nand (2) decline of Overlapping benefit owing to the possible data dependency in\nGC schemes. In this paper, we propose COVAP, a novel GC scheme designing a new\ncoarse-grained filter, makes the compression overhead close to zero. COVAP\nensures an almost complete overlap of communication and computation by\nemploying adaptive compression ratios and tensor sharding tailored to specific\ntraining tasks. COVAP also adopts an improved error feedback mechanism to\nmaintain training accuracy. Experiments are conducted on Alibaba Cloud ECS\ninstances with different DNNs of real-world applications. The results\nillustrate that COVAP outperforms existent GC schemes in time-to-solution by\n1.92x-15.39x and exhibits near-linear scaling. Furthermore, COVAP achieves best\nscalability under experiments on four different cluster sizes.",
            "author": [
                "Lin Meng",
                "Yuzhong Sun",
                "Weimin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04499v1",
                "http://arxiv.org/pdf/2311.04499v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04498v3",
            "title": "NExT-Chat: An LMM for Chat, Detection and Segmentation",
            "updated": "2023-11-13T03:35:23Z",
            "published": "2023-11-08T07:15:05Z",
            "summary": "The development of large language models (LLMs) has greatly advanced the\nfield of multimodal understanding, leading to the emergence of large multimodal\nmodels (LMMs). In order to enhance the level of visual comprehension, recent\nstudies have equipped LMMs with region-level understanding capabilities by\nrepresenting object bounding box coordinates as a series of text sequences\n(pixel2seq). In this paper, we introduce a novel paradigm for object location\nmodeling called pixel2emb method, where we ask the LMM to output the location\nembeddings and then decoded by different decoders. This paradigm allows for\ndifferent location formats (such as bounding boxes and masks) to be used in\nmultimodal conversations Furthermore, this kind of embedding based location\nmodeling enables the utilization of existing practices in localization tasks,\nsuch as detection and segmentation. In scenarios with limited resources, our\npixel2emb demonstrates superior performance compared to existing\nstate-of-the-art (SOTA) approaches in both the location input and output tasks\nunder fair comparison. Leveraging the proposed pixel2emb method, we train an\nLMM named NExT-Chat and demonstrate its capability of handling multiple tasks\nlike visual grounding, region caption, and grounded reasoning.",
            "author": [
                "Ao Zhang",
                "Wei Ji",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04498v3",
                "http://arxiv.org/pdf/2311.04498v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04496v1",
            "title": "PersonMAE: Person Re-Identification Pre-Training with Masked\n  AutoEncoders",
            "updated": "2023-11-08T07:02:27Z",
            "published": "2023-11-08T07:02:27Z",
            "summary": "Pre-training is playing an increasingly important role in learning generic\nfeature representation for Person Re-identification (ReID). We argue that a\nhigh-quality ReID representation should have three properties, namely,\nmulti-level awareness, occlusion robustness, and cross-region invariance. To\nthis end, we propose a simple yet effective pre-training framework, namely\nPersonMAE, which involves two core designs into masked autoencoders to better\nserve the task of Person Re-ID. 1) PersonMAE generates two regions from the\ngiven image with RegionA as the input and \\textit{RegionB} as the prediction\ntarget. RegionA is corrupted with block-wise masking to mimic common occlusion\nin ReID and its remaining visible parts are fed into the encoder. 2) Then\nPersonMAE aims to predict the whole RegionB at both pixel level and semantic\nfeature level. It encourages its pre-trained feature representations with the\nthree properties mentioned above. These properties make PersonMAE compatible\nwith downstream Person ReID tasks, leading to state-of-the-art performance on\nfour downstream ReID tasks, i.e., supervised (holistic and occluded setting),\nand unsupervised (UDA and USL setting). Notably, on the commonly adopted\nsupervised setting, PersonMAE with ViT-B backbone achieves 79.8% and 69.5% mAP\non the MSMT17 and OccDuke datasets, surpassing the previous state-of-the-art by\na large margin of +8.0 mAP, and +5.3 mAP, respectively.",
            "author": [
                "Hezhen Hu",
                "Xiaoyi Dong",
                "Jianmin Bao",
                "Dongdong Chen",
                "Lu Yuan",
                "Dong Chen",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04496v1",
                "http://arxiv.org/pdf/2311.04496v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05651v1",
            "title": "On Mergable Coresets for Polytope Distance",
            "updated": "2023-11-08T06:55:26Z",
            "published": "2023-11-08T06:55:26Z",
            "summary": "We show that a constant-size constant-error coreset for polytope distance is\nsimple to maintain under merges of coresets. However, increasing the size\ncannot improve the error bound significantly beyond that constant.",
            "author": [
                "Benwei Shi",
                "Aditya Bhaskara",
                "Wai Ming Tai",
                "Jeff M. Phillips"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05651v1",
                "http://arxiv.org/pdf/2311.05651v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS",
                "cs.LG",
                "I.3.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04495v1",
            "title": "Multi-label and Multi-target Sampling of Machine Annotation for\n  Computational Stance Detection",
            "updated": "2023-11-08T06:54:34Z",
            "published": "2023-11-08T06:54:34Z",
            "summary": "Data collection from manual labeling provides domain-specific and\ntask-aligned supervision for data-driven approaches, and a critical mass of\nwell-annotated resources is required to achieve reasonable performance in\nnatural language processing tasks. However, manual annotations are often\nchallenging to scale up in terms of time and budget, especially when domain\nknowledge, capturing subtle semantic features, and reasoning steps are needed.\nIn this paper, we investigate the efficacy of leveraging large language models\non automated labeling for computational stance detection. We empirically\nobserve that while large language models show strong potential as an\nalternative to human annotators, their sensitivity to task-specific\ninstructions and their intrinsic biases pose intriguing yet unique challenges\nin machine annotation. We introduce a multi-label and multi-target sampling\nstrategy to optimize the annotation quality. Experimental results on the\nbenchmark stance detection corpora show that our method can significantly\nimprove performance and learning efficacy.",
            "author": [
                "Zhengyuan Liu",
                "Hai Leong Chieu",
                "Nancy F. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04495v1",
                "http://arxiv.org/pdf/2311.04495v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04494v1",
            "title": "Non-Rigid Shape Registration via Deep Functional Maps Prior",
            "updated": "2023-11-08T06:52:57Z",
            "published": "2023-11-08T06:52:57Z",
            "summary": "In this paper, we propose a learning-based framework for non-rigid shape\nregistration without correspondence supervision. Traditional shape registration\ntechniques typically rely on correspondences induced by extrinsic proximity,\ntherefore can fail in the presence of large intrinsic deformations. Spectral\nmapping methods overcome this challenge by embedding shapes into, geometric or\nlearned, high-dimensional spaces, where shapes are easier to align. However,\ndue to the dependency on abstract, non-linear embedding schemes, the latter can\nbe vulnerable with respect to perturbed or alien input. In light of this, our\nframework takes the best of both worlds. Namely, we deform source mesh towards\nthe target point cloud, guided by correspondences induced by high-dimensional\nembeddings learned from deep functional maps (DFM). In particular, the\ncorrespondences are dynamically updated according to the intermediate\nregistrations and filtered by consistency prior, which prominently robustify\nthe overall pipeline. Moreover, in order to alleviate the requirement of\nextrinsically aligned input, we train an orientation regressor on a set of\naligned synthetic shapes independent of the training shapes for DFM. Empirical\nresults show that, with as few as dozens of training shapes of limited\nvariability, our pipeline achieves state-of-the-art results on several\nbenchmarks of non-rigid point cloud matching, but also delivers high-quality\ncorrespondences between unseen challenging shape pairs that undergo both\nsignificant extrinsic and intrinsic deformations, in which case neither\ntraditional registration methods nor intrinsic methods work. The code is\navailable at https://github.com/rqhuang88/DFR.",
            "author": [
                "Puhua Jiang",
                "Mingze Sun",
                "Ruqi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04494v1",
                "http://arxiv.org/pdf/2311.04494v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04493v1",
            "title": "On conformal biharmonic maps and hypersurfaces",
            "updated": "2023-11-08T06:51:48Z",
            "published": "2023-11-08T06:51:48Z",
            "summary": "In this article we initiate a thorough geometric study of the conformal\nbienergy functional which consists of the standard bienergy augmented by two\nadditional curvature terms. The conformal bienergy is conformally invariant in\ndimension four and its precise structure is motivated by the Paneitz operator\nfrom conformal geometry. The critical points of the conformal bienergy are\ncalled conformal biharmonic maps.\n  Besides establishing a number of basic results on conformal biharmonic maps,\nwe pay special attention to conformal biharmonic hypersurfaces in space forms.\nFor hypersurfaces in spheres, we determine all conformal biharmonic\nhyperspheres and then we construct conformal biharmonic generalized Clifford\ntori. Moreover, in sharp contrast to biharmonic hypersurfaces, we show that\nthere also exist conformal biharmonic hypersurfaces of hyperbolic space,\npointing out a fundamental difference between biharmonic and conformal\nbiharmonic hypersurfaces.\n  Finally, we also study the stability of the conformal biharmonic hyperspheres\nin spheres and explicitly compute their index and nullity. In particular, we\nobtain that the index of the equator $\\mathbb{S}^4$ of $\\mathbb{S}^5$ is zero,\ni.e. it is stable, while the index of the equator $\\mathbb{S}^5$ of\n$\\mathbb{S}^6$ is seven.",
            "author": [
                "Volker Branding",
                "Simona Nistor",
                "Cezar Oniciuc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04493v1",
                "http://arxiv.org/pdf/2311.04493v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "58E20, 53C43, 53C42"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04482v1",
            "title": "Optimizing Distributed Networking with Big Data Scheduling and Cloud\n  Computing",
            "updated": "2023-11-08T06:22:44Z",
            "published": "2023-11-08T06:22:44Z",
            "summary": "With the rapid transformation of computer hardware and algorithms, mobile\nnetworking has evolved from low data carrying capacity and high latency to\nbetter-optimized networks, either by enhancing the digital network or using\ndifferent approaches to reduce network traffic. This paper discusses the big\ndata applications and scheduling in the distributed networking and analyzes the\nopportunities and challenges of data management systems. The analysis shows\nthat the big data scheduling in the cloud computing environment produces the\nmost efficient way to transfer and synchronize data. Since scheduling problems\nand cloud models are very complex to analyze in different settings, we set it\nto the typical software defined networks. The development of cloud management\nmodels and coflow scheduling algorithm is proved to be the priority of the\ndigital communications and networks development in the future.",
            "author": [
                "Wenbo Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1117/12.2642577",
                "http://arxiv.org/abs/2311.04482v1",
                "http://arxiv.org/pdf/2311.04482v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04480v1",
            "title": "CLearViD: Curriculum Learning for Video Description",
            "updated": "2023-11-08T06:20:32Z",
            "published": "2023-11-08T06:20:32Z",
            "summary": "Video description entails automatically generating coherent natural language\nsentences that narrate the content of a given video. We introduce CLearViD, a\ntransformer-based model for video description generation that leverages\ncurriculum learning to accomplish this task. In particular, we investigate two\ncurriculum strategies: (1) progressively exposing the model to more challenging\nsamples by gradually applying a Gaussian noise to the video data, and (2)\ngradually reducing the capacity of the network through dropout during the\ntraining process. These methods enable the model to learn more robust and\ngeneralizable features. Moreover, CLearViD leverages the Mish activation\nfunction, which provides non-linearity and non-monotonicity and helps alleviate\nthe issue of vanishing gradients. Our extensive experiments and ablation\nstudies demonstrate the effectiveness of the proposed model. The results on two\ndatasets, namely ActivityNet Captions and YouCook2, show that CLearViD\nsignificantly outperforms existing state-of-the-art models in terms of both\naccuracy and diversity metrics.",
            "author": [
                "Cheng-Yu Chuang",
                "Pooyan Fazli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04480v1",
                "http://arxiv.org/pdf/2311.04480v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04479v1",
            "title": "Twitter Sentiment Analysis of Covid Vacciness",
            "updated": "2023-11-08T06:16:04Z",
            "published": "2023-11-08T06:16:04Z",
            "summary": "In this paper, we look at a database of tweets sorted by various keywords\nthat could indicate the users sentiment towards covid vaccines. With social\nmedia becoming such a prevalent source of opinion, sorting and ranking tweets\nthat hold important information such as opinions on covid vaccines is of utmost\nimportance. Two different ranking scales were used, and ranking a tweet in this\nway could represent the difference between an opinion being lost and an opinion\nbeing featured on the site, which affects the decisions and behavior of people,\nand why researchers were interested in it. Using natural language processing\ntechniques, our aim is to determine and categorize opinions about covid\nvaccines with the highest accuracy possible.",
            "author": [
                "Wenbo Zhu",
                "Tiechuan Hu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3480433.3480442",
                "http://arxiv.org/abs/2311.04479v1",
                "http://arxiv.org/pdf/2311.04479v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04478v1",
            "title": "Mixed causality graphs for continuous-time state space models and\n  orthogonal projections",
            "updated": "2023-11-08T06:11:02Z",
            "published": "2023-11-08T06:11:02Z",
            "summary": "In this paper we derive (local) causality graphs for the popular\ncontinuous-time state space models, including in particular multivariate\ncontinuous-time ARMA (MCARMA) processes. In these (local) causality graphs,\nvertices represent the components of the process, directed edges between the\nvertices indicate causal influences, and undirected edges indicate\ncontemporaneous uncorrelatednesses between the component processes. We present\nsufficient criteria for state space models to satisfy the assumptions of\nFasen-Hartmann and Schenk (2023) so that the (local) causality graphs are well\ndefined and various causal Markov properties hold. Both directed and undirected\nedges in these graphs are characterised by orthogonal projections on\nwell-defined linear spaces. To compute these orthogonal projections, we use the\nunique controller canonical form of a state space model, which exists under\nmild assumptions, to recover the input process from the output process. We are\nthen able to derive some alternative representations of the output process and\nits highest derivative. Finally, we apply these representations to calculate\nthe necessary orthogonal projections, which culminate in the characterisations\nof the edges in the (local) causality graph. These characterisations are\ninterpretatively meaningful and are given by the parameters of the controller\ncanonical form and the covariance matrix of the driving L\\'evy process.",
            "author": [
                "Vicky Fasen-Hartmann",
                "Lea Schenk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04478v1",
                "http://arxiv.org/pdf/2311.04478v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "Primary 62H22, 62M20, Secondary 62M10, 60G25",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04473v1",
            "title": "All-Optical Phase Conjugation Using Diffractive Wavefront Processing",
            "updated": "2023-11-08T05:54:36Z",
            "published": "2023-11-08T05:54:36Z",
            "summary": "Optical phase conjugation (OPC) is a nonlinear technique used for\ncounteracting wavefront distortions, with various applications ranging from\nimaging to beam focusing. Here, we present the design of a diffractive\nwavefront processor to approximate all-optical phase conjugation operation for\ninput fields with phase aberrations. Leveraging deep learning, a set of passive\ndiffractive layers was optimized to all-optically process an arbitrary\nphase-aberrated coherent field from an input aperture, producing an output\nfield with a phase distribution that is the conjugate of the input wave. We\nexperimentally validated the efficacy of this wavefront processor by 3D\nfabricating diffractive layers trained using deep learning and performing OPC\non phase distortions never seen by the diffractive processor during its\ntraining. Employing terahertz radiation, our physical diffractive processor\nsuccessfully performed the OPC task through a shallow spatially-engineered\nvolume that axially spans tens of wavelengths. In addition to this transmissive\nOPC configuration, we also created a diffractive phase-conjugate mirror by\ncombining deep learning-optimized diffractive layers with a standard mirror.\nGiven its compact, passive and scalable nature, our diffractive wavefront\nprocessor can be used for diverse OPC-related applications, e.g., turbidity\nsuppression and aberration correction, and is also adaptable to different parts\nof the electromagnetic spectrum, especially those where cost-effective\nwavefront engineering solutions do not exist.",
            "author": [
                "Che-Yung Shen",
                "Jingxi Li",
                "Tianyi Gan",
                "Mona Jarrahi",
                "Aydogan Ozcan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04473v1",
                "http://arxiv.org/pdf/2311.04473v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.CV",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04472v2",
            "title": "Autonomous Advanced Aerial Mobility -- An End-to-end Autonomy Framework\n  for UAVs and Beyond",
            "updated": "2023-12-03T00:19:12Z",
            "published": "2023-11-08T05:54:22Z",
            "summary": "Developing aerial robots that can both safely navigate and execute assigned\nmission without any human intervention - i.e., fully autonomous aerial mobility\nof passengers and goods - is the larger vision that guides the research,\ndesign, and development efforts in the aerial autonomy space. However, it is\nhighly challenging to concurrently operationalize all types of aerial vehicles\nthat are operating fully autonomously sharing the airspace. Full autonomy of\nthe aerial transportation sector includes several aspects, such as design of\nthe technology that powers the vehicles, operations of multi-agent fleets, and\nprocess of certification that meets stringent safety requirements of aviation\nsector. Thereby, Autonomous Advanced Aerial Mobility is still a vague term and\nits consequences for researchers and professionals are ambiguous. To address\nthis gap, we present a comprehensive perspective on the emerging field of\nautonomous advanced aerial mobility, which involves the use of unmanned aerial\nvehicles (UAVs) and electric vertical takeoff and landing (eVTOL) aircraft for\nvarious applications, such as urban air mobility, package delivery, and\nsurveillance. The article proposes a scalable and extensible autonomy framework\nconsisting of four main blocks: sensing, perception, planning, and controls.\nFurthermore, the article discusses the challenges and opportunities in\nmulti-agent fleet operations and management, as well as the testing,\nvalidation, and certification aspects of autonomous aerial systems. Finally,\nthe article explores the potential of monolithic models for aerial autonomy and\nanalyzes their advantages and limitations. The perspective aims to provide a\nholistic picture of the autonomous advanced aerial mobility field and its\nfuture directions.",
            "author": [
                "Sakshi Mishra",
                "Praveen Palanisamy"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2023.3339631",
                "http://arxiv.org/abs/2311.04472v2",
                "http://arxiv.org/pdf/2311.04472v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.MA",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04470v1",
            "title": "Determina\u00e7\u00e3o da Dist\u00e2ncia \u00e0 Grande Nuvem de Magalh\u00e3es\n  Atrav\u00e9s das Estrelas Vari\u00e1veis Cefeidas Dispon\u00edveis no Cat\u00e1logo\n  OGLE-IV",
            "updated": "2023-11-08T05:52:33Z",
            "published": "2023-11-08T05:52:33Z",
            "summary": "In this work, we discuss the determination of the distance to the Large\nMagellanic Cloud (LMC) using the Leavitt Law, utilizing the public catalog of\nClassical Cepheid Variable stars from the observational project OGLE-IV (The\nOptical Gravitational Lensing Experiment Collection of Variable Stars),\nconsisting of 4709 stars in the Large Magellanic Cloud. To determine the\npulsation period of Cepheid Variable stars, we employ the computational\nalgorithm \\textit{Lomb-Scargle periodogram} modified for our data.\nAdditionally, with the calculation of the period, we can derive a\nperiod-luminosity relation for Cepheid Variables in the Large Magellanic Cloud\nand, using an independent calibration distance, deduce their distance moduli.\nWe also discuss some general theoretical concepts of the physical mechanism\nbehind the oscillation of variable stars.",
            "author": [
                "Kevin Mota da Costa",
                "Alan Miguel Vel\u00e1squez",
                "Julio Cesar Fabris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04470v1",
                "http://arxiv.org/pdf/2311.04470v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04468v1",
            "title": "A human brain atlas of chi-separation for normative iron and myelin\n  distributions",
            "updated": "2023-11-08T05:41:37Z",
            "published": "2023-11-08T05:41:37Z",
            "summary": "Iron and myelin are primary susceptibility sources in the human brain. These\nsubstances are essential for healthy brain, and their abnormalities are often\nrelated to various neurological disorders. Recently, an advanced susceptibility\nmapping technique, which is referred to as chi-separation, has been proposed\nsuccessfully disentangling paramagnetic iron from diamagnetic myelin, opening a\nnew potential for generating iron map and myelin map in the brain. Utilizing\nthis technique, this study constructs a normative chi-separation atlas from 106\nhealthy human brains. The resulting atlas provides detailed anatomical\nstructures associated with the distributions of iron and myelin, clearly\ndelineating subcortical nuclei and white matter fiber bundles. Additionally,\nsusceptibility values in a number of regions of interest are reported along\nwith age-dependent changes. This atlas may have direct applications such as\nlocalization of subcortical structures for deep brain stimulation or\nhigh-intensity focused ultrasound and also serve as a valuable resource for\nfuture research.",
            "author": [
                "Kyeongseon Min",
                "Beomseok Sohn",
                "Woo Jung Kim",
                "Chae Jung Park",
                "Soohwa Song",
                "Dong Hoon Shin",
                "Kyung Won Chang",
                "Na-Young Shin",
                "Minjun Kim",
                "Hyeong-Geol Shin",
                "Phil Hyu Lee",
                "Jongho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04468v1",
                "http://arxiv.org/pdf/2311.04468v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04467v1",
            "title": "RDGCN: Reinforced Dependency Graph Convolutional Network for\n  Aspect-based Sentiment Analysis",
            "updated": "2023-11-08T05:37:49Z",
            "published": "2023-11-08T05:37:49Z",
            "summary": "Aspect-based sentiment analysis (ABSA) is dedicated to forecasting the\nsentiment polarity of aspect terms within sentences. Employing graph neural\nnetworks to capture structural patterns from syntactic dependency parsing has\nbeen confirmed as an effective approach for boosting ABSA. In most works, the\ntopology of dependency trees or dependency-based attention coefficients is\noften loosely regarded as edges between aspects and opinions, which can result\nin insufficient and ambiguous syntactic utilization. To address these problems,\nwe propose a new reinforced dependency graph convolutional network (RDGCN) that\nimproves the importance calculation of dependencies in both distance and type\nviews. Initially, we propose an importance calculation criterion for the\nminimum distances over dependency trees. Under the criterion, we design a\ndistance-importance function that leverages reinforcement learning for weight\ndistribution search and dissimilarity control. Since dependency types often do\nnot have explicit syntax like tree distances, we use global attention and mask\nmechanisms to design type-importance functions. Finally, we merge these weights\nand implement feature aggregation and classification. Comprehensive experiments\non three popular datasets demonstrate the effectiveness of the criterion and\nimportance functions. RDGCN outperforms state-of-the-art GNN-based baselines in\nall validations.",
            "author": [
                "Xusheng Zhao",
                "Hao Peng",
                "Qiong Dai",
                "Xu Bai",
                "Huailiang Peng",
                "Yanbing Liu",
                "Qinglang Guo",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04467v1",
                "http://arxiv.org/pdf/2311.04467v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04465v1",
            "title": "Solving High Frequency and Multi-Scale PDEs with Gaussian Processes",
            "updated": "2023-11-08T05:26:58Z",
            "published": "2023-11-08T05:26:58Z",
            "summary": "Machine learning based solvers have garnered much attention in physical\nsimulation and scientific computing, with a prominent example, physics-informed\nneural networks (PINNs). However, PINNs often struggle to solve high-frequency\nand multi-scale PDEs, which can be due to spectral bias during neural network\ntraining. To address this problem, we resort to the Gaussian process (GP)\nframework. To flexibly capture the dominant frequencies, we model the power\nspectrum of the PDE solution with a student t mixture or Gaussian mixture. We\nthen apply the inverse Fourier transform to obtain the covariance function\n(according to the Wiener-Khinchin theorem). The covariance derived from the\nGaussian mixture spectrum corresponds to the known spectral mixture kernel. We\nare the first to discover its rationale and effectiveness for PDE solving.\nNext,we estimate the mixture weights in the log domain, which we show is\nequivalent to placing a Jeffreys prior. It automatically induces sparsity,\nprunes excessive frequencies, and adjusts the remaining toward the ground\ntruth. Third, to enable efficient and scalable computation on massive\ncollocation points, which are critical to capture high frequencies, we place\nthe collocation points on a grid, and multiply our covariance function at each\ninput dimension. We use the GP conditional mean to predict the solution and its\nderivatives so as to fit the boundary condition and the equation itself. As a\nresult, we can derive a Kronecker product structure in the covariance matrix.\nWe use Kronecker product properties and multilinear algebra to greatly promote\ncomputational efficiency and scalability, without any low-rank approximations.\nWe show the advantage of our method in systematic experiments.",
            "author": [
                "Shikai Fang",
                "Madison Cooley",
                "Da Long",
                "Shibo Li",
                "Robert Kirby",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04465v1",
                "http://arxiv.org/pdf/2311.04465v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04464v3",
            "title": "Enhancing Few-shot CLIP with Semantic-Aware Fine-Tuning",
            "updated": "2023-12-07T04:35:24Z",
            "published": "2023-11-08T05:18:57Z",
            "summary": "Learning generalized representations from limited training samples is crucial\nfor applying deep neural networks in low-resource scenarios. Recently, methods\nbased on Contrastive Language-Image Pre-training (CLIP) have exhibited\npromising performance in few-shot adaptation tasks. To avoid catastrophic\nforgetting and overfitting caused by few-shot fine-tuning, existing works\nusually freeze the parameters of CLIP pre-trained on large-scale datasets,\noverlooking the possibility that some parameters might not be suitable for\ndownstream tasks. To this end, we revisit CLIP's visual encoder with a specific\nfocus on its distinctive attention pooling layer, which performs a spatial\nweighted-sum of the dense feature maps. Given that dense feature maps contain\nmeaningful semantic information, and different semantics hold varying\nimportance for diverse downstream tasks (such as prioritizing semantics like\nears and eyes in pet classification tasks rather than side mirrors), using the\nsame weighted-sum operation for dense features across different few-shot tasks\nmight not be appropriate. Hence, we propose fine-tuning the parameters of the\nattention pooling layer during the training process to encourage the model to\nfocus on task-specific semantics. In the inference process, we perform residual\nblending between the features pooled by the fine-tuned and the original\nattention pooling layers to incorporate both the few-shot knowledge and the\npre-trained CLIP's prior knowledge. We term this method as Semantic-Aware\nFinE-tuning (SAFE). SAFE is effective in enhancing the conventional few-shot\nCLIP and is compatible with the existing adapter approach (termed SAFE-A).",
            "author": [
                "Yao Zhu",
                "Yuefeng Chen",
                "Wei Wang",
                "Xiaofeng Mao",
                "Xiu Yan",
                "Yue Wang",
                "Zhigang Li",
                "Wang lu",
                "Jindong Wang",
                "Xiangyang Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04464v3",
                "http://arxiv.org/pdf/2311.04464v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04944v1",
            "title": "Edge-assisted U-Shaped Split Federated Learning with Privacy-preserving\n  for Internet of Things",
            "updated": "2023-11-08T05:14:41Z",
            "published": "2023-11-08T05:14:41Z",
            "summary": "In the realm of the Internet of Things (IoT), deploying deep learning models\nto process data generated or collected by IoT devices is a critical challenge.\nHowever, direct data transmission can cause network congestion and inefficient\nexecution, given that IoT devices typically lack computation and communication\ncapabilities. Centralized data processing in data centers is also no longer\nfeasible due to concerns over data privacy and security. To address these\nchallenges, we present an innovative Edge-assisted U-Shaped Split Federated\nLearning (EUSFL) framework, which harnesses the high-performance capabilities\nof edge servers to assist IoT devices in model training and optimization\nprocess. In this framework, we leverage Federated Learning (FL) to enable data\nholders to collaboratively train models without sharing their data, thereby\nenhancing data privacy protection by transmitting only model parameters.\nAdditionally, inspired by Split Learning (SL), we split the neural network into\nthree parts using U-shaped splitting for local training on IoT devices. By\nexploiting the greater computation capability of edge servers, our framework\neffectively reduces overall training time and allows IoT devices with varying\ncapabilities to perform training tasks efficiently. Furthermore, we proposed a\nnovel noise mechanism called LabelDP to ensure that data features and labels\ncan securely resist reconstruction attacks, eliminating the risk of privacy\nleakage. Our theoretical analysis and experimental results demonstrate that\nEUSFL can be integrated with various aggregation algorithms, maintaining good\nperformance across different computing capabilities of IoT devices, and\nsignificantly reducing training time and local computation overhead.",
            "author": [
                "Hengliang Tang",
                "Zihang Zhao",
                "Detian Liu",
                "Yang Cao",
                "Shiqiang Zhang",
                "Siqing You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04944v1",
                "http://arxiv.org/pdf/2311.04944v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04462v2",
            "title": "The decay contribution to the parity-odd fragmentation functions",
            "updated": "2023-11-14T08:37:13Z",
            "published": "2023-11-08T05:11:28Z",
            "summary": "Parity violation in QCD is a consequence of the so-called QCD\n$\\theta$-vacuum. As a result, parity-odd fragmentation functions are introduced\nand they bring in new observables in the back-to-back dihadron productions in\n$e^+e^-$-annihilation experiment [Phys.Rev.Lett. 106 (2011) 042001]. Therefore,\nthe experimental measurements on the corresponding parity-odd fragmentation\nfunctions can shed light on the local CP violation effect in QCD. In this\npaper, we investigate the decay contribution to those parity-odd fragmentation\nfunctions and compute their contribution to these new observables. In\nprinciple, the decay contribution should/can be excluded in the theoretical\nanalysis and experimental measurements. However, this is usually not the common\npractice so far. Furthermore, in light of that the value of the\n$\\theta$-parameter is extremely small ($\\theta < 3 \\times 10^{-10}$), we should\nbe very careful while constraining those parity-odd fragmentation functions\nfrom experiments.",
            "author": [
                "Yan-Lei Pan",
                "Kai-Bao Chen",
                "Yu-Kun Song",
                "Shu-Yi Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04462v2",
                "http://arxiv.org/pdf/2311.04462v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04459v1",
            "title": "Improving Pacing in Long-Form Story Planning",
            "updated": "2023-11-08T04:58:29Z",
            "published": "2023-11-08T04:58:29Z",
            "summary": "Existing LLM-based systems for writing long-form stories or story outlines\nfrequently suffer from unnatural pacing, whether glossing over important events\nor over-elaborating on insignificant details, resulting in a jarring experience\nfor the reader. We propose a CONCrete Outline ConTrol (CONCOCT) system to\nimprove pacing when automatically generating story outlines. We first train a\nconcreteness evaluator to judge which of two events is more concrete\n(low-level-detailed). This evaluator can then be used to control pacing in\nhierarchical outline generation; in this work, we explore a vaguest-first\nexpansion procedure that aims for uniform pacing. We further use the evaluator\nto filter new outline items based on predicted concreteness. Compared to a\nbaseline hierarchical outline generator, humans judge CONCOCT's pacing to be\nmore consistent over 57% of the time across multiple outline lengths; the gains\nalso translate to downstream stories. All code, data, and models are\nopen-sourced.",
            "author": [
                "Yichen Wang",
                "Kevin Yang",
                "Xiaoming Liu",
                "Dan Klein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04459v1",
                "http://arxiv.org/pdf/2311.04459v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04458v2",
            "title": "Retargeting video with an end-to-end framework",
            "updated": "2023-11-09T02:21:05Z",
            "published": "2023-11-08T04:56:41Z",
            "summary": "Video holds significance in computer graphics applications. Because of the\nheterogeneous of digital devices, retargeting videos becomes an essential\nfunction to enhance user viewing experience in such applications. In the\nresearch of video retargeting, preserving the relevant visual content in\nvideos, avoiding flicking, and processing time are the vital challenges.\nExtending image retargeting techniques to the video domain is challenging due\nto the high running time. Prior work of video retargeting mainly utilizes\ntime-consuming preprocessing to analyze frames. Plus, being tolerant of\ndifferent video content, avoiding important objects from shrinking, and the\nability to play with arbitrary ratios are the limitations that need to be\nresolved in these systems requiring investigation. In this paper, we present an\nend-to-end RETVI method to retarget videos to arbitrary aspect ratios. We\neliminate the computational bottleneck in the conventional approaches by\ndesigning RETVI with two modules, content feature analyzer (CFA) and adaptive\ndeforming estimator (ADE). The extensive experiments and evaluations show that\nour system outperforms previous work in quality and running time. Visit our\nproject website for more results at http://graphics.csie.ncku.edu.tw/RETVI.",
            "author": [
                "Thi-Ngoc-Hanh Le",
                "HuiGuang Huang",
                "Yi-Ru Chen",
                "Tong-Yee Lee"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TVCG.2023.3327825",
                "http://arxiv.org/abs/2311.04458v2",
                "http://arxiv.org/pdf/2311.04458v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06304v1",
            "title": "Retro-BLEU: Quantifying Chemical Plausibility of Retrosynthesis Routes\n  through Reaction Template Sequence Analysis",
            "updated": "2023-11-08T04:54:09Z",
            "published": "2023-11-08T04:54:09Z",
            "summary": "Computer-assisted methods have emerged as valuable tools for retrosynthesis\nanalysis. However, quantifying the plausibility of generated retrosynthesis\nroutes remains a challenging task. We introduce Retro-BLEU, a statistical\nmetric adapted from the well-established BLEU score in machine translation, to\nevaluate the plausibility of retrosynthesis routes based on reaction template\nsequences analysis. We demonstrate the effectiveness of Retro-BLEU by applying\nit to a diverse set of retrosynthesis routes generated by state-of-the-art\nalgorithms and compare the performance with other evaluation metrics. The\nresults show that Retro-BLEU is capable of differentiating between plausible\nand implausible routes. Furthermore, we provide insights into the strengths and\nweaknesses of Retro-BLEU, paving the way for future developments and\nimprovements in this field.",
            "author": [
                "Junren Li",
                "Lei Fang",
                "Jian-Guang Lou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06304v1",
                "http://arxiv.org/pdf/2311.06304v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04457v1",
            "title": "Evaluating Uncertainty Quantification approaches for Neural PDEs in\n  scientific applications",
            "updated": "2023-11-08T04:52:20Z",
            "published": "2023-11-08T04:52:20Z",
            "summary": "The accessibility of spatially distributed data, enabled by affordable\nsensors, field, and numerical experiments, has facilitated the development of\ndata-driven solutions for scientific problems, including climate change,\nweather prediction, and urban planning. Neural Partial Differential Equations\n(Neural PDEs), which combine deep learning (DL) techniques with domain\nexpertise (e.g., governing equations) for parameterization, have proven to be\neffective in capturing valuable correlations within spatiotemporal datasets.\nHowever, sparse and noisy measurements coupled with modeling approximation\nintroduce aleatoric and epistemic uncertainties. Therefore, quantifying\nuncertainties propagated from model inputs to outputs remains a challenge and\nan essential goal for establishing the trustworthiness of Neural PDEs. This\nwork evaluates various Uncertainty Quantification (UQ) approaches for both\nForward and Inverse Problems in scientific applications. Specifically, we\ninvestigate the effectiveness of Bayesian methods, such as Hamiltonian Monte\nCarlo (HMC) and Monte-Carlo Dropout (MCD), and a more conventional approach,\nDeep Ensembles (DE). To illustrate their performance, we take two canonical\nPDEs: Burger's equation and the Navier-Stokes equation. Our results indicate\nthat Neural PDEs can effectively reconstruct flow systems and predict the\nassociated unknown parameters. However, it is noteworthy that the results\nderived from Bayesian methods, based on our observations, tend to display a\nhigher degree of certainty in their predictions as compared to those obtained\nusing the DE. This elevated certainty in predictions suggests that Bayesian\ntechniques might underestimate the true underlying uncertainty, thereby\nappearing more confident in their predictions than the DE approach.",
            "author": [
                "Vardhan Dongre",
                "Gurpreet Singh Hora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04457v1",
                "http://arxiv.org/pdf/2311.04457v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.comp-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04453v1",
            "title": "Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments",
            "updated": "2023-11-08T04:34:30Z",
            "published": "2023-11-08T04:34:30Z",
            "summary": "As a sub-discipline of evolutionary and computational linguistics, emergent\ncommunication (EC) studies communication protocols, called emergent languages,\narising in simulations where agents communicate. A key goal of EC is to give\nrise to languages that share statistical properties with natural languages. In\nthis paper, we reinterpret Lewis's signaling game, a frequently used setting in\nEC, as beta-VAE and reformulate its objective function as ELBO. Consequently,\nwe clarify the existence of prior distributions of emergent languages and show\nthat the choice of the priors can influence their statistical properties.\nSpecifically, we address the properties of word lengths and segmentation, known\nas Zipf's law of abbreviation (ZLA) and Harris's articulation scheme (HAS),\nrespectively. It has been reported that the emergent languages do not follow\nthem when using the conventional objective. We experimentally demonstrate that\nby selecting an appropriate prior distribution, more natural segments emerge,\nwhile suggesting that the conventional one prevents the languages from\nfollowing ZLA and HAS.",
            "author": [
                "Ryo Ueda",
                "Tadahiro Taniguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04453v1",
                "http://arxiv.org/pdf/2311.04453v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04943v2",
            "title": "MathNAS: If Blocks Have a Role in Mathematical Architecture Design",
            "updated": "2023-11-12T12:26:53Z",
            "published": "2023-11-08T04:34:18Z",
            "summary": "Neural Architecture Search (NAS) has emerged as a favoured method for\nunearthing effective neural architectures. Recent development of large models\nhas intensified the demand for faster search speeds and more accurate search\nresults. However, designing large models by NAS is challenging due to the\ndramatical increase of search space and the associated huge performance\nevaluation cost. Consider a typical modular search space widely used in NAS, in\nwhich a neural architecture consists of $m$ block nodes and a block node has\n$n$ alternative blocks. Facing the space containing $n^m$ candidate networks,\nexisting NAS methods attempt to find the best one by searching and evaluating\ncandidate networks directly.Different from the general strategy that takes\narchitecture search as a whole problem, we propose a novel divide-and-conquer\nstrategy by making use of the modular nature of the search space.Here, we\nintroduce MathNAS, a general NAS framework based on mathematical programming.In\nMathNAS, the performances of the $m*n$ possible building blocks in the search\nspace are calculated first, and then the performance of a network is directly\npredicted based on the performances of its building blocks. Although estimating\nblock performances involves network training, just as what happens for network\nperformance evaluation in existing NAS methods, predicting network performance\nis completely training-free and thus extremely fast. In contrast to the $n^m$\ncandidate networks to evaluate in existing NAS methods, which require training\nand a formidable computational burden, there are only $m*n$ possible blocks to\nhandle in MathNAS. Therefore, our approach effectively reduces the complexity\nof network performance evaluation.Our code is available at\nhttps://github.com/wangqinsi1/MathNAS.",
            "author": [
                "Wang Qinsi",
                "Ke Jinghan",
                "Liang Zhi",
                "Zhang Sihai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04943v2",
                "http://arxiv.org/pdf/2311.04943v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04449v1",
            "title": "Recursion in Recursion: Two-Level Nested Recursion for Length\n  Generalization with Scalability",
            "updated": "2023-11-08T04:20:56Z",
            "published": "2023-11-08T04:20:56Z",
            "summary": "Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according\nto a preset balanced binary tree structure. Thus, their non-linear recursion\ndepth is just $\\log_2 n$ ($n$ being the sequence length). Such logarithmic\nscaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as\nLong Range Arena (LRA). However, such computational efficiency comes at a cost\nbecause BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the\nflip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other\nstructure-sensitive tasks like formal logical inference) are generally several\ntimes more expensive than even RNNs. In this paper, we introduce a novel\nframework -- Recursion in Recursion (RIR) to strike a balance between the two\nsides - getting some of the benefits from both worlds. In RIR, we use a form of\ntwo-level nested recursion - where the outer recursion is a $k$-ary balanced\ntree model with another recursive model (inner recursion) implementing its cell\nfunction. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To\nadjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment.\nOverall, this entails that the total recursive depth in RIR is upper-bounded by\n$k \\log_k n$. Our best RIR-based model is the first model that demonstrates\nhigh ($\\geq 90\\%$) length-generalization performance on ListOps while at the\nsame time being scalable enough to be trainable on long sequence inputs from\nLRA. Moreover, in terms of accuracy in the LRA language tasks, it performs\ncompetitively with Structured State Space Models (SSMs) without any special\ninitialization - outperforming Transformers by a large margin. On the other\nhand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to\nlength-generalize on ListOps. Our code is available at:\n\\url{https://github.com/JRC1995/BeamRecursionFamily/}.",
            "author": [
                "Jishnu Ray Chowdhury",
                "Cornelia Caragea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04449v1",
                "http://arxiv.org/pdf/2311.04449v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04442v1",
            "title": "SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote\n  Sensing Image Classification",
            "updated": "2023-11-08T03:54:44Z",
            "published": "2023-11-08T03:54:44Z",
            "summary": "Masked image modeling (MIM) is a highly popular and effective self-supervised\nlearning method for image understanding. Existing MIM-based methods mostly\nfocus on spatial feature modeling, neglecting spectral feature modeling.\nMeanwhile, existing MIM-based methods use Transformer for feature extraction,\nsome local or high-frequency information may get lost. To this end, we propose\na spatial-spectral masked auto-encoder (SS-MAE) for HSI and LiDAR/SAR data\njoint classification. Specifically, SS-MAE consists of a spatial-wise branch\nand a spectral-wise branch. The spatial-wise branch masks random patches and\nreconstructs missing pixels, while the spectral-wise branch masks random\nspectral channels and reconstructs missing channels. Our SS-MAE fully exploits\nthe spatial and spectral representations of the input data. Furthermore, to\ncomplement local features in the training stage, we add two lightweight CNNs\nfor feature extraction. Both global and local features are taken into account\nfor feature modeling. To demonstrate the effectiveness of the proposed SS-MAE,\nwe conduct extensive experiments on three publicly available datasets.\nExtensive experiments on three multi-source datasets verify the superiority of\nour SS-MAE compared with several state-of-the-art baselines. The source codes\nare available at \\url{https://github.com/summitgao/SS-MAE}.",
            "author": [
                "Junyan Lin",
                "Feng Gao",
                "Xiaocheng Shi",
                "Junyu Dong",
                "Qian Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04442v1",
                "http://arxiv.org/pdf/2311.04442v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04437v1",
            "title": "Cryogenic resonant amplifier for electron-on-helium image charge readout",
            "updated": "2023-11-08T03:14:39Z",
            "published": "2023-11-08T03:14:39Z",
            "summary": "An electron-on-helium qubit is a promising physical platform for quantum\ninformation technologies. Among all the \"blueprints\" for the qubit realization,\na hybrid Rydberg-spin qubit seems to be a promising one towards quantum\ncomputing using electron spins. The main technological challenge on the way to\nsuch qubits is a detection of fA range image current induced by Rydberg\ntransition of a single electron. To address this problem we aim to use a tank\nLC-circuit in conjunction with a high impedance and low power dissipation\ncryogenic amplifier. Here, we report our progress towards realization of a\nresonant image current detector with a home-made cryogenic amplifier based on\nFHX13LG HEMT. We present a detailed characterization of the transistor at room\nand cryogenic temperatures, as well as details of the amplifier design and\nperformance. At the power dissipation level of amplifier well below\n100~${\\mu}$W the measured voltage and current noise level is 0.6~nV/$\\sqrt{Hz}$\nand below 1.5~fA/$\\sqrt{Hz}$, respectively. Based on the actual image current\nmeasurements of the Rydberg transition in a many-electron system on liquid\nhelium, we estimate SNR=8 with the measurement bandwidth 1 Hz for the detection\nof a single-electron transition, providing the noise level at the output is\nsolely determined by the noise of the amplifier.",
            "author": [
                "Mikhail Belianchikov",
                "Jakob A. Kraus",
                "Denis Konstantinov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04437v1",
                "http://arxiv.org/pdf/2311.04437v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mes-hall",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04435v1",
            "title": "Hubbard model on Semiclassical approximation in combination with an\n  optimizer based on GPU technology",
            "updated": "2023-11-08T02:58:24Z",
            "published": "2023-11-08T02:58:24Z",
            "summary": "We developed a semiclassical approximation method in combination with an\nadaptive moment estimation optimizer (SCA + ADAM) approach based on the PyTorch\nplus CUDA library on a the graphics processing unit (GPU). This method was\nemployed to evaluate one-particle properties of the Hubbard model with\nlong-range spatial correlations within an appropriate computing duration. The\nmethod was applied to the ionic Hubbard model on a two-dimensional square\nlattice with long-range spatial correlations. The computation time was\nevaluated as a function of the lattice size on the central processing unit and\nGPU. Herein, we also discuss the density of states and antiferromagnetic (AF)\norder parameter in the Hubbard model without the ionic potential and compare\nthe results with those of the Hartree-Fock approximation. Finally, we present\nthe one-particle properties and order parameter in charge density wave, AF\nmetal and AF insulator of the ionic Hubbard model.",
            "author": [
                "Hayun Park",
                "Hunpyo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04435v1",
                "http://arxiv.org/pdf/2311.04435v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04434v1",
            "title": "A Hierarchical Spatial Transformer for Massive Point Samples in\n  Continuous Space",
            "updated": "2023-11-08T02:54:19Z",
            "published": "2023-11-08T02:54:19Z",
            "summary": "Transformers are widely used deep learning architectures. Existing\ntransformers are mostly designed for sequences (texts or time series), images\nor videos, and graphs. This paper proposes a novel transformer model for\nmassive (up to a million) point samples in continuous space. Such data are\nubiquitous in environment sciences (e.g., sensor observations), numerical\nsimulations (e.g., particle-laden flow, astrophysics), and location-based\nservices (e.g., POIs and trajectories). However, designing a transformer for\nmassive spatial points is non-trivial due to several challenges, including\nimplicit long-range and multi-scale dependency on irregular points in\ncontinuous space, a non-uniform point distribution, the potential high\ncomputational costs of calculating all-pair attention across massive points,\nand the risks of over-confident predictions due to varying point density. To\naddress these challenges, we propose a new hierarchical spatial transformer\nmodel, which includes multi-resolution representation learning within a\nquad-tree hierarchy and efficient spatial attention via coarse approximation.\nWe also design an uncertainty quantification branch to estimate prediction\nconfidence related to input feature noise and point sparsity. We provide a\ntheoretical analysis of computational time complexity and memory costs.\nExtensive experiments on both real-world and synthetic datasets show that our\nmethod outperforms multiple baselines in prediction accuracy and our model can\nscale up to one million points on one NVIDIA A100 GPU. The code is available at\n\\url{https://github.com/spatialdatasciencegroup/HST}.",
            "author": [
                "Wenchong He",
                "Zhe Jiang",
                "Tingsong Xiao",
                "Zelin Xu",
                "Shigang Chen",
                "Ronald Fick",
                "Miles Medina",
                "Christine Angelini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04434v1",
                "http://arxiv.org/pdf/2311.04434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04430v1",
            "title": "Blurry Video Compression: A Trade-off between Visual Enhancement and\n  Data Compression",
            "updated": "2023-11-08T02:17:54Z",
            "published": "2023-11-08T02:17:54Z",
            "summary": "Existing video compression (VC) methods primarily aim to reduce the spatial\nand temporal redundancies between consecutive frames in a video while\npreserving its quality. In this regard, previous works have achieved remarkable\nresults on videos acquired under specific settings such as instant (known)\nexposure time and shutter speed which often result in sharp videos. However,\nwhen these methods are evaluated on videos captured under different temporal\npriors, which lead to degradations like motion blur and low frame rate, they\nfail to maintain the quality of the contents. In this work, we tackle the VC\nproblem in a general scenario where a given video can be blurry due to\npredefined camera settings or dynamics in the scene. By exploiting the natural\ntrade-off between visual enhancement and data compression, we formulate VC as a\nmin-max optimization problem and propose an effective framework and training\nstrategy to tackle the problem. Extensive experimental results on several\nbenchmark datasets confirm the effectiveness of our method compared to several\nstate-of-the-art VC approaches.",
            "author": [
                "Dawit Mureja Argaw",
                "Junsik Kim",
                "In So Kweon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04430v1",
                "http://arxiv.org/pdf/2311.04430v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04942v2",
            "title": "CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric\n  Medical Image Segmentation",
            "updated": "2023-11-27T03:12:17Z",
            "published": "2023-11-08T02:13:26Z",
            "summary": "A large portion of volumetric medical data, especially magnetic resonance\nimaging (MRI) data, is anisotropic, as the through-plane resolution is\ntypically much lower than the in-plane resolution. Both 3D and purely 2D deep\nlearning-based segmentation methods are deficient in dealing with such\nvolumetric data since the performance of 3D methods suffers when confronting\nanisotropic data, and 2D methods disregard crucial volumetric information.\nInsufficient work has been done on 2.5D methods, in which 2D convolution is\nmainly used in concert with volumetric information. These models focus on\nlearning the relationship across slices, but typically have many parameters to\ntrain. We offer a Cross-Slice Attention Module (CSAM) with minimal trainable\nparameters, which captures information across all the slices in the volume by\napplying semantic, positional, and slice attention on deep feature maps at\ndifferent scales. Our extensive experiments using different network\narchitectures and tasks demonstrate the usefulness and generalizability of\nCSAM. Associated code is available at https://github.com/aL3x-O-o-Hung/CSAM.",
            "author": [
                "Alex Ling Yu Hung",
                "Haoxin Zheng",
                "Kai Zhao",
                "Xiaoxi Du",
                "Kaifeng Pang",
                "Qi Miao",
                "Steven S. Raman",
                "Demetri Terzopoulos",
                "Kyunghyun Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04942v2",
                "http://arxiv.org/pdf/2311.04942v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04940v1",
            "title": "Interpretable Geoscience Artificial Intelligence (XGeoS-AI): Application\n  to Demystify Image Recognition",
            "updated": "2023-11-08T01:54:56Z",
            "published": "2023-11-08T01:54:56Z",
            "summary": "As Earth science enters the era of big data, artificial intelligence (AI) not\nonly offers great potential for solving geoscience problems, but also plays a\ncritical role in accelerating the understanding of the complex, interactive,\nand multiscale processes of Earth's behavior. As geoscience AI models are\nprogressively utilized for significant predictions in crucial situations,\ngeoscience researchers are increasingly demanding their interpretability and\nversatility. This study proposes an interpretable geoscience artificial\nintelligence (XGeoS-AI) framework to unravel the mystery of image recognition\nin the Earth sciences, and its effectiveness and versatility is demonstrated by\ntaking computed tomography (CT) image recognition as an example. Inspired by\nthe mechanism of human vision, the proposed XGeoS-AI framework generates a\nthreshold value from a local region within the whole image to complete the\nrecognition. Different kinds of artificial intelligence (AI) methods, such as\nSupport Vector Regression (SVR), Multilayer Perceptron (MLP), Convolutional\nNeural Network (CNN), can be adopted as the AI engines of the proposed XGeoS-AI\nframework to efficiently complete geoscience image recognition tasks.\nExperimental results demonstrate that the effectiveness, versatility, and\nheuristics of the proposed framework have great potential in solving geoscience\nimage recognition problems. Interpretable AI should receive more and more\nattention in the field of the Earth sciences, which is the key to promoting\nmore rational and wider applications of AI in the field of Earth sciences. In\naddition, the proposed interpretable framework may be the forerunner of\ntechnological innovation in the Earth sciences.",
            "author": [
                "Jin-Jian Xu",
                "Hao Zhang",
                "Chao-Sheng Tang",
                "Lin Li",
                "Bin Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04940v1",
                "http://arxiv.org/pdf/2311.04940v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04939v1",
            "title": "LooGLE: Can Long-Context Language Models Understand Long Contexts?",
            "updated": "2023-11-08T01:45:37Z",
            "published": "2023-11-08T01:45:37Z",
            "summary": "Large language models (LLMs), despite their impressive performance in various\nlanguage tasks, are typically limited to processing texts within context-window\nsize. This limitation has spurred significant research efforts to enhance LLMs'\nlong-context understanding with high-quality long-sequence benchmarks. However,\nprior datasets in this regard suffer from shortcomings, such as short context\nlength compared to the context window of modern LLMs; outdated documents that\nhave data leakage problems; and an emphasis on short dependency tasks rather\nthan long dependency tasks. In this paper, we present LooGLE, a Long Context\nGeneric Language Evaluation benchmark for LLMs' long context understanding.\nLooGLE features relatively new documents post-2022, with over 24,000 tokens per\ndocument and 6,000 newly generated questions spanning diverse domains. Human\nannotators meticulously crafted more than 1,100 high-quality question-answer\npairs to meet the long dependency requirements. These pairs underwent thorough\ncross-validation, yielding the most precise assessment of LLMs' long dependency\ncapabilities. The evaluation of eight state-of-the-art LLMs on LooGLE revealed\nkey findings: (i) commercial models outperformed open-sourced models; (ii) LLMs\nexcelled in short dependency tasks like short question-answering and cloze\ntasks but struggled with more intricate long dependency tasks; (iii) in-context\nlearning and chaining thoughts offered only marginal improvements; (iv)\nretrieval-based techniques demonstrated substantial benefits for short\nquestion-answering, while strategies for extending context window length had\nlimited impact on long context understanding. As such, LooGLE not only provides\na systematic and comprehensive evaluation schema on long-context LLMs, but also\nsheds light on future development of enhanced models towards \"true long-context\nunderstanding\".",
            "author": [
                "Jiaqi Li",
                "Mengmeng Wang",
                "Zilong Zheng",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04939v1",
                "http://arxiv.org/pdf/2311.04939v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04423v2",
            "title": "Erasure detection of a dual-rail qubit encoded in a double-post\n  superconducting cavity",
            "updated": "2023-11-17T15:25:15Z",
            "published": "2023-11-08T01:36:51Z",
            "summary": "Qubits with predominantly erasure errors present distinctive advantages for\nquantum error correction(QEC) and fault tolerant quantum computing. Logical\nqubits based on dual-rail encoding that exploit erasure detection have been\nrecently proposed in superconducting circuit architectures, either with coupled\ntransmons or cavities. Here, we implement a dual-rail qubit encoded in a\ncompact, double-post superconducting cavity. Using an auxiliary transmon, we\nperform erasure detection on the dual-rail subspace. We characterize the\nbehaviour of the codespace by a novel method to perform joint-Wigner\ntomography. This is based on modifying the cross-Kerr interaction between the\ncavity modes and the transmon. We measure an erasure rate of 3.981 +/- 0.003\n(ms)-1 and a residual dephasing error rate up to 0.17 (ms)-1 within the\ncodespace. This strong hierarchy of error rates, together with the compact and\nhardware-efficient nature of this novel architecture, hold promise in realising\nQEC schemes with enhanced thresholds and improved scaling.",
            "author": [
                "Akshay Koottandavida",
                "Ioannis Tsioutsios",
                "Aikaterini Kargioti",
                "Cassady R. Smith",
                "Vidul R. Joshi",
                "Wei Dai",
                "James D. Teoh",
                "Jacob C. Curtis",
                "Luigi Frunzio",
                "Robert J. Schoelkopf",
                "Michel H. Devoret"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04423v2",
                "http://arxiv.org/pdf/2311.04423v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04420v1",
            "title": "Data Factors for Better Compositional Generalization",
            "updated": "2023-11-08T01:27:34Z",
            "published": "2023-11-08T01:27:34Z",
            "summary": "Recent diagnostic datasets on compositional generalization, such as SCAN\n(Lake and Baroni, 2018) and COGS (Kim and Linzen, 2020), expose severe problems\nin models trained from scratch on these datasets. However, in contrast to this\npoor performance, state-of-the-art models trained on larger and more general\ndatasets show better generalization ability. In this work, to reconcile this\ninconsistency, we conduct an empirical analysis by training Transformer models\non a variety of training sets with different data factors, including dataset\nscale, pattern complexity, example difficulty, etc. First, we show that\nincreased dataset complexity can lead to better generalization behavior on\nmultiple different generalization challenges. To further understand this\nimprovement, we show two axes of the benefit from more complex datasets: they\nprovide more diverse examples so compositional understanding becomes more\neffective, and they also prevent ungeneralizable memorization of the examples\ndue to reduced example repetition frequency. Finally, we explore how training\nexamples of different difficulty levels influence generalization differently.\nOn synthetic datasets, simple examples invoke stronger compositionality than\nhard examples do. On larger-scale real language datasets, while hard examples\nbecome more important potentially to ensure decent data coverage, a balanced\nmixture of simple and hard examples manages to induce the strongest\ngeneralizability. The code and data for this work are available at\nhttps://github.com/owenzx/data4comp",
            "author": [
                "Xiang Zhou",
                "Yichen Jiang",
                "Mohit Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04420v1",
                "http://arxiv.org/pdf/2311.04420v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04419v1",
            "title": "PepLand: a large-scale pre-trained peptide representation model for a\n  comprehensive landscape of both canonical and non-canonical amino acids",
            "updated": "2023-11-08T01:18:32Z",
            "published": "2023-11-08T01:18:32Z",
            "summary": "In recent years, the scientific community has become increasingly interested\non peptides with non-canonical amino acids due to their superior stability and\nresistance to proteolytic degradation. These peptides present promising\nmodifications to biological, pharmacological, and physiochemical attributes in\nboth endogenous and engineered peptides. Notwithstanding their considerable\nadvantages, the scientific community exhibits a conspicuous absence of an\neffective pre-trained model adept at distilling feature representations from\nsuch complex peptide sequences. We herein propose PepLand, a novel pre-training\narchitecture for representation and property analysis of peptides spanning both\ncanonical and non-canonical amino acids. In essence, PepLand leverages a\ncomprehensive multi-view heterogeneous graph neural network tailored to unveil\nthe subtle structural representations of peptides. Empirical validations\nunderscore PepLand's effectiveness across an array of peptide property\npredictions, encompassing protein-protein interactions, permeability,\nsolubility, and synthesizability. The rigorous evaluation confirms PepLand's\nunparalleled capability in capturing salient synthetic peptide features,\nthereby laying a robust foundation for transformative advances in\npeptide-centric research domains. We have made all the source code utilized in\nthis study publicly accessible via GitHub at\nhttps://github.com/zhangruochi/pepland",
            "author": [
                "Ruochi Zhang",
                "Haoran Wu",
                "Yuting Xiu",
                "Kewei Li",
                "Ningning Chen",
                "Yu Wang",
                "Yan Wang",
                "Xin Gao",
                "Fengfeng Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04419v1",
                "http://arxiv.org/pdf/2311.04419v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04418v2",
            "title": "AI-accelerated Discovery of Altermagnetic Materials",
            "updated": "2023-11-13T02:53:04Z",
            "published": "2023-11-08T01:06:48Z",
            "summary": "Altermagnetism, a new magnetic phase, has been theoretically proposed and\nexperimentally verified to be distinct from ferromagnetism and\nantiferromagnetism. Although altermagnets have been found to possess many\nexotic physical properties, the very limited availability of known\naltermagnetic materials (e.g., 14 confirmed materials) hinders the study of\nsuch properties. Hence, discovering more types of altermagnetic materials is\ncrucial for a comprehensive understanding of altermagnetism and thus\nfacilitating new applications in the next-generation information technologies,\ne.g., storage devices and high-sensitivity sensors. Here, we report 25 new\naltermagnetic materials that cover metals, semiconductors, and insulators,\ndiscovered by an AI search engine unifying symmetry analysis, graph neural\nnetwork pre-training, optimal transport theory, and first-principles electronic\nstructure calculation. The wide range of electronic structural characteristics\nreveals that various novel physical properties manifest in these newly\ndiscovered altermagnetic materials, e.g., anomalous Hall effect, anomalous Kerr\neffect, and topological property. Noteworthy, we discovered 8 i-wave\naltermagnetic materials for the first time. Overall, the AI search engine\nperforms much better than human experts and suggests a set of new altermagnetic\nmaterials with unique properties, outlining its potential for accelerated\ndiscovery of the materials with targeting properties.",
            "author": [
                "Ze-Feng Gao",
                "Shuai Qu",
                "Bocheng Zeng",
                "Yang Liu",
                "Ji-Rong Wen",
                "Hao Sun",
                "Peng-Jie Guo",
                "Zhong-Yi Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04418v2",
                "http://arxiv.org/pdf/2311.04418v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04417v1",
            "title": "Evaluating Emerging AI/ML Accelerators: IPU, RDU, and NVIDIA/AMD GPUs",
            "updated": "2023-11-08T01:06:25Z",
            "published": "2023-11-08T01:06:25Z",
            "summary": "The relentless advancement of artificial intelligence (AI) and machine\nlearning (ML) applications necessitates the development of specialized hardware\naccelerators capable of handling the increasing complexity and computational\ndemands. Traditional computing architectures, based on the von Neumann model,\nare being outstripped by the requirements of contemporary AI/ML algorithms,\nleading to a surge in the creation of accelerators like the Graphcore\nIntelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit\n(RDU), and enhanced GPU platforms. These hardware accelerators are\ncharacterized by their innovative data-flow architectures and other design\noptimizations that promise to deliver superior performance and energy\nefficiency for AI/ML tasks.\n  This research provides a preliminary evaluation and comparison of these\ncommercial AI/ML accelerators, delving into their hardware and software design\nfeatures to discern their strengths and unique capabilities. By conducting a\nseries of benchmark evaluations on common DNN operators and other AI/ML\nworkloads, we aim to illuminate the advantages of data-flow architectures over\nconventional processor designs and offer insights into the performance\ntrade-offs of each platform. The findings from our study will serve as a\nvaluable reference for the design and performance expectations of research\nprototypes, thereby facilitating the development of next-generation hardware\naccelerators tailored for the ever-evolving landscape of AI/ML applications.\nThrough this analysis, we aspire to contribute to the broader understanding of\ncurrent accelerator technologies and to provide guidance for future innovations\nin the field.",
            "author": [
                "Hongwu Peng",
                "Caiwen Ding",
                "Tong Geng",
                "Sutanay Choudhury",
                "Kevin Barker",
                "Ang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04417v1",
                "http://arxiv.org/pdf/2311.04417v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC",
                "cs.LG",
                "cs.PF",
                "C.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04414v2",
            "title": "Learning the What and How of Annotation in Video Object Segmentation",
            "updated": "2023-11-11T19:15:57Z",
            "published": "2023-11-08T00:56:31Z",
            "summary": "Video Object Segmentation (VOS) is crucial for several applications, from\nvideo editing to video data generation. Training a VOS model requires an\nabundance of manually labeled training videos. The de-facto traditional way of\nannotating objects requires humans to draw detailed segmentation masks on the\ntarget objects at each video frame. This annotation process, however, is\ntedious and time-consuming. To reduce this annotation cost, in this paper, we\npropose EVA-VOS, a human-in-the-loop annotation framework for video object\nsegmentation. Unlike the traditional approach, we introduce an agent that\npredicts iteratively both which frame (\"What\") to annotate and which annotation\ntype (\"How\") to use. Then, the annotator annotates only the selected frame that\nis used to update a VOS module, leading to significant gains in annotation\ntime. We conduct experiments on the MOSE and the DAVIS datasets and we show\nthat: (a) EVA-VOS leads to masks with accuracy close to the human agreement\n3.5x faster than the standard way of annotating videos; (b) our frame selection\nachieves state-of-the-art performance; (c) EVA-VOS yields significant\nperformance gains in terms of annotation time compared to all other methods and\nbaselines.",
            "author": [
                "Thanos Delatolas",
                "Vicky Kalogeiton",
                "Dim P. Papadopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04414v2",
                "http://arxiv.org/pdf/2311.04414v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04412v1",
            "title": "Human Conditional Reasoning in Answer Set Programming",
            "updated": "2023-11-08T00:54:06Z",
            "published": "2023-11-08T00:54:06Z",
            "summary": "Given a conditional sentence P=>Q (if P then Q) and respective facts, four\ndifferent types of inferences are observed in human reasoning. Affirming the\nantecedent (AA) (or modus ponens) reasons Q from P; affirming the consequent\n(AC) reasons P from Q; denying the antecedent (DA) reasons -Q from -P; and\ndenying the consequent (DC) (or modus tollens) reasons -P from -Q. Among them,\nAA and DC are logically valid, while AC and DA are logically invalid and often\ncalled logical fallacies. Nevertheless, humans often perform AC or DA as\npragmatic inference in daily life. In this paper, we realize AC, DA and DC\ninferences in answer set programming. Eight different types of completion are\nintroduced and their semantics are given by answer sets. We investigate formal\nproperties and characterize human reasoning tasks in cognitive psychology.\nThose completions are also applied to commonsense reasoning in AI.",
            "author": [
                "Chiaki Sakama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04412v1",
                "http://arxiv.org/pdf/2311.04412v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04410v1",
            "title": "An Efficient Probabilistic Solution to Mapping Errors in LiDAR-Camera\n  Fusion for Autonomous Vehicles",
            "updated": "2023-11-08T00:43:16Z",
            "published": "2023-11-08T00:43:16Z",
            "summary": "LiDAR-camera fusion is one of the core processes for the perception system of\ncurrent automated driving systems. The typical sensor fusion process includes a\nlist of coordinate transformation operations following system calibration.\nAlthough a significant amount of research has been done to improve the fusion\naccuracy, there are still inherent data mapping errors in practice related to\nsystem synchronization offsets, vehicle vibrations, the small size of the\ntarget, and fast relative moving speeds. Moreover, more and more complicated\nalgorithms to improve fusion accuracy can overwhelm the onboard computational\nresources, limiting the actual implementation. This study proposes a novel and\nlow-cost probabilistic LiDAR-Camera fusion method to alleviate these inherent\nmapping errors in scene reconstruction. By calculating shape similarity using\nKL-divergence and applying RANSAC-regression-based trajectory smoother, the\neffects of LiDAR-camera mapping errors are minimized in object localization and\ndistance estimation. Designed experiments are conducted to prove the robustness\nand effectiveness of the proposed strategy.",
            "author": [
                "Dan Shen",
                "Zhengming Zhang",
                "Renran Tian",
                "Yaobin Chen",
                "Rini Sherony"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04410v1",
                "http://arxiv.org/pdf/2311.04410v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04938v1",
            "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
            "updated": "2023-11-08T00:24:50Z",
            "published": "2023-11-08T00:24:50Z",
            "summary": "We propose using a Gaussian Mixture Model (GMM) as reverse transition\noperator (kernel) within the Denoising Diffusion Implicit Models (DDIM)\nframework, which is one of the most widely used approaches for accelerated\nsampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).\nSpecifically we match the first and second order central moments of the DDPM\nforward marginals by constraining the parameters of the GMM. We see that moment\nmatching is sufficient to obtain samples with equal or better quality than the\noriginal DDIM with Gaussian kernels. We provide experimental results with\nunconditional models trained on CelebAHQ and FFHQ and class-conditional models\ntrained on ImageNet datasets respectively. Our results suggest that using the\nGMM kernel leads to significant improvements in the quality of the generated\nsamples when the number of sampling steps is small, as measured by FID and IS\nmetrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a\nFID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73\nrespectively with a Gaussian kernel.",
            "author": [
                "Prasad Gabbur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04938v1",
                "http://arxiv.org/pdf/2311.04938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.2, I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04406v1",
            "title": "CompactTag: Minimizing Computation Overheads in Actively-Secure MPC for\n  Deep Neural Networks",
            "updated": "2023-11-08T00:18:08Z",
            "published": "2023-11-08T00:18:08Z",
            "summary": "Secure Multiparty Computation (MPC) protocols enable secure evaluation of a\ncircuit by several parties, even in the presence of an adversary who\nmaliciously corrupts all but one of the parties. These MPC protocols are\nconstructed using the well-known secret-sharing-based paradigm (SPDZ and\nSPDZ2k), where the protocols ensure security against a malicious adversary by\ncomputing Message Authentication Code (MAC) tags on the input shares and then\nevaluating the circuit with these input shares and tags. However, this tag\ncomputation adds a significant runtime overhead, particularly for machine\nlearning (ML) applications with numerous linear computation layers such as\nconvolutions and fully connected layers.\n  To alleviate the tag computation overhead, we introduce CompactTag, a\nlightweight algorithm for generating MAC tags specifically tailored for linear\nlayers in ML. Linear layer operations in ML, including convolutions, can be\ntransformed into Toeplitz matrix multiplications. For the multiplication of two\nmatrices with dimensions T1 x T2 and T2 x T3 respectively, SPDZ2k required O(T1\nx T2 x T3) local multiplications for the tag computation. In contrast,\nCompactTag only requires O(T1 x T2 + T1 x T3 + T2 x T3) local multiplications,\nresulting in a substantial performance boost for various ML models.\n  We empirically compared our protocol to the SPDZ2k protocol for various ML\ncircuits, including ResNet Training-Inference, Transformer Training-Inference,\nand VGG16 Training-Inference. SPDZ2k dedicated around 30% of its online runtime\nfor tag computation. CompactTag speeds up this tag computation bottleneck by up\nto 23x, resulting in up to 1.47x total online phase runtime speedups for\nvarious ML workloads.",
            "author": [
                "Yongqin Wang",
                "Pratik Sarkar",
                "Nishat Koti",
                "Arpita Patra",
                "Murali Annavaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04406v1",
                "http://arxiv.org/pdf/2311.04406v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04405v1",
            "title": "Toward Computing Bounds for Ramsey Numbers Using Quantum Annealing",
            "updated": "2023-11-08T00:16:46Z",
            "published": "2023-11-08T00:16:46Z",
            "summary": "Quantum annealing is a powerful tool for solving and approximating\ncombinatorial optimization problems such as graph partitioning, community\ndetection, centrality, routing problems, and more. In this paper we explore the\nuse of quantum annealing as a tool for use in exploring combinatorial\nmathematics research problems. We consider the monochromatic triangle problem\nand the Ramsey number problem, both examples of graph coloring. Conversion to\nquadratic unconstrained binary optimization (QUBO) form is required to run on\nquantum hardware. While the monochromatic triangle problem is quadratic by\nnature, the Ramsey number problem requires the use of order reduction methods\nfor a quadratic formulation. We discuss implementations, limitations, and\nresults when running on the D-Wave Advantage quantum annealer.",
            "author": [
                "Joel E. Pion",
                "Susan M. Mniszewski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04405v1",
                "http://arxiv.org/pdf/2311.04405v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04403v1",
            "title": "Human-Centered Planning",
            "updated": "2023-11-08T00:14:05Z",
            "published": "2023-11-08T00:14:05Z",
            "summary": "LLMs have recently made impressive inroads on tasks whose output is\nstructured, such as coding, robotic planning and querying databases. The vision\nof creating AI-powered personal assistants also involves creating structured\noutputs, such as a plan for one's day, or for an overseas trip. Here, since the\nplan is executed by a human, the output doesn't have to satisfy strict\nsyntactic constraints. A useful assistant should also be able to incorporate\nvague constraints specified by the user in natural language. This makes LLMs an\nattractive option for planning.\n  We consider the problem of planning one's day. We develop an LLM-based\nplanner (LLMPlan) extended with the ability to self-reflect on its output and a\nsymbolic planner (SymPlan) with the ability to translate text constraints into\na symbolic representation. Despite no formal specification of constraints, we\nfind that LLMPlan performs explicit constraint satisfaction akin to the\ntraditional symbolic planners on average (2% performance difference), while\nretaining the reasoning of implicit requirements. Consequently, LLM-based\nplanners outperform their symbolic counterparts in user satisfaction (70.5% vs.\n40.4%) during interactive evaluation with 40 users.",
            "author": [
                "Yuliang Li",
                "Nitin Kamra",
                "Ruta Desai",
                "Alon Halevy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04403v1",
                "http://arxiv.org/pdf/2311.04403v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04400v1",
            "title": "LRM: Large Reconstruction Model for Single Image to 3D",
            "updated": "2023-11-08T00:03:52Z",
            "published": "2023-11-08T00:03:52Z",
            "summary": "We propose the first Large Reconstruction Model (LRM) that predicts the 3D\nmodel of an object from a single input image within just 5 seconds. In contrast\nto many previous methods that are trained on small-scale datasets such as\nShapeNet in a category-specific fashion, LRM adopts a highly scalable\ntransformer-based architecture with 500 million learnable parameters to\ndirectly predict a neural radiance field (NeRF) from the input image. We train\nour model in an end-to-end manner on massive multi-view data containing around\n1 million objects, including both synthetic renderings from Objaverse and real\ncaptures from MVImgNet. This combination of a high-capacity model and\nlarge-scale training data empowers our model to be highly generalizable and\nproduce high-quality 3D reconstructions from various testing inputs including\nreal-world in-the-wild captures and images from generative models. Video demos\nand interactable 3D meshes can be found on this website:\nhttps://yiconghong.me/LRM/.",
            "author": [
                "Yicong Hong",
                "Kai Zhang",
                "Jiuxiang Gu",
                "Sai Bi",
                "Yang Zhou",
                "Difan Liu",
                "Feng Liu",
                "Kalyan Sunkavalli",
                "Trung Bui",
                "Hao Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04400v1",
                "http://arxiv.org/pdf/2311.04400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14696v1",
            "title": "Navigating information and uncertainty: A fuzzy logic model to approach\n  transparency, democracy and social wellbeing",
            "updated": "2023-11-07T23:54:32Z",
            "published": "2023-11-07T23:54:32Z",
            "summary": "In the digital age of information overload and uncertainty, the authors\npropose the tDTSW model based on fuzzy logic to navigate governance\ncomplexities. This model transcends binary thinking, analyzes democracy,\ntransparency, and social well-being, highlighting their roles in just societies\nthrough case studies. It addresses challenges like capitalism, sustainability,\ngender equality, and education in modern democracies, emphasizing their\ninterplay for positive change. \"Navigating Information and Uncertainty\"\nintroduces fuzzy logic, offering a structured approach. It calls for collective\nefforts to create equitable, sustainable, and just societies, inviting readers\nto shape a brighter future.",
            "author": [
                "Carlos Medel-Ram\u00edrez",
                "Hilario Medel-L\u00f3pez",
                "Jennifer Lara-M\u00e9rida"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.33060.24963",
                "http://arxiv.org/abs/2311.14696v1",
                "http://arxiv.org/pdf/2311.14696v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "03B52",
                "F.4.1; I.2.3; I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04396v1",
            "title": "Viscosity of non equilibrium hot $\\&$ dense QCD drop formed at LHC",
            "updated": "2023-11-07T23:53:48Z",
            "published": "2023-11-07T23:53:48Z",
            "summary": "We compute the bulk, $\\zeta$, and shear, $\\eta$, viscosity over entropy\ndensity, $s$, for the QCD matter formed in small collision systems at LHC. We\nconsider a scenario of the String Percolation Model by proposing a global form\nof the color reduction factor that describes both the thermodynamic limit and\nits maximum deviation due to small-bounded effects. Our method involves\nestimations at vanishing baryon-chemical potential, assuming local equilibrium\nfor string clusters in the initial state. To compute $\\eta/s$, we employed a\nkinetic approach that accounts QCD states as an ideal gas of partons, while\n$\\zeta/s$ is computed by using two different approaches: a simple kinetic\nformula and the causal dissipative relativistic fluid dynamics formulation. Our\nresults align with Lattice QCD computations and Bayesian methods and are\nconsistent with holographic conjecture bounds. Furthermore, our findings\nsupport the notion of a strongly interacting medium, similar to that observed\nin nuclear collisions, albeit with a phase transition occurring outside the\nthermodynamic limit.",
            "author": [
                "J. R. Alvarado Garc\u00eda",
                "I. Bautista",
                "A. Fern\u00e1ndez T\u00e9llez",
                "P. Fierro"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevD.108.114002",
                "http://arxiv.org/abs/2311.04396v1",
                "http://arxiv.org/pdf/2311.04396v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04391v1",
            "title": "3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features",
            "updated": "2023-11-07T23:46:41Z",
            "published": "2023-11-07T23:46:41Z",
            "summary": "We present 3DiffTection, a state-of-the-art method for 3D object detection\nfrom single images, leveraging features from a 3D-aware diffusion model.\nAnnotating large-scale image data for 3D detection is resource-intensive and\ntime-consuming. Recently, pretrained large image diffusion models have become\nprominent as effective feature extractors for 2D perception tasks. However,\nthese features are initially trained on paired text and image data, which are\nnot optimized for 3D tasks, and often exhibit a domain gap when applied to the\ntarget data. Our approach bridges these gaps through two specialized tuning\nstrategies: geometric and semantic. For geometric tuning, we fine-tune a\ndiffusion model to perform novel view synthesis conditioned on a single image,\nby introducing a novel epipolar warp operator. This task meets two essential\ncriteria: the necessity for 3D awareness and reliance solely on posed image\ndata, which are readily available (e.g., from videos) and does not require\nmanual annotation. For semantic refinement, we further train the model on\ntarget data with detection supervision. Both tuning phases employ ControlNet to\npreserve the integrity of the original feature capabilities. In the final step,\nwe harness these enhanced capabilities to conduct a test-time prediction\nensemble across multiple virtual viewpoints. Through our methodology, we obtain\n3D-aware features that are tailored for 3D detection and excel in identifying\ncross-view point correspondences. Consequently, our model emerges as a powerful\n3D detector, substantially surpassing previous benchmarks, e.g., Cube-RCNN, a\nprecedent in single-view 3D detection by 9.43\\% in AP3D on the\nOmni3D-ARkitscene dataset. Furthermore, 3DiffTection showcases robust data\nefficiency and generalization to cross-domain data.",
            "author": [
                "Chenfeng Xu",
                "Huan Ling",
                "Sanja Fidler",
                "Or Litany"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04391v1",
                "http://arxiv.org/pdf/2311.04391v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04390v1",
            "title": "Force-Constrained Visual Policy: Safe Robot-Assisted Dressing via\n  Multi-Modal Sensing",
            "updated": "2023-11-07T23:39:43Z",
            "published": "2023-11-07T23:39:43Z",
            "summary": "Robot-assisted dressing could profoundly enhance the quality of life of\nadults with physical disabilities. To achieve this, a robot can benefit from\nboth visual and force sensing. The former enables the robot to ascertain human\nbody pose and garment deformations, while the latter helps maintain safety and\ncomfort during the dressing process. In this paper, we introduce a new\ntechnique that leverages both vision and force modalities for this assistive\ntask. Our approach first trains a vision-based dressing policy using\nreinforcement learning in simulation with varying body sizes, poses, and types\nof garments. We then learn a force dynamics model for action planning to ensure\nsafety. Due to limitations of simulating accurate force data when deformable\ngarments interact with the human body, we learn a force dynamics model directly\nfrom real-world data. Our proposed method combines the vision-based policy,\ntrained in simulation, with the force dynamics model, learned in the real\nworld, by solving a constrained optimization problem to infer actions that\nfacilitate the dressing process without applying excessive force on the person.\nWe evaluate our system in simulation and in a real-world human study with 10\nparticipants across 240 dressing trials, showing it greatly outperforms prior\nbaselines. Video demonstrations are available on our project\nwebsite\\footnote{\\url{https://sites.google.com/view/dressing-fcvp}}.",
            "author": [
                "Zhanyi Sun",
                "Yufei Wang",
                "David Held",
                "Zackory Erickson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04390v1",
                "http://arxiv.org/pdf/2311.04390v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04387v2",
            "title": "The Maximum Overlap Time in the M/M/1 Queue",
            "updated": "2023-11-13T20:33:15Z",
            "published": "2023-11-07T23:22:21Z",
            "summary": "In this paper, we analyze the steady state maximum overlap time in the M/M/1\nqueue. We derive the maximum overlap time tail distribution, its moments and\nthe moment generating function. We also analyze the steady state minimum\noverlap time of the adjacent customers and compute its moments and moment\ngenerating function. Our results provide new insight on how customers become\ninfected in the M/M/1 queue.",
            "author": [
                "Sergio Palomo",
                "Jamol Pender"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04387v2",
                "http://arxiv.org/pdf/2311.04387v2"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04386v1",
            "title": "Harnessing Manycore Processors with Distributed Memory for Accelerated\n  Training of Sparse and Recurrent Models",
            "updated": "2023-11-07T23:18:35Z",
            "published": "2023-11-07T23:18:35Z",
            "summary": "Current AI training infrastructure is dominated by single instruction\nmultiple data (SIMD) and systolic array architectures, such as Graphics\nProcessing Units (GPUs) and Tensor Processing Units (TPUs), that excel at\naccelerating parallel workloads and dense vector matrix multiplications.\nPotentially more efficient neural network models utilizing sparsity and\nrecurrence cannot leverage the full power of SIMD processor and are thus at a\nsevere disadvantage compared to today's prominent parallel architectures like\nTransformers and CNNs, thereby hindering the path towards more sustainable AI.\nTo overcome this limitation, we explore sparse and recurrent model training on\na massively parallel multiple instruction multiple data (MIMD) architecture\nwith distributed local memory. We implement a training routine based on\nbackpropagation through time (BPTT) for the brain-inspired class of Spiking\nNeural Networks (SNNs) that feature binary sparse activations. We observe a\nmassive advantage in using sparse activation tensors with a MIMD processor, the\nIntelligence Processing Unit (IPU) compared to GPUs. On training workloads, our\nresults demonstrate 5-10x throughput gains compared to A100 GPUs and up to 38x\ngains for higher levels of activation sparsity, without a significant slowdown\nin training convergence or reduction in final model performance. Furthermore,\nour results show highly promising trends for both single and multi IPU\nconfigurations as we scale up to larger model sizes. Our work paves the way\ntowards more efficient, non-standard models via AI training hardware beyond\nGPUs, and competitive large scale SNN models.",
            "author": [
                "Jan Finkbeiner",
                "Thomas Gmeinder",
                "Mark Pupilli",
                "Alexander Titterton",
                "Emre Neftci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04386v1",
                "http://arxiv.org/pdf/2311.04386v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14695v1",
            "title": "AI for All: Operationalising Diversity and Inclusion Requirements for AI\n  Systems",
            "updated": "2023-11-07T23:15:03Z",
            "published": "2023-11-07T23:15:03Z",
            "summary": "As Artificial Intelligence (AI) permeates many aspects of society, it brings\nnumerous advantages while at the same time raising ethical concerns and\npotential risks, such as perpetuating inequalities through biased or\ndiscriminatory decision-making. To develop AI systems that cater for the needs\nof diverse users and uphold ethical values, it is essential to consider and\nintegrate diversity and inclusion (D&I) principles throughout AI development\nand deployment. Requirements engineering (RE) is a fundamental process in\ndeveloping software systems by eliciting and specifying relevant needs from\ndiverse stakeholders. This research aims to address the lack of research and\npractice on how to elicit and capture D&I requirements for AI systems. We have\nconducted comprehensive data collection and synthesis from the literature\nreview to extract requirements themes related to D&I in AI. We have proposed a\ntailored user story template to capture D&I requirements and conducted focus\ngroup exercises to use the themes and user story template in writing D&I\nrequirements for two example AI systems. Additionally, we have investigated the\ncapability of our solution by generating synthetic D&I requirements captured in\nuser stories with the help of a Large Language Model.",
            "author": [
                "Muneera Bano",
                "Didar Zowghi",
                "Vincenzo Gervasi",
                "Rifat Shams"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14695v1",
                "http://arxiv.org/pdf/2311.14695v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04382v1",
            "title": "Basis restricted elastic shape analysis on the space of unregistered\n  surfaces",
            "updated": "2023-11-07T23:06:22Z",
            "published": "2023-11-07T23:06:22Z",
            "summary": "This paper introduces a new mathematical and numerical framework for surface\nanalysis derived from the general setting of elastic Riemannian metrics on\nshape spaces. Traditionally, those metrics are defined over the infinite\ndimensional manifold of immersed surfaces and satisfy specific invariance\nproperties enabling the comparison of surfaces modulo shape preserving\ntransformations such as reparametrizations. The specificity of the approach we\ndevelop is to restrict the space of allowable transformations to predefined\nfinite dimensional bases of deformation fields. These are estimated in a\ndata-driven way so as to emulate specific types of surface transformations\nobserved in a training set. The use of such bases allows to simplify the\nrepresentation of the corresponding shape space to a finite dimensional latent\nspace. However, in sharp contrast with methods involving e.g. mesh\nautoencoders, the latent space is here equipped with a non-Euclidean Riemannian\nmetric precisely inherited from the family of aforementioned elastic metrics.\nWe demonstrate how this basis restricted model can be then effectively\nimplemented to perform a variety of tasks on surface meshes which, importantly,\ndoes not assume these to be pre-registered (i.e. with given point\ncorrespondences) or to even have a consistent mesh structure. We specifically\nvalidate our approach on human body shape and pose data as well as human face\nscans, and show how it generally outperforms state-of-the-art methods on\nproblems such as shape registration, interpolation, motion transfer or random\npose generation.",
            "author": [
                "Emmanuel Hartman",
                "Emery Pierson",
                "Martin Bauer",
                "Mohamed Daoudi",
                "Nicolas Charon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04382v1",
                "http://arxiv.org/pdf/2311.04382v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "math.DG",
                "I.4.0, I.5.1, I.4.9"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04378v2",
            "title": "Watermarks in the Sand: Impossibility of Strong Watermarking for\n  Generative Models",
            "updated": "2023-11-15T00:21:29Z",
            "published": "2023-11-07T22:52:54Z",
            "summary": "Watermarking generative models consists of planting a statistical signal\n(watermark) in a model's output so that it can be later verified that the\noutput was generated by the given model. A strong watermarking scheme satisfies\nthe property that a computationally bounded attacker cannot erase the watermark\nwithout causing significant quality degradation. In this paper, we study the\n(im)possibility of strong watermarking schemes. We prove that, under\nwell-specified and natural assumptions, strong watermarking is impossible to\nachieve. This holds even in the private detection algorithm setting, where the\nwatermark insertion and detection algorithms share a secret key, unknown to the\nattacker. To prove this result, we introduce a generic efficient watermark\nattack; the attacker is not required to know the private key of the scheme or\neven which scheme is used. Our attack is based on two assumptions: (1) The\nattacker has access to a \"quality oracle\" that can evaluate whether a candidate\noutput is a high-quality response to a prompt, and (2) The attacker has access\nto a \"perturbation oracle\" which can modify an output with a nontrivial\nprobability of maintaining quality, and which induces an efficiently mixing\nrandom walk on high-quality outputs. We argue that both assumptions can be\nsatisfied in practice by an attacker with weaker computational capabilities\nthan the watermarked model itself, to which the attacker has only black-box\naccess. Furthermore, our assumptions will likely only be easier to satisfy over\ntime as models grow in capabilities and modalities. We demonstrate the\nfeasibility of our attack by instantiating it to attack three existing\nwatermarking schemes for large language models: Kirchenbauer et al. (2023),\nKuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully\nremoves the watermarks planted by all three schemes, with only minor quality\ndegradation.",
            "author": [
                "Hanlin Zhang",
                "Benjamin L. Edelman",
                "Danilo Francati",
                "Daniele Venturi",
                "Giuseppe Ateniese",
                "Boaz Barak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04378v2",
                "http://arxiv.org/pdf/2311.04378v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04374v1",
            "title": "Common Knowledge, Regained",
            "updated": "2023-11-07T22:38:16Z",
            "published": "2023-11-07T22:38:16Z",
            "summary": "Formally, for common knowledge to arise in a dynamic setting, knowledge that\nit has arisen must be simultaneously attained by all players. As a result, new\ncommon knowledge is unattainable in many realistic settings, due to timing\nfrictions. This unintuitive phenomenon, observed by Halpern and Moses (1990),\nwas discussed by Arrow et al. (1987) and by Aumann (1989), was called a paradox\nby Morris (2014), and has evaded satisfactory resolution for four decades. We\nresolve this paradox by proposing a new definition for common knowledge, which\ncoincides with the traditional one in static settings but generalizes it in\ndynamic settings. Under our definition, common knowledge can arise without\nsimultaneity, particularly in canonical examples of the Haplern-Moses paradox.\nWe demonstrate its usefulness by deriving for it an agreement theorem \\`a la\nAumann (1976), and showing that it arises in the setting of Geanakoplos and\nPolemarchakis (1982) with timing frictions added.",
            "author": [
                "Yannai A. Gonczarowski",
                "Yoram Moses"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04374v1",
                "http://arxiv.org/pdf/2311.04374v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.DC",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04371v1",
            "title": "How Charles Babbage invented the Computer",
            "updated": "2023-11-07T22:30:56Z",
            "published": "2023-11-07T22:30:56Z",
            "summary": "This paper provides an overview of the successive stages in the development\nof Charles Babbage's Analytical Engine, based on the blueprints held in the\nBabbage Papers Archive, accessible online through the Science Museum in London.\nThe first person to decipher these schematics was Allan Bromley, whose\ncontributions in the 1980s and 1990s significantly advanced our understanding\nof Babbage's pioneering work. The Science Museum's digitization of the Babbage\nPapers enables a chronological exploration of the evolution of Babbage's\nmachines. The focus is on the Analytical Engine, shedding light on its lesser\nknown but crucial transitional phases.",
            "author": [
                "Raul Rojas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04371v1",
                "http://arxiv.org/pdf/2311.04371v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.NA",
                "math.NA",
                "physics.hist-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04368v1",
            "title": "Evaluating multiple large language models in pediatric ophthalmology",
            "updated": "2023-11-07T22:23:51Z",
            "published": "2023-11-07T22:23:51Z",
            "summary": "IMPORTANCE The response effectiveness of different large language models\n(LLMs) and various individuals, including medical students, graduate students,\nand practicing physicians, in pediatric ophthalmology consultations, has not\nbeen clearly established yet. OBJECTIVE Design a 100-question exam based on\npediatric ophthalmology to evaluate the performance of LLMs in highly\nspecialized scenarios and compare them with the performance of medical students\nand physicians at different levels. DESIGN, SETTING, AND PARTICIPANTS This\nsurvey study assessed three LLMs, namely ChatGPT (GPT-3.5), GPT-4, and PaLM2,\nwere assessed alongside three human cohorts: medical students, postgraduate\nstudents, and attending physicians, in their ability to answer questions\nrelated to pediatric ophthalmology. It was conducted by administering\nquestionnaires in the form of test papers through the LLM network interface,\nwith the valuable participation of volunteers. MAIN OUTCOMES AND MEASURES Mean\nscores of LLM and humans on 100 multiple-choice questions, as well as the\nanswer stability, correlation, and response confidence of each LLM. RESULTS\nGPT-4 performed comparably to attending physicians, while ChatGPT (GPT-3.5) and\nPaLM2 outperformed medical students but slightly trailed behind postgraduate\nstudents. Furthermore, GPT-4 exhibited greater stability and confidence when\nresponding to inquiries compared to ChatGPT (GPT-3.5) and PaLM2. CONCLUSIONS\nAND RELEVANCE Our results underscore the potential for LLMs to provide medical\nassistance in pediatric ophthalmology and suggest significant capacity to guide\nthe education of medical students.",
            "author": [
                "Jason Holmes",
                "Rui Peng",
                "Yiwei Li",
                "Jinyu Hu",
                "Zhengliang Liu",
                "Zihao Wu",
                "Huan Zhao",
                "Xi Jiang",
                "Wei Liu",
                "Hong Wei",
                "Jie Zou",
                "Tianming Liu",
                "Yi Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04368v1",
                "http://arxiv.org/pdf/2311.04368v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04364v1",
            "title": "Syntax-Guided Transformers: Elevating Compositional Generalization and\n  Grounding in Multimodal Environments",
            "updated": "2023-11-07T21:59:16Z",
            "published": "2023-11-07T21:59:16Z",
            "summary": "Compositional generalization, the ability of intelligent models to\nextrapolate understanding of components to novel compositions, is a fundamental\nyet challenging facet in AI research, especially within multimodal\nenvironments. In this work, we address this challenge by exploiting the\nsyntactic structure of language to boost compositional generalization. This\npaper elevates the importance of syntactic grounding, particularly through\nattention masking techniques derived from text input parsing. We introduce and\nevaluate the merits of using syntactic information in the multimodal grounding\nproblem. Our results on grounded compositional generalization underscore the\npositive impact of dependency parsing across diverse tasks when utilized with\nWeight Sharing across the Transformer encoder. The results push the\nstate-of-the-art in multimodal grounding and parameter-efficient modeling and\nprovide insights for future research.",
            "author": [
                "Danial Kamali",
                "Parisa Kordjamshidi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04364v1",
                "http://arxiv.org/pdf/2311.04364v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04361v2",
            "title": "\\textsc{DeFault}: Deep-learning-based Fault Delineation",
            "updated": "2023-11-13T18:54:52Z",
            "published": "2023-11-07T21:51:55Z",
            "summary": "The carbon capture, utilization, and storage (CCUS) framework is an essential\ncomponent in reducing greenhouse gas emissions, with its success hinging on the\ncomprehensive knowledge of subsurface geology and geomechanics. Passive seismic\nevent relocation and fault detection serve as indispensable tools, offering\nvital insights into subsurface structures and fluid migration pathways.\nAccurate identification and localization of seismic events, however, face\nsignificant challenges, including the necessity for high-quality seismic data\nand advanced computational methods. To address these challenges, we introduce a\nnovel deep learning method, DeFault, specifically designed for passive seismic\nsource relocation and fault delineating for passive seismic monitoring\nprojects. By leveraging data domain-adaptation, DeFault allows us to train a\nneural network with labeled synthetic data and apply it directly to field data.\nUsing DeFault, the passive seismic sources are automatically clustered based on\ntheir recording time and spatial locations, and subsequently, faults and\nfractures are delineated accordingly. We demonstrate the efficacy of DeFault on\na field case study involving CO2 injection related microseismic data from the\nDecatur, Illinois area. Our approach accurately and efficiently relocated\npassive seismic events, identified faults and aided in the prevention of\npotential geological hazards. Our results highlight the potential of DeFault as\na valuable tool for passive seismic monitoring, emphasizing its role in\nensuring CCUS project safety. This research bolsters the understanding of\nsubsurface characterization in CCUS, illustrating machine learning's capacity\nto refine these methods. Ultimately, our work bear significant implications for\nCCUS technology deployment, an essential strategy in combating climate change.",
            "author": [
                "Hanchen Wang",
                "Yinpeng Chen",
                "Tariq Alkhalifah",
                "Ting Chen",
                "Youzuo Lin",
                "David Alumbaugh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04361v2",
                "http://arxiv.org/pdf/2311.04361v2"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04354v2",
            "title": "Uncovering Intermediate Variables in Transformers using Circuit Probing",
            "updated": "2023-11-17T15:15:17Z",
            "published": "2023-11-07T21:27:17Z",
            "summary": "Neural network models have achieved high performance on a wide variety of\ncomplex tasks, but the algorithms that they implement are notoriously difficult\nto interpret. In order to understand these algorithms, it is often necessary to\nhypothesize intermediate variables involved in the network's computation. For\nexample, does a language model depend on particular syntactic properties when\ngenerating a sentence? However, existing analysis tools make it difficult to\ntest hypotheses of this type. We propose a new analysis technique -- circuit\nprobing -- that automatically uncovers low-level circuits that compute\nhypothesized intermediate variables. This enables causal analysis through\ntargeted ablation at the level of model parameters. We apply this method to\nmodels trained on simple arithmetic tasks, demonstrating its effectiveness at\n(1) deciphering the algorithms that models have learned, (2) revealing modular\nstructure within a model, and (3) tracking the development of circuits over\ntraining. We compare circuit probing to other methods across these three\nexperiments, and find it on par or more effective than existing analysis\nmethods. Finally, we demonstrate circuit probing on a real-world use case,\nuncovering circuits that are responsible for subject-verb agreement and\nreflexive anaphora in GPT2-Small and Medium.",
            "author": [
                "Michael A. Lepori",
                "Thomas Serre",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04354v2",
                "http://arxiv.org/pdf/2311.04354v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04351v1",
            "title": "A Deep Learning Approach to Video Anomaly Detection using Convolutional\n  Autoencoders",
            "updated": "2023-11-07T21:23:32Z",
            "published": "2023-11-07T21:23:32Z",
            "summary": "In this research we propose a deep learning approach for detecting anomalies\nin videos using convolutional autoencoder and decoder neural networks on the\nUCSD dataset.Our method utilizes a convolutional autoencoder to learn the\nspatiotemporal patterns of normal videos and then compares each frame of a test\nvideo to this learned representation. We evaluated our approach on the UCSD\ndataset and achieved an overall accuracy of 99.35% on the Ped1 dataset and\n99.77% on the Ped2 dataset, demonstrating the effectiveness of our method for\ndetecting anomalies in surveillance videos. The results show that our method\noutperforms other state-of-the-art methods, and it can be used in real-world\napplications for video anomaly detection.",
            "author": [
                "Gopikrishna Pavuluri",
                "Gayathri Annem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04351v1",
                "http://arxiv.org/pdf/2311.04351v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04350v1",
            "title": "Device Sampling and Resource Optimization for Federated Learning in\n  Cooperative Edge Networks",
            "updated": "2023-11-07T21:17:59Z",
            "published": "2023-11-07T21:17:59Z",
            "summary": "The conventional federated learning (FedL) architecture distributes machine\nlearning (ML) across worker devices by having them train local models that are\nperiodically aggregated by a server. FedL ignores two important characteristics\nof contemporary wireless networks, however: (i) the network may contain\nheterogeneous communication/computation resources, and (ii) there may be\nsignificant overlaps in devices' local data distributions. In this work, we\ndevelop a novel optimization methodology that jointly accounts for these\nfactors via intelligent device sampling complemented by device-to-device (D2D)\noffloading. Our optimization methodology aims to select the best combination of\nsampled nodes and data offloading configuration to maximize FedL training\naccuracy while minimizing data processing and D2D communication resource\nconsumption subject to realistic constraints on the network topology and device\ncapabilities. Theoretical analysis of the D2D offloading subproblem leads to\nnew FedL convergence bounds and an efficient sequential convex optimizer. Using\nthese results, we develop a sampling methodology based on graph convolutional\nnetworks (GCNs) which learns the relationship between network attributes,\nsampled nodes, and D2D data offloading to maximize FedL accuracy. Through\nevaluation on popular datasets and real-world network measurements from our\nedge testbed, we find that our methodology outperforms popular device sampling\nmethodologies from literature in terms of ML model performance, data processing\noverhead, and energy consumption.",
            "author": [
                "Su Wang",
                "Roberto Morabito",
                "Seyyedali Hosseinalipour",
                "Mung Chiang",
                "Christopher G. Brinton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04350v1",
                "http://arxiv.org/pdf/2311.04350v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04348v1",
            "title": "Evaluating the Effectiveness of Retrieval-Augmented Large Language\n  Models in Scientific Document Reasoning",
            "updated": "2023-11-07T21:09:57Z",
            "published": "2023-11-07T21:09:57Z",
            "summary": "Despite the dramatic progress in Large Language Model (LLM) development, LLMs\noften provide seemingly plausible but not factual information, often referred\nto as hallucinations. Retrieval-augmented LLMs provide a non-parametric\napproach to solve these issues by retrieving relevant information from external\ndata sources and augment the training process. These models help to trace\nevidence from an externally provided knowledge base allowing the model\npredictions to be better interpreted and verified. In this work, we critically\nevaluate these models in their ability to perform in scientific document\nreasoning tasks. To this end, we tuned multiple such model variants with\nscience-focused instructions and evaluated them on a scientific document\nreasoning benchmark for the usefulness of the retrieved document passages. Our\nfindings suggest that models justify predictions in science tasks with\nfabricated evidence and leveraging scientific corpus as pretraining data does\nnot alleviate the risk of evidence fabrication.",
            "author": [
                "Sai Munikoti",
                "Anurag Acharya",
                "Sridevi Wagle",
                "Sameera Horawalavithana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04348v1",
                "http://arxiv.org/pdf/2311.04348v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04346v1",
            "title": "SaFL: Sybil-aware Federated Learning with Application to Face\n  Recognition",
            "updated": "2023-11-07T21:06:06Z",
            "published": "2023-11-07T21:06:06Z",
            "summary": "Federated Learning (FL) is a machine learning paradigm to conduct\ncollaborative learning among clients on a joint model. The primary goal is to\nshare clients' local training parameters with an integrating server while\npreserving their privacy. This method permits to exploit the potential of\nmassive mobile users' data for the benefit of machine learning models'\nperformance while keeping sensitive data on local devices. On the downside, FL\nraises security and privacy concerns that have just started to be studied. To\naddress some of the key threats in FL, researchers have proposed to use secure\naggregation methods (e.g. homomorphic encryption, secure multiparty\ncomputation, etc.). These solutions improve some security and privacy metrics,\nbut at the same time bring about other serious threats such as poisoning\nattacks, backdoor attacks, and free running attacks. This paper proposes a new\ndefense method against poisoning attacks in FL called SaFL (Sybil-aware\nFederated Learning) that minimizes the effect of sybils with a novel\ntime-variant aggregation scheme.",
            "author": [
                "Mahdi Ghafourian",
                "Julian Fierrez",
                "Ruben Vera-Rodriguez",
                "Ruben Tolosana",
                "Aythami Morales"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04346v1",
                "http://arxiv.org/pdf/2311.04346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04345v1",
            "title": "A Taxonomy of Rater Disagreements: Surveying Challenges & Opportunities\n  from the Perspective of Annotating Online Toxicity",
            "updated": "2023-11-07T21:00:51Z",
            "published": "2023-11-07T21:00:51Z",
            "summary": "Toxicity is an increasingly common and severe issue in online spaces.\nConsequently, a rich line of machine learning research over the past decade has\nfocused on computationally detecting and mitigating online toxicity. These\nefforts crucially rely on human-annotated datasets that identify toxic content\nof various kinds in social media texts. However, such annotations historically\nyield low inter-rater agreement, which was often dealt with by taking the\nmajority vote or other such approaches to arrive at a single ground truth\nlabel. Recent research has pointed out the importance of accounting for the\nsubjective nature of this task when building and utilizing these datasets, and\nthis has triggered work on analyzing and better understanding rater\ndisagreements, and how they could be effectively incorporated into the machine\nlearning developmental pipeline. While these efforts are filling an important\ngap, there is a lack of a broader framework about the root causes of rater\ndisagreement, and therefore, we situate this work within that broader\nlandscape. In this survey paper, we analyze a broad set of literature on the\nreasons behind rater disagreements focusing on online toxicity, and propose a\ndetailed taxonomy for the same. Further, we summarize and discuss the potential\nsolutions targeting each reason for disagreement. We also discuss several open\nissues, which could promote the future development of online toxicity research.",
            "author": [
                "Wenbo Zhang",
                "Hangzhi Guo",
                "Ian D Kivlichan",
                "Vinodkumar Prabhakaran",
                "Davis Yadav",
                "Amulya Yadav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04345v1",
                "http://arxiv.org/pdf/2311.04345v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04342v2",
            "title": "Electrostatic microinstabilities and turbulence in Wendelstein 7-X close\n  to the stability threshold",
            "updated": "2023-11-09T09:50:17Z",
            "published": "2023-11-07T20:52:56Z",
            "summary": "Electrostatic gyrokinetic instabilities and turbulence in the Wendelstein 7-X\nstellarator are studied. Particular attention is paid to the\nion-temperature-gradient (ITG) instability and its character close to marginal\nstability (Floquet-type turbulence (Zocco et al. 2022)). The flux-tube version\nof the $\\delta$f code stella (Barnes et al. 2019) is used to run linear and\nnonlinear gyrokinetic simulations with kinetic electrons. The nature of the\ndominant instability depends on the wavelength perpendicular to the magnetic\nfield, and the results are conveniently displayed in stability diagrams that\ntake this dependence into account. Close to the stability threshold, the linear\neigenmodes and turbulence form highly extended structures along the\ncomputational domain if the magnetic shear is small. Numerical experiments and\ndiagnostics are undertaken to assess the resulting radial localisation of the\nturbulence, which affects the interaction of the latter with zonal flows.\nIncreasing the amplitude of the magnetic shear (e.g. through current drive) has\na stabilising effect on the turbulence and thus reduces the nonlinear energy\ntransport.",
            "author": [
                "L. Podavini",
                "A. Zocco",
                "J. M. Garc\u00eda-Rega\u00f1a",
                "M. Barnes",
                "F. I. Parra",
                "A. Mishchenko",
                "P. Helander"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04342v2",
                "http://arxiv.org/pdf/2311.04342v2"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04338v2",
            "title": "Convex Methods for Constrained Linear Bandits",
            "updated": "2023-11-10T01:05:55Z",
            "published": "2023-11-07T20:45:46Z",
            "summary": "Recently, bandit optimization has received significant attention in\nreal-world safety-critical systems that involve repeated interactions with\nhumans. While there exist various algorithms with performance guarantees in the\nliterature, practical implementation of the algorithms has not received as much\nattention. This work presents a comprehensive study on the computational\naspects of safe bandit algorithms, specifically safe linear bandits, by\nintroducing a framework that leverages convex programming tools to create\ncomputationally efficient policies. In particular, we first characterize the\nproperties of the optimal policy for safe linear bandit problem and then\npropose an end-to-end pipeline of safe linear bandit algorithms that only\ninvolves solving convex problems. We also numerically evaluate the performance\nof our proposed methods.",
            "author": [
                "Amirhossein Afsharrad",
                "Ahmadreza Moradipari",
                "Sanjay Lall"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04338v2",
                "http://arxiv.org/pdf/2311.04338v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04336v1",
            "title": "Efficient Semantic Matching with Hypercolumn Correlation",
            "updated": "2023-11-07T20:40:07Z",
            "published": "2023-11-07T20:40:07Z",
            "summary": "Recent studies show that leveraging the match-wise relationships within the\n4D correlation map yields significant improvements in establishing semantic\ncorrespondences - but at the cost of increased computation and latency. In this\nwork, we focus on the aspect that the performance improvements of recent\nmethods can also largely be attributed to the usage of multi-scale correlation\nmaps, which hold various information ranging from low-level geometric cues to\nhigh-level semantic contexts. To this end, we propose HCCNet, an efficient yet\neffective semantic matching method which exploits the full potential of\nmulti-scale correlation maps, while eschewing the reliance on expensive\nmatch-wise relationship mining on the 4D correlation map. Specifically, HCCNet\nperforms feature slicing on the bottleneck features to yield a richer set of\nintermediate features, which are used to construct a hypercolumn correlation.\nHCCNet can consequently establish semantic correspondences in an effective\nmanner by reducing the volume of conventional high-dimensional convolution or\nself-attention operations to efficient point-wise convolutions. HCCNet\ndemonstrates state-of-the-art or competitive performances on the standard\nbenchmarks of semantic matching, while incurring a notably lower latency and\ncomputation overhead compared to the existing SoTA methods.",
            "author": [
                "Seungwook Kim",
                "Juhong Min",
                "Minsu Cho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04336v1",
                "http://arxiv.org/pdf/2311.04336v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04335v1",
            "title": "Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic\n  Representations",
            "updated": "2023-11-07T20:38:30Z",
            "published": "2023-11-07T20:38:30Z",
            "summary": "We introduce sub-sentence encoder, a contrastively-learned contextual\nembedding model for fine-grained semantic representation of text. In contrast\nto the standard practice with sentence embeddings, where the meaning of an\nentire sequence of text is encoded into a fixed-length vector, the sub-sentence\nencoder learns to produce distinct contextual embeddings corresponding to\ndifferent atomic propositions, i.e. atomic units of meaning expressed within a\ntext sequence. The sub-sentence embeddings are contrastively learned to\nrecognize (inferred) semantic equivalence between propositions across different\ntext sequences. Our experiments show the effectiveness of sub-sentence encoders\nin applications, such as retrieving supporting facts for fine-grained text\nattribution or recognizing the conditional semantic similarity between texts.\nIn practice, we demonstrate that sub-sentence encoders keep the same level of\ninference cost and space complexity compared to sentence encoders.",
            "author": [
                "Sihao Chen",
                "Hongming Zhang",
                "Tong Chen",
                "Ben Zhou",
                "Wenhao Yu",
                "Dian Yu",
                "Baolin Peng",
                "Hongwei Wang",
                "Dan Roth",
                "Dong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04335v1",
                "http://arxiv.org/pdf/2311.04335v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04333v1",
            "title": "Practical Parallel Algorithms for Near-Optimal Densest Subgraphs on\n  Massive Graphs",
            "updated": "2023-11-07T20:36:01Z",
            "published": "2023-11-07T20:36:01Z",
            "summary": "The densest subgraph problem has received significant attention, both in\ntheory and in practice, due to its applications in problems such as community\ndetection, social network analysis, and spam detection. Due to the high cost of\nobtaining exact solutions, much attention has focused on designing approximate\ndensest subgraph algorithms. However, existing approaches are not able to scale\nto massive graphs with billions of edges.\n  In this paper, we introduce a new framework that combines approximate densest\nsubgraph algorithms with a pruning optimization. We design new parallel\nvariants of the state-of-the-art sequential Greedy++ algorithm, and plug it\ninto our framework in conjunction with a parallel pruning technique based on\n$k$-core decomposition to obtain parallel $(1+\\varepsilon)$-approximate densest\nsubgraph algorithms. On a single thread, our algorithms achieve\n$2.6$--$34\\times$ speedup over Greedy++, and obtain up to $22.37\\times$ self\nrelative parallel speedup on a 30-core machine with two-way hyper-threading.\nCompared with the state-of-the-art parallel algorithm by Harb et al.\n[NeurIPS'22], we achieve up to a $114\\times$ speedup on the same machine.\nFinally, against the recent sequential algorithm of Xu et al. [PACMMOD'23], we\nachieve up to a $25.9\\times$ speedup. The scalability of our algorithms enables\nus to obtain near-optimal density statistics on the hyperlink2012 (with roughly\n113 billion edges) and clueweb (with roughly 37 billion edges) graphs for the\nfirst time in the literature.",
            "author": [
                "Pattara Sukprasert",
                "Quanquan C. Liu",
                "Laxman Dhulipala",
                "Julian Shun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04333v1",
                "http://arxiv.org/pdf/2311.04333v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04329v1",
            "title": "Formal Aspects of Language Modeling",
            "updated": "2023-11-07T20:21:42Z",
            "published": "2023-11-07T20:21:42Z",
            "summary": "Large language models have become one of the most commonly deployed NLP\ninventions. In the past half-decade, their integration into core natural\nlanguage processing tools has dramatically increased the performance of such\ntools, and they have entered the public discourse surrounding artificial\nintelligence. Consequently, it is important for both developers and researchers\nalike to understand the mathematical foundations of large language models, as\nwell as how to implement them. These notes are the accompaniment to the\ntheoretical portion of the ETH Z\\\"urich course on large language models,\ncovering what constitutes a language model from a formal, theoretical\nperspective.",
            "author": [
                "Ryan Cotterell",
                "Anej Svete",
                "Clara Meister",
                "Tianyu Liu",
                "Li Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04329v1",
                "http://arxiv.org/pdf/2311.04329v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04327v1",
            "title": "Promoting Rural Entrepreneurship through Technology: A Case Study using\n  Productivity Enhancing Technology Experience Kits (PETE-Kits)",
            "updated": "2023-11-07T20:06:49Z",
            "published": "2023-11-07T20:06:49Z",
            "summary": "Contribution: Case study of a rural-focused educational program with two\ncomponents: 1) introducing high school students and teachers to Smart and\nConnected Technologies (SCTs) that can be used to solve local problems; 2)\nengaging the local community in supporting local technology-driven\nentrepreneurship.\n  Background: Rural communities typically lag behind in terms of participation\nin the digital economy, and use of technology in general. Yet they often have\nthe most to gain, due to high rates of self-employment and lower private-sector\njob opportunities.\n  Research Questions: Can a broadly-scoped rural technology education program\nlead to improvements in 1) student and teacher SCT awareness, 2) SCT skills, 3)\naspirations for future SCT use directed toward entrepreneurship and overall\ncommunity wellbeing?\n  Methodology: Our multidisciplinary team used a mixed-methods approach to\nengage a rural high school robotics team as well as the local community. Over\nthe course of one year, students took part in hands-on-training with SCTs\n(\"PETE-Kits\" and associated curriculum) and brainstormed entrepreneurial\nprojects via ideation events. Community members were involved at the beginning\nand end of the project, including judging a \"shark-tank\" style event where\nstudent business ideas using SCT were presented.\n  Findings: Results from student pre / post activity assessments suggest that\nthe program was effective at increasing comfort with technology and combining\ntechnical skills with entrepreneurial opportunities. Post surveys from\ncommunity members, including teachers, demonstrated clear support for the\nprogram and an appreciation of how SCTs / digital skills could benefit the\nlocal economy and wellbeing.",
            "author": [
                "Matthew W. Rutherford",
                "Brian E. Whitacre",
                "Levi Captain",
                "Sabit Ekin",
                "Julie Angle",
                "Tom Hensley",
                "John F. O'Hara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04327v1",
                "http://arxiv.org/pdf/2311.04327v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04326v1",
            "title": "Educating for AI Cybersecurity Work and Research: Ethics, Systems\n  Thinking, and Communication Requirements",
            "updated": "2023-11-07T20:06:38Z",
            "published": "2023-11-07T20:06:38Z",
            "summary": "The present study explored managerial and instructor perceptions of their\nfreshly employed cybersecurity workers' or students' preparedness to work\neffectively in a changing cybersecurity environment that includes AI tools.\nSpecifically, we related perceptions of technical preparedness to ethical,\nsystems thinking, and communication skills. We found that managers and\nprofessors perceive preparedness to use AI tools in cybersecurity to be\nsignificantly associated with all three non-technical skill sets. Most\nimportant, ethics is a clear leader in the network of relationships. Contrary\nto expectations that ethical concerns are left behind in the rush to adopt the\nmost advanced AI tools in security, both higher education instructors and\nmanagers appreciate their role and see them closely associated with technical\nprowess. Another significant finding is that professors over-estimate students'\npreparedness for ethical, system thinking, and communication abilities compared\nto IT managers' perceptions of their newly employed IT workers.",
            "author": [
                "Sorin Adam Matei",
                "Elisa Bertino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04326v1",
                "http://arxiv.org/pdf/2311.04326v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04325v1",
            "title": "Extending Machine Learning-Based Early Sepsis Detection to Different\n  Demographics",
            "updated": "2023-11-07T20:02:52Z",
            "published": "2023-11-07T20:02:52Z",
            "summary": "Sepsis requires urgent diagnosis, but research is predominantly focused on\nWestern datasets. In this study, we perform a comparative analysis of two\nensemble learning methods, LightGBM and XGBoost, using the public eICU-CRD\ndataset and a private South Korean St. Mary's Hospital's dataset. Our analysis\nreveals the effectiveness of these methods in addressing healthcare data\nimbalance and enhancing sepsis detection. Specifically, LightGBM shows a slight\nedge in computational efficiency and scalability. The study paves the way for\nthe broader application of machine learning in critical care, thereby expanding\nthe reach of predictive analytics in healthcare globally.",
            "author": [
                "Surajsinh Parmar",
                "Tao Shan",
                "San Lee",
                "Yonghwan Kim",
                "Jang Yong Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04325v1",
                "http://arxiv.org/pdf/2311.04325v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04319v1",
            "title": "On-The-Fly Static Analysis via Dynamic Bidirected Dyck Reachability",
            "updated": "2023-11-07T19:52:36Z",
            "published": "2023-11-07T19:52:36Z",
            "summary": "Dyck reachability is a principled, graph-based formulation of a plethora of\nstatic analyses. Bidirected graphs are used for capturing dataflow through\nmutable heap data, and are usual formalisms of demand-driven points-to and\nalias analyses. The best (offline) algorithm runs in $O(m+n\\cdot \\alpha(n))$\ntime, where $n$ is the number of nodes and $m$ is the number of edges in the\nflow graph, which becomes $O(n^2)$ in the worst case.\n  In the everyday practice of program analysis, the analyzed code is subject to\ncontinuous change, with source code being added and removed. On-the-fly static\nanalysis under such continuous updates gives rise to dynamic Dyck reachability,\nwhere reachability queries run on a dynamically changing graph, following\nprogram updates. Naturally, executing the offline algorithm in this online\nsetting is inadequate, as the time required to process a single update is\nprohibitively large.\n  In this work we develop a novel dynamic algorithm for bidirected Dyck\nreachability that has $O(n\\cdot \\alpha(n))$ worst-case performance per update,\nthus beating the $O(n^2)$ bound, and is also optimal in certain settings. We\nalso implement our algorithm and evaluate its performance on on-the-fly\ndata-dependence and alias analyses, and compare it with two best known\nalternatives, namely (i) the optimal offline algorithm, and (ii) a fully\ndynamic Datalog solver. Our experiments show that our dynamic algorithm is\nconsistently, and by far, the top performing algorithm, exhibiting speedups in\nthe order of 1000X. The running time of each update is almost always\nunnoticeable to the human eye, making it ideal for the on-the-fly analysis\nsetting.",
            "author": [
                "Shankaranarayanan Krishna",
                "Aniket Lal",
                "Andreas Pavlogiannis",
                "Omkar Tuppe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04319v1",
                "http://arxiv.org/pdf/2311.04319v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04315v1",
            "title": "A Data Perspective on Enhanced Identity Preservation for Diffusion\n  Personalization",
            "updated": "2023-11-07T19:41:19Z",
            "published": "2023-11-07T19:41:19Z",
            "summary": "Large text-to-image models have revolutionized the ability to generate\nimagery using natural language. However, particularly unique or personal visual\nconcepts, such as your pet, an object in your house, etc., will not be captured\nby the original model. This has led to interest in how to inject new visual\nconcepts, bound to a new text token, using as few as 4-6 examples. Despite\nsignificant progress, this task remains a formidable challenge, particularly in\npreserving the subject's identity. While most researchers attempt to to address\nthis issue by modifying model architectures, our approach takes a data-centric\nperspective, advocating the modification of data rather than the model itself.\nWe introduce a novel regularization dataset generation strategy on both the\ntext and image level; demonstrating the importance of a rich and structured\nregularization dataset (automatically generated) to prevent losing text\ncoherence and better identity preservation. The better quality is enabled by\nallowing up to 5x more fine-tuning iterations without overfitting and\ndegeneration. The generated renditions of the desired subject preserve even\nfine details such as text and logos; all while maintaining the ability to\ngenerate diverse samples that follow the input text prompt. Since our method\nfocuses on data augmentation, rather than adjusting the model architecture, it\nis complementary and can be combined with prior work. We show on established\nbenchmarks that our data-centric approach forms the new state of the art in\nterms of image quality, with the best trade-off between identity preservation,\ndiversity, and text alignment.",
            "author": [
                "Xingzhe He",
                "Zhiwen Cao",
                "Nicholas Kolkin",
                "Lantao Yu",
                "Helge Rhodin",
                "Ratheesh Kalarot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04315v1",
                "http://arxiv.org/pdf/2311.04315v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04936v1",
            "title": "A comparative analysis between Conformer-Transducer, Whisper, and\n  wav2vec2 for improving the child speech recognition",
            "updated": "2023-11-07T19:32:48Z",
            "published": "2023-11-07T19:32:48Z",
            "summary": "Automatic Speech Recognition (ASR) systems have progressed significantly in\ntheir performance on adult speech data; however, transcribing child speech\nremains challenging due to the acoustic differences in the characteristics of\nchild and adult voices. This work aims to explore the potential of adapting\nstate-of-the-art Conformer-transducer models to child speech to improve child\nspeech recognition performance. Furthermore, the results are compared with\nthose of self-supervised wav2vec2 models and semi-supervised multi-domain\nWhisper models that were previously finetuned on the same data. We demonstrate\nthat finetuning Conformer-transducer models on child speech yields significant\nimprovements in ASR performance on child speech, compared to the non-finetuned\nmodels. We also show Whisper and wav2vec2 adaptation on different child speech\ndatasets. Our detailed comparative analysis shows that wav2vec2 provides the\nmost consistent performance improvements among the three methods studied.",
            "author": [
                "Andrei Barcovschi",
                "Rishabh Jain",
                "Peter Corcoran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04936v1",
                "http://arxiv.org/pdf/2311.04936v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14694v1",
            "title": "Standardized Analysis Ready (STAR) data cube for high-resolution Flood\n  mapping using Sentinel-1 data",
            "updated": "2023-11-07T19:32:33Z",
            "published": "2023-11-07T19:32:33Z",
            "summary": "Floods are one of the most common disasters globally. Flood affects humans in\nmany ways. Therefore, rapid assessment is needed to assess the effect of floods\nand to take early action to support the vulnerable community in time.\nSentinel-1 is one such Earth Observation (EO) mission widely used for mapping\nthe flooding conditions at a 10m scale. However, various preprocessing steps\nare involved before analyses of the Sentinel-1 data. Researchers sometimes\navoid a few necessary corrections since it is time-consuming and complex.\nStandardization of the Sentinel-1 data is the need of the hour, specifically\nfor supporting researchers to use the Standardized Analysis-Ready (STAR) data\ncube without experiencing the complexity of the Sentinel-1 data processing. In\nthe present study, we proposed a workflow to use STAR in Google Earth Engine\n(GEE) environment. The Nigeria Flood of 2022 has been used as a case study for\nassessing the model performance.",
            "author": [
                "Surajit Ghosh",
                "Arpan Dawn",
                "Sneha Kour",
                "Susmita Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14694v1",
                "http://arxiv.org/pdf/2311.14694v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04308v1",
            "title": "Application of Response Surface Method and Genetic Algorithm in the\n  Design of High-Efficiency Prototype Vehicle",
            "updated": "2023-11-07T19:26:16Z",
            "published": "2023-11-07T19:26:16Z",
            "summary": "Breakthroughs in aerodynamic optimization have made it possible to develop\nefficient modes of transport with lesser exploitation of valuable resources.\nThis makes it crucial for technical professionals such as engineers and\nscientists to understand the methodologies behind carrying out such\noptimizations. A common approach towards improving the aerodynamic properties\nof a vehicle is to alter its physical shape, which has concurrently been a very\nstrenuous process given the time consumed to remodel the vehicle for each\nsimulation process. This research aims to tackle this problem by using\nintelligent techniques to automate the step-by-step process of remodeling the\ncar and arriving at a final optimized solution with a significantly lower drag\ncoefficient, a quantity used to measure the amount of drag force acting on a\nvehicle. This is achieved by assigning particular parameters to ensure guided\nimprovement of the airfoil in a process known as parametrization, followed by\nimplementing a response surface methodology primarily to circumvent the\nstrenuous task of performing a large number of CFD simulations by employing\nsurrogate models to generate a response surface between selected independent\nvariables. Further, evolutionary algorithms such as Genetic Algorithm have\ngained momentum in the optimization studies carried out during product design\nby selecting the optimum parameters from the available design spaces on the\nbasis of natural evolution. The proposed method of optimization has been\nsuccessfully implemented on a prototype vehicle with an improvement of 26.6%\nand 51.1% in the drag coefficient and drag area respectively.",
            "author": [
                "Paras Singh",
                "Harshit Gupta",
                "Ojas Vinayak",
                "Aryan Tyagi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04308v1",
                "http://arxiv.org/pdf/2311.04308v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04306v2",
            "title": "High-Order Numerical Method for 1D Non-local Diffusive Equation",
            "updated": "2023-11-11T09:51:56Z",
            "published": "2023-11-07T19:24:24Z",
            "summary": "In this paper we present a non-local numerical scheme based on the Local\nDiscontinuous Galerkin method for a non-local diffusive partial differential\nequation with application to traffic flow. In this model, the velocity is\ndetermined by both the average of the traffic density as well as the changes in\nthe traffic density at a neighborhood of each point. We discuss nonphysical\nbehaviors that can arise when including diffusion, and our measures to prevent\nthem in our model. The numerical results suggest that this is an accurate\nmethod for solving this type of equation and that the model can capture desired\ntraffic flow behavior. We show that computation of the non-local convolution\nresults in $\\mathcal{O}(n^2)$ complexity, but the increased computation time\ncan be mitigated with high-order schemes like the one proposed.",
            "author": [
                "D. Do",
                "H. Nick Zinat Matin",
                "M. L. Delle Monache"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04306v2",
                "http://arxiv.org/pdf/2311.04306v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04305v1",
            "title": "Revealing the ultra-fast domain wall motion in Manganese Gold through\n  permalloy capping",
            "updated": "2023-11-07T19:24:15Z",
            "published": "2023-11-07T19:24:15Z",
            "summary": "Antiferromagnets offer much faster dynamics compared to their ferromagnetic\ncounterparts but their order parameter is extremely difficult to detect and\ncontrol. So far, controlling the N\\'eel order parameter electrically is limited\nto only very few materials where N\\'eel spin-orbit torques are allowed by\nsymmetry. In this work, we show that coupling a thin ferromagnet (permalloy)\nlayer on top of an antiferromagnet (Mn$_2$Au) solves a major roadblock -- the\ncontrolled reading, writing, and manipulation of antiferromagnetic domains. We\nconfirm by atomistic spin dynamics simulations that the domain wall patterns in\nthe Mn$_2$Au are imprinted on the permalloy, therefore allowing for indirect\nimaging of the N\\'eel order parameter. Our simulations show that the coupled\ndomain wall structures in Mn$_2$Au-Py bilayers can be manipulated by either\nacting on the N\\'eel order parameter via N\\'eel spin-orbit torques or by acting\non the magnetisation (the ferromagnetic order parameter) via magnetic fields.\nIn both cases, we predict ultra-high domain wall speeds on the order of 8.5\nkm/s. Thus, employing a thin ferromagnetic layer has the potential to easily\ncontrol the N\\'eel order parameter in antiferromagnets even where N\\'eel\nspin-orbit torques are forbidden by symmetry. The controlled manipulation of\nthe antiferromagnetic order parameter provides a promising basis for the\ndevelopment of high-density storage and efficient computing technologies\nworking in the THz regime.",
            "author": [
                "Sarah Jenkins",
                "Tobias Wagner",
                "Olena Gomonay",
                "Karin Everschor-Sitte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04305v1",
                "http://arxiv.org/pdf/2311.04305v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04304v1",
            "title": "Unraveling the Holomorphic Twist: Central Charges",
            "updated": "2023-11-07T19:21:12Z",
            "published": "2023-11-07T19:21:12Z",
            "summary": "The holomorphic twist provides a powerful framework to study minimally\nprotected sectors in supersymmetric quantum field theories. We investigate the\nalgebraic structure underlying the holomorphic twist of $\\mathcal{N}=1$\nsuperconformal field theories in four dimensions. In particular, in\nholomorphically twisted theories the flavour and conformal symmetry algebras\nare enhanced to infinite-dimensional higher Kac Moody and higher Virasoro\nsymmetry algebras respectively. We explicitly compute the binary and ternary\n$\\lambda$-brackets and clarify their relation with the underlying\ninfinite-dimensional symmetry algebra. Doing so we show that the central\nextensions of said symmetry algebras precisely encode the conformal anomalies\n$a$ and $c$ as well as the flavour central charges of the physical\nfour-dimensional theory. This parallels the familiar story in two dimensions\nwhere the conformal anomaly $c$ is encoded in the central extension of the\nVirasoro algebra.",
            "author": [
                "Pieter Bomans",
                "Jingxiang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04304v1",
                "http://arxiv.org/pdf/2311.04304v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04302v2",
            "title": "How Hard is Weak-Memory Testing?",
            "updated": "2023-11-15T09:09:35Z",
            "published": "2023-11-07T19:19:03Z",
            "summary": "Weak-memory models are standard formal specifications of concurrency across\nhardware, programming languages, and distributed systems. A fundamental\ncomputational problem is consistency testing: is the observed execution of a\nconcurrent program in alignment with the specification of the underlying\nsystem? The problem has been studied extensively across Sequential Consistency\n(SC) and weak memory, and proven to be NP-complete when some aspect of the\ninput (e.g., number of threads/memory locations) is unbounded. This\nunboundedness has left a natural question open: are there efficient\nparameterized algorithms for testing?\n  The main contribution of this paper is a deep hardness result for consistency\ntesting under many popular weak-memory models: the problem remains NP-complete\neven in its bounded setting, where candidate executions contain a bounded\nnumber of threads, memory locations, and values. This hardness spreads across\nseveral Release-Acquire variants of C11, a popular variant of its Relaxed\nfragment, popular Causal Consistency models, and the POWER architecture. To our\nknowledge, this is the first result that fully exposes the hardness of\nweak-memory testing and proves that the problem admits no parameterization\nunder standard input parameters. It also yields a computational separation of\nthese models from SC, x86-TSO, PSO, and Relaxed, for which bounded consistency\ntesting is either known (for SC), or shown here (for the rest), to be in\npolynomial time.",
            "author": [
                "Soham Chakraborty",
                "Shankaranarayanan Krishna",
                "Umang Mathur",
                "Andreas Pavlogiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04302v2",
                "http://arxiv.org/pdf/2311.04302v2"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04301v1",
            "title": "Class-Incremental Continual Learning for General Purpose Healthcare\n  Models",
            "updated": "2023-11-07T19:17:59Z",
            "published": "2023-11-07T19:17:59Z",
            "summary": "Healthcare clinics regularly encounter dynamic data that changes due to\nvariations in patient populations, treatment policies, medical devices, and\nemerging disease patterns. Deep learning models can suffer from catastrophic\nforgetting when fine-tuned in such scenarios, causing poor performance on\npreviously learned tasks. Continual learning allows learning on new tasks\nwithout performance drop on previous tasks. In this work, we investigate the\nperformance of continual learning models on four different medical imaging\nscenarios involving ten classification datasets from diverse modalities,\nclinical specialties, and hospitals. We implement various continual learning\napproaches and evaluate their performance in these scenarios. Our results\ndemonstrate that a single model can sequentially learn new tasks from different\nspecialties and achieve comparable performance to naive methods. These findings\nindicate the feasibility of recycling or sharing models across the same or\ndifferent medical specialties, offering another step towards the development of\ngeneral-purpose medical imaging AI that can be shared across institutions.",
            "author": [
                "Amritpal Singh",
                "Mustafa Burak Gurbuz",
                "Shiva Souhith Gantha",
                "Prahlad Jasti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04301v1",
                "http://arxiv.org/pdf/2311.04301v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04296v1",
            "title": "Optimization of Inverted Double-Element Airfoil in Ground Effect using\n  Improved HHO and Kriging Surrogate Model",
            "updated": "2023-11-07T19:09:20Z",
            "published": "2023-11-07T19:09:20Z",
            "summary": "In the automotive industry, multi-element wings have been used to improve the\naerodynamics of race cars. Multi-element wings can enhance a vehicle's handling\nand stability by reducing drag and increasing downforce, allowing it to corner\nmore effectively and achieve higher speeds. Performance gains by utilizing the\nground effect are highly sensitive to the wing setup. This study focuses on\nidentifying the optimum design parameters for the airfoil to achieve the\ndesired downforce and drag performance. The design parameters chosen are ride\nheight, flap overlap, flap angle, and flap gap (the spacing between the flap\nand the main airfoil). These parameters are optimized for three different use\ncases: high downforce, low drag, and a setup with the highest airfoil\nefficiency. The force coefficient and flow field data were gathered using\ntwo-dimensional (2D) Reynolds Averaged Navier Stokes (RANS) simulations, with\nthe turbulent flow modeled using the k-{\\omega} Shear Stress Transport (SST)\nturbulence model. The Improved Harris Hawks Optimization (HHO) algorithm was\nused to obtain the optimal configuration of the double-element and the\nresulting designs showed a significant improvement in downforce and drag\nperformance compared to the baseline designs. Improved HHO was further compared\nwith other state-of-the-art algorithms for assessing the algorithm's\nperformance for a problem with highly non-linear behavior, where it was able to\ndemonstrate its ability to obtain the optimal solutions more efficiently.",
            "author": [
                "Paras Singh",
                "Arun Ravindranath",
                "Aryan Tyagi",
                "Aryaman Rao",
                "Raj Kumar Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04296v1",
                "http://arxiv.org/pdf/2311.04296v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04292v1",
            "title": "Aspect-based Meeting Transcript Summarization: A Two-Stage Approach with\n  Weak Supervision on Sentence Classification",
            "updated": "2023-11-07T19:06:31Z",
            "published": "2023-11-07T19:06:31Z",
            "summary": "Aspect-based meeting transcript summarization aims to produce multiple\nsummaries, each focusing on one aspect of content in a meeting transcript. It\nis challenging as sentences related to different aspects can mingle together,\nand those relevant to a specific aspect can be scattered throughout the long\ntranscript of a meeting. The traditional summarization methods produce one\nsummary mixing information of all aspects, which cannot deal with the above\nchallenges of aspect-based meeting transcript summarization. In this paper, we\npropose a two-stage method for aspect-based meeting transcript summarization.\nTo select the input content related to specific aspects, we train a sentence\nclassifier on a dataset constructed from the AMI corpus with pseudo-labeling.\nThen we merge the sentences selected for a specific aspect as the input for the\nsummarizer to produce the aspect-based summary. Experimental results on the AMI\ncorpus outperform many strong baselines, which verifies the effectiveness of\nour proposed method.",
            "author": [
                "Zhongfen Deng",
                "Seunghyun Yoon",
                "Trung Bui",
                "Franck Dernoncourt",
                "Quan Hung Tran",
                "Shuaiqi Liu",
                "Wenting Zhao",
                "Tao Zhang",
                "Yibo Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04292v1",
                "http://arxiv.org/pdf/2311.04292v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04290v1",
            "title": "SCADDA: Spatio-temporal cluster analysis with density-based distance\n  augmentation and its application to fire carbon emissions",
            "updated": "2023-11-07T19:04:08Z",
            "published": "2023-11-07T19:04:08Z",
            "summary": "Spatio-temporal clustering occupies an established role in various fields\ndealing with geospatial analysis, spanning from healthcare analysis to\nenvironmental science. One major challenge are applications in which cluster\nassignments are dependent on local densities, meaning that higher-density areas\nshould be treated more strictly for spatial clustering and vice versa. Meeting\nthis need, we describe and implement an extended method that covers continuous\nand adaptive distance rescaling based on kernel density estimates and the\northodromic metric, as well as the distance between time series via dynamic\ntime warping. In doing so, we provide the wider research community, as well as\npractitioners, with a novel approach to solve an existing challenge as well as\nan easy-to-handle and robust open-source software tool. The resulting\nimplementation is highly customizable to suit different application cases, and\nwe verify and test the latter on both an idealized scenario and the recreation\nof prior work on broadband antibiotics prescriptions in Scotland to demonstrate\nwell-behaved comparative performance. Following this, we apply our approach to\nfire emissions in Sub-Saharan Africa using data from Earth-observing\nsatellites, and show our implementation's ability to uncover seasonality shifts\nin carbon emissions of subgroups as a result of time series-driven cluster\nsplits.",
            "author": [
                "Ben Moews",
                "Antonia Gieschen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04290v1",
                "http://arxiv.org/pdf/2311.04290v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.AP",
                "62H11, 62H30, 62P12, 86A08"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04289v1",
            "title": "Parameter Tuning in the Radial Kernel-Based Partition of Unity Method by\n  Bayesian Optimization",
            "updated": "2023-11-07T19:03:17Z",
            "published": "2023-11-07T19:03:17Z",
            "summary": "In this paper, we employ Bayesian optimization to concurrently explore the\noptimal values for both the shape parameter and the radius in the partition of\nunity interpolation using radial basis functions. Bayesian optimization is a\nprobabilistic, iterative approach that models the error function through a\nprogressively self-updated Gaussian process. Meanwhile, the partition of unity\napproach harnesses a meshfree method, allowing us to significantly reduce\ncomputational expenses, particularly when considering a substantial number of\nscattered data points. This reduction in computational cost is achieved by\ndecomposing the entire domain into several smaller subdomains, each of them\nwith a variable radius. We provide an estimation of the complexity of our\nalgorithm and carry out numerical experiments to illustrate the effectiveness\nof our approach, dealing with test and real-world datasets.",
            "author": [
                "Roberto Cavoretto",
                "Alessandra De Rossi",
                "Sandro Lancellotti",
                "Federico Romaniello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04289v1",
                "http://arxiv.org/pdf/2311.04289v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04287v1",
            "title": "Holistic Evaluation of Text-To-Image Models",
            "updated": "2023-11-07T19:00:56Z",
            "published": "2023-11-07T19:00:56Z",
            "summary": "The stunning qualitative improvement of recent text-to-image models has led\nto their widespread attention and adoption. However, we lack a comprehensive\nquantitative understanding of their capabilities and risks. To fill this gap,\nwe introduce a new benchmark, Holistic Evaluation of Text-to-Image Models\n(HEIM). Whereas previous evaluations focus mostly on text-image alignment and\nimage quality, we identify 12 aspects, including text-image alignment, image\nquality, aesthetics, originality, reasoning, knowledge, bias, toxicity,\nfairness, robustness, multilinguality, and efficiency. We curate 62 scenarios\nencompassing these aspects and evaluate 26 state-of-the-art text-to-image\nmodels on this benchmark. Our results reveal that no single model excels in all\naspects, with different models demonstrating different strengths. We release\nthe generated images and human evaluation results for full transparency at\nhttps://crfm.stanford.edu/heim/v1.1.0 and the code at\nhttps://github.com/stanford-crfm/helm, which is integrated with the HELM\ncodebase.",
            "author": [
                "Tony Lee",
                "Michihiro Yasunaga",
                "Chenlin Meng",
                "Yifan Mai",
                "Joon Sung Park",
                "Agrim Gupta",
                "Yunzhi Zhang",
                "Deepak Narayanan",
                "Hannah Benita Teufel",
                "Marco Bellagente",
                "Minguk Kang",
                "Taesung Park",
                "Jure Leskovec",
                "Jun-Yan Zhu",
                "Li Fei-Fei",
                "Jiajun Wu",
                "Stefano Ermon",
                "Percy Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04287v1",
                "http://arxiv.org/pdf/2311.04287v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04284v1",
            "title": "CRAB: Assessing the Strength of Causal Relationships Between Real-world\n  Events",
            "updated": "2023-11-07T19:00:44Z",
            "published": "2023-11-07T19:00:44Z",
            "summary": "Understanding narratives requires reasoning about the cause-and-effect\nrelationships between events mentioned in the text. While existing foundation\nmodels yield impressive results in many NLP tasks requiring reasoning, it is\nunclear whether they understand the complexity of the underlying network of\ncausal relationships of events in narratives. In this work, we present CRAB, a\nnew Causal Reasoning Assessment Benchmark designed to evaluate causal\nunderstanding of events in real-world narratives. CRAB contains fine-grained,\ncontextual causality annotations for ~2.7K pairs of real-world events that\ndescribe various newsworthy event timelines (e.g., the acquisition of Twitter\nby Elon Musk). Using CRAB, we measure the performance of several large language\nmodels, demonstrating that most systems achieve poor performance on the task.\nMotivated by classical causal principles, we also analyze the causal structures\nof groups of events in CRAB, and find that models perform worse on causal\nreasoning when events are derived from complex causal structures compared to\nsimple linear causal chains. We make our dataset and code available to the\nresearch community.",
            "author": [
                "Angelika Romanou",
                "Syrielle Montariol",
                "Debjit Paul",
                "Leo Laugier",
                "Karl Aberer",
                "Antoine Bosselut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04284v1",
                "http://arxiv.org/pdf/2311.04284v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04285v1",
            "title": "Compilation of product-formula Hamiltonian simulation via reinforcement\n  learning",
            "updated": "2023-11-07T19:00:44Z",
            "published": "2023-11-07T19:00:44Z",
            "summary": "Hamiltonian simulation is believed to be one of the first tasks where quantum\ncomputers can yield a quantum advantage. One of the most popular methods of\nHamiltonian simulation is Trotterization, which makes use of the approximation\n$e^{i\\sum_jA_j}\\sim \\prod_je^{iA_j}$ and higher-order corrections thereto.\nHowever, this leaves open the question of the order of operations (i.e. the\norder of the product over $j$, which is known to affect the quality of\napproximation). In some cases this order is fixed by the desire to minimise the\nerror of approximation; when it is not the case, we propose that the order can\nbe chosen to optimize compilation to a native quantum architecture. This\npresents a new compilation problem -- order-agnostic quantum circuit\ncompilation -- which we prove is NP-hard in the worst case. In lieu of an\neasily-computable exact solution, we turn to methods of heuristic optimization\nof compilation. We focus on reinforcement learning due to the sequential nature\nof the compilation task, comparing it to simulated annealing and Monte Carlo\ntree search. While two of the methods outperform a naive heuristic,\nreinforcement learning clearly outperforms all others, with a gain of around\n12% with respect to the second-best method and of around 50% compared to the\nnaive heuristic in terms of the gate count. We further test the ability of RL\nto generalize across instances of the compilation problem, and find that a\nsingle learner is able to solve entire problem families. This demonstrates the\nability of machine learning techniques to provide assistance in an\norder-agnostic quantum compilation task.",
            "author": [
                "Lea M. Trenkwalder",
                "Eleanor Scerri",
                "Thomas E. O'Brien",
                "Vedran Dunjko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04285v1",
                "http://arxiv.org/pdf/2311.04285v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04282v1",
            "title": "Counterdiabatic optimized driving in quantum phase sensitive models",
            "updated": "2023-11-07T19:00:22Z",
            "published": "2023-11-07T19:00:22Z",
            "summary": "State preparation plays a pivotal role in numerous quantum algorithms,\nincluding quantum phase estimation. This paper extends and benchmarks\ncounterdiabatic driving protocols across three one-dimensional spin systems\ncharacterized by phase transitions: the axial next-nearest neighbor Ising\n(ANNNI), XXZ, and Haldane-Shastry (HS) models. We perform quantum optimal\ncontrol protocols by optimizing the energy cost function, which can always be\nevaluated as opposed to the fidelity one requiring the exact state. Moreover,\nwe incorporate Bayesian optimization within a code package for computing\nvarious adiabatic gauge potentials. This protocol consistently surpasses\nstandard annealing schedules, often achieving performance improvements of\nseveral orders of magnitude. Notably, the ANNNI model stands out as a notable\nexample, where fidelities exceeding 0.5 are attainable in most cases.\nFurthermore, the optimized paths exhibits promising generalization capabilities\nto higher-dimensional systems, allowing for the extension of parameters from\nsmaller models. This opens up possibilities for applying the protocol to\nhigher-dimensional systems. However, our investigations reveal limitations in\nthe case of the XXZ and HS models, particularly when transitioning away from\nthe ferromagnetic phase. This suggests that finding optimal diabatic gauge\npotentials for specific systems remains an important research direction.",
            "author": [
                "Francesco Pio Barone",
                "Oriel Kiss",
                "Michele Grossi",
                "Sofia Vallecorsa",
                "Antonio Mandarino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04282v1",
                "http://arxiv.org/pdf/2311.04282v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04280v1",
            "title": "Production of two, three, and four Higgs bosons: where SMEFT and HEFT\n  depart",
            "updated": "2023-11-07T19:00:04Z",
            "published": "2023-11-07T19:00:04Z",
            "summary": "In this article we study the phenomenological implications of multiple Higgs\nboson production from longitudinal vector boson scattering in the context of\neffective field theories. We find compact representations for effective\ntree-level amplitudes with up to four final state Higgs bosons. Total cross\nsections are then computed for scenarios relevant at the LHC in which we find\nthe general Higgs Effective Theory (HEFT) prediction avoids the heavy\nsuppression observed in Standard Model Effective Field Theory (SMEFT).",
            "author": [
                "Rafael L. Delgado",
                "Raquel G\u00f3mez-Ambrosio",
                "Javier Mart\u00ednez-Mart\u00edn",
                "Alexandre Salas-Bern\u00e1rdez",
                "Juan J. Sanz-Cillero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04280v1",
                "http://arxiv.org/pdf/2311.04280v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04274v1",
            "title": "Binary Systems in Massive Scalar-Tensor Theories: Next-to-Leading Order\n  Gravitational Waveform from Effective Field Theory",
            "updated": "2023-11-07T19:00:02Z",
            "published": "2023-11-07T19:00:02Z",
            "summary": "Neutron star binaries and their associated gravitational wave signal\nfacilitate precision tests of General Relativity. Any deviation of the detected\ngravitational waveform from General Relativity would therefore be a smoking gun\nsignature of new physics, in the form of additional forces, dark matter\nparticles, or extra gravitational degrees of freedom. To be able to probe new\ntheories, precise knowledge of the expected waveform is required. In our work,\nwe consider a generic setup by augmenting General Relativity with an\nadditional, massive scalar field. We then compute the inspiral dynamics of a\nbinary system by employing an effective field theoretical approach, while\ngiving a detailed introduction to the computational framework. Finally, we\nderive the modified gravitational waveform at next-to-leading order. As a\nconsequence of our model-agnostic approach, our results are readily adaptable\nto a plethora of new physics scenarios, including modified gravity theories and\nscalar dark matter models.",
            "author": [
                "Robin Fynn Diedrichs",
                "Daniel Schmitt",
                "Laura Sagunski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04274v1",
                "http://arxiv.org/pdf/2311.04274v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.CO",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04277v1",
            "title": "The Complexity of Being Entangled",
            "updated": "2023-11-07T19:00:02Z",
            "published": "2023-11-07T19:00:02Z",
            "summary": "Nielsen's approach to quantum state complexity relates the minimal number of\nquantum gates required to prepare a state to the length of geodesics computed\nwith a certain norm on the manifold of unitary transformations. For a bipartite\nsystem, we investigate binding complexity, which corresponds to norms in which\ngates acting on a single subsystem are free of cost. We reduce the problem to\nthe study of geodesics on the manifold of Schmidt coefficients, equipped with\nan appropriate metric. Binding complexity is closely related to other\nquantities such as distributed computing and quantum communication complexity,\nand has a proposed holographic dual in the context of AdS/CFT. For finite\ndimensional systems with a Riemannian norm, we find an exact relation between\nbinding complexity and the minimal R\\'enyi entropy. We also find analytic\nresults for the most commonly used non-Riemannian norm (the so-called $F_1$\nnorm) and provide lower bounds for the associated notion of state complexity\nubiquitous in quantum computation and holography. We argue that our results are\nvalid for a large class of penalty factors assigned to generators acting across\nthe subsystems. We demonstrate that our results can be borrowed to study the\nusual complexity (not-binding) for a single spin for the case of the $F_1$ norm\nwhich was previously lacking from the literature. Finally, we derive bounds for\nmulti-partite binding complexities and the related (continuous) circuit\ncomplexity where the circuit contains at most $2$-local interactions.",
            "author": [
                "Stefano Baiguera",
                "Shira Chapman",
                "Giuseppe Policastro",
                "Tal Schwartzman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04277v1",
                "http://arxiv.org/pdf/2311.04277v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04269v1",
            "title": "A pseudofermion functional renormalization group study of\n  dipolar-octupolar pyrochlore magnets",
            "updated": "2023-11-07T19:00:01Z",
            "published": "2023-11-07T19:00:01Z",
            "summary": "Motivated by recent experiments on Ce$_2$Zr$_2$O$_7$ that reveal a dynamic,\nliquid-like ground state, we study the nearest neighbor XYZ Hamiltonian of\ndipolar-octupolar pyrochlore magnets with the pseudofermion functional\nrenormalization group (PFFRG), which is numerically implemented by the\nSpinParser software. Taking the interaction between the octupolar components to\nbe dominant and antiferromagnetic, we map out the phase diagram demarcating the\nquantum disordered and magnetically ordered states. We identify four distinct\nphases, namely the $0$-flux and $\\pi$-flux quantum spin ices, and the\nall-in-all-out magnetic orders along the local $z$ and $x$ axes. We further use\nthe static two-spin correlations output by the PFFRG algorithm to compute the\npolarized neutron scattering cross-sections, which are able to capture several\nqualitative features observed experimentally, in the materially relevant\nparameter regime that stabilizes the $\\pi$-flux quantum spin ice. Our results\nprovide support for a quantum spin liquid ground state in Ce$_2$Zr$_2$O$_7$.",
            "author": [
                "Li Ern Chern",
                "F\u00e9lix Desrochers",
                "Yong Baek Kim",
                "Claudio Castelnovo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04269v1",
                "http://arxiv.org/pdf/2311.04269v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04219v1",
            "title": "OtterHD: A High-Resolution Multi-modality Model",
            "updated": "2023-11-07T18:59:58Z",
            "published": "2023-11-07T18:59:58Z",
            "summary": "In this paper, we present OtterHD-8B, an innovative multimodal model evolved\nfrom Fuyu-8B, specifically engineered to interpret high-resolution visual\ninputs with granular precision. Unlike conventional models that are constrained\nby fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible\ninput dimensions, ensuring its versatility across various inference\nrequirements. Alongside this model, we introduce MagnifierBench, an evaluation\nframework designed to scrutinize models' ability to discern minute details and\nspatial relationships of small objects. Our comparative analysis reveals that\nwhile current leading models falter on this benchmark, OtterHD-8B, particularly\nwhen directly processing high-resolution inputs, outperforms its counterparts\nby a substantial margin. The findings illuminate the structural variances in\nvisual information processing among different models and the influence that the\nvision encoders' pre-training resolution disparities have on model\neffectiveness within such benchmarks. Our study highlights the critical role of\nflexibility and high-resolution input capabilities in large multimodal models\nand also exemplifies the potential inherent in the Fuyu architecture's\nsimplicity for handling complex visual data.",
            "author": [
                "Bo Li",
                "Peiyuan Zhang",
                "Jingkang Yang",
                "Yuanhan Zhang",
                "Fanyi Pu",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04219v1",
                "http://arxiv.org/pdf/2311.04219v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04218v1",
            "title": "Towards Garment Sewing Pattern Reconstruction from a Single Image",
            "updated": "2023-11-07T18:59:51Z",
            "published": "2023-11-07T18:59:51Z",
            "summary": "Garment sewing pattern represents the intrinsic rest shape of a garment, and\nis the core for many applications like fashion design, virtual try-on, and\ndigital avatars. In this work, we explore the challenging problem of recovering\ngarment sewing patterns from daily photos for augmenting these applications. To\nsolve the problem, we first synthesize a versatile dataset, named SewFactory,\nwhich consists of around 1M images and ground-truth sewing patterns for model\ntraining and quantitative evaluation. SewFactory covers a wide range of human\nposes, body shapes, and sewing patterns, and possesses realistic appearances\nthanks to the proposed human texture synthesis network. Then, we propose a\ntwo-level Transformer network called Sewformer, which significantly improves\nthe sewing pattern prediction performance. Extensive experiments demonstrate\nthat the proposed framework is effective in recovering sewing patterns and well\ngeneralizes to casually-taken human photos. Code, dataset, and pre-trained\nmodels are available at: https://sewformer.github.io.",
            "author": [
                "Lijuan Liu",
                "Xiangyu Xu",
                "Zhijie Lin",
                "Jiabin Liang",
                "Shuicheng Yan"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3618319",
                "http://arxiv.org/abs/2311.04218v1",
                "http://arxiv.org/pdf/2311.04218v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04216v1",
            "title": "Replica symmetry breaking in a quantum-optical vector spin glass",
            "updated": "2023-11-07T18:59:34Z",
            "published": "2023-11-07T18:59:34Z",
            "summary": "Spin glasses are canonical examples of complex matter. Although much about\ntheir structure remains uncertain, they inform the description of a wide array\nof complex phenomena, ranging from magnetic ordering in metals with impurities\nto aspects of evolution, protein folding, climate models, combinatorial\noptimization, and artificial intelligence. Indeed, spin glass theory forms a\nmathematical basis for neuromorphic computing and brain modeling. Advancing\nexperimental insight into their structure requires repeatable control over\nmicroscopic degrees of freedom. Here, we achieve this at the atomic level using\na quantum-optical system comprised of ultracold gases of atoms coupled via\nphotons resonating within a confocal cavity. This active quantum gas microscope\nrealizes an unusual type of transverse-field vector spin glass with all-to-all\nconnectivity. Spin configurations are observed in cavity emission and reveal\nthe emergence of replica symmetry breaking and nascent ultrametric structure as\nsignatures of spin-glass order. The driven-dissipative nature of the system\nmanifests as a nonthermal Parisi distribution, in qualitative correspondence\nwith Monte Carlo simulations. The controllability provided by this new\nspin-glass system, potentially down to the quantum-spin-level, enables the\nstudy of spin-glass physics in novel regimes with application to quantum neural\nnetwork computing.",
            "author": [
                "Ronen M. Kroeze",
                "Brendan P. Marsh",
                "David Atri Schuller",
                "Henry S. Hunt",
                "Sarang Gopalakrishnan",
                "Jonathan Keeling",
                "Benjamin L. Lev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04216v1",
                "http://arxiv.org/pdf/2311.04216v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn",
                "cond-mat.quant-gas",
                "cond-mat.stat-mech",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04212v2",
            "title": "Video Instance Matting",
            "updated": "2023-11-08T05:30:54Z",
            "published": "2023-11-07T18:57:12Z",
            "summary": "Conventional video matting outputs one alpha matte for all instances\nappearing in a video frame so that individual instances are not distinguished.\nWhile video instance segmentation provides time-consistent instance masks,\nresults are unsatisfactory for matting applications, especially due to applied\nbinarization. To remedy this deficiency, we propose Video Instance\nMatting~(VIM), that is, estimating alpha mattes of each instance at each frame\nof a video sequence. To tackle this challenging problem, we present MSG-VIM, a\nMask Sequence Guided Video Instance Matting neural network, as a novel baseline\nmodel for VIM. MSG-VIM leverages a mixture of mask augmentations to make\npredictions robust to inaccurate and inconsistent mask guidance. It\nincorporates temporal mask and temporal feature guidance to improve the\ntemporal consistency of alpha matte predictions. Furthermore, we build a new\nbenchmark for VIM, called VIM50, which comprises 50 video clips with multiple\nhuman instances as foreground objects. To evaluate performances on the VIM\ntask, we introduce a suitable metric called Video Instance-aware Matting\nQuality~(VIMQ). Our proposed model MSG-VIM sets a strong baseline on the VIM50\nbenchmark and outperforms existing methods by a large margin. The project is\nopen-sourced at https://github.com/SHI-Labs/VIM.",
            "author": [
                "Jiachen Li",
                "Roberto Henschel",
                "Vidit Goel",
                "Marianna Ohanyan",
                "Shant Navasardyan",
                "Humphrey Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04212v2",
                "http://arxiv.org/pdf/2311.04212v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04210v1",
            "title": "A Bayesian Approach for Simultaneously Radial Kernel Parameter Tuning in\n  the Partition of Unity Method",
            "updated": "2023-11-07T18:54:41Z",
            "published": "2023-11-07T18:54:41Z",
            "summary": "In this paper, Bayesian optimisation is used to simultaneously search the\noptimal values of the shape parameter and the radius in radial basis function\npartition of unity interpolation problem. It is a probabilistic iterative\napproach that models the error function with a step-by-step self-updated\nGaussian process, whereas partition of unity leverages a mesh-free method that\nallows us to reduce cost-intensive computations when the number of scattered\ndata is very large, as the entire domain is decomposed into several smaller\nsubdomains of variable radius. Numerical experiments on the scattered data\ninterpolation problem show that the combination of these two tools sharply\nreduces the search time with respect to other techniques such as the leave one\nout cross validation.",
            "author": [
                "Roberto Cavoretto",
                "Alessandra De Rossi",
                "Sandro Lancellotti",
                "Federico Romaniello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04210v1",
                "http://arxiv.org/pdf/2311.04210v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04207v1",
            "title": "Deep Hashing via Householder Quantization",
            "updated": "2023-11-07T18:47:28Z",
            "published": "2023-11-07T18:47:28Z",
            "summary": "Hashing is at the heart of large-scale image similarity search, and recent\nmethods have been substantially improved through deep learning techniques. Such\nalgorithms typically learn continuous embeddings of the data. To avoid a\nsubsequent costly binarization step, a common solution is to employ loss\nfunctions that combine a similarity learning term (to ensure similar images are\ngrouped to nearby embeddings) and a quantization penalty term (to ensure that\nthe embedding entries are close to binarized entries, e.g., -1 or 1). Still,\nthe interaction between these two terms can make learning harder and the\nembeddings worse. We propose an alternative quantization strategy that\ndecomposes the learning problem in two stages: first, perform similarity\nlearning over the embedding space with no quantization; second, find an optimal\northogonal transformation of the embeddings so each coordinate of the embedding\nis close to its sign, and then quantize the transformed embedding through the\nsign function. In the second step, we parametrize orthogonal transformations\nusing Householder matrices to efficiently leverage stochastic gradient descent.\nSince similarity measures are usually invariant under orthogonal\ntransformations, this quantization strategy comes at no cost in terms of\nperformance. The resulting algorithm is unsupervised, fast, hyperparameter-free\nand can be run on top of any existing deep hashing or metric learning\nalgorithm. We provide extensive experimental results showing that this approach\nleads to state-of-the-art performance on widely used image datasets, and,\nunlike other quantization strategies, brings consistent improvements in\nperformance to existing deep hashing algorithms.",
            "author": [
                "Lucas R. Schwengber",
                "Lucas Resende",
                "Paulo Orenstein",
                "Roberto I. Oliveira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04207v1",
                "http://arxiv.org/pdf/2311.04207v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04205v1",
            "title": "Rephrase and Respond: Let Large Language Models Ask Better Questions for\n  Themselves",
            "updated": "2023-11-07T18:43:34Z",
            "published": "2023-11-07T18:43:34Z",
            "summary": "Misunderstandings arise not only in interpersonal communication but also\nbetween humans and Large Language Models (LLMs). Such discrepancies can make\nLLMs interpret seemingly unambiguous questions in unexpected ways, yielding\nincorrect responses. While it is widely acknowledged that the quality of a\nprompt, such as a question, significantly impacts the quality of the response\nprovided by LLMs, a systematic method for crafting questions that LLMs can\nbetter comprehend is still underdeveloped. In this paper, we present a method\nnamed `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand\nquestions posed by humans and provide responses in a single prompt. This\napproach serves as a simple yet effective prompting method for improving\nperformance. We also introduce a two-step variant of RaR, where a rephrasing\nLLM first rephrases the question and then passes the original and rephrased\nquestions together to a different responding LLM. This facilitates the\neffective utilization of rephrased questions generated by one LLM with another.\nOur experiments demonstrate that our methods significantly improve the\nperformance of different models across a wide range to tasks. We further\nprovide a comprehensive comparison between RaR and the popular Chain-of-Thought\n(CoT) methods, both theoretically and empirically. We show that RaR is\ncomplementary to CoT and can be combined with CoT to achieve even better\nperformance. Our work not only contributes to enhancing LLM performance\nefficiently and effectively but also sheds light on a fair evaluation of LLM\ncapabilities. Data and codes are available at\nhttps://github.com/uclaml/Rephrase-and-Respond.",
            "author": [
                "Yihe Deng",
                "Weitong Zhang",
                "Zixiang Chen",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04205v1",
                "http://arxiv.org/pdf/2311.04205v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04204v2",
            "title": "Sharp Thresholds Imply Circuit Lower Bounds: from random 2-SAT to\n  Planted Clique",
            "updated": "2023-11-30T22:56:25Z",
            "published": "2023-11-07T18:43:27Z",
            "summary": "We show that sharp thresholds for Boolean functions directly imply\naverage-case circuit lower bounds. More formally we show that any Boolean\nfunction exhibiting a sharp enough threshold at \\emph{arbitrary} critical\ndensity cannot be computed by Boolean circuits of bounded depth and polynomial\nsize.\n  Our general result implies new average-case bounded depth circuit lower\nbounds in a variety of settings.\n  (a) ($k$-cliques) For $k=\\Theta(n)$, we prove that any circuit of depth $d$\ndeciding the presence of a size $k$ clique in a random graph requires\nexponential-in-$n^{\\Theta(1/d)}$ size. To the best of our knowledge, this is\nthe first average-case exponential size lower bound for bounded depth (not\nnecessarily monotone) circuits solving the fundamental $k$-clique problem (for\nany $k=k_n$).\n  (b)(random 2-SAT) We prove that any circuit of depth $d$ deciding the\nsatisfiability of a random 2-SAT formula requires\nexponential-in-$n^{\\Theta(1/d)}$ size. To the best of our knowledge, this is\nthe first bounded depth circuit lower bound for random $k$-SAT for any value of\n$k \\geq 2.$ Our results also provide the first rigorous lower bound in\nagreement with a conjectured, but debated, ``computational hardness'' of random\n$k$-SAT around its satisfiability threshold.\n  (c)(Statistical estimation -- planted $k$-clique) Over the recent years,\nmultiple statistical estimation problems have also been proven to exhibit a\n``statistical'' sharp threshold, called the All-or-Nothing (AoN) phenomenon. We\nshow that AoN also implies circuit lower bounds for statistical problems. As a\nsimple corollary of that, we prove that any circuit of depth $d$ that solves to\ninformation-theoretic optimality a ``dense'' variant of the celebrated planted\n$k$-clique problem requires exponential-in-$n^{\\Theta(1/d)}$ size.",
            "author": [
                "David Gamarnik",
                "Elchanan Mossel",
                "Ilias Zadik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04204v2",
                "http://arxiv.org/pdf/2311.04204v2"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "math.PR",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04203v1",
            "title": "Derived Categories of Permutahedral and Stellahedral Varieties",
            "updated": "2023-11-07T18:42:52Z",
            "published": "2023-11-07T18:42:52Z",
            "summary": "We utilize the coherent-constructible correspondence to construct full\nstrongly exceptional collections of nef line bundles in the derived category of\na toric variety through the combinatorics of constructible sheaves built from\npolytopes. To show that sequences are full, we build exact complexes of line\nbundles that categorify the relations in the McMullen polytope algebra. We\ncompute the homomorphisms between certain constructible sheaves on polytopes\nand use this to reduce the question of exceptionality to showing that certain\nset differences of polytopes are contractible.\n  As an application of our method, we construct full strongly exceptional\ncollections of nef line bundles for the toric varieties associated to the\npermutahedron, stellahedron, and the type $B_n$ Coxeter permutahedron. The line\nbundles in our collections are indexed by base polytopes of loopless Schubert\nmatroids, independence polytopes of all Schubert matroids, and feasible\npolytopes of loopless Schubert delta matroids, respectively.\n  Our collections satisfy a number of nice properties: First, the quiver with\nrelations that encodes the endomorphism algebra of the tilting sheaf can be\ndescribed matroid-theoretically as a slight extension of the notion of weak\nmaps and inclusion of matroids; Second, our collections are invariant under the\nnatural symmetries of the corresponding fans; Finally, the induced\nsemi-orthogonal decomposition of the derived categories refines the cuspidal\nsemi-orthogonal decomposition as studied by Castravet and Tevelev. This gives a\nfull strongly exceptional collection of nef line bundles for the cuspidal parts\nof the derived categories of our varieties indexed by loopless and coloopless\nSchubert matroids and Schubert delta matroids.",
            "author": [
                "Mario Sanchez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04203v1",
                "http://arxiv.org/pdf/2311.04203v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.CO",
                "14M25 (Primary), 52B40, 18G80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04199v1",
            "title": "Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary\n  Case Study",
            "updated": "2023-11-07T18:39:10Z",
            "published": "2023-11-07T18:39:10Z",
            "summary": "Large Multimodal Models (LMMs) have demonstrated impressive performance\nacross various vision and language tasks, yet their potential applications in\nrecommendation tasks with visual assistance remain unexplored. To bridge this\ngap, we present a preliminary case study investigating the recommendation\ncapabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a\nseries of qualitative test samples spanning multiple domains and employ these\nsamples to assess the quality of GPT-4V's responses within recommendation\nscenarios. Evaluation results on these test samples prove that GPT-4V has\nremarkable zero-shot recommendation abilities across diverse domains, thanks to\nits robust visual-text comprehension capabilities and extensive general\nknowledge. However, we have also identified some limitations in using GPT-4V\nfor recommendations, including a tendency to provide similar responses when\ngiven similar inputs. This report concludes with an in-depth discussion of the\nchallenges and research opportunities associated with utilizing GPT-4V in\nrecommendation scenarios. Our objective is to explore the potential of\nextending LMMs from vision and language tasks to recommendation tasks. We hope\nto inspire further research into next-generation multimodal generative\nrecommendation models, which can enhance user experiences by offering greater\ndiversity and interactivity. All images and prompts used in this report will be\naccessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.",
            "author": [
                "Peilin Zhou",
                "Meng Cao",
                "You-Liang Huang",
                "Qichen Ye",
                "Peiyan Zhang",
                "Junling Liu",
                "Yueqi Xie",
                "Yining Hua",
                "Jaeboum Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04199v1",
                "http://arxiv.org/pdf/2311.04199v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04196v1",
            "title": "JPAVE: A Generation and Classification-based Model for Joint Product\n  Attribute Prediction and Value Extraction",
            "updated": "2023-11-07T18:36:16Z",
            "published": "2023-11-07T18:36:16Z",
            "summary": "Product attribute value extraction is an important task in e-Commerce which\ncan help several downstream applications such as product search and\nrecommendation. Most previous models handle this task using sequence labeling\nor question answering method which rely on the sequential position information\nof values in the product text and are vulnerable to data discrepancy between\ntraining and testing. This limits their generalization ability to real-world\nscenario in which each product can have multiple descriptions across various\nshopping platforms with different composition of text and style. They also have\nlimited zero-shot ability to new values. In this paper, we propose a multi-task\nlearning model with value generation/classification and attribute prediction\ncalled JPAVE to predict values without the necessity of position information of\nvalues in the text. Furthermore, the copy mechanism in value generator and the\nvalue attention module in value classifier help our model address the data\ndiscrepancy issue by only focusing on the relevant part of input text and\nignoring other information which causes the discrepancy issue such as sentence\nstructure in the text. Besides, two variants of our model are designed for\nopen-world and closed-world scenarios. In addition, copy mechanism introduced\nin the first variant based on value generation can improve its zero-shot\nability for identifying unseen values. Experimental results on a public dataset\ndemonstrate the superiority of our model compared with strong baselines and its\ngeneralization ability of predicting new values.",
            "author": [
                "Zhongfen Deng",
                "Hao Peng",
                "Tao Zhang",
                "Shuaiqi Liu",
                "Wenting Zhao",
                "Yibo Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04196v1",
                "http://arxiv.org/pdf/2311.04196v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04194v1",
            "title": "Quantization-aware Neural Architectural Search for Intrusion Detection",
            "updated": "2023-11-07T18:35:29Z",
            "published": "2023-11-07T18:35:29Z",
            "summary": "Deploying machine learning-based intrusion detection systems (IDSs) on\nhardware devices is challenging due to their limited computational resources,\npower consumption, and network connectivity. Hence, there is a significant need\nfor robust, deep learning models specifically designed with such constraints in\nmind. In this paper, we present a design methodology that automatically trains\nand evolves quantized neural network (NN) models that are a thousand times\nsmaller than state-of-the-art NNs but can efficiently analyze network data for\nintrusion at high accuracy. In this regard, the number of LUTs utilized by this\nnetwork when deployed to an FPGA is between 2.3x and 8.5x smaller with\nperformance comparable to prior work.",
            "author": [
                "Rabin Yu Acharya",
                "Laurens Le Jeune",
                "Nele Mentens",
                "Fatemeh Ganji",
                "Domenic Forte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04194v1",
                "http://arxiv.org/pdf/2311.04194v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04193v1",
            "title": "Selective Visual Representations Improve Convergence and Generalization\n  for Embodied AI",
            "updated": "2023-11-07T18:34:02Z",
            "published": "2023-11-07T18:34:02Z",
            "summary": "Embodied AI models often employ off the shelf vision backbones like CLIP to\nencode their visual observations. Although such general purpose representations\nencode rich syntactic and semantic information about the scene, much of this\ninformation is often irrelevant to the specific task at hand. This introduces\nnoise within the learning process and distracts the agent's focus from\ntask-relevant visual cues. Inspired by selective attention in humans-the\nprocess through which people filter their perception based on their\nexperiences, knowledge, and the task at hand-we introduce a parameter-efficient\napproach to filter visual stimuli for embodied AI. Our approach induces a\ntask-conditioned bottleneck using a small learnable codebook module. This\ncodebook is trained jointly to optimize task reward and acts as a\ntask-conditioned selective filter over the visual observation. Our experiments\nshowcase state-of-the-art performance for object goal navigation and object\ndisplacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR,\nand ManipulaTHOR. The filtered representations produced by the codebook are\nalso able generalize better and converge faster when adapted to other\nsimulation environments such as Habitat. Our qualitative analyses show that\nagents explore their environments more effectively and their representations\nretain task-relevant information like target object recognition while ignoring\nsuperfluous information about other objects. Code and pretrained models are\navailable at our project website: https://embodied-codebook.github.io.",
            "author": [
                "Ainaz Eftekhar",
                "Kuo-Hao Zeng",
                "Jiafei Duan",
                "Ali Farhadi",
                "Ani Kembhavi",
                "Ranjay Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04193v1",
                "http://arxiv.org/pdf/2311.04193v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04192v1",
            "title": "JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures\n  for Image Captioning Models",
            "updated": "2023-11-07T18:33:34Z",
            "published": "2023-11-07T18:33:34Z",
            "summary": "Image captioning studies heavily rely on automatic evaluation metrics such as\nBLEU and METEOR. However, such n-gram-based metrics have been shown to\ncorrelate poorly with human evaluation, leading to the proposal of alternative\nmetrics such as SPICE for English; however, no equivalent metrics have been\nestablished for other languages. Therefore, in this study, we propose an\nautomatic evaluation metric called JaSPICE, which evaluates Japanese captions\nbased on scene graphs. The proposed method generates a scene graph from\ndependencies and the predicate-argument structure, and extends the graph using\nsynonyms. We conducted experiments employing 10 image captioning models trained\non STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which\ncontains 103,170 human evaluations. The results showed that our metric\noutperformed the baseline metrics for the correlation coefficient with the\nhuman evaluation.",
            "author": [
                "Yuiga Wada",
                "Kanta Kaneda",
                "Komei Sugiura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04192v1",
                "http://arxiv.org/pdf/2311.04192v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04189v1",
            "title": "SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions\n  for Collocations in Spanish",
            "updated": "2023-11-07T18:32:34Z",
            "published": "2023-11-07T18:32:34Z",
            "summary": "In natural language processing (NLP), lexical function is a concept to\nunambiguously represent semantic and syntactic features of words and phrases in\ntext first crafted in the Meaning-Text Theory. Hierarchical classification of\nlexical functions involves organizing these features into a tree-like hierarchy\nof categories or labels. This is a challenging task as it requires a good\nunderstanding of the context and the relationships among words and phrases in\ntext. It also needs large amounts of labeled data to train language models\neffectively. In this paper, we present a dataset of most frequent Spanish\nverb-noun collocations and sentences where they occur, each collocation is\nassigned to one of 37 lexical functions defined as classes for a hierarchical\nclassification task. Each class represents a relation between the noun and the\nverb in a collocation involving their semantic and syntactic features. We\ncombine the classes in a tree-based structure, and introduce classification\nobjectives for each level of the structure. The dataset was created by\ndependency tree parsing and matching of the phrases in Spanish news. We provide\nbaselines and data splits for each objective.",
            "author": [
                "Yevhen Kostiuk",
                "Grigori Sidorov",
                "Olga Kolesnikova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04189v1",
                "http://arxiv.org/pdf/2311.04189v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04186v1",
            "title": "Resource analysis of quantum algorithms for coarse-grained protein\n  folding models",
            "updated": "2023-11-07T18:27:44Z",
            "published": "2023-11-07T18:27:44Z",
            "summary": "Protein folding processes are a vital aspect of molecular biology that is\nhard to simulate with conventional computers. Quantum algorithms have been\nproven superior for certain problems and may help tackle this complex life\nscience challenge. We analyze the resource requirements for simulating protein\nfolding on a quantum computer, assessing this problem's feasibility in the\ncurrent and near-future technological landscape. We calculate the minimum\nnumber of qubits, interactions, and two-qubit gates necessary to build a\nheuristic quantum algorithm with the specific information of a folding problem.\nParticularly, we focus on the resources needed to build quantum operations\nbased on the Hamiltonian linked to the protein folding models for a given amino\nacid count. Such operations are a fundamental component of these quantum\nalgorithms, guiding the evolution of the quantum state for efficient\ncomputations. Specifically, we study course-grained folding models on the\nlattice and the fixed backbone side-chain conformation model and assess their\ncompatibility with the constraints of existing quantum hardware given different\nbit-encodings. We conclude that the number of qubits required falls within\ncurrent technological capabilities. However, the limiting factor is the high\nnumber of interactions in the Hamiltonian, resulting in a quantum gate count\nunavailable today.",
            "author": [
                "Hanna Linn",
                "Isak Brundin",
                "Laura Garc\u00eda-\u00c1lvarez",
                "G\u00f6ran Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04186v1",
                "http://arxiv.org/pdf/2311.04186v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04934v1",
            "title": "Prompt Cache: Modular Attention Reuse for Low-Latency Inference",
            "updated": "2023-11-07T18:17:05Z",
            "published": "2023-11-07T18:17:05Z",
            "summary": "We present Prompt Cache, an approach for accelerating inference for large\nlanguage models (LLM) by reusing attention states across different LLM prompts.\nMany input prompts have overlapping text segments, such as system messages,\nprompt templates, and documents provided for context. Our key insight is that\nby precomputing and storing the attention states of these frequently occurring\ntext segments on the inference server, we can efficiently reuse them when these\nsegments appear in user prompts. Prompt Cache employs a schema to explicitly\ndefine such reusable text segments, called prompt modules. The schema ensures\npositional accuracy during attention state reuse and provides users with an\ninterface to access cached states in their prompt. Using a prototype\nimplementation, we evaluate Prompt Cache across several LLMs. We show that\nPrompt Cache significantly reduce latency in time-to-first-token, especially\nfor longer prompts such as document-based question answering and\nrecommendations. The improvements range from 8x for GPU-based inference to 60x\nfor CPU-based inference, all while maintaining output accuracy and without the\nneed for model parameter modifications.",
            "author": [
                "In Gim",
                "Guojun Chen",
                "Seung-seob Lee",
                "Nikhil Sarda",
                "Anurag Khandelwal",
                "Lin Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04934v1",
                "http://arxiv.org/pdf/2311.04934v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04180v1",
            "title": "Polyregular functions on unordered trees of bounded height",
            "updated": "2023-11-07T18:10:37Z",
            "published": "2023-11-07T18:10:37Z",
            "summary": "We consider injective first-order interpretations that input and output trees\nof bounded height. The corresponding functions have polynomial output size,\nsince a first-order interpretation can use a k-tuple of input nodes to\nrepresent a single output node. We prove that the equivalence problem for such\nfunctions is decidable, i.e. given two such interpretations, one can decide\nwhether, for every input tree, the two output trees are isomorphic.\n  We also give a calculus of typed functions and combinators which derives\nexactly injective first-order interpretations for unordered trees of bounded\nheight. The calculus is based on a type system, where the type constructors are\nproducts, coproducts and a monad of multisets. Thanks to our results about\ntree-to-tree interpretations, the equivalence problem is decidable for this\ncalculus.\n  As an application, we show that the equivalence problem is decidable for\nfirst-order interpretations between classes of graphs that have bounded\ntree-depth. In all cases studied in this paper, first-order logic and MSO have\nthe same expressive power, and hence all results apply also to MSO\ninterpretations.",
            "author": [
                "Miko\u0142aj Boja\u0144czyk",
                "Bartek Klin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04180v1",
                "http://arxiv.org/pdf/2311.04180v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04177v1",
            "title": "Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for\n  Retrieval Augmented Generation",
            "updated": "2023-11-07T18:03:23Z",
            "published": "2023-11-07T18:03:23Z",
            "summary": "Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g.,\n(Bubeck et al., 2023)) on modern LLMs have shown that they are capable of\nperforming amazing tasks typically necessitating human-level intelligence.\nHowever, unlike humans, frozen LLMs do not improve over time; they neither\nacquire new knowledge nor learn from their successes or failures. Some\napproaches to improving the intelligence of LLMs include fine-tuning models\nbased on problem-solving performance (Zelikman et al., 2022), and building\nbigger and more sophisticated models (Bubeck et al., 2023). However, these\nmethods have the drawback of requiring substantial data and computational\nresources to retrain existing models. In this paper, we explore the use of\nRetrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to\nimprove problem-solving performance. We propose ARM-RAG (Auxiliary Rationale\nMemory for Retrieval Augmented Generation), a system that learns from its\nsuccesses without incurring high training costs. We demonstrate that the\nstorage and subsequent retrieval of reasoning chains have a positive influence\non performance in grade-school math problems.",
            "author": [
                "Eric Melz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04177v1",
                "http://arxiv.org/pdf/2311.04177v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04172v1",
            "title": "Measure transport via polynomial density surrogates",
            "updated": "2023-11-07T17:54:59Z",
            "published": "2023-11-07T17:54:59Z",
            "summary": "We discuss an algorithm to compute transport maps that couple the uniform\nmeasure on $[0,1]^d$ with a specified target distribution $\\pi$ on $[0,1]^d$.\nThe primary objectives are either to sample from or to compute expectations\nw.r.t. $\\pi$. The method is based on leveraging a polynomial surrogate of the\ntarget density, which is obtained by a least-squares or interpolation\napproximation. We discuss the design and construction of suitable sparse\napproximation spaces, and provide a complete error and cost analysis for target\ndensities belonging to certain smoothness classes. Further, we explore the\nrelation between our proposed algorithm and related approaches that aim to find\nsuitable transports via optimization over a class of parametrized transports.\nFinally, we discuss the efficient implementation of our algorithm and report on\nnumerical experiments which confirm our theory.",
            "author": [
                "Josephine Westermann",
                "Jakob Zech"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04172v1",
                "http://arxiv.org/pdf/2311.04172v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.ST",
                "stat.TH",
                "65C10, 62F15, 65C05, 65D40, 41A10, 41A25, 41A63"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04171v1",
            "title": "HADES: Fast Singularity Detection with Local Measure Comparison",
            "updated": "2023-11-07T17:54:04Z",
            "published": "2023-11-07T17:54:04Z",
            "summary": "We introduce Hades, an unsupervised algorithm to detect singularities in\ndata. This algorithm employs a kernel goodness-of-fit test, and as a\nconsequence it is much faster and far more scaleable than the existing\ntopology-based alternatives. Using tools from differential geometry and optimal\ntransport theory, we prove that Hades correctly detects singularities with high\nprobability when the data sample lives on a transverse intersection of\nequidimensional manifolds. In computational experiments, Hades recovers\nsingularities in synthetically generated data, branching points in road network\ndata, intersection rings in molecular conformation space, and anomalies in\nimage data.",
            "author": [
                "Uzu Lim",
                "Harald Oberhauser",
                "Vidit Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04171v1",
                "http://arxiv.org/pdf/2311.04171v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.AT",
                "math.DG",
                "math.ST",
                "stat.TH",
                "55N31, 32S50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04166v1",
            "title": "Perturbed examples reveal invariances shared by language models",
            "updated": "2023-11-07T17:48:35Z",
            "published": "2023-11-07T17:48:35Z",
            "summary": "An explosion of work in language is leading to ever-increasing numbers of\navailable natural language processing models, with little understanding of how\nnew models compare to better-understood models. One major reason for this\ndifficulty is saturating benchmark datasets, which may not reflect well\ndifferences in model performance in the wild. In this work, we propose a novel\nframework for comparing two natural language processing models by revealing\ntheir shared invariance to interpretable input perturbations that are designed\nto target a specific linguistic capability (e.g., Synonym-Invariance,\nTypo-Invariance). Via experiments on models from within the same and across\ndifferent architecture families, this framework offers a number of insights\nabout how changes in models (e.g., distillation, increase in size, amount of\npre-training) affect multiple well-defined linguistic capabilities.\nFurthermore, we also demonstrate how our framework can enable evaluation of the\ninvariances shared between models that are available as commercial black-box\nAPIs (e.g., InstructGPT family) and models that are relatively better\nunderstood (e.g., GPT-2). Across several experiments, we observe that large\nlanguage models share many of the invariances encoded by models of various\nsizes, whereas the invariances encoded by large language models are only shared\nby other large models. Possessing a wide variety of invariances may be a key\nreason for the recent successes of large language models, and our framework can\nshed light on the types of invariances that are retained by or emerge in new\nmodels.",
            "author": [
                "Ruchit Rawal",
                "Mariya Toneva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04166v1",
                "http://arxiv.org/pdf/2311.04166v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04164v1",
            "title": "Models towards Risk Behavior Prediction and Analysis: A Netherlands Case\n  study",
            "updated": "2023-11-07T17:47:20Z",
            "published": "2023-11-07T17:47:20Z",
            "summary": "In many countries financial service providers have to elicit their customers\nrisk preferences, when offering products and services. For instance, in the\nNetherlands pension funds will be legally obliged to factor in their clients\nrisk preferences when devising their investment strategies. Therefore,\nassessing and measuring the risk preferences of individuals is critical for the\nanalysis of individuals' behavior and policy prescriptions. In the psychology\nand economics, a number of methods to elicit risk preferences have been\ndeveloped using hypothetical scenarios and economic experiments. These methods\nof eliciting individual risk preferences are usually applied to small samples\nbecause they are expensive and the implementation can be complex and not\nsuitable when large cohorts need to be measured. A large number of supervised\nlearning models ranging from linear regression to support vector machines are\nused to predict risk preference measures using socio-economic register data\nsuch as age, gender, migration background and other demographic variables in\ncombination with data on income, wealth, pension fund contributions, and other\nfinancial data. The employed machine learning models cover a range of\nassumptions and properties as well as a diverse set of regression metrics. The\noptimum model is selected using the metrics and interpretability of the model.\nThe optimal models are lasso regression and gradient boosting machines with\nmean average percentage error of about 30%. This is important as it helps to\nestimate risk attitudes without actually measuring them. It should be noted\nthat with the current accuracy the tested models are not ready for deployment\nfor applications that require high accuracy. However, the results do indicate\nwhich models should be used in situations that do not require the most accurate\npredictions such as augmentation data for pensions' recommendation.",
            "author": [
                "Onaopepo Adekunle",
                "Arno Riedl",
                "Michel Dumontier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04164v1",
                "http://arxiv.org/pdf/2311.04164v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04163v1",
            "title": "Outliers with Opposing Signals Have an Outsized Effect on Neural Network\n  Optimization",
            "updated": "2023-11-07T17:43:50Z",
            "published": "2023-11-07T17:43:50Z",
            "summary": "We identify a new phenomenon in neural network optimization which arises from\nthe interaction of depth and a particular heavy-tailed structure in natural\ndata. Our result offers intuitive explanations for several previously reported\nobservations about network training dynamics. In particular, it implies a\nconceptually new cause for progressive sharpening and the edge of stability; we\nalso highlight connections to other concepts in optimization and generalization\nincluding grokking, simplicity bias, and Sharpness-Aware Minimization.\n  Experimentally, we demonstrate the significant influence of paired groups of\noutliers in the training data with strong opposing signals: consistent, large\nmagnitude features which dominate the network output throughout training and\nprovide gradients which point in opposite directions. Due to these outliers,\nearly optimization enters a narrow valley which carefully balances the opposing\ngroups; subsequent sharpening causes their loss to rise rapidly, oscillating\nbetween high on one group and then the other, until the overall loss spikes. We\ndescribe how to identify these groups, explore what sets them apart, and\ncarefully study their effect on the network's optimization and behavior. We\ncomplement these experiments with a mechanistic explanation on a toy example of\nopposing signals and a theoretical analysis of a two-layer linear network on a\nsimple model. Our finding enables new qualitative predictions of training\nbehavior which we confirm experimentally. It also provides a new lens through\nwhich to study and improve modern training practices for stochastic\noptimization, which we highlight via a case study of Adam versus SGD.",
            "author": [
                "Elan Rosenfeld",
                "Andrej Risteski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04163v1",
                "http://arxiv.org/pdf/2311.04163v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04162v1",
            "title": "Coarse correlated equilibria in linear quadratic mean field games and\n  application to an emission abatement game",
            "updated": "2023-11-07T17:41:39Z",
            "published": "2023-11-07T17:41:39Z",
            "summary": "Coarse correlated equilibria (CCE) are a good alternative to Nash equilibria\n(NE), as they arise more naturally as outcomes of learning algorithms and they\nmay exhibit higher payoffs than NE. CCEs include a device which allows players'\nstrategies to be correlated without any cooperation, only through information\nsent by a mediator. We develop a methodology to concretely compute mean field\nCCEs in a linear-quadratic mean field game framework. We compare their\nperformance to mean field control solutions and mean field NE (usually named\nMFG solutions). Our approach is implemented in the mean field version of an\nemission abatement game between greenhouse gas emitters. In particular, we\nexhibit a simple and tractable class of mean field CCEs which allows to\noutperform very significantly the mean field NE payoff and abatement levels,\nbridging the gap between the mean field NE and the social optimum obtained by\nmean field control.",
            "author": [
                "Luciano Campi",
                "Federico Cannerozzi",
                "Fanny Cartellier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04162v1",
                "http://arxiv.org/pdf/2311.04162v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "econ.GN",
                "math.PR",
                "q-fin.EC",
                "91A16, 49N80, 49N10, 91B76"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04158v2",
            "title": "Computing Approximate $\\ell_p$ Sensitivities",
            "updated": "2023-11-21T14:55:52Z",
            "published": "2023-11-07T17:34:56Z",
            "summary": "Recent works in dimensionality reduction for regression tasks have introduced\nthe notion of sensitivity, an estimate of the importance of a specific\ndatapoint in a dataset, offering provable guarantees on the quality of the\napproximation after removing low-sensitivity datapoints via subsampling.\nHowever, fast algorithms for approximating $\\ell_p$ sensitivities, which we\nshow is equivalent to approximate $\\ell_p$ regression, are known for only the\n$\\ell_2$ setting, in which they are termed leverage scores.\n  In this work, we provide efficient algorithms for approximating $\\ell_p$\nsensitivities and related summary statistics of a given matrix. In particular,\nfor a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its\n$\\ell_1$ sensitivities at the cost of $O(n/\\alpha)$ sensitivity computations.\nFor estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$\nsensitivities), we provide an algorithm based on importance sampling of\n$\\ell_p$ Lewis weights, which computes a constant factor approximation to the\ntotal sensitivity at the cost of roughly $O(\\sqrt{d})$ sensitivity\ncomputations. Furthermore, we estimate the maximum $\\ell_1$ sensitivity, up to\na $\\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all\nthese results to $\\ell_p$ norms for $p > 1$. Lastly, we experimentally show\nthat for a wide class of matrices in real-world datasets, the total sensitivity\ncan be quickly approximated and is significantly smaller than the theoretical\nprediction, demonstrating that real-world datasets have low intrinsic effective\ndimensionality.",
            "author": [
                "Swati Padmanabhan",
                "David P. Woodruff",
                "Qiuyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04158v2",
                "http://arxiv.org/pdf/2311.04158v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04157v1",
            "title": "A Simple Interpretable Transformer for Fine-Grained Image Classification\n  and Analysis",
            "updated": "2023-11-07T17:32:55Z",
            "published": "2023-11-07T17:32:55Z",
            "summary": "We present a novel usage of Transformers to make image classification\ninterpretable. Unlike mainstream classifiers that wait until the last\nfully-connected layer to incorporate class information to make predictions, we\ninvestigate a proactive approach, asking each class to search for itself in an\nimage. We realize this idea via a Transformer encoder-decoder inspired by\nDEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each\nclass) as input to the decoder, enabling each class to localize its patterns in\nan image via cross-attention. We name our approach INterpretable TRansformer\n(INTR), which is fairly easy to implement and exhibits several compelling\nproperties. We show that INTR intrinsically encourages each class to attend\ndistinctively; the cross-attention weights thus provide a faithful\ninterpretation of the prediction. Interestingly, via ``multi-head''\ncross-attention, INTR could identify different ``attributes'' of a class,\nmaking it particularly suitable for fine-grained classification and analysis,\nwhich we demonstrate on eight datasets. Our code and pre-trained model are\npublicly accessible at https://github.com/Imageomics/INTR.",
            "author": [
                "Dipanjyoti Paul",
                "Arpita Chowdhury",
                "Xinqi Xiong",
                "Feng-Ju Chang",
                "David Carlyn",
                "Samuel Stevens",
                "Kaiya Provost",
                "Anuj Karpatne",
                "Bryan Carstens",
                "Daniel Rubenstein",
                "Charles Stewart",
                "Tanya Berger-Wolf",
                "Yu Su",
                "Wei-Lun Chao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04157v1",
                "http://arxiv.org/pdf/2311.04157v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04155v2",
            "title": "Black-Box Prompt Optimization: Aligning Large Language Models without\n  Model Training",
            "updated": "2023-11-08T04:21:41Z",
            "published": "2023-11-07T17:31:50Z",
            "summary": "Large language models (LLMs) have shown impressive success in various\napplications. However, these models are often not well aligned with human\nintents, which calls for additional treatments on them, that is, the alignment\nproblem. To make LLMs better follow user instructions, existing alignment\nmethods mostly focus on further training them. However, the extra training of\nLLMs are usually expensive in terms of GPU compute; worse still, LLMs of\ninterest are oftentimes not accessible for user-demanded training, such as\nGPTs. In this work, we take a different perspective -- Black-Box Prompt\nOptimization (BPO) -- to perform alignments. The idea is to optimize user\nprompts to suit LLMs' input understanding, so as to best realize users' intents\nwithout updating LLMs' parameters. BPO is model-agnostic and the empirical\nresults demonstrate that the BPO-aligned ChatGPT yields a 22% increase in the\nwin rate against its original version, and 10% for GPT-4. Importantly, the\nBPO-aligned LLMs can outperform the same models aligned by PPO and DPO, and it\nalso brings additional performance gains when combining BPO with PPO or DPO.\nCode and datasets are released at https://github.com/thu-coai/BPO.",
            "author": [
                "Jiale Cheng",
                "Xiao Liu",
                "Kehan Zheng",
                "Pei Ke",
                "Hongning Wang",
                "Yuxiao Dong",
                "Jie Tang",
                "Minlie Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04155v2",
                "http://arxiv.org/pdf/2311.04155v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04154v1",
            "title": "High-fidelity 3D Reconstruction of Plants using Neural Radiance Field",
            "updated": "2023-11-07T17:31:27Z",
            "published": "2023-11-07T17:31:27Z",
            "summary": "Accurate reconstruction of plant phenotypes plays a key role in optimising\nsustainable farming practices in the field of Precision Agriculture (PA).\nCurrently, optical sensor-based approaches dominate the field, but the need for\nhigh-fidelity 3D reconstruction of crops and plants in unstructured\nagricultural environments remains challenging. Recently, a promising\ndevelopment has emerged in the form of Neural Radiance Field (NeRF), a novel\nmethod that utilises neural density fields. This technique has shown impressive\nperformance in various novel vision synthesis tasks, but has remained\nrelatively unexplored in the agricultural context. In our study, we focus on\ntwo fundamental tasks within plant phenotyping: (1) the synthesis of 2D\nnovel-view images and (2) the 3D reconstruction of crop and plant models. We\nexplore the world of neural radiance fields, in particular two SOTA methods:\nInstant-NGP, which excels in generating high-quality images with impressive\ntraining and inference speed, and Instant-NSR, which improves the reconstructed\ngeometry by incorporating the Signed Distance Function (SDF) during training.\nIn particular, we present a novel plant phenotype dataset comprising real plant\nimages from production environments. This dataset is a first-of-its-kind\ninitiative aimed at comprehensively exploring the advantages and limitations of\nNeRF in agricultural contexts. Our experimental results show that NeRF\ndemonstrates commendable performance in the synthesis of novel-view images and\nis able to achieve reconstruction results that are competitive with Reality\nCapture, a leading commercial software for 3D Multi-View Stereo (MVS)-based\nreconstruction. However, our study also highlights certain drawbacks of NeRF,\nincluding relatively slow training speeds, performance limitations in cases of\ninsufficient sampling, and challenges in obtaining geometry quality in complex\nsetups.",
            "author": [
                "Kewei Hu",
                "Ying Wei",
                "Yaoqiang Pan",
                "Hanwen Kang",
                "Chao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04154v1",
                "http://arxiv.org/pdf/2311.04154v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04148v1",
            "title": "Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep\n  Learning Approach",
            "updated": "2023-11-07T17:19:59Z",
            "published": "2023-11-07T17:19:59Z",
            "summary": "Contactless fingerprint recognition offers a higher level of user comfort and\naddresses hygiene concerns more effectively. However, it is also more\nvulnerable to presentation attacks such as photo paper, paper-printout, and\nvarious display attacks, which makes it more challenging to implement in\nbiometric systems compared to contact-based modalities. Limited research has\nbeen conducted on presentation attacks in contactless fingerprint systems, and\nthese studies have encountered challenges in terms of generalization and\nscalability since both bonafide samples and presentation attacks are utilized\nduring training model. Although this approach appears promising, it lacks the\nability to handle unseen attacks, which is a crucial factor for developing PAD\nmethods that can generalize effectively. We introduced an innovative\nanti-spoofing approach that combines an unsupervised autoencoder with a\nconvolutional block attention module to address the limitations of existing\nmethods. Our model is exclusively trained on bonafide images without exposure\nto any spoofed samples during the training phase. It is then evaluated against\nvarious types of presentation attack images in the testing phase. The scheme we\nproposed has achieved an average BPCER of 0.96\\% with an APCER of 1.6\\% for\npresentation attacks involving various types of spoofed samples.",
            "author": [
                "Banafsheh Adami",
                "Nima Karimian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04148v1",
                "http://arxiv.org/pdf/2311.04148v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04145v1",
            "title": "I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion\n  Models",
            "updated": "2023-11-07T17:16:06Z",
            "published": "2023-11-07T17:16:06Z",
            "summary": "Video synthesis has recently made remarkable strides benefiting from the\nrapid development of diffusion models. However, it still encounters challenges\nin terms of semantic accuracy, clarity and spatio-temporal continuity. They\nprimarily arise from the scarcity of well-aligned text-video data and the\ncomplex inherent structure of videos, making it difficult for the model to\nsimultaneously ensure semantic and qualitative excellence. In this report, we\npropose a cascaded I2VGen-XL approach that enhances model performance by\ndecoupling these two factors and ensures the alignment of the input data by\nutilizing static images as a form of crucial guidance. I2VGen-XL consists of\ntwo stages: i) the base stage guarantees coherent semantics and preserves\ncontent from input images by using two hierarchical encoders, and ii) the\nrefinement stage enhances the video's details by incorporating an additional\nbrief text and improves the resolution to 1280$\\times$720. To improve the\ndiversity, we collect around 35 million single-shot text-video pairs and 6\nbillion text-image pairs to optimize the model. By this means, I2VGen-XL can\nsimultaneously enhance the semantic accuracy, continuity of details and clarity\nof generated videos. Through extensive experiments, we have investigated the\nunderlying principles of I2VGen-XL and compared it with current top methods,\nwhich can demonstrate its effectiveness on diverse data. The source code and\nmodels will be publicly available at \\url{https://i2vgen-xl.github.io}.",
            "author": [
                "Shiwei Zhang",
                "Jiayu Wang",
                "Yingya Zhang",
                "Kang Zhao",
                "Hangjie Yuan",
                "Zhiwu Qin",
                "Xiang Wang",
                "Deli Zhao",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04145v1",
                "http://arxiv.org/pdf/2311.04145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04144v1",
            "title": "A new fast numerical method for the generalized Rosen-Zener model",
            "updated": "2023-11-07T17:15:58Z",
            "published": "2023-11-07T17:15:58Z",
            "summary": "In quantum mechanics, the Rosen-Zener model represents a two-level quantum\nsystem. Its generalization to multiple degenerate sets of states leads to\nlarger non-autonomous linear system of ordinary differential equations (ODEs).\nWe propose a new method for computing the solution operator of this system of\nODEs. This new method is based on a recently introduced expression of the\nsolution in terms of an infinite matrix equation, which can be efficiently\napproximated by combining truncation, fixed point iterations, and low-rank\napproximation. This expression is possible thanks to the so-called\n$\\star$-product approach for linear ODEs. In the numerical experiments, the new\nmethod's computing time scales linearly with the model's size. We provide a\nfirst partial explanation of this linear behavior.",
            "author": [
                "Christian Bonhomme",
                "Stefano Pozza",
                "Niel Van Buggenhout"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04144v1",
                "http://arxiv.org/pdf/2311.04144v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04142v1",
            "title": "What is Lost in Knowledge Distillation?",
            "updated": "2023-11-07T17:13:40Z",
            "published": "2023-11-07T17:13:40Z",
            "summary": "Deep neural networks (DNNs) have improved NLP tasks significantly, but\ntraining and maintaining such networks could be costly. Model compression\ntechniques, such as, knowledge distillation (KD), have been proposed to address\nthe issue; however, the compression process could be lossy. Motivated by this,\nour work investigates how a distilled student model differs from its teacher,\nif the distillation process causes any information losses, and if the loss\nfollows a specific pattern. Our experiments aim to shed light on the type of\ntasks might be less or more sensitive to KD by reporting data points on the\ncontribution of different factors, such as the number of layers or attention\nheads. Results such as ours could be utilized when determining effective and\nefficient configurations to achieve optimal information transfers between\nlarger (teacher) and smaller (student) models.",
            "author": [
                "Manas Mohanty",
                "Tanya Roosta",
                "Peyman Passban"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04142v1",
                "http://arxiv.org/pdf/2311.04142v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04141v1",
            "title": "Benchmarking a Neutral-Atom Quantum Computer",
            "updated": "2023-11-07T17:13:31Z",
            "published": "2023-11-07T17:13:31Z",
            "summary": "In this study, we simulated the algorithmic performance of a small neutral\natom quantum computer and compared its performance when operating with\nall-to-all versus nearest-neighbor connectivity. This comparison was made using\na suite of algorithmic benchmarks developed by the Quantum Economic Development\nConsortium. Circuits were simulated with a noise model consistent with\nexperimental data from Nature 604, 457 (2022). We find that all-to-all\nconnectivity improves simulated circuit fidelity by $10\\%-15\\%$, compared to\nnearest-neighbor connectivity.",
            "author": [
                "N. Wagner",
                "C. Poole",
                "T. M. Graham",
                "M. Saffman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04141v1",
                "http://arxiv.org/pdf/2311.04141v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04140v2",
            "title": "A Nearly Linear-Time Distributed Algorithm for Exact Maximum Matching",
            "updated": "2023-11-14T05:03:25Z",
            "published": "2023-11-07T17:12:58Z",
            "summary": "In this paper, we propose a randomized $\\tilde{O}(\\mu(G))$-round algorithm\nfor the maximum cardinality matching problem in the CONGEST model, where\n$\\mu(G)$ means the maximum size of a matching of the input graph $G$. The\nproposed algorithm substantially improves the current best worst-case running\ntime. The key technical ingredient is a new randomized algorithm of finding an\naugmenting path of length $\\ell$ with high probability within $\\tilde{O}(\\ell)$\nrounds, which positively settles an open problem left in the prior work by\nAhmadi and Kuhn [DISC'20].\n  The idea of our augmenting path algorithm is based on a recent result by\nKitamura and Izumi [IEICE Trans.'22], which efficiently identifies a sparse\nsubstructure of the input graph containing an augmenting path, following a new\nconcept called \\emph{alternating base trees}. Their algorithm, however, resorts\nto a centralized approach of collecting the entire information of the\nsubstructure into a single vertex for constructing an augmenting path. The\ntechnical highlight of this paper is to provide a fully-decentralized\ncounterpart of such a centralized method. To develop the algorithm, we prove\nseveral new structural properties of alternating base trees, which are of\nindependent interest.",
            "author": [
                "Taisuke Izumi",
                "Naoki Kitamura",
                "Yutaro Yamaguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04140v2",
                "http://arxiv.org/pdf/2311.04140v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DS",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04139v1",
            "title": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
            "updated": "2023-11-07T17:12:39Z",
            "published": "2023-11-07T17:12:39Z",
            "summary": "This paper provides different approaches for a binary sentiment\nclassification on a small training dataset. LLMs that provided state-of-the-art\nresults in sentiment analysis and similar domains are being used, such as BERT,\nRoBERTa and XLNet.",
            "author": [
                "Guillem Senabre Prades"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04139v1",
                "http://arxiv.org/pdf/2311.04139v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04136v1",
            "title": "On the $\\mathrm{v}$-number of Gorenstein ideals and Frobenius powers",
            "updated": "2023-11-07T17:07:00Z",
            "published": "2023-11-07T17:07:00Z",
            "summary": "In this paper, we show the equality of the (local) $\\mathrm{v}$-number and\nCastelnuovo-Mumford regularity of certain classes of Gorenstein algebras,\nincluding the class of Gorenstein monomial algebras. Also, for the same classes\nof algebras with the assumption of level, we show that the (local)\n$\\mathrm{v}$-number serves as an upper bound for the regularity. Moreover, we\ninvestigate the $\\mathrm{v}$-number of Frobenius powers of graded ideals in\nprime characteristic setup. In this study, we demonstrate that the\n$\\mathrm{v}$-numbers of Frobenius powers of graded ideals have an\nasymptotically linear behaviour. In the case of unmixed monomial ideals, we\nprovide a method for computing the $\\mathrm{v}$-number without prior knowledge\nof the associated primes.",
            "author": [
                "Nirmal Kotal",
                "Kamalesh Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04136v1",
                "http://arxiv.org/pdf/2311.04136v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO",
                "13H10, 13A35, 13F20, 05E40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04135v1",
            "title": "Random Natural Gradient",
            "updated": "2023-11-07T17:04:23Z",
            "published": "2023-11-07T17:04:23Z",
            "summary": "Hybrid quantum-classical algorithms appear to be the most promising approach\nfor near-term quantum applications. An important bottleneck is the classical\noptimization loop, where the multiple local minima and the emergence of barren\nplateaux make these approaches less appealing. To improve the optimization the\nQuantum Natural Gradient (QNG) method [Quantum 4, 269 (2020)] was introduced -\na method that uses information about the local geometry of the quantum\nstate-space. While the QNG-based optimization is promising, in each step it\nrequires more quantum resources, since to compute the QNG one requires $O(m^2)$\nquantum state preparations, where $m$ is the number of parameters in the\nparameterized circuit. In this work we propose two methods that reduce the\nresources/state preparations required for QNG, while keeping the advantages and\nperformance of the QNG-based optimization. Specifically, we first introduce the\nRandom Natural Gradient (RNG) that uses random measurements and the classical\nFisher information matrix (as opposed to the quantum Fisher information used in\nQNG). The essential quantum resources reduce to linear $O(m)$ and thus offer a\nquadratic \"speed-up\", while in our numerical simulations it matches QNG in\nterms of accuracy. We give some theoretical arguments for RNG and then\nbenchmark the method with the QNG on both classical and quantum problems.\nSecondly, inspired by stochastic-coordinate methods, we propose a novel\napproximation to the QNG which we call Stochastic-Coordinate Quantum Natural\nGradient that optimizes only a small (randomly sampled) fraction of the total\nparameters at each iteration. This method also performs equally well in our\nbenchmarks, while it uses fewer resources than the QNG.",
            "author": [
                "Ioannis Kolotouros",
                "Petros Wallden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04135v1",
                "http://arxiv.org/pdf/2311.04135v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04131v1",
            "title": "Locating Cross-Task Sequence Continuation Circuits in Transformers",
            "updated": "2023-11-07T16:58:51Z",
            "published": "2023-11-07T16:58:51Z",
            "summary": "While transformer models exhibit strong capabilities on linguistic tasks,\ntheir complex architectures make them difficult to interpret. Recent work has\naimed to reverse engineer transformer models into human-readable\nrepresentations called circuits that implement algorithmic functions. We extend\nthis research by analyzing and comparing circuits for similar sequence\ncontinuation tasks, which include increasing sequences of digits, number words,\nand months. Through the application of circuit analysis techniques, we identify\nkey sub-circuits responsible for detecting sequence members and for predicting\nthe next member in a sequence. Our analysis reveals that semantically related\nsequences rely on shared circuit subgraphs with analogous roles. Overall,\ndocumenting shared computational structures enables better prediction of model\nbehaviors, identification of errors, and safer editing procedures. This\nmechanistic understanding of transformers is a critical step towards building\nmore robust, aligned, and interpretable language models.",
            "author": [
                "Michael Lan",
                "Fazl Barez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04131v1",
                "http://arxiv.org/pdf/2311.04131v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04130v2",
            "title": "The Baker-Coon-Romans $N$-point amplitude and an exact field theory\n  limit of the Coon amplitude",
            "updated": "2023-12-04T17:37:36Z",
            "published": "2023-11-07T16:55:20Z",
            "summary": "We study the $N$-point Coon amplitude discovered first by Baker and Coon in\nthe 1970s and then again independently by Romans in the 1980s. This\nBaker-Coon-Romans (BCR) amplitude retains several properties of tree-level\nstring amplitudes, namely duality and factorization, with a $q$-deformed\nversion of the string spectrum. Although the formula for the $N$-point BCR\namplitude is only valid for ${q > 1}$, the four-point case admits a\nstraightforward extension to all ${q \\geq 0}$ which reproduces the usual\nexpression for the four-point Coon amplitude. At five points, there are\ninconsistencies with factorization when pushing ${q < 1}$. Despite these\nissues, we find a new relation between the five-point BCR amplitude and Cheung\nand Remmen's four-point basic hypergeometric amplitude, placing the latter\nwithin the broader family of Coon amplitudes. Finally, we compute the $q \\to\n\\infty$ limit of the $N$-point BCR amplitudes and discover an exact\ncorrespondence between these amplitudes and the field theory amplitudes of a\nscalar transforming in the adjoint representation of a global symmetry group\nwith an infinite set of non-derivative single-trace interaction terms. This\ncorrespondence at $q = \\infty$ is the first definitive realization of the Coon\namplitude (in any limit) from a field theory described by an explicit\nLagrangian.",
            "author": [
                "Nicholas Geiser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04130v2",
                "http://arxiv.org/pdf/2311.04130v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04128v1",
            "title": "Generative learning for nonlinear dynamics",
            "updated": "2023-11-07T16:53:56Z",
            "published": "2023-11-07T16:53:56Z",
            "summary": "Modern generative machine learning models demonstrate surprising ability to\ncreate realistic outputs far beyond their training data, such as photorealistic\nartwork, accurate protein structures, or conversational text. These successes\nsuggest that generative models learn to effectively parametrize and sample\narbitrarily complex distributions. Beginning half a century ago, foundational\nworks in nonlinear dynamics used tools from information theory to infer\nproperties of chaotic attractors from time series, motivating the development\nof algorithms for parametrizing chaos in real datasets. In this perspective, we\naim to connect these classical works to emerging themes in large-scale\ngenerative statistical learning. We first consider classical attractor\nreconstruction, which mirrors constraints on latent representations learned by\nstate space models of time series. We next revisit early efforts to use\nsymbolic approximations to compare minimal discrete generators underlying\ncomplex processes, a problem relevant to modern efforts to distill and\ninterpret black-box statistical models. Emerging interdisciplinary works bridge\nnonlinear dynamics and learning theory, such as operator-theoretic methods for\ncomplex fluid flows, or detection of broken detailed balance in biological\ndatasets. We anticipate that future machine learning techniques may revisit\nother classical concepts from nonlinear dynamics, such as transinformation\ndecay and complexity-entropy tradeoffs.",
            "author": [
                "William Gilpin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04128v1",
                "http://arxiv.org/pdf/2311.04128v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "nlin.CD",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16151v1",
            "title": "Estimating Post-Synaptic Effects for Online Training of Feed-Forward\n  SNNs",
            "updated": "2023-11-07T16:53:39Z",
            "published": "2023-11-07T16:53:39Z",
            "summary": "Facilitating online learning in spiking neural networks (SNNs) is a key step\nin developing event-based models that can adapt to changing environments and\nlearn from continuous data streams in real-time. Although forward-mode\ndifferentiation enables online learning, its computational requirements\nrestrict scalability. This is typically addressed through approximations that\nlimit learning in deep models. In this study, we propose Online Training with\nPostsynaptic Estimates (OTPE) for training feed-forward SNNs, which\napproximates Real-Time Recurrent Learning (RTRL) by incorporating temporal\ndynamics not captured by current approximations, such as Online Training\nThrough Time (OTTT) and Online Spatio-Temporal Learning (OSTL). We show\nimproved scaling for multi-layer networks using a novel approximation of\ntemporal effects on the subsequent layer's activity. This approximation incurs\nminimal overhead in the time and space complexity compared to similar\nalgorithms, and the calculation of temporal effects remains local to each\nlayer. We characterize the learning performance of our proposed algorithms on\nmultiple SNN model configurations for rate-based and time-based encoding. OTPE\nexhibits the highest directional alignment to exact gradients, calculated with\nbackpropagation through time (BPTT), in deep networks and, on time-based\nencoding, outperforms other approximate methods. We also observe sizeable gains\nin average performance over similar algorithms in offline training of Spiking\nHeidelberg Digits with equivalent hyper-parameters (OTTT/OSTL - 70.5%; OTPE -\n75.2%; BPTT - 78.1%).",
            "author": [
                "Thomas Summe",
                "Clemens JS Schaefer",
                "Siddharth Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16151v1",
                "http://arxiv.org/pdf/2311.16151v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04127v1",
            "title": "Precision Measurement of Sub-Continuum Gas Conduction within\n  Micro-Confinements",
            "updated": "2023-11-07T16:53:37Z",
            "published": "2023-11-07T16:53:37Z",
            "summary": "Sub-continuum gas conduction is an essentially important phenomenon in\ndisparate fields of applications ranging from aerospace vehicles to biomedical\nsensors, and has been the focus of many computational studies over the past\ndecades. These studies predicted that the energy exchange mechanisms are driven\nby gas-surface interactions, strongly dependent on the gas and surface\ncharacteristics. Despite its fundamental and practical importance, thermal\ntransport via gas conduction at non-continuum regimes mostly remains\nexperimentally unverified. Here, we report precision measurements of\nsub-continuum gas conduction within parallel micro-cavities and elucidate its\ndependence on the gas and surface characteristics. More importantly, we\ndemonstrate a systematic approach for extracting the energy accommodation\ncoefficient (EAC), which is necessary to establish gas-surface scattering\nkernels or develop diffusive-specular solutions to the Boltzmann transport\nequation. EACs are also required for calculating the temperature jump\ncoefficient in near-continuum conditions to solve classical hydrodynamical\nequations. For the first time, we show a correction to the kinetic theory in\nthe transition to near-continuum regimes (particularly for non-monatomic gases)\nby extracting a physical parameter representing the intermolecular collisions\nwithin the Knudsen layer. Our results agree well with the kinetic theory\npredictions and are expected to inform the development of technologies such as\nthermal switches, gas sensors, and light-driven actuators.",
            "author": [
                "Greg I. Acosta",
                "Malachi Hood",
                "Mohammad Ghashami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04127v1",
                "http://arxiv.org/pdf/2311.04127v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.other",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04124v1",
            "title": "Unveiling Safety Vulnerabilities of Large Language Models",
            "updated": "2023-11-07T16:50:33Z",
            "published": "2023-11-07T16:50:33Z",
            "summary": "As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.",
            "author": [
                "George Kour",
                "Marcel Zalmanovici",
                "Naama Zwerdling",
                "Esther Goldbraich",
                "Ora Nova Fandina",
                "Ateret Anaby-Tavor",
                "Orna Raz",
                "Eitan Farchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04124v1",
                "http://arxiv.org/pdf/2311.04124v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04121v1",
            "title": "Observation of the distribution of nuclear magnetization in a molecule",
            "updated": "2023-11-07T16:45:34Z",
            "published": "2023-11-07T16:45:34Z",
            "summary": "Rapid progress in the experimental control and interrogation of molecules,\ncombined with developments in precise calculations of their structure, are\nenabling new opportunities in the investigation of nuclear and particle physics\nphenomena. Molecules containing heavy, octupole-deformed nuclei such as radium\nare of particular interest for such studies, offering an enhanced sensitivity\nto the properties of fundamental particles and interactions. Here, we report\nprecision laser spectroscopy measurements and theoretical calculations of the\nstructure of the radioactive radium monofluoride molecule, $^{225}$Ra$^{19}$F.\nOur results allow fine details of the short-range electron-nucleus interaction\nto be revealed, indicating the high sensitivity of this molecule to the\ndistribution of magnetization, currently a poorly constrained nuclear property,\nwithin the radium nucleus. These results provide a direct and stringent test of\nthe description of the electronic wavefunction inside the nuclear volume,\nhighlighting the suitability of these molecules to investigate subatomic\nphenomena.",
            "author": [
                "S. G. Wilkins",
                "S. M. Udrescu",
                "M. Athanasakis-Kaklamanakis",
                "R. F. Garcia Ruiz",
                "M. Au",
                "I. Belo\u0161evi\u0107",
                "R. Berger",
                "M. L. Bissell",
                "A. A. Breier",
                "A. J. Brinson",
                "K. Chrysalidis",
                "T. E. Cocolios",
                "R. P. de Groote",
                "A. Dorne",
                "K. T. Flanagan",
                "S. Franchoo",
                "K. Gaul",
                "S. Geldhof",
                "T. F. Giesen",
                "D. Hanstorp",
                "R. Heinke",
                "T. Isaev",
                "\u00c1. Koszor\u00fas",
                "S. Kujanp\u00e4\u00e4",
                "L. Lalanne",
                "G. Neyens",
                "M. Nichols",
                "H. A. Perrett",
                "J. R. Reilly",
                "L. V. Skripnikov",
                "S. Rothe",
                "B. van den Borne",
                "Q. Wang",
                "J. Wessolek",
                "X. F. Yang",
                "C. Z\u00fclch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04121v1",
                "http://arxiv.org/pdf/2311.04121v1"
            ],
            "primary_category": "nucl-ex",
            "category": [
                "nucl-ex",
                "physics.atom-ph",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04119v1",
            "title": "Computability in Dynamical Systems",
            "updated": "2023-11-07T16:43:42Z",
            "published": "2023-11-07T16:43:42Z",
            "summary": "In this paper we present an introduction to the area of computability in\ndynamical systems. This is a fairly new field which has received quite some\nattention in recent years. One of the central questions in this area is if\nrelevant dynamical objects can be algorithmically presented by a Turing\nmachine. After providing an overview of the relevant objects we discuss recent\nresults concerning the computability of the entropy for symbolic systems and\nthe computability of Julia sets as well as their Brolin-Lyubich measures.",
            "author": [
                "Michael Burr",
                "Christian Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04119v1",
                "http://arxiv.org/pdf/2311.04119v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "37A35, 37B12, 37F10, 03D15, 03D80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04263v1",
            "title": "Perceptual Quality Improvement in Videoconferencing using\n  Keyframes-based GAN",
            "updated": "2023-11-07T16:38:23Z",
            "published": "2023-11-07T16:38:23Z",
            "summary": "In the latest years, videoconferencing has taken a fundamental role in\ninterpersonal relations, both for personal and business purposes. Lossy video\ncompression algorithms are the enabling technology for videoconferencing, as\nthey reduce the bandwidth required for real-time video streaming. However,\nlossy video compression decreases the perceived visual quality. Thus, many\ntechniques for reducing compression artifacts and improving video visual\nquality have been proposed in recent years. In this work, we propose a novel\nGAN-based method for compression artifacts reduction in videoconferencing.\nGiven that, in this context, the speaker is typically in front of the camera\nand remains the same for the entire duration of the transmission, we can\nmaintain a set of reference keyframes of the person from the higher-quality\nI-frames that are transmitted within the video stream and exploit them to guide\nthe visual quality improvement; a novel aspect of this approach is the update\npolicy that maintains and updates a compact and effective set of reference\nkeyframes. First, we extract multi-scale features from the compressed and\nreference frames. Then, our architecture combines these features in a\nprogressive manner according to facial landmarks. This allows the restoration\nof the high-frequency details lost after the video compression. Experiments\nshow that the proposed approach improves visual quality and generates\nphoto-realistic results even with high compression rates. Code and pre-trained\nnetworks are publicly available at\nhttps://github.com/LorenzoAgnolucci/Keyframes-GAN.",
            "author": [
                "Lorenzo Agnolucci",
                "Leonardo Galteri",
                "Marco Bertini",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04263v1",
                "http://arxiv.org/pdf/2311.04263v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04108v1",
            "title": "The Early Microbenchmark Catches the Bug -- Studying Performance Issues\n  Using Micro- and Application Benchmarks",
            "updated": "2023-11-07T16:30:38Z",
            "published": "2023-11-07T16:30:38Z",
            "summary": "An application's performance regressions can be detected by both application\nor microbenchmarks. While application benchmarks stress the system under test\nby sending synthetic but realistic requests which, e.g., simulate real user\ntraffic, microbenchmarks evaluate the performance on a subroutine level by\ncalling the function under test repeatedly.\n  In this paper, we use a testbed microservice application which includes three\nperformance issues to study the detection capabilities of both approaches. In\nextensive benchmarking experiments, we increase the severity of each\nperformance issue stepwise, run both an application benchmark and the\nmicrobenchmark suite, and check at which point each benchmark detects the\nperformance issue. Our results show that microbenchmarks detect all three\nissues earlier, some even at the lowest severity level. Application benchmarks,\nhowever, raised false positive alarms, wrongly detected performance\nimprovements, and detected the performance issues later.",
            "author": [
                "Nils Japke",
                "Christoph Witzko",
                "Martin Grambow",
                "David Bermbach"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3603166.3632128",
                "http://arxiv.org/abs/2311.04108v1",
                "http://arxiv.org/pdf/2311.04108v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04107v1",
            "title": "Interactive Semantic Map Representation for Skill-based Visual Object\n  Navigation",
            "updated": "2023-11-07T16:30:12Z",
            "published": "2023-11-07T16:30:12Z",
            "summary": "Visual object navigation using learning methods is one of the key tasks in\nmobile robotics. This paper introduces a new representation of a scene semantic\nmap formed during the embodied agent interaction with the indoor environment.\nIt is based on a neural network method that adjusts the weights of the\nsegmentation model with backpropagation of the predicted fusion loss values\nduring inference on a regular (backward) or delayed (forward) image sequence.\nWe have implemented this representation into a full-fledged navigation approach\ncalled SkillTron, which can select robot skills from end-to-end policies based\non reinforcement learning and classic map-based planning methods. The proposed\napproach makes it possible to form both intermediate goals for robot\nexploration and the final goal for object navigation. We conducted intensive\nexperiments with the proposed approach in the Habitat environment, which showed\na significant superiority in navigation quality metrics compared to\nstate-of-the-art approaches. The developed code and used custom datasets are\npublicly available at github.com/AIRI-Institute/skill-fusion.",
            "author": [
                "Tatiana Zemskova",
                "Aleksei Staroverov",
                "Kirill Muravyev",
                "Dmitry Yudin",
                "Aleksandr Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04107v1",
                "http://arxiv.org/pdf/2311.04107v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04106v1",
            "title": "SPIRAL: An Efficient Algorithm for the Integration of the Equation of\n  Rotational Motion",
            "updated": "2023-11-07T16:29:27Z",
            "published": "2023-11-07T16:29:27Z",
            "summary": "We introduce Spiral, a third-order integration algorithm for the rotational\nmotion of extended bodies. It requires only one force calculation per time\nstep, does not require quaternion normalization at each time step, and can be\nformulated for both leapfrog and synchronous integration schemes, making it\ncompatible with many particle simulation codes. The stability and precision of\nSpiral exceed those of state-of-the-art algorithms currently used in popular\nDEM codes such as Yade, MercuryDPM, LIGGGHTS, PFC, and more, at only slightly\nhigher computational cost. Also, beyond DEM, we see potential applications in\nall numerical simulations that involve the 3D rotation of extended bodies.",
            "author": [
                "Carlos Andr\u00e9s del Valle",
                "Vasileios Angelidakis",
                "Sudeshna Roy",
                "Jos\u00e9 Daniel Mu\u00f1oz",
                "Thorsten P\u00f6schel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04106v1",
                "http://arxiv.org/pdf/2311.04106v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04262v1",
            "title": "ETDPC: A Multimodality Framework for Classifying Pages in Electronic\n  Theses and Dissertations",
            "updated": "2023-11-07T16:27:37Z",
            "published": "2023-11-07T16:27:37Z",
            "summary": "Electronic theses and dissertations (ETDs) have been proposed, advocated, and\ngenerated for more than 25 years. Although ETDs are hosted by commercial or\ninstitutional digital library repositories, they are still an understudied type\nof scholarly big data, partially because they are usually longer than\nconference proceedings and journals. Segmenting ETDs will allow researchers to\nstudy sectional content. Readers can navigate to particular pages of interest,\ndiscover, and explore the content buried in these long documents. Most existing\nframeworks on document page classification are designed for classifying general\ndocuments and perform poorly on ETDs. In this paper, we propose ETDPC. Its\nbackbone is a two-stream multimodal model with a cross-attention network to\nclassify ETD pages into 13 categories. To overcome the challenge of imbalanced\nlabeled samples, we augmented data for minority categories and employed a\nhierarchical classifier. ETDPC outperforms the state-of-the-art models in all\ncategories, achieving an F1 of 0.84 -- 0.96 for 9 out of 13 categories. We also\ndemonstrated its data efficiency. The code and data can be found on GitHub\n(https://github.com/lamps-lab/ETDMiner/tree/master/etd_segmentation).",
            "author": [
                "Muntabir Hasan Choudhury",
                "Lamia Salsabil",
                "William A. Ingram",
                "Edward A. Fox",
                "Jian Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04262v1",
                "http://arxiv.org/pdf/2311.04262v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04933v1",
            "title": "Evaluating Large Language Models in Ophthalmology",
            "updated": "2023-11-07T16:19:45Z",
            "published": "2023-11-07T16:19:45Z",
            "summary": "Purpose: The performance of three different large language models (LLMS)\n(GPT-3.5, GPT-4, and PaLM2) in answering ophthalmology professional questions\nwas evaluated and compared with that of three different professional\npopulations (medical undergraduates, medical masters, and attending\nphysicians). Methods: A 100-item ophthalmology single-choice test was\nadministered to three different LLMs (GPT-3.5, GPT-4, and PaLM2) and three\ndifferent professional levels (medical undergraduates, medical masters, and\nattending physicians), respectively. The performance of LLM was comprehensively\nevaluated and compared with the human group in terms of average score,\nstability, and confidence. Results: Each LLM outperformed undergraduates in\ngeneral, with GPT-3.5 and PaLM2 being slightly below the master's level, while\nGPT-4 showed a level comparable to that of attending physicians. In addition,\nGPT-4 showed significantly higher answer stability and confidence than GPT-3.5\nand PaLM2. Conclusion: Our study shows that LLM represented by GPT-4 performs\nbetter in the field of ophthalmology. With further improvements, LLM will bring\nunexpected benefits in medical education and clinical decision making in the\nnear future.",
            "author": [
                "Jason Holmes",
                "Shuyuan Ye",
                "Yiwei Li",
                "Shi-Nan Wu",
                "Zhengliang Liu",
                "Zihao Wu",
                "Jinyu Hu",
                "Huan Zhao",
                "Xi Jiang",
                "Wei Liu",
                "Hong Wei",
                "Jie Zou",
                "Tianming Liu",
                "Yi Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04933v1",
                "http://arxiv.org/pdf/2311.04933v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04101v1",
            "title": "Quantum correction to a new Wilson line-based action for Gluodynamics",
            "updated": "2023-11-07T16:18:45Z",
            "published": "2023-11-07T16:18:45Z",
            "summary": "We discuss a new classical action that enables efficient computation of the\ngluonic tree amplitudes but does not contain any triple point vertices. This\nnew formulation is obtained via a canonical transformation of the light-cone\nYang-Mills action, with the field transformations based on Wilson line\nfunctionals. In addition to MHV vertices, the action contains also\n$\\mathrm{N}^k\\mathrm{MHV}$ vertices, where $1 \\leq k \\leq (n - 4)$, and $n$ is\nthe number of external legs. We computed tree-level amplitudes up to 8 gluons\nand found agreement with standard results. The classical action is however not\nsufficient to obtain rational parts of amplitudes, in particular the finite\namplitudes with all same helicity gluons. In order to systematically develop\nquantum corrections to this new action, we derive the one-loop effective\naction, in such a way there are no quantum contributions missing at one loop.",
            "author": [
                "Hiren Kakkad",
                "Piotr Kotko",
                "Anna Stasto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04101v1",
                "http://arxiv.org/pdf/2311.04101v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04100v1",
            "title": "Graph-controlled Permutation Mixers in QAOA for the Flexible Job-Shop\n  Problem",
            "updated": "2023-11-07T16:16:52Z",
            "published": "2023-11-07T16:16:52Z",
            "summary": "One of the most promising attempts towards solving optimization problems with\nquantum computers in the noisy intermediate scale era of quantum computing are\nvariational quantum algorithms. The Quantum Alternating Operator Ansatz\nprovides an algorithmic framework for constrained, combinatorial optimization\nproblems. As opposed to the better known standard QAOA protocol, the\nconstraints of the optimization problem are built into the mixing layers of the\nansatz circuit, thereby limiting the search to the much smaller Hilbert space\nof feasible solutions. In this work we develop mixing operators for a wide\nrange of scheduling problems including the flexible job shop problem. These\nmixing operators are based on a special control scheme defined by a constraint\ngraph model. After describing an explicit construction of those mixing\noperators, they are proven to be feasibility preserving, as well as exploring\nthe feasible subspace.",
            "author": [
                "Lilly Palackal",
                "Leonhard Richter",
                "Maximilian Hess"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04100v1",
                "http://arxiv.org/pdf/2311.04100v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04098v1",
            "title": "DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing\n  Understanding",
            "updated": "2023-11-07T16:14:38Z",
            "published": "2023-11-07T16:14:38Z",
            "summary": "Recent advances in computer vision (CV) and natural language processing have\nbeen driven by exploiting big data on practical applications. However, these\nresearch fields are still limited by the sheer volume, versatility, and\ndiversity of the available datasets. CV tasks, such as image captioning, which\nhas primarily been carried out on natural images, still struggle to produce\naccurate and meaningful captions on sketched images often included in\nscientific and technical documents. The advancement of other tasks such as 3D\nreconstruction from 2D images requires larger datasets with multiple\nviewpoints. We introduce DeepPatent2, a large-scale dataset, providing more\nthan 2.7 million technical drawings with 132,890 object names and 22,394\nviewpoints extracted from 14 years of US design patent documents. We\ndemonstrate the usefulness of DeepPatent2 with conceptual captioning. We\nfurther provide the potential usefulness of our dataset to facilitate other\nresearch areas such as 3D image reconstruction and image retrieval.",
            "author": [
                "Kehinde Ajayi",
                "Xin Wei",
                "Martin Gryder",
                "Winston Shields",
                "Jian Wu",
                "Shawn M. Jones",
                "Michal Kucer",
                "Diane Oyen"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41597-023-02653-7",
                "http://arxiv.org/abs/2311.04098v1",
                "http://arxiv.org/pdf/2311.04098v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04097v1",
            "title": "Exact fluctuation and long-range correlations in a single-file model\n  under resetting",
            "updated": "2023-11-07T16:07:08Z",
            "published": "2023-11-07T16:07:08Z",
            "summary": "Resetting is a renewal mechanism in which a process is intermittently\nrepeated after a random or fixed time. This simple act of stop and repeat\nprofoundly influences the behaviour of a system as exemplified by the emergence\nof non-equilibrium properties and expedition of search processes. Herein, we\nexplore the ramifications of stochastic resetting in the context of a\nsingle-file system called random average process (RAP) in one dimension. In\nparticular, we focus on the dynamics of tracer particles and analytically\ncompute the variance, equal time correlation, autocorrelation and unequal time\ncorrelation between the positions of different tracer particles. Our study\nunveils that resetting gives rise to rather different behaviours depending on\nwhether the particles move symmetrically or asymmetrically. For the asymmetric\ncase, the system for instance exhibits a long-range correlation which is not\nseen in absence of the resetting. Similarly, in contrast to the reset-free RAP,\nthe variance shows distinct scalings for symmetric and asymmetric cases. While\nfor the symmetric case, it decays (towards its steady value) as $\\sim e^{-r t}\n/ \\sqrt{t}$, we find $\\sim t e^{-r t}$ decay for the asymmetric case ($r$ being\nthe resetting rate). Finally, we examine the autocorrelation and unequal time\ncorrelation in the steady state and demonstrate that they obey interesting\nscaling forms at late times. All our analytical results are substantiated by\nextensive numerical simulations.",
            "author": [
                "Saikat Santra",
                "Prashant Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04097v1",
                "http://arxiv.org/pdf/2311.04097v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04095v1",
            "title": "Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset",
            "updated": "2023-11-07T16:05:27Z",
            "published": "2023-11-07T16:05:27Z",
            "summary": "We present PD-REAL, a novel large-scale dataset for unsupervised anomaly\ndetection (AD) in the 3D domain. It is motivated by the fact that 2D-only\nrepresentations in the AD task may fail to capture the geometric structures of\nanomalies due to uncertainty in lighting conditions or shooting angles. PD-REAL\nconsists entirely of Play-Doh models for 15 object categories and focuses on\nthe analysis of potential benefits from 3D information in a controlled\nenvironment. Specifically, objects are first created with six types of\nanomalies, such as dent, crack, or perforation, and then photographed under\ndifferent lighting conditions to mimic real-world inspection scenarios. To\ndemonstrate the usefulness of 3D information, we use a commercially available\nRealSense camera to capture RGB and depth images. Compared to the existing 3D\ndataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper,\neasily scalable and easier to control variables. Extensive evaluations with\nstate-of-the-art AD algorithms on our dataset demonstrate the benefits as well\nas challenges of using 3D information. Our dataset can be downloaded from\nhttps://github.com/Andy-cs008/PD-REAL",
            "author": [
                "Jianjian Qin",
                "Chunzhi Gu",
                "Jun Yu",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04095v1",
                "http://arxiv.org/pdf/2311.04095v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04091v1",
            "title": "Proceedings of the 5th International Workshop on Reading Music Systems",
            "updated": "2023-11-07T16:00:42Z",
            "published": "2023-11-07T16:00:42Z",
            "summary": "The International Workshop on Reading Music Systems (WoRMS) is a workshop\nthat tries to connect researchers who develop systems for reading music, such\nas in the field of Optical Music Recognition, with other researchers and\npractitioners that could benefit from such systems, like librarians or\nmusicologists. The relevant topics of interest for the workshop include, but\nare not limited to: Music reading systems; Optical music recognition; Datasets\nand performance evaluation; Image processing on music scores; Writer\nidentification; Authoring, editing, storing and presentation systems for music\nscores; Multi-modal systems; Novel input-methods for music to produce written\nmusic; Web-based Music Information Retrieval services; Applications and\nprojects; Use-cases related to written music.\n  These are the proceedings of the 5th International Workshop on Reading Music\nSystems, held in Milan, Italy on Nov. 4th 2023.",
            "author": [
                "Jorge Calvo-Zaragoza",
                "Alexander Pacha",
                "Elona Shatri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04091v1",
                "http://arxiv.org/pdf/2311.04091v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04261v1",
            "title": "Restoration of Analog Videos Using Swin-UNet",
            "updated": "2023-11-07T16:00:31Z",
            "published": "2023-11-07T16:00:31Z",
            "summary": "In this paper, we present a system to restore analog videos of historical\narchives. These videos often contain severe visual degradation due to the\ndeterioration of their tape supports that require costly and slow manual\ninterventions to recover the original content. The proposed system uses a\nmulti-frame approach and is able to deal with severe tape mistracking, which\nresults in completely scrambled frames. Tests on real-world videos from a major\nhistorical video archive show the effectiveness of our demo system. The code\nand the pre-trained model are publicly available at\nhttps://github.com/miccunifi/analog-video-restoration.",
            "author": [
                "Lorenzo Agnolucci",
                "Leonardo Galteri",
                "Marco Bertini",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04261v1",
                "http://arxiv.org/pdf/2311.04261v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04088v1",
            "title": "Personality Style Recognition via Machine Learning: Identifying\n  Anaclitic and Introjective Personality Styles from Patients' Speech",
            "updated": "2023-11-07T15:56:19Z",
            "published": "2023-11-07T15:56:19Z",
            "summary": "In disentangling the heterogeneity observed in psychopathology, personality\nof the patients is considered crucial. While it has been demonstrated that\npersonality traits are reflected in the language used by a patient, we\nhypothesize that this enables automatic inference of the personality type\ndirectly from speech utterances, potentially more accurately than through a\ntraditional questionnaire-based approach explicitly designed for personality\nclassification. To validate this hypothesis, we adopt natural language\nprocessing (NLP) and standard machine learning tools for classification. We\ntest this on a dataset of recorded clinical diagnostic interviews (CDI) on a\nsample of 79 patients diagnosed with major depressive disorder (MDD) -- a\ncondition for which differentiated treatment based on personality styles has\nbeen advocated -- and classified into anaclitic and introjective personality\nstyles. We start by analyzing the interviews to see which linguistic features\nare associated with each style, in order to gain a better understanding of the\nstyles. Then, we develop automatic classifiers based on (a) standardized\nquestionnaire responses; (b) basic text features, i.e., TF-IDF scores of words\nand word sequences; (c) more advanced text features, using LIWC (linguistic\ninquiry and word count) and context-aware features using BERT (bidirectional\nencoder representations from transformers); (d) audio features. We find that\nautomated classification with language-derived features (i.e., based on LIWC)\nsignificantly outperforms questionnaire-based classification models.\nFurthermore, the best performance is achieved by combining LIWC with the\nquestionnaire features. This suggests that more work should be put into\ndeveloping linguistically based automated techniques for characterizing\npersonality, however questionnaires still to some extent complement such\nmethods.",
            "author": [
                "Semere Kiros Bitew",
                "Vincent Schelstraete",
                "Klim Zaporojets",
                "Kimberly Van Nieuwenhove",
                "Reitske Meganck",
                "Chris Develder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04088v1",
                "http://arxiv.org/pdf/2311.04088v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04085v1",
            "title": "A Categorical Model for Retrosynthetic Reaction Analysis",
            "updated": "2023-11-07T15:51:56Z",
            "published": "2023-11-07T15:51:56Z",
            "summary": "We introduce a mathematical framework for retrosynthetic analysis, an\nimportant research method in synthetic chemistry. Our approach represents\nmolecules and their interaction using string diagrams in layered props - a\nrecently introduced categorical model for partial explanations in scientific\nreasoning. Such principled approach allows one to model features currently not\navailable in automated retrosynthesis tools, such as chirality, reaction\nenvironment and protection-deprotection steps.",
            "author": [
                "Ella Gale",
                "Leo Lobski",
                "Fabio Zanasi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04085v1",
                "http://arxiv.org/pdf/2311.04085v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "math.CT",
                "18M30",
                "F.4.1; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04083v1",
            "title": "Formulating and Heuristic Solving of Contact Problems in Hybrid\n  Data-Driven Computational Mechanics",
            "updated": "2023-11-07T15:48:31Z",
            "published": "2023-11-07T15:48:31Z",
            "summary": "In this work we consider the hybrid Data-Driven Computational Mechanics\n(DDCM) approach, in which a smooth constitutive manifold is reconstructed to\nobtain a well-behaved nonlinear optimization problem (NLP) rather than the much\nharder discrete-continous NLP (DCNLP) of the direct DDCM approach. The key\nfocus is on the addition of geometric inequality constraints to the hybrid DDCM\nformulation. Therein, the required constraint force leads to a contact problem\nin the form of a mathematical program with complementarity constraints (MPCC),\na problem class that is still less complex than the DCNLP. For this MPCC we\npropose a heuristic quick-shot solution approach, which can produce verifiable\nsolutions by solving up to four NLPs. We perform various numerical experiments\non three different contact problems of increasing difficulty to demonstrate the\npotential and limitations of this approach.",
            "author": [
                "Cristian Guillermo Gebhardt",
                "Senta Lange",
                "Marc Christian Steinbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04083v1",
                "http://arxiv.org/pdf/2311.04083v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "74B20, 74M15, 90C30, 90C33, 90C59"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04081v1",
            "title": "Learning Super-Resolution Ultrasound Localization Microscopy from\n  Radio-Frequency Data",
            "updated": "2023-11-07T15:47:38Z",
            "published": "2023-11-07T15:47:38Z",
            "summary": "Ultrasound Localization Microscopy (ULM) enables imaging of vascular\nstructures in the micrometer range by accumulating contrast agent particle\nlocations over time. Precise and efficient target localization accuracy remains\nan active research topic in the ULM field to further push the boundaries of\nthis promising medical imaging technology. Existing work incorporates\nDelay-And-Sum (DAS) beamforming into particle localization pipelines, which\nultimately determines the ULM image resolution capability. In this paper we\npropose to feed unprocessed Radio-Frequency (RF) data into a super-resolution\nnetwork while bypassing DAS beamforming and its limitations. To facilitate\nthis, we demonstrate label projection and inverse point transformation between\nB-mode and RF coordinate space as required by our approach. We assess our\nmethod against state-of-the-art techniques based on a public dataset featuring\nin silico and in vivo data. Results from our RF-trained network suggest that\nexcluding DAS beamforming offers a great potential to optimize on the ULM\nresolution performance.",
            "author": [
                "Christopher Hahne",
                "Georges Chabouh",
                "Olivier Couture",
                "Raphael Sznitman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04081v1",
                "http://arxiv.org/pdf/2311.04081v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04079v1",
            "title": "Augmenting Lane Perception and Topology Understanding with Standard\n  Definition Navigation Maps",
            "updated": "2023-11-07T15:42:22Z",
            "published": "2023-11-07T15:42:22Z",
            "summary": "Autonomous driving has traditionally relied heavily on costly and\nlabor-intensive High Definition (HD) maps, hindering scalability. In contrast,\nStandard Definition (SD) maps are more affordable and have worldwide coverage,\noffering a scalable alternative. In this work, we systematically explore the\neffect of SD maps for real-time lane-topology understanding. We propose a novel\nframework to integrate SD maps into online map prediction and propose a\nTransformer-based encoder, SD Map Encoder Representations from transFormers, to\nleverage priors in SD maps for the lane-topology prediction task. This\nenhancement consistently and significantly boosts (by up to 60%) lane detection\nand topology prediction on current state-of-the-art online map prediction\nmethods without bells and whistles and can be immediately incorporated into any\nTransformer-based lane-topology method. Code is available at\nhttps://github.com/NVlabs/SMERF.",
            "author": [
                "Katie Z Luo",
                "Xinshuo Weng",
                "Yan Wang",
                "Shuang Wu",
                "Jie Li",
                "Kilian Q Weinberger",
                "Yue Wang",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04079v1",
                "http://arxiv.org/pdf/2311.04079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04078v1",
            "title": "A Lightweight and Secure PUF-Based Authentication and Key-exchange\n  Protocol for IoT Devices",
            "updated": "2023-11-07T15:42:14Z",
            "published": "2023-11-07T15:42:14Z",
            "summary": "The Internet of Things (IoT) has improved people's lives by seamlessly\nintegrating into many facets of modern life and facilitating information\nsharing across platforms. Device Authentication and Key exchange are major\nchallenges for the IoT. High computational resource requirements for\ncryptographic primitives and message transmission during Authentication make\nthe existing methods like PKI and IBE not suitable for these resource\nconstrained devices. PUF appears to offer a practical and economical security\nmechanism in place of typically sophisticated cryptosystems like PKI and IBE.\nPUF provides an unclonable and tamper sensitive unique signature based on the\nPUF chip by using manufacturing process variability. Therefore, in this study,\nwe use lightweight bitwise XOR, hash function, and PUF to Authenticate IoT\ndevices. Despite several studies employing the PUF to authenticate\ncommunication between IoT devices, to the authors' knowledge, existing\nsolutions require intermediary gateway and internet capabilities by the IoT\ndevice to directly interact with a Server for Authentication and hence, are not\nscalable when the IoT device works on different technologies like BLE, Zigbee,\netc. To address the aforementioned issue, we present a system in which the IoT\ndevice does not require a continuous active internet connection to communicate\nwith the server in order to Authenticate itself. The results of a thorough\nsecurity study are validated against adversarial attacks and PUF modeling\nattacks. For formal security validation, the AVISPA verification tool is also\nused. Performance study recommends this protocol's lightweight characteristics.\nThe proposed protocol's acceptability and defenses against adversarial assaults\nare supported by a prototype developed with ESP32.",
            "author": [
                "Chandranshu Gupta",
                "Gaurav Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04078v1",
                "http://arxiv.org/pdf/2311.04078v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04077v1",
            "title": "Deep Neural Network based Optimal Control of Greenhouses",
            "updated": "2023-11-07T15:40:44Z",
            "published": "2023-11-07T15:40:44Z",
            "summary": "Automatic control of greenhouse crop production is of great interest owing to\nthe increasing energy and labor costs. Hierarchical Model Predictive Control\n(HMPC) is a multi-level control strategy for regulating environmental\nconditions in a greenhouse through energy-efficient operation and resource\nutilization. We suggest in this work to use two-level HMPC, where the upper\nlevel generates suitable reference trajectories based on day-ahead predictions.\nThese references are tracked down in the lower level using Nonlinear Model\nPredictive Control (NMPC). In order to apply HMPC, a model of the crop dynamics\nis essential. However, the complex nature of the underlying model including\ndiscontinuities and nonlinearities results in intractable computational\ncomplexity and long sampling times. In this paper, we propose to use NMPC as a\ndata generator to learn the tracking control policy using deep neural networks.\nThen, the references are tracked using the trained Deep Neural Network (DNN) to\nreduce the computational burden. The efficiency of our approach under real-time\ndisturbances is demonstrated by means of a simulation study.",
            "author": [
                "Kiran Kumar Sathyanarayanan",
                "Philipp Sauerteig",
                "Stefan Streif"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04077v1",
                "http://arxiv.org/pdf/2311.04077v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04076v2",
            "title": "Do LLMs exhibit human-like response biases? A case study in survey\n  design",
            "updated": "2023-11-29T22:00:12Z",
            "published": "2023-11-07T15:40:43Z",
            "summary": "As large language models (LLMs) become more capable, there is growing\nexcitement about the possibility of using LLMs as proxies for humans in\nreal-world tasks where subjective labels are desired, such as in surveys and\nopinion polling. One widely-cited barrier to the adoption of LLMs is their\nsensitivity to prompt wording - but interestingly, humans also display\nsensitivities to instruction changes in the form of response biases. As such,\nwe argue that if LLMs are going to be used to approximate human opinions, it is\nnecessary to investigate the extent to which LLMs also reflect human response\nbiases, if at all. In this work, we use survey design as a case study, where\nhuman response biases caused by permutations in wordings of \"prompts\" have been\nextensively studied. Drawing from prior work in social psychology, we design a\ndataset and propose a framework to evaluate whether LLMs exhibit human-like\nresponse biases in survey questionnaires. Our comprehensive evaluation of nine\nmodels shows that popular open and commercial LLMs generally fail to reflect\nhuman-like behavior. These inconsistencies tend to be more prominent in models\nthat have been instruction fine-tuned. Furthermore, even if a model shows a\nsignificant change in the same direction as humans, we find that perturbations\nthat are not meant to elicit significant changes in humans may also result in a\nsimilar change. These results highlight the potential pitfalls of using LLMs to\nsubstitute humans in parts of the annotation pipeline, and further underscore\nthe importance of finer-grained characterizations of model behavior. Our code,\ndataset, and collected samples are available at\nhttps://github.com/lindiatjuatja/BiasMonkey",
            "author": [
                "Lindia Tjuatja",
                "Valerie Chen",
                "Sherry Tongshuang Wu",
                "Ameet Talwalkar",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04076v2",
                "http://arxiv.org/pdf/2311.04076v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04075v1",
            "title": "General relativistic dynamical tides in binary inspirals, without modes",
            "updated": "2023-11-07T15:40:36Z",
            "published": "2023-11-07T15:40:36Z",
            "summary": "A neutron star in an inspiraling binary system is tidally deformed by its\ncompanion, and the effect leaves a measurable imprint on the emitted\ngravitational waves. While the tidal interaction falls within the regime of\nstatic tides during the early stages of inspiral, a regime of dynamical tides\ntakes over in the later stages. The description of dynamical tides found in the\nliterature makes integral use of a spectral representation of the tidal\ndeformation, in which it is expressed as a sum over the star's normal modes of\nvibration. This description is deeply rooted in Newtonian fluid mechanics and\ngravitation, and we point out that considerable obstacles manifest themselves\nin an extension to general relativity. To remedy this we propose an\nalternative, mode-less description of dynamical tides that can be formulated in\nboth Newtonian and relativistic mechanics. Our description is based on a\ntime-derivative expansion of the tidal dynamics. The tidal deformation is\ncharacterized by two sets of Love numbers: the static Love numbers $k_\\ell$ and\nthe dynamic Love numbers $\\ddot{k}_\\ell$. These are computed here for\npolytropic stellar models in both Newtonian gravity and general relativity. The\ntime-derivative expansion of the tidal dynamics seems to preclude any attempt\nto capture an approach to resonance, which occurs when the frequency of the\ntidal field becomes equal to a normal-mode frequency. To overcome this\nlimitation we propose a pragmatic extension of the time-derivative expansion\nwhich does capture an approach to resonance. We demonstrate that with this\nextension, our formulation of dynamical tides should be just as accurate as the\n$f$-mode truncation of the mode representation, in which the sum over modes is\ntruncated to a single term involving the star's fundamental mode of vibration.",
            "author": [
                "Tristan Pitre",
                "Eric Poisson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04075v1",
                "http://arxiv.org/pdf/2311.04075v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04260v1",
            "title": "Fully Automated Task Management for Generation, Execution, and\n  Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language\n  Instructions in Continuous Space",
            "updated": "2023-11-07T15:38:09Z",
            "published": "2023-11-07T15:38:09Z",
            "summary": "This paper aims to develop a framework that enables a robot to execute tasks\nbased on visual information, in response to natural language instructions for\nFetch-and-Carry with Object Grounding (FCOG) tasks. Although there have been\nmany frameworks, they usually rely on manually given instruction sentences.\nTherefore, evaluations have only been conducted with fixed tasks. Furthermore,\nmany multimodal language understanding models for the benchmarks only consider\ndiscrete actions. To address the limitations, we propose a framework for the\nfull automation of the generation, execution, and evaluation of FCOG tasks. In\naddition, we introduce an approach to solving the FCOG tasks by dividing them\ninto four distinct subtasks.",
            "author": [
                "Motonari Kambara",
                "Komei Sugiura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04260v1",
                "http://arxiv.org/pdf/2311.04260v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04072v1",
            "title": "Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment",
            "updated": "2023-11-07T15:36:40Z",
            "published": "2023-11-07T15:36:40Z",
            "summary": "Alignment with human preference is a desired property of large language\nmodels (LLMs). Currently, the main alignment approach is based on reinforcement\nlearning from human feedback (RLHF). Despite the effectiveness of RLHF, it is\nintricate to implement and train, thus recent studies explore how to develop\nalternative alignment approaches based on supervised fine-tuning (SFT). A major\nlimitation of SFT is that it essentially does imitation learning, which cannot\nfully understand what are the expected behaviors. To address this issue, we\npropose an improved alignment approach named FIGA. Different from prior\nmethods, we incorporate fine-grained (i.e., token or phrase level) quality\nsignals that are derived by contrasting good and bad responses. Our approach\nhas made two major contributions. Firstly, we curate a refined alignment\ndataset that pairs initial responses and the corresponding revised ones.\nSecondly, we devise a new loss function can leverage fine-grained quality\nsignals to instruct the learning of LLMs for alignment. Extensive experiments\nhave demonstrated the effectiveness of our approaches by comparing a number of\ncompetitive baselines.",
            "author": [
                "Geyang Guo",
                "Ranchi Zhao",
                "Tianyi Tang",
                "Wayne Xin Zhao",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04072v1",
                "http://arxiv.org/pdf/2311.04072v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04071v2",
            "title": "Energy-Calibrated VAE with Test Time Free Lunch",
            "updated": "2023-11-21T09:58:34Z",
            "published": "2023-11-07T15:35:56Z",
            "summary": "In this paper, we propose a novel generative model that utilizes a\nconditional Energy-Based Model (EBM) for enhancing Variational Autoencoder\n(VAE), termed Energy-Calibrated VAE (EC-VAE). Specifically, VAEs often suffer\nfrom blurry generated samples due to the lack of a tailored training on the\nsamples generated in the generative direction. On the other hand, EBMs can\ngenerate high-quality samples but require expensive Markov Chain Monte Carlo\n(MCMC) sampling. To address these issues, we introduce a conditional EBM for\ncalibrating the generative direction of VAE during training, without requiring\nit for the generation at test time. In particular, we train EC-VAE upon both\nthe input data and the calibrated samples with adaptive weight to enhance\nefficacy while avoiding MCMC sampling at test time. Furthermore, we extend the\ncalibration idea of EC-VAE to variational learning and normalizing flows, and\napply EC-VAE to an additional application of zero-shot image restoration via\nneural transport prior and range-null theory. We evaluate the proposed method\nwith two applications, including image generation and zero-shot image\nrestoration, and the experimental results show that our method achieves the\nstate-of-the-art performance over single-step non-adversarial generation.",
            "author": [
                "Yihong Luo",
                "Siya Qiu",
                "Xingjian Tao",
                "Yujun Cai",
                "Jing Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04071v2",
                "http://arxiv.org/pdf/2311.04071v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04069v1",
            "title": "LISBET: a self-supervised Transformer model for the automatic\n  segmentation of social behavior motifs",
            "updated": "2023-11-07T15:35:17Z",
            "published": "2023-11-07T15:35:17Z",
            "summary": "Social behavior, defined as the process by which individuals act and react in\nresponse to others, is crucial for the function of societies and holds profound\nimplications for mental health. To fully grasp the intricacies of social\nbehavior and identify potential therapeutic targets for addressing social\ndeficits, it is essential to understand its core principles. Although machine\nlearning algorithms have made it easier to study specific aspects of complex\nbehavior, current methodologies tend to focus primarily on single-animal\nbehavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral\nTransformer), a model designed to detect and segment social interactions. Our\nmodel eliminates the need for feature selection and extensive human annotation\nby using self-supervised learning to detect and quantify social behaviors from\ndynamic body parts tracking data. LISBET can be used in hypothesis-driven mode\nto automate behavior classification using supervised finetuning, and in\ndiscovery-driven mode to segment social behavior motifs using unsupervised\nlearning. We found that motifs recognized using the discovery-driven approach\nnot only closely match the human annotations but also correlate with the\nelectrophysiological activity of dopaminergic neurons in the Ventral Tegmental\nArea (VTA). We hope LISBET will help the community improve our understanding of\nsocial behaviors and their neural underpinnings.",
            "author": [
                "Giuseppe Chindemi",
                "Benoit Girard",
                "Camilla Bellone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04069v1",
                "http://arxiv.org/pdf/2311.04069v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04067v1",
            "title": "Multitask Multimodal Prompted Training for Interactive Embodied Task\n  Completion",
            "updated": "2023-11-07T15:27:52Z",
            "published": "2023-11-07T15:27:52Z",
            "summary": "Interactive and embodied tasks pose at least two fundamental challenges to\nexisting Vision & Language (VL) models, including 1) grounding language in\ntrajectories of actions and observations, and 2) referential disambiguation. To\ntackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a\nunified encoder-decoder model that reasons over images and trajectories, and\ncasts action prediction as multimodal text generation. By unifying all tasks as\ntext generation, EMMA learns a language of actions which facilitates transfer\nacross tasks. Different to previous modular approaches with independently\ntrained components, we use a single multitask model where each task contributes\nto goal completion. EMMA performs on par with similar models on several VL\nbenchmarks and sets a new state-of-the-art performance (36.81% success rate) on\nthe Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided\nagents in the Alexa Arena",
            "author": [
                "Georgios Pantazopoulos",
                "Malvina Nikandrou",
                "Amit Parekh",
                "Bhathiya Hemanthage",
                "Arash Eshghi",
                "Ioannis Konstas",
                "Verena Rieser",
                "Oliver Lemon",
                "Alessandro Suglia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04067v1",
                "http://arxiv.org/pdf/2311.04067v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04066v1",
            "title": "Can CLIP Help Sound Source Localization?",
            "updated": "2023-11-07T15:26:57Z",
            "published": "2023-11-07T15:26:57Z",
            "summary": "Large-scale pre-trained image-text models demonstrate remarkable versatility\nacross diverse tasks, benefiting from their robust representational\ncapabilities and effective multimodal alignment. We extend the application of\nthese models, specifically CLIP, to the domain of sound source localization.\nUnlike conventional approaches, we employ the pre-trained CLIP model without\nexplicit text input, relying solely on the audio-visual correspondence. To this\nend, we introduce a framework that translates audio signals into tokens\ncompatible with CLIP's text encoder, yielding audio-driven embeddings. By\ndirectly using these embeddings, our method generates audio-grounded masks for\nthe provided audio, extracts audio-grounded image features from the highlighted\nregions, and aligns them with the audio-driven embeddings using the\naudio-visual correspondence objective. Our findings suggest that utilizing\npre-trained image-text models enable our model to generate more complete and\ncompact localization maps for the sounding objects. Extensive experiments show\nthat our method outperforms state-of-the-art approaches by a significant\nmargin.",
            "author": [
                "Sooyoung Park",
                "Arda Senocak",
                "Joon Son Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04066v1",
                "http://arxiv.org/pdf/2311.04066v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04065v1",
            "title": "A Study of the One-Dimensional Heat-Conduction Equation with Radiation",
            "updated": "2023-11-07T15:26:23Z",
            "published": "2023-11-07T15:26:23Z",
            "summary": "We consider a boundary value problem (BVP) modelling one-dimensional\nheat-conduction with radiation, which is derived from the Stefan-Boltzmann law.\nThe problem strongly depends on the parameters, making difficult to estimate\nthe solution. We use an analytical approach to determine upper and lower bounds\nto the exact solution of the BVP, which allows estimating the latter. Finally,\nwe support our theoretical arguments with numerical data, by implementing them\ninto the MAPLE computer program.",
            "author": [
                "Mihai Halic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04065v1",
                "http://arxiv.org/pdf/2311.04065v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.CA",
                "34B15, 34L30, 34B60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04064v2",
            "title": "KPI Extraction from Maintenance Work Orders -- A Comparison of Expert\n  Labeling, Text Classification and AI-Assisted Tagging for Computing Failure\n  Rates of Wind Turbines",
            "updated": "2023-12-06T17:17:00Z",
            "published": "2023-11-07T15:25:52Z",
            "summary": "Maintenance work orders are commonly used to document information about wind\nturbine operation and maintenance. This includes details about proactive and\nreactive wind turbine downtimes, such as preventative and corrective\nmaintenance. However, the information contained in maintenance work orders is\noften unstructured and difficult to analyze, presenting challenges for\ndecision-makers wishing to use it for optimizing operation and maintenance. To\naddress this issue, this work compares three different approaches to calculate\nreliability by performance indicators from maintenance work orders. The first\napproach involves manual labeling of the maintenance work orders by domain\nexperts, using the schema defined in an industrial guideline to assign the\nlabel accordingly. The second approach involves the development of a model that\nautomatically labels the maintenance work orders using text classification\nmethods. Through this method, we are able to achieve macro average and weighted\naverage F1-Scores of 0.75 and 0.85 respectively. The third technique uses an\nAI-assisted tagging tool to tag and structure the raw maintenance information,\ntogether with a novel rule-based approach for extracting relevant maintenance\nwork orders for failure rate calculation. In our experiments the AI-assisted\ntool leads to a 88% drop in tagging time in comparison to the other two\napproaches, while expert labeling and text classification are more accurate in\nKPI extraction. Overall, our findings make extracting maintenance information\nfrom maintenance work orders more efficient, enable the assessment of\nreliability key performance indicators and therefore support the optimization\nof wind turbine operation and maintenance.",
            "author": [
                "Marc-Alexander Lutz",
                "Bastian Sch\u00e4fermeier",
                "Rachael Sexton",
                "Michael Sharp",
                "Alden Dima",
                "Stefan Faulstich",
                "Jagan Mohini Aluri"
            ],
            "link": [
                "http://dx.doi.org/10.3390/en16247937",
                "http://arxiv.org/abs/2311.04064v2",
                "http://arxiv.org/pdf/2311.04064v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7; I.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04062v2",
            "title": "$b\\to c\u03c4\\bar\u03bd$ anomaly from a minimal composite $S_1$ leptoquark",
            "updated": "2023-11-23T13:35:57Z",
            "published": "2023-11-07T15:21:13Z",
            "summary": "Several experiments have measured a deviation in $B\\to D^{(*)}$ semileptonic\ndecays, that point to new physics at the TeV scale violating lepton flavor\nuniversality. A scalar leptoquark $S_1$ is known to be able to solve this\nanomaly modifying $b\\to c\\tau\\bar\\nu$. In the context of composite Higgs\nmodels, we consider a theory containing $H$ and $S_1$ as Nambu-Goldstone bosons\n(NGBs) of a new strongly interacting sector, with ordinary resonances at a\nscale ${\\cal O}(10)$ TeV. Assuming anarchic partial compositeness of the\nStandard Model (SM) fermions we calculate the potential of the NGBs that is\ndominated by the fermions of the third generation, we compute $R_{D^{(*)}}$ and\nestimate the corrections to flavor observables by the presence of $S_1$. We\nfind that the SM spectrum and $m_{S_1}\\sim$ TeV can be obtained with a NGB\ndecay constant of order $\\sim 5$ TeV, simultaneously reproducing the deviation\nin $R_{D^{(*)}}$. We find that the bounds on the flavor observables\n$B_{K^{(*)}\\nu\\nu}$, $g_\\tau^W$, BR$(\\tau\\to\\mu\\gamma)$ and $\\Delta m_{B_s}$\nare saturated, with the first two requiring a coupling between resonances\n$g_*\\lesssim 2$, whereas the third one demands $m_{S_1}\\gtrsim 1.7$ TeV, up to\ncorrections of ${\\cal O}(1)$.",
            "author": [
                "Leandro Da Rold"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04062v2",
                "http://arxiv.org/pdf/2311.04062v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04059v1",
            "title": "Over-the-Air Computation Empowered Federated Learning: A Joint\n  Uplink-Downlink Design",
            "updated": "2023-11-07T15:14:35Z",
            "published": "2023-11-07T15:14:35Z",
            "summary": "In this paper, we investigate the communication designs of over-the-air\ncomputation (AirComp) empowered federated learning (FL) systems considering\nuplink model aggregation and downlink model dissemination jointly. We first\nderive an upper bound on the expected difference between the training loss and\nthe optimal loss, which reveals that optimizing the FL performance is\nequivalent to minimizing the distortion in the received global gradient vector\nat each edge node. As such, we jointly optimize each edge node transmit and\nreceive equalization coefficients along with the edge server forwarding matrix\nto minimize the maximum gradient distortion across all edge nodes. We further\nutilize the MNIST dataset to evaluate the performance of the considered FL\nsystem in the context of the handwritten digit recognition task. Experiment\nresults show that deploying multiple antennas at the edge server significantly\nreduces the distortion in the received global gradient vector, leading to a\nnotable improvement in recognition accuracy compared to the single antenna\ncase.",
            "author": [
                "Deyou Zhang",
                "Ming Xiao",
                "Mikael Skoglund"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04059v1",
                "http://arxiv.org/pdf/2311.04059v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04058v1",
            "title": "mmFUSION: Multimodal Fusion for 3D Objects Detection",
            "updated": "2023-11-07T15:11:27Z",
            "published": "2023-11-07T15:11:27Z",
            "summary": "Multi-sensor fusion is essential for accurate 3D object detection in\nself-driving systems. Camera and LiDAR are the most commonly used sensors, and\nusually, their fusion happens at the early or late stages of 3D detectors with\nthe help of regions of interest (RoIs). On the other hand, fusion at the\nintermediate level is more adaptive because it does not need RoIs from\nmodalities but is complex as the features of both modalities are presented from\ndifferent points of view. In this paper, we propose a new intermediate-level\nmulti-modal fusion (mmFUSION) approach to overcome these challenges. First, the\nmmFUSION uses separate encoders for each modality to compute features at a\ndesired lower space volume. Second, these features are fused through\ncross-modality and multi-modality attention mechanisms proposed in mmFUSION.\nThe mmFUSION framework preserves multi-modal information and learns to\ncomplement modalities' deficiencies through attention weights. The strong\nmulti-modal features from the mmFUSION framework are fed to a simple 3D\ndetection head for 3D predictions. We evaluate mmFUSION on the KITTI and\nNuScenes dataset where it performs better than available early, intermediate,\nlate, and even two-stage based fusion schemes. The code with the mmdetection3D\nproject plugin will be publicly available soon.",
            "author": [
                "Javed Ahmad",
                "Alessio Del Bue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04058v1",
                "http://arxiv.org/pdf/2311.04058v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04052v1",
            "title": "Generative Structural Design Integrating BIM and Diffusion Model",
            "updated": "2023-11-07T15:05:19Z",
            "published": "2023-11-07T15:05:19Z",
            "summary": "Intelligent structural design using AI can effectively reduce time overhead\nand increase efficiency. It has potential to become the new design paradigm in\nthe future to assist and even replace engineers, and so it has become a\nresearch hotspot in the academic community. However, current methods have some\nlimitations to be addressed, whether in terms of application scope, visual\nquality of generated results, or evaluation metrics of results. This study\nproposes a comprehensive solution. Firstly, we introduce building information\nmodeling (BIM) into intelligent structural design and establishes a structural\ndesign pipeline integrating BIM and generative AI, which is a powerful\nsupplement to the previous frameworks that only considered CAD drawings. In\norder to improve the perceptual quality and details of generations, this study\nmakes 3 contributions. Firstly, in terms of generation framework, inspired by\nthe process of human drawing, a novel 2-stage generation framework is proposed\nto replace the traditional end-to-end framework to reduce the generation\ndifficulty for AI models. Secondly, in terms of generative AI tools adopted,\ndiffusion models (DMs) are introduced to replace widely used generative\nadversarial network (GAN)-based models, and a novel physics-based conditional\ndiffusion model (PCDM) is proposed to consider different design prerequisites.\nThirdly, in terms of neural networks, an attention block (AB) consisting of a\nself-attention block (SAB) and a parallel cross-attention block (PCAB) is\ndesigned to facilitate cross-domain data fusion. The quantitative and\nqualitative results demonstrate the powerful generation and representation\ncapabilities of PCDM. Necessary ablation studies are conducted to examine the\nvalidity of the methods. This study also shows that DMs have the potential to\nreplace GANs and become the new benchmark for generative problems in civil\nengineering.",
            "author": [
                "Zhili He",
                "Yu-Hsing Wang",
                "Jian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04052v1",
                "http://arxiv.org/pdf/2311.04052v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04049v1",
            "title": "3D EAGAN: 3D edge-aware attention generative adversarial network for\n  prostate segmentation in transrectal ultrasound images",
            "updated": "2023-11-07T15:03:17Z",
            "published": "2023-11-07T15:03:17Z",
            "summary": "Automatic prostate segmentation in TRUS images has always been a challenging\nproblem, since prostates in TRUS images have ambiguous boundaries and\ninhomogeneous intensity distribution. Although many prostate segmentation\nmethods have been proposed, they still need to be improved due to the lack of\nsensibility to edge information. Consequently, the objective of this study is\nto devise a highly effective prostate segmentation method that overcomes these\nlimitations and achieves accurate segmentation of prostates in TRUS images. A\n3D edge-aware attention generative adversarial network (3D EAGAN)-based\nprostate segmentation method is proposed in this paper, which consists of an\nedge-aware segmentation network (EASNet) that performs the prostate\nsegmentation and a discriminator network that distinguishes predicted prostates\nfrom real prostates. The proposed EASNet is composed of an\nencoder-decoder-based U-Net backbone network, a detail compensation module,\nfour 3D spatial and channel attention modules, an edge enhance module, and a\nglobal feature extractor. The detail compensation module is proposed to\ncompensate for the loss of detailed information caused by the down-sampling\nprocess of the encoder. The features of the detail compensation module are\nselectively enhanced by the 3D spatial and channel attention module.\nFurthermore, an edge enhance module is proposed to guide shallow layers in the\nEASNet to focus on contour and edge information in prostates. Finally, features\nfrom shallow layers and hierarchical features from the decoder module are fused\nthrough the global feature extractor to predict the segmentation prostates.",
            "author": [
                "Mengqing Liu",
                "Xiao Shao",
                "Liping Jiang",
                "Kaizhi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04049v1",
                "http://arxiv.org/pdf/2311.04049v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04046v1",
            "title": "Reinforcement Learning Fine-tuning of Language Models is Biased Towards\n  More Extractable Features",
            "updated": "2023-11-07T15:00:39Z",
            "published": "2023-11-07T15:00:39Z",
            "summary": "Many capable large language models (LLMs) are developed via self-supervised\npre-training followed by a reinforcement-learning fine-tuning phase, often\nbased on human or AI feedback. During this stage, models may be guided by their\ninductive biases to rely on simpler features which may be easier to extract, at\na cost to robustness and generalisation. We investigate whether principles\ngoverning inductive biases in the supervised fine-tuning of LLMs also apply\nwhen the fine-tuning process uses reinforcement learning. Following Lovering et\nal (2021), we test two hypotheses: that features more $\\textit{extractable}$\nafter pre-training are more likely to be utilised by the final policy, and that\nthe evidence for/against a feature predicts whether it will be utilised.\nThrough controlled experiments on synthetic and natural language tasks, we find\nstatistically significant correlations which constitute strong evidence for\nthese hypotheses.",
            "author": [
                "Diogo Cruz",
                "Edoardo Pona",
                "Alex Holness-Tofts",
                "Elias Schmied",
                "V\u00edctor Abia Alonso",
                "Charlie Griffin",
                "Bogdan-Ionut Cirstea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04046v1",
                "http://arxiv.org/pdf/2311.04046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04044v1",
            "title": "P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models",
            "updated": "2023-11-07T14:55:52Z",
            "published": "2023-11-07T14:55:52Z",
            "summary": "The rapid development of language models (LMs) brings unprecedented\naccessibility and usage for both models and users. On the one hand, powerful\nLMs, trained with massive textual data, achieve state-of-the-art performance\nover numerous downstream NLP tasks. On the other hand, more and more attention\nis paid to unrestricted model accesses that may bring malicious privacy risks\nof data leakage. To address these issues, many recent works propose\nprivacy-preserving language models (PPLMs) with differential privacy (DP).\nUnfortunately, different DP implementations make it challenging for a fair\ncomparison among existing PPLMs. In this paper, we present P-Bench, a\nmulti-perspective privacy evaluation benchmark to empirically and intuitively\nquantify the privacy leakage of LMs. Instead of only protecting and measuring\nthe privacy of protected data with DP parameters, P-Bench sheds light on the\nneglected inference data privacy during actual usage. P-Bench first clearly\ndefines multi-faceted privacy objectives during private fine-tuning. Then,\nP-Bench constructs a unified pipeline to perform private fine-tuning. Lastly,\nP-Bench performs existing privacy attacks on LMs with pre-defined privacy\nobjectives as the empirical evaluation results. The empirical attack results\nare used to fairly and intuitively evaluate the privacy leakage of various\nPPLMs. We conduct extensive experiments on three datasets of GLUE for\nmainstream LMs.",
            "author": [
                "Haoran Li",
                "Dadi Guo",
                "Donghao Li",
                "Wei Fan",
                "Qi Hu",
                "Xin Liu",
                "Chunkit Chan",
                "Duanyi Yao",
                "Yangqiu Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04044v1",
                "http://arxiv.org/pdf/2311.04044v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04042v1",
            "title": "Analyzing Near-Infrared Hyperspectral Imaging for Protein Content\n  Regression and Grain Variety Classification Using Bulk References and Varying\n  Grain-to-Background Ratios",
            "updated": "2023-11-07T14:54:46Z",
            "published": "2023-11-07T14:54:46Z",
            "summary": "Based on previous work, we assess the use of NIR-HSI images for calibrating\nmodels on two datasets, focusing on protein content regression and grain\nvariety classification. Limited reference data for protein content is expanded\nby subsampling and associating it with the bulk sample. However, this method\nintroduces significant biases due to skewed leptokurtic prediction\ndistributions, affecting both PLS-R and deep CNN models. We propose adjustments\nto mitigate these biases, improving mean protein reference predictions.\nAdditionally, we investigate the impact of grain-to-background ratios on both\ntasks. Higher ratios yield more accurate predictions, but including lower-ratio\nimages in calibration enhances model robustness for such scenarios.",
            "author": [
                "Ole-Christian Galbo Engstr\u00f8m",
                "Erik Schou Dreier",
                "Birthe M\u00f8ller Jespersen",
                "Kim Steenstrup Pedersen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04042v1",
                "http://arxiv.org/pdf/2311.04042v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.5.1; I.5.2; I.5.4; I.4.9; G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04040v1",
            "title": "Data exploitation: multi-task learning of object detection and semantic\n  segmentation on partially annotated data",
            "updated": "2023-11-07T14:49:54Z",
            "published": "2023-11-07T14:49:54Z",
            "summary": "Multi-task partially annotated data where each data point is annotated for\nonly a single task are potentially helpful for data scarcity if a network can\nleverage the inter-task relationship. In this paper, we study the joint\nlearning of object detection and semantic segmentation, the two most popular\nvision problems, from multi-task data with partial annotations. Extensive\nexperiments are performed to evaluate each task performance and explore their\ncomplementarity when a multi-task network cannot optimize both tasks\nsimultaneously. We propose employing knowledge distillation to leverage\njoint-task optimization. The experimental results show favorable results for\nmulti-task learning and knowledge distillation over single-task learning and\neven full supervision scenario. All code and data splits are available at\nhttps://github.com/lhoangan/multas",
            "author": [
                "Ho\u00e0ng-\u00c2n L\u00ea",
                "Minh-Tan Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04040v1",
                "http://arxiv.org/pdf/2311.04040v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04039v1",
            "title": "Free Integral Calculus",
            "updated": "2023-11-07T14:45:52Z",
            "published": "2023-11-07T14:45:52Z",
            "summary": "We study the problem of conditional expectations in free random variables and\nprovide closed formulas for the conditional expectation of resolvents of\narbitrary non-commutative polynomials in free random variables onto the\nsubalgebra of an arbitray subset of the variables. More precisely, given a\nlinearization of the resolvent we compute a linearization of its conditional\nexpectation. The coefficients of the expressions obtained in this process\ninvolve certain Boolean cumulant functionals which can be computed by solving a\nsystem of equations. On the way towards the main result we introduce a\nnon-commutative differential calculus which allows to evaluate conditional\nexpectations and the said Boolean cumulant functionals. We conclude the paper\nwith several examples which illustrate the working of the developed machinery\nand two appendices. The first appendix contains a purely algebraic approach to\nBoolean cumulants and the second appendix provides a crash course on\nlinearizations of rational series.",
            "author": [
                "Franz Lehner",
                "Kamil Szpojankowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04039v1",
                "http://arxiv.org/pdf/2311.04039v1"
            ],
            "primary_category": "math.OA",
            "category": [
                "math.OA",
                "math.PR",
                "Primary: 46L54. Secondary: 15B52"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04035v1",
            "title": "Discordance Minimization-based Imputation Algorithms for Missing Values\n  in Rating Data",
            "updated": "2023-11-07T14:42:06Z",
            "published": "2023-11-07T14:42:06Z",
            "summary": "Ratings are frequently used to evaluate and compare subjects in various\napplications, from education to healthcare, because ratings provide succinct\nyet credible measures for comparing subjects. However, when multiple rating\nlists are combined or considered together, subjects often have missing ratings,\nbecause most rating lists do not rate every subject in the combined list. In\nthis study, we propose analyses on missing value patterns using six real-world\ndata sets in various applications, as well as the conditions for applicability\nof imputation algorithms. Based on the special structures and properties\nderived from the analyses, we propose optimization models and algorithms that\nminimize the total rating discordance across rating providers to impute missing\nratings in the combined rating lists, using only the known rating information.\nThe total rating discordance is defined as the sum of the pairwise discordance\nmetric, which can be written as a quadratic function. Computational experiments\nbased on real-world and synthetic rating data sets show that the proposed\nmethods outperform the state-of-the-art general imputation methods in the\nliterature in terms of imputation accuracy.",
            "author": [
                "Young Woong Park",
                "Jinhak Kim",
                "Dan Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s10994-023-06452-4",
                "http://arxiv.org/abs/2311.04035v1",
                "http://arxiv.org/pdf/2311.04035v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04259v1",
            "title": "Ookami: An A64FX Computing Resource",
            "updated": "2023-11-07T14:36:03Z",
            "published": "2023-11-07T14:36:03Z",
            "summary": "We present a look at Ookami, a project providing community access to a\ntestbed supercomputer with the ARM-based A64FX processors developed by a\ncollaboration between RIKEN and Fujitsu and deployed in the Japanese\nsupercomputer Fugaku. We describe the project, provide details about the user\nbase and education/training program, and present highlights from performance\nstudies of two astrophysical simulation codes.",
            "author": [
                "A. C. Calder",
                "E. Siegmann",
                "C. Feldman",
                "S. Chheda",
                "D. C. Smolarski",
                "F. D. Swesty",
                "A. Curtis",
                "J. Dey",
                "D. Carlson",
                "B. Michalowicz",
                "R. J. Harrison"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04259v1",
                "http://arxiv.org/pdf/2311.04259v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.HE",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04031v1",
            "title": "Ramsey Quantifiers in Linear Arithmetics",
            "updated": "2023-11-07T14:33:29Z",
            "published": "2023-11-07T14:33:29Z",
            "summary": "We study Satisfiability Modulo Theories (SMT) enriched with the so-called\nRamsey quantifiers, which assert the existence of cliques (complete graphs) in\nthe graph induced by some formulas. The extended framework is known to have\napplications in proving program termination (in particular, whether a\ntransitive binary predicate is well-founded), and monadic decomposability of\nSMT formulas. Our main result is a new algorithm for eliminating Ramsey\nquantifiers from three common SMT theories: Linear Integer Arithmetic (LIA),\nLinear Real Arithmetic (LRA), and Linear Integer Real Arithmetic (LIRA). In\nparticular, if we work only with existentially quantified formulas, then our\nalgorithm runs in polynomial time and produces a formula of linear size. One\nimmediate consequence is that checking well-foundedness of a given formula in\nthe aforementioned theory defining a transitive predicate can be\nstraightforwardly handled by highly optimized SMT-solvers. We show also how\nthis provides a uniform semi-algorithm for verifying termination and liveness\nwith completeness guarantee (in fact, with an optimal computational complexity)\nfor several well-known classes of infinite-state systems, which include\nsuccinct timed systems, one-counter systems, and monotonic counter systems.\nAnother immediate consequence is a solution to an open problem on checking\nmonadic decomposability of a given relation in quantifier-free fragments of LRA\nand LIRA, which is an important problem in automated reasoning and constraint\ndatabases. Our result immediately implies decidability of this problem with an\noptimal complexity (coNP-complete) and enables exploitation of SMT-solvers. It\nalso provides a termination guarantee for the generic monadic decomposition\nalgorithm of Veanes et al. for LIA, LRA, and LIRA. We report encouraging\nexperimental results on a prototype implementation of our algorithms on\nmicro-benchmarks.",
            "author": [
                "Pascal Bergstr\u00e4\u00dfer",
                "Moses Ganardi",
                "Anthony W. Lin",
                "Georg Zetzsche"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04031v1",
                "http://arxiv.org/pdf/2311.04031v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04030v1",
            "title": "A Biologically-Inspired Computational Model of Time Perception",
            "updated": "2023-11-07T14:32:51Z",
            "published": "2023-11-07T14:32:51Z",
            "summary": "Time perception - how humans and animals perceive the passage of time - forms\nthe basis for important cognitive skills such as decision-making, planning, and\ncommunication. In this work, we propose a framework for examining the\nmechanisms responsible for time perception. We first model neural time\nperception as a combination of two known timing sources: internal neuronal\nmechanisms and external (environmental) stimuli, and design a decision-making\nframework to replicate them. We then implement this framework in a simulated\nrobot. We measure the agent's success on a temporal discrimination task\noriginally conducted by mice to evaluate its capacity to exploit temporal\nknowledge. We conclude that the agent is able to perceive time similarly to\nanimals when it comes to their intrinsic mechanisms of interpreting time and\nperforming time-aware actions. Next, by analysing the behaviour of agents\nequipped with the framework, we propose an estimator to infer characteristics\nof the timing mechanisms intrinsic to the agents. In particular, we show that\nfrom their empirical action probability distribution we are able to estimate\nparameters used for perceiving time. Overall, our work shows promising results\nwhen it comes to drawing conclusions regarding some of the characteristics\npresent in biological timing mechanisms.",
            "author": [
                "In\u00eas Louren\u00e7o",
                "Robert Mattila",
                "Rodrigo Ventura",
                "Bo Wahlberg"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TCDS.2021.3120301",
                "http://arxiv.org/abs/2311.04030v1",
                "http://arxiv.org/pdf/2311.04030v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04257v2",
            "title": "mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with\n  Modality Collaboration",
            "updated": "2023-11-09T01:56:51Z",
            "published": "2023-11-07T14:21:29Z",
            "summary": "Multi-modal Large Language Models (MLLMs) have demonstrated impressive\ninstruction abilities across various open-ended tasks. However, previous\nmethods primarily focus on enhancing multi-modal capabilities. In this work, we\nintroduce a versatile multi-modal large language model, mPLUG-Owl2, which\neffectively leverages modality collaboration to improve performance in both\ntext and multi-modal tasks. mPLUG-Owl2 utilizes a modularized network design,\nwith the language decoder acting as a universal interface for managing\ndifferent modalities. Specifically, mPLUG-Owl2 incorporates shared functional\nmodules to facilitate modality collaboration and introduces a modality-adaptive\nmodule that preserves modality-specific features. Extensive experiments reveal\nthat mPLUG-Owl2 is capable of generalizing both text tasks and multi-modal\ntasks and achieving state-of-the-art performances with a single generic model.\nNotably, mPLUG-Owl2 is the first MLLM model that demonstrates the modality\ncollaboration phenomenon in both pure-text and multi-modal scenarios, setting a\npioneering path in the development of future multi-modal foundation models.",
            "author": [
                "Qinghao Ye",
                "Haiyang Xu",
                "Jiabo Ye",
                "Ming Yan",
                "Anwen Hu",
                "Haowei Liu",
                "Qi Qian",
                "Ji Zhang",
                "Fei Huang",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04257v2",
                "http://arxiv.org/pdf/2311.04257v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04020v1",
            "title": "Analyzing Film Adaptation through Narrative Alignment",
            "updated": "2023-11-07T14:18:03Z",
            "published": "2023-11-07T14:18:03Z",
            "summary": "Novels are often adapted into feature films, but the differences between the\ntwo media usually require dropping sections of the source text from the movie\nscript. Here we study this screen adaptation process by constructing narrative\nalignments using the Smith-Waterman local alignment algorithm coupled with\nSBERT embedding distance to quantify text similarity between scenes and book\nunits. We use these alignments to perform an automated analysis of 40\nadaptations, revealing insights into the screenwriting process concerning (i)\nfaithfulness of adaptation, (ii) importance of dialog, (iii) preservation of\nnarrative order, and (iv) gender representation issues reflective of the\nBechdel test.",
            "author": [
                "Tanzir Pial",
                "Shahreen Salim",
                "Charuta Pethe",
                "Allen Kim",
                "Steven Skiena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04020v1",
                "http://arxiv.org/pdf/2311.04020v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04017v1",
            "title": "Multivariate quantile-based permutation tests with application to\n  functional data",
            "updated": "2023-11-07T14:14:56Z",
            "published": "2023-11-07T14:14:56Z",
            "summary": "Permutation tests enable testing statistical hypotheses in situations when\nthe distribution of the test statistic is complicated or not available. In some\nsituations, the test statistic under investigation is multivariate, with the\nmultiple testing problem being an important example. The corresponding\nmultivariate permutation tests are then typically based on a\nsuitableone-dimensional transformation of the vector of partial permutation\np-values via so called combining functions. This paper proposes a new approach\nthat utilizes the optimal measure transportation concept. The final single\np-value is computed from the empirical center-outward distribution function of\nthe permuted multivariate test statistics. This method avoids computation of\nthe partial p-values and it is easy to be implemented. In addition, it allows\nto compute and interpret contributions of the components of the multivariate\ntest statistic to the non-conformity score and to the rejection of the null\nhypothesis. Apart from this method, the measure transportation is applied also\nto the vector of partial p-values as an alternative to the classical combining\nfunctions. Both techniques are compared with the standard approaches using\nvarious practical examples in a Monte Carlo study. An application on a\nfunctional data set is provided as well.",
            "author": [
                "Zden\u011bk Hl\u00e1vka",
                "Daniel Hlubinka",
                "\u0160\u00e1rka Hudecov\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04017v1",
                "http://arxiv.org/pdf/2311.04017v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06303v1",
            "title": "MatNexus: A Comprehensive Text Mining and Analysis Suite for Materials\n  Discover",
            "updated": "2023-11-07T14:14:36Z",
            "published": "2023-11-07T14:14:36Z",
            "summary": "MatNexus is a specialized software for the automated collection, processing,\nand analysis of text from scientific articles. Through an integrated suite of\nmodules, the MatNexus facilitates the retrieval of scientific articles,\nprocesses textual data for insights, generates vector representations suitable\nfor machine learning, and offers visualization capabilities for word\nembeddings. With the vast volume of scientific publications, MatNexus stands\nout as an end-to-end tool for researchers aiming to gain insights from\nscientific literature in material science, making the exploration of materials,\nsuch as the electrocatalyst examples we show here, efficient and insightful.",
            "author": [
                "Lei Zhang",
                "Markus Stricker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06303v1",
                "http://arxiv.org/pdf/2311.06303v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CL",
                "physics.chem-ph",
                "H.4; H.5; I.5; I.7; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04016v1",
            "title": "Exploring Dataset-Scale Indicators of Data Quality",
            "updated": "2023-11-07T14:14:32Z",
            "published": "2023-11-07T14:14:32Z",
            "summary": "Modern computer vision foundation models are trained on massive amounts of\ndata, incurring large economic and environmental costs. Recent research has\nsuggested that improving data quality can significantly reduce the need for\ndata quantity. But what constitutes data quality in computer vision? We posit\nthat the quality of a given dataset can be decomposed into distinct\nsample-level and dataset-level constituents, and that the former have been more\nextensively studied than the latter. We ablate the effects of two important\ndataset-level constituents: label set design, and class balance. By monitoring\nthese constituents using key indicators we provide, researchers and\npractitioners can better anticipate model performance, measured in terms of its\naccuracy and robustness to distribution shifts.",
            "author": [
                "Benjamin Feuer",
                "Chinmay Hegde"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04016v1",
                "http://arxiv.org/pdf/2311.04016v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05649v1",
            "title": "Bayesian Image-on-Image Regression via Deep Kernel Learning based\n  Gaussian Processes",
            "updated": "2023-11-07T14:14:09Z",
            "published": "2023-11-07T14:14:09Z",
            "summary": "In neuroimaging studies, it becomes increasingly important to study\nassociations between different imaging modalities using image-on-image\nregression (IIR), which faces challenges in interpretation, statistical\ninference, and prediction. Our motivating problem is how to predict task-evoked\nfMRI activity using resting-state fMRI data in the Human Connectome Project\n(HCP). The main difficulty lies in effectively combining different types of\nimaging predictors with varying resolutions and spatial domains in IIR. To\naddress these issues, we develop Bayesian Image-on-image Regression via Deep\nKernel Learning Gaussian Processes (BIRD-GP) and develop efficient posterior\ncomputation methods through Stein variational gradient descent. We demonstrate\nthe advantages of BIRD-GP over state-of-the-art IIR methods using simulations.\nFor HCP data analysis using BIRD-GP, we combine the voxel-wise fALFF maps and\nregion-wise connectivity matrices to predict fMRI contrast maps for language\nand social recognition tasks. We show that fALFF is less predictive than the\nconnectivity matrix for both tasks, but combining both yields improved results.\nAngular Gyrus Right emerges as the most predictable region for the language\ntask (75.9% predictable voxels), while Superior Parietal Gyrus Right tops for\nthe social recognition task (48.9% predictable voxels). Additionally, we\nidentify features from the resting-state fMRI data that are important for task\nfMRI prediction.",
            "author": [
                "Guoxuan Ma",
                "Bangyao Zhao",
                "Hasan Abu-Amara",
                "Jian Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05649v1",
                "http://arxiv.org/pdf/2311.05649v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14693v1",
            "title": "Benefits and Harms of Large Language Models in Digital Mental Health",
            "updated": "2023-11-07T14:11:10Z",
            "published": "2023-11-07T14:11:10Z",
            "summary": "The past decade has been transformative for mental health research and\npractice. The ability to harness large repositories of data, whether from\nelectronic health records (EHR), mobile devices, or social media, has revealed\na potential for valuable insights into patient experiences, promising early,\nproactive interventions, as well as personalized treatment plans. Recent\ndevelopments in generative artificial intelligence, particularly large language\nmodels (LLMs), show promise in leading digital mental health to uncharted\nterritory. Patients are arriving at doctors' appointments with information\nsourced from chatbots, state-of-the-art LLMs are being incorporated in medical\nsoftware and EHR systems, and chatbots from an ever-increasing number of\nstartups promise to serve as AI companions, friends, and partners. This article\npresents contemporary perspectives on the opportunities and risks posed by LLMs\nin the design, development, and implementation of digital mental health tools.\nWe adopt an ecological framework and draw on the affordances offered by LLMs to\ndiscuss four application areas -- care-seeking behaviors from individuals in\nneed of care, community care provision, institutional and medical care\nprovision, and larger care ecologies at the societal level. We engage in a\nthoughtful consideration of whether and how LLM-based technologies could or\nshould be employed for enhancing mental health. The benefits and harms our\narticle surfaces could serve to help shape future research, advocacy, and\nregulatory efforts focused on creating more responsible, user-friendly,\nequitable, and secure LLM-based tools for mental health treatment and\nintervention.",
            "author": [
                "Munmun De Choudhury",
                "Sachin R. Pendse",
                "Neha Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14693v1",
                "http://arxiv.org/pdf/2311.14693v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04010v1",
            "title": "The Conjugacy Problem for $Out(F_3)$",
            "updated": "2023-11-07T14:06:43Z",
            "published": "2023-11-07T14:06:43Z",
            "summary": "We present a solution to the Conjugacy Problem in the group of\nouter-automorphisms of $F_3$, a free group of rank 3. We distinguish according\nto several computable invariants, such as irreducibility, subgroups of\npolynomial growth, and subgroups carrying the attracting lamination. We\nestablish, by considerations on train tracks, that the conjugacy problem is\ndecidable for the outer-automorphisms of $F_3$ that preserve a given rank 2\nfree factor. Then we establish, by consideration on mapping tori, that it is\ndecidable for outer-automorphisms of $F_3$ whose maximal polynomial growth\nsubgroups are cyclic. This covers all the cases left by the state of the art.",
            "author": [
                "Fran\u00e7ois Dahmani",
                "Stefano Francaviglia",
                "Armando Martino",
                "Nicholas Touikan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04010v1",
                "http://arxiv.org/pdf/2311.04010v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04009v1",
            "title": "AGNES: Abstraction-guided Framework for Deep Neural Networks Security",
            "updated": "2023-11-07T14:05:20Z",
            "published": "2023-11-07T14:05:20Z",
            "summary": "Deep Neural Networks (DNNs) are becoming widespread, particularly in\nsafety-critical areas. One prominent application is image recognition in\nautonomous driving, where the correct classification of objects, such as\ntraffic signs, is essential for safe driving. Unfortunately, DNNs are prone to\nbackdoors, meaning that they concentrate on attributes of the image that should\nbe irrelevant for their correct classification. Backdoors are integrated into a\nDNN during training, either with malicious intent (such as a manipulated\ntraining process, because of which a yellow sticker always leads to a traffic\nsign being recognised as a stop sign) or unintentional (such as a rural\nbackground leading to any traffic sign being recognised as animal crossing,\nbecause of biased training data).\n  In this paper, we introduce AGNES, a tool to detect backdoors in DNNs for\nimage recognition. We discuss the principle approach on which AGNES is based.\nAfterwards, we show that our tool performs better than many state-of-the-art\nmethods for multiple relevant case studies.",
            "author": [
                "Akshay Dhonthi",
                "Marcello Eiermann",
                "Ernst Moritz Hahn",
                "Vahid Hashemi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04009v1",
                "http://arxiv.org/pdf/2311.04009v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04008v1",
            "title": "Joint model for longitudinal and spatio-temporal survival data",
            "updated": "2023-11-07T14:05:14Z",
            "published": "2023-11-07T14:05:14Z",
            "summary": "In credit risk analysis, survival models with fixed and time-varying\ncovariates are widely used to predict a borrower's time-to-event. When the\ntime-varying drivers are endogenous, modelling jointly the evolution of the\nsurvival time and the endogenous covariates is the most appropriate approach,\nalso known as the joint model for longitudinal and survival data. In addition\nto the temporal component, credit risk models can be enhanced when including\nborrowers' geographical information by considering spatial clustering and its\nvariation over time. We propose the Spatio-Temporal Joint Model (STJM) to\ncapture spatial and temporal effects and their interaction. This Bayesian\nhierarchical joint model reckons the survival effect of unobserved\nheterogeneity among borrowers located in the same region at a particular time.\nTo estimate the STJM model for large datasets, we consider the Integrated\nNested Laplace Approximation (INLA) methodology. We apply the STJM to predict\nthe time to full prepayment on a large dataset of 57,258 US mortgage borrowers\nwith more than 2.5 million observations. Empirical results indicate that\nincluding spatial effects consistently improves the performance of the joint\nmodel. However, the gains are less definitive when we additionally include\nspatio-temporal interactions.",
            "author": [
                "Victor Medina-Olivares",
                "Finn Lindgren",
                "Raffaella Calabrese",
                "Jonathan Crook"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04008v1",
                "http://arxiv.org/pdf/2311.04008v1"
            ],
            "primary_category": "q-fin.RM",
            "category": [
                "q-fin.RM",
                "cs.CE",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04007v1",
            "title": "The Energy Prediction Smart-Meter Dataset: Analysis of Previous\n  Competitions and Beyond",
            "updated": "2023-11-07T14:05:01Z",
            "published": "2023-11-07T14:05:01Z",
            "summary": "This paper presents the real-world smart-meter dataset and offers an analysis\nof solutions derived from the Energy Prediction Technical Challenges, focusing\nprimarily on two key competitions: the IEEE Computational Intelligence Society\n(IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in\n2020 (named EP) and its follow-up challenge at the IEEE International\nConference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These\ncompetitions focus on accurate energy consumption forecasting and the\nimportance of interpretability in understanding the underlying factors. The\nchallenge aims to predict monthly and yearly estimated consumption for\nhouseholds, addressing the accurate billing problem with limited historical\nsmart meter data. The dataset comprises 3,248 smart meters, with varying data\navailability ranging from a minimum of one month to a year. This paper delves\ninto the challenges, solutions and analysing issues related to the provided\nreal-world smart meter data, developing accurate predictions at the household\nlevel, and introducing evaluation criteria for assessing interpretability.\nAdditionally, this paper discusses aspects beyond the competitions:\nopportunities for energy disaggregation and pattern detection applications at\nthe household level, significance of communicating energy-driven factors for\noptimised billing, and emphasising the importance of responsible AI and data\nprivacy considerations. These aspects provide insights into the broader\nimplications and potential advancements in energy consumption prediction.\nOverall, these competitions provide a dataset for residential energy research\nand serve as a catalyst for exploring accurate forecasting, enhancing\ninterpretability, and driving progress towards the discussion of various\naspects such as energy disaggregation, demand response programs or behavioural\ninterventions.",
            "author": [
                "Direnc Pekaslan",
                "Jose Maria Alonso-Moral",
                "Kasun Bandara",
                "Christoph Bergmeir",
                "Juan Bernabe-Moreno",
                "Robert Eigenmann",
                "Nils Einecke",
                "Selvi Ergen",
                "Rakshitha Godahewa",
                "Hansika Hewamalage",
                "Jesus Lago",
                "Steffen Limmer",
                "Sven Rebhan",
                "Boris Rabinovich",
                "Dilini Rajapasksha",
                "Heda Song",
                "Christian Wagner",
                "Wenlong Wu",
                "Luis Magdalena",
                "Isaac Triguero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04007v1",
                "http://arxiv.org/pdf/2311.04007v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06302v1",
            "title": "Knowledge-Based Support for Adhesive Selection: Will it Stick?",
            "updated": "2023-11-07T14:02:32Z",
            "published": "2023-11-07T14:02:32Z",
            "summary": "As the popularity of adhesive joints in industry increases, so does the need\nfor tools to support the process of selecting a suitable adhesive. While some\nsuch tools already exist, they are either too limited in scope, or offer too\nlittle flexibility in use. This work presents a more advanced tool, that was\ndeveloped together with a team of adhesive experts. We first extract the\nexperts' knowledge about this domain and formalize it in a Knowledge Base (KB).\nThe IDP-Z3 reasoning system can then be used to derive the necessary\nfunctionality from this KB. Together with a user-friendly interactive\ninterface, this creates an easy-to-use tool capable of assisting the adhesive\nexperts. To validate our approach, we performed user testing in the form of\nqualitative interviews. The experts are very positive about the tool, stating\nthat, among others, it will help save time and find more suitable adhesives.\nUnder consideration in Theory and Practice of Logic Programming (TPLP).",
            "author": [
                "Simon Vandevelde",
                "Jeroen Jordens",
                "Bart Van Doninck",
                "Maarten Witters",
                "Joost Vennekens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06302v1",
                "http://arxiv.org/pdf/2311.06302v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05709v1",
            "title": "OmniVec: Learning robust representations with cross modal sharing",
            "updated": "2023-11-07T14:00:09Z",
            "published": "2023-11-07T14:00:09Z",
            "summary": "Majority of research in learning based methods has been towards designing and\ntraining networks for specific tasks. However, many of the learning based\ntasks, across modalities, share commonalities and could be potentially tackled\nin a joint framework. We present an approach in such direction, to learn\nmultiple tasks, in multiple modalities, with a unified architecture. The\nproposed network is composed of task specific encoders, a common trunk in the\nmiddle, followed by task specific prediction heads. We first pre-train it by\nself-supervised masked training, followed by sequential training for the\ndifferent tasks. We train the network on all major modalities, e.g.\\ visual,\naudio, text and 3D, and report results on $22$ diverse and challenging public\nbenchmarks. We demonstrate empirically that, using a joint network to train\nacross modalities leads to meaningful information sharing and this allows us to\nachieve state-of-the-art results on most of the benchmarks. We also show\ngeneralization of the trained network on cross-modal tasks as well as unseen\ndatasets and tasks.",
            "author": [
                "Siddharth Srivastava",
                "Gaurav Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05709v1",
                "http://arxiv.org/pdf/2311.05709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04002v1",
            "title": "Enhanced Information Extraction from Cylindrical Visual-Tactile Sensors\n  via Image Fusion",
            "updated": "2023-11-07T13:56:41Z",
            "published": "2023-11-07T13:56:41Z",
            "summary": "Vision-based tactile sensors equipped with planar contact structures acquire\nthe shape, force, and motion states of objects in contact. The limited planar\ncontact area presents a challenge in acquiring information about larger target\nobjects. In contrast, vision-based tactile sensors with cylindrical contact\nstructures could extend the contact area by rolling, which can acquire much\ntactile information that exceeds the sensing projection area in a single\ncontact. However, the tactile data acquired by cylindrical structures does not\nconsistently correspond to the same depth level. Therefore, stitching and\nanalyzing the data in an extended contact area is a challenging problem. In\nthis work, we propose an image fusion method based on cylindrical vision-based\ntactile sensors. The method takes advantage of the changing characteristics of\nthe contact depth of cylindrical structures, extracts the effective information\nof different contact depths in the frequency domain, and performs differential\nfusion for the information characteristics. The results show that in object\ncontact confronting an area larger than single sensing, the images fused with\nour proposed method have higher information and structural similarity compared\nwith the method of stitching based on motion distance sampling. Meanwhile, it\nis robust to sampling time. We complement this method with a deep neural\nnetwork to illustrate its potential for fusing and recognizing object contact\ninformation using cylindrical vision-based tactile sensors.",
            "author": [
                "Zilan Li",
                "Zhibin Zou",
                "Weiliang Xu",
                "Yuanzhi Zhou",
                "Guoyuan Zhou",
                "Xuan Huang",
                "Xinming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04002v1",
                "http://arxiv.org/pdf/2311.04002v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03998v1",
            "title": "Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals",
            "updated": "2023-11-07T13:54:01Z",
            "published": "2023-11-07T13:54:01Z",
            "summary": "In many domains of argumentation, people's arguments are driven by so-called\nattitude roots, i.e., underlying beliefs and world views, and their\ncorresponding attitude themes. Given the strength of these latent drivers of\narguments, recent work in psychology suggests that instead of directly\ncountering surface-level reasoning (e.g., falsifying given premises), one\nshould follow an argumentation style inspired by the Jiu-Jitsu 'soft' combat\nsystem (Hornsey and Fielding, 2017): first, identify an arguer's attitude roots\nand themes, and then choose a prototypical rebuttal that is aligned with those\ndrivers instead of invalidating those. In this work, we are the first to\nexplore Jiu-Jitsu argumentation for peer review by proposing the novel task of\nattitude and theme-guided rebuttal generation. To this end, we enrich an\nexisting dataset for discourse structure in peer reviews with attitude roots,\nattitude themes, and canonical rebuttals. To facilitate this process, we recast\nestablished annotation concepts from the domain of peer reviews (e.g., aspects\na review sentence is relating to) and train domain-specific models. We then\npropose strong rebuttal generation strategies, which we benchmark on our novel\ndataset for the task of end-to-end attitude and theme-guided rebuttal\ngeneration and two subtasks.",
            "author": [
                "Sukannya Purkayastha",
                "Anne Lauscher",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03998v1",
                "http://arxiv.org/pdf/2311.03998v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04255v1",
            "title": "Quantum stabilizer formalism for any composite system",
            "updated": "2023-11-07T13:47:57Z",
            "published": "2023-11-07T13:47:57Z",
            "summary": "The quantum stabilizer formalism was originally introduced to describe\nquantum error correction codes more conveniently and now are also playing an\nimportant role in many other fields, e.g., quantum computing and quantum\nfoundation. In this dissertation, we first introduce relevant background and\nnecessary basic knowledge, then introduce the definition of quantum stabilizer\nand its application in quantum system evolution and measurement. Finally, we\ntry to extend the quantum stabilizer formalism to qubit-qutrit and\nqubit-ququart systems which not defined before, and further define quantum\nstabilizers of arbitrary composite systems.",
            "author": [
                "Zhelin Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04255v1",
                "http://arxiv.org/pdf/2311.04255v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03990v1",
            "title": "Effects of Renormalon Scheme and Perturbative Scale Choices on\n  Determinations of the Strong Coupling from $e^+e^-$ Event Shapes",
            "updated": "2023-11-07T13:42:04Z",
            "published": "2023-11-07T13:42:04Z",
            "summary": "We study the role of renormalon cancellation schemes and perturbative scale\nchoices in extractions of the strong coupling constant $\\alpha_s(m_Z)$ and the\nleading non-perturbative shift parameter $\\Omega_1$ from resummed predictions\nof the $e^+e^-$ event shape thrust. We calculate the thrust distribution to\nN$^{3}$LL$^\\prime$ resummed accuracy in Soft-Collinear Effective Theory (SCET)\nmatched to the fixed-order $\\mathcal{O}(\\alpha_s^2)$ prediction, and perform a\nnew high-statistics computation of the $\\mathcal{O}(\\alpha_s^3)$ matching in\nEERAD3, although we do not include the latter in our final $\\alpha_s$ fits due\nto some observed systematics that require further investigation. We are\nprimarily interested in testing the phenomenological impact sourced from\nvarying amongst three renormalon cancellation schemes and two sets of\nperturbative scale profile choices. We then perform a global fit to available\ndata spanning center-of-mass energies between 35-207 GeV in each scenario.\nRelevant subsets of our results are consistent with prior SCET-based\nextractions of $\\alpha_s(m_Z)$, but we are also led to a number of novel\nobservations. Notably, we find that the combined effect of altering the\nrenormalon cancellation scheme and profile parameters can lead to\nfew-percent-level impacts on the extracted values in the $\\alpha_s-\\Omega_1$\nplane, indicating a potentially important systematic theory uncertainty that\nshould be accounted for. We also observe that fits performed over windows\ndominated by dijet events are typically of a higher quality than those that\nextend into the far tails of the distributions, possibly motivating future fits\nfocused more heavily in this region. Finally, we discuss how different\nestimates of the three-loop soft matching coefficient $c_{\\tilde{S}}^3$ can\nalso lead to measurable changes in the fitted $\\lbrace \\alpha_s, \\Omega_1\n\\rbrace$ values.",
            "author": [
                "Guido Bell",
                "Christopher Lee",
                "Yiannis Makris",
                "Jim Talbert",
                "Bin Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03990v1",
                "http://arxiv.org/pdf/2311.03990v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03985v1",
            "title": "Quadrotor Experimental Dynamic Identification with Comprehensive NARX\n  Neural Networks",
            "updated": "2023-11-07T13:37:39Z",
            "published": "2023-11-07T13:37:39Z",
            "summary": "This research paper delves into the field of quadrotor dynamics, which are\nfamous by their nonlinearity, under-actuation, and multivariable nature. Due to\nthe critical need for precise modeling and control in this context we explore\nthe capabilities of NARX (Nonlinear AutoRegressive with eXogenous inputs)\nNeural Networks (NN). These networks are employed for comprehensive and\naccurate modeling of quadrotor behaviors, take advantage of their ability to\ncapture the hided dynamics. Our research encompasses a rigorous experimental\nsetup, including the use of PRBS (Pseudo-random binary sequence) signals for\nexcitation, to validate the efficacy of NARX-NN in predicting and controlling\nquadrotor dynamics. The results reveal exceptional accuracy, with fit\npercentages exceeding 99% on both estimation and validation data. Moreover, we\nidentified the quadrotor dynamics using different NARX NN structures, including\nthe NARX model with a sigmoid NN, NARX feedforward NN, and cascade NN. In\nsummary, our study positions NARX-NN as a transformative tool for quadrotor\napplications, ranging from autonomous navigation to aerial robotics, thanks to\ntheir accurate and comprehensive modeling capabilities.",
            "author": [
                "Khaled Telli",
                "Okba Kraa",
                "Yassine Himeur",
                "Mohamed Boumehraz",
                "Shadi Atalla",
                "Wathiq Mansoor",
                "Abdelmalik Ouamane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03985v1",
                "http://arxiv.org/pdf/2311.03985v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03982v1",
            "title": "Federated Learning via Active RIS Assisted Over-the-Air Computation",
            "updated": "2023-11-07T13:34:58Z",
            "published": "2023-11-07T13:34:58Z",
            "summary": "In this paper, we propose leveraging the active reconfigurable intelligence\nsurface (RIS) to support reliable gradient aggregation for over-the-air\ncomputation (AirComp) enabled federated learning (FL) systems. An analysis of\nthe FL convergence property reveals that minimizing gradient aggregation errors\nin each training round is crucial for narrowing the convergence gap. As such,\nwe formulate an optimization problem, aiming to minimize these errors by\njointly optimizing the transceiver design and RIS configuration. To handle the\nformulated highly non-convex problem, we devise a two-layer alternative\noptimization framework to decompose it into several convex subproblems, each\nsolvable optimally. Simulation results demonstrate the superiority of the\nactive RIS in reducing gradient aggregation errors compared to its passive\ncounterpart.",
            "author": [
                "Deyou Zhang",
                "Ming Xiao",
                "Mikael Skoglund",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03982v1",
                "http://arxiv.org/pdf/2311.03982v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03974v1",
            "title": "NOMA Enabled Multi-Access Edge Computing: A Joint MU-MIMO Precoding and\n  Computation Offloading Design",
            "updated": "2023-11-07T13:20:00Z",
            "published": "2023-11-07T13:20:00Z",
            "summary": "This letter investigates computation offloading and transmit precoding\nco-design for multi-access edge computing (MEC), where multiple MEC users (MUs)\nequipped with multiple antennas access the MEC server in a non-orthogonal\nmultiple access manner. We aim to minimize the total energy consumption of all\nMUs while satisfying the latency constraints by jointly optimizing the\ncomputational frequency, offloading ratio, and precoding matrix of each MU. For\ntractability, we first decompose the original problem into three subproblems\nand then solve these subproblems iteratively until convergence. Simulation\nresults validate the convergence of the proposed method and demonstrate its\nsuperiority over baseline algorithms.",
            "author": [
                "Deyou Zhang",
                "Meng Wang",
                "Shuo Shi",
                "Ming Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03974v1",
                "http://arxiv.org/pdf/2311.03974v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03973v1",
            "title": "Pregeometry, Formal Language and Constructivist Foundations of Physics",
            "updated": "2023-11-07T13:19:29Z",
            "published": "2023-11-07T13:19:29Z",
            "summary": "How does one formalize the structure of structures necessary for the\nfoundations of physics? This work is an attempt at conceptualizing the\nmetaphysics of pregeometric structures, upon which new and existing notions of\nquantum geometry may find a foundation. We discuss the philosophy of\npregeometric structures due to Wheeler, Leibniz as well as modern\nmanifestations in topos theory. We draw attention to evidence suggesting that\nthe framework of formal language, in particular, homotopy type theory, provides\nthe conceptual building blocks for a theory of pregeometry. This work is\nlargely a synthesis of ideas that serve as a precursor for conceptualizing the\nnotion of space in physical theories. In particular, the approach we espouse is\nbased on a constructivist philosophy, wherein ``structureless structures'' are\nsyntactic types realizing formal proofs and programs. Spaces and algebras\nrelevant to physical theories are modeled as type-theoretic routines\nconstructed from compositional rules of a formal language. This offers the\nremarkable possibility of taxonomizing distinct notions of geometry using a\ncommon theoretical framework. In particular, this perspective addresses the\ncrucial issue of how spatiality may be realized in models that link formal\ncomputation to physics, such as the Wolfram model.",
            "author": [
                "Xerxes D. Arsiwalla",
                "Hatem Elshatlawy",
                "Dean Rickles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03973v1",
                "http://arxiv.org/pdf/2311.03973v1"
            ],
            "primary_category": "physics.hist-ph",
            "category": [
                "physics.hist-ph",
                "gr-qc",
                "hep-th",
                "math-ph",
                "math.MP",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16148v1",
            "title": "Univariate Radial Basis Function Layers: Brain-inspired Deep Neural\n  Layers for Low-Dimensional Inputs",
            "updated": "2023-11-07T13:14:49Z",
            "published": "2023-11-07T13:14:49Z",
            "summary": "Deep Neural Networks (DNNs) became the standard tool for function\napproximation with most of the introduced architectures being developed for\nhigh-dimensional input data. However, many real-world problems have\nlow-dimensional inputs for which standard Multi-Layer Perceptrons (MLPs) are\nthe default choice. An investigation into specialized architectures is missing.\nWe propose a novel DNN layer called Univariate Radial Basis Function (U-RBF)\nlayer as an alternative. Similar to sensory neurons in the brain, the U-RBF\nlayer processes each individual input dimension with a population of neurons\nwhose activations depend on different preferred input values. We verify its\neffectiveness compared to MLPs in low-dimensional function regressions and\nreinforcement learning tasks. The results show that the U-RBF is especially\nadvantageous when the target function becomes complex and difficult to\napproximate.",
            "author": [
                "Basavasagar Patil",
                "Xavier Alameda-Pineda",
                "Chris Reinke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16148v1",
                "http://arxiv.org/pdf/2311.16148v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03970v1",
            "title": "Bias and Diversity in Synthetic-based Face Recognition",
            "updated": "2023-11-07T13:12:34Z",
            "published": "2023-11-07T13:12:34Z",
            "summary": "Synthetic data is emerging as a substitute for authentic data to solve\nethical and legal challenges in handling authentic face data. The current\nmodels can create real-looking face images of people who do not exist. However,\nit is a known and sensitive problem that face recognition systems are\nsusceptible to bias, i.e. performance differences between different demographic\nand non-demographics attributes, which can lead to unfair decisions. In this\nwork, we investigate how the diversity of synthetic face recognition datasets\ncompares to authentic datasets, and how the distribution of the training data\nof the generative models affects the distribution of the synthetic data. To do\nthis, we looked at the distribution of gender, ethnicity, age, and head\nposition. Furthermore, we investigated the concrete bias of three recent\nsynthetic-based face recognition models on the studied attributes in comparison\nto a baseline model trained on authentic data. Our results show that the\ngenerator generate a similar distribution as the used training data in terms of\nthe different attributes. With regard to bias, it can be seen that the\nsynthetic-based models share a similar bias behavior with the authentic-based\nmodels. However, with the uncovered lower intra-identity attribute consistency\nseems to be beneficial in reducing bias.",
            "author": [
                "Marco Huber",
                "Anh Thi Luu",
                "Fadi Boutros",
                "Arjan Kuijper",
                "Naser Damer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03970v1",
                "http://arxiv.org/pdf/2311.03970v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03969v1",
            "title": "Factoring Hate Speech: A New Annotation Framework to Study Hate Speech\n  in Social Media",
            "updated": "2023-11-07T13:08:55Z",
            "published": "2023-11-07T13:08:55Z",
            "summary": "In this work we propose a novel annotation scheme which factors hate speech\ninto five separate discursive categories. To evaluate our scheme, we construct\na corpus of over 2.9M Twitter posts containing hateful expressions directed at\nJews, and annotate a sample dataset of 1,050 tweets. We present a statistical\nanalysis of the annotated dataset as well as discuss annotation examples, and\nconclude by discussing promising directions for future work.",
            "author": [
                "Gal Ron",
                "Effi Levi",
                "Odelia Oshri",
                "Shaul R. Shenhav"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.woah-1.21",
                "http://arxiv.org/abs/2311.03969v1",
                "http://arxiv.org/pdf/2311.03969v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03967v1",
            "title": "CeCNN: Copula-enhanced convolutional neural networks in joint prediction\n  of refraction error and axial length based on ultra-widefield fundus images",
            "updated": "2023-11-07T13:06:50Z",
            "published": "2023-11-07T13:06:50Z",
            "summary": "Ultra-widefield (UWF) fundus images are replacing traditional fundus images\nin screening, detection, prediction, and treatment of complications related to\nmyopia because their much broader visual range is advantageous for highly\nmyopic eyes. Spherical equivalent (SE) is extensively used as the main myopia\noutcome measure, and axial length (AL) has drawn increasing interest as an\nimportant ocular component for assessing myopia. Cutting-edge studies show that\nSE and AL are strongly correlated. Using the joint information from SE and AL\nis potentially better than using either separately. In the deep learning\ncommunity, though there is research on multiple-response tasks with a 3D image\nbiomarker, dependence among responses is only sporadically taken into\nconsideration. Inspired by the spirit that information extracted from the data\nby statistical methods can improve the prediction accuracy of deep learning\nmodels, we formulate a class of multivariate response regression models with a\nhigher-order tensor biomarker, for the bivariate tasks of\nregression-classification and regression-regression. Specifically, we propose a\ncopula-enhanced convolutional neural network (CeCNN) framework that\nincorporates the dependence between responses through a Gaussian copula (with\nparameters estimated from a warm-up CNN) and uses the induced copula-likelihood\nloss with the backbone CNNs. We establish the statistical framework and\nalgorithms for the aforementioned two bivariate tasks. We show that the CeCNN\nhas better prediction accuracy after adding the dependency information to the\nbackbone models. The modeling and the proposed CeCNN algorithm are applicable\nbeyond the UWF scenario and can be effective with other backbones beyond ResNet\nand LeNet.",
            "author": [
                "Chong Zhong",
                "Yang Li",
                "Danjuan Yang",
                "Meiyan Li",
                "Xingyao Zhou",
                "Bo Fu",
                "Catherine C. Liu",
                "A. H. Welsh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03967v1",
                "http://arxiv.org/pdf/2311.03967v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03965v1",
            "title": "Fast Sun-aligned Outdoor Scene Relighting based on TensoRF",
            "updated": "2023-11-07T13:06:30Z",
            "published": "2023-11-07T13:06:30Z",
            "summary": "In this work, we introduce our method of outdoor scene relighting for Neural\nRadiance Fields (NeRF) named Sun-aligned Relighting TensoRF (SR-TensoRF).\nSR-TensoRF offers a lightweight and rapid pipeline aligned with the sun,\nthereby achieving a simplified workflow that eliminates the need for\nenvironment maps. Our sun-alignment strategy is motivated by the insight that\nshadows, unlike viewpoint-dependent albedo, are determined by light direction.\nWe directly use the sun direction as an input during shadow generation,\nsimplifying the requirements of the inference process significantly. Moreover,\nSR-TensoRF leverages the training efficiency of TensoRF by incorporating our\nproposed cubemap concept, resulting in notable acceleration in both training\nand rendering processes compared to existing methods.",
            "author": [
                "Yeonjin Chang",
                "Yearim Kim",
                "Seunghyeon Seo",
                "Jung Yi",
                "Nojun Kwak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03965v1",
                "http://arxiv.org/pdf/2311.03965v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03964v1",
            "title": "Enhancing Multimodal Compositional Reasoning of Visual Language Models\n  with Generative Negative Mining",
            "updated": "2023-11-07T13:05:47Z",
            "published": "2023-11-07T13:05:47Z",
            "summary": "Contemporary large-scale visual language models (VLMs) exhibit strong\nrepresentation capacities, making them ubiquitous for enhancing image and text\nunderstanding tasks. They are often trained in a contrastive manner on a large\nand diverse corpus of images and corresponding text captions scraped from the\ninternet. Despite this, VLMs often struggle with compositional reasoning tasks\nwhich require a fine-grained understanding of the complex interactions of\nobjects and their attributes. This failure can be attributed to two main\nfactors: 1) Contrastive approaches have traditionally focused on mining\nnegative examples from existing datasets. However, the mined negative examples\nmight not be difficult for the model to discriminate from the positive. An\nalternative to mining would be negative sample generation 2) But existing\ngenerative approaches primarily focus on generating hard negative texts\nassociated with a given image. Mining in the other direction, i.e., generating\nnegative image samples associated with a given text has been ignored. To\novercome both these limitations, we propose a framework that not only mines in\nboth directions but also generates challenging negative samples in both\nmodalities, i.e., images and texts. Leveraging these generative hard negative\nsamples, we significantly enhance VLMs' performance in tasks involving\nmultimodal compositional reasoning. Our code and dataset are released at\nhttps://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html.",
            "author": [
                "Ugur Sahin",
                "Hang Li",
                "Qadeer Khan",
                "Daniel Cremers",
                "Volker Tresp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03964v1",
                "http://arxiv.org/pdf/2311.03964v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03963v1",
            "title": "An Expectation-Realization Model for Metaphor Detection",
            "updated": "2023-11-07T13:03:54Z",
            "published": "2023-11-07T13:03:54Z",
            "summary": "We propose a metaphor detection architecture that is structured around two\nmain modules: an expectation component that estimates representations of\nliteral word expectations given a context, and a realization component that\ncomputes representations of actual word meanings in context. The overall\narchitecture is trained to learn expectation-realization (ER) patterns that\ncharacterize metaphorical uses of words. When evaluated on three metaphor\ndatasets for within distribution, out of distribution, and novel metaphor\ngeneralization, the proposed method is shown to obtain results that are\ncompetitive or better than state-of-the art. Further increases in metaphor\ndetection accuracy are obtained through ensembling of ER models.",
            "author": [
                "Oseremen O. Uduehi",
                "Razvan C. Bunescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03963v1",
                "http://arxiv.org/pdf/2311.03963v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03960v1",
            "title": "Algebraic solutions for $o(12) {\\leftrightarrow} u(2) \\otimes u(10)$\n  quantum phase transitions in the proton-neutron interacting boson model",
            "updated": "2023-11-07T13:00:38Z",
            "published": "2023-11-07T13:00:38Z",
            "summary": "A simple systematic procedure to construct the proton-neutron unitary,\n$u_{\\text{sd}}^{\\pi \\nu }{(12)}$, orthogonal, $o_{\\text{sd}}^{\\pi \\nu }{(12)}$,\nand quasi-spin $\\text{su}_{\\text{sd}}^{\\pi \\nu }{(1,1)}$ algebras of the sd\nbosonic system is presented. New algebraic substructures of these algebras are\ndiscussed and the explicit formulae for their generators and Casimir operators\nare given in the spherical tensor form. The complementarity relationship of the\nCasimir operators of the $\\text{su}_{\\text{sd}}^{\\pi \\nu }{(1,1)}$ and\n$o_{\\text{sd}}^{\\pi \\nu }{(12)}$ is derived. The exact algebraic solutions of\nthe quantum phase transition Hamiltonian between the $o_{\\text{sd}}^{\\pi \\nu\n}{(12)}$ and $u_s^{\\pi \\nu }{(2)} \\otimes u_d^{\\pi \\nu }{(10)}$ limits has been\nconsidered, for the first time, in the framework of affine\n$\\text{su}_{\\text{sd}}^{\\pi \\nu }{(1,1)}$ Lie algebra. The low lying energy\nspectra of the $\\, ^{70}\\text{Ge},\\, ^{76-78}\\text{Se},\\,\n^{96-98}\\text{Mo},\\text{and}\\, ^{100-102}\\text{Ru}$ isotopes are calculated\nusing the $o_{\\text{sd}}^{\\pi \\nu } {(12)} {\\leftrightarrow} u_s^{\\pi \\nu\n}{(2)} \\otimes u_d^{\\pi \\nu }{(10)}$ transition Hamiltonian. The good agreement\nof our computation with empirical result in these isotopes emphasizes the\nimportance of $u_s^{\\pi \\nu }{(2)} \\otimes u_d^{\\pi \\nu }{(10)}$ limit. With\nthis addition, symmetry can be extended to many nuclei.",
            "author": [
                "M. M. Hammad",
                "Andriana Martinou",
                "Dennis Bonatsos"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.nuclphysa.2022.122540",
                "http://arxiv.org/abs/2311.03960v1",
                "http://arxiv.org/pdf/2311.03960v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03959v2",
            "title": "Improving the Effectiveness of Deep Generative Data",
            "updated": "2023-11-08T08:50:25Z",
            "published": "2023-11-07T12:57:58Z",
            "summary": "Recent deep generative models (DGMs) such as generative adversarial networks\n(GANs) and diffusion probabilistic models (DPMs) have shown their impressive\nability in generating high-fidelity photorealistic images. Although looking\nappealing to human eyes, training a model on purely synthetic images for\ndownstream image processing tasks like image classification often results in an\nundesired performance drop compared to training on real data. Previous works\nhave demonstrated that enhancing a real dataset with synthetic images from DGMs\ncan be beneficial. However, the improvements were subjected to certain\ncircumstances and yet were not comparable to adding the same number of real\nimages. In this work, we propose a new taxonomy to describe factors\ncontributing to this commonly observed phenomenon and investigate it on the\npopular CIFAR-10 dataset. We hypothesize that the Content Gap accounts for a\nlarge portion of the performance drop when using synthetic images from DGM and\npropose strategies to better utilize them in downstream tasks. Extensive\nexperiments on multiple datasets showcase that our method outperforms baselines\non downstream classification tasks both in case of training on synthetic only\n(Synthetic-to-Real) and training on a mix of real and synthetic data (Data\nAugmentation), particularly in the data-scarce scenario.",
            "author": [
                "Ruyu Wang",
                "Sabrina Schmedding",
                "Marco F. Huber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03959v2",
                "http://arxiv.org/pdf/2311.03959v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06301v1",
            "title": "Scaling of average trapping time and average weighted shortest path on a\n  residual multi-weighted crystal network",
            "updated": "2023-11-07T12:52:54Z",
            "published": "2023-11-07T12:52:54Z",
            "summary": "This article constructs the residual network after some regions were damaged\nand detached from the original crystal network. This residual crystal network\nsimulates the situation where parts of a computer system or power system failed\nafter been attacked in real life. Furthermore, we assign multiple weight\nfactors to the edges in the network, exhibiting mixed weight growth. By using\nthe symmetry and self-similarity of the network structure, the analytical\nexpression for the average trapping time and the average weighted shortest path\non this network are solved, and the numerical results are given by taking the\nresidual hexagonal crystal network as an example. By analyzing the network and\nstudying the topological properties, we show the robustness of the network\nstructure and find the residual network is more efficient for communication\nbetween nodes.",
            "author": [
                "Xie Bingyan",
                "Wu Bo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06301v1",
                "http://arxiv.org/pdf/2311.06301v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03953v1",
            "title": "Spectral functions of the strongly interacting 3D Fermi gas",
            "updated": "2023-11-07T12:50:14Z",
            "published": "2023-11-07T12:50:14Z",
            "summary": "Computing dynamical properties of strongly interacting quantum many-body\nsystems poses a major challenge to theoretical approaches. Usually, one has to\nresort to numerical analytic continuation of results on imaginary frequencies,\nwhich is a mathematically ill-defined procedure. Here, we present an efficient\nmethod to compute the spectral functions of the two-component Fermi gas near\nthe strongly interacting unitary limit directly in real frequencies. To this\nend, we combine the Keldysh path integral that is defined in real time with the\nself-consistent T-matrix approximation. The latter is known to predict\nthermodynamic and transport properties in good agreement with experimental\nobservations in ultracold atoms. We validate our method by comparison with\nthermodynamic quantities obtained from imaginary time calculations and by\ntransforming our real-time propagators to imaginary time. By comparison with\nstate-of-the-art numerical analytic continuation of the imaginary time results,\nwe show that our real-time results give qualitative improvements for dynamical\nquantities. Moreover, we show that no significant pseudogap regime exists in\nthe self-consistent T-matrix approximation above the critical temperature\n$T_c$, an issue that has been under significant debate. We close by pointing\nout the versatile nature of our method as it can be extended to other systems,\nlike the spin- or mass-imbalanced Fermi gas, other Bose-Fermi models, 2D\nsystems as well as systems out of equilibrium.",
            "author": [
                "Christian H. Johansen",
                "Bernhard Frank",
                "Johannes Lang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03953v1",
                "http://arxiv.org/pdf/2311.03953v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03952v1",
            "title": "An Analysis of Dialogue Repair in Voice Assistants",
            "updated": "2023-11-07T12:50:11Z",
            "published": "2023-11-07T12:50:11Z",
            "summary": "Spoken dialogue systems have transformed human-machine interaction by\nproviding real-time responses to queries. However, misunderstandings between\nthe user and system persist. This study explores the significance of\ninteractional language in dialogue repair between virtual assistants and users\nby analyzing interactions with Google Assistant and Siri, focusing on their\nutilization and response to the other-initiated repair strategy \"huh?\"\nprevalent in human-human interaction. Findings reveal several\nassistant-generated strategies but an inability to replicate human-like repair\nstrategies such as \"huh?\". English and Spanish user acceptability surveys show\ndifferences in users' repair strategy preferences and assistant usage, with\nboth similarities and disparities among the two surveyed languages. These\nresults shed light on inequalities between interactional language in\nhuman-human interaction and human-machine interaction, underscoring the need\nfor further research on the impact of interactional language in human-machine\ninteraction in English and beyond.",
            "author": [
                "Matthew Galbraith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03952v1",
                "http://arxiv.org/pdf/2311.03952v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03943v2",
            "title": "CLIP Guided Image-perceptive Prompt Learning for Image Enhancement",
            "updated": "2023-11-22T07:52:06Z",
            "published": "2023-11-07T12:36:20Z",
            "summary": "Image enhancement is a significant research area in the fields of computer\nvision and image processing. In recent years, many learning-based methods for\nimage enhancement have been developed, where the Look-up-table (LUT) has proven\nto be an effective tool. In this paper, we delve into the potential of\nContrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning,\nproposing a simple structure called CLIP-LUT for image enhancement. We found\nthat the prior knowledge of CLIP can effectively discern the quality of\ndegraded images, which can provide reliable guidance. To be specific, We\ninitially learn image-perceptive prompts to distinguish between original and\ntarget images using CLIP model, in the meanwhile, we introduce a very simple\nnetwork by incorporating a simple baseline to predict the weights of three\ndifferent LUT as enhancement network. The obtained prompts are used to steer\nthe enhancement network like a loss function and improve the performance of\nmodel. We demonstrate that by simply combining a straightforward method with\nCLIP, we can obtain satisfactory results.",
            "author": [
                "Weiwen Chen",
                "Qiuhong Ke",
                "Zinuo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03943v2",
                "http://arxiv.org/pdf/2311.03943v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04242v1",
            "title": "Surgery Exact Triangles in Instanton Theory",
            "updated": "2023-11-07T12:24:16Z",
            "published": "2023-11-07T12:24:16Z",
            "summary": "We prove an exact triangle relating knot instanton Floer homology to the\ninstanton homology of surgeries along the knot. To the author's knowledge, this\nis the first such result in instanton homology with integer coefficients and\nhas no analogue in Heegaard Floer homology. To illustrate the latter claim, we\nderive as a consequence of this triangle, building on previous computations in\nthe literature, that the Poincar\\'e Homology Sphere is not an instanton\n$L$-space with $\\mathbb{Z}/2$-coefficients.",
            "author": [
                "Deeparaj Bhat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04242v1",
                "http://arxiv.org/pdf/2311.04242v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "57R58"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03939v2",
            "title": "Computation of the Distribution of the Absorption Time of the Drifted\n  Diffusion with Stochastic Resetting and Mixed Boundary Conditions",
            "updated": "2023-11-15T15:57:05Z",
            "published": "2023-11-07T12:23:24Z",
            "summary": "This article introduces two techniques for computing the distribution of the\nfirst passage or absorption time of a drifted Wiener diffusion with Poisson\nresetting times, in presence of an upper hard wall reflection and a lower\nabsorbing barrier. The first method starts with the Pad\\'e approximation to the\nLaplace transform of the first passage time, which is then inverted through the\npartial fraction decomposition. The second method, which we call\n\"multiresolution algorithm\", is a Monte Carlo technique that exploits the\nproperties of the Wiener process in order to generate Brownian bridges at\nincreasing resolution levels. This technique allows to approximate the first\npassage time at any level of accuracy. An intensive numerical study reveals\nthat the multiresolution algorithm has higher accuracy than standard Monte\nCarlo, whereas the faster method based on the Pad\\'e approximation provides\nsufficient accuracy in specific circumstances only. Besides these two numerical\napproximations, this article provides a closed-form expression for the expected\nfirst passage time.",
            "author": [
                "Riccardo Turin",
                "Juan Magalang",
                "Javier Aguilar",
                "Laetitia Colombani",
                "Daniel Sanchez-Taltavull",
                "Riccardo Gatto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03939v2",
                "http://arxiv.org/pdf/2311.03939v2"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.stat-mech",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03938v1",
            "title": "Analysis of NaN Divergence in Training Monocular Depth Estimation Model",
            "updated": "2023-11-07T12:19:30Z",
            "published": "2023-11-07T12:19:30Z",
            "summary": "The latest advances in deep learning have facilitated the development of\nhighly accurate monocular depth estimation models. However, when training a\nmonocular depth estimation network, practitioners and researchers have observed\nnot a number (NaN) loss, which disrupts gradient descent optimization. Although\nseveral practitioners have reported the stochastic and mysterious occurrence of\nNaN loss that bothers training, its root cause is not discussed in the\nliterature. This study conducted an in-depth analysis of NaN loss during\ntraining a monocular depth estimation network and identified three types of\nvulnerabilities that cause NaN loss: 1) the use of square root loss, which\nleads to an unstable gradient; 2) the log-sigmoid function, which exhibits\nnumerical stability issues; and 3) certain variance implementations, which\nyield incorrect computations. Furthermore, for each vulnerability, the\noccurrence of NaN loss was demonstrated and practical guidelines to prevent NaN\nloss were presented. Experiments showed that both optimization stability and\nperformance on monocular depth estimation could be improved by following our\nguidelines.",
            "author": [
                "Bum Jun Kim",
                "Hyeonah Jang",
                "Sang Woo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03938v1",
                "http://arxiv.org/pdf/2311.03938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03928v1",
            "title": "Improving Korean NLP Tasks with Linguistically Informed Subword\n  Tokenization and Sub-character Decomposition",
            "updated": "2023-11-07T12:08:21Z",
            "published": "2023-11-07T12:08:21Z",
            "summary": "We introduce a morpheme-aware subword tokenization method that utilizes\nsub-character decomposition to address the challenges of applying Byte Pair\nEncoding (BPE) to Korean, a language characterized by its rich morphology and\nunique writing system. Our approach balances linguistic accuracy with\ncomputational efficiency in Pre-trained Language Models (PLMs). Our evaluations\nshow that this technique achieves good performances overall, notably improving\nresults in the syntactic task of NIKL-CoLA. This suggests that integrating\nmorpheme type information can enhance language models' syntactic and semantic\ncapabilities, indicating that adopting more linguistic insights can further\nimprove performance beyond standard morphological analysis.",
            "author": [
                "Taehee Jeon",
                "Bongseok Yang",
                "Changhwan Kim",
                "Yoonseob Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03928v1",
                "http://arxiv.org/pdf/2311.03928v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03926v1",
            "title": "On the Coupling of Hamilton's Principle and Thermodynamic Extremal\n  Principles",
            "updated": "2023-11-07T12:07:51Z",
            "published": "2023-11-07T12:07:51Z",
            "summary": "Extremal principles can generally be divided into two rather distinct\nclasses. There are, on the one hand side, formulations based on the Lagrangian\nor Hamiltonian mechanics, respectively, dealing with time dependent problems,\nbut essentially resting on conservation of energy and thus being not applicable\nto dissipative systems in a consistent way. On the other hand, there are\nformulations based essentially on maximizing the dissipation, working\nefficiently for the description of dissipative systems, but being not suitable\nfor including inertia effects. Many at-tempts can be found in the literature to\novercome this split into incompatible principles. How-ever, essentially all of\nthem possess an unnatural appearance. In this work, we suggest a solution to\nthis dilemma resting on an additional assumption based on the thermodynamic\ndriving forces involved. Applications to a simple dissipative structure and a\nmaterial with varying mass demonstrate the capability of the proposed approach.",
            "author": [
                "Klaus Hackl",
                "Ji\u0159\u00ed Svoboda",
                "Franz Dieter Fischer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03926v1",
                "http://arxiv.org/pdf/2311.03926v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "74A15, 49S05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04253v1",
            "title": "Blind Federated Learning via Over-the-Air q-QAM",
            "updated": "2023-11-07T12:02:59Z",
            "published": "2023-11-07T12:02:59Z",
            "summary": "In this work, we investigate federated edge learning over a fading multiple\naccess channel. To alleviate the communication burden between the edge devices\nand the access point, we introduce a pioneering digital over-the-air\ncomputation strategy employing q-ary quadrature amplitude modulation,\nculminating in a low latency communication scheme. Indeed, we propose a new\nfederated edge learning framework in which edge devices use digital modulation\nfor over-the-air uplink transmission to the edge server while they have no\naccess to the channel state information. Furthermore, we incorporate multiple\nantennas at the edge server to overcome the fading inherent in wireless\ncommunication. We analyze the number of antennas required to mitigate the\nfading impact effectively. We prove a non-asymptotic upper bound for the mean\nsquared error for the proposed federated learning with digital over-the-air\nuplink transmissions under both noisy and fading conditions. Leveraging the\nderived upper bound, we characterize the convergence rate of the learning\nprocess of a non-convex loss function in terms of the mean square error of\ngradients due to the fading channel. Furthermore, we substantiate the\ntheoretical assurances through numerical experiments concerning mean square\nerror and the convergence efficacy of the digital federated edge learning\nframework. Notably, the results demonstrate that augmenting the number of\nantennas at the edge server and adopting higher-order modulations improve the\nmodel accuracy up to 60\\%.",
            "author": [
                "Saeed Razavikia",
                "Jos\u00e9 Mairton Barros Da Silva J\u00fanior",
                "Carlo Fischione"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04253v1",
                "http://arxiv.org/pdf/2311.04253v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03923v1",
            "title": "Hardware Aware Evolutionary Neural Architecture Search using\n  Representation Similarity Metric",
            "updated": "2023-11-07T11:58:40Z",
            "published": "2023-11-07T11:58:40Z",
            "summary": "Hardware-aware Neural Architecture Search (HW-NAS) is a technique used to\nautomatically design the architecture of a neural network for a specific task\nand target hardware. However, evaluating the performance of candidate\narchitectures is a key challenge in HW-NAS, as it requires significant\ncomputational resources. To address this challenge, we propose an efficient\nhardware-aware evolution-based NAS approach called HW-EvRSNAS. Our approach\nre-frames the neural architecture search problem as finding an architecture\nwith performance similar to that of a reference model for a target hardware,\nwhile adhering to a cost constraint for that hardware. This is achieved through\na representation similarity metric known as Representation Mutual Information\n(RMI) employed as a proxy performance evaluator. It measures the mutual\ninformation between the hidden layer representations of a reference model and\nthose of sampled architectures using a single training batch. We also use a\npenalty term that penalizes the search process in proportion to how far an\narchitecture's hardware cost is from the desired hardware cost threshold. This\nresulted in a significantly reduced search time compared to the literature that\nreached up to 8000x speedups resulting in lower CO2 emissions. The proposed\napproach is evaluated on two different search spaces while using lower\ncomputational resources. Furthermore, our approach is thoroughly examined on\nsix different edge devices under various hardware cost constraints.",
            "author": [
                "Nilotpal Sinha",
                "Abd El Rahman Shabayek",
                "Anis Kacem",
                "Peyman Rostami",
                "Carl Shneider",
                "Djamila Aouada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03923v1",
                "http://arxiv.org/pdf/2311.03923v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03921v1",
            "title": "Fast and Efficient Type-II Phototransistors Integrated on Silicon",
            "updated": "2023-11-07T11:58:20Z",
            "published": "2023-11-07T11:58:20Z",
            "summary": "Increasing the efficiency and reducing the footprint of on-chip\nphotodetectors enables dense optical interconnects for emerging computational\nand sensing applications. Avalanche photodetectors (APD) are currently the\ndominating on-chip photodetectors. However, the physics of avalanche\nmultiplication leads to low energy efficiencies and prevents device operation\nat a high gain, due to a high excess noise, resulting in the need for\nelectrical amplifiers. These properties significantly increase power\nconsumption and footprint of current optical receivers. In contrast,\nheterojunction phototransistors (HPT) exhibit high efficiency and very small\nexcess noise at high gain. However, HPT's gain-bandwidth product (GBP) is\ncurrently inferior to that of APDs at low optical powers. Here, we demonstrate\nthat the type-II energy band alignment in an antimony-based HPT results in a\nsignificantly smaller junction capacitance and higher GBP at low optical\npowers. We used a CMOS-compatible heterogeneous integration method to create\ncompact optical receivers on silicon with an energy efficiency that is about\none order of magnitude higher than that of the best reported integrated APDs on\nsilicon at a similar GBP of 270 GHz. Bitrate measurements show data rate\nspatial density above 800 Tbps per mm2, and an energy-per-bit consumption of\nonly 6 fJ/bit at 3 Gbps. These unique features suggest new opportunities for\ncreating highly efficient and compact on-chip optical receivers based on\ndevices with type-II band alignment.",
            "author": [
                "Lining Liu",
                "Simone Bianconi",
                "Skylar Wheaton",
                "Nathaniel Coirier",
                "Farah Fahim",
                "Hooman Mohseni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03921v1",
                "http://arxiv.org/pdf/2311.03921v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03920v1",
            "title": "An Intelligent Edge-Deployable Indoor Air Quality Monitoring and\n  Activity Recognition Approach",
            "updated": "2023-11-07T11:58:11Z",
            "published": "2023-11-07T11:58:11Z",
            "summary": "The surveillance of indoor air quality is paramount for ensuring\nenvironmental safety, a task made increasingly viable due to advancements in\ntechnology and the application of artificial intelligence and deep learning\n(DL) tools. This paper introduces an intelligent system dedicated to monitoring\nair quality and categorizing activities within indoor environments using a DL\napproach based on 1D Convolutional Neural Networks (1D-CNNs). Our system\nintegrates six diverse sensors to gather measurement parameters, which\nsubsequently train a 1D CNN model for activity recognition. This proposed model\nboasts a lightweight and edge-deployable design, rendering it ideal for\nreal-time applications. We conducted our experiments utilizing an air quality\ndataset specifically designed for Activity of Daily Living (ADL)\nclassification. The results illustrate the proposed model's efficacy, achieving\na remarkable accuracy of 97.00%, a minimal loss value of 0.15%, and a swift\nprediction time of 41 milliseconds.",
            "author": [
                "Mohamed Rafik Aymene Berkani",
                "Ammar Chouchane",
                "Yassine Himeur",
                "Abdelmalik Ouamane",
                "Abbes Amira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03920v1",
                "http://arxiv.org/pdf/2311.03920v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03912v1",
            "title": "FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer",
            "updated": "2023-11-07T11:51:33Z",
            "published": "2023-11-07T11:51:33Z",
            "summary": "Vision Transformers (ViT) have recently demonstrated success across a myriad\nof computer vision tasks. However, their elevated computational demands pose\nsignificant challenges for real-world deployment. While low-rank approximation\nstands out as a renowned method to reduce computational loads, efficiently\nautomating the target rank selection in ViT remains a challenge. Drawing from\nthe notable similarity and alignment between the processes of rank selection\nand One-Shot NAS, we introduce FLORA, an end-to-end automatic framework based\non NAS. To overcome the design challenge of supernet posed by vast search\nspace, FLORA employs a low-rank aware candidate filtering strategy. This method\nadeptly identifies and eliminates underperforming candidates, effectively\nalleviating potential undertraining and interference among subnetworks. To\nfurther enhance the quality of low-rank supernets, we design a low-rank\nspecific training paradigm. First, we propose weight inheritance to construct\nsupernet and enable gradient sharing among low-rank modules. Secondly, we adopt\nlow-rank aware sampling to strategically allocate training resources, taking\ninto account inherited information from pre-trained models. Empirical results\nunderscore FLORA's efficacy. With our method, a more fine-grained rank\nconfiguration can be generated automatically and yield up to 33% extra FLOPs\nreduction compared to a simple uniform configuration. More specific,\nFLORA-DeiT-B/FLORA-Swin-B can save up to 55%/42% FLOPs almost without\nperformance degradtion. Importantly, FLORA boasts both versatility and\northogonality, offering an extra 21%-26% FLOPs reduction when integrated with\nleading compression techniques or compact hybrid structures. Our code is\npublicly available at https://github.com/shadowpa0327/FLORA.",
            "author": [
                "Chi-Chih Chang",
                "Yuan-Yao Sung",
                "Shixing Yu",
                "Ning-Chi Huang",
                "Diana Marculescu",
                "Kai-Chiang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03912v1",
                "http://arxiv.org/pdf/2311.03912v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03910v1",
            "title": "Structure of universal formulas",
            "updated": "2023-11-07T11:50:25Z",
            "published": "2023-11-07T11:50:25Z",
            "summary": "By universal formulas we understand parameterized analytic expressions that\nhave a fixed complexity, but nevertheless can approximate any continuous\nfunction on a compact set. There exist various examples of such formulas,\nincluding some in the form of neural networks. In this paper we analyze the\nessential structural elements of these highly expressive models. We introduce a\nhierarchy of expressiveness classes connecting the global approximability\nproperty to the weaker property of infinite VC dimension, and prove a series of\nclassification results for several increasingly complex functional families. In\nparticular, we introduce a general family of\npolynomially-exponentially-algebraic functions that, as we prove, is subject to\npolynomial constraints. As a consequence, we show that fixed-size neural\nnetworks with not more than one layer of neurons having transcendental\nactivations (e.g., sine or standard sigmoid) cannot in general approximate\nfunctions on arbitrary finite sets. On the other hand, we give examples of\nfunctional families, including two-hidden-layer neural networks, that\napproximate functions on arbitrary finite sets, but fail to do that on the\nwhole domain of definition.",
            "author": [
                "Dmitry Yarotsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03910v1",
                "http://arxiv.org/pdf/2311.03910v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "cs.NE",
                "math.CA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03908v1",
            "title": "Direct reduction of iron-ore with hydrogen in fluidized beds: A\n  coarse-grained CFD-DEM-IBM study",
            "updated": "2023-11-07T11:48:08Z",
            "published": "2023-11-07T11:48:08Z",
            "summary": "Hydrogen metallurgy technology uses hydrogen as the reducing agent instead of\ncarbon reduction, which is one of the important ways to reduce carbon dioxide\nemissions and ensure the green and sustainable development of iron and steel\nindustry. Due to the advantages of high gas-solid contact efficiency and\noutstanding mass and heat transfer, direct reduction of iron ore in fluidized\nbeds has attracted much attention. In this study, a coarse-grained CFD-DEM-IBM\nsolver based on hybrid CPU-GPU computing is developed to simulate the direct\nreduction process of two kinds of iron ore with hydrogen in fluidized beds,\nwhere an unreacted shrinking core model based on multiple reaction paths is\nused to model the reduction reactions, a coarse-grained model and multiple GPUs\nenable the significant acceleration of particle computation, and the immersed\nboundary method (IBM) enables the use of simple mesh even in complex geometries\nof reactors. The predicted results of particle reduction degree are in good\nagreement with the experimental values, which proves the correctness of the\nCFD-DEM-IBM solver. In addition, the effects of reaction kinetic parameters and\noperating temperature on particle reduction degree are also investigated.\nPresent study provides a method for digital design, optimization and scale-up\nof ironmaking reactors.",
            "author": [
                "Bin Lan",
                "Ji Xu",
                "Shuai Lu",
                "Yige Liu",
                "Fan Xu",
                "Bidan Zhao",
                "Zheng Zou",
                "Ming Zhai",
                "Junwu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03908v1",
                "http://arxiv.org/pdf/2311.03908v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03907v1",
            "title": "The Polyakov loop models in the large N limit: Correlation function and\n  screening masses",
            "updated": "2023-11-07T11:47:24Z",
            "published": "2023-11-07T11:47:24Z",
            "summary": "We explore the 't Hooft-Veneziano limit of the Polyakov loop models at finite\nbaryon chemical potential. Using methods developed by us earlier we calculate\nthe two- and $N$-point correlation functions of the Polyakov loops. This gives\na possibility to compute the various potentials in the confinement phase and to\nderive the screening masses outside the confinement region. In particular, we\nestablish the existence of complex masses and an oscillating decay of\ncorrelations in a certain range of parameters. Furthermore, it is shown that\nthe calculation of the $N$-point correlation function in the confinement phase\nreduces to the geometric median problem. This leads to a large $N$ analog of\nthe $Y$ law for the baryon potential.",
            "author": [
                "O. Borisenko",
                "V. Chelnokov",
                "S. Voloshyn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03907v1",
                "http://arxiv.org/pdf/2311.03907v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "hep-th",
                "81T25 (Primary) 81V05, 82B26 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03904v1",
            "title": "RobustMat: Neural Diffusion for Street Landmark Patch Matching under\n  Challenging Environments",
            "updated": "2023-11-07T11:37:20Z",
            "published": "2023-11-07T11:37:20Z",
            "summary": "For autonomous vehicles (AVs), visual perception techniques based on sensors\nlike cameras play crucial roles in information acquisition and processing. In\nvarious computer perception tasks for AVs, it may be helpful to match landmark\npatches taken by an onboard camera with other landmark patches captured at a\ndifferent time or saved in a street scene image database. To perform matching\nunder challenging driving environments caused by changing seasons, weather, and\nillumination, we utilize the spatial neighborhood information of each patch. We\npropose an approach, named RobustMat, which derives its robustness to\nperturbations from neural differential equations. A convolutional neural ODE\ndiffusion module is used to learn the feature representation for the landmark\npatches. A graph neural PDE diffusion module then aggregates information from\nneighboring landmark patches in the street scene. Finally, feature similarity\nlearning outputs the final matching score. Our approach is evaluated on several\nstreet scene datasets and demonstrated to achieve state-of-the-art matching\nresults under environmental perturbations.",
            "author": [
                "Rui She",
                "Qiyu Kang",
                "Sijie Wang",
                "Yuan-Rui Yang",
                "Kai Zhao",
                "Yang Song",
                "Wee Peng Tay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03904v1",
                "http://arxiv.org/pdf/2311.03904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04251v1",
            "title": "MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters",
            "updated": "2023-11-07T11:37:08Z",
            "published": "2023-11-07T11:37:08Z",
            "summary": "Most deep neural networks are trained under fixed network architectures and\nrequire retraining when the architecture changes. If expanding the network's\nsize is needed, it is necessary to retrain from scratch, which is expensive. To\navoid this, one can grow from a small network by adding random weights over\ntime to gradually achieve the target network size. However, this naive approach\nfalls short in practice as it brings too much noise to the growing process.\nPrior work tackled this issue by leveraging the already learned weights and\ntraining data for generating new weights through conducting a computationally\nexpensive analysis step. In this paper, we introduce MixtureGrowth, a new\napproach to growing networks that circumvents the initialization overhead in\nprior work. Before growing, each layer in our model is generated with a linear\ncombination of parameter templates. Newly grown layer weights are generated by\nusing a new linear combination of existing templates for a layer. On one hand,\nthese templates are already trained for the task, providing a strong\ninitialization. On the other, the new coefficients provide flexibility for the\nadded layer weights to learn something new. We show that our approach boosts\ntop-1 accuracy over the state-of-the-art by 2-2.5% on CIFAR-100 and ImageNet\ndatasets, while achieving comparable performance with fewer FLOPs to a larger\nnetwork trained from scratch. Code is available at\nhttps://github.com/chaudatascience/mixturegrowth.",
            "author": [
                "Chau Pham",
                "Piotr Teterwak",
                "Soren Nelson",
                "Bryan A. Plummer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04251v1",
                "http://arxiv.org/pdf/2311.04251v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03901v1",
            "title": "Parikh's Theorem Made Symbolic",
            "updated": "2023-11-07T11:31:13Z",
            "published": "2023-11-07T11:31:13Z",
            "summary": "Parikh's Theorem is a fundamental result in automata theory with numerous\napplications in computer science: software verification (e.g. infinite-state\nverification, string constraints, and theory of arrays), verification of\ncryptographic protocols (e.g. using Horn clauses modulo equational theories)\nand database querying (e.g. evaluating path-queries in graph databases).\nParikh's Theorem states that the letter-counting abstraction of a language\nrecognized by finite automata or context-free grammars is definable in\nPresburger Arithmetic. Unfortunately, real-world applications typically require\nlarge alphabets - which are well-known to be not amenable to explicit treatment\nof the alphabets.\n  Symbolic automata have proven in the last decade to be an effective\nalgorithmic framework for handling large finite or even infinite alphabets. A\nsymbolic automaton employs an effective boolean algebra, which offers a\nsymbolic representation of character sets and often lends itself to an\nexponentially more succinct representation of a language. Instead of\nletter-counting, Parikh's Theorem for symbolic automata amounts to counting the\nnumber of times different predicates are satisfied by an input sequence.\nUnfortunately, naively applying Parikh's Theorem from classical automata theory\nto symbolic automata yields existential Presburger formulas of exponential\nsize. We provide a new construction for Parikh's Theorem for symbolic automata\nand grammars, which avoids this exponential blowup: our algorithm computes an\nexistential formula in polynomial-time over (quantifier-free) Presburger and\nthe base theory. In fact, our algorithm extends to the model of parametric\nsymbolic grammars, which are one of the most expressive models of languages\nover infinite alphabets. We have implemented our algorithm and show it can be\nused to solve string constraints that are difficult to solve by existing\nsolvers.",
            "author": [
                "Matthew Hague",
                "Artur Je\u017c",
                "Anthony W. Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03901v1",
                "http://arxiv.org/pdf/2311.03901v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03900v1",
            "title": "Why Fair Automated Hiring Systems Breach EU Non-Discrimination Law",
            "updated": "2023-11-07T11:31:00Z",
            "published": "2023-11-07T11:31:00Z",
            "summary": "Employment selection processes that use automated hiring systems based on\nmachine learning are becoming increasingly commonplace. Meanwhile, concerns\nabout algorithmic direct and indirect discrimination that result from such\nsystems are front-and-center, and the technical solutions provided by the\nresearch community often systematically deviate from the principle of equal\ntreatment to combat disparate or adverse impacts on groups based on protected\nattributes. Those technical solutions are now being used in commercially\navailable automated hiring systems, potentially engaging in real-world\ndiscrimination. Algorithmic fairness and algorithmic non-discrimination are not\nthe same. This article examines a conflict between the two: whether such hiring\nsystems are compliant with EU non-discrimination law.",
            "author": [
                "Robert Lee Poe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03900v1",
                "http://arxiv.org/pdf/2311.03900v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17282v1",
            "title": "Reducing energy consumption of cloud data centers using proper placement\n  of virtual machines",
            "updated": "2023-11-07T11:30:44Z",
            "published": "2023-11-07T11:30:44Z",
            "summary": "In today's world, the use of cloud data centers for easy access to data and\nprocessing resources is expanding rapidly. Rapid technology growth and\nincreasing number of users make hardware and software architectures upgrade a\nconstant need. The necessary infrastructure to implement this architecture is\nthe use of virtual machines in physical systems. The main issue in this\narchitecture is how to allocate virtual machines to physical machines on the\nnetwork. In this paper we have proposed a method to use virtualization for\nminimizing energy consumption and decreasing the cloud resource waste. We have\nused learning automata as a reinforcement learning model for optimal placement\nof virtual machines. The simulation results show the proposed method has good\nperformance in reducing energy consumption of servers in cloud data centers.",
            "author": [
                "Hamid Reza Naji",
                "Reza Esmaeili"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17282v1",
                "http://arxiv.org/pdf/2311.17282v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03899v1",
            "title": "Learning-Based Latency-Constrained Fronthaul Compression Optimization in\n  C-RAN",
            "updated": "2023-11-07T11:26:26Z",
            "published": "2023-11-07T11:26:26Z",
            "summary": "The evolution of wireless mobile networks towards cloudification, where Radio\nAccess Network (RAN) functions can be hosted at either a central or distributed\nlocations, offers many benefits like low cost deployment, higher capacity, and\nimproved hardware utilization. Nevertheless, the flexibility in the functional\ndeployment comes at the cost of stringent fronthaul (FH) capacity and latency\nrequirements. One possible approach to deal with these rigorous constraints is\nto use FH compression techniques. To ensure that FH capacity and latency\nrequirements are met, more FH compression is applied during high load, while\nless compression is applied during medium and low load to improve FH\nutilization and air interface performance. In this paper, a model-free deep\nreinforcement learning (DRL) based FH compression (DRL-FC) framework is\nproposed that dynamically controls FH compression through various configuration\nparameters such as modulation order, precoder granularity, and precoder weight\nquantization that affect both FH load and air interface performance. Simulation\nresults show that DRL-FC exhibits significantly higher FH utilization (68.7% on\naverage) and air interface throughput than a reference scheme (i.e. with no\napplied compression) across different FH load levels. At the same time, the\nproposed DRL-FC framework is able to meet the predefined FH latency constraints\n(in our case set to 260 $\\mu$s) under various FH loads.",
            "author": [
                "Axel Gr\u00f6nland",
                "Bleron Klaiqi",
                "Xavier Gelabert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03899v1",
                "http://arxiv.org/pdf/2311.03899v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03896v1",
            "title": "iACOS: Advancing Implicit Sentiment Extraction with Informative and\n  Adaptive Negative Examples",
            "updated": "2023-11-07T11:19:06Z",
            "published": "2023-11-07T11:19:06Z",
            "summary": "Aspect-based sentiment analysis (ABSA) have been extensively studied, but\nlittle light has been shed on the quadruple extraction consisting of four\nfundamental elements: aspects, categories, opinions and sentiments, especially\nwith implicit aspects and opinions. In this paper, we propose a new method\niACOS for extracting Implicit Aspects with Categories and Opinions with\nSentiments. First, iACOS appends two implicit tokens at the end of a text to\ncapture the context-aware representation of all tokens including implicit\naspects and opinions. Second, iACOS develops a sequence labeling model over the\ncontext-aware token representation to co-extract explicit and implicit aspects\nand opinions. Third, iACOS devises a multi-label classifier with a specialized\nmulti-head attention for discovering aspect-opinion pairs and predicting their\ncategories and sentiments simultaneously. Fourth, iACOS leverages informative\nand adaptive negative examples to jointly train the multi-label classifier and\nthe other two classifiers on categories and sentiments by multi-task learning.\nFinally, the experimental results show that iACOS significantly outperforms\nother quadruple extraction baselines according to the F1 score on two public\nbenchmark datasets.",
            "author": [
                "Xiancai Xu",
                "Jia-Dong Zhang",
                "Lei Xiong",
                "Zhishang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03896v1",
                "http://arxiv.org/pdf/2311.03896v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04250v1",
            "title": "Unifying Structure and Language Semantic for Efficient Contrastive\n  Knowledge Graph Completion with Structured Entity Anchors",
            "updated": "2023-11-07T11:17:55Z",
            "published": "2023-11-07T11:17:55Z",
            "summary": "The goal of knowledge graph completion (KGC) is to predict missing links in a\nKG using trained facts that are already known. In recent, pre-trained language\nmodel (PLM) based methods that utilize both textual and structural information\nare emerging, but their performances lag behind state-of-the-art (SOTA)\nstructure-based methods or some methods lose their inductive inference\ncapabilities in the process of fusing structure embedding to text encoder. In\nthis paper, we propose a novel method to effectively unify structure\ninformation and language semantics without losing the power of inductive\nreasoning. We adopt entity anchors and these anchors and textual description of\nKG elements are fed together into the PLM-based encoder to learn unified\nrepresentations. In addition, the proposed method utilizes additional random\nnegative samples which can be reused in the each mini-batch during contrastive\nlearning to learn a generalized entity representations. We verify the\neffectiveness of the our proposed method through various experiments and\nanalysis. The experimental results on standard benchmark widely used in link\nprediction task show that the proposed model outperforms existing the SOTA KGC\nmodels. Especially, our method show the largest performance improvement on\nFB15K-237, which is competitive to the SOTA of structure-based KGC methods.",
            "author": [
                "Sang-Hyun Je",
                "Wontae Choi",
                "Kwangjin Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04250v1",
                "http://arxiv.org/pdf/2311.04250v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16147v1",
            "title": "Load balancing in cloud data centers with optimized virtual machines\n  placement",
            "updated": "2023-11-07T11:08:13Z",
            "published": "2023-11-07T11:08:13Z",
            "summary": "So far, various solutions have been proposed for symmetric distribution of\nload cloud computing environments. In this article, a new solution to the\noptimal allocation of virtual machines in the cloud data centers is presented\nto provide a good load balancing among servers. The proposed method offers a\nsolution uses learning automata as a reinforcement learning model to improve\nthe performance of the optimization algorithm for optimal placement of virtual\nmachines. Also, it helps the search algorithm to converge more quickly to the\nglobal optimum. The simulation results show the proposed method has been able\nto perform good level of load balancing in cloud data centers.",
            "author": [
                "Hamid Reza naji",
                "Reza Esmaeili"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16147v1",
                "http://arxiv.org/pdf/2311.16147v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03889v1",
            "title": "Efficiently Detecting Performance Changes in FaaS Application Releases",
            "updated": "2023-11-07T11:08:04Z",
            "published": "2023-11-07T11:08:04Z",
            "summary": "The source code of Function as a Service (FaaS) applications is constantly\nbeing refined. To detect if a source code change introduces a significant\nperformance regression, the traditional benchmarking approach evaluates both\nthe old and new function version separately using numerous artificial requests.\n  In this paper, we describe a wrapper approach that enables the Randomized\nMultiple Interleaved Trials (RMIT) benchmark execution methodology in FaaS\nenvironments and use bootstrapping percentile intervals to derive more accurate\nconfidence intervals of detected performance changes. We evaluate our approach\nusing two public FaaS providers, an artificial performance issue, and several\nbenchmark configuration parameters. We conclude that RMIT can shrink the width\nof confidence intervals in the results from 10.65% using the traditional\napproach to 0.37% using RMIT and thus enables a more fine-grained performance\nchange detection.",
            "author": [
                "Martin Grambow",
                "Tim Dockenfu\u00df",
                "Trever Schirmer",
                "Nils Japke",
                "David Bermbach"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3631295.3631395",
                "http://arxiv.org/abs/2311.03889v1",
                "http://arxiv.org/pdf/2311.03889v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03885v1",
            "title": "A New Branching Rule for Range Minimization Problems",
            "updated": "2023-11-07T10:59:25Z",
            "published": "2023-11-07T10:59:25Z",
            "summary": "We consider range minimization problems featuring exponentially many\nvariables, as frequently arising in fairness-oriented or bi-objective\noptimization. While branch-and-price is successful at solving cost-oriented\nproblems with many variables, the performance of classical branch-and-price\nalgorithms for range minimization is drastically impaired by weak linear\nprogramming relaxations. We propose range branching, a generic branching rule\nthat directly tackles this issue and is compatible with any problem-specific\nbranching scheme. We show several desirable properties of range branching and\nshow its effectiveness on a series of fair capacitated vehicle routing\ninstances. Range branching outperforms multiple classical branching schemes in\nterms of computing time, optimality gap, and size of the branch-and-bound tree,\nallowing us to solve many more large instances than classical methods.",
            "author": [
                "Bart van Rossum",
                "Rui Chen",
                "Andrea Lodi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03885v1",
                "http://arxiv.org/pdf/2311.03885v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03884v1",
            "title": "MeVGAN: GAN-based Plugin Model for Video Generation with Applications in\n  Colonoscopy",
            "updated": "2023-11-07T10:58:16Z",
            "published": "2023-11-07T10:58:16Z",
            "summary": "Video generation is important, especially in medicine, as much data is given\nin this form. However, video generation of high-resolution data is a very\ndemanding task for generative models, due to the large need for memory. In this\npaper, we propose Memory Efficient Video GAN (MeVGAN) - a Generative\nAdversarial Network (GAN) which uses plugin-type architecture. We use a\npre-trained 2D-image GAN and only add a simple neural network to construct\nrespective trajectories in the noise space, so that the trajectory forwarded\nthrough the GAN model constructs a real-life video. We apply MeVGAN in the task\nof generating colonoscopy videos. Colonoscopy is an important medical\nprocedure, especially beneficial in screening and managing colorectal cancer.\nHowever, because colonoscopy is difficult and time-consuming to learn,\ncolonoscopy simulators are widely used in educating young colonoscopists. We\nshow that MeVGAN can produce good quality synthetic colonoscopy videos, which\ncan be potentially used in virtual simulators.",
            "author": [
                "\u0141ukasz Struski",
                "Tomasz Urba\u0144czyk",
                "Krzysztof Bucki",
                "Bart\u0142omiej Cupia\u0142",
                "Aneta Kaczy\u0144ska",
                "Przemys\u0142aw Spurek",
                "Jacek Tabor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03884v1",
                "http://arxiv.org/pdf/2311.03884v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03882v1",
            "title": "Odd nuclei and quasiparticle excitations with the Barcelona Catania\n  Paris Madrid energy density functional",
            "updated": "2023-11-07T10:56:33Z",
            "published": "2023-11-07T10:56:33Z",
            "summary": "An extension of the Barcelona Catania Paris Madrid (BCPM) energy density\nfunctional is proposed to deal with odd mass systems as well as quasiparticle\nexcitations. The extension is based on the assumption that the equal filling\napproximation (EFA) with its time-even densities is a very good substitute of\nthe traditional full blocking of the Hartree-Fock-Bogoliubov method. The\nassumption is supported by the excellent agreement of full blocking results\nwith those of EFA for Gogny forces and Skyrme functionals. The EFA augmented\nBCPM functional is used to compute low energy excitation spectra of selected\nnuclei in different regions of the nuclear chart. We show that BCPM predictions\nare in good agreement with Gogny D1M ones. As an example of multiquasiparticle\nexcitations, high-$K$ isomers in 178HF are also studied.",
            "author": [
                "S. A. Giuliani",
                "L. M. Robledo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03882v1",
                "http://arxiv.org/pdf/2311.03882v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03881v1",
            "title": "Sparse Contrastive Learning of Sentence Embeddings",
            "updated": "2023-11-07T10:54:45Z",
            "published": "2023-11-07T10:54:45Z",
            "summary": "Recently, SimCSE has shown the feasibility of contrastive learning in\ntraining sentence embeddings and illustrates its expressiveness in spanning an\naligned and uniform embedding space. However, prior studies have shown that\ndense models could contain harmful parameters that affect the model\nperformance, and it is no wonder that SimCSE can as well be invented with such\nparameters. Driven by this, parameter sparsification is applied, where\nalignment and uniformity scores are used to measure the contribution of each\nparameter to the overall quality of sentence embeddings. Drawing from a\npreliminary study, we consider parameters with minimal contributions to be\ndetrimental, as their sparsification results in improved model performance. To\ndiscuss the ubiquity of detrimental parameters and remove them, more\nexperiments on the standard semantic textual similarity (STS) tasks and\ntransfer learning tasks are conducted, and the results show that the proposed\nsparsified SimCSE (SparseCSE) has excellent performance in comparison with\nSimCSE. Furthermore, through in-depth analysis, we establish the validity and\nstability of our sparsification method, showcasing that the embedding space\ngenerated by SparseCSE exhibits improved alignment compared to that produced by\nSimCSE. Importantly, the uniformity yet remains uncompromised.",
            "author": [
                "Ruize An",
                "Chen Zhang",
                "Dawei Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03881v1",
                "http://arxiv.org/pdf/2311.03881v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03873v1",
            "title": "Mini but Mighty: Finetuning ViTs with Mini Adapters",
            "updated": "2023-11-07T10:41:27Z",
            "published": "2023-11-07T10:41:27Z",
            "summary": "Vision Transformers (ViTs) have become one of the dominant architectures in\ncomputer vision, and pre-trained ViT models are commonly adapted to new tasks\nvia fine-tuning. Recent works proposed several parameter-efficient transfer\nlearning methods, such as adapters, to avoid the prohibitive training and\nstorage cost of finetuning. In this work, we observe that adapters perform\npoorly when the dimension of adapters is small, and we propose MiMi, a training\nframework that addresses this issue. We start with large adapters which can\nreach high performance, and iteratively reduce their size. To enable automatic\nestimation of the hidden dimension of every adapter, we also introduce a new\nscoring function, specifically designed for adapters, that compares the neuron\nimportance across layers. Our method outperforms existing methods in finding\nthe best trade-off between accuracy and trained parameters across the three\ndataset benchmarks DomainNet, VTAB, and Multi-task, for a total of 29 datasets.",
            "author": [
                "Imad Eddine Marouf",
                "Enzo Tartaglione",
                "St\u00e9phane Lathuili\u00e8re"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03873v1",
                "http://arxiv.org/pdf/2311.03873v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03867v1",
            "title": "A Comparative Study of Knowledge Transfer Methods for Misaligned Urban\n  Building Labels",
            "updated": "2023-11-07T10:31:41Z",
            "published": "2023-11-07T10:31:41Z",
            "summary": "Misalignment in Earth observation (EO) images and building labels impact the\ntraining of accurate convolutional neural networks (CNNs) for semantic\nsegmentation of building footprints. Recently, three Teacher-Student knowledge\ntransfer methods have been introduced to address this issue: supervised domain\nadaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML).\nHowever, these methods are merely studied for different urban buildings\n(low-rise, mid-rise, high-rise, and skyscrapers), where misalignment increases\nwith building height and spatial resolution. In this study, we present a\nworkflow for the systematic comparative study of the three methods. The\nworkflow first identifies the best (with the highest evaluation scores)\nhyperparameters, lightweight CNNs for the Student (among 43 CNNs from Computer\nVision), and encoder-decoder networks (EDNs) for both Teachers and Students.\nSecondly, three building footprint datasets are developed to train and evaluate\nthe identified Teachers and Students in the three transfer methods. The results\nshow that U-Net with VGG19 (U-VGG19) is the best Teacher, and\nU-EfficientNetv2B3 and U-EfficientNet-lite0 are among the best Students. With\nthese Teacher-Student pairs, SDA could yield upto 0.943, 0.868, 0.912, and\n0.697 F1 scores in the low-rise, mid-rise, high-rise, and skyscrapers\nrespectively. KD and DML provide model compression of upto 82%, despite\nmarginal loss in performance. This new comparison concludes that SDA is the\nmost effective method to address the misalignment problem, while KD and DML can\nefficiently compress network size without significant loss in performance. The\n158 experiments and datasets developed in this study will be valuable to\nminimise the misaligned labels.",
            "author": [
                "Bipul Neupane",
                "Jagannath Aryal",
                "Abbas Rajabifard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03867v1",
                "http://arxiv.org/pdf/2311.03867v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03866v1",
            "title": "SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial\n  Network for an end-to-end image translation",
            "updated": "2023-11-07T10:29:16Z",
            "published": "2023-11-07T10:29:16Z",
            "summary": "SCONE-GAN presents an end-to-end image translation, which is shown to be\neffective for learning to generate realistic and diverse scenery images. Most\ncurrent image-to-image translation approaches are devised as two mappings: a\ntranslation from the source to target domain and another to represent its\ninverse. While successful in many applications, these approaches may suffer\nfrom generating trivial solutions with limited diversity. That is because these\nmethods learn more frequent associations rather than the scene structures. To\nmitigate the problem, we propose SCONE-GAN that utilises graph convolutional\nnetworks to learn the objects dependencies, maintain the image structure and\npreserve its semantics while transferring images into the target domain. For\nmore realistic and diverse image generation we introduce style reference image.\nWe enforce the model to maximize the mutual information between the style image\nand output. The proposed method explicitly maximizes the mutual information\nbetween the related patches, thus encouraging the generator to produce more\ndiverse images. We validate the proposed algorithm for image-to-image\ntranslation and stylizing outdoor images. Both qualitative and quantitative\nresults demonstrate the effectiveness of our approach on four dataset.",
            "author": [
                "Iman Abbasnejad",
                "Fabio Zambetta",
                "Flora Salim",
                "Timothy Wiley",
                "Jeffrey Chan",
                "Russell Gallagher",
                "Ehsan Abbasnejad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03866v1",
                "http://arxiv.org/pdf/2311.03866v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03863v1",
            "title": "An Explainable Framework for Machine learning-Based Reactive Power\n  Optimization of Distribution Network",
            "updated": "2023-11-07T10:24:03Z",
            "published": "2023-11-07T10:24:03Z",
            "summary": "To reduce the heavy computational burden of reactive power optimization of\ndistribution networks, machine learning models are receiving increasing\nattention. However, most machine learning models (e.g., neural networks) are\nusually considered as black boxes, making it challenging for power system\noperators to identify and comprehend potential biases or errors in the\ndecision-making process of machine learning models. To address this issue, an\nexplainable machine-learning framework is proposed to optimize the reactive\npower in distribution networks. Firstly, a Shapley additive explanation\nframework is presented to measure the contribution of each input feature to the\nsolution of reactive power optimizations generated from machine learning\nmodels. Secondly, a model-agnostic approximation method is developed to\nestimate Shapley values, so as to avoid the heavy computational burden\nassociated with direct calculations of Shapley values. The simulation results\nshow that the proposed explainable framework can accurately explain the\nsolution of the machine learning model-based reactive power optimization by\nusing visual analytics, from both global and instance perspectives. Moreover,\nthe proposed explainable framework is model-agnostic, and thus applicable to\nvarious models (e.g., neural networks).",
            "author": [
                "Wenlong Liao",
                "Benjamin Sch\u00e4fer",
                "Dalin Qin",
                "Gonghao Zhang",
                "Zhixian Wang",
                "Zhe Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03863v1",
                "http://arxiv.org/pdf/2311.03863v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03855v1",
            "title": "Terrain Recognition and Contact Force Estimation through a Sensorized\n  Paw for Legged Robots",
            "updated": "2023-11-07T10:13:12Z",
            "published": "2023-11-07T10:13:12Z",
            "summary": "This paper introduces the Terrain Recognition And Contact Force Estimation\nPaw, a compact and sensorized shoe designed for legged robots. The paw\nend-effector is made of silicon that deforms upon the application of contact\nforces, while an embedded micro camera is utilized to capture images of the\ndeformed inner surface inside the shoe, and a microphone picks up audio\nsignals. Processed through machine learning techniques, the images are mapped\nto compute an accurate estimate of the cumulative 3D force vector, while the\naudio signals are analyzed to identify the terrain class (e.g., gravel, snow).\nBy leveraging its on-edge computation ability, the paw enhances the\ncapabilities of legged robots by providing key information in real-time that\ncan be used to adapt locomotion control strategies. To assess the performance\nof this novel sensorized paw, we conducted experiments on the data collected\nthrough a specially-designed testbed for force estimation, as well as data from\nrecordings of the audio signatures of different terrains interacting with the\npaw. The results demonstrate the accuracy and effectiveness of the system,\nhighlighting its potential for improving legged robot performance.",
            "author": [
                "Aleksander Vangen",
                "Tejal Barnwal",
                "J\u00f8rgen Anker Olsen",
                "Kostas Alexis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03855v1",
                "http://arxiv.org/pdf/2311.03855v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04932v1",
            "title": "GC-VTON: Predicting Globally Consistent and Occlusion Aware Local Flows\n  with Neighborhood Integrity Preservation for Virtual Try-on",
            "updated": "2023-11-07T10:09:49Z",
            "published": "2023-11-07T10:09:49Z",
            "summary": "Flow based garment warping is an integral part of image-based virtual try-on\nnetworks. However, optimizing a single flow predicting network for simultaneous\nglobal boundary alignment and local texture preservation results in sub-optimal\nflow fields. Moreover, dense flows are inherently not suited to handle\nintricate conditions like garment occlusion by body parts or by other garments.\nForcing flows to handle the above issues results in various distortions like\ntexture squeezing, and stretching. In this work, we propose a novel approach\nwhere we disentangle the global boundary alignment and local texture preserving\ntasks via our GlobalNet and LocalNet modules. A consistency loss is then\nemployed between the two modules which harmonizes the local flows with the\nglobal boundary alignment. Additionally, we explicitly handle occlusions by\npredicting body-parts visibility mask, which is used to mask out the occluded\nregions in the warped garment. The masking prevents the LocalNet from\npredicting flows that distort texture to compensate for occlusions. We also\nintroduce a novel regularization loss (NIPR), that defines a criteria to\nidentify the regions in the warped garment where texture integrity is violated\n(squeezed or stretched). NIPR subsequently penalizes the flow in those regions\nto ensure regular and coherent warps that preserve the texture in local\nneighborhoods. Evaluation on a widely used virtual try-on dataset demonstrates\nstrong performance of our network compared to the current SOTA methods.",
            "author": [
                "Hamza Rawal",
                "Muhammad Junaid Ahmad",
                "Farooq Zaman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04932v1",
                "http://arxiv.org/pdf/2311.04932v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03846v1",
            "title": "Shaping photons: quantum computation with bosonic cQED",
            "updated": "2023-11-07T09:59:57Z",
            "published": "2023-11-07T09:59:57Z",
            "summary": "With its rich dynamics, the quantum harmonic oscillator is an innate platform\nfor understanding real-world quantum systems, and could even excel as the heart\nof a quantum computer. A particularly promising and rapidly advancing platform\nthat harnesses quantum harmonic oscillators for information processing is the\nbosonic circuit quantum electrodynamics (cQED) system. In this article, we\nprovide perspectives on the progress, challenges, and future directions in\nbuilding a bosonic cQED quantum computer. We describe the main hardware\nbuilding blocks and how they facilitate quantum error correction, metrology,\nand simulation. We conclude with our views of the key challenges that lie on\nthe horizon, as well as scientific and cultural strategies for overcoming them\nand building a practical quantum computer with bosonic cQED hardware.",
            "author": [
                "Adrian Copetudo",
                "Clara Yun Fontaine",
                "Fernando Valadares",
                "Yvonne Y. Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03846v1",
                "http://arxiv.org/pdf/2311.03846v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07585v2",
            "title": "Input Reconstruction Attack against Vertical Federated Large Language\n  Models",
            "updated": "2023-11-24T07:46:23Z",
            "published": "2023-11-07T09:39:22Z",
            "summary": "Recently, large language models (LLMs) have drawn extensive attention from\nacademia and the public, due to the advent of the ChatGPT. While LLMs show\ntheir astonishing ability in text generation for various tasks, privacy\nconcerns limit their usage in real-life businesses. More specifically, either\nthe user's inputs (the user sends the query to the model-hosting server) or the\nmodel (the user downloads the complete model) itself will be revealed during\nthe usage. Vertical federated learning (VFL) is a promising solution to this\nkind of problem. It protects both the user's input and the knowledge of the\nmodel by splitting the model into a bottom part and a top part, which is\nmaintained by the user and the model provider, respectively. However, in this\npaper, we demonstrate that in LLMs, VFL fails to protect the user input since\nit is simple and cheap to reconstruct the input from the intermediate\nembeddings. Experiments show that even with a commercial GPU, the input\nsentence can be reconstructed in only one second. We also discuss several\npossible solutions to enhance the privacy of vertical federated LLMs.",
            "author": [
                "Fei Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07585v2",
                "http://arxiv.org/pdf/2311.07585v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03839v2",
            "title": "Aspects of human memory and Large Language Models",
            "updated": "2023-11-09T18:16:24Z",
            "published": "2023-11-07T09:39:12Z",
            "summary": "Large Language Models (LLMs) are huge artificial neural networks which\nprimarily serve to generate text, but also provide a very sophisticated\nprobabilistic model of language use. Since generating a semantically consistent\ntext requires a form of effective memory, we investigate the memory properties\nof LLMs and find surprising similarities with key characteristics of human\nmemory. We argue that the human-like memory properties of the Large Language\nModel do not follow automatically from the LLM architecture but are rather\nlearned from the statistics of the training textual data. These results\nstrongly suggest that the biological features of human memory leave an imprint\non the way that we structure our textual narratives.",
            "author": [
                "Romuald A. Janik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03839v2",
                "http://arxiv.org/pdf/2311.03839v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03837v1",
            "title": "OLaLa: Ontology Matching with Large Language Models",
            "updated": "2023-11-07T09:34:20Z",
            "published": "2023-11-07T09:34:20Z",
            "summary": "Ontology (and more generally: Knowledge Graph) Matching is a challenging task\nwhere information in natural language is one of the most important signals to\nprocess. With the rise of Large Language Models, it is possible to incorporate\nthis knowledge in a better way into the matching pipeline. A number of\ndecisions still need to be taken, e.g., how to generate a prompt that is useful\nto the model, how information in the KG can be formulated in prompts, which\nLarge Language Model to choose, how to provide existing correspondences to the\nmodel, how to generate candidates, etc. In this paper, we present a prototype\nthat explores these questions by applying zero-shot and few-shot prompting with\nmultiple open Large Language Models to different tasks of the Ontology\nAlignment Evaluation Initiative (OAEI). We show that with only a handful of\nexamples and a well-designed prompt, it is possible to achieve results that are\nen par with supervised matching systems which use a much larger portion of the\nground truth.",
            "author": [
                "Sven Hertling",
                "Heiko Paulheim"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3587259.3627571",
                "http://arxiv.org/abs/2311.03837v1",
                "http://arxiv.org/pdf/2311.03837v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03830v1",
            "title": "Reducing Spatial Fitting Error in Distillation of Denoising Diffusion\n  Models",
            "updated": "2023-11-07T09:19:28Z",
            "published": "2023-11-07T09:19:28Z",
            "summary": "Denoising Diffusion models have exhibited remarkable capabilities in image\ngeneration. However, generating high-quality samples requires a large number of\niterations. Knowledge distillation for diffusion models is an effective method\nto address this limitation with a shortened sampling process but causes\ndegraded generative quality. Based on our analysis with bias-variance\ndecomposition and experimental observations, we attribute the degradation to\nthe spatial fitting error occurring in the training of both the teacher and\nstudent model. Accordingly, we propose $\\textbf{S}$patial\n$\\textbf{F}$itting-$\\textbf{E}$rror $\\textbf{R}$eduction\n$\\textbf{D}$istillation model ($\\textbf{SFERD}$). SFERD utilizes attention\nguidance from the teacher model and a designed semantic gradient predictor to\nreduce the student's fitting error. Empirically, our proposed model facilitates\nhigh-quality sample generation in a few function evaluations. We achieve an FID\nof 5.31 on CIFAR-10 and 9.39 on ImageNet 64$\\times$64 with only one step,\noutperforming existing diffusion methods. Our study provides a new perspective\non diffusion distillation by highlighting the intrinsic denoising ability of\nmodels.",
            "author": [
                "Shengzhe Zhou",
                "Zejian Lee",
                "Shengyuan Zhang",
                "Lefan Hou",
                "Changyuan Yang",
                "Guang Yang",
                "Lingyun Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03830v1",
                "http://arxiv.org/pdf/2311.03830v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03828v2",
            "title": "Multi-view Information Integration and Propagation for Occluded Person\n  Re-identification",
            "updated": "2023-11-09T07:18:54Z",
            "published": "2023-11-07T09:17:56Z",
            "summary": "Occluded person re-identification (re-ID) presents a challenging task due to\nocclusion perturbations. Although great efforts have been made to prevent the\nmodel from being disturbed by occlusion noise, most current solutions only\ncapture information from a single image, disregarding the rich complementary\ninformation available in multiple images depicting the same pedestrian. In this\npaper, we propose a novel framework called Multi-view Information Integration\nand Propagation (MVI$^{2}$P). Specifically, realizing the potential of\nmulti-view images in effectively characterizing the occluded target pedestrian,\nwe integrate feature maps of which to create a comprehensive representation.\nDuring this process, to avoid introducing occlusion noise, we develop a\nCAMs-aware Localization module that selectively integrates information\ncontributing to the identification. Additionally, considering the divergence in\nthe discriminative nature of different images, we design a probability-aware\nQuantification module to emphatically integrate highly reliable information.\nMoreover, as multiple images with the same identity are not accessible in the\ntesting stage, we devise an Information Propagation (IP) mechanism to distill\nknowledge from the comprehensive representation to that of a single occluded\nimage. Extensive experiments and analyses have unequivocally demonstrated the\neffectiveness and superiority of the proposed MVI$^{2}$P. The code will be\nreleased at \\url{https://github.com/nengdong96/MVIIP}.",
            "author": [
                "Neng Dong",
                "Shuanglin Yan",
                "Hao Tang",
                "Jinhui Tang",
                "Liyan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03828v2",
                "http://arxiv.org/pdf/2311.03828v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03826v1",
            "title": "Accelerating Unstructured SpGEMM using Structured In-situ Computing",
            "updated": "2023-11-07T09:15:12Z",
            "published": "2023-11-07T09:15:12Z",
            "summary": "Sparse matrix-matrix multiplication (SpGEMM) is a critical kernel widely\nemployed in machine learning and graph algorithms. However, real-world\nmatrices' high sparsity makes SpGEMM memory-intensive. In-situ computing offers\nthe potential to accelerate memory-intensive applications through high\nbandwidth and parallelism. Nevertheless, the irregular distribution of\nnon-zeros renders SpGEMM a typical unstructured software. In contrast, in-situ\ncomputing platforms follow a fixed calculation manner, making them structured\nhardware. The mismatch between unstructured software and structured hardware\nleads to sub-optimal performance of current solutions.\n  In this paper, we propose SPLIM, a novel in-situ computing SpGEMM\naccelerator. SPLIM involves two innovations. First, we present a novel\ncomputation paradigm that converts SpGEMM into structured in-situ\nmultiplication and unstructured accumulation. Second, we develop a unique\ncoordinates alignment method utilizing in-situ search operations, effectively\ntransforming unstructured accumulation into high parallel searching operations.\nOur experimental results demonstrate that SPLIM achieves 275.74$\\times$\nperformance improvement and 687.19$\\times$ energy saving compared to NVIDIA RTX\nA6000 GPU.",
            "author": [
                "Huize Li",
                "Tulika Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03826v1",
                "http://arxiv.org/pdf/2311.03826v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03823v1",
            "title": "Data-informed uncertainty quantification for laser-based powder bed\n  fusion additive manufacturing",
            "updated": "2023-11-07T09:12:53Z",
            "published": "2023-11-07T09:12:53Z",
            "summary": "We present an efficient approach to quantify the uncertainties associated\nwith the numerical simulations of the laser-based powder bed fusion of metal\nprocesses. Our study focuses on a thermomechanical model of an Inconel 625\ncantilever beam, based on the AMBench2018-01 benchmark proposed by the National\nInstitute of Standards and Technology (NIST). The proposed approach consists of\na forward uncertainty quantification analysis of the residual strain of the\ncantilever beam given the uncertainty on some of the parameters of the\nnumerical simulation, namely the powder convection coefficient and the\nactivation temperature. The uncertainty on such parameters is modeled by a\ndata-informed probability density function obtained by a Bayesian inversion\nprocedure, based on the displacement experimental data provided by NIST. To\novercome the computational challenges of both the Bayesian inversion and the\nforward uncertainty quantification analysis we employ a multi-fidelity\nsurrogate modeling technique, specifically the multi-index stochastic\ncollocation method. The proposed approach allows us to achieve a 33\\% reduction\nin the uncertainties on the prediction of residual strains compared with what\nwe would get basing the forward UQ analysis on a-priori ranges for the\nuncertain parameters, and in particular the mode of the probability density\nfunction of such quantities (i.e., its ``most likely value'', roughly speaking)\nresults to be in good agreement with the experimental data provided by NIST,\neven though only displacement data were used for the Bayesian inversion\nprocedure.",
            "author": [
                "Mihaela Chiappetta",
                "Chiara Piazzola",
                "Lorenzo Tamellini",
                "Alessandro Reali",
                "Ferdinando Auricchio",
                "Massimo Carraturo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03823v1",
                "http://arxiv.org/pdf/2311.03823v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03820v1",
            "title": "High-Fidelity Multi-Scale Simulation of Swirled Air-blast Atomization\n  with Comparison against Experiments",
            "updated": "2023-11-07T09:09:11Z",
            "published": "2023-11-07T09:09:11Z",
            "summary": "In liquid-fueled combustion systems, optimization of the fuel atomization\nprocess is critical to reducing fuel consumption and lowering pollutant\nemissions. Accurate and efficient computational modeling of liquid atomization\ncan open the door to spray optimization, however it presents a significant\nchallenge to modelers due to the extremely complex flow field and wide range of\nlength and time scales involved. In this work, a multi-scale and multi-domain\nsimulation strategy is used to model end-to-end the turbulent spray produced by\na swirled two-fluid coaxial atomizer, a device that utilize a high-speed\nswirled gas stream to destabilize a co-flowing low-speed liquid, widely used in\nsystems such as fuel injectors. Our computational method relies on sub-grid\nscale modeling; in particular, we will introduce a thin structure break-up\nmodel to account for topology changes, converting thin liquid structures into\nspherical Lagrangian particles. With such simulations, the impact of swirl on\nthe break-up process can be analyzed by varying the swirl ratio, and we aim to\nquantitatively validate our simulations against experiments at identical\noperating conditions, including drop size statistics.",
            "author": [
                "Lorenzo Bruni",
                "Olivier Desjardins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03820v1",
                "http://arxiv.org/pdf/2311.03820v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03815v1",
            "title": "Integrated Sensing, Communication, and Computing for Cost-effective\n  Multimodal Federated Perception",
            "updated": "2023-11-07T08:55:56Z",
            "published": "2023-11-07T08:55:56Z",
            "summary": "Federated learning (FL) is a classic paradigm of 6G edge intelligence (EI),\nwhich alleviates privacy leaks and high communication pressure caused by\ntraditional centralized data processing in the artificial intelligence of\nthings (AIoT). The implementation of multimodal federated perception (MFP)\nservices involves three sub-processes, including sensing-based multimodal data\ngeneration, communication-based model transmission, and computing-based model\ntraining, ultimately relying on available underlying multi-domain physical\nresources such as time, frequency, and computing power. How to reasonably\ncoordinate the multi-domain resources scheduling among sensing, communication,\nand computing, therefore, is crucial to the MFP networks. To address the above\nissues, this paper investigates service-oriented resource management with\nintegrated sensing, communication, and computing (ISCC). With the incentive\nmechanism of the MFP service market, the resources management problem is\nredefined as a social welfare maximization problem, where the idea of\n\"expanding resources\" and \"reducing costs\" is used to improve learning\nperformance gain and reduce resource costs. Experimental results demonstrate\nthe effectiveness and robustness of the proposed resource scheduling\nmechanisms.",
            "author": [
                "Ning Chen",
                "Zhipeng Cheng",
                "Xuwei Fan",
                "Bangzhen Huang",
                "Yifeng Zhao",
                "Lianfen Huang",
                "Xiaojiang Du",
                "Mohsen Guizani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03815v1",
                "http://arxiv.org/pdf/2311.03815v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03814v1",
            "title": "Ultimatum game: regret or fairness?",
            "updated": "2023-11-07T08:54:02Z",
            "published": "2023-11-07T08:54:02Z",
            "summary": "In the ultimatum game, the challenge is to explain why responders reject\nnon-zero offers thereby defying classical rationality. Fairness and related\nnotions have been the main explanations so far. We explain this rejection\nbehavior via the following principle: if the responder regrets less about\nlosing the offer than the proposer regrets not offering the best option, the\noffer is rejected. This principle qualifies as a rational punishing behavior\nand it replaces the experimentally falsified classical rationality (the subgame\nperfect Nash equilibrium) that leads to accepting any non-zero offer. The\nprinciple is implemented via the transitive regret theory for probabilistic\nlotteries. The expected utility implementation is a limiting case of this. We\nshow that several experimental results normally prescribed to fairness and\nintent-recognition can be given an alternative explanation via rational\npunishment; e.g. the comparison between \"fair\" and \"superfair\", the behavior\nunder raising the stakes etc. Hence we also propose experiments that can\ndistinguish these two scenarios (fairness versus regret-based punishment). They\nassume different utilities for the proposer and responder. We focus on the\nmini-ultimatum version of the game and also show how it can emerge from a more\ngeneral setup of the game.",
            "author": [
                "Lida H. Aleksanyan",
                "Armen E. Allahverdyan",
                "Vardan G. Bardakhchyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03814v1",
                "http://arxiv.org/pdf/2311.03814v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03812v1",
            "title": "Conversations in Galician: a Large Language Model for an\n  Underrepresented Language",
            "updated": "2023-11-07T08:52:28Z",
            "published": "2023-11-07T08:52:28Z",
            "summary": "The recent proliferation of Large Conversation Language Models has\nhighlighted the economic significance of widespread access to this type of AI\ntechnologies in the current information age. Nevertheless, prevailing models\nhave primarily been trained on corpora consisting of documents written in\npopular languages. The dearth of such cutting-edge tools for low-resource\nlanguages further exacerbates their underrepresentation in the current economic\nlandscape, thereby impacting their native speakers. This paper introduces two\nnovel resources designed to enhance Natural Language Processing (NLP) for the\nGalician language. We present a Galician adaptation of the Alpaca dataset,\ncomprising 52,000 instructions and demonstrations. This dataset proves\ninvaluable for enhancing language models by fine-tuning them to more accurately\nadhere to provided instructions. Additionally, as a demonstration of the\ndataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician,\na language not originally supported by the model, by following the Alpaca\nformat. This work contributes to the research on multilingual models tailored\nfor low-resource settings, a crucial endeavor in ensuring the inclusion of all\nlinguistic communities in the development of Large Language Models. Another\nnoteworthy aspect of this research is the exploration of how knowledge of a\nclosely related language, in this case, Portuguese, can assist in generating\ncoherent text when training resources are scarce. Both the Galician Alpaca\ndataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we\nhave made the source code available to facilitate replication of this\nexperiment and encourage further advancements for underrepresented languages.",
            "author": [
                "Eliseo Bao",
                "Anxo P\u00e9rez",
                "Javier Parapar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03812v1",
                "http://arxiv.org/pdf/2311.03812v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03810v1",
            "title": "Rethinking and Improving Multi-task Learning for End-to-end Speech\n  Translation",
            "updated": "2023-11-07T08:48:46Z",
            "published": "2023-11-07T08:48:46Z",
            "summary": "Significant improvements in end-to-end speech translation (ST) have been\nachieved through the application of multi-task learning. However, the extent to\nwhich auxiliary tasks are highly consistent with the ST task, and how much this\napproach truly helps, have not been thoroughly studied. In this paper, we\ninvestigate the consistency between different tasks, considering different\ntimes and modules. We find that the textual encoder primarily facilitates\ncross-modal conversion, but the presence of noise in speech impedes the\nconsistency between text and speech representations. Furthermore, we propose an\nimproved multi-task learning (IMTL) approach for the ST task, which bridges the\nmodal gap by mitigating the difference in length and representation. We conduct\nexperiments on the MuST-C dataset. The results demonstrate that our method\nattains state-of-the-art results. Moreover, when additional data is used, we\nachieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the\ntraining time required by the current SOTA method.",
            "author": [
                "Yuhao Zhang",
                "Chen Xu",
                "Bei Li",
                "Hao Chen",
                "Tong Xiao",
                "Chunliang Zhang",
                "Jingbo Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03810v1",
                "http://arxiv.org/pdf/2311.03810v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03809v1",
            "title": "SoK: Security Below the OS -- A Security Analysis of UEFI",
            "updated": "2023-11-07T08:45:39Z",
            "published": "2023-11-07T08:45:39Z",
            "summary": "The Unified Extensible Firmware Interface (UEFI) is a linchpin of modern\ncomputing systems, governing secure system initialization and booting. This\npaper is urgently needed because of the surge in UEFI-related attacks and\nvulnerabilities in recent years. Motivated by this urgent concern, we undertake\nan extensive exploration of the UEFI landscape, dissecting its distribution\nsupply chain, booting process, and security features. We carefully study a\nspectrum of UEFI-targeted attacks and proofs of concept (PoCs) for exploiting\nUEFI-related vulnerabilities. Building upon these insights, we construct a\ncomprehensive attack threat model encompassing threat actors, attack vectors,\nattack types, vulnerabilities, attack capabilities, and attacker objectives.\nDrawing inspiration from the MITRE ATT&CK framework, we present a MITRE\nATT&CK-like taxonomy delineating tactics, techniques, and sub-techniques in the\ncontext of UEFI attacks. This taxonomy can provide a road map for identifying\nexisting gaps and developing new techniques for rootkit prevention, detection,\nand removal. Finally, the paper discusses existing countermeasures against UEFI\nattacks including a variety of technical and operational measures that can be\nimplemented to lower the risk of UEFI attacks to an acceptable level. This\npaper seeks to clarify the complexities of UEFI and equip the cybersecurity\ncommunity with the necessary knowledge to strengthen the security of this\ncritical component against a growing threat landscape.",
            "author": [
                "Priyanka Prakash Surve",
                "Oleg Brodt",
                "Mark Yampolskiy",
                "Yuval Elovici",
                "Asaf Shabtai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03809v1",
                "http://arxiv.org/pdf/2311.03809v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03808v2",
            "title": "An operad structure on the free commutative monoid over a positive\n  operad",
            "updated": "2023-11-24T19:17:41Z",
            "published": "2023-11-07T08:40:27Z",
            "summary": "We give the explicit description of an operad structure on the free\ncommutative monoid E o q generated by a given positive operad q. This\nconstruction, new up to our knowledge, does not seem to be reachable through a\ndistributive law.",
            "author": [
                "Dominique Manchon",
                "Hedi Regeiba",
                "Imen Rjaiba",
                "Yannic Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03808v2",
                "http://arxiv.org/pdf/2311.03808v2"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03806v1",
            "title": "Exploring the transformation of user interactions to Adaptive\n  Human-Machine Interfaces",
            "updated": "2023-11-07T08:38:24Z",
            "published": "2023-11-07T08:38:24Z",
            "summary": "Human-machine interfaces (HMI) facilitate communication between humans and\nmachines, and their importance has increased in modern technology. However,\ntraditional HMIs are often static and do not adapt to individual user\npreferences or behavior. Adaptive User Interfaces (AUIs) have become\nincreasingly important in providing personalized user experiences. Machine\nlearning techniques have gained traction in User Experience (UX) research to\nprovide smart adaptations that can reduce user cognitive load. This paper\npresents an ongoing exploration of a method for generating adaptive user\ninterfaces by analyzing user interactions and contextual data. It also provides\nan illustrative example using Markov chains to predict the next step for users\ninteracting with an app for an industrial mixing machine. Furthermore, the\npaper conducts an offline evaluation of the approach, focusing on the precision\nof the recommendations. The study emphasizes the importance of incorporating\nuser interactions and contextual data into the design of adaptive HMIs, while\nacknowledging the existing challenges and potential benefits.",
            "author": [
                "Angela Carrera-Rivera",
                "Daniel Reguera-Bakhache",
                "Felix Larrinaga",
                "Ganix Lasa"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3612783.3612807",
                "http://arxiv.org/abs/2311.03806v1",
                "http://arxiv.org/pdf/2311.03806v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03805v1",
            "title": "Quantum Circuit Unoptimization",
            "updated": "2023-11-07T08:38:18Z",
            "published": "2023-11-07T08:38:18Z",
            "summary": "Optimization of circuits is an essential task for both quantum and classical\ncomputers to improve their efficiency. In contrast, classical logic\noptimization is known to be difficult, and a lot of heuristic approaches have\nbeen developed so far. In this study, we define and construct a quantum\nalgorithmic primitive called quantum circuit unoptimization, which makes a\ngiven quantum circuit complex by introducing some redundancies while preserving\ncircuit equivalence, i.e., the inverse operation of circuit optimization. Using\nquantum circuit unoptimization, we propose the quantum circuit equivalence\ntest, a decision problem contained both in NP and BQP classes. Furthermore, as\na practical application, we construct concrete unoptimization recipes to\ngenerate compiler benchmarks and evaluate circuit optimization performance\nusing Qiskit and Pytket. Our numerical simulations demonstrate that quantum\ncircuit unoptimizer systematically generates redundant circuits that are\nchallenging for compilers to optimize, which can be used to compare the\nperformance of different compilers and improve them. We also offer potential\napplications of quantum circuit unoptimization, such as generating quantum\nadvantageous machine learning datasets and quantum computer fidelity\nbenchmarks.",
            "author": [
                "Yusei Mori",
                "Hideaki Hakoshima",
                "Kyohei Sudo",
                "Toshio Mori",
                "Kosuke Mitarai",
                "Keisuke Fujii"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03805v1",
                "http://arxiv.org/pdf/2311.03805v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03804v1",
            "title": "Searches for neutrino counterparts of gravitational waves from the\n  LIGO/Virgo third observing run with KM3NeT",
            "updated": "2023-11-07T08:34:09Z",
            "published": "2023-11-07T08:34:09Z",
            "summary": "The KM3NeT neutrino telescope is currently being deployed at two different\nsites in the Mediterranean Sea. First searches for astrophysical neutrinos have\nbeen performed using data taken with the partial detector configuration already\nin operation. The paper presents the results of two independent searches for\nneutrinos from compact binary mergers detected during the third observing run\nof the LIGO and Virgo gravitational wave interferometers. The first search\nlooks for a global increase in the detector counting rates that could be\nassociated with inverse beta decay events generated by MeV-scale electron\nanti-neutrinos. The second one focuses on upgoing track-like events mainly\ninduced by muon (anti-)neutrinos in the GeV--TeV energy range. Both searches\nyield no significant excess for the sources in the gravitational wave catalogs.\nFor each source, upper limits on the neutrino flux and on the total energy\nemitted in neutrinos in the respective energy ranges have been set. Stacking\nanalyses of binary black hole mergers and neutron star-black hole mergers have\nalso been performed to constrain the characteristic neutrino emission from\nthese categories.",
            "author": [
                "KM3NeT Collaboration",
                "S. Aiello",
                "A. Albert",
                "S. Alves Garre",
                "Z. Aly",
                "A. Ambrosone",
                "F. Ameli",
                "M. Andre",
                "E. Androutsou",
                "M. Anguita",
                "L. Aphecetche",
                "M. Ardid",
                "S. Ardid",
                "H. Atmani",
                "J. Aublin",
                "L. Bailly-Salins",
                "Z. Barda\u010dov\u00e1",
                "B. Baret",
                "A. Bariego-Quintana",
                "S. Basegmez du Pree",
                "Y. Becherini",
                "M. Bendahman",
                "F. Benfenati",
                "M. Benhassi",
                "D. M. Benoit",
                "E. Berbee",
                "V. Bertin",
                "S. Biagi",
                "M. Boettcher",
                "D. Bonanno",
                "J. Boumaaza",
                "M. Bouta",
                "M. Bouwhuis",
                "C. Bozza",
                "R. M. Bozza",
                "H. Br\u00e2nza\u015f",
                "F. Bretaudeau",
                "R. Bruijn",
                "J. Brunner",
                "R. Bruno",
                "E. Buis",
                "R. Buompane",
                "J. Busto",
                "B. Caiffi",
                "D. Calvo",
                "S. Campion",
                "A. Capone",
                "F. Carenini",
                "V. Carretero",
                "T. Cartraud",
                "P. Castaldi",
                "V. Cecchini",
                "S. Celli",
                "L. Cerisy",
                "M. Chabab",
                "M. Chadolias",
                "A. Chen",
                "S. Cherubini",
                "T. Chiarusi",
                "M. Circella",
                "R. Cocimano",
                "J. A. B. Coelho",
                "A. Coleiro",
                "R. Coniglione",
                "P. Coyle",
                "A. Creusot",
                "G. Cuttone",
                "R. Dallier",
                "Y. Darras",
                "A. De Benedittis",
                "B. De Martino",
                "G. De Wasseige",
                "V. Decoene",
                "R. Del Burgo",
                "I. Del Rosso",
                "U. M. Di Cerbo",
                "L. S. Di Mauro",
                "I. Di Palma",
                "A. F. D\u00edaz",
                "C. Diaz",
                "D. Diego-Tortosa",
                "C. Distefano",
                "A. Domi",
                "C. Donzaud",
                "D. Dornic",
                "M. D\u00f6rr",
                "E. Drakopoulou",
                "D. Drouhin",
                "R. Dvornick\u00fd",
                "T. Eberl",
                "E. Eckerov\u00e1",
                "A. Eddymaoui",
                "T. van Eeden",
                "M. Eff",
                "D. van Eijk",
                "I. El Bojaddaini",
                "S. El Hedri",
                "A. Enzenh\u00f6fer",
                "G. Ferrara",
                "M. D. Filipovi\u0107",
                "F. Filippini",
                "D. Franciotti",
                "L. A. Fusco",
                "J. Gabriel",
                "S. Gagliardini",
                "T. Gal",
                "J. Garc\u00eda M\u00e9ndez",
                "A. Garcia Soto",
                "C. Gatius Oliver",
                "N. Gei\u00dfelbrecht",
                "H. Ghaddari",
                "L. Gialanella",
                "B. K. Gibson",
                "E. Giorgio",
                "I. Goos",
                "P. Goswami",
                "D. Goupilliere",
                "S. R. Gozzini",
                "R. Gracia",
                "K. Graf",
                "C. Guidi",
                "B. Guillon",
                "M. Guti\u00e9rrez",
                "H. van Haren",
                "A. Heijboer",
                "A. Hekalo",
                "L. Hennig",
                "J. J. Hern\u00e1ndez-Rey",
                "W. Idrissi Ibnsalih",
                "G. Illuminati",
                "M. de Jong",
                "P. de Jong",
                "B. J. Jung",
                "P. Kalaczy\u0144ski",
                "O. Kalekin",
                "U. F. Katz",
                "A. Khatun",
                "G. Kistauri",
                "C. Kopper",
                "A. Kouchner",
                "V. Kueviakoe",
                "V. Kulikovskiy",
                "R. Kvatadze",
                "M. Labalme",
                "R. Lahmann",
                "M. Lamoureux",
                "G. Larosa",
                "C. Lastoria",
                "A. Lazo",
                "S. Le Stum",
                "G. Lehaut",
                "E. Leonora",
                "N. Lessing",
                "G. Levi",
                "M. Lindsey Clark",
                "F. Longhitano",
                "J. Majumdar",
                "L. Malerba",
                "F. Mamedov",
                "J. Ma\u0144czak",
                "A. Manfreda",
                "M. Marconi",
                "A. Margiotta",
                "A. Marinelli",
                "C. Markou",
                "L. Martin",
                "J. A. Mart\u00ednez-Mora",
                "F. Marzaioli",
                "M. Mastrodicasa",
                "S. Mastroianni",
                "S. Miccich\u00e8",
                "G. Miele",
                "P. Migliozzi",
                "E. Migneco",
                "M. L. Mitsou",
                "C. M. Mollo",
                "L. Morales-Gallegos",
                "M. Morga",
                "A. Moussa",
                "I. Mozun Mateo",
                "R. Muller",
                "M. R. Musone",
                "M. Musumeci",
                "S. Navas",
                "A. Nayerhoda",
                "C. A. Nicolau",
                "B. Nkosi",
                "B. \u00d3 Fearraigh",
                "V. Oliviero",
                "A. Orlando",
                "E. Oukacha",
                "D. Paesani",
                "J. Palacios Gonz\u00e1lez",
                "G. Papalashvili",
                "V. Parisi",
                "E. J. Pastor Gomez",
                "A. M. P\u0103un",
                "G. E. P\u0103v\u0103la\u015f",
                "S. Pe\u00f1a Mart\u00ednez",
                "M. Perrin-Terrin",
                "J. Perronnel",
                "V. Pestel",
                "R. Pestes",
                "P. Piattelli",
                "C. Poir\u00e8",
                "V. Popa",
                "T. Pradier",
                "J. Prado",
                "S. Pulvirenti",
                "G. Qu\u00e9m\u00e9ner",
                "C. A. Quiroz-Rangel",
                "U. Rahaman",
                "N. Randazzo",
                "R. Randriatoamanana",
                "S. Razzaque",
                "I. C. Rea",
                "D. Real",
                "G. Riccobene",
                "J. Robinson",
                "A. Romanov",
                "A. \u0160aina",
                "F. Salesa Greus",
                "D. F. E. Samtleben",
                "A. S\u00e1nchez Losa",
                "S. Sanfilippo",
                "M. Sanguineti",
                "C. Santonastaso",
                "D. Santonocito",
                "P. Sapienza",
                "J. Schnabel",
                "J. Schumann",
                "H. M. Schutte",
                "J. Seneca",
                "N. Sennan",
                "B. Setter",
                "I. Sgura",
                "R. Shanidze",
                "A. Sharma",
                "Y. Shitov",
                "F. \u0160imkovic",
                "A. Simonelli",
                "A. Sinopoulou",
                "M. V. Smirnov",
                "B. Spisso",
                "M. Spurio",
                "D. Stavropoulos",
                "I. \u0160tekl",
                "M. Taiuti",
                "Y. Tayalati",
                "H. Thiersen",
                "I. Tosta e Melo",
                "E. Tragia",
                "B. Trocm\u00e9",
                "V. Tsourapis",
                "E. Tzamariudaki",
                "A. Vacheret",
                "A. Valer Melchor",
                "V. Valsecchi",
                "V. Van Elewyck",
                "G. Vannoye",
                "G. Vasileiadis",
                "F. Vazquez de Sola",
                "C. Verilhac",
                "A. Veutro",
                "S. Viola",
                "D. Vivolo",
                "J. Wilms",
                "E. de Wolf",
                "H. Yepes-Ramirez",
                "G. Zarpapis",
                "S. Zavatarelli",
                "A. Zegarelli",
                "D. Zito",
                "J. D. Zornoza",
                "J. Z\u00fa\u00f1iga",
                "N. Zywucka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03804v1",
                "http://arxiv.org/pdf/2311.03804v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03799v1",
            "title": "Detecting Any Human-Object Interaction Relationship: Universal HOI\n  Detector with Spatial Prompt Learning on Foundation Models",
            "updated": "2023-11-07T08:27:32Z",
            "published": "2023-11-07T08:27:32Z",
            "summary": "Human-object interaction (HOI) detection aims to comprehend the intricate\nrelationships between humans and objects, predicting $<human, action, object>$\ntriplets, and serving as the foundation for numerous computer vision tasks. The\ncomplexity and diversity of human-object interactions in the real world,\nhowever, pose significant challenges for both annotation and recognition,\nparticularly in recognizing interactions within an open world context. This\nstudy explores the universal interaction recognition in an open-world setting\nthrough the use of Vision-Language (VL) foundation models and large language\nmodels (LLMs). The proposed method is dubbed as \\emph{\\textbf{UniHOI}}. We\nconduct a deep analysis of the three hierarchical features inherent in visual\nHOI detectors and propose a method for high-level relation extraction aimed at\nVL foundation models, which we call HO prompt-based learning. Our design\nincludes an HO Prompt-guided Decoder (HOPD), facilitates the association of\nhigh-level relation representations in the foundation model with various HO\npairs within the image. Furthermore, we utilize a LLM (\\emph{i.e.} GPT) for\ninteraction interpretation, generating a richer linguistic understanding for\ncomplex HOIs. For open-category interaction recognition, our method supports\neither of two input types: interaction phrase or interpretive sentence. Our\nefficient architecture design and learning methods effectively unleash the\npotential of the VL foundation models and LLMs, allowing UniHOI to surpass all\nexisting methods with a substantial margin, under both supervised and zero-shot\nsettings. The code and pre-trained weights are available at:\n\\url{https://github.com/Caoyichao/UniHOI}.",
            "author": [
                "Yichao Cao",
                "Qingfei Tang",
                "Xiu Su",
                "Chen Song",
                "Shan You",
                "Xiaobo Lu",
                "Chang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03799v1",
                "http://arxiv.org/pdf/2311.03799v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03798v1",
            "title": "Noisy Pair Corrector for Dense Retrieval",
            "updated": "2023-11-07T08:27:14Z",
            "published": "2023-11-07T08:27:14Z",
            "summary": "Most dense retrieval models contain an implicit assumption: the training\nquery-document pairs are exactly matched. Since it is expensive to annotate the\ncorpus manually, training pairs in real-world applications are usually\ncollected automatically, which inevitably introduces mismatched-pair noise. In\nthis paper, we explore an interesting and challenging problem in dense\nretrieval, how to train an effective model with mismatched-pair noise. To solve\nthis problem, we propose a novel approach called Noisy Pair Corrector (NPC),\nwhich consists of a detection module and a correction module. The detection\nmodule estimates noise pairs by calculating the perplexity between annotated\npositive and easy negative documents. The correction module utilizes an\nexponential moving average (EMA) model to provide a soft supervised signal,\naiding in mitigating the effects of noise. We conduct experiments on\ntext-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks\nStaQC and SO-DS. Experimental results show that NPC achieves excellent\nperformance in handling both synthetic and realistic noise.",
            "author": [
                "Hang Zhang",
                "Yeyun Gong",
                "Xingwei He",
                "Dayiheng Liu",
                "Daya Guo",
                "Jiancheng Lv",
                "Jian Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03798v1",
                "http://arxiv.org/pdf/2311.03798v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03793v1",
            "title": "HaptStarter: Designing Haptic Stimulus Start System for Deaf and Hard of\n  Hearing Sprinters",
            "updated": "2023-11-07T08:20:17Z",
            "published": "2023-11-07T08:20:17Z",
            "summary": "In this study, we design and develop HaptStarter -- a haptic stimulus start\nsystem -- to improve the starting performance of the deaf and hard of hearing\n(DHH) sprinters. A DHH person has a physical ability nearly equivalent to\nhearing; however, the difficulties in perceiving audio information lead to\ndifferences in their performance in sports.\n  Furthermore, the visual reaction time is slower than the auditory reaction\ntime (ART), while the haptic reaction time is equivalent to it.\n  However, a light stimulus start system is increasingly being used in sprint\nraces to aid DHH sprinters. In this study, we design a brand-new haptic\nstimulus start system for DHH sprinters; we also determine and leverage an\noptimum haptic stimulus interface. The proposed method has the potential to\ncontribute toward the development of prototypes based on the universal design\nprinciple for everyone (DHH, blind and low-vision, and other disabled sprinters\nwith wheelchairs or artificial arms or legs, etc.) by focusing on the\noverlapping area of sports and disability with human-computer interaction.",
            "author": [
                "Akihisa Shitara",
                "Miki Namatame",
                "Sayan Sarcar",
                "Yoichi Ochiai",
                "Yuhki Shiraishi"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.ijhcs.2023.103168",
                "http://arxiv.org/abs/2311.03793v1",
                "http://arxiv.org/pdf/2311.03793v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03792v1",
            "title": "Character-Level Bangla Text-to-IPA Transcription Using Transformer\n  Architecture with Sequence Alignment",
            "updated": "2023-11-07T08:20:06Z",
            "published": "2023-11-07T08:20:06Z",
            "summary": "The International Phonetic Alphabet (IPA) is indispensable in language\nlearning and understanding, aiding users in accurate pronunciation and\ncomprehension. Additionally, it plays a pivotal role in speech therapy,\nlinguistic research, accurate transliteration, and the development of\ntext-to-speech systems, making it an essential tool across diverse fields.\nBangla being 7th as one of the widely used languages, gives rise to the need\nfor IPA in its domain. Its IPA mapping is too diverse to be captured manually\ngiving the need for Artificial Intelligence and Machine Learning in this field.\nIn this study, we have utilized a transformer-based sequence-to-sequence model\nat the letter and symbol level to get the IPA of each Bangla word as the\nvariation of IPA in association of different words is almost null. Our\ntransformer model only consisted of 8.5 million parameters with only a single\ndecoder and encoder layer. Additionally, to handle the punctuation marks and\nthe occurrence of foreign languages in the text, we have utilized manual\nmapping as the model won't be able to learn to separate them from Bangla words\nwhile decreasing our required computational resources. Finally, maintaining the\nrelative position of the sentence component IPAs and generation of the combined\nIPA has led us to achieve the top position with a word error rate of 0.10582 in\nthe public ranking of DataVerse Challenge - ITVerse 2023\n(https://www.kaggle.com/competitions/dataverse_2023/).",
            "author": [
                "Jakir Hasan",
                "Shrestha Datta",
                "Ameya Debnath"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03792v1",
                "http://arxiv.org/pdf/2311.03792v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03788v1",
            "title": "Language Representation Projection: Can We Transfer Factual Knowledge\n  across Languages in Multilingual Language Models?",
            "updated": "2023-11-07T08:16:16Z",
            "published": "2023-11-07T08:16:16Z",
            "summary": "Multilingual pretrained language models serve as repositories of multilingual\nfactual knowledge. Nevertheless, a substantial performance gap of factual\nknowledge probing exists between high-resource languages and low-resource\nlanguages, suggesting limited implicit factual knowledge transfer across\nlanguages in multilingual pretrained language models. This paper investigates\nthe feasibility of explicitly transferring relatively rich factual knowledge\nfrom English to non-English languages. To accomplish this, we propose two\nparameter-free $\\textbf{L}$anguage $\\textbf{R}$epresentation\n$\\textbf{P}$rojection modules (LRP2). The first module converts non-English\nrepresentations into English-like equivalents, while the second module reverts\nEnglish-like representations back into representations of the corresponding\nnon-English language. Experimental results on the mLAMA dataset demonstrate\nthat LRP2 significantly improves factual knowledge retrieval accuracy and\nfacilitates knowledge transferability across diverse non-English languages. We\nfurther investigate the working mechanism of LRP2 from the perspectives of\nrepresentation space and cross-lingual knowledge neuron.",
            "author": [
                "Shaoyang Xu",
                "Junzhuo Li",
                "Deyi Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03788v1",
                "http://arxiv.org/pdf/2311.03788v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03785v1",
            "title": "Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task\n  Learning with Auxiliary Mutual Information Maximization",
            "updated": "2023-11-07T08:10:36Z",
            "published": "2023-11-07T08:10:36Z",
            "summary": "Multimodal representation learning poses significant challenges in capturing\ninformative and distinct features from multiple modalities. Existing methods\noften struggle to exploit the unique characteristics of each modality due to\nunified multimodal annotations. In this study, we propose Self-MI in the\nself-supervised learning fashion, which also leverage Contrastive Predictive\nCoding (CPC) as an auxiliary technique to maximize the Mutual Information (MI)\nbetween unimodal input pairs and the multimodal fusion result with unimodal\ninputs. Moreover, we design a label generation module, $ULG_{MI}$ for short,\nthat enables us to create meaningful and informative labels for each modality\nin a self-supervised manner. By maximizing the Mutual Information, we encourage\nbetter alignment between the multimodal fusion and the individual modalities,\nfacilitating improved multimodal fusion. Extensive experiments on three\nbenchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the\neffectiveness of Self-MI in enhancing the multimodal fusion task.",
            "author": [
                "Cam-Van Thi Nguyen",
                "Ngoc-Hoa Thi Nguyen",
                "Duc-Trong Le",
                "Quang-Thuy Ha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03785v1",
                "http://arxiv.org/pdf/2311.03785v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03784v2",
            "title": "UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields",
            "updated": "2023-11-08T02:52:47Z",
            "published": "2023-11-07T08:10:29Z",
            "summary": "Neural Radiance Field (NeRF) has enabled novel view synthesis with high\nfidelity given images and camera poses. Subsequent works even succeeded in\neliminating the necessity of pose priors by jointly optimizing NeRF and camera\npose. However, these works are limited to relatively simple settings such as\nphotometrically consistent and occluder-free image collections or a sequence of\nimages from a video. So they have difficulty handling unconstrained images with\nvarying illumination and transient occluders. In this paper, we propose\n$\\textbf{UP-NeRF}$ ($\\textbf{U}$nconstrained $\\textbf{P}$ose-prior-free\n$\\textbf{Ne}$ural $\\textbf{R}$adiance $\\textbf{F}$ields) to optimize NeRF with\nunconstrained image collections without camera pose prior. We tackle these\nchallenges with surrogate tasks that optimize color-insensitive feature fields\nand a separate module for transient occluders to block their influence on pose\nestimation. In addition, we introduce a candidate head to enable more robust\npose estimation and transient-aware depth supervision to minimize the effect of\nincorrect prior. Our experiments verify the superior performance of our method\ncompared to the baselines including BARF and its variants in a challenging\ninternet photo collection, $\\textit{Phototourism}$ dataset.",
            "author": [
                "Injae Kim",
                "Minhyuk Choi",
                "Hyunwoo J. Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03784v2",
                "http://arxiv.org/pdf/2311.03784v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03783v1",
            "title": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
            "updated": "2023-11-07T08:06:27Z",
            "published": "2023-11-07T08:06:27Z",
            "summary": "Embodied AI is one of the most popular studies in artificial intelligence and\nrobotics, which can effectively improve the intelligence of real-world agents\n(i.e. robots) serving human beings. Scene knowledge is important for an agent\nto understand the surroundings and make correct decisions in the varied open\nworld. Currently, knowledge base for embodied tasks is missing and most\nexisting work use general knowledge base or pre-trained models to enhance the\nintelligence of an agent. For conventional knowledge base, it is sparse,\ninsufficient in capacity and cost in data collection. For pre-trained models,\nthey face the uncertainty of knowledge and hard maintenance. To overcome the\nchallenges of scene knowledge, we propose a scene-driven multimodal knowledge\ngraph (Scene-MMKG) construction method combining conventional knowledge\nengineering and large language models. A unified scene knowledge injection\nframework is introduced for knowledge representation. To evaluate the\nadvantages of our proposed method, we instantiate Scene-MMKG considering\ntypical indoor robotic functionalities (Manipulation and Mobility), named\nManipMob-MMKG. Comparisons in characteristics indicate our instantiated\nManipMob-MMKG has broad superiority in data-collection efficiency and knowledge\nquality. Experimental results on typical embodied tasks show that\nknowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the\nperformance obviously without re-designing model structures complexly. Our\nproject can be found at https://sites.google.com/view/manipmob-mmkg",
            "author": [
                "Song Yaoxian",
                "Sun Penglei",
                "Liu Haoyu",
                "Li Zhixu",
                "Song Wei",
                "Xiao Yanghua",
                "Zhou Xiaofang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03783v1",
                "http://arxiv.org/pdf/2311.03783v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03782v2",
            "title": "CapST: An Enhanced and Lightweight Model Attribution Approach for\n  Synthetic Videos",
            "updated": "2023-11-28T09:23:30Z",
            "published": "2023-11-07T08:05:09Z",
            "summary": "Deepfake videos, generated through AI faceswapping techniques, have garnered\nconsiderable attention due to their potential for powerful impersonation\nattacks. While existing research primarily focuses on binary classification to\ndiscern between real and fake videos, however determining the specific\ngeneration model for a fake video is crucial for forensic investigation.\nAddressing this gap, this paper investigates the model attribution problem of\nDeepfake videos from a recently proposed dataset, Deepfakes from Different\nModels (DFDM), derived from various Autoencoder models. The dataset comprises\n6,450 Deepfake videos generated by five distinct models with variations in\nencoder, decoder, intermediate layer, input resolution, and compression ratio.\nThis study formulates Deepfakes model attribution as a multiclass\nclassification task, proposing a segment of VGG19 as a feature extraction\nbackbone, known for its effectiveness in imagerelated tasks, while integrated a\nCapsule Network with a Spatio-Temporal attention mechanism. The Capsule module\ncaptures intricate hierarchies among features for robust identification of\ndeepfake attributes. Additionally, the video-level fusion technique leverages\ntemporal attention mechanisms to handle concatenated feature vectors,\ncapitalizing on inherent temporal dependencies in deepfake videos. By\naggregating insights across frames, our model gains a comprehensive\nunderstanding of video content, resulting in more precise predictions.\nExperimental results on the deepfake benchmark dataset (DFDM) demonstrate the\nefficacy of our proposed method, achieving up to a 4% improvement in accurately\ncategorizing deepfake videos compared to baseline models while demanding fewer\ncomputational resources.",
            "author": [
                "Wasim Ahmad",
                "Yan-Tsung Peng",
                "Yuan-Hao Chang",
                "Gaddisa Olani Ganfure",
                "Sarwar Khan",
                "Sahibzada Adil Shahzad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03782v2",
                "http://arxiv.org/pdf/2311.03782v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03780v1",
            "title": "Ensembling Textual and Structure-Based Models for Knowledge Graph\n  Completion",
            "updated": "2023-11-07T07:53:06Z",
            "published": "2023-11-07T07:53:06Z",
            "summary": "We consider two popular approaches to Knowledge Graph Completion (KGC):\ntextual models that rely on textual entity descriptions, and structure-based\nmodels that exploit the connectivity structure of the Knowledge Graph (KG).\nPreliminary experiments show that these approaches have complementary\nstrengths: structure-based models perform well when the gold answer is easily\nreachable from the query head in the KG, while textual models exploit\ndescriptions to give good performance even when the gold answer is not\nreachable. In response, we explore ensembling as a way of combining the best of\nboth approaches. We propose a novel method for learning query-dependent\nensemble weights by using the distributions of scores assigned by individual\nmodels to all candidate entities. Our ensemble baseline achieves\nstate-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR\nand 8.3 pt Hits@1 gains over best individual models.",
            "author": [
                "Ananjan Nandi",
                "Navdeep Kaur",
                "Parag Singla",
                "Mausam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03780v1",
                "http://arxiv.org/pdf/2311.03780v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03776v1",
            "title": "Filtered Partial Differential Equations: a robust surrogate constraint\n  in physics-informed deep learning framework",
            "updated": "2023-11-07T07:38:23Z",
            "published": "2023-11-07T07:38:23Z",
            "summary": "Embedding physical knowledge into neural network (NN) training has been a hot\ntopic. However, when facing the complex real-world, most of the existing\nmethods still strongly rely on the quantity and quality of observation data.\nFurthermore, the neural networks often struggle to converge when the solution\nto the real equation is very complex. Inspired by large eddy simulation in\ncomputational fluid dynamics, we propose an improved method based on filtering.\nWe analyzed the causes of the difficulties in physics informed machine\nlearning, and proposed a surrogate constraint (filtered PDE, FPDE in short) of\nthe original physical equations to reduce the influence of noisy and sparse\nobservation data. In the noise and sparsity experiment, the proposed FPDE\nmodels (which are optimized by FPDE constraints) have better robustness than\nthe conventional PDE models. Experiments demonstrate that the FPDE model can\nobtain the same quality solution with 100% higher noise and 12% quantity of\nobservation data of the baseline. Besides, two groups of real measurement data\nare used to show the FPDE improvements in real cases. The final results show\nthat FPDE still gives more physically reasonable solutions when facing the\nincomplete equation problem and the extremely sparse and high-noise conditions.\nFor combining real-world experiment data into physics-informed training, the\nproposed FPDE constraint is useful and performs well in two real-world\nexperiments: modeling the blood velocity in vessels and cell migration in\nscratches.",
            "author": [
                "Dashan Zhang",
                "Yuntian Chen",
                "Shiyi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03776v1",
                "http://arxiv.org/pdf/2311.03776v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03774v1",
            "title": "Meta-Adapter: An Online Few-shot Learner for Vision-Language Model",
            "updated": "2023-11-07T07:27:16Z",
            "published": "2023-11-07T07:27:16Z",
            "summary": "The contrastive vision-language pre-training, known as CLIP, demonstrates\nremarkable potential in perceiving open-world visual concepts, enabling\neffective zero-shot image recognition. Nevertheless, few-shot learning methods\nbased on CLIP typically require offline fine-tuning of the parameters on\nfew-shot samples, resulting in longer inference time and the risk of\nover-fitting in certain domains. To tackle these challenges, we propose the\nMeta-Adapter, a lightweight residual-style adapter, to refine the CLIP features\nguided by the few-shot samples in an online manner. With a few training\nsamples, our method can enable effective few-shot learning capabilities and\ngeneralize to unseen data or tasks without additional fine-tuning, achieving\ncompetitive performance and high efficiency. Without bells and whistles, our\napproach outperforms the state-of-the-art online few-shot learning method by an\naverage of 3.6\\% on eight image classification datasets with higher inference\nspeed. Furthermore, our model is simple and flexible, serving as a\nplug-and-play module directly applicable to downstream tasks. Without further\nfine-tuning, Meta-Adapter obtains notable performance improvements in\nopen-vocabulary object detection and segmentation tasks.",
            "author": [
                "Cheng Cheng",
                "Lin Song",
                "Ruoyi Xue",
                "Hang Wang",
                "Hongbin Sun",
                "Yixiao Ge",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03774v1",
                "http://arxiv.org/pdf/2311.03774v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03772v1",
            "title": "Asymptotically Steerable Finite Fourier-Bessel Transforms and Closure\n  under Convolution",
            "updated": "2023-11-07T07:20:11Z",
            "published": "2023-11-07T07:20:11Z",
            "summary": "This paper develops a constructive numerical scheme for Fourier-Bessel\napproximations on disks compatible with convolutions supported on disks. We\naddress accurate finite Fourier-Bessel transforms (FFBT) and inverse finite\nFourier-Bessel transforms (iFFBT) of functions on disks using the discrete\nFourier Transform (DFT) on Cartesian grids. Whereas the DFT and its fast\nimplementation (FFT) are ubiquitous and are powerful for computing\nconvolutions, they are not exactly steerable under rotations. In contrast,\nFourier-Bessel expansions are steerable, but lose both this property and the\npreservation of band limits under convolution. This work captures the best\nfeatures of both as the band limit is allowed to increase. The\nconvergence/error analysis and asymptotic steerability of FFBT/ iFFBT are\ninvestigated. Conditions are established for the FFBT to converge to the\nFourier-Bessel coefficient and for the iFFBT to uniformly approximate the\nFourier-Bessel partial sums. The matrix form of the finite transforms is\ndiscussed. The implementation of the discrete method to compute numerical\napproximation of convolutions of compactly supported functions on disks is\nconsidered as well.",
            "author": [
                "Arash Ghaani Farashahi",
                "Gregory S. Chirikjian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03772v1",
                "http://arxiv.org/pdf/2311.03772v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.FA",
                "42C10, 65R10, 33C10, 42C05, 65D20, 65D30, 65T40, 65T50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03770v1",
            "title": "Lightweight Portrait Matting via Regional Attention and Refinement",
            "updated": "2023-11-07T07:14:28Z",
            "published": "2023-11-07T07:14:28Z",
            "summary": "We present a lightweight model for high resolution portrait matting. The\nmodel does not use any auxiliary inputs such as trimaps or background captures\nand achieves real time performance for HD videos and near real time for 4K. Our\nmodel is built upon a two-stage framework with a low resolution network for\ncoarse alpha estimation followed by a refinement network for local region\nimprovement. However, a naive implementation of the two-stage model suffers\nfrom poor matting quality if not utilizing any auxiliary inputs. We address the\nperformance gap by leveraging the vision transformer (ViT) as the backbone of\nthe low resolution network, motivated by the observation that the tokenization\nstep of ViT can reduce spatial resolution while retain as much pixel\ninformation as possible. To inform local regions of the context, we propose a\nnovel cross region attention (CRA) module in the refinement network to\npropagate the contextual information across the neighboring regions. We\ndemonstrate that our method achieves superior results and outperforms other\nbaselines on three benchmark datasets while only uses $1/20$ of the FLOPS\ncompared to the existing state-of-the-art model.",
            "author": [
                "Yatao Zhong",
                "Ilya Zharkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03770v1",
                "http://arxiv.org/pdf/2311.03770v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03767v1",
            "title": "Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for\n  Bias Evaluation in Machine Translation",
            "updated": "2023-11-07T07:09:59Z",
            "published": "2023-11-07T07:09:59Z",
            "summary": "Neural Machine Translation (NMT) models are state-of-the-art for machine\ntranslation. However, these models are known to have various social biases,\nespecially gender bias. Most of the work on evaluating gender bias in NMT has\nfocused primarily on English as the source language. For source languages\ndifferent from English, most of the studies use gender-neutral sentences to\nevaluate gender bias. However, practically, many sentences that we encounter do\nhave gender information. Therefore, it makes more sense to evaluate for bias\nusing such sentences. This allows us to determine if NMT models can identify\nthe correct gender based on the grammatical gender cues in the source sentence\nrather than relying on biased correlations with, say, occupation terms. To\ndemonstrate our point, in this work, we use Hindi as the source language and\nconstruct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi\nthat we use to evaluate different Hindi-English (HI-EN) NMT systems\nautomatically for gender bias. Our work highlights the importance of\nconsidering the nature of language when designing such extrinsic bias\nevaluation datasets.",
            "author": [
                "Pushpdeep Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03767v1",
                "http://arxiv.org/pdf/2311.03767v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03765v1",
            "title": "Classification of Various Types of Damages in Honeycomb Composite\n  Sandwich Structures using Guided Wave Structural Health Monitoring",
            "updated": "2023-11-07T07:08:02Z",
            "published": "2023-11-07T07:08:02Z",
            "summary": "Classification of damages in honeycomb composite sandwich structure (HCSS) is\nimportant to decide remedial actions. However, previous studies have only\ndetected damages using deviations of monitoring signal from healthy (baseline)\nusing a guided wave (GW) based structural health monitoring system.\nClassification between various types of damages has not been reported for\nchallenging cases. We show that using careful feature engineering and machine\nlearning it is possible to classify between various types of damages such as\ncore crush (CC), high density core (HDC), lost film adhesive (LFA) and teflon\nrelease film (TRF). We believe that we are the first to report numerical models\nfor four types of damages in HCSS, which is followed up with experimental\nvalidation. We found that two out of four damages affect the GW signal in a\nparticularly similar manner. We extracted and evaluated multiple features from\ntime as well as frequency domains, and also experimented with features relative\nto as baseline as well as those that were baseline-free. Using Pearson's\ncorrelation coefficient based filtering, redundant features were eliminated.\nFinally, using an optimal feature set determined using feature elimination,\nhigh accuracy was achieved with a random forest classifier on held-out signals.\nFor evaluating performance of the proposed method for different damage sizes,\nwe used simulated data obtained from extensive parametric studies and got an\naccuracy of 77.89%. Interpretability studies to determine importance of various\nfeatures showed that features computed using the baseline signal prove more\neffective as compared to baseline-free features.",
            "author": [
                "Shruti Sawant",
                "Jeslin Thalapil",
                "Siddharth Tallur",
                "Sauvik Banerjee",
                "Amit Sethi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03765v1",
                "http://arxiv.org/pdf/2311.03765v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03764v3",
            "title": "Neuro-GPT: Developing A Foundation Model for EEG",
            "updated": "2023-11-11T02:23:07Z",
            "published": "2023-11-07T07:07:18Z",
            "summary": "To handle the scarcity and heterogeneity of electroencephalography (EEG) data\nfor Brain-Computer Interface (BCI) tasks, and to harness the power of large\npublicly available data sets, we propose Neuro-GPT, a foundation model\nconsisting of an EEG encoder and a GPT model. The foundation model is\npre-trained on a large-scale data set using a self-supervised task that learns\nhow to reconstruct masked EEG segments. We then fine-tune the model on a Motor\nImagery Classification task to validate its performance in a low-data regime (9\nsubjects). Our experiments demonstrate that applying a foundation model can\nsignificantly improve classification performance compared to a model trained\nfrom scratch, which provides evidence for the generalizability of the\nfoundation model and its ability to address challenges of data scarcity and\nheterogeneity in EEG.",
            "author": [
                "Wenhui Cui",
                "Woojae Jeong",
                "Philipp Th\u00f6lke",
                "Takfarinas Medani",
                "Karim Jerbi",
                "Anand A. Joshi",
                "Richard M. Leahy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03764v3",
                "http://arxiv.org/pdf/2311.03764v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03762v1",
            "title": "Image change detection with only a few samples",
            "updated": "2023-11-07T07:01:35Z",
            "published": "2023-11-07T07:01:35Z",
            "summary": "This paper considers image change detection with only a small number of\nsamples, which is a significant problem in terms of a few annotations\navailable. A major impediment of image change detection task is the lack of\nlarge annotated datasets covering a wide variety of scenes. Change detection\nmodels trained on insufficient datasets have shown poor generalization\ncapability. To address the poor generalization issue, we propose using simple\nimage processing methods for generating synthetic but informative datasets, and\ndesign an early fusion network based on object detection which could outperform\nthe siamese neural network. Our key insight is that the synthetic data enables\nthe trained model to have good generalization ability for various scenarios. We\ncompare the model trained on the synthetic data with that on the real-world\ndata captured from a challenging dataset, CDNet, using six different test sets.\nThe results demonstrate that the synthetic data is informative enough to\nachieve higher generalization ability than the insufficient real-world data.\nBesides, the experiment shows that utilizing a few (often tens of) samples to\nfine-tune the model trained on the synthetic data will achieve excellent\nresults.",
            "author": [
                "Ke Liu",
                "Zhaoyi Song",
                "Haoyue Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03762v1",
                "http://arxiv.org/pdf/2311.03762v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05646v1",
            "title": "Automatic differentiation accelerated shape optimization approaches to\n  photonic inverse design on rectilinear simulation grids",
            "updated": "2023-11-07T06:46:59Z",
            "published": "2023-11-07T06:46:59Z",
            "summary": "Shape optimization approaches to inverse design offer low-dimensional,\nphysically-guided parameterizations of structures by representing them as\ncombinations of shape primitives. However, on discretized rectilinear\nsimulation grids, computing the gradient of a user objective via the adjoint\nvariables method requires a sum reduction of the forward/adjoint field\nsolutions and the Jacobian of the simulation material distribution with respect\nto the structural shape parameters. These shape parameters often perturb large\nor global parts of the simulation grid resulting in many non-zero Jacobian\nentries, which are typically computed by finite-difference in practice.\nConsequently, the gradient calculation can be non-trivial. In this work we\npropose to accelerate the gradient calculation by invoking automatic\ndifferentiation (AutoDiff) in instantiations of structural material\ndistributions. In doing so, we develop extensible differentiable mappings from\nshape parameters to shape primitives and differentiable effective logic\noperations (denoted AutoDiffGeo). These AutoDiffGeo definitions may introduce\nsome additional discretization error into the field solutions because they\nrelax notions of sub-pixel smoothing along shape boundaries. However, we show\nthat some mappings (e.g. simple cuboids) can achieve zero error with respect to\nvolumetric averaging strategies. We demonstrate AutoDiff enhanced shape\noptimization using three integrated photonic examples: a multi-etch blazed\ngrating coupler, a non-adiabatic waveguide transition taper, and a\npolarization-splitting grating coupler. We find accelerations of the gradient\ncalculation by AutoDiff relative to finite-difference often exceed 50x,\nresulting in total wall time accelerations of 4x or more on the same hardware\nwith little or no compromise to final device performance. Our code is available\nopen source at https://github.com/smhooten/emopt",
            "author": [
                "Sean Hooten",
                "Peng Sun",
                "Liron Gantz",
                "Marco Fiorentino",
                "Raymond G. Beausoleil",
                "Thomas Van Vaerenbergh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05646v1",
                "http://arxiv.org/pdf/2311.05646v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03755v2",
            "title": "Multilingual Mathematical Autoformalization",
            "updated": "2023-11-09T09:58:15Z",
            "published": "2023-11-07T06:42:15Z",
            "summary": "Autoformalization is the task of translating natural language materials into\nmachine-verifiable formalisations. Progress in autoformalization research is\nhindered by the lack of a sizeable dataset consisting of informal-formal pairs\nexpressing the same essence. Existing methods tend to circumvent this challenge\nby manually curating small corpora or using few-shot learning with large\nlanguage models. But these methods suffer from data scarcity and formal\nlanguage acquisition difficulty. In this work, we create $\\texttt{MMA}$, a\nlarge, flexible, multilingual, and multi-domain dataset of informal-formal\npairs, by using a language model to translate in the reverse direction, that\nis, from formal mathematical statements into corresponding informal ones.\nExperiments show that language models fine-tuned on $\\texttt{MMA}$ produce\n$16-18\\%$ of statements acceptable with minimal corrections on the\n$\\texttt{miniF2F}$ and $\\texttt{ProofNet}$ benchmarks, up from $0\\%$ with the\nbase model. We demonstrate that fine-tuning on multilingual formal data results\nin more capable autoformalization models even when deployed on monolingual\ntasks.",
            "author": [
                "Albert Q. Jiang",
                "Wenda Li",
                "Mateja Jamnik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03755v2",
                "http://arxiv.org/pdf/2311.03755v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03754v1",
            "title": "Which is better? Exploring Prompting Strategy For LLM-based Metrics",
            "updated": "2023-11-07T06:36:39Z",
            "published": "2023-11-07T06:36:39Z",
            "summary": "This paper describes the DSBA submissions to the Prompting Large Language\nModels as Explainable Metrics shared task, where systems were submitted to two\ntracks: small and large summarization tracks. With advanced Large Language\nModels (LLMs) such as GPT-4, evaluating the quality of Natural Language\nGeneration (NLG) has become increasingly paramount. Traditional\nsimilarity-based metrics such as BLEU and ROUGE have shown to misalign with\nhuman evaluation and are ill-suited for open-ended generation tasks. To address\nthis issue, we explore the potential capability of LLM-based metrics,\nespecially leveraging open-source LLMs. In this study, wide range of prompts\nand prompting techniques are systematically analyzed with three approaches:\nprompting strategy, score aggregation, and explainability. Our research focuses\non formulating effective prompt templates, determining the granularity of NLG\nquality scores and assessing the impact of in-context examples on LLM-based\nevaluation. Furthermore, three aggregation strategies are compared to identify\nthe most reliable method for aggregating NLG quality scores. To examine\nexplainability, we devise a strategy that generates rationales for the scores\nand analyzes the characteristics of the explanation produced by the open-source\nLLMs. Extensive experiments provide insights regarding evaluation capabilities\nof open-source LLMs and suggest effective prompting strategies.",
            "author": [
                "Joonghoon Kim",
                "Saeran Park",
                "Kiyoon Jeong",
                "Sangmin Lee",
                "Seung Hun Han",
                "Jiyoon Lee",
                "Pilsung Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03754v1",
                "http://arxiv.org/pdf/2311.03754v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03753v1",
            "title": "COOL: A Constraint Object-Oriented Logic Programming Language and its\n  Neural-Symbolic Compilation System",
            "updated": "2023-11-07T06:29:59Z",
            "published": "2023-11-07T06:29:59Z",
            "summary": "This paper explores the integration of neural networks with logic\nprogramming, addressing the longstanding challenges of combining the\ngeneralization and learning capabilities of neural networks with the precision\nof symbolic logic. Traditional attempts at this integration have been hampered\nby difficulties in initial data acquisition, the reliability of undertrained\nnetworks, and the complexity of reusing and augmenting trained models. To\novercome these issues, we introduce the COOL (Constraint Object-Oriented Logic)\nprogramming language, an innovative approach that seamlessly combines logical\nreasoning with neural network technologies. COOL is engineered to autonomously\nhandle data collection, mitigating the need for user-supplied initial data. It\nincorporates user prompts into the coding process to reduce the risks of\nundertraining and enhances the interaction among models throughout their\nlifecycle to promote the reuse and augmentation of networks. Furthermore, the\nfoundational principles and algorithms in COOL's design and its compilation\nsystem could provide valuable insights for future developments in programming\nlanguages and neural network architectures.",
            "author": [
                "Jipeng Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03753v1",
                "http://arxiv.org/pdf/2311.03753v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DC",
                "cs.FL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03749v1",
            "title": "Multiclass Segmentation using Teeth Attention Modules for Dental X-ray\n  Images",
            "updated": "2023-11-07T06:20:34Z",
            "published": "2023-11-07T06:20:34Z",
            "summary": "This paper proposed a cutting-edge multiclass teeth segmentation architecture\nthat integrates an M-Net-like structure with Swin Transformers and a novel\ncomponent named Teeth Attention Block (TAB). Existing teeth image segmentation\nmethods have issues with less accurate and unreliable segmentation outcomes due\nto the complex and varying morphology of teeth, although teeth segmentation in\ndental panoramic images is essential for dental disease diagnosis. We propose a\nnovel teeth segmentation model incorporating an M-Net-like structure with Swin\nTransformers and TAB. The proposed TAB utilizes a unique attention mechanism\nthat focuses specifically on the complex structures of teeth. The attention\nmechanism in TAB precisely highlights key elements of teeth features in\npanoramic images, resulting in more accurate segmentation outcomes. The\nproposed architecture effectively captures local and global contextual\ninformation, accurately defining each tooth and its surrounding structures.\nFurthermore, we employ a multiscale supervision strategy, which leverages the\nleft and right legs of the U-Net structure, boosting the performance of the\nsegmentation with enhanced feature representation. The squared Dice loss is\nutilized to tackle the class imbalance issue, ensuring accurate segmentation\nacross all classes. The proposed method was validated on a panoramic teeth\nX-ray dataset, which was taken in a real-world dental diagnosis. The\nexperimental results demonstrate the efficacy of our proposed architecture for\ntooth segmentation on multiple benchmark dental image datasets, outperforming\nexisting state-of-the-art methods in objective metrics and visual examinations.\nThis study has the potential to significantly enhance dental image analysis and\ncontribute to advances in dental applications.",
            "author": [
                "Afnan Ghafoor",
                "Seong-Yong Moon",
                "Bumshik Lee"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2023.3329364",
                "http://arxiv.org/abs/2311.03749v1",
                "http://arxiv.org/pdf/2311.03749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03748v1",
            "title": "Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse\n  Finetuning",
            "updated": "2023-11-07T06:19:37Z",
            "published": "2023-11-07T06:19:37Z",
            "summary": "Unified Sequence Labeling that articulates different sequence labeling\nproblems such as Named Entity Recognition, Relation Extraction, Semantic Role\nLabeling, etc. in a generalized sequence-to-sequence format opens up the\nopportunity to make the maximum utilization of large language model knowledge\ntoward structured prediction. Unfortunately, this requires formatting them into\nspecialized augmented format unknown to the base pretrained language model\n(PLMs) necessitating finetuning to the target format. This significantly bounds\nits usefulness in data-limited settings where finetuning large models cannot\nproperly generalize to the target format. To address this challenge and\nleverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic\nsparse finetuning strategy that selectively focuses on a fraction of\nparameters, informed by feedback from highly regressing examples, during the\nfine-tuning process. By leveraging the dynamism of sparsity, our approach\nmitigates the impact of well-learned samples and prioritizes underperforming\ninstances for improvement in generalization. Across five tasks of sequence\nlabeling, we demonstrate that FISH-DIP can smoothly optimize the model in low\nresource settings offering upto 40% performance improvements over full\nfine-tuning depending on target evaluation settings. Also, compared to\nin-context learning and other parameter-efficient fine-tuning approaches,\nFISH-DIP performs comparably or better, notably in extreme low-resource\nsettings.",
            "author": [
                "Sarkar Snigdha Sarathi Das",
                "Ranran Haoran Zhang",
                "Peng Shi",
                "Wenpeng Yin",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03748v1",
                "http://arxiv.org/pdf/2311.03748v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03747v1",
            "title": "SBCFormer: Lightweight Network Capable of Full-size ImageNet\n  Classification at 1 FPS on Single Board Computers",
            "updated": "2023-11-07T06:09:56Z",
            "published": "2023-11-07T06:09:56Z",
            "summary": "Computer vision has become increasingly prevalent in solving real-world\nproblems across diverse domains, including smart agriculture, fishery, and\nlivestock management. These applications may not require processing many image\nframes per second, leading practitioners to use single board computers (SBCs).\nAlthough many lightweight networks have been developed for mobile/edge devices,\nthey primarily target smartphones with more powerful processors and not SBCs\nwith the low-end CPUs. This paper introduces a CNN-ViT hybrid network called\nSBCFormer, which achieves high accuracy and fast computation on such low-end\nCPUs. The hardware constraints of these CPUs make the Transformer's attention\nmechanism preferable to convolution. However, using attention on low-end CPUs\npresents a challenge: high-resolution internal feature maps demand excessive\ncomputational resources, but reducing their resolution results in the loss of\nlocal image details. SBCFormer introduces an architectural design to address\nthis issue. As a result, SBCFormer achieves the highest trade-off between\naccuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For\nthe first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a\nspeed of 1.0 frame/sec on the SBC. Code is available at\nhttps://github.com/xyongLu/SBCFormer.",
            "author": [
                "Xiangyong Lu",
                "Masanori Suganuma",
                "Takayuki Okatani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03747v1",
                "http://arxiv.org/pdf/2311.03747v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03746v1",
            "title": "Enhanced physics-informed neural networks with domain scaling and\n  residual correction methods for multi-frequency elliptic problems",
            "updated": "2023-11-07T06:08:47Z",
            "published": "2023-11-07T06:08:47Z",
            "summary": "In this paper, neural network approximation methods are developed for\nelliptic partial differential equations with multi-frequency solutions. Neural\nnetwork work approximation methods have advantages over classical approaches in\nthat they can be applied without much concerns on the form of the differential\nequations or the shape or dimension of the problem domain. When applied to\nproblems with multi-frequency solutions, the performance and accuracy of neural\nnetwork approximation methods are strongly affected by the contrast of the\nhigh- and low-frequency parts in the solutions. To address this issue, domain\nscaling and residual correction methods are proposed. The efficiency and\naccuracy of the proposed methods are demonstrated for multi-frequency model\nproblems.",
            "author": [
                "Deok-Kyu Jang",
                "Hyea Hyun Kim",
                "Kyungsoo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03746v1",
                "http://arxiv.org/pdf/2311.03746v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03745v1",
            "title": "Unsupervised Video Summarization",
            "updated": "2023-11-07T06:01:56Z",
            "published": "2023-11-07T06:01:56Z",
            "summary": "This paper introduces a new, unsupervised method for automatic video\nsummarization using ideas from generative adversarial networks but eliminating\nthe discriminator, having a simple loss function, and separating training of\ndifferent parts of the model. An iterative training strategy is also applied by\nalternately training the reconstructor and the frame selector for multiple\niterations. Furthermore, a trainable mask vector is added to the model in\nsummary generation during training and evaluation. The method also includes an\nunsupervised model selection algorithm. Results from experiments on two public\ndatasets (SumMe and TVSum) and four datasets we created (Soccer, LoL, MLB, and\nShortMLB) demonstrate the effectiveness of each component on the model\nperformance, particularly the iterative training strategy. Evaluations and\ncomparisons with the state-of-the-art methods highlight the advantages of the\nproposed method in performance, stability, and training efficiency.",
            "author": [
                "Hanqing Li",
                "Diego Klabjan",
                "Jean Utke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03745v1",
                "http://arxiv.org/pdf/2311.03745v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03742v1",
            "title": "3DifFusionDet: Diffusion Model for 3D Object Detection with Robust\n  LiDAR-Camera Fusion",
            "updated": "2023-11-07T05:53:09Z",
            "published": "2023-11-07T05:53:09Z",
            "summary": "Good 3D object detection performance from LiDAR-Camera sensors demands\nseamless feature alignment and fusion strategies. We propose the 3DifFusionDet\nframework in this paper, which structures 3D object detection as a denoising\ndiffusion process from noisy 3D boxes to target boxes. In this framework,\nground truth boxes diffuse in a random distribution for training, and the model\nlearns to reverse the noising process. During inference, the model gradually\nrefines a set of boxes that were generated at random to the outcomes. Under the\nfeature align strategy, the progressive refinement method could make a\nsignificant contribution to robust LiDAR-Camera fusion. The iterative\nrefinement process could also demonstrate great adaptability by applying the\nframework to various detecting circumstances where varying levels of accuracy\nand speed are required. Extensive experiments on KITTI, a benchmark for\nreal-world traffic object identification, revealed that 3DifFusionDet is able\nto perform favorably in comparison to earlier, well-respected detectors.",
            "author": [
                "Xinhao Xiang",
                "Simon Dr\u00e4ger",
                "Jiawei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03742v1",
                "http://arxiv.org/pdf/2311.03742v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03741v1",
            "title": "Beyond Traditional Beamforming: Singular Vector Projection Techniques\n  for MU-MIMO Interference Management",
            "updated": "2023-11-07T05:52:23Z",
            "published": "2023-11-07T05:52:23Z",
            "summary": "This paper introduces low-complexity beamforming algorithms for multi-user\nmultiple-input multiple-output (MU-MIMO) systems to minimize inter-user\ninterference and enhance spectral efficiency (SE). A Singular-Vector Beamspace\nSearch (SVBS) algorithm is initially presented, wherein all the singular\nvectors are assessed to determine the most effective beamforming scheme. We\nthen establish a mathematical proof demonstrating that the total inter-user\ninterference of a MU-MIMO beamforming system can be efficiently calculated from\nthe mutual projections of orthonormal singular vectors. Capitalizing on this,\nwe present an Interference-optimized Singular Vector Beamforming (IOSVB)\nalgorithm for optimal singular vector selection. For further reducing the\ncomputational burden, we propose a Dimensionality-reduced IOSVB (DR-IOSVB)\nalgorithm by integrating the principal component analysis (PCA). The numerical\nresults demonstrate the superiority of the SVBS algorithm over the existing\nalgorithms, with the IOSVB offering near-identical SE and the DR-IOSVB\nbalancing the performance and computational efficiency. This work establishes a\nnew benchmark for high-performance and low-complexity beamforming in MU-MIMO\nwireless communication systems.",
            "author": [
                "Md Saheed Ullah",
                "Rafid Umayer Murshed",
                "Md. Forkan Uddin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03741v1",
                "http://arxiv.org/pdf/2311.03741v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03740v1",
            "title": "Reductions of semi-stable representations using the Iwahori mod $p$\n  Local Langlands Correspondence",
            "updated": "2023-11-07T05:50:55Z",
            "published": "2023-11-07T05:50:55Z",
            "summary": "We determine the mod $p$ reductions of all two-dimensional semi-stable\nrepresentations $V_{k,\\mathcal{L}}$ of the Galois group of $\\mathbb{Q}_p$ of\nweights $3 \\leq k \\leq p+1$ and $\\mathcal{L}$-invariants $\\mathcal{L}$ for\nprimes $p \\geq 5$. In particular, we describe the constants appearing in the\nunramified characters completely. The proof involves computing the reduction of\nBreuil's $\\mathrm{GL}_2(\\mathbb{Q}_p)$-Banach space $\\tilde{B}(k,\\mathcal{L})$,\nby studying certain logarithmic functions using background material developed\nby Colmez, and then applying an Iwahori theoretic version of the mod $p$ Local\nLanglands Correspondence.",
            "author": [
                "Anand Chitrao",
                "Eknath Ghate"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03740v1",
                "http://arxiv.org/pdf/2311.03740v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "11F80"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03734v1",
            "title": "Leveraging Structured Information for Explainable Multi-hop Question\n  Answering and Reasoning",
            "updated": "2023-11-07T05:32:39Z",
            "published": "2023-11-07T05:32:39Z",
            "summary": "Neural models, including large language models (LLMs), achieve superior\nperformance on multi-hop question-answering. To elicit reasoning capabilities\nfrom LLMs, recent works propose using the chain-of-thought (CoT) mechanism to\ngenerate both the reasoning chain and the answer, which enhances the model's\ncapabilities in conducting multi-hop reasoning. However, several challenges\nstill remain: such as struggling with inaccurate reasoning, hallucinations, and\nlack of interpretability. On the other hand, information extraction (IE)\nidentifies entities, relations, and events grounded to the text. The extracted\nstructured information can be easily interpreted by humans and machines\n(Grishman, 2019). In this work, we investigate constructing and leveraging\nextracted semantic structures (graphs) for multi-hop question answering,\nespecially the reasoning process. Empirical results and human evaluations show\nthat our framework: generates more faithful reasoning chains and substantially\nimproves the QA performance on two benchmark datasets. Moreover, the extracted\nstructures themselves naturally provide grounded explanations that are\npreferred by humans, as compared to the generated reasoning chains and\nsaliency-based explanations.",
            "author": [
                "Ruosen Li",
                "Xinya Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03734v1",
                "http://arxiv.org/pdf/2311.03734v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03733v1",
            "title": "Improved weight initialization for deep and narrow feedforward neural\n  network",
            "updated": "2023-11-07T05:28:12Z",
            "published": "2023-11-07T05:28:12Z",
            "summary": "Appropriate weight initialization settings, along with the ReLU activation\nfunction, have been a cornerstone of modern deep learning, making it possible\nto train and deploy highly effective and efficient neural network models across\ndiverse artificial intelligence. The problem of dying ReLU, where ReLU neurons\nbecome inactive and yield zero output, presents a significant challenge in the\ntraining of deep neural networks with ReLU activation function. Theoretical\nresearch and various methods have been introduced to address the problem.\nHowever, even with these methods and research, training remains challenging for\nextremely deep and narrow feedforward networks with ReLU activation function.\nIn this paper, we propose a new weight initialization method to address this\nissue. We prove the properties of the proposed initial weight matrix and\ndemonstrate how these properties facilitate the effective propagation of signal\nvectors. Through a series of experiments and comparisons with existing methods,\nwe demonstrate the effectiveness of the new initialization method.",
            "author": [
                "Hyunwoo Lee",
                "Yunho Kim",
                "Seungyeop Yang",
                "Hayoung Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03733v1",
                "http://arxiv.org/pdf/2311.03733v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03732v1",
            "title": "Learning to Learn for Few-shot Continual Active Learning",
            "updated": "2023-11-07T05:22:11Z",
            "published": "2023-11-07T05:22:11Z",
            "summary": "Continual learning strives to ensure stability in solving previously seen\ntasks while demonstrating plasticity in a novel domain. Recent advances in CL\nare mostly confined to a supervised learning setting, especially in NLP domain.\nIn this work, we consider a few-shot continual active learning (CAL) setting\nwhere labeled data is inadequate, and unlabeled data is abundant but with a\nlimited annotation budget. We propose a simple but efficient method, called\nMeta-Continual Active Learning. Specifically, we employ meta-learning and\nexperience replay to address the trade-off between stability and plasticity. As\na result, it finds an optimal initialization that efficiently utilizes\nannotated information for fast adaptation while preventing catastrophic\nforgetting of past tasks. We conduct extensive experiments to validate the\neffectiveness of the proposed method and analyze the effect of various active\nlearning strategies and memory sample selection methods in a few-shot CAL\nsetup. Our experiment results demonstrate that random sampling is the best\ndefault strategy for both active learning and memory sample selection to solve\nfew-shot CAL problems.",
            "author": [
                "Stella Ho",
                "Ming Liu",
                "Shang Gao",
                "Longxiang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03732v1",
                "http://arxiv.org/pdf/2311.03732v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04246v2",
            "title": "ADFactory: An Effective Framework for Generalizing Optical Flow with\n  Nerf",
            "updated": "2023-11-14T08:52:57Z",
            "published": "2023-11-07T05:21:45Z",
            "summary": "A significant challenge facing current optical flow methods is the difficulty\nin generalizing them well to the real world. This is mainly due to the high\ncost of hand-crafted datasets, and existing self-supervised methods are limited\nby indirect loss and occlusions, resulting in fuzzy outcomes. To address this\nchallenge, we introduce a novel optical flow training framework: automatic data\nfactory (ADF). ADF only requires RGB images as input to effectively train the\noptical flow network on the target data domain. Specifically, we use advanced\nNerf technology to reconstruct scenes from photo groups collected by a\nmonocular camera, and then calculate optical flow labels between camera pose\npairs based on the rendering results. To eliminate erroneous labels caused by\ndefects in the scene reconstructed by Nerf, we screened the generated labels\nfrom multiple aspects, such as optical flow matching accuracy, radiation field\nconfidence, and depth consistency. The filtered labels can be directly used for\nnetwork supervision. Experimentally, the generalization ability of ADF on KITTI\nsurpasses existing self-supervised optical flow and monocular scene flow\nalgorithms. In addition, ADF achieves impressive results in real-world\nzero-point generalization evaluations and surpasses most supervised methods.",
            "author": [
                "Han Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04246v2",
                "http://arxiv.org/pdf/2311.04246v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03731v1",
            "title": "A Survey of Large Language Models Attribution",
            "updated": "2023-11-07T05:20:09Z",
            "published": "2023-11-07T05:20:09Z",
            "summary": "Open-domain generative systems have gained significant attention in the field\nof conversational AI (e.g., generative search engines). This paper presents a\ncomprehensive review of the attribution mechanisms employed by these systems,\nparticularly large language models. Though attribution or citation improve the\nfactuality and verifiability, issues like ambiguous knowledge reservoirs,\ninherent biases, and the drawbacks of excessive attribution can hinder the\neffectiveness of these systems. The aim of this survey is to provide valuable\ninsights for researchers, aiding in the refinement of attribution methodologies\nto enhance the reliability and veracity of responses generated by open-domain\ngenerative systems. We believe that this field is still in its early stages;\nhence, we maintain a repository to keep track of ongoing studies at\nhttps://github.com/HITsz-TMG/awesome-llm-attributions.",
            "author": [
                "Dongfang Li",
                "Zetian Sun",
                "Xinshuo Hu",
                "Zhenyu Liu",
                "Ziyang Chen",
                "Baotian Hu",
                "Aiguo Wu",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03731v1",
                "http://arxiv.org/pdf/2311.03731v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03725v2",
            "title": "DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries",
            "updated": "2023-11-08T07:45:58Z",
            "published": "2023-11-07T04:59:43Z",
            "summary": "Utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks\n(RNNs), and Generative Adversarial Networks (GANs), our system introduces an\ninnovative approach to defect detection in manufacturing. This technology\nexcels in precisely identifying faults by extracting intricate details from\nproduct photographs, utilizing RNNs to detect evolving errors and generating\nsynthetic defect data to bolster the model's robustness and adaptability across\nvarious defect scenarios. The project leverages a deep learning framework to\nautomate real-time flaw detection in the manufacturing process. It harnesses\nextensive datasets of annotated images to discern complex defect patterns. This\nintegrated system seamlessly fits into production workflows, thereby boosting\nefficiency and elevating product quality. As a result, it reduces waste and\noperational costs, ultimately enhancing market competitiveness.",
            "author": [
                "Arti Kumbhar",
                "Amruta Chougule",
                "Priya Lokhande",
                "Saloni Navaghane",
                "Aditi Burud",
                "Saee Nimbalkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03725v2",
                "http://arxiv.org/pdf/2311.03725v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03722v1",
            "title": "Inertial Guided Uncertainty Estimation of Feature Correspondence in\n  Visual-Inertial Odometry/SLAM",
            "updated": "2023-11-07T04:56:29Z",
            "published": "2023-11-07T04:56:29Z",
            "summary": "Visual odometry and Simultaneous Localization And Mapping (SLAM) has been\nstudied as one of the most important tasks in the areas of computer vision and\nrobotics, to contribute to autonomous navigation and augmented reality systems.\nIn case of feature-based odometry/SLAM, a moving visual sensor observes a set\nof 3D points from different viewpoints, correspondences between the projected\n2D points in each image are usually established by feature tracking and\nmatching. However, since the corresponding point could be erroneous and noisy,\nreliable uncertainty estimation can improve the accuracy of odometry/SLAM\nmethods. In addition, inertial measurement unit is utilized to aid the visual\nsensor in terms of Visual-Inertial fusion. In this paper, we propose a method\nto estimate the uncertainty of feature correspondence using an inertial\nguidance robust to image degradation caused by motion blur, illumination change\nand occlusion. Modeling a guidance distribution to sample possible\ncorrespondence, we fit the distribution to an energy function based on image\nerror, yielding more robust uncertainty than conventional methods. We also\ndemonstrate the feasibility of our approach by incorporating it into one of\nrecent visual-inertial odometry/SLAM algorithms for public datasets.",
            "author": [
                "Seongwook Yoon",
                "Jaehyun Kim",
                "Sanghoon Sull"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03722v1",
                "http://arxiv.org/pdf/2311.03722v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03721v1",
            "title": "ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning",
            "updated": "2023-11-07T04:55:36Z",
            "published": "2023-11-07T04:55:36Z",
            "summary": "Climate models have been key for assessing the impact of climate change and\nsimulating future climate scenarios. The machine learning (ML) community has\ntaken an increased interest in supporting climate scientists' efforts on\nvarious tasks such as climate model emulation, downscaling, and prediction\ntasks. Many of those tasks have been addressed on datasets created with single\nclimate models. However, both the climate science and ML communities have\nsuggested that to address those tasks at scale, we need large, consistent, and\nML-ready climate model datasets. Here, we introduce ClimateSet, a dataset\ncontaining the inputs and outputs of 36 climate models from the Input4MIPs and\nCMIP6 archives. In addition, we provide a modular dataset pipeline for\nretrieving and preprocessing additional climate models and scenarios. We\nshowcase the potential of our dataset by using it as a benchmark for ML-based\nclimate model emulation. We gain new insights about the performance and\ngeneralization capabilities of the different ML models by analyzing their\nperformance across different climate models. Furthermore, the dataset can be\nused to train an ML emulator on several climate models instead of just one.\nSuch a \"super emulator\" can quickly project new climate change scenarios,\ncomplementing existing scenarios already provided to policymakers. We believe\nClimateSet will create the basis needed for the ML community to tackle\nclimate-related tasks at scale.",
            "author": [
                "Julia Kaltenborn",
                "Charlotte E. E. Lange",
                "Venkatesh Ramesh",
                "Philippe Brouillard",
                "Yaniv Gurwicz",
                "Chandni Nagda",
                "Jakob Runge",
                "Peer Nowack",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03721v1",
                "http://arxiv.org/pdf/2311.03721v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03719v1",
            "title": "Refining resource estimation for the quantum computation of vibrational\n  molecular spectra through Trotter error analysis",
            "updated": "2023-11-07T04:52:27Z",
            "published": "2023-11-07T04:52:27Z",
            "summary": "Accurate simulations of vibrational molecular spectra are expensive on\nconventional computers. Compared to the electronic structure problem, the\nvibrational structure problem with quantum computers is less investigated. In\nthis work we accurately estimate quantum resources, such as number of qubits\nand quantum gates, required for vibrational structure calculations on a\nprogrammable quantum computer. Our approach is based on quantum phase\nestimation and focuses on fault-tolerant quantum devices. In addition to\nasymptotic estimates for generic chemical compounds, we present a more detailed\nanalysis of the quantum resources needed for the simulation of the Hamiltonian\narising in the vibrational structure calculation of acetylene-like polyynes of\ninterest. Leveraging nested commutators, we provide an in-depth quantitative\nanalysis of trotter errors compared to the prior investigations. Ultimately,\nthis work serves as a guide for analyzing the potential quantum advantage\nwithin vibrational structure simulations.",
            "author": [
                "Dimitar Trenev",
                "Pauline J Ollitrault",
                "Stuart M. Harwood",
                "Tanvi P. Gujarati",
                "Sumathy Raman",
                "Antonio Mezzacapo",
                "Sarah Mostame"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03719v1",
                "http://arxiv.org/pdf/2311.03719v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03716v1",
            "title": "LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media\n  Generators",
            "updated": "2023-11-07T04:44:40Z",
            "published": "2023-11-07T04:44:40Z",
            "summary": "Recent advancements in text-to-image generation have revolutionized numerous\nfields, including art and cinema, by automating the generation of high-quality,\ncontext-aware images and video. However, the utility of these technologies is\noften limited by the inadequacy of text prompts in guiding the generator to\nproduce artistically coherent and subject-relevant images. In this paper, We\ndescribe the techniques that can be used to make Large Language Models (LLMs)\nact as Art Directors that enhance image and video generation. We describe our\nunified system for this called \"LaDi\". We explore how LaDi integrates multiple\ntechniques for augmenting the capabilities of text-to-image generators (T2Is)\nand text-to-video generators (T2Vs), with a focus on constrained decoding,\nintelligent prompting, fine-tuning, and retrieval. LaDi and these techniques\nare being used today in apps and platforms developed by Plai Labs.",
            "author": [
                "Allen Roush",
                "Emil Zakirov",
                "Artemiy Shirokov",
                "Polina Lunina",
                "Jack Gane",
                "Alexander Duffy",
                "Charlie Basil",
                "Aber Whitcomb",
                "Jim Benedetto",
                "Chris DeWolfe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03716v1",
                "http://arxiv.org/pdf/2311.03716v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03713v1",
            "title": "Multimodal deep representation learning for quantum cross-platform\n  verification",
            "updated": "2023-11-07T04:35:03Z",
            "published": "2023-11-07T04:35:03Z",
            "summary": "Cross-platform verification, a critical undertaking in the realm of\nearly-stage quantum computing, endeavors to characterize the similarity of two\nimperfect quantum devices executing identical algorithms, utilizing minimal\nmeasurements. While the random measurement approach has been instrumental in\nthis context, the quasi-exponential computational demand with increasing qubit\ncount hurdles its feasibility in large-qubit scenarios. To bridge this\nknowledge gap, here we introduce an innovative multimodal learning approach,\nrecognizing that the formalism of data in this task embodies two distinct\nmodalities: measurement outcomes and classical description of compiled circuits\non explored quantum devices, both enriched with unique information. Building\nupon this insight, we devise a multimodal neural network to independently\nextract knowledge from these modalities, followed by a fusion operation to\ncreate a comprehensive data representation. The learned representation can\neffectively characterize the similarity between the explored quantum devices\nwhen executing new quantum algorithms not present in the training data. We\nevaluate our proposal on platforms featuring diverse noise models, encompassing\nsystem sizes up to 50 qubits. The achieved results demonstrate a\nthree-orders-of-magnitude improvement in prediction accuracy compared to the\nrandom measurements and offer compelling evidence of the complementary roles\nplayed by each modality in cross-platform verification. These findings pave the\nway for harnessing the power of multimodal learning to overcome challenges in\nwider quantum system learning tasks.",
            "author": [
                "Yang Qian",
                "Yuxuan Du",
                "Zhenliang He",
                "Min-hsiu Hsieh",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03713v1",
                "http://arxiv.org/pdf/2311.03713v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03712v2",
            "title": "Contributions of Individual Generators to Nodal Carbon Emissions",
            "updated": "2023-11-08T02:50:51Z",
            "published": "2023-11-07T04:31:44Z",
            "summary": "Recent shifts toward sustainable energy systems have witnessed the fast\ndeployment of carbon-free and carbon-efficient generations across the power\nnetworks. However, the benefits of carbon reduction are not experienced evenly\nthroughout the grid. Each generator can have distinct carbon emission rates.\nDue to the existence of physical power flows, nodal power consumption is met by\na combination of a set of generators, while such combination is determined by\nnetwork topology, generators' characteristics and power demand. This paper\ndescribes a technique based on physical power flow model, which can efficiently\ncompute the nodal carbon emissions contributed by each single generator given\nthe generation and power flow information. We also extend the technique to\ncalculate both the nodal average carbon emission and marginal carbon emission\nrates. Simulation results validate the effectiveness of the calculations, while\nour technique provides a fundamental tool for applications such as carbon\nauditing, carbon-oriented demand management and future carbon-oriented capacity\nexpansion.",
            "author": [
                "Yize Chen",
                "Deepjyoti Deka",
                "Yuanyuan Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03712v2",
                "http://arxiv.org/pdf/2311.03712v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03709v1",
            "title": "Geodesic Envelopes in the Thurston Metric on Teichmuller space",
            "updated": "2023-11-07T04:22:38Z",
            "published": "2023-11-07T04:22:38Z",
            "summary": "The Thurston metric on Teichmuller space, first introduced by W. P. Thurston\nis an asymmetric metric on Teichmuller space defined by $d_{Th}(X,Y) = \\frac12\nlog\\sup_{\\alpha} \\frac{l_{\\alpha}(Y)}{l_{\\alpha}(X)}$. This metric is geodesic,\nbut geodesics are far from unique. In this thesis, we show that in the\nonce-punctured torus, and in the four-times punctured sphere, geodesics stay a\nuniformly-bounded distance from each other. In other words, we show that the\n\\textbf{width} of the geodesic envelope, E(X,Y) between any pair of points $X,Y\n\\in T(S)$ (where $S = S_{1,1}$ or $S = S_{0,4}$) is bounded uniformly. To do\nthis, we first identify extremal geodesics in Env(X,Y), and show that these\ncorrespond to stretch vectors, proving a conjecture of Huang, Ohshika and\nPapadopoulos. We then compute Fenchel-Nielsen twisting along these paths, and\nuse these computations, along with estimates on earthquake path lengths, to\nprove the main theorem.",
            "author": [
                "Assaf Bar-Natan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03709v1",
                "http://arxiv.org/pdf/2311.03709v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03706v1",
            "title": "Parallelized Conflict Graph Cut Generation",
            "updated": "2023-11-07T04:12:54Z",
            "published": "2023-11-07T04:12:54Z",
            "summary": "A conflict graph represents logical relations between binary variables, and\neffective use of the graph can significantly accelerate branch-and-cut solvers\nfor mixed-integer programming (MIP). In this paper we develop efficient\nparallel algorithms for the various components of conflict graph management:\nconflict detection; maximal clique generation; clique extension; and clique\nmerging. We leverage parallel computing in order to intensify computational\neffort on the conflict graph, thereby generating a much larger pool of cutting\nplanes than what can be practically achieved in serial. Computational\nexperiments demonstrate near-linear (i.e. ideal) speedups using up to 64 cores\nwhen there is high computational load from the conflict graph. Moreover, the\nexpanded pool of cuts enabled by parallel computing lead to substantial\nreductions in total MIP solve time, especially for more challenging cases.",
            "author": [
                "Yongzheng Dai",
                "Chen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03706v1",
                "http://arxiv.org/pdf/2311.03706v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "90C10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03703v1",
            "title": "Pipeline Parallelism for DNN Inference with Practical Performance\n  Guarantees",
            "updated": "2023-11-07T03:55:39Z",
            "published": "2023-11-07T03:55:39Z",
            "summary": "We optimize pipeline parallelism for deep neural network (DNN) inference by\npartitioning model graphs into $k$ stages and minimizing the running time of\nthe bottleneck stage, including communication. We design practical algorithms\nfor this NP-hard problem and show that they are nearly optimal in practice by\ncomparing against strong lower bounds obtained via novel mixed-integer\nprogramming (MIP) formulations. We apply these algorithms and lower-bound\nmethods to production models to achieve substantially improved approximation\nguarantees compared to standard combinatorial lower bounds. For example,\nevaluated via geometric means across production data with $k=16$ pipeline\nstages, our MIP formulations more than double the lower bounds, improving the\napproximation ratio from $2.175$ to $1.058$. This work shows that while\nmax-throughput partitioning is theoretically hard, we have a handle on the\nalgorithmic side of the problem in practice and much of the remaining challenge\nis in developing more accurate cost models to feed into the partitioning\nalgorithms.",
            "author": [
                "Aaron Archer",
                "Matthew Fahrbach",
                "Kuikui Liu",
                "Prakash Prabhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03703v1",
                "http://arxiv.org/pdf/2311.03703v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03699v1",
            "title": "A weighted matching scheme of magnetic coil design for FRC shaping\n  control",
            "updated": "2023-11-07T03:53:07Z",
            "published": "2023-11-07T03:53:07Z",
            "summary": "The two-dimentional (2D) separatrix shaping plays a crucial role in the\nconfinement of the Field Reversed Configuration (FRC), and the magnetic coils\nserve as an effective means for its control. In this work we develop a method\nto optimize the location, and current amplitude of the coils required for\nachieving the target separatrix shape. By iteratively calculating the coil\ncurrents, the plasma current, and the equilibrium magnetic flux, the\nequilibrium separatrix progressively converges towards the desired shape. The\ncoil currents are determined through a matching method, and the NIMEQ code is\nemployed to compute the FRC equilibrium with a Rigid Rotor type of plasma\ndistribution. This approach enables the adaption of the equilibrium separatrix\ninto any desired shape, thus offering a potential coil optimization scheme for\nthe device design and the 2D shaping control of FRC plasma.",
            "author": [
                "Zitong Qu",
                "Ping Zhu",
                "Zhipeng Chen",
                "Haolong Li",
                "Jiaxing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03699v1",
                "http://arxiv.org/pdf/2311.03699v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03696v1",
            "title": "Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine\n  Translation of Lecture Transcripts",
            "updated": "2023-11-07T03:50:25Z",
            "published": "2023-11-07T03:50:25Z",
            "summary": "Lecture transcript translation helps learners understand online courses,\nhowever, building a high-quality lecture machine translation system lacks\npublicly available parallel corpora. To address this, we examine a framework\nfor parallel corpus mining, which provides a quick and effective way to mine a\nparallel corpus from publicly available lectures on Coursera. To create the\nparallel corpora, we propose a dynamic programming based sentence alignment\nalgorithm which leverages the cosine similarity of machine-translated\nsentences. The sentence alignment F1 score reaches 96%, which is higher than\nusing the BERTScore, LASER, or sentBERT methods. For both English--Japanese and\nEnglish--Chinese lecture translations, we extracted parallel corpora of\napproximately 50,000 lines and created development and test sets through manual\nfiltering for benchmarking translation performance. Through machine translation\nexperiments, we show that the mined corpora enhance the quality of lecture\ntranscript translation when used in conjunction with out-of-domain parallel\ncorpora via multistage fine-tuning. Furthermore, this study also suggests\nguidelines for gathering and cleaning corpora, mining parallel sentences,\ncleaning noise in the mined data, and creating high-quality evaluation splits.\nFor the sake of reproducibility, we have released the corpora as well as the\ncode to create them. The dataset is available at\nhttps://github.com/shyyhs/CourseraParallelCorpusMining.",
            "author": [
                "Haiyue Song",
                "Raj Dabre",
                "Chenhui Chu",
                "Atsushi Fujita",
                "Sadao Kurohashi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03696v1",
                "http://arxiv.org/pdf/2311.03696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03694v1",
            "title": "Accelerating the Galerkin Reduced-Order Model with the Tensor\n  Decomposition for Turbulent Flows",
            "updated": "2023-11-07T03:47:05Z",
            "published": "2023-11-07T03:47:05Z",
            "summary": "Galerkin-based reduced-order models (G-ROMs) have provided efficient and\naccurate approximations of laminar flows. In order to capture the complex\ndynamics of the turbulent flows, standard G-ROMs require a relatively large\nnumber of reduced basis functions (on the order of hundreds and even\nthousands). Although the resulting G-ROM is still relatively low-dimensional\ncompared to the full-order model (FOM), its computational cost becomes\nprohibitive due to the 3rd-order convection tensor contraction. The tensor\nrequires storage of $N^3$ entries with a corresponding work of $2N^3$\noperations per timestep, which makes such ROMs impossible to use in realistic\napplications, such as control of turbulent flows. In this paper, we focus on\nthe scenario where the G-ROM requires large $N$ values and propose a novel\napproach that utilizes the CANDECOMC/PARAFAC decomposition (CPD), a tensor\ndecomposition technique, to accelerate the G-ROM by approximating the 3rd-order\nconvection tensor by a sum of $R$ rank-1 tensors. In addition, we show that the\ntensor is partially skew-symmetric and derive two conditions for the CP\ndecomposition for preserving the skew-symmetry. Moreover, we investigate the\nG-ROM with the singular value decomposition (SVD). The G-ROM with CP\ndecomposition is investigated in several flow configurations from 2D periodic\nflow to 3D turbulent flows. Our numerical investigation shows CPD-ROM achieves\nat least a factor of 10 speedup. Additionally, the skew-symmetry preserving\nCPD-ROM is more stable and allows the usage of smaller rank $R$. Moreover, from\nthe singular value behavior, the advection tensor formed using the $H^1_0$-POD\nbasis has a low-rank structure, and is preserved even in higher Reynolds\nnumbers. Furthermore, for a given level of accuracy, the CP decomposition is\nmore efficient in size and cost than the SVD.",
            "author": [
                "Ping-Hsuan Tsai",
                "Paul Fischer",
                "Edgar Solomonik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03694v1",
                "http://arxiv.org/pdf/2311.03694v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03687v2",
            "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and\n  Inference of Large Language Models",
            "updated": "2023-12-01T15:37:07Z",
            "published": "2023-11-07T03:25:56Z",
            "summary": "Large Language Models (LLMs) have seen great advance in both academia and\nindustry, and their popularity results in numerous open-source frameworks and\ntechniques in accelerating LLM pre-training, fine-tuning, and inference.\nTraining and deploying LLMs are expensive as it requires considerable computing\nresources and memory, hence many efficient approaches have been developed for\nimproving system pipelines as well as operators. However, the runtime\nperformance can vary significantly across hardware and software stacks, which\nmakes it difficult to choose the best configuration. In this work, we aim to\nbenchmark the performance from both macro and micro perspectives. First, we\nbenchmark the end-to-end performance of pre-training, fine-tuning, and serving\nLLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and\n70B) on three 8-GPU platforms with and without individual optimization\ntechniques, including ZeRO, quantization, recomputation, FlashAttention. Then,\nwe dive deeper to provide a detailed runtime analysis of the sub-modules,\nincluding computing and communication operators in LLMs. For end users, our\nbenchmark and findings help better understand different optimization\ntechniques, training and inference frameworks, together with hardware platforms\nin choosing configurations for deploying LLMs. For researchers, our in-depth\nmodule-wise analyses discover potential opportunities for future work to\nfurther optimize the runtime performance of LLMs.",
            "author": [
                "Longteng Zhang",
                "Xiang Liu",
                "Zeyu Li",
                "Xinglin Pan",
                "Peijie Dong",
                "Ruibo Fan",
                "Rui Guo",
                "Xin Wang",
                "Qiong Luo",
                "Shaohuai Shi",
                "Xiaowen Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03687v2",
                "http://arxiv.org/pdf/2311.03687v2"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03684v1",
            "title": "Reinforcement learning pulses for transmon qubit entangling gates",
            "updated": "2023-11-07T03:19:19Z",
            "published": "2023-11-07T03:19:19Z",
            "summary": "The utility of a quantum computer depends heavily on the ability to reliably\nperform accurate quantum logic operations. For finding optimal control\nsolutions, it is of particular interest to explore model-free approaches, since\ntheir quality is not constrained by the limited accuracy of theoretical models\nfor the quantum processor - in contrast to many established gate implementation\nstrategies. In this work, we utilize a continuous-control reinforcement\nlearning algorithm to design entangling two-qubit gates for superconducting\nqubits; specifically, our agent constructs cross-resonance and CNOT gates\nwithout any prior information about the physical system. Using a simulated\nenvironment of fixed-frequency, fixed-coupling transmon qubits, we demonstrate\nthe capability to generate novel pulse sequences that outperform the standard\ncross-resonance gates in both fidelity and gate duration, while maintaining a\ncomparable susceptibility to stochastic unitary noise. We further showcase an\naugmentation in training and input information that allows our agent to adapt\nits pulse design abilities to drifting hardware characteristics, importantly\nwith little to no additional optimization. Our results exhibit clearly the\nadvantages of unbiased adaptive-feedback learning-based optimization methods\nfor transmon gate design.",
            "author": [
                "Ho Nam Nguyen",
                "Felix Motzoi",
                "Mekena Metcalf",
                "K. Birgitta Whaley",
                "Marin Bukov",
                "Markus Schmitt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03684v1",
                "http://arxiv.org/pdf/2311.03684v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03680v1",
            "title": "Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers\n  and Docking",
            "updated": "2023-11-07T03:12:58Z",
            "published": "2023-11-07T03:12:58Z",
            "summary": "In the pursuit of autonomous spacecraft proximity maneuvers and docking(PMD),\nwe introduce a novel Bayesian actor-critic reinforcement learning algorithm to\nlearn a control policy with the stability guarantee. The PMD task is formulated\nas a Markov decision process that reflects the relative dynamic model, the\ndocking cone and the cost function. Drawing from the principles of Lyapunov\ntheory, we frame the temporal difference learning as a constrained Gaussian\nprocess regression problem. This innovative approach allows the state-value\nfunction to be expressed as a Lyapunov function, leveraging the Gaussian\nprocess and deep kernel learning. We develop a novel Bayesian quadrature policy\noptimization procedure to analytically compute the policy gradient while\nintegrating Lyapunov-based stability constraints. This integration is pivotal\nin satisfying the rigorous safety demands of spaceflight missions. The proposed\nalgorithm has been experimentally evaluated on a spacecraft air-bearing testbed\nand shows impressive and promising performance.",
            "author": [
                "Desong Du",
                "Naiming Qi",
                "Yanfang Liu",
                "Wei Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03680v1",
                "http://arxiv.org/pdf/2311.03680v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03679v1",
            "title": "Unsupervised convolutional neural network fusion approach for change\n  detection in remote sensing images",
            "updated": "2023-11-07T03:10:17Z",
            "published": "2023-11-07T03:10:17Z",
            "summary": "With the rapid development of deep learning, a variety of change detection\nmethods based on deep learning have emerged in recent years. However, these\nmethods usually require a large number of training samples to train the network\nmodel, so it is very expensive. In this paper, we introduce a completely\nunsupervised shallow convolutional neural network (USCNN) fusion approach for\nchange detection. Firstly, the bi-temporal images are transformed into\ndifferent feature spaces by using convolution kernels of different sizes to\nextract multi-scale information of the images. Secondly, the output features of\nbi-temporal images at the same convolution kernels are subtracted to obtain the\ncorresponding difference images, and the difference feature images at the same\nscale are fused into one feature image by using 1 * 1 convolution layer.\nFinally, the output features of different scales are concatenated and a 1 * 1\nconvolution layer is used to fuse the multi-scale information of the image. The\nmodel parameters are obtained by a redesigned sparse function. Our model has\nthree features: the entire training process is conducted in an unsupervised\nmanner, the network architecture is shallow, and the objective function is\nsparse. Thus, it can be seen as a kind of lightweight network model.\nExperimental results on four real remote sensing datasets indicate the\nfeasibility and effectiveness of the proposed approach.",
            "author": [
                "Weidong Yan",
                "Pei Yan",
                "Li Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03679v1",
                "http://arxiv.org/pdf/2311.03679v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03677v1",
            "title": "High-Order Harmonic Generation in Helium: A Comparison Study",
            "updated": "2023-11-07T03:09:22Z",
            "published": "2023-11-07T03:09:22Z",
            "summary": "We report a detailed study of high-order harmonic generation (HHG) in helium.\nWhen comparing predictions from a single-active-electron model with those from\nall-electron simulations, such as ATTOMESA and R-matrix with time-dependence,\nwhich can include different numbers of states in the close-coupling expansion,\nit seems imperative to generate absolute numbers for the HHG spectrum in a\nwell-defined framework. While qualitative agreement in the overall frequency\ndependence of the spectrum, including the cut-off frequency predicted by a\nsemi-classical model, can be achieved by many models in arbitrary units, only\nabsolute numbers can be used for benchmark comparisons between different\napproaches.",
            "author": [
                "A. T. Bondy",
                "S. Saha",
                "A. Harth",
                "N. Douguet",
                "K. R. Hamilton",
                "K. Bartschat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03677v1",
                "http://arxiv.org/pdf/2311.03677v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03672v1",
            "title": "CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation\n  with Weighted Prefix-to-Prefix Training",
            "updated": "2023-11-07T02:44:45Z",
            "published": "2023-11-07T02:44:45Z",
            "summary": "Simultaneous machine translation (SiMT) is a challenging task that requires\nstarting translation before the full source sentence is available.\nPrefix-to-prefix framework is often applied to SiMT, which learns to predict\ntarget tokens using only a partial source prefix. However, due to the word\norder difference between languages, misaligned prefix pairs would make SiMT\nmodels suffer from serious hallucination problems, i.e. target outputs that are\nunfaithful to source inputs. Such problems can not only produce target tokens\nthat are not supported by the source prefix, but also hinder generating the\ncorrect translation by receiving more source words. In this work, we propose a\nConfidence-Based Simultaneous Machine Translation (CBSiMT) framework, which\nuses model confidence to perceive hallucination tokens and mitigates their\nnegative impact with weighted prefix-to-prefix training. Specifically,\ntoken-level and sentence-level weights are calculated based on model confidence\nand acted on the loss function. We explicitly quantify the faithfulness of the\ngenerated target tokens using the token-level weight, and employ the\nsentence-level weight to alleviate the disturbance of sentence pairs with\nserious word order differences on the model. Experimental results on MuST-C\nEnglish-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our\nmethod can consistently improve translation quality at most latency regimes,\nwith up to 2 BLEU scores improvement at low latency.",
            "author": [
                "Mengge Liu",
                "Wen Zhang",
                "Xiang Li",
                "Yanzhi Tian",
                "Yuhang Guo",
                "Jian Luan",
                "Bin Wang",
                "Shuoying Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03672v1",
                "http://arxiv.org/pdf/2311.03672v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04245v1",
            "title": "GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks",
            "updated": "2023-11-07T02:36:24Z",
            "published": "2023-11-07T02:36:24Z",
            "summary": "In recent years, there has been a rapid development of spatio-temporal\nprediction techniques in response to the increasing demands of traffic\nmanagement and travel planning. While advanced end-to-end models have achieved\nnotable success in improving predictive performance, their integration and\nexpansion pose significant challenges. This work aims to address these\nchallenges by introducing a spatio-temporal pre-training framework that\nseamlessly integrates with downstream baselines and enhances their performance.\nThe framework is built upon two key designs: (i) We propose a spatio-temporal\nmask autoencoder as a pre-training model for learning spatio-temporal\ndependencies. The model incorporates customized parameter learners and\nhierarchical spatial pattern encoding networks. These modules are specifically\ndesigned to capture spatio-temporal customized representations and intra- and\ninter-cluster region semantic relationships, which have often been neglected in\nexisting approaches. (ii) We introduce an adaptive mask strategy as part of the\npre-training mechanism. This strategy guides the mask autoencoder in learning\nrobust spatio-temporal representations and facilitates the modeling of\ndifferent relationships, ranging from intra-cluster to inter-cluster, in an\neasy-to-hard training manner. Extensive experiments conducted on representative\nbenchmarks demonstrate the effectiveness of our proposed method. We have made\nour model implementation publicly available at https://github.com/HKUDS/GPT-ST.",
            "author": [
                "Zhonghang Li",
                "Lianghao Xia",
                "Yong Xu",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04245v1",
                "http://arxiv.org/pdf/2311.04245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16145v1",
            "title": "Dual-Stream Attention Transformers for Sewer Defect Classification",
            "updated": "2023-11-07T02:31:51Z",
            "published": "2023-11-07T02:31:51Z",
            "summary": "We propose a dual-stream multi-scale vision transformer (DS-MSHViT)\narchitecture that processes RGB and optical flow inputs for efficient sewer\ndefect classification. Unlike existing methods that combine the predictions of\ntwo separate networks trained on each modality, we jointly train a single\nnetwork with two branches for RGB and motion. Our key idea is to use\nself-attention regularization to harness the complementary strengths of the RGB\nand motion streams. The motion stream alone struggles to generate accurate\nattention maps, as motion images lack the rich visual features present in RGB\nimages. To facilitate this, we introduce an attention consistency loss between\nthe dual streams. By leveraging motion cues through a self-attention\nregularizer, we align and enhance RGB attention maps, enabling the network to\nconcentrate on pertinent input regions. We evaluate our data on a public\ndataset as well as cross-validate our model performance in a novel dataset. Our\nmethod outperforms existing models that utilize either convolutional neural\nnetworks (CNNs) or multi-scale hybrid vision transformers (MSHViTs) without\nemploying attention regularization between the two streams.",
            "author": [
                "Abdullah Al Redwan Newaz",
                "Mahdi Abdeldguerfi",
                "Kendall N. Niles",
                "Joe Tom"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16145v1",
                "http://arxiv.org/pdf/2311.16145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03666v1",
            "title": "Stochastic Control with Distributionally Robust Constraints for\n  Cyber-Physical Systems Vulnerable to Attacks",
            "updated": "2023-11-07T02:31:08Z",
            "published": "2023-11-07T02:31:08Z",
            "summary": "In this paper, we investigate the control of a cyber-physical system (CPS)\nwhile accounting for its vulnerability to external attacks. We formulate a\nconstrained stochastic problem with a robust constraint to ensure robust\noperation against potential attacks. We seek to minimize the expected cost\nsubject to a constraint limiting the worst-case expected damage an attacker can\nimpose on the CPS. We present a dynamic programming decomposition to compute\nthe optimal control strategy in this robust-constrained formulation and prove\nits recursive feasibility. We also illustrate the utility of our results by\napplying them to a numerical simulation.",
            "author": [
                "Nishanth Venkatesh",
                "Aditya Dave",
                "Ioannis Faros",
                "Andreas A. Malikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03666v1",
                "http://arxiv.org/pdf/2311.03666v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03665v1",
            "title": "Faster Algorithms for Cycle Hitting Problems on Disk Graphs",
            "updated": "2023-11-07T02:21:35Z",
            "published": "2023-11-07T02:21:35Z",
            "summary": "In this paper, we consider three hitting problems on a disk intersection\ngraph: Triangle Hitting Set, Feedback Vertex Set, and Odd Cycle Transversal.\nGiven a disk intersection graph $G$, our goal is to compute a set of vertices\nhitting all triangles, all cycles, or all odd cycles, respectively. Our\nalgorithms run in time $2^{\\tilde O(k^{4/5})}n^{O(1)}$, $2^{\\tilde\nO(k^{9/10})}n^{O(1)}$, and $2^{\\tilde O(k^{19/20})}n^{O(1)}$, respectively,\nwhere $n$ denotes the number of vertices of $G$. These do not require a\ngeometric representation of a disk graph. If a geometric representation of a\ndisk graph is given as input, we can solve these problems more efficiently. In\nthis way, we improve the algorithms for those three problem by Lokshtanov et\nal. [SODA 2022].",
            "author": [
                "Shinwoo An",
                "Kyungjin Cho",
                "Eunjin Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03665v1",
                "http://arxiv.org/pdf/2311.03665v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03664v1",
            "title": "Healthcare Security Breaches in the United States: Insights and their\n  Socio-Technical Implications",
            "updated": "2023-11-07T02:20:31Z",
            "published": "2023-11-07T02:20:31Z",
            "summary": "This research examines the pivotal role of human behavior in the realm of\nhealthcare data management, situated at the confluence of technological\nadvancements and human conduct. An in-depth analysis of security breaches in\nthe United States from 2009 to the present elucidates the dominance of\nhuman-induced security breaches. While technological weak points are certainly\na concern, our study highlights that a significant proportion of breaches are\nprecipitated by human errors and practices, thus pinpointing a conspicuous\ndeficiency in training, awareness, and organizational architecture. In spite of\nstringent federal mandates, such as the Health Insurance Portability and\nAccountability Act (HIPAA) and the Health Information Technology for Economic\nand Clinical Health (HITECH) Act, breaches persist, emphasizing the\nindispensable role of human factors within this domain. Such oversights not\nonly jeopardize patient data confidentiality but also undermine the\nfoundational trust inherent in the healthcare infrastructure. By probing the\nsocio-technical facets of healthcare security infringements, this article\nadvocates for an integrated, dynamic, and holistic approach to healthcare data\nsecurity. The findings underscore the imperative of augmenting technological\ndefenses while concurrently elevating human conduct and institutional ethos,\nthereby cultivating a robust and impervious healthcare data management\nenvironment.",
            "author": [
                "Megha M. Moncy",
                "Sadia Afreen",
                "Saptarshi Purkayastha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03664v1",
                "http://arxiv.org/pdf/2311.03664v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03663v2",
            "title": "Principles from Clinical Research for NLP Model Generalization",
            "updated": "2023-11-09T15:09:04Z",
            "published": "2023-11-07T02:17:25Z",
            "summary": "The NLP community typically relies on performance of a model on a held-out\ntest set to assess generalization. Performance drops observed in datasets\noutside of official test sets are generally attributed to\n\"out-of-distribution'' effects. Here, we explore the foundations of\ngeneralizability and study the various factors that affect it, articulating\ngeneralizability lessons from clinical studies. In clinical research\ngeneralizability depends on (a) internal validity of experiments to ensure\ncontrolled measurement of cause and effect, and (b) external validity or\ntransportability of the results to the wider population. We present the need to\nensure internal validity when building machine learning models in natural\nlanguage processing, especially where results may be impacted by spurious\ncorrelations in the data. We demonstrate how spurious factors, such as the\ndistance between entities in relation extraction tasks, can affect model\ninternal validity and in turn adversely impact generalization. We also offer\nguidance on how to analyze generalization failures.",
            "author": [
                "Aparna Elangovan",
                "Jiayuan He",
                "Yuan Li",
                "Karin Verspoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03663v2",
                "http://arxiv.org/pdf/2311.03663v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03658v1",
            "title": "The Linear Representation Hypothesis and the Geometry of Large Language\n  Models",
            "updated": "2023-11-07T01:59:11Z",
            "published": "2023-11-07T01:59:11Z",
            "summary": "Informally, the 'linear representation hypothesis' is the idea that\nhigh-level concepts are represented linearly as directions in some\nrepresentation space. In this paper, we address two closely related questions:\nWhat does \"linear representation\" actually mean? And, how do we make sense of\ngeometric notions (e.g., cosine similarity or projection) in the representation\nspace? To answer these, we use the language of counterfactuals to give two\nformalizations of \"linear representation\", one in the output (word)\nrepresentation space, and one in the input (sentence) space. We then prove\nthese connect to linear probing and model steering, respectively. To make sense\nof geometric notions, we use the formalization to identify a particular\n(non-Euclidean) inner product that respects language structure in a sense we\nmake precise. Using this causal inner product, we show how to unify all notions\nof linear representation. In particular, this allows the construction of probes\nand steering vectors using counterfactual pairs. Experiments with LLaMA-2\ndemonstrate the existence of linear representations of concepts, the connection\nto interpretation and control, and the fundamental role of the choice of inner\nproduct.",
            "author": [
                "Kiho Park",
                "Yo Joong Choe",
                "Victor Veitch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03658v1",
                "http://arxiv.org/pdf/2311.03658v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03650v1",
            "title": "Image Generation and Learning Strategy for Deep Document Forgery\n  Detection",
            "updated": "2023-11-07T01:40:00Z",
            "published": "2023-11-07T01:40:00Z",
            "summary": "In recent years, document processing has flourished and brought numerous\nbenefits. However, there has been a significant rise in reported cases of\nforged document images. Specifically, recent advancements in deep neural\nnetwork (DNN) methods for generative tasks may amplify the threat of document\nforgery. Traditional approaches for forged document images created by prevalent\ncopy-move methods are unsuitable against those created by DNN-based methods, as\nwe have verified. To address this issue, we construct a training dataset of\ndocument forgery images, named FD-VIED, by emulating possible attacks, such as\ntext addition, removal, and replacement with recent DNN-methods. Additionally,\nwe introduce an effective pre-training approach through self-supervised\nlearning with both natural images and document images. In our experiments, we\ndemonstrate that our approach enhances detection performance.",
            "author": [
                "Yamato Okamoto",
                "Osada Genki",
                "Iu Yahiro",
                "Rintaro Hasegawa",
                "Peifei Zhu",
                "Hirokatsu Kataoka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03650v1",
                "http://arxiv.org/pdf/2311.03650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03648v1",
            "title": "Instruct Me More! Random Prompting for Visual In-Context Learning",
            "updated": "2023-11-07T01:39:00Z",
            "published": "2023-11-07T01:39:00Z",
            "summary": "Large-scale models trained on extensive datasets, have emerged as the\npreferred approach due to their high generalizability across various tasks.\nIn-context learning (ICL), a popular strategy in natural language processing,\nuses such models for different tasks by providing instructive prompts but\nwithout updating model parameters. This idea is now being explored in computer\nvision, where an input-output image pair (called an in-context pair) is\nsupplied to the model with a query image as a prompt to exemplify the desired\noutput. The efficacy of visual ICL often depends on the quality of the prompts.\nWe thus introduce a method coined Instruct Me More (InMeMo), which augments\nin-context pairs with a learnable perturbation (prompt), to explore its\npotential. Our experiments on mainstream tasks reveal that InMeMo surpasses the\ncurrent state-of-the-art performance. Specifically, compared to the baseline\nwithout learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for\nforeground segmentation and single object detection tasks, respectively. Our\nfindings suggest that InMeMo offers a versatile and efficient way to enhance\nthe performance of visual ICL with lightweight training. Code is available at\nhttps://github.com/Jackieam/InMeMo.",
            "author": [
                "Jiahao Zhang",
                "Bowen Wang",
                "Liangzhi Li",
                "Yuta Nakashima",
                "Hajime Nagahara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03648v1",
                "http://arxiv.org/pdf/2311.03648v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03645v1",
            "title": "Minimizing Pentagons in the Plane through Automated Reasoning",
            "updated": "2023-11-07T01:23:57Z",
            "published": "2023-11-07T01:23:57Z",
            "summary": "We study $\\mu_5(n)$, the minimum number of convex pentagons induced by $n$\npoints in the plane in general position. Despite a significant body of research\nin understanding $\\mu_4(n)$, the variant concerning convex quadrilaterals, not\nmuch is known about $\\mu_5(n)$. We present two explicit constructions, inspired\nby point placements obtained through a combination of Stochastic Local Search\nand a program for realizability of point sets, that provide $\\mu_5(n) \\leq\n\\binom{\\lfloor n/2 \\rfloor}{5} + \\binom{\\lceil n/2 \\rceil}{5}$. Furthermore, we\nconjecture this bound to be optimal, and provide partial evidence by leveraging\na MaxSAT encoding that allows us to verify our conjecture for $n \\leq 16$.",
            "author": [
                "Bernardo Subercaseaux",
                "John Mackey",
                "Marijn J. H. Heule",
                "Ruben Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03645v1",
                "http://arxiv.org/pdf/2311.03645v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03644v1",
            "title": "BOB: Bayesian Optimized Bootstrap with Applications to Gaussian Mixture\n  Models",
            "updated": "2023-11-07T01:23:22Z",
            "published": "2023-11-07T01:23:22Z",
            "summary": "Sampling from the joint posterior distribution of Gaussian mixture models\n(GMMs) via standard Markov chain Monte Carlo (MCMC) imposes several\ncomputational challenges, which have prevented a broader full Bayesian\nimplementation of these models. A growing body of literature has introduced the\nWeighted Likelihood Bootstrap and the Weighted Bayesian Bootstrap as\nalternatives to MCMC sampling. The core idea of these methods is to repeatedly\ncompute maximum a posteriori (MAP) estimates on many randomly weighted\nposterior densities. These MAP estimates then can be treated as approximate\nposterior draws. Nonetheless, a central question remains unanswered: How to\nselect the distribution of the random weights under arbitrary sample sizes.\nThus, we introduce the Bayesian Optimized Bootstrap (BOB), a computational\nmethod to automatically select the weights distribution by minimizing, through\nBayesian Optimization, a black-box and noisy version of the reverse KL\ndivergence between the Bayesian posterior and an approximate posterior obtained\nvia random weighting. Our proposed method allows for uncertainty\nquantification, approximate posterior sampling, and embraces recent\ndevelopments in parallel computing. We show that BOB outperforms competing\napproaches in recovering the Bayesian posterior, while retaining key\ntheoretical properties from existing methods. BOB's performance is demonstrated\nthrough extensive simulations, along with real-world data analyses.",
            "author": [
                "Santiago Marin",
                "Bronwyn Loong",
                "Anton Westveld"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03644v1",
                "http://arxiv.org/pdf/2311.03644v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03641v1",
            "title": "Spectral Maps for Learning Reduced Representations of Molecular Systems",
            "updated": "2023-11-07T01:07:12Z",
            "published": "2023-11-07T01:07:12Z",
            "summary": "Investigating processes in complex molecular systems characterized by many\nvariables is a crucial problem in computational physics. In theory, such\nsystems can be reduced to a few meaningful degrees of freedom called collective\nvariables (CVs). However, identifying CVs is a significant challenge,\nespecially for the systems with long-lived metastable states, as information\nabout the slow kinetics of rare transitions needs to be encoded in CVs. Here,\nwe present our spectral map technique as a promising deep-learning method to\nlearn CVs based on the slowest timescales. Spectral map maximizes the spectral\ngap between slow and fast eigenvalues of a Markov transition matrix constructed\nfrom simulation data. As an example, we show that our method can effectively\ncapture a simplified representation of alanine dipeptide in solvent. Its\nability to extract the slow CVs makes it a valuable tool for analyzing complex\nsystems.",
            "author": [
                "Tu\u011f\u00e7e G\u00f6kdemir",
                "Jakub Rydzewski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03641v1",
                "http://arxiv.org/pdf/2311.03641v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03639v1",
            "title": "A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning\n  Framework for Predicting Time Evolution of Drag and Lift Coefficients",
            "updated": "2023-11-07T00:56:54Z",
            "published": "2023-11-07T00:56:54Z",
            "summary": "In the pursuit of accurate experimental and computational data while\nminimizing effort, there is a constant need for high-fidelity results. However,\nachieving such results often requires significant computational resources. To\naddress this challenge, this paper proposes a deep operator learning-based\nframework that requires a limited high-fidelity dataset for training. We\nintroduce a novel physics-guided, bi-fidelity, Fourier-featured Deep Operator\nNetwork (DeepONet) framework that effectively combines low and high-fidelity\ndatasets, leveraging the strengths of each. In our methodology, we began by\ndesigning a physics-guided Fourier-featured DeepONet, drawing inspiration from\nthe intrinsic physical behavior of the target solution. Subsequently, we train\nthis network to primarily learn the low-fidelity solution, utilizing an\nextensive dataset. This process ensures a comprehensive grasp of the\nfoundational solution patterns. Following this foundational learning, the\nlow-fidelity deep operator network's output is enhanced using a physics-guided\nFourier-featured residual deep operator network. This network refines the\ninitial low-fidelity output, achieving the high-fidelity solution by employing\na small high-fidelity dataset for training. Notably, in our framework, we\nemploy the Fourier feature network as the Trunk network for the DeepONets,\ngiven its proficiency in capturing and learning the oscillatory nature of the\ntarget solution with high precision. We validate our approach using a\nwell-known 2D benchmark cylinder problem, which aims to predict the time\ntrajectories of lift and drag coefficients. The results highlight that the\nphysics-guided Fourier-featured deep operator network, serving as a\nfoundational building block of our framework, possesses superior predictive\ncapability for the lift and drag coefficients compared to its data-driven\ncounterparts.",
            "author": [
                "Amirhossein Mollaali",
                "Izzet Sahin",
                "Iqrar Raza",
                "Christian Moya",
                "Guillermo Paniagua",
                "Guang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03639v1",
                "http://arxiv.org/pdf/2311.03639v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03633v1",
            "title": "Innovation and Word Usage Patterns in Machine Learning",
            "updated": "2023-11-07T00:41:15Z",
            "published": "2023-11-07T00:41:15Z",
            "summary": "In this study, we delve into the dynamic landscape of machine learning\nresearch evolution. Initially, through the utilization of Latent Dirichlet\nAllocation, we discern pivotal themes and fundamental concepts that have\nemerged within the realm of machine learning. Subsequently, we undertake a\ncomprehensive analysis to track the evolutionary trajectories of these\nidentified themes. To quantify the novelty and divergence of research\ncontributions, we employ the Kullback-Leibler Divergence metric. This\nstatistical measure serves as a proxy for ``surprise'', indicating the extent\nof differentiation between the content of academic papers and the subsequent\ndevelopments in research. By amalgamating these insights, we gain the ability\nto ascertain the pivotal roles played by prominent researchers and the\nsignificance of specific academic venues (periodicals and conferences) within\nthe machine learning domain.",
            "author": [
                "V\u00edtor Bandeira Borges",
                "Daniel Oliveira Cajueiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03633v1",
                "http://arxiv.org/pdf/2311.03633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03629v1",
            "title": "Random Field Augmentations for Self-Supervised Representation Learning",
            "updated": "2023-11-07T00:35:09Z",
            "published": "2023-11-07T00:35:09Z",
            "summary": "Self-supervised representation learning is heavily dependent on data\naugmentations to specify the invariances encoded in representations. Previous\nwork has shown that applying diverse data augmentations is crucial to\ndownstream performance, but augmentation techniques remain under-explored. In\nthis work, we propose a new family of local transformations based on Gaussian\nrandom fields to generate image augmentations for self-supervised\nrepresentation learning. These transformations generalize the well-established\naffine and color transformations (translation, rotation, color jitter, etc.)\nand greatly increase the space of augmentations by allowing transformation\nparameter values to vary from pixel to pixel. The parameters are treated as\ncontinuous functions of spatial coordinates, and modeled as independent\nGaussian random fields. Empirical results show the effectiveness of the new\ntransformations for self-supervised representation learning. Specifically, we\nachieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream\nclassification, and a 3.6% improvement on out-of-distribution iNaturalist\ndownstream classification. However, due to the flexibility of the new\ntransformations, learned representations are sensitive to hyperparameters.\nWhile mild transformations improve representations, we observe that strong\ntransformations can degrade the structure of an image, indicating that\nbalancing the diversity and strength of augmentations is important for\nimproving generalization of learned representations.",
            "author": [
                "Philip Andrew Mansfield",
                "Arash Afkanpour",
                "Warren Richard Morningstar",
                "Karan Singhal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03629v1",
                "http://arxiv.org/pdf/2311.03629v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.2.6; I.2.10; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03628v1",
            "title": "Reinforcement Twinning: from digital twins to model-based reinforcement\n  learning",
            "updated": "2023-11-07T00:24:25Z",
            "published": "2023-11-07T00:24:25Z",
            "summary": "We propose a novel framework for simultaneously training the digital twin of\nan engineering system and an associated control agent. The training of the twin\ncombines methods from data assimilation and system identification, while the\ntraining of the control agent combines model-based optimal control and\nmodel-free reinforcement learning. The combined training of the control agent\nis achieved by letting it evolve independently along two paths (one driven by a\nmodel-based optimal control and another driven by reinforcement learning) and\nusing the virtual environment offered by the digital twin as a playground for\nconfrontation and indirect interaction. This interaction occurs as an \"expert\ndemonstrator\", where the best policy is selected for the interaction with the\nreal environment and \"taught\" to the other if the independent training\nstagnates. We refer to this framework as Reinforcement Twinning (RT). The\nframework is tested on three vastly different engineering systems and control\ntasks, namely (1) the control of a wind turbine subject to time-varying wind\nspeed, (2) the trajectory control of flapping-wing micro air vehicles (FWMAVs)\nsubject to wind gusts, and (3) the mitigation of thermal loads in the\nmanagement of cryogenic storage tanks. The test cases are implemented using\nsimplified models for which the ground truth on the closure law is available.\nThe results show that the adjoint-based training of the digital twin is\nremarkably sample-efficient and completed within a few iterations. Concerning\nthe control agent training, the results show that the model-based and the\nmodel-free control training benefit from the learning experience and the\ncomplementary learning approach of each other. The encouraging results open the\npath towards implementing the RT framework on real systems.",
            "author": [
                "Lorenzo Schena",
                "Pedro Marques",
                "Romain Poletti",
                "Samuel Ahizi",
                "Jan Van den Berghe",
                "Miguel A. Mendez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03628v1",
                "http://arxiv.org/pdf/2311.03628v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03627v1",
            "title": "GNAT: A General Narrative Alignment Tool",
            "updated": "2023-11-07T00:24:14Z",
            "published": "2023-11-07T00:24:14Z",
            "summary": "Algorithmic sequence alignment identifies similar segments shared between\npairs of documents, and is fundamental to many NLP tasks. But it is difficult\nto recognize similarities between distant versions of narratives such as\ntranslations and retellings, particularly for summaries and abridgements which\nare much shorter than the original novels.\n  We develop a general approach to narrative alignment coupling the\nSmith-Waterman algorithm from bioinformatics with modern text similarity\nmetrics. We show that the background of alignment scores fits a Gumbel\ndistribution, enabling us to define rigorous p-values on the significance of\nany alignment. We apply and evaluate our general narrative alignment tool\n(GNAT) on four distinct problem domains differing greatly in both the relative\nand absolute length of documents, namely summary-to-book alignment, translated\nbook alignment, short story alignment, and plagiarism detection --\ndemonstrating the power and performance of our methods.",
            "author": [
                "Tanzir Pial",
                "Steven Skiena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03627v1",
                "http://arxiv.org/pdf/2311.03627v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03626v1",
            "title": "PINNs-TF2: Fast and User-Friendly Physics-Informed Neural Networks in\n  TensorFlow V2",
            "updated": "2023-11-07T00:23:50Z",
            "published": "2023-11-07T00:23:50Z",
            "summary": "Physics-informed neural networks (PINNs) have gained prominence for their\ncapability to tackle supervised learning tasks that conform to physical laws,\nnotably nonlinear partial differential equations (PDEs). This paper presents\n\"PINNs-TF2\", a Python package built on the TensorFlow V2 framework. It not only\naccelerates PINNs implementation but also simplifies user interactions by\nabstracting complex PDE challenges. We underscore the pivotal role of compilers\nin PINNs, highlighting their ability to boost performance by up to 119x. Across\neight diverse examples, our package, integrated with XLA compilers,\ndemonstrated its flexibility and achieved an average speed-up of 18.12 times\nover TensorFlow V1. Moreover, a real-world case study is implemented to\nunderscore the compilers' potential to handle many trainable parameters and\nlarge batch sizes. For community engagement and future enhancements, our\npackage's source code is openly available at:\nhttps://github.com/rezaakb/pinns-tf2.",
            "author": [
                "Reza Akbarian Bafghi",
                "Maziar Raissi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03626v1",
                "http://arxiv.org/pdf/2311.03626v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03622v1",
            "title": "TWIST: Teacher-Student World Model Distillation for Efficient\n  Sim-to-Real Transfer",
            "updated": "2023-11-07T00:18:07Z",
            "published": "2023-11-07T00:18:07Z",
            "summary": "Model-based RL is a promising approach for real-world robotics due to its\nimproved sample efficiency and generalization capabilities compared to\nmodel-free RL. However, effective model-based RL solutions for vision-based\nreal-world applications require bridging the sim-to-real gap for any world\nmodel learnt. Due to its significant computational cost, standard domain\nrandomisation does not provide an effective solution to this problem. This\npaper proposes TWIST (Teacher-Student World Model Distillation for Sim-to-Real\nTransfer) to achieve efficient sim-to-real transfer of vision-based model-based\nRL using distillation. Specifically, TWIST leverages state observations as\nreadily accessible, privileged information commonly garnered from a simulator\nto significantly accelerate sim-to-real transfer. Specifically, a teacher world\nmodel is trained efficiently on state information. At the same time, a matching\ndataset is collected of domain-randomised image observations. The teacher world\nmodel then supervises a student world model that takes the domain-randomised\nimage observations as input. By distilling the learned latent dynamics model\nfrom the teacher to the student model, TWIST achieves efficient and effective\nsim-to-real transfer for vision-based model-based RL tasks. Experiments in\nsimulated and real robotics tasks demonstrate that our approach outperforms\nnaive domain randomisation and model-free methods in terms of sample efficiency\nand task performance of sim-to-real transfer.",
            "author": [
                "Jun Yamada",
                "Marc Rigter",
                "Jack Collins",
                "Ingmar Posner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03622v1",
                "http://arxiv.org/pdf/2311.03622v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03621v1",
            "title": "Exploring Latent Spaces of Tonal Music using Variational Autoencoders",
            "updated": "2023-11-07T00:15:29Z",
            "published": "2023-11-07T00:15:29Z",
            "summary": "Variational Autoencoders (VAEs) have proven to be effective models for\nproducing latent representations of cognitive and semantic value. We assess the\ndegree to which VAEs trained on a prototypical tonal music corpus of 371 Bach's\nchorales define latent spaces representative of the circle of fifths and the\nhierarchical relation of each key component pitch as drawn in music cognition.\nIn detail, we compare the latent space of different VAE corpus encodings --\nPiano roll, MIDI, ABC, Tonnetz, DFT of pitch, and pitch class distributions --\nin providing a pitch space for key relations that align with cognitive\ndistances. We evaluate the model performance of these encodings using objective\nmetrics to capture accuracy, mean square error (MSE), KL-divergence, and\ncomputational cost. The ABC encoding performs the best in reconstructing the\noriginal data, while the Pitch DFT seems to capture more information from the\nlatent space. Furthermore, an objective evaluation of 12 major or minor\ntranspositions per piece is adopted to quantify the alignment of 1) intra- and\ninter-segment distances per key and 2) the key distances to cognitive pitch\nspaces. Our results show that Pitch DFT VAE latent spaces align best with\ncognitive spaces and provide a common-tone space where overlapping objects\nwithin a key are fuzzy clusters, which impose a well-defined order of\nstructural significance or stability -- i.e., a tonal hierarchy. Tonal\nhierarchies of different keys can be used to measure key distances and the\nrelationships of their in-key components at multiple hierarchies (e.g., notes\nand chords). The implementation of our VAE and the encodings framework are made\navailable online.",
            "author": [
                "N\u00e1dia Carvalho",
                "Gilberto Bernardes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03621v1",
                "http://arxiv.org/pdf/2311.03621v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03620v1",
            "title": "FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision\n  Transformer Fusion",
            "updated": "2023-11-07T00:12:01Z",
            "published": "2023-11-07T00:12:01Z",
            "summary": "For 3D object detection, both camera and lidar have been demonstrated to be\nuseful sensory devices for providing complementary information about the same\nscenery with data representations in different modalities, e.g., 2D RGB image\nvs 3D point cloud. An effective representation learning and fusion of such\nmulti-modal sensor data is necessary and critical for better 3D object\ndetection performance. To solve the problem, in this paper, we will introduce a\nnovel vision transformer-based 3D object detection model, namely FusionViT.\nDifferent from the existing 3D object detection approaches, FusionViT is a\npure-ViT based framework, which adopts a hierarchical architecture by extending\nthe transformer model to embed both images and point clouds for effective\nrepresentation learning. Such multi-modal data embedding representations will\nbe further fused together via a fusion vision transformer model prior to\nfeeding the learned features to the object detection head for both detection\nand localization of the 3D objects in the input scenery. To demonstrate the\neffectiveness of FusionViT, extensive experiments have been done on real-world\ntraffic object detection benchmark datasets KITTI and Waymo Open. Notably, our\nFusionViT model can achieve state-of-the-art performance and outperforms not\nonly the existing baseline methods that merely rely on camera images or lidar\npoint clouds, but also the latest multi-modal image-point cloud deep fusion\napproaches.",
            "author": [
                "Xinhao Xiang",
                "Jiawei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03620v1",
                "http://arxiv.org/pdf/2311.03620v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03616v1",
            "title": "Governance Capture in a Self-Governing Community: A Qualitative\n  Comparison of the Serbo-Croatian Wikipedias",
            "updated": "2023-11-06T23:59:48Z",
            "published": "2023-11-06T23:59:48Z",
            "summary": "What types of governance arrangements makes some self-governed online groups\nmore vulnerable to disinformation campaigns? To answer this question, we\npresent a qualitative comparative analysis of the Croatian and Serbian\nWikipedia editions. We do so because between at least 2011 and 2020, the\nCroatian language version of Wikipedia was taken over by a small group of\nadministrators who introduced far-right bias and outright disinformation;\ndissenting editorial voices were reverted, banned, and blocked. Although\nSerbian Wikipedia is roughly similar in size and age, shares many linguistic\nand cultural features, and faced similar threats, it seems to have largely\navoided this fate. Based on a grounded theory analysis of interviews with\nmembers of both communities and others in cross-functional platform-level\nroles, we propose that the convergence of three features -- high perceived\nvalue as a target, limited early bureaucratic openness, and a preference for\npersonalistic, informal forms of organization over formal ones -- produced a\nwindow of opportunity for governance capture on Croatian Wikipedia. Our\nfindings illustrate that online community governing infrastructures can play a\ncrucial role in systematic disinformation campaigns and other influence\noperations.",
            "author": [
                "Zarine Kharazian",
                "Kate Starbird",
                "Benjamin Mako Hill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03616v1",
                "http://arxiv.org/pdf/2311.03616v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03615v1",
            "title": "CAFE: Carbon-Aware Federated Learning in Geographically Distributed Data\n  Centers",
            "updated": "2023-11-06T23:59:22Z",
            "published": "2023-11-06T23:59:22Z",
            "summary": "Training large-scale artificial intelligence (AI) models demands significant\ncomputational power and energy, leading to increased carbon footprint with\npotential environmental repercussions. This paper delves into the challenges of\ntraining AI models across geographically distributed (geo-distributed) data\ncenters, emphasizing the balance between learning performance and carbon\nfootprint. We consider Federated Learning (FL) as a solution, which prioritizes\nmodel parameter exchange over raw data, ensuring data privacy and compliance\nwith local regulations. Given the variability in carbon intensity across\nregions, we propose a new framework called CAFE (short for Carbon-Aware\nFederated Learning) to optimize training within a fixed carbon footprint\nbudget. Our approach incorporates coreset selection to assess learning\nperformance, employs the Lyapunov drift-plus-penalty framework to address the\nunpredictability of future carbon intensity, and devises an efficient algorithm\nto address the combinatorial complexity of the data center selection. Through\nextensive simulations using real-world carbon intensity data, we demonstrate\nthe efficacy of our algorithm, highlighting its superiority over existing\nmethods in optimizing learning performance while minimizing environmental\nimpact.",
            "author": [
                "Jieming Bian",
                "Shaolei Ren",
                "Jie Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03615v1",
                "http://arxiv.org/pdf/2311.03615v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04931v1",
            "title": "GPT4All: An Ecosystem of Open Source Compressed Language Models",
            "updated": "2023-11-06T23:50:20Z",
            "published": "2023-11-06T23:50:20Z",
            "summary": "Large language models (LLMs) have recently achieved human-level performance\non a range of professional and academic benchmarks. The accessibility of these\nmodels has lagged behind their performance. State-of-the-art LLMs require\ncostly infrastructure; are only accessible via rate-limited, geo-locked, and\ncensored web interfaces; and lack publicly available code and technical\nreports. In this paper, we tell the story of GPT4All, a popular open source\nrepository that aims to democratize access to LLMs. We outline the technical\ndetails of the original GPT4All model family, as well as the evolution of the\nGPT4All project from a single model into a fully fledged open source ecosystem.\nIt is our hope that this paper acts as both a technical overview of the\noriginal GPT4All models as well as a case study on the subsequent growth of the\nGPT4All open source ecosystem.",
            "author": [
                "Yuvanesh Anand",
                "Zach Nussbaum",
                "Adam Treat",
                "Aaron Miller",
                "Richard Guo",
                "Ben Schmidt",
                "GPT4All Community",
                "Brandon Duderstadt",
                "Andriy Mulyar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04931v1",
                "http://arxiv.org/pdf/2311.04931v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03614v1",
            "title": "STONYBOOK: A System and Resource for Large-Scale Analysis of Novels",
            "updated": "2023-11-06T23:46:40Z",
            "published": "2023-11-06T23:46:40Z",
            "summary": "Books have historically been the primary mechanism through which narratives\nare transmitted. We have developed a collection of resources for the\nlarge-scale analysis of novels, including: (1) an open source end-to-end NLP\nanalysis pipeline for the annotation of novels into a standard XML format, (2)\na collection of 49,207 distinct cleaned and annotated novels, and (3) a\ndatabase with an associated web interface for the large-scale aggregate\nanalysis of these literary works. We describe the major functionalities\nprovided in the annotation system along with their utilities. We present\nsamples of analysis artifacts from our website, such as visualizations of\ncharacter occurrences and interactions, similar books, representative\nvocabulary, part of speech statistics, and readability metrics. We also\ndescribe the use of the annotated format in qualitative and quantitative\nanalysis across large corpora of novels.",
            "author": [
                "Charuta Pethe",
                "Allen Kim",
                "Rajesh Prabhakar",
                "Tanzir Pial",
                "Steven Skiena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03614v1",
                "http://arxiv.org/pdf/2311.03614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03612v2",
            "title": "BlockEmulator: An Emulator Enabling to Test Blockchain Sharding\n  Protocols",
            "updated": "2023-11-11T13:44:45Z",
            "published": "2023-11-06T23:45:11Z",
            "summary": "Numerous blockchain simulators have been proposed to allow researchers to\nsimulate mainstream blockchains. However, we have not yet found a testbed that\nenables researchers to develop and evaluate their new consensus algorithms or\nnew protocols for blockchain sharding systems. To fill this gap, we develop\nBlockEmulator, which is designed as an experimental platform, particularly for\nemulating blockchain sharding mechanisms. BlockEmulator adopts a lightweight\nblockchain architecture such that developers can only focus on implementing\ntheir new protocols or mechanisms. Using layered modules and useful programming\ninterfaces offered by BlockEmulator, researchers can implement a new protocol\nwith minimum effort. Through experiments, we test various functionalities of\nBlockEmulator in two steps. Firstly, we prove the correctness of the emulation\nresults yielded by BlockEmulator by comparing the theoretical analysis with the\nobserved experiment results. Secondly, other experimental results demonstrate\nthat BlockEmulator can facilitate the measurement of a series of metrics,\nincluding throughput, transaction confirmation latency, cross-shard transaction\nratio, the queuing size of transaction pools, workload distribution across\nblockchain shards, etc. We have made BlockEmulator open-source in Github.",
            "author": [
                "Huawei Huang",
                "Guang Ye",
                "Qinde Chen",
                "Zhaokang Yin",
                "Xiaofei Luo",
                "Jianru Lin",
                "Taotao Li",
                "Qinglin Yang",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03612v2",
                "http://arxiv.org/pdf/2311.03612v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03611v1",
            "title": "Plug-and-Play Stability for Intracortical Brain-Computer Interfaces: A\n  One-Year Demonstration of Seamless Brain-to-Text Communication",
            "updated": "2023-11-06T23:42:01Z",
            "published": "2023-11-06T23:42:01Z",
            "summary": "Intracortical brain-computer interfaces (iBCIs) have shown promise for\nrestoring rapid communication to people with neurological disorders such as\namyotrophic lateral sclerosis (ALS). However, to maintain high performance over\ntime, iBCIs typically need frequent recalibration to combat changes in the\nneural recordings that accrue over days. This requires iBCI users to stop using\nthe iBCI and engage in supervised data collection, making the iBCI system hard\nto use. In this paper, we propose a method that enables self-recalibration of\ncommunication iBCIs without interrupting the user. Our method leverages large\nlanguage models (LMs) to automatically correct errors in iBCI outputs. The\nself-recalibration process uses these corrected outputs (\"pseudo-labels\") to\ncontinually update the iBCI decoder online. Over a period of more than one year\n(403 days), we evaluated our Continual Online Recalibration with Pseudo-labels\n(CORP) framework with one clinical trial participant. CORP achieved a stable\ndecoding accuracy of 93.84% in an online handwriting iBCI task, significantly\noutperforming other baseline methods. Notably, this is the longest-running iBCI\nstability demonstration involving a human participant. Our results provide the\nfirst evidence for long-term stabilization of a plug-and-play, high-performance\ncommunication iBCI, addressing a major barrier for the clinical translation of\niBCIs.",
            "author": [
                "Chaofei Fan",
                "Nick Hahn",
                "Foram Kamdar",
                "Donald Avansino",
                "Guy H. Wilson",
                "Leigh Hochberg",
                "Krishna V. Shenoy",
                "Jaimie M. Henderson",
                "Francis R. Willett"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03611v1",
                "http://arxiv.org/pdf/2311.03611v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03609v1",
            "title": "Testing RadiX-Nets: Advances in Viable Sparse Topologies",
            "updated": "2023-11-06T23:27:28Z",
            "published": "2023-11-06T23:27:28Z",
            "summary": "The exponential growth of data has sparked computational demands on ML\nresearch and industry use. Sparsification of hyper-parametrized deep neural\nnetworks (DNNs) creates simpler representations of complex data. Past research\nhas shown that some sparse networks achieve similar performance as dense ones,\nreducing runtime and storage. RadiX-Nets, a subgroup of sparse DNNs, maintain\nuniformity which counteracts their lack of neural connections. Generation,\nindependent of a dense network, yields faster asymptotic training and removes\nthe need for costly pruning. However, little work has been done on RadiX-Nets,\nmaking testing challenging. This paper presents a testing suite for RadiX-Nets\nin TensorFlow. We test RadiX-Net performance to streamline processing in\nscalable models, revealing relationships between network topology,\ninitialization, and training behavior. We also encounter \"strange models\" that\ntrain inconsistently and to lower accuracy while models of similar sparsity\ntrain well.",
            "author": [
                "Kevin Kwak",
                "Zack West",
                "Hayden Jananthan",
                "Jeremy Kepner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03609v1",
                "http://arxiv.org/pdf/2311.03609v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03608v1",
            "title": "Implicit Knowledge in Unawareness Structures",
            "updated": "2023-11-06T23:26:21Z",
            "published": "2023-11-06T23:26:21Z",
            "summary": "Awareness structures by Fagin and Halpern (1988) (FH) feature a syntactic\nawareness correspondence and accessibility relations modeling implicit\nknowledge. They are a flexible model of unawareness, and best interpreted from\na outside modeler's perspective. Unawareness structures by Heifetz, Meier, and\nSchipper (2006, 2008) (HMS) model awareness by a lattice of state spaces and\nexplicit knowledge via possibility correspondences. Sublattices thereof can be\ninterpreted as subjective views of agents. Open questions include (1) how\nimplicit knowledge can be defined in HMS structures, and (2) in which way FH\nstructures can be extended to model the agents' subjective views. In this\npaper, we address (1) by defining implicit knowledge such that it is consistent\nwith explicit knowledge in HMS models. We also introduce a variant of HMS\nmodels that instead of explicit knowledge, takes implicit knowledge and\nawareness as primitives. Further, we address (2) by introducing a category of\nFH models that are modally equivalent relative to sublanguages and can be\ninterpreted as agents' subjective views depending on their awareness. These\nconstructions allow us to show an equivalence between HMS and FH models. As a\ncorollary, we obtain soundness and completeness of HMS models with respect to\nthe Logic of Propositional Awareness, based on a language featuring both\nimplicit and explicit knowledge.",
            "author": [
                "Gaia Belardinelli",
                "Burkhard C. Schipper"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03608v1",
                "http://arxiv.org/pdf/2311.03608v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.GT",
                "F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03606v1",
            "title": "Multimodal Stress Detection Using Facial Landmarks and Biometric Signals",
            "updated": "2023-11-06T23:20:30Z",
            "published": "2023-11-06T23:20:30Z",
            "summary": "The development of various sensing technologies is improving measurements of\nstress and the well-being of individuals. Although progress has been made with\nsingle signal modalities like wearables and facial emotion recognition,\nintegrating multiple modalities provides a more comprehensive understanding of\nstress, given that stress manifests differently across different people.\nMulti-modal learning aims to capitalize on the strength of each modality rather\nthan relying on a single signal. Given the complexity of processing and\nintegrating high-dimensional data from limited subjects, more research is\nneeded. Numerous research efforts have been focused on fusing stress and\nemotion signals at an early stage, e.g., feature-level fusion using basic\nmachine learning methods and 1D-CNN Methods. This paper proposes a multi-modal\nlearning approach for stress detection that integrates facial landmarks and\nbiometric signals. We test this multi-modal integration with various\nearly-fusion and late-fusion techniques to integrate the 1D-CNN model from\nbiometric signals and 2-D CNN using facial landmarks. We evaluate these\narchitectures using a rigorous test of models' generalizability using the\nleave-one-subject-out mechanism, i.e., all samples related to a single subject\nare left out to train the model. Our findings show that late-fusion achieved\n94.39\\% accuracy, and early-fusion surpassed it with a 98.38\\% accuracy rate.\nThis research contributes valuable insights into enhancing stress detection\nthrough a multi-modal approach. The proposed research offers important\nknowledge in improving stress detection using a multi-modal approach.",
            "author": [
                "Majid Hosseini",
                "Morteza Bodaghi",
                "Ravi Teja Bhupatiraju",
                "Anthony Maida",
                "Raju Gottumukkala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03606v1",
                "http://arxiv.org/pdf/2311.03606v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03602v1",
            "title": "Use Adaptive Fast Function Approximator in Motor-Filament Binding\n  Kinetics",
            "updated": "2023-11-06T23:12:37Z",
            "published": "2023-11-06T23:12:37Z",
            "summary": "The cytoskeleton, consisting of biopolymer filaments, molecular motors, and\npassive crosslinking proteins, provides the internal structure of cells that\nfacilitate movement, growth, and cell division. Understanding the microscopic\nmotor-filament kinetics and dynamics is essential for comprehending macroscopic\nbehaviors of reconstituted cytoskeletal assemblies, such as self-organized flow\nand active stress. In this study, we employ an adaptive fast Chebyshev\napproximation based on tree search alongside parallel computing to accurately\nrecover the equilibrium distribution of crosslinking proteins, thus satisfying\ndetailed balance in binding through kinetic Monte Carlo sampling, while\nmaintaining cost-effectiveness. Additionally, we offer expandable features,\nincluding segregating the simulation process via pre-building and allowing the\nfree-loading of different explicit formulations of the motor's potential\nenergy. This research has the potential to better describe the evolution of\ncytoskeletal active matter.",
            "author": [
                "Zihan Zhang",
                "Adam R. Lamson",
                "Robert Blackwell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03602v1",
                "http://arxiv.org/pdf/2311.03602v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04243v1",
            "title": "Toward Planet-Wide Traffic Camera Calibration",
            "updated": "2023-11-06T23:01:02Z",
            "published": "2023-11-06T23:01:02Z",
            "summary": "Despite the widespread deployment of outdoor cameras, their potential for\nautomated analysis remains largely untapped due, in part, to calibration\nchallenges. The absence of precise camera calibration data, including intrinsic\nand extrinsic parameters, hinders accurate real-world distance measurements\nfrom captured videos. To address this, we present a scalable framework that\nutilizes street-level imagery to reconstruct a metric 3D model, facilitating\nprecise calibration of in-the-wild traffic cameras. Notably, our framework\nachieves 3D scene reconstruction and accurate localization of over 100 global\ntraffic cameras and is scalable to any camera with sufficient street-level\nimagery. For evaluation, we introduce a dataset of 20 fully calibrated traffic\ncameras, demonstrating our method's significant enhancements over existing\nautomatic calibration techniques. Furthermore, we highlight our approach's\nutility in traffic analysis by extracting insights via 3D vehicle\nreconstruction and speed measurement, thereby opening up the potential of using\noutdoor cameras for automated analysis.",
            "author": [
                "Khiem Vuong",
                "Robert Tamburo",
                "Srinivasa G. Narasimhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04243v1",
                "http://arxiv.org/pdf/2311.04243v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03596v1",
            "title": "CORHEL-CME: An Interactive Tool For Modeling Solar Eruptions",
            "updated": "2023-11-06T22:58:50Z",
            "published": "2023-11-06T22:58:50Z",
            "summary": "Coronal Mass Ejections (CMEs) are immense eruptions of plasma and magnetic\nfields that are propelled outward from the Sun, sometimes with velocities\ngreater than 2000 km/s. They are responsible for some of the most severe space\nweather at Earth, including geomagnetic storms and solar energetic particle\n(SEP) events. We have developed CORHEL-CME, an interactive tool that allows\nnon-expert users to routinely model multiple CMEs in a realistic coronal and\nheliospheric environment. The tool features a web-based user interface that\nallows the user to select a time period of interest, and employs RBSL flux\nropes to create stable and unstable pre-eruptive configurations within a\nbackground global magnetic field. The properties of these configurations can\nfirst be explored in a zero-beta magnetohydrodynamic (MHD) model, followed by\ncomplete CME simulations in thermodynamic MHD, with propagation out to 1 AU. We\ndescribe design features of the interface and computations, including the\ninnovations required to efficiently compute results on practical timescales\nwith moderate computational resources. CORHEL-CME is now implemented at NASA's\nCommunity Coordinated Modeling Center (CCMC) using NASA Amazon Web Services\n(AWS). It will be available to the public by the time this paper is published.",
            "author": [
                "Jon Linker",
                "Tibor Torok",
                "Cooper Downs",
                "Ronald Caplan",
                "Viacheslav Titov",
                "Andres Reyes",
                "Roberto Lionello",
                "Pete Riley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03596v1",
                "http://arxiv.org/pdf/2311.03596v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.IM",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03593v1",
            "title": "Identifying Markov chain models from time-to-event data: an algebraic\n  approach",
            "updated": "2023-11-06T22:52:30Z",
            "published": "2023-11-06T22:52:30Z",
            "summary": "In many fields, including biology, medicine, physics, chemistry, economy and\nactuarial science, data can be represented as the time-to-event of a finite\nstate Markov chain model. The distribution of time intervals between successive\nrecorded events is known as a phase-type distribution. We demonstrate that in\ncases where the eigenvalues of the Markov chain transition matrix are distinct\n(non-degenerate), the phase-type distribution is multi-exponential. We then\npose and solve an inverse problem: given knowledge of the phase-type\ndistribution, can we determine the transition rate parameters of the underlying\nMarkov chain? To tackle this challenge, we initially convert the inverse\nproblem into a computer algebraic task, involving the solution of a system of\npolynomial equations. These equations are symmetrized with respect to the\nparameters of the phase-type distribution. For a specific subset of Markov\nmodels that we refer to as \"solvable,\" the inverse problem yields a unique\nsolution, up to transformations by finite symmetries. We outline a recursive\napproach to compute these solutions for specific families of models, regardless\nof their number of states. Additionally, we use the Thomas decomposition\ntechnique to calculate solutions for models possessing 2, 3, or 4 states.\nInterestingly, we show that models having the same number of states but\ndifferent transition graphs can yield identical phase-distributions. In such\n\"Rashomon effect\" scenarios, time-to-event data permits the formulation of\nmultiple models and interpretations, all of which are consistent with the\nobserved experimental data. To differentiate among these models, we propose\nadditional distinguishing properties beyond just the time until the next event.\nIn order to prove its applicability, we discuss how this method can be used to\ninfer models of transcription regulation from transcriptional bursting data.",
            "author": [
                "Ovidiu Radulescu",
                "Dima Grigoriev",
                "Matthias Seiss",
                "Maria Douaihy",
                "Mounia Lagha",
                "Edouard Bertrand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03593v1",
                "http://arxiv.org/pdf/2311.03593v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "q-bio.QM",
                "60J28"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03592v1",
            "title": "Sketching methods with small window guarantee using minimum decycling\n  sets",
            "updated": "2023-11-06T22:50:00Z",
            "published": "2023-11-06T22:50:00Z",
            "summary": "Most sequence sketching methods work by selecting specific $k$-mers from\nsequences so that the similarity between two sequences can be estimated using\nonly the sketches. Estimating sequence similarity is much faster using sketches\nthan using sequence alignment, hence sketching methods are used to reduce the\ncomputational requirements of computational biology software packages.\nApplications using sketches often rely on properties of the $k$-mer selection\nprocedure to ensure that using a sketch does not degrade the quality of the\nresults compared with using sequence alignment. In particular the window\nguarantee ensures that no long region of the sequence goes unrepresented in the\nsketch.\n  A sketching method with a window guarantee corresponds to a Decycling Set,\naka an unavoidable sets of $k$-mers. Any long enough sequence must contain a\n$k$-mer from any decycling set (hence, it is unavoidable). Conversely, a\ndecycling set defines a sketching method by selecting the $k$-mers from the\nset. Although current methods use one of a small number of sketching method\nfamilies, the space of decycling sets is much larger, and largely unexplored.\nFinding decycling sets with desirable characteristics is a promising approach\nto discovering new sketching methods with improved performance (e.g., with\nsmall window guarantee).\n  The Minimum Decycling Sets (MDSs) are of particular interest because of their\nsmall size. Only two algorithms, by Mykkeltveit and Champarnaud, are known to\ngenerate two particular MDSs, although there is a vast number of alternative\nMDSs. We provide a simple method that allows one to explore the space of MDSs\nand to find sets optimized for desirable properties. We give evidence that the\nMykkeltveit sets are close to optimal regarding one particular property, the\nremaining path length.",
            "author": [
                "Guillaume Mar\u00e7ais",
                "Dan DeBlasio",
                "Carl Kingsford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03592v1",
                "http://arxiv.org/pdf/2311.03592v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03585v1",
            "title": "OpenBSD formal driver verification with SeL4",
            "updated": "2023-11-06T22:35:53Z",
            "published": "2023-11-06T22:35:53Z",
            "summary": "The seL4 microkernel is currently the only kernel that has been fully\nformally verified. In general, the increased interest in ensuring the security\nof a kernel's code results from its important role in the entire operating\nsystem. One of the basic features of an operating system is that it abstracts\nthe handling of devices. This abstraction is represented by device drivers -\nthe software that manages the hardware. A proper verification of the software\ncomponent could ensure that the device would work properly unless there is a\nhardware failure.In this paper, we choose to model the behavior of a device\ndriver and build the proof that the code implementation matches the expected\nbehavior. The proof was written in Isabelle/HOL, the code translation from C to\nIsabelle was done automatically by the use of the C-to-Isabelle Parser and\nAutoCorres tools. We choose Isabelle theorem prover because its efficiency was\nalready shown through the verification of seL4 microkernel.",
            "author": [
                "Adriana Nicolae",
                "Paul Irofti",
                "Ioana Leustean"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03585v1",
                "http://arxiv.org/pdf/2311.03585v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LO",
                "cs.OS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03584v1",
            "title": "Dimensions of Online Conflict: Towards Modeling Agonism",
            "updated": "2023-11-06T22:34:17Z",
            "published": "2023-11-06T22:34:17Z",
            "summary": "Agonism plays a vital role in democratic dialogue by fostering diverse\nperspectives and robust discussions. Within the realm of online conflict there\nis another type: hateful antagonism, which undermines constructive dialogue.\nDetecting conflict online is central to platform moderation and monetization.\nIt is also vital for democratic dialogue, but only when it takes the form of\nagonism. To model these two types of conflict, we collected Twitter\nconversations related to trending controversial topics. We introduce a\ncomprehensive annotation schema for labelling different dimensions of conflict\nin the conversations, such as the source of conflict, the target, and the\nrhetorical strategies deployed. Using this schema, we annotated approximately\n4,000 conversations with multiple labels. We then trained both logistic\nregression and transformer-based models on the dataset, incorporating context\nfrom the conversation, including the number of participants and the structure\nof the interactions. Results show that contextual labels are helpful in\nidentifying conflict and make the models robust to variations in topic. Our\nresearch contributes a conceptualization of different dimensions of conflict, a\nrichly annotated dataset, and promising results that can contribute to content\nmoderation.",
            "author": [
                "Matt Canute",
                "Mali Jin",
                "hannah holtzclaw",
                "Alberto Lusoli",
                "Philippa R Adams",
                "Mugdha Pandya",
                "Maite Taboada",
                "Diana Maynard",
                "Wendy Hui Kyong Chun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03584v1",
                "http://arxiv.org/pdf/2311.03584v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03574v1",
            "title": "Fuzzy Relational Databases via Associative Arrays",
            "updated": "2023-11-06T22:19:30Z",
            "published": "2023-11-06T22:19:30Z",
            "summary": "The increasing rise in artificial intelligence has made the use of imprecise\nlanguage in computer programs like ChatGPT more prominent. Fuzzy logic\naddresses this form of imprecise language by introducing the concept of fuzzy\nsets, where elements belong to the set with a certain membership value (called\nthe fuzzy value). This paper combines fuzzy data with relational algebra to\nprovide the mathematical foundation for a fuzzy database querying language,\ndescribing various useful operations in the language of linear algebra and\nmultiset operations, in addition to rigorously proving key identities.",
            "author": [
                "Kevin Min",
                "Hayden Jananthan",
                "Jeremy Kepner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03574v1",
                "http://arxiv.org/pdf/2311.03574v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03572v1",
            "title": "Unsupervised Region-Growing Network for Object Segmentation in\n  Atmospheric Turbulence",
            "updated": "2023-11-06T22:17:18Z",
            "published": "2023-11-06T22:17:18Z",
            "summary": "In this paper, we present a two-stage unsupervised foreground object\nsegmentation network tailored for dynamic scenes affected by atmospheric\nturbulence. In the first stage, we utilize averaged optical flow from\nturbulence-distorted image sequences to feed a novel region-growing algorithm,\ncrafting preliminary masks for each moving object in the video. In the second\nstage, we employ a U-Net architecture with consistency and grouping losses to\nfurther refine these masks optimizing their spatio-temporal alignment. Our\napproach does not require labeled training data and works across varied\nturbulence strengths for long-range video. Furthermore, we release the first\nmoving object segmentation dataset of turbulence-affected videos, complete with\nmanually annotated ground truth masks. Our method, evaluated on this new\ndataset, demonstrates superior segmentation accuracy and robustness as compared\nto current state-of-the-art unsupervised methods.",
            "author": [
                "Dehao Qin",
                "Ripon Saha",
                "Suren Jayasuriya",
                "Jinwei Ye",
                "Nianyi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03572v1",
                "http://arxiv.org/pdf/2311.03572v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03570v1",
            "title": "Cal-DETR: Calibrated Detection Transformer",
            "updated": "2023-11-06T22:13:10Z",
            "published": "2023-11-06T22:13:10Z",
            "summary": "Albeit revealing impressive predictive performance for several computer\nvision tasks, deep neural networks (DNNs) are prone to making overconfident\npredictions. This limits the adoption and wider utilization of DNNs in many\nsafety-critical applications. There have been recent efforts toward calibrating\nDNNs, however, almost all of them focus on the classification task.\nSurprisingly, very little attention has been devoted to calibrating modern\nDNN-based object detectors, especially detection transformers, which have\nrecently demonstrated promising detection performance and are influential in\nmany decision-making systems. In this work, we address the problem by proposing\na mechanism for calibrated detection transformers (Cal-DETR), particularly for\nDeformable-DETR, UP-DETR and DINO. We pursue the train-time calibration route\nand make the following contributions. First, we propose a simple yet effective\napproach for quantifying uncertainty in transformer-based object detectors.\nSecond, we develop an uncertainty-guided logit modulation mechanism that\nleverages the uncertainty to modulate the class logits. Third, we develop a\nlogit mixing approach that acts as a regularizer with detection-specific losses\nand is also complementary to the uncertainty-guided logit modulation technique\nto further improve the calibration performance. Lastly, we conduct extensive\nexperiments across three in-domain and four out-domain scenarios. Results\ncorroborate the effectiveness of Cal-DETR against the competing train-time\nmethods in calibrating both in-domain and out-domain detections while\nmaintaining or even improving the detection performance. Our codebase and\npre-trained models can be accessed at\n\\url{https://github.com/akhtarvision/cal-detr}.",
            "author": [
                "Muhammad Akhtar Munir",
                "Salman Khan",
                "Muhammad Haris Khan",
                "Mohsen Ali",
                "Fahad Shahbaz Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03570v1",
                "http://arxiv.org/pdf/2311.03570v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03566v1",
            "title": "Measuring Adversarial Datasets",
            "updated": "2023-11-06T22:08:16Z",
            "published": "2023-11-06T22:08:16Z",
            "summary": "In the era of widespread public use of AI systems across various domains,\nensuring adversarial robustness has become increasingly vital to maintain\nsafety and prevent undesirable errors. Researchers have curated various\nadversarial datasets (through perturbations) for capturing model deficiencies\nthat cannot be revealed in standard benchmark datasets. However, little is\nknown about how these adversarial examples differ from the original data\npoints, and there is still no methodology to measure the intended and\nunintended consequences of those adversarial transformations. In this research,\nwe conducted a systematic survey of existing quantifiable metrics that describe\ntext instances in NLP tasks, among dimensions of difficulty, diversity, and\ndisagreement. We selected several current adversarial effect datasets and\ncompared the distributions between the original and their adversarial\ncounterparts. The results provide valuable insights into what makes these\ndatasets more challenging from a metrics perspective and whether they align\nwith underlying assumptions.",
            "author": [
                "Yuanchen Bai",
                "Raoyi Huang",
                "Vijay Viswanathan",
                "Tzu-Sheng Kuo",
                "Tongshuang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03566v1",
                "http://arxiv.org/pdf/2311.03566v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03563v1",
            "title": "Quantitative Phase Field Model for Electrochemical Systems",
            "updated": "2023-11-06T22:02:06Z",
            "published": "2023-11-06T22:02:06Z",
            "summary": "Modeling microstructure evolution in electrochemical systems is vital for\nunderstanding the mechanism of various electrochemical processes. In this work,\nwe propose a general phase field framework that is fully variational and thus\nguarantees that the energy decreases upon evolution in an isothermal system.\nThe bulk and interface free energies are decoupled using a grand potential\nformulation to enhance numerical efficiency. The variational definition of the\noverpotential is used, and the reaction kinetics is incorporated into the\nevolution equation for the phase field to correctly capture capillary effects\nand eliminate additional model parameter calibrations. A higher-order kinetic\ncorrection is derived to accurately reproduce general reaction models such as\nthe Butler-Volmer, Marcus, and Marcus-Hush-Chidsey models. Electrostatic\npotentials in the electrode and the electrolyte are considered separately as\nindependent variables, providing additional freedom to capture the interfacial\npotential jump. To handle realistic materials and processing parameters for\npractical applications, a driving force extension method is used to enhance the\ngrid size by three orders of magnitude. Finally, we comprehensively verify our\nphase field model using classical electrochemical theory.",
            "author": [
                "Jin Zhang",
                "Alexander F. Chadwick",
                "Peter W. Voorhees"
            ],
            "link": [
                "http://dx.doi.org/10.1149/1945-7111/ad0ff6",
                "http://arxiv.org/abs/2311.03563v1",
                "http://arxiv.org/pdf/2311.03563v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03561v2",
            "title": "Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based\n  Multi-Object Tracking",
            "updated": "2023-11-22T19:26:30Z",
            "published": "2023-11-06T22:01:27Z",
            "summary": "Re-identification (ReID) in multi-object tracking (MOT) for UAVs in maritime\ncomputer vision has been challenging for several reasons. More specifically,\nshort-term re-identification (ReID) is difficult due to the nature of the\ncharacteristics of small targets and the sudden movement of the drone's gimbal.\nLong-term ReID suffers from the lack of useful appearance diversity. In\nresponse to these challenges, we present an adaptable motion-based MOT\nalgorithm, called Metadata Guided MOT (MG-MOT). This algorithm effectively\nmerges short-term tracking data into coherent long-term tracks, harnessing\ncrucial metadata from UAVs, including GPS position, drone altitude, and camera\norientations. Extensive experiments are conducted to validate the efficacy of\nour MOT algorithm. Utilizing the challenging SeaDroneSee tracking dataset,\nwhich encompasses the aforementioned scenarios, we achieve a much-improved\nperformance in the latest edition of the UAV-based Maritime Object Tracking\nChallenge with a state-of-the-art HOTA of 69.5% and an IDF1 of 85.9% on the\ntesting split.",
            "author": [
                "Cheng-Yen Yang",
                "Hsiang-Wei Huang",
                "Zhongyu Jiang",
                "Heng-Cheng Kuo",
                "Jie Mei",
                "Chung-I Huang",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03561v2",
                "http://arxiv.org/pdf/2311.03561v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03559v1",
            "title": "Algebraic Conditions on One-Step Breadth-First Search",
            "updated": "2023-11-06T22:01:15Z",
            "published": "2023-11-06T22:01:15Z",
            "summary": "The GraphBLAS community has demonstrated the power of linear\nalgebra-leveraged graph algorithms, such as matrix-vector products for\nbreadth-first search (BFS) traversals. This paper investigates the algebraic\nconditions needed for such computations when working with directed hypergraphs,\nrepresented by incidence arrays with entries from an arbitrary value set with\nbinary addition and multiplication operations. Our results show the one-step\nBFS traversal is equivalent to requiring specific algebraic properties of those\noperations. Assuming identity elements 0, 1 for operations, we show that the\ntwo operations must be zero-sum-free, zero-divisor-free, and 0 must be an\nannihilator under multiplication. Additionally, associativity and commutativity\nare shown to be necessary and sufficient for independence of the one-step BFS\ncomputation from several arbitrary conventions. These results aid in\napplication and algorithm development by determining the efficacy of a value\nset in computations.",
            "author": [
                "Emma Fu",
                "Hayden Jananthan",
                "Jeremy Kepner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03559v1",
                "http://arxiv.org/pdf/2311.03559v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03558v1",
            "title": "Replication and study of anomalies in LK-99--the alleged\n  ambient-pressure, room-temperature superconductor",
            "updated": "2023-11-06T21:59:46Z",
            "published": "2023-11-06T21:59:46Z",
            "summary": "We have studied LK-99 [Pb$_{10-x}$Cu$_x$(PO$_4$)$_6$O], alleged by Lee et al.\nto exhibit superconductivity above room temperature and at ambient pressure,\nand have reproduced all anomalies in electric and magnetic measurements that\nthey reported as evidence for the claim of LK-99 being an ambient-pressure,\nroom-temperature superconductor. We found that these anomalies are associated\nwith the structural transition of the Cu$_2$S impurity in their sample and not\nwith superconductivity.",
            "author": [
                "T. Habamahoro",
                "T. Bontke",
                "M. Chirom",
                "Z. Wu",
                "J. M. Bao",
                "L. Z. Deng",
                "C. W. Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03558v1",
                "http://arxiv.org/pdf/2311.03558v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03557v1",
            "title": "Spatio-Temporal Similarity Measure based Multi-Task Learning for\n  Predicting Alzheimer's Disease Progression using MRI Data",
            "updated": "2023-11-06T21:59:19Z",
            "published": "2023-11-06T21:59:19Z",
            "summary": "Identifying and utilising various biomarkers for tracking Alzheimer's disease\n(AD) progression have received many recent attentions and enable helping\nclinicians make the prompt decisions. Traditional progression models focus on\nextracting morphological biomarkers in regions of interest (ROIs) from MRI/PET\nimages, such as regional average cortical thickness and regional volume. They\nare effective but ignore the relationships between brain ROIs over time, which\nwould lead to synergistic deterioration. For exploring the synergistic\ndeteriorating relationship between these biomarkers, in this paper, we propose\na novel spatio-temporal similarity measure based multi-task learning approach\nfor effectively predicting AD progression and sensitively capturing the\ncritical relationships between biomarkers. Specifically, we firstly define a\ntemporal measure for estimating the magnitude and velocity of biomarker change\nover time, which indicate a changing trend(temporal). Converting this trend\ninto the vector, we then compare this variability between biomarkers in a\nunified vector space(spatial). The experimental results show that compared with\ndirectly ROI based learning, our proposed method is more effective in\npredicting disease progression. Our method also enables performing longitudinal\nstability selection to identify the changing relationships between biomarkers,\nwhich play a key role in disease progression. We prove that the synergistic\ndeteriorating biomarkers between cortical volumes or surface areas have a\nsignificant effect on the cognitive prediction.",
            "author": [
                "Xulong Wang",
                "Yu Zhang",
                "Menghui Zhou",
                "Tong Liu",
                "Jun Qi",
                "Po Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03557v1",
                "http://arxiv.org/pdf/2311.03557v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03556v1",
            "title": "Bounds on tidal charges from gravitational-wave ringdown observations",
            "updated": "2023-11-06T21:48:46Z",
            "published": "2023-11-06T21:48:46Z",
            "summary": "Black hole solutions in the braneworld scenario are predicted to possess a\ntidal charge parameter, leaving imprints in the quasinormal spectrum. We\nconduct an extensive computation of such spectrum, and use it to construct a\nwaveform model for the ringdown relaxation regime of binary black hole mergers\nobserved by LIGO and Virgo. Applying a Bayesian time-domain analysis formalism,\nwe analyse a selected dataset from the GWTC-3 LIGO-Virgo-Kagra catalog of\nbinary coalescences, bounding the value of the tidal charge. With our analysis\nwe obtain the first robust constraints on such charges, highlighting the\nimportance of accounting for the previously ignored correlations with the other\nblack hole intrinsic parameters.",
            "author": [
                "Akash K Mishra",
                "Gregorio Carullo",
                "Sumanta Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03556v1",
                "http://arxiv.org/pdf/2311.03556v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03551v1",
            "title": "Context Unlocks Emotions: Text-based Emotion Classification Dataset\n  Auditing with Large Language Models",
            "updated": "2023-11-06T21:34:49Z",
            "published": "2023-11-06T21:34:49Z",
            "summary": "The lack of contextual information in text data can make the annotation\nprocess of text-based emotion classification datasets challenging. As a result,\nsuch datasets often contain labels that fail to consider all the relevant\nemotions in the vocabulary. This misalignment between text inputs and labels\ncan degrade the performance of machine learning models trained on top of them.\nAs re-annotating entire datasets is a costly and time-consuming task that\ncannot be done at scale, we propose to use the expressive capabilities of large\nlanguage models to synthesize additional context for input text to increase its\nalignment with the annotated emotional labels. In this work, we propose a\nformal definition of textual context to motivate a prompting strategy to\nenhance such contextual information. We provide both human and empirical\nevaluation to demonstrate the efficacy of the enhanced context. Our method\nimproves alignment between inputs and their human-annotated labels from both an\nempirical and human-evaluated standpoint.",
            "author": [
                "Daniel Yang",
                "Aditya Kommineni",
                "Mohammad Alshehri",
                "Nilamadhab Mohanty",
                "Vedant Modi",
                "Jonathan Gratch",
                "Shrikanth Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03551v1",
                "http://arxiv.org/pdf/2311.03551v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03550v1",
            "title": "United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure\n  Learning from Videos",
            "updated": "2023-11-06T21:33:56Z",
            "published": "2023-11-06T21:33:56Z",
            "summary": "Given multiple videos of the same task, procedure learning addresses\nidentifying the key-steps and determining their order to perform the task. For\nthis purpose, existing approaches use the signal generated from a pair of\nvideos. This makes key-steps discovery challenging as the algorithms lack\ninter-videos perspective. Instead, we propose an unsupervised Graph-based\nProcedure Learning (GPL) framework. GPL consists of the novel UnityGraph that\nrepresents all the videos of a task as a graph to obtain both intra-video and\ninter-videos context. Further, to obtain similar embeddings for the same\nkey-steps, the embeddings of UnityGraph are updated in an unsupervised manner\nusing the Node2Vec algorithm. Finally, to identify the key-steps, we cluster\nthe embeddings using KMeans. We test GPL on benchmark ProceL, CrossTask, and\nEgoProceL datasets and achieve an average improvement of 2% on third-person\ndatasets and 3.6% on EgoProceL over the state-of-the-art.",
            "author": [
                "Siddhant Bansal",
                "Chetan Arora",
                "C. V. Jawahar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03550v1",
                "http://arxiv.org/pdf/2311.03550v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03547v1",
            "title": "InterVLS: Interactive Model Understanding and Improvement with\n  Vision-Language Surrogates",
            "updated": "2023-11-06T21:30:59Z",
            "published": "2023-11-06T21:30:59Z",
            "summary": "Deep learning models are widely used in critical applications, highlighting\nthe need for pre-deployment model understanding and improvement. Visual\nconcept-based methods, while increasingly used for this purpose, face\nchallenges: (1) most concepts lack interpretability, (2) existing methods\nrequire model knowledge, often unavailable at run time. Additionally, (3) there\nlacks a no-code method for post-understanding model improvement. Addressing\nthese, we present InterVLS. The system facilitates model understanding by\ndiscovering text-aligned concepts, measuring their influence with\nmodel-agnostic linear surrogates. Employing visual analytics, InterVLS offers\nconcept-based explanations and performance insights. It enables users to adjust\nconcept influences to update a model, facilitating no-code model improvement.\nWe evaluate InterVLS in a user study, illustrating its functionality with two\nscenarios. Results indicates that InterVLS is effective to help users identify\ninfluential concepts to a model, gain insights and adjust concept influence to\nimprove the model. We conclude with a discussion based on our study results.",
            "author": [
                "Jinbin Huang",
                "Wenbin He",
                "Liang Gou",
                "Liu Ren",
                "Chris Bryan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03547v1",
                "http://arxiv.org/pdf/2311.03547v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03545v1",
            "title": "Time-optimal Design and Control of Electric Race Cars Equipped with\n  Multi-speed Transmissions",
            "updated": "2023-11-06T21:29:27Z",
            "published": "2023-11-06T21:29:27Z",
            "summary": "This paper presents a framework to jointly optimize the design and control of\nan electric race car equipped with a multiple-gear transmission, specifically\naccounting for the discrete gearshift dynamics. We formulate the problem as a\nmixed-integer optimal control problem, and deal with its complexity by\ncombining convex optimization and Pontryagin's Minimum Principle in a\ncomputationally efficient iterative algorithm satisfying necessary conditions\nfor optimality upon convergence. Finally, we leverage our framework to compute\nthe achievable lap time of a race car equipped with a fixed-gear transmission,\na continuously variable transmission and a multiple-gear transmission with 2 to\n4 speeds, revealing that a multiple-gear transmission can strike the best\ntrade-off in terms of electric motor control, and transmission weight and\nefficiency, ultimately yielding the overall best lap time.",
            "author": [
                "Camiel Cartignij",
                "Mauro Salazar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03545v1",
                "http://arxiv.org/pdf/2311.03545v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03543v1",
            "title": "Enabling Dynamic Selection of Implementation Variants in Component-Based\n  Parallel Programming for Heterogeneous Systems",
            "updated": "2023-11-06T21:28:20Z",
            "published": "2023-11-06T21:28:20Z",
            "summary": "Heterogeneous systems, consisting of CPUs and GPUs, offer the capability to\naddress the demands of compute- and data-intensive applications. However,\nprogramming such systems is challenging, requiring knowledge of various\nparallel programming frameworks. This paper introduces COMPAR, a\ncomponent-based parallel programming framework that enables the exposure and\nselection of multiple implementation variants of components at runtime. The\nframework leverages compiler directive-based language extensions to annotate\nthe source code and generate the necessary glue code for the StarPU runtime\nsystem. COMPAR provides a unified view of implementation variants and allows\nfor intelligent selection based on runtime context. Our evaluation demonstrates\nthe effectiveness of COMPAR through benchmark applications. The proposed\napproach simplifies heterogeneous parallel programming and promotes code reuse\nwhile achieving optimal performance.",
            "author": [
                "Suejb Memeti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03543v1",
                "http://arxiv.org/pdf/2311.03543v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03541v1",
            "title": "Orbit separation dimension as complexity measure for primitive inflation\n  tilings",
            "updated": "2023-11-06T21:24:43Z",
            "published": "2023-11-06T21:24:43Z",
            "summary": "Orbit separation dimension (OSD), previously introduced as amorphic\ncomplexity, is a powerful complexity measure for topological dynamical systems\nwith pure-point spectrum. Here, we develop methods and tools for it that allow\na systematic application to translation dynamical systems of tiling spaces that\nare generated by primitive inflation rules. These systems share many nice\nproperties that permit the explicit computation of the OSD, thus providing a\nrich class of examples with non-trivial OSD.",
            "author": [
                "Michael Baake",
                "Franz G\u00e4hler",
                "Philipp Gohlke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03541v1",
                "http://arxiv.org/pdf/2311.03541v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "37B52, 52C23"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03538v2",
            "title": "On an Optimal Stopping Problem with a Discontinuous Reward",
            "updated": "2023-11-27T19:57:13Z",
            "published": "2023-11-06T21:18:59Z",
            "summary": "We study an optimal stopping problem with an unbounded, time-dependent and\ndiscontinuous reward function.This problem is motivated by the pricing of a\nvariable annuity contract with guaranteed minimum maturity benefit, under the\nassumption that the policyholder's surrender behaviour maximizes the\nrisk-neutral value of the contract. We consider a general fee and surrender\ncharge function, and give a condition under which optimal stopping always\noccurs at maturity. Using an alternative representation for the value function\nof the optimization problem, we study its analytical properties and the\nresulting surrender (or exercise) region. In particular, we show that the\nnon-emptiness and the shape of the surrender region are fully characterized by\nthe fee and the surrender charge functions, which provides a powerful tool to\nunderstand their interrelation and how it affects early surrenders and the\noptimal surrender boundary. Under certain conditions on these two functions, we\ndevelop three representations for the value function; two are analogous to\ntheir American option counterpart, and one is new to the actuarial and American\noption pricing literature.",
            "author": [
                "Anne Mackay",
                "Marie-Claude Vachon"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.36565.40160",
                "http://arxiv.org/abs/2311.03538v2",
                "http://arxiv.org/pdf/2311.03538v2"
            ],
            "primary_category": "q-fin.MF",
            "category": [
                "q-fin.MF",
                "q-fin.CP",
                "q-fin.PR",
                "91G80, 62P05, 60G40, 35R35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03537v1",
            "title": "Leveraging point annotations in segmentation learning with boundary loss",
            "updated": "2023-11-06T21:18:39Z",
            "published": "2023-11-06T21:18:39Z",
            "summary": "This paper investigates the combination of intensity-based distance maps with\nboundary loss for point-supervised semantic segmentation. By design the\nboundary loss imposes a stronger penalty on the false positives the farther\naway from the object they occur. Hence it is intuitively inappropriate for weak\nsupervision, where the ground truth label may be much smaller than the actual\nobject and a certain amount of false positives (w.r.t. the weak ground truth)\nis actually desirable. Using intensity-aware distances instead may alleviate\nthis drawback, allowing for a certain amount of false positives without a\nsignificant increase to the training loss. The motivation for applying the\nboundary loss directly under weak supervision lies in its great success for\nfully supervised segmentation tasks, but also in not requiring extra priors or\noutside information that is usually required -- in some form -- with existing\nweakly supervised methods in the literature. This formulation also remains\npotentially more attractive than existing CRF-based regularizers, due to its\nsimplicity and computational efficiency. We perform experiments on two\nmulti-class datasets; ACDC (heart segmentation) and POEM (whole-body abdominal\norgan segmentation). Preliminary results are encouraging and show that this\nsupervision strategy has great potential. On ACDC it outperforms the CRF-loss\nbased approach, and on POEM data it performs on par with it. The code for all\nour experiments is openly available.",
            "author": [
                "Eva Breznik",
                "Hoel Kervadec",
                "Filip Malmberg",
                "Joel Kullberg",
                "H\u00e5kan Ahlstr\u00f6m",
                "Marleen de Bruijne",
                "Robin Strand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03537v1",
                "http://arxiv.org/pdf/2311.03537v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03533v1",
            "title": "Quantifying Uncertainty in Natural Language Explanations of Large\n  Language Models",
            "updated": "2023-11-06T21:14:40Z",
            "published": "2023-11-06T21:14:40Z",
            "summary": "Large Language Models (LLMs) are increasingly used as powerful tools for\nseveral high-stakes natural language processing (NLP) applications. Recent\nprompting works claim to elicit intermediate reasoning steps and key tokens\nthat serve as proxy explanations for LLM predictions. However, there is no\ncertainty whether these explanations are reliable and reflect the LLMs\nbehavior. In this work, we make one of the first attempts at quantifying the\nuncertainty in explanations of LLMs. To this end, we propose two novel metrics\n-- $\\textit{Verbalized Uncertainty}$ and $\\textit{Probing Uncertainty}$ -- to\nquantify the uncertainty of generated explanations. While verbalized\nuncertainty involves prompting the LLM to express its confidence in its\nexplanations, probing uncertainty leverages sample and model perturbations as a\nmeans to quantify the uncertainty. Our empirical analysis of benchmark datasets\nreveals that verbalized uncertainty is not a reliable estimate of explanation\nconfidence. Further, we show that the probing uncertainty estimates are\ncorrelated with the faithfulness of an explanation, with lower uncertainty\ncorresponding to explanations with higher faithfulness. Our study provides\ninsights into the challenges and opportunities of quantifying uncertainty in\nLLM explanations, contributing to the broader discussion of the trustworthiness\nof foundation models.",
            "author": [
                "Sree Harsha Tanneru",
                "Chirag Agarwal",
                "Himabindu Lakkaraju"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03533v1",
                "http://arxiv.org/pdf/2311.03533v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05776v1",
            "title": "Multi-fidelity Bayesian Optimisation of Syngas Fermentation Simulators",
            "updated": "2023-11-06T21:09:04Z",
            "published": "2023-11-06T21:09:04Z",
            "summary": "A Bayesian optimization approach for maximizing the gas conversion rate in an\nindustrial-scale bioreactor for syngas fermentation is presented. We have\naccess to a high-fidelity, computational fluid dynamic (CFD) reactor model and\na low-fidelity ideal-mixing-based reactor model. The goal is to maximize the\ngas conversion rate, with respect to the input variables (e.g., pressure,\nbiomass concentration, gas flow rate). Due to the high cost of the CFD reactor\nmodel, a multi-fidelity Bayesian optimization algorithm is adopted to solve the\noptimization problem using both high and low fidelities. We first describe the\nproblem in the context of syngas fermentation followed by our approach to\nsolving simulator optimization using multiple fidelities. We discuss concerns\nregarding significant differences in fidelity cost and their impact on fidelity\nsampling and conclude with a discussion on the integration of real-world\nfermentation data.",
            "author": [
                "Mahdi Eskandari",
                "Lars Puiman",
                "Jakob Zeitler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05776v1",
                "http://arxiv.org/pdf/2311.05776v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03526v1",
            "title": "Towards Automated Negative Sampling in Implicit Recommendation",
            "updated": "2023-11-06T21:05:00Z",
            "published": "2023-11-06T21:05:00Z",
            "summary": "Negative sampling methods are vital in implicit recommendation models as they\nallow us to obtain negative instances from massive unlabeled data. Most\nexisting approaches focus on sampling hard negative samples in various ways.\nThese studies are orthogonal to the recommendation model and implicit datasets.\nHowever, such an idea contradicts the common belief in AutoML that the model\nand dataset should be matched. Empirical experiments suggest that the\nbest-performing negative sampler depends on the implicit dataset and the\nspecific recommendation model. Hence, we propose a hypothesis that the negative\nsampler should align with the capacity of the recommendation models as well as\nthe statistics of the datasets to achieve optimal performance. A mismatch\nbetween these three would result in sub-optimal outcomes. An intuitive idea to\naddress the mismatch problem is to exhaustively select the best-performing\nnegative sampler given the model and dataset. However, such an approach is\ncomputationally expensive and time-consuming, leaving the problem unsolved. In\nthis work, we propose the AutoSample framework that adaptively selects the\nbest-performing negative sampler among candidates. Specifically, we propose a\nloss-to-instance approximation to transform the negative sampler search task\ninto the learning task over a weighted sum, enabling end-to-end training of the\nmodel. We also designed an adaptive search algorithm to extensively and\nefficiently explore the search space. A specific initialization approach is\nalso obtained to better utilize the obtained model parameters during the search\nstage, which is similar to curriculum learning and leads to better performance\nand less computation resource consumption. We evaluate the proposed framework\non four benchmarks over three models. Extensive experiments demonstrate the\neffectiveness and efficiency of our proposed framework.",
            "author": [
                "Fuyuan Lyu",
                "Yaochen Hu",
                "Xing Tang",
                "Yingxue Zhang",
                "Ruiming Tang",
                "Xue Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03526v1",
                "http://arxiv.org/pdf/2311.03526v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03518v2",
            "title": "High-resolution power equipment recognition based on improved\n  self-attention",
            "updated": "2023-12-07T00:45:21Z",
            "published": "2023-11-06T20:51:37Z",
            "summary": "The current trend of automating inspections at substations has sparked a\nsurge in interest in the field of transformer image recognition. However, due\nto restrictions in the number of parameters in existing models, high-resolution\nimages can't be directly applied, leaving significant room for enhancing\nrecognition accuracy. Addressing this challenge, the paper introduces a novel\nimprovement on deep self-attention networks tailored for this issue. The\nproposed model comprises four key components: a foundational network, a region\nproposal network, a module for extracting and segmenting target areas, and a\nfinal prediction network. The innovative approach of this paper differentiates\nitself by decoupling the processes of part localization and recognition,\ninitially using low-resolution images for localization followed by\nhigh-resolution images for recognition. Moreover, the deep self-attention\nnetwork's prediction mechanism uniquely incorporates the semantic context of\nimages, resulting in substantially improved recognition performance.\nComparative experiments validate that this method outperforms the two other\nprevalent target recognition models, offering a groundbreaking perspective for\nautomating electrical equipment inspections.",
            "author": [
                "Siyi Zhang",
                "Cheng Liu",
                "Xiang Li",
                "Xin Zhai",
                "Zhen Wei",
                "Sizhe Li",
                "Xun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03518v2",
                "http://arxiv.org/pdf/2311.03518v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03517v1",
            "title": "SoundCam: A Dataset for Finding Humans Using Room Acoustics",
            "updated": "2023-11-06T20:51:16Z",
            "published": "2023-11-06T20:51:16Z",
            "summary": "A room's acoustic properties are a product of the room's geometry, the\nobjects within the room, and their specific positions. A room's acoustic\nproperties can be characterized by its impulse response (RIR) between a source\nand listener location, or roughly inferred from recordings of natural signals\npresent in the room. Variations in the positions of objects in a room can\neffect measurable changes in the room's acoustic properties, as characterized\nby the RIR. Existing datasets of RIRs either do not systematically vary\npositions of objects in an environment, or they consist of only simulated RIRs.\nWe present SoundCam, the largest dataset of unique RIRs from in-the-wild rooms\npublicly released to date. It includes 5,000 10-channel real-world measurements\nof room impulse responses and 2,000 10-channel recordings of music in three\ndifferent rooms, including a controlled acoustic lab, an in-the-wild living\nroom, and a conference room, with different humans in positions throughout each\nroom. We show that these measurements can be used for interesting tasks, such\nas detecting and identifying humans, and tracking their positions.",
            "author": [
                "Mason Wang",
                "Samuel Clarke",
                "Jui-Hsien Wang",
                "Ruohan Gao",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03517v1",
                "http://arxiv.org/pdf/2311.03517v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03512v1",
            "title": "Towards the Impossibility of Quantum Public Key Encryption with\n  Classical Keys from One-Way Functions",
            "updated": "2023-11-06T20:41:25Z",
            "published": "2023-11-06T20:41:25Z",
            "summary": "There has been a recent interest in proposing quantum protocols whose\nsecurity relies on weaker computational assumptions than their classical\ncounterparts. Importantly to our work, it has been recently shown that\npublic-key encryption (PKE) from one-way functions (OWF) is possible if we\nconsider quantum public keys. Notice that we do not expect classical PKE from\nOWF given the impossibility results of Impagliazzo and Rudich (STOC'89).\nHowever, the distribution of quantum public keys is a challenging task.\nTherefore, the main question that motivates our work is if quantum PKE from OWF\nis possible if we have classical public keys. Such protocols are impossible if\nciphertexts are also classical, given the impossibility result of Austrin et\nal. (CRYPTO'22) of quantum enhanced key-agreement (KA) with classical\ncommunication. In this paper, we focus on black-box separation for PKE with\nclassical public key and quantum ciphertext from OWF under the polynomial\ncompatibility conjecture, first introduced in Austrin et al.. More precisely,\nwe show the separation when the decryption algorithm of the PKE does not query\nthe OWF. We prove our result by extending the techniques of Austrin et al. and\nwe show an attack for KA in an extended classical communication model where the\nlast message in the protocol can be a quantum state.",
            "author": [
                "Samuel Bouaziz--Ermann",
                "Alex B. Grilo",
                "Damien Vergnaud",
                "Quoc-Huy Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03512v1",
                "http://arxiv.org/pdf/2311.03512v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03510v1",
            "title": "Spoken Dialogue System for Medical Prescription Acquisition on\n  Smartphone: Development, Corpus and Evaluation",
            "updated": "2023-11-06T20:36:55Z",
            "published": "2023-11-06T20:36:55Z",
            "summary": "Hospital information systems (HIS) have become an essential part of\nhealthcare institutions and now incorporate prescribing support software.\nPrescription support software allows for structured information capture, which\nimproves the safety, appropriateness and efficiency of prescriptions and\nreduces the number of adverse drug events (ADEs). However, such a system\nincreases the amount of time physicians spend at a computer entering\ninformation instead of providing medical care. In addition, any new visiting\nclinician must learn to manage complex interfaces since each HIS has its own\ninterfaces. In this paper, we present a natural language interface for\ne-prescribing software in the form of a spoken dialogue system accessible on a\nsmartphone. This system allows prescribers to record their prescriptions\nverbally, a form of interaction closer to their usual practice. The system\nextracts the formal representation of the prescription ready to be checked by\nthe prescribing software and uses the dialogue to request mandatory\ninformation, correct errors or warn of particular situations. Since, to the\nbest of our knowledge, there is no existing voice-based prescription dialogue\nsystem, we present the system developed in a low-resource environment, focusing\non dialogue modeling, semantic extraction and data augmentation. The system was\nevaluated in the wild with 55 participants. This evaluation showed that our\nsystem has an average prescription time of 66.15 seconds for physicians and\n35.64 seconds for other experts, and a task success rate of 76\\% for physicians\nand 72\\% for other experts. All evaluation data were recorded and annotated to\nform PxCorpus, the first spoken drug prescription corpus that has been made\nfully available to the community\n(\\url{https://doi.org/10.5281/zenodo.6524162}).",
            "author": [
                "Ali Can Kocabiyikoglu",
                "Fran\u00e7ois Portet",
                "Jean-Marc Babouchkine",
                "Prudence Gibert",
                "Herv\u00e9 Blanchon",
                "Ga\u00ebtan Gavazzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03510v1",
                "http://arxiv.org/pdf/2311.03510v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03508v2",
            "title": "Astrocytes as a mechanism for meta-plasticity and contextually-guided\n  network function",
            "updated": "2023-11-10T15:59:40Z",
            "published": "2023-11-06T20:31:01Z",
            "summary": "Astrocytes are a ubiquitous and enigmatic type of non-neuronal cell and are\nfound in the brain of all vertebrates. While traditionally viewed as being\nsupportive of neurons, it is increasingly recognized that astrocytes may play a\nmore direct and active role in brain function and neural computation. On\naccount of their sensitivity to a host of physiological covariates and ability\nto modulate neuronal activity and connectivity on slower time scales,\nastrocytes may be particularly well poised to modulate the dynamics of neural\ncircuits in functionally salient ways. In the current paper, we seek to capture\nthese features via actionable abstractions within computational models of\nneuron-astrocyte interaction. Specifically, we engage how nested feedback loops\nof neuron-astrocyte interaction, acting over separated time-scales may endow\nastrocytes with the capability to enable learning in context-dependent\nsettings, where fluctuations in task parameters may occur much more slowly than\nwithin-task requirements. We pose a general model of neuron-synapse-astrocyte\ninteraction and use formal analysis to characterize how astrocytic modulation\nmay constitute a form of meta-plasticity, altering the ways in which synapses\nand neurons adapt as a function of time. We then embed this model in a\nbandit-based reinforcement learning task environment, and show how the presence\nof time-scale separated astrocytic modulation enables learning over multiple\nfluctuating contexts. Indeed, these networks learn far more reliably versus\ndynamically homogeneous networks and conventional non-network-based bandit\nalgorithms. Our results indicate how the presence of neuron-astrocyte\ninteraction in the brain may benefit learning over different time-scales and\nthe conveyance of task-relevant contextual information onto circuit dynamics.",
            "author": [
                "Lulu Gong",
                "Fabio Pasqualetti",
                "Thomas Papouin",
                "ShiNung Ching"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03508v2",
                "http://arxiv.org/pdf/2311.03508v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03505v1",
            "title": "2D Magnetic Heterostructures: Spintronics and Quantum Future",
            "updated": "2023-11-06T20:27:56Z",
            "published": "2023-11-06T20:27:56Z",
            "summary": "The discovery of two-dimensional (2D) magnetism within atomically thin\nstructures derived from layered crystals has opened up a new realm for\nexploring magnetic heterostructures. This emerging field provides a\nfoundational platform for investigating unique physical properties and\nexquisite phenomena at the nanometer and molecular/atomic scales. By\nengineering 2D interfaces using physical methods and selecting interlayer\ninteractions, we unlock the potential for extraordinary exchange dynamics. This\npotential extends to high-performance and high-density magnetic memory\napplications, as well as future advancements in neuromorphic and quantum\ncomputing. This review delves into recent advances in 2D magnets, elucidates\nthe mechanisms behind 2D interfaces, and highlights the development of 2D\ndevices for spintronics and quantum information. Particular focus is placed on\n2D magnetic heterostructures with topological properties, promising for a\nresilient and low-error information system. Finally, we discuss the trends of\n2D heterostructures for future electronics, considering the challenges and\nopportunities from physics, material synthesis, and technological prospective.",
            "author": [
                "Bingyu Zhang",
                "Pengcheng Lu",
                "Roozbeh Tabrizian",
                "Philip X. -L. Feng",
                "Yingying Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03505v1",
                "http://arxiv.org/pdf/2311.03505v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03504v1",
            "title": "Convolution finite element-based digital image correlation for\n  displacement and strain measurements",
            "updated": "2023-11-06T20:21:45Z",
            "published": "2023-11-06T20:21:45Z",
            "summary": "This work presents a novel global digital image correlation (DIC) method,\nbased on a newly developed convolution finite element (C-FE) approximation. The\nconvolution approximation can rely on the mesh of linear finite elements and\nenables arbitrarily high order approximations without adding more degrees of\nfreedom. Therefore, the C-FE based DIC can be more accurate than {the} usual FE\nbased DIC by providing highly smooth and accurate displacement and strain\nresults with the same element size. The detailed formulation and implementation\nof the method have been discussed in this work. The controlling parameters in\nthe method include the polynomial order, patch size, and dilation. A general\nchoice of the parameters and their potential adaptivity have been discussed.\nThe proposed DIC method has been tested by several representative examples,\nincluding the DIC challenge 2.0 benchmark problems, with comparison to the\nusual FE based DIC. C-FE outperformed FE in all the DIC results for the tested\nexamples. This work demonstrates the potential of C-FE and opens a new avenue\nto enable highly smooth, accurate, and robust DIC analysis for full-field\ndisplacement and strain measurements.",
            "author": [
                "Ye Lu",
                "Weidong Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03504v1",
                "http://arxiv.org/pdf/2311.03504v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03501v1",
            "title": "Joint Sparse Estimation with Cardinality Constraint via Mixed-Integer\n  Semidefinite Programming",
            "updated": "2023-11-06T20:18:58Z",
            "published": "2023-11-06T20:18:58Z",
            "summary": "The multiple measurement vectors (MMV) problem refers to the joint estimation\nof a row-sparse signal matrix from multiple realizations of mixtures with a\nknown dictionary. As a generalization of the standard sparse representation\nproblem for a single measurement, this problem is fundamental in various\napplications in signal processing, e.g., spectral analysis and\ndirection-of-arrival (DOA) estimation. In this paper, we consider the maximum a\nposteriori (MAP) estimation for the MMV problem, which is classically\nformulated as a regularized least-squares (LS) problem with an\n$\\ell_{2,0}$-norm constraint, and derive an equivalent mixed-integer\nsemidefinite program (MISDP) reformulation. The proposed MISDP reformulation\ncan be exactly solved by a generic MISDP solver, which, however, becomes\ncomputationally demanding for problems of extremely large dimensions. To\nfurther reduce the computation time in such scenarios, a relaxation-based\napproach can be employed to obtain an approximate solution of the MISDP\nreformulation, at the expense of a reduced estimation performance. Numerical\nsimulations in the context of DOA estimation demonstrate the improved error\nperformance of our proposed method in comparison to several popular DOA\nestimation methods. In particular, compared to the deterministic maximum\nlikelihood (DML) estimator, which is often used as a benchmark, the proposed\nmethod applied with a state-of-the-art MISDP solver exhibits a superior\nestimation performance at a significantly reduced running time. Moreover,\nunlike other nonconvex approaches for the MMV problem, including the greedy\nmethods and the sparse Bayesian learning, the proposed MISDP-based method\noffers a guarantee of finding a global optimum.",
            "author": [
                "Tianyi Liu",
                "Frederic Matter",
                "Alexander Sorg",
                "Marc E. Pfetsch",
                "Martin Haardt",
                "Marius Pesavento"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03501v1",
                "http://arxiv.org/pdf/2311.03501v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03500v1",
            "title": "Predicting Age from White Matter Diffusivity with Residual Learning",
            "updated": "2023-11-06T20:18:26Z",
            "published": "2023-11-06T20:18:26Z",
            "summary": "Imaging findings inconsistent with those expected at specific chronological\nage ranges may serve as early indicators of neurological disorders and\nincreased mortality risk. Estimation of chronological age, and deviations from\nexpected results, from structural MRI data has become an important task for\ndeveloping biomarkers that are sensitive to such deviations. Complementary to\nstructural analysis, diffusion tensor imaging (DTI) has proven effective in\nidentifying age-related microstructural changes within the brain white matter,\nthereby presenting itself as a promising additional modality for brain age\nprediction. Although early studies have sought to harness DTI's advantages for\nage estimation, there is no evidence that the success of this prediction is\nowed to the unique microstructural and diffusivity features that DTI provides,\nrather than the macrostructural features that are also available in DTI data.\nTherefore, we seek to develop white-matter-specific age estimation to capture\ndeviations from normal white matter aging. Specifically, we deliberately\ndisregard the macrostructural information when predicting age from DTI scalar\nimages, using two distinct methods. The first method relies on extracting only\nmicrostructural features from regions of interest. The second applies 3D\nresidual neural networks (ResNets) to learn features directly from the images,\nwhich are non-linearly registered and warped to a template to minimize\nmacrostructural variations. When tested on unseen data, the first method yields\nmean absolute error (MAE) of 6.11 years for cognitively normal participants and\nMAE of 6.62 years for cognitively impaired participants, while the second\nmethod achieves MAE of 4.69 years for cognitively normal participants and MAE\nof 4.96 years for cognitively impaired participants. We find that the ResNet\nmodel captures subtler, non-macrostructural features for brain age prediction.",
            "author": [
                "Chenyu Gao",
                "Michael E. Kim",
                "Ho Hin Lee",
                "Qi Yang",
                "Nazirah Mohd Khairi",
                "Praitayini Kanakaraj",
                "Nancy R. Newlin",
                "Derek B. Archer",
                "Angela L. Jefferson",
                "Warren D. Taylor",
                "Brian D. Boyd",
                "Lori L. Beason-Held",
                "Susan M. Resnick",
                "The BIOCARD Study Team",
                "Yuankai Huo",
                "Katherine D. Van Schaik",
                "Kurt G. Schilling",
                "Daniel Moyer",
                "Ivana I\u0161gum",
                "Bennett A. Landman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03500v1",
                "http://arxiv.org/pdf/2311.03500v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03498v1",
            "title": "In-Context Exemplars as Clues to Retrieving from Large Associative\n  Memory",
            "updated": "2023-11-06T20:13:29Z",
            "published": "2023-11-06T20:13:29Z",
            "summary": "Recently, large language models (LLMs) have made remarkable progress in\nnatural language processing. The most representative ability of LLMs is\nin-context learning (ICL), which enables LLMs to learn patterns from in-context\nexemplars without training. The performance of ICL greatly depends on the\nexemplars used. However, how to choose exemplars remains unclear due to the\nlack of understanding of how in-context learning works. In this paper, we\npresent a novel perspective on ICL by conceptualizing it as contextual\nretrieval from a model of associative memory. We establish a theoretical\nframework of ICL based on Hopfield Networks. Based on our framework, we look\ninto how in-context exemplars influence the performance of ICL and propose more\nefficient active exemplar selection. Our study sheds new light on the mechanism\nof ICL by connecting it to memory retrieval, with potential implications for\nadvancing the understanding of LLMs.",
            "author": [
                "Jiachen Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03498v1",
                "http://arxiv.org/pdf/2311.03498v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03496v1",
            "title": "Asynchronous Local Computations in Distributed Bayesian Learning",
            "updated": "2023-11-06T20:11:41Z",
            "published": "2023-11-06T20:11:41Z",
            "summary": "Due to the expanding scope of machine learning (ML) to the fields of sensor\nnetworking, cooperative robotics and many other multi-agent systems,\ndistributed deployment of inference algorithms has received a lot of attention.\nThese algorithms involve collaboratively learning unknown parameters from\ndispersed data collected by multiple agents. There are two competing aspects in\nsuch algorithms, namely, intra-agent computation and inter-agent communication.\nTraditionally, algorithms are designed to perform both synchronously. However,\ncertain circumstances need frugal use of communication channels as they are\neither unreliable, time-consuming, or resource-expensive. In this paper, we\npropose gossip-based asynchronous communication to leverage fast computations\nand reduce communication overhead simultaneously. We analyze the effects of\nmultiple (local) intra-agent computations by the active agents between\nsuccessive inter-agent communications. For local computations, Bayesian\nsampling via unadjusted Langevin algorithm (ULA) MCMC is utilized. The\ncommunication is assumed to be over a connected graph (e.g., as in\ndecentralized learning), however, the results can be extended to coordinated\ncommunication where there is a central server (e.g., federated learning). We\ntheoretically quantify the convergence rates in the process. To demonstrate the\nefficacy of the proposed algorithm, we present simulations on a toy problem as\nwell as on real world data sets to train ML models to perform classification\ntasks. We observe faster initial convergence and improved performance accuracy,\nespecially in the low data range. We achieve on average 78% and over 90%\nclassification accuracy respectively on the Gamma Telescope and mHealth data\nsets from the UCI ML repository.",
            "author": [
                "Kinjal Bhar",
                "He Bai",
                "Jemin George",
                "Carl Busart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03496v1",
                "http://arxiv.org/pdf/2311.03496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03489v2",
            "title": "Leveraging High-Level Synthesis and Large Language Models to Generate,\n  Simulate, and Deploy a Uniform Random Number Generator Hardware Design",
            "updated": "2023-11-21T17:28:17Z",
            "published": "2023-11-06T19:58:26Z",
            "summary": "We present a new high-level synthesis methodology for using large language\nmodel tools to generate hardware designs. The methodology uses exclusively\nopen-source tools excluding the large language model. As a case study, we use\nour methodology to generate a permuted congruential random number generator\ndesign with a wishbone interface. We verify the functionality and quality of\nthe random number generator design using large language model-generated\nsimulations and the Dieharder randomness test suite. We document all the large\nlanguage model chat logs, Python scripts, Verilog scripts, and simulation\nresults used in the case study. We believe that our method of hardware design\ngeneration coupled with the open source silicon 130 nm design tools will\nrevolutionize application-specific integrated circuit design. Our methodology\nsignificantly lowers the bar to entry when building domain-specific computing\naccelerators for the Internet of Things and proof of concept prototypes for\nlater fabrication in more modern process nodes.",
            "author": [
                "James T. Meech"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03489v2",
                "http://arxiv.org/pdf/2311.03489v2"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03486v2",
            "title": "Fostering Human Learning in Sequential Decision-Making: Understanding\n  the Role of Evaluative Feedback",
            "updated": "2023-11-10T04:52:21Z",
            "published": "2023-11-06T19:48:33Z",
            "summary": "Cognitive rehabilitation, STEM skill acquisition, and coaching games such as\nchess often require tutoring decision-making strategies. The advancement of\nAI-driven tutoring systems for facilitating human learning requires an\nunderstanding of the impact of evaluative feedback on human decision-making and\nskill development. To this end, we conduct human experiments using Amazon\nMechanical Turk to study the influence of evaluative feedback on human\ndecision-making in sequential tasks. In these experiments, participants solve\nthe Tower of Hanoi puzzle and receive AI-generated feedback while solving it.\nWe examine how this feedback affects their learning and skill transfer to\nrelated tasks. We also explore various computational models to understand how\npeople incorporate evaluative feedback into their decision-making processes.",
            "author": [
                "Piyush Gupta",
                "Subir Biswas",
                "Vaibhav Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03486v2",
                "http://arxiv.org/pdf/2311.03486v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03478v1",
            "title": "Multi Loss-based Feature Fusion and Top Two Voting Ensemble Decision\n  Strategy for Facial Expression Recognition in the Wild",
            "updated": "2023-11-06T19:30:23Z",
            "published": "2023-11-06T19:30:23Z",
            "summary": "Facial expression recognition (FER) in the wild is a challenging task\naffected by the image quality and has attracted broad interest in computer\nvision. There is no research using feature fusion and ensemble strategy for FER\nsimultaneously. Different from previous studies, this paper applies both\ninternal feature fusion for a single model and feature fusion among multiple\nnetworks, as well as the ensemble strategy. This paper proposes one novel\nsingle model named R18+FAML, as well as one ensemble model named\nR18+FAML-FGA-T2V to improve the performance of the FER in the wild. Based on\nthe structure of ResNet18 (R18), R18+FAML combines internal Feature fusion and\nthree Attention blocks using Multiple Loss functions (FAML) to improve the\ndiversity of the feature extraction. To improve the performance of R18+FAML, we\npropose a Feature fusion among networks based on the Genetic Algorithm (FGA),\nwhich can fuse the convolution kernels for feature extraction of multiple\nnetworks. On the basis of R18+FAML and FGA, we propose one ensemble strategy,\ni.e., the Top Two Voting (T2V) to support the classification of FER, which can\nconsider more classification information comprehensively. Combining the above\nstrategies, R18+FAML-FGA-T2V can focus on the main expression-aware areas.\nExtensive experiments demonstrate that our single model R18+FAML and the\nensemble model R18+FAML-FGA-T2V achieve the accuracies of $\\left( 90.32, 62.17,\n65.83 \\right)\\%$ and $\\left( 91.59, 63.27, 66.63 \\right)\\%$ on three\nchallenging unbalanced FER datasets RAF-DB, AffectNet-8 and AffectNet-7\nrespectively, both outperforming the state-of-the-art results.",
            "author": [
                "Guangyao Zhou",
                "Yuanlun Xie",
                "Wenhong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03478v1",
                "http://arxiv.org/pdf/2311.03478v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03470v1",
            "title": "Orion: A Fully Homomorphic Encryption Compiler for Private Deep Neural\n  Network Inference",
            "updated": "2023-11-06T19:14:17Z",
            "published": "2023-11-06T19:14:17Z",
            "summary": "Fully Homomorphic Encryption (FHE) has the potential to substantially improve\nprivacy and security by enabling computation on encrypted data. This is\nespecially true with deep learning, as today many popular user services are\npowered by neural networks. One of the major challenges facing wide-scale\ndeployment of FHE-secured neural inference is effectively mapping them to the\nFHE domain. FHE poses many programming challenges including packing large\nvectors, handling expensive rotations, and correctly implementing complex\nstrided convolutions. This makes programming FHE inferences prone to poor\nperformance and errors. In this paper we overcome these challenges with Orion,\nan automated optimizing FHE compiler for neural inference. Orion automatically\nmaps PyTorch-specified networks to FHE, handling common layer types and\narbitrary tensor shapes and strides. Moreover, we develop novel optimizations\nthat balance dense FHE vector packing, efficient rotations, and minimize\noperations to improve performance. We have implemented Orion, which will be\nopen sourced, and evaluated it on common benchmarks used by the FHE deep\nlearning community. We compare Orion to multiple state-of-the-art solutions and\nreport iso-accuracy speedups ranging from 2.7$\\times$ to 20.5$\\times$.",
            "author": [
                "Austin Ebel",
                "Karthik Garimella",
                "Brandon Reagen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03470v1",
                "http://arxiv.org/pdf/2311.03470v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03468v1",
            "title": "FinA: Fairness of Adverse Effects in Decision-Making of\n  Human-Cyber-Physical-System",
            "updated": "2023-11-06T19:10:03Z",
            "published": "2023-11-06T19:10:03Z",
            "summary": "Ensuring fairness in decision-making systems within\nHuman-Cyber-Physical-Systems (HCPS) is a pressing concern, particularly when\ndiverse individuals, each with varying behaviors and expectations, coexist\nwithin the same application space, influenced by a shared set of control\nactions in the system. The long-term adverse effects of these actions further\npose the challenge, as historical experiences and interactions shape individual\nperceptions of fairness. This paper addresses the challenge of fairness from an\nequity perspective of adverse effects, taking into account the dynamic nature\nof human behavior and evolving preferences while recognizing the lasting impact\nof adverse effects. We formally introduce the concept of\nFairness-in-Adverse-Effects (FinA) within the HCPS context. We put forth a\ncomprehensive set of five formulations for FinA, encompassing both the\ninstantaneous and long-term aspects of adverse effects. To empirically validate\nthe effectiveness of our FinA approach, we conducted an evaluation within the\ndomain of smart homes, a pertinent HCPS application. The outcomes of our\nevaluation demonstrate that the adoption of FinA significantly enhances the\noverall perception of fairness among individuals, yielding an average\nimprovement of 66.7% when compared to the state-of-the-art method.",
            "author": [
                "Tianyu Zhao",
                "Salma Elmalaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03468v1",
                "http://arxiv.org/pdf/2311.03468v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03463v1",
            "title": "Universal features of $ 2\\to N$ scattering in QCD and gravity from\n  shockwave collisions",
            "updated": "2023-11-06T19:02:57Z",
            "published": "2023-11-06T19:02:57Z",
            "summary": "A remarkable double copy relation of Einstein gravity to QCD in Regge\nasymptotics is $\\Gamma^{\\mu\\nu}= \\frac12C^\\mu C^\\nu- \\frac12N^\\mu N^\\nu$, where\n$\\Gamma^{\\mu\\nu}$ is the gravitational Lipatov vertex in the $2\\to 3$ graviton\nscattering amplitude, $C^\\mu$ its Yang-Mills counterpart, and $N^\\mu$ the QED\nbremssstrahlung vertex. In QCD, the Lipatov vertex is a fundamental building\nblock of the BFKL equation describing $2\\to N$ scattering of gluons at high\nenergies. Likewise, the gravitational Lipatov vertex is a key ingredient in a\n2-D effective field theory framework describing trans-Planckian $2\\to N$\ngraviton scattering. We construct a quantitative correspondence between a\nsemi-classical Yang-Mills framework for radiation in gluon shockwave collisions\nand its counterpart in general relativity. In particular, we demonstrate the\nLipatov double copy in a dilute-dilute approximation corresponding to\n$R_{S,L}$, $R_{S,H}$ $ \\ll b$, with $R_{S,L}$, $R_{S,H}$ the respective\nemergent Schwarzchild radii generated in shockwave collisions and $b$ is the\nimpact parameter. We outline extensions of the correspondence developed here to\nthe dilute-dense computation of gravitational wave radiation in close vicinity\nof one of the black holes, the construction of graviton propagators in the\nshockwave background, and a renormalization group approach to compute\n$2\\rightarrow N$ amplitudes that incorporates graviton reggeization and\ncoherent graviton multiple scattering.",
            "author": [
                "Himanshu Raj",
                "Raju Venugopalan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03463v1",
                "http://arxiv.org/pdf/2311.03463v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03461v2",
            "title": "A low phase noise cavity transmission self-injection locked laser system\n  for atomic physics experiments",
            "updated": "2023-11-10T13:22:55Z",
            "published": "2023-11-06T19:02:32Z",
            "summary": "Lasers with high spectral purity are indispensable for optical clocks and\ncoherent manipulation of atomic and molecular qubits for applications such as\nquantum computing and quantum simulation. Stabilisation of the laser to a\nreference can provide a narrow linewidth and high spectral purity. However,\nwidely-used diode lasers exhibit fast phase noise that prevents high fidelity\nqubit manipulation. Here we demonstrate a self-injection locked diode laser\nsystem utilizing a medium finesse cavity. The cavity not only provides a stable\nresonance frequency, but at the same time acts as a low-pass filter for phase\nnoise beyond the cavity linewidth of around 100 kHz, resulting in low phase\nnoise from dc to the injection lock limit.\n  We model the expected laser performance and benchmark it using a single\ntrapped $^{40}$Ca$^{+}$-ion as a spectrum analyser. We show that the fast phase\nnoise of the laser at relevant Fourier frequencies of 100 kHz to >2 MHz is\nsuppressed to a noise floor of between -110 dBc/Hz and -120 dBc/Hz, an\nimprovement of 20 to 30 dB over state-of-the-art Pound-Drever-Hall-stabilized\nextended-cavity diode lasers. This strong suppression avoids incoherent\n(spurious) spin flips during manipulation of optical qubits and improves\nlaser-driven gates in using diode lasers with applications in quantum logic\nspectroscopy, quantum simulation and quantum computation.",
            "author": [
                "Ludwig Krinner",
                "Kai Dietze",
                "Lennart Pelzer",
                "Nicolas Spethmann",
                "Piet O. Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03461v2",
                "http://arxiv.org/pdf/2311.03461v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.atom-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03454v1",
            "title": "Using Boolean Satisfiability for Exact Shuttling in Trapped-Ion Quantum\n  Computers",
            "updated": "2023-11-06T19:00:22Z",
            "published": "2023-11-06T19:00:22Z",
            "summary": "Trapped ions are a promising technology for building scalable quantum\ncomputers. Not only can they provide a high qubit quality, but they also enable\nmodular architectures, referred to as Quantum Charge Coupled Device (QCCD)\narchitecture. Within these devices, ions can be shuttled (moved) throughout the\ntrap and through different dedicated zones, e.g., a memory zone for storage and\na processing zone for the actual computation. However, this movement incurs a\ncost in terms of required time steps, which increases the probability of\ndecoherence, and, thus, should be minimized. In this paper, we propose a\nformalization of the possible movements in ion traps via Boolean\nsatisfiability. This formalization allows for determining the minimal number of\ntime steps needed for a given quantum algorithm and device architecture, hence\nreducing the decoherence probability. An empirical evaluation confirms that --\nusing the proposed approach -- minimal results (i.e., the lower bound) can be\ndetermined for the first time. An open-source implementation of the proposed\napproach is publicly available at https://github.com/cda-tum/mqt-ion-shuttler.",
            "author": [
                "Daniel Schoenberger",
                "Stefan Hillmich",
                "Matthias Brandl",
                "Robert Wille"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03454v1",
                "http://arxiv.org/pdf/2311.03454v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03449v1",
            "title": "Into the LAIONs Den: Investigating Hate in Multimodal Datasets",
            "updated": "2023-11-06T19:00:05Z",
            "published": "2023-11-06T19:00:05Z",
            "summary": "'Scale the model, scale the data, scale the compute' is the reigning\nsentiment in the world of generative AI today. While the impact of model\nscaling has been extensively studied, we are only beginning to scratch the\nsurface of data scaling and its consequences. This is especially of critical\nimportance in the context of vision-language datasets such as LAION. These\ndatasets are continually growing in size and are built based on large-scale\ninternet dumps such as the Common Crawl, which is known to have numerous\ndrawbacks ranging from quality, legality, and content. The datasets then serve\nas the backbone for large generative models, contributing to the\noperationalization and perpetuation of harmful societal and historical biases\nand stereotypes. In this paper, we investigate the effect of scaling datasets\non hateful content through a comparative audit of two datasets: LAION-400M and\nLAION-2B. Our results show that hate content increased by nearly 12% with\ndataset scale, measured both qualitatively and quantitatively using a metric\nthat we term as Hate Content Rate (HCR). We also found that filtering dataset\ncontents based on Not Safe For Work (NSFW) values calculated based on images\nalone does not exclude all the harmful content in alt-text. Instead, we found\nthat trace amounts of hateful, targeted, and aggressive text remain even when\ncarrying out conservative filtering. We end with a reflection and a discussion\nof the significance of our results for dataset curation and usage in the AI\ncommunity. Code and the meta-data assets curated in this paper are publicly\navailable at https://github.com/vinayprabhu/hate_scaling. Content warning: This\npaper contains examples of hateful text that might be disturbing, distressing,\nand/or offensive.",
            "author": [
                "Abeba Birhane",
                "Vinay Prabhu",
                "Sang Han",
                "Vishnu Naresh Boddeti",
                "Alexandra Sasha Luccioni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03449v1",
                "http://arxiv.org/pdf/2311.03449v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03447v1",
            "title": "Radiative transfer of Lyman-$\u03b1$ photons at cosmic dawn with\n  realistic gas physics",
            "updated": "2023-11-06T19:00:04Z",
            "published": "2023-11-06T19:00:04Z",
            "summary": "The cosmic dawn 21-cm signal is enabled by Ly~$\\alpha$ photons through a\nprocess called the Wouthuysen-Field effect. An accurate model of the signal in\nthis epoch hinges on the accuracy of the computation of the Ly~$\\alpha$\ncoupling, which requires one to calculate the specific intensity of UV\nradiation from sources such as the first stars. Most traditional calculations\nof the Ly~$\\alpha$ coupling assume a delta-function scattering cross-section,\nas the resonant nature of the Ly~$\\alpha$ scattering makes an accurate\nradiative transfer solution computationally expensive. Attempts to improve upon\nthis traditional approach using numerical radiative transfer have recently\nemerged. However, the radiative transfer computation in these treatments\nsuffers from assumptions such as a uniform density of intergalactic gas, zero\ngas temperature, and absence of gas bulk motion, or numerical approximations\nsuch as core skipping. We investigate the role played by these approximations\nin setting the value of the Ly~$\\alpha$ coupling and the 21-cm signal at cosmic\ndawn. We present results of Monte Carlo radiative transfer simulations, without\ncore skipping, and show that neglecting gas temperature in the radiative\ntransfer significantly underestimates the scattering rate and hence the\nLy~$\\alpha$ coupling and the 21-cm signal. We also discuss the effect of these\nprocesses on the 21-cm power spectrum from the cosmic dawn. This work points\nthe way towards higher-accuracy models to enable better inferences from future\nmeasurements.",
            "author": [
                "Shikhar Mittal",
                "Girish Kulkarni",
                "Thibault Garel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03447v1",
                "http://arxiv.org/pdf/2311.03447v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03448v1",
            "title": "An integral algorithm of exponential observables for interacting\n  fermions in quantum Monte Carlo simulation",
            "updated": "2023-11-06T19:00:04Z",
            "published": "2023-11-06T19:00:04Z",
            "summary": "Exponential observables, formulated as $\\log \\langle e^{\\hat{X}}\\rangle$\nwhere $\\hat{X}$ is an extensive quantity, play a critical role in study of\nquantum many-body systems, examples of which include the free-energy and\nentanglement entropy. Given that $e^{X}$ becomes exponentially large (or small)\nin the thermodynamic limit, accurately computing the expectation value of this\nexponential quantity presents a significant challenge. In this Letter, we\npropose a comprehensive algorithm for quantifying these observables in\ninteracting fermion systems, utilizing the determinant quantum Monte Carlo\n(DQMC) method. We have applied this novel algorithm to the 2D half-filled\nHubbard model. At the strong coupling limit, our method showcases a significant\naccuracy improvement compared to conventional methods that are derived from the\ninternal energy. We also illustrate that this novel approach delivers highly\nefficient and precise measurements of the nth R\\'enyi entanglement entropy.\nEven more noteworthy is that this improvement comes without incurring increases\nin computational complexity. This algorithm effectively suppresses exponential\nfluctuations and can be easily generalized to other models.",
            "author": [
                "Xu Zhang",
                "Gaopei Pan",
                "Bin-Bin Chen",
                "Kai Sun",
                "Zi Yang Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03448v1",
                "http://arxiv.org/pdf/2311.03448v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.stat-mech",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03432v1",
            "title": "Seeding Gaussian boson samplers with single photons for enhanced state\n  generation",
            "updated": "2023-11-06T19:00:00Z",
            "published": "2023-11-06T19:00:00Z",
            "summary": "Non-Gaussian quantum states are crucial to fault-tolerant quantum computation\nwith continuous-variable systems. Usually, generation of such states involves\ntradeoffs between success probability and quality of the resultant state. For\nexample, injecting squeezed light into a multimode interferometer and\npostselecting on certain patterns of photon-number outputs in all but one mode,\na fundamentally probabilistic task, can herald the creation of cat states,\nGottesman-Kitaev-Preskill (GKP) states, and more. We consider the addition of a\nnon-Gaussian resource state, particularly single photons, to this configuration\nand show how it improves the qualities and generation probabilities of desired\nstates. With only two modes, adding a single photon source improves GKP-state\nfidelity from 0.68 to 0.95 and adding a second then increases the success\nprobability eightfold; for cat states with a fixed target fidelity, the\nprobability of success can be improved by factors of up to 4 by adding\nsingle-photon sources. These demonstrate the usefulness of additional\ncommonplace non-Gaussian resources for generating desirable states of light.",
            "author": [
                "Valerio Crescimanna",
                "Aaron Z. Goldberg",
                "Khabat Heshami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03432v1",
                "http://arxiv.org/pdf/2311.03432v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03357v1",
            "title": "Exploitation-Guided Exploration for Semantic Embodied Navigation",
            "updated": "2023-11-06T18:59:58Z",
            "published": "2023-11-06T18:59:58Z",
            "summary": "In the recent progress in embodied navigation and sim-to-robot transfer,\nmodular policies have emerged as a de facto framework. However, there is more\nto compositionality beyond the decomposition of the learning load into modular\ncomponents. In this work, we investigate a principled way to syntactically\ncombine these components. Particularly, we propose Exploitation-Guided\nExploration (XGX) where separate modules for exploration and exploitation come\ntogether in a novel and intuitive manner. We configure the exploitation module\nto take over in the deterministic final steps of navigation i.e. when the goal\nbecomes visible. Crucially, an exploitation module teacher-forces the\nexploration module and continues driving an overridden policy optimization.\nXGX, with effective decomposition and novel guidance, improves the\nstate-of-the-art performance on the challenging object navigation task from 70%\nto 73%. Along with better accuracy, through targeted analysis, we show that XGX\nis also more efficient at goal-conditioned exploration. Finally, we show\nsim-to-real transfer to robot hardware and XGX performs over two-fold better\nthan the best baseline from simulation benchmarking. Project page:\nxgxvisnav.github.io",
            "author": [
                "Justin Wasserman",
                "Girish Chowdhary",
                "Abhinav Gupta",
                "Unnat Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03357v1",
                "http://arxiv.org/pdf/2311.03357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03355v1",
            "title": "SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img\n  Synthesis",
            "updated": "2023-11-06T18:59:57Z",
            "published": "2023-11-06T18:59:57Z",
            "summary": "We propose SegGen, a highly-effective training data generation method for\nimage segmentation, which pushes the performance limits of state-of-the-art\nsegmentation models to a significant extent. SegGen designs and integrates two\ndata generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new\nmask-image pairs via our proposed text-to-mask generation model and\nmask-to-image generation model, greatly improving the diversity in segmentation\nmasks for model supervision; (ii) ImgSyn synthesizes new images based on\nexisting masks using the mask-to-image generation model, strongly improving\nimage diversity for model inputs. On the highly competitive ADE20K and COCO\nbenchmarks, our data generation method markedly improves the performance of\nstate-of-the-art segmentation models in semantic segmentation, panoptic\nsegmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU,\nMask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L\nis also significantly increased from 56.1 to 57.4 (+1.3). These promising\nresults strongly suggest the effectiveness of our SegGen even when abundant\nhuman-annotated training data is utilized. Moreover, training with our\nsynthetic data makes the segmentation models more robust towards unseen\ndomains. Project website: https://seggenerator.github.io",
            "author": [
                "Hanrong Ye",
                "Jason Kuen",
                "Qing Liu",
                "Zhe Lin",
                "Brian Price",
                "Dan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03355v1",
                "http://arxiv.org/pdf/2311.03355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03356v1",
            "title": "GLaMM: Pixel Grounding Large Multimodal Model",
            "updated": "2023-11-06T18:59:57Z",
            "published": "2023-11-06T18:59:57Z",
            "summary": "Large Multimodal Models (LMMs) extend Large Language Models to the vision\ndomain. Initial efforts towards LMMs used holistic images and text prompts to\ngenerate ungrounded textual responses. Very recently, region-level LMMs have\nbeen used to generate visually grounded responses. However, they are limited to\nonly referring a single object category at a time, require users to specify the\nregions in inputs, or cannot offer dense pixel-wise object grounding. In this\nwork, we present Grounding LMM (GLaMM), the first model that can generate\nnatural language responses seamlessly intertwined with corresponding object\nsegmentation masks. GLaMM not only grounds objects appearing in the\nconversations but is flexible enough to accept both textual and optional visual\nprompts (region of interest) as input. This empowers users to interact with the\nmodel at various levels of granularity, both in textual and visual domains. Due\nto the lack of standard benchmarks for the novel setting of generating visually\ngrounded detailed conversations, we introduce a comprehensive evaluation\nprotocol with our curated grounded conversations. Our proposed Grounded\nConversation Generation (GCG) task requires densely grounded concepts in\nnatural scenes at a large-scale. To this end, we propose a densely annotated\nGrounding-anything Dataset (GranD) using our proposed automated annotation\npipeline that encompasses 7.5M unique concepts grounded in a total of 810M\nregions available with segmentation masks. Besides GCG, GLaMM also performs\neffectively on several downstream tasks e.g., referring expression\nsegmentation, image and region-level captioning and vision-language\nconversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.",
            "author": [
                "Hanoona Rasheed",
                "Muhammad Maaz",
                "Sahal Shaji",
                "Abdelrahman Shaker",
                "Salman Khan",
                "Hisham Cholakkal",
                "Rao M. Anwer",
                "Erix Xing",
                "Ming-Hsuan Yang",
                "Fahad S. Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03356v1",
                "http://arxiv.org/pdf/2311.03356v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03354v1",
            "title": "CoVLM: Composing Visual Entities and Relationships in Large Language\n  Models Via Communicative Decoding",
            "updated": "2023-11-06T18:59:44Z",
            "published": "2023-11-06T18:59:44Z",
            "summary": "A remarkable ability of human beings resides in compositional reasoning,\ni.e., the capacity to make \"infinite use of finite means\". However, current\nlarge vision-language foundation models (VLMs) fall short of such compositional\nabilities due to their \"bag-of-words\" behaviors and inability to construct\nwords that correctly represent visual entities and the relations among the\nentities. To this end, we propose CoVLM, which can guide the LLM to explicitly\ncompose visual entities and relationships among the text and dynamically\ncommunicate with the vision encoder and detection network to achieve\nvision-language communicative decoding. Specifically, we first devise a set of\nnovel communication tokens for the LLM, for dynamic communication between the\nvisual detection system and the language system. A communication token is\ngenerated by the LLM following a visual entity or a relation, to inform the\ndetection network to propose regions that are relevant to the sentence\ngenerated so far. The proposed regions-of-interests (ROIs) are then fed back\ninto the LLM for better language generation contingent on the relevant regions.\nThe LLM is thus able to compose the visual entities and relationships through\nthe communication tokens. The vision-to-language and language-to-vision\ncommunication are iteratively performed until the entire sentence is generated.\nOur framework seamlessly bridges the gap between visual perception and LLMs and\noutperforms previous VLMs by a large margin on compositional reasoning\nbenchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on\nARO top-1 accuracy). We also achieve state-of-the-art performances on\ntraditional vision-language tasks such as referring expression comprehension\nand visual question answering.",
            "author": [
                "Junyan Li",
                "Delin Chen",
                "Yining Hong",
                "Zhenfang Chen",
                "Peihao Chen",
                "Yikang Shen",
                "Chuang Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03354v1",
                "http://arxiv.org/pdf/2311.03354v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03353v1",
            "title": "Topological Orders Having no Topological Quantum Field Theory\n  Description",
            "updated": "2023-11-06T18:59:09Z",
            "published": "2023-11-06T18:59:09Z",
            "summary": "Systems displaying quantum topological order feature robust characteristics\nthat have been very attractive to quantum computing schemes. It has long been\nbelieved that the salient universal features of topologically ordered systems\nare invariably described by topological quantum field theories. In the current\nwork, we illustrate that this is not necessarily so. Towards this end, we\nconstruct and study a rich class of two- and three-dimensional topologically\nordered models featuring interacting anyons (both Abelian and non-Abelian). In\nthese theories, the lowest excitation energies depend on the relative\ngeometrical placement of the anyons leading to properties that cannot be\ndescribed by topological quantum field theories. We examine these models by\nperforming dualities to systems displaying conventional (i.e., Landau) orders.\nOur approach enables a general method for mapping general Landau type theories\nto topologically ordered dual models. The low-energy subspaces of our models\nare more resilient to thermal effects than those of surface codes.",
            "author": [
                "P. Vojta",
                "G. Ortiz",
                "Z. Nussinov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03353v1",
                "http://arxiv.org/pdf/2311.03353v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.str-el",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03352v1",
            "title": "Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion",
            "updated": "2023-11-06T18:59:01Z",
            "published": "2023-11-06T18:59:01Z",
            "summary": "In this paper, we highlight a problem of evaluation metrics adopted in the\nopen-vocabulary segmentation. That is, the evaluation process still heavily\nrelies on closed-set metrics on zero-shot or cross-dataset pipelines without\nconsidering the similarity between predicted and ground truth categories. To\ntackle this issue, we first survey eleven similarity measurements between two\ncategorical words using WordNet linguistics statistics, text embedding, and\nlanguage models by comprehensive quantitative analysis and user study. Built\nupon those explored measurements, we designed novel evaluation metrics, namely\nOpen mIoU, Open AP, and Open PQ, tailored for three open-vocabulary\nsegmentation tasks. We benchmarked the proposed evaluation metrics on 12\nopen-vocabulary methods of three segmentation tasks. Even though the relative\nsubjectivity of similarity distance, we demonstrate that our metrics can still\nwell evaluate the open ability of the existing open-vocabulary segmentation\nmethods. We hope that our work can bring with the community new thinking about\nhow to evaluate the open ability of models. The evaluation code is released in\ngithub.",
            "author": [
                "Hao Zhou",
                "Tiancheng Shen",
                "Xu Yang",
                "Hai Huang",
                "Xiangtai Li",
                "Lu Qi",
                "Ming-Hsuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03352v1",
                "http://arxiv.org/pdf/2311.03352v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03350v3",
            "title": "Differentiable Cutting-plane Layers for Mixed-integer Linear\n  Optimization",
            "updated": "2023-11-09T17:19:56Z",
            "published": "2023-11-06T18:57:07Z",
            "summary": "We consider the problem of solving a family of parametric mixed-integer\nlinear optimization problems where some entries in the input data change. We\nintroduce the concept of cutting-plane layer (CPL), i.e., a differentiable\ncutting-plane generator mapping the problem data and previous iterates to\ncutting planes. We propose a CPL implementation to generate split cuts, and by\ncombining several CPLs, we devise a differentiable cutting-plane algorithm that\nexploits the repeated nature of parametric instances. In an offline phase, we\ntrain our algorithm by updating the internal parameters controlling the CPLs,\nthus altering cut generation. Once trained, our algorithm computes, with\npredictable execution times and a fixed number of cuts, solutions with low\nintegrality gaps. Preliminary computational tests show that our algorithm\ngeneralizes on unseen instances and captures underlying parametric structures.",
            "author": [
                "Gabriele Dragotto",
                "Stefan Clarke",
                "Jaime Fern\u00e1ndez Fisac",
                "Bartolomeo Stellato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03350v3",
                "http://arxiv.org/pdf/2311.03350v3"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03348v2",
            "title": "Scalable and Transferable Black-Box Jailbreaks for Language Models via\n  Persona Modulation",
            "updated": "2023-11-24T12:50:31Z",
            "published": "2023-11-06T18:55:18Z",
            "summary": "Despite efforts to align large language models to produce harmless responses,\nthey are still vulnerable to jailbreak prompts that elicit unrestricted\nbehaviour. In this work, we investigate persona modulation as a black-box\njailbreaking method to steer a target model to take on personalities that are\nwilling to comply with harmful instructions. Rather than manually crafting\nprompts for each persona, we automate the generation of jailbreaks using a\nlanguage model assistant. We demonstrate a range of harmful completions made\npossible by persona modulation, including detailed instructions for\nsynthesising methamphetamine, building a bomb, and laundering money. These\nautomated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is\n185 times larger than before modulation (0.23%). These prompts also transfer to\nClaude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,\nrespectively. Our work reveals yet another vulnerability in commercial large\nlanguage models and highlights the need for more comprehensive safeguards.",
            "author": [
                "Rusheb Shah",
                "Quentin Feuillade--Montixi",
                "Soroush Pour",
                "Arush Tagade",
                "Stephen Casper",
                "Javier Rando"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03348v2",
                "http://arxiv.org/pdf/2311.03348v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03347v2",
            "title": "Sparse Quantum State Preparation for Strongly Correlated Systems",
            "updated": "2023-11-10T19:36:08Z",
            "published": "2023-11-06T18:53:50Z",
            "summary": "Quantum Computing allows, in principle, the encoding of the exponentially\nscaling many-electron wave function onto a linearly scaling qubit register,\noffering a promising solution to overcome the limitations of traditional\nquantum chemistry methods. An essential requirement for ground state quantum\nalgorithms to be practical is the initialisation of the qubits to a\nhigh-quality approximation of the sought-after ground state. Quantum State\nPreparation (QSP) allows the preparation of approximate eigenstates obtained\nfrom classical calculations, but it is frequently treated as an oracle in\nquantum information. In this study, we conduct QSP on the ground state of\nprototypical strongly correlated systems, up to 28 qubits, using the Hyperion\nGPU-accelerated state-vector emulator. Various variational and non-variational\nmethods are compared in terms of their circuit depth and classical complexity.\nOur results indicate that the recently developed Overlap-ADAPT-VQE algorithm\noffers the most advantageous performance for near-term applications.",
            "author": [
                "C. Feniou",
                "O. Adjoua",
                "B. Claudon",
                "J. Zylberman",
                "E. Giner",
                "J. -P. Piquemal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03347v2",
                "http://arxiv.org/pdf/2311.03347v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03345v1",
            "title": "Long-Term Invariant Local Features via Implicit Cross-Domain\n  Correspondences",
            "updated": "2023-11-06T18:53:01Z",
            "published": "2023-11-06T18:53:01Z",
            "summary": "Modern learning-based visual feature extraction networks perform well in\nintra-domain localization, however, their performance significantly declines\nwhen image pairs are captured across long-term visual domain variations, such\nas different seasonal and daytime variations. In this paper, our first\ncontribution is a benchmark to investigate the performance impact of long-term\nvariations on visual localization. We conduct a thorough analysis of the\nperformance of current state-of-the-art feature extraction networks under\nvarious domain changes and find a significant performance gap between intra-\nand cross-domain localization. We investigate different methods to close this\ngap by improving the supervision of modern feature extractor networks. We\npropose a novel data-centric method, Implicit Cross-Domain Correspondences\n(iCDC). iCDC represents the same environment with multiple Neural Radiance\nFields, each fitting the scene under individual visual domains. It utilizes the\nunderlying 3D representations to generate accurate correspondences across\ndifferent long-term visual conditions. Our proposed method enhances\ncross-domain localization performance, significantly reducing the performance\ngap. When evaluated on popular long-term localization benchmarks, our trained\nnetworks consistently outperform existing methods. This work serves as a\nsubstantial stride toward more robust visual localization pipelines for\nlong-term deployments, and opens up research avenues in the development of\nlong-term invariant descriptors.",
            "author": [
                "Zador Pataki",
                "Mohammad Altillawi",
                "Menelaos Kanakis",
                "R\u00e9mi Pautrat",
                "Fengyi Shen",
                "Ziyuan Liu",
                "Luc Van Gool",
                "Marc Pollefeys"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03345v1",
                "http://arxiv.org/pdf/2311.03345v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03340v2",
            "title": "Multitask Kernel-based Learning with First-Order Logic Constraints",
            "updated": "2023-11-08T18:03:48Z",
            "published": "2023-11-06T18:44:55Z",
            "summary": "In this paper we propose a general framework to integrate supervised and\nunsupervised examples with background knowledge expressed by a collection of\nfirst-order logic clauses into kernel machines. In particular, we consider a\nmulti-task learning scheme where multiple predicates defined on a set of\nobjects are to be jointly learned from examples, enforcing a set of FOL\nconstraints on the admissible configurations of their values. The predicates\nare defined on the feature spaces, in which the input objects are represented,\nand can be either known a priori or approximated by an appropriate kernel-based\nlearner. A general approach is presented to convert the FOL clauses into a\ncontinuous implementation that can deal with the outputs computed by the\nkernel-based predicates. The learning problem is formulated as a\nsemi-supervised task that requires the optimization in the primal of a loss\nfunction that combines a fitting loss measure on the supervised examples, a\nregularization term, and a penalty term that enforces the constraints on both\nthe supervised and unsupervised examples. Unfortunately, the penalty term is\nnot convex and it can hinder the optimization process. However, it is possible\nto avoid poor solutions by using a two stage learning schema, in which the\nsupervised examples are learned first and then the constraints are enforced.",
            "author": [
                "Michelangelo Diligenti",
                "Marco Gori",
                "Marco Maggini",
                "Leonardo Rigutini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03340v2",
                "http://arxiv.org/pdf/2311.03340v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03339v1",
            "title": "FLOGA: A machine learning ready dataset, a benchmark and a novel deep\n  learning model for burnt area mapping with Sentinel-2",
            "updated": "2023-11-06T18:42:05Z",
            "published": "2023-11-06T18:42:05Z",
            "summary": "Over the last decade there has been an increasing frequency and intensity of\nwildfires across the globe, posing significant threats to human and animal\nlives, ecosystems, and socio-economic stability. Therefore urgent action is\nrequired to mitigate their devastating impact and safeguard Earth's natural\nresources. Robust Machine Learning methods combined with the abundance of\nhigh-resolution satellite imagery can provide accurate and timely mappings of\nthe affected area in order to assess the scale of the event, identify the\nimpacted assets and prioritize and allocate resources effectively for the\nproper restoration of the damaged region. In this work, we create and introduce\na machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations\nfor the Greek Area). This dataset is unique as it comprises of satellite\nimagery acquired before and after a wildfire event, it contains information\nfrom Sentinel-2 and MODIS modalities with variable spatial and spectral\nresolution, and contains a large number of events where the corresponding burnt\narea ground truth has been annotated by domain experts. FLOGA covers the wider\nregion of Greece, which is characterized by a Mediterranean landscape and\nclimatic conditions. We use FLOGA to provide a thorough comparison of multiple\nMachine Learning and Deep Learning algorithms for the automatic extraction of\nburnt areas, approached as a change detection task. We also compare the results\nto those obtained using standard specialized spectral indices for burnt area\nmapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our\nbenchmark results demonstrate the efficacy of the proposed technique in the\nautomatic extraction of burnt areas, outperforming all other methods in terms\nof accuracy and robustness. Our dataset and code are publicly available at:\nhttps://github.com/Orion-AI-Lab/FLOGA.",
            "author": [
                "Maria Sdraka",
                "Alkinoos Dimakos",
                "Alexandros Malounis",
                "Zisoula Ntasiou",
                "Konstantinos Karantzalos",
                "Dimitrios Michail",
                "Ioannis Papoutsis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03339v1",
                "http://arxiv.org/pdf/2311.03339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03335v1",
            "title": "Cross-Image Attention for Zero-Shot Appearance Transfer",
            "updated": "2023-11-06T18:33:24Z",
            "published": "2023-11-06T18:33:24Z",
            "summary": "Recent advancements in text-to-image generative models have demonstrated a\nremarkable ability to capture a deep semantic understanding of images. In this\nwork, we leverage this semantic knowledge to transfer the visual appearance\nbetween objects that share similar semantics but may differ significantly in\nshape. To achieve this, we build upon the self-attention layers of these\ngenerative models and introduce a cross-image attention mechanism that\nimplicitly establishes semantic correspondences across images. Specifically,\ngiven a pair of images -- one depicting the target structure and the other\nspecifying the desired appearance -- our cross-image attention combines the\nqueries corresponding to the structure image with the keys and values of the\nappearance image. This operation, when applied during the denoising process,\nleverages the established semantic correspondences to generate an image\ncombining the desired structure and appearance. In addition, to improve the\noutput image quality, we harness three mechanisms that either manipulate the\nnoisy latent codes or the model's internal representations throughout the\ndenoising process. Importantly, our approach is zero-shot, requiring no\noptimization or training. Experiments show that our method is effective across\na wide range of object categories and is robust to variations in shape, size,\nand viewpoint between the two input images.",
            "author": [
                "Yuval Alaluf",
                "Daniel Garibi",
                "Or Patashnik",
                "Hadar Averbuch-Elor",
                "Daniel Cohen-Or"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03335v1",
                "http://arxiv.org/pdf/2311.03335v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03334v1",
            "title": "Emergent magnetic order in the antiferromagnetic Kitaev model with a\n  [111] field",
            "updated": "2023-11-06T18:32:57Z",
            "published": "2023-11-06T18:32:57Z",
            "summary": "The Kitaev spin liquid, stabilized as the ground state of the Kitaev\nhoneycomb model, is a paradigmatic example of a topological $\\mathbb{Z}_2$\nquantum spin liquid. The fate of the Kitaev spin liquid in presence of an\nexternal magnetic field is a topic of current interest due to experiments,\nwhich apparently unveil a $\\mathbb{Z}_2$ topological phase in the so-called\nKitaev materials, and theoretical studies predicting the emergence of an\nintermediate quantum phase of debated nature before the appearance of a trivial\npartially polarized phase. In this work, we employ hierarchical mean-field\ntheory, an algebraic and numerical method based on the use of clusters\npreserving relevant symmetries and short-range quantum correlations, to\ninvestigate the quantum phase diagram of the antiferromagnetic Kitaev's model\nin a [111] field. By using clusters of 24 sites, we predict that the Kitaev\nspin liquid transits through two intermediate phases characterized by stripe\nand chiral order, respectively, before entering the trivial partially polarized\nphase, differing from previous studies. We assess our results by performing\nexact diagonalization and computing the scaling of different observables,\nincluding the many-body Chern number and other topological quantities, thus\nestablishing hierarchical mean-field theory as a method to study topological\nquantum spin liquids.",
            "author": [
                "Will Holdhusen",
                "Daniel Huerga",
                "Gerardo Ortiz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03334v1",
                "http://arxiv.org/pdf/2311.03334v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03331v1",
            "title": "Casimir energy of hyperbolic orbifolds with conical singularities",
            "updated": "2023-11-06T18:28:32Z",
            "published": "2023-11-06T18:28:32Z",
            "summary": "In this article, we obtain the explicit expression of the Casimir energy for\n2-dimensional Clifford-Klein space forms in terms of the geometrical data of\nthe underlying spacetime with the help of zeta-regularization techniques. The\nspacetime is geometrically expressed as a compact hyperbolic orbifold surface\nthat may have finitely many conical singularities. In computing the\ncontribution to the energy from a conical singularity, we derive an expression\nof an elliptic orbital integral as an infinite sum of special functions. We\nprove that this sum converges exponentially fast. Additionally, we show that\nunder a natural assumption (known to hold asymptotically) on the growth of the\nlengths of primitive closed geodesics of the $(2, 3, 7)$-triangle group\norbifold its Casimir energy is positive (repulsive).",
            "author": [
                "Ksenia Fedosova",
                "Julie Rowlett",
                "Genkai Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03331v1",
                "http://arxiv.org/pdf/2311.03331v1"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math-ph",
                "math.MP",
                "math.NT",
                "58J50, 33E99, 11F72, 11M36, 58C40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03328v2",
            "title": "On Asynchrony, Memory, and Communication: Separations and Landscapes",
            "updated": "2023-11-22T05:18:19Z",
            "published": "2023-11-06T18:25:28Z",
            "summary": "Research on distributed computing by a team of identical mobile computational\nentities, called robots, operating in a Euclidean space in\n$\\mathit{Look}$-$\\mathit{Compute}$-$\\mathit{Move}$ ($\\mathit{LCM}$) cycles, has\nrecently focused on better understanding how the computational power of robots\ndepends on the interplay between their internal capabilities (i.e., persistent\nmemory, communication), captured by the four standard computational models\n(OBLOT, LUMI, FSTA, and FCOM) and the conditions imposed by the external\nenvironment, controlling the activation of the robots and their synchronization\nof their activities, perceived and modeled as an adversarial scheduler.\n  We consider a set of adversarial asynchronous schedulers ranging from the\nclassical semi-synchronous (SSYNCH) and fully asynchronous (ASYNCH) settings,\nincluding schedulers (emerging when studying the atomicity of the combination\nof operations in the $\\mathit{LCM}$ cycles) whose adversarial power is in\nbetween those two. We ask the question: what is the computational relationship\nbetween a model $M_1$ under adversarial scheduler $K_1$ ($M_1(K_1)$) and a\nmodel $M_2$ under scheduler $K_2$ ($M_2(K_2)$)? For example, are the robots in\n$M_1(K_1)$ more powerful (i.e., they can solve more problems) than those in\n$M_2(K_2)$?\n  We answer all these questions by providing, through cross-model analysis, a\ncomplete characterization of the computational relationship between the power\nof the four models of robots under the considered asynchronous schedulers. In\nthis process, we also provide qualified answers to several open questions,\nincluding the outstanding one on the proper dominance of SSYNCH over ASYNCH in\nthe case of unrestricted visibility.",
            "author": [
                "Paola Flocchini",
                "Nicola Santoro",
                "Yuichi Sudo",
                "Koichi Wada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03328v2",
                "http://arxiv.org/pdf/2311.03328v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03326v1",
            "title": "Non-convex potential game approach to global solution in sensor network\n  localization",
            "updated": "2023-11-06T18:22:18Z",
            "published": "2023-11-06T18:22:18Z",
            "summary": "Sensor network localization (SNL) problems require determining the physical\ncoordinates of all sensors in a network. This process relies on the global\ncoordinates of anchors and the available measurements between non-anchor and\nanchor nodes. Attributed to the intrinsic non-convexity, obtaining a globally\noptimal solution to SNL is challenging, as well as implementing corresponding\nalgorithms. In this paper, we formulate a non-convex multi-player potential\ngame for a generic SNL problem to investigate the identification condition of\nthe global Nash equilibrium (NE) therein, where the global NE represents the\nglobal solution of SNL. We employ canonical duality theory to transform the\nnon-convex game into a complementary dual problem. Then we develop a\nconjugation-based algorithm to compute the stationary points of the\ncomplementary dual problem. On this basis, we show an identification condition\nof the global NE: the stationary point of the proposed algorithm satisfies a\nduality relation. Finally, simulation results are provided to validate the\neffectiveness of the theoretical results.",
            "author": [
                "Gehui Xu",
                "Guanpu Chen",
                "Yiguang Hong",
                "Thomas Parisini",
                "Baris Fidan",
                "Karl H. Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03326v1",
                "http://arxiv.org/pdf/2311.03326v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.GT",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03325v1",
            "title": "The chiral condensate at large $N$",
            "updated": "2023-11-06T18:20:24Z",
            "published": "2023-11-06T18:20:24Z",
            "summary": "We present results for the large-$N$ limit of the chiral condensate computed\nfrom twisted reduced models. We followed a two-fold strategy, one constiting in\nextracting the condensate from the quark-mass dependence of the pion mass, the\nother consisting in extracting the condensate from the mode number of the Dirac\noperator.",
            "author": [
                "Claudio Bonanno",
                "Pietro Butti",
                "Margarita Garc\u00eda Per\u00e9z",
                "Antonio Gonz\u00e1lez-Arroyo",
                "Ken-Ichi Ishikawa",
                "Masanori Okawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03325v1",
                "http://arxiv.org/pdf/2311.03325v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03427v1",
            "title": "TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic\n  Scene Understanding",
            "updated": "2023-11-06T18:20:02Z",
            "published": "2023-11-06T18:20:02Z",
            "summary": "Holistic scene understanding includes semantic segmentation, surface normal\nestimation, object boundary detection, depth estimation, etc. The key aspect of\nthis problem is to learn representation effectively, as each subtask builds\nupon not only correlated but also distinct attributes. Inspired by\nvisual-prompt tuning, we propose a Task-Specific Prompts Transformer, dubbed\nTSP-Transformer, for holistic scene understanding. It features a vanilla\ntransformer in the early stage and tasks-specific prompts transformer encoder\nin the lateral stage, where tasks-specific prompts are augmented. By doing so,\nthe transformer layer learns the generic information from the shared parts and\nis endowed with task-specific capacity. First, the tasks-specific prompts serve\nas induced priors for each task effectively. Moreover, the task-specific\nprompts can be seen as switches to favor task-specific representation learning\nfor different tasks. Extensive experiments on NYUD-v2 and PASCAL-Context show\nthat our method achieves state-of-the-art performance, validating the\neffectiveness of our method for holistic scene understanding. We also provide\nour code in the following link https://github.com/tb2-sy/TSP-Transformer.",
            "author": [
                "Shuo Wang",
                "Jing Li",
                "Zibo Zhao",
                "Dongze Lian",
                "Binbin Huang",
                "Xiaomei Wang",
                "Zhengxin Li",
                "Shenghua Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03427v1",
                "http://arxiv.org/pdf/2311.03427v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10754v2",
            "title": "A Recent Survey of the Advancements in Deep Learning Techniques for\n  Monkeypox Disease Detection",
            "updated": "2023-11-23T20:08:49Z",
            "published": "2023-11-06T18:18:42Z",
            "summary": "Monkeypox (MPox) is a zoonotic infectious disease induced by the MPox Virus,\npart of the poxviridae orthopoxvirus group initially discovered in Africa and\ngained global attention in mid-2022 with cases reported outside endemic areas.\nSymptoms include headaches, chills, fever, smallpox, measles, and\nchickenpox-like skin manifestations and the WHO officially announced MPox as a\nglobal public health pandemic, in July 2022.Traditionally, PCR testing of skin\nlesions is considered a benchmark for the primary diagnosis by WHO, with\nsymptom management as the primary treatment and antiviral drugs like\ntecovirimat for severe cases. However, manual analysis within hospitals poses a\nsubstantial challenge including the substantial burden on healthcare\nprofessionals, limited facilities, availability and fatigue among doctors, and\nhuman error during public health emergencies. Therefore, this survey paper\nprovides an extensive and efficient analysis of deep learning (DL) methods for\nthe automatic detection of MPox in skin lesion images. These DL techniques are\nbroadly grouped into categories, including deep CNN, Deep CNNs ensemble, deep\nhybrid learning, the newly developed, and Vision transformer for diagnosing\nMPox. Moreover, this study offers a systematic exploration of the evolutionary\nprogression of DL techniques and identifies, and addresses limitations in\nprevious methods while highlighting the valuable contributions and innovation.\nAdditionally, the paper addresses benchmark datasets and their collection from\nvarious authentic sources, pre-processing techniques, and evaluation metrics.\nThe survey also briefly delves into emerging concepts, identifies research\ngaps, limitations, and applications, and outlines challenges in the diagnosis\nprocess. This survey furnishes valuable insights into the prospective areas of\nDL innovative ideas and is anticipated to serve as a path for researchers.",
            "author": [
                "Saddam Hussain Khan",
                "Rashid Iqbal",
                "Saeeda Naz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10754v2",
                "http://arxiv.org/pdf/2311.10754v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03323v1",
            "title": "A Robust Bi-Directional Algorithm For People Count In Crowded Areas",
            "updated": "2023-11-06T18:18:26Z",
            "published": "2023-11-06T18:18:26Z",
            "summary": "People counting system in crowded places has become a very useful practical\napplication that can be accomplished in various ways which include many\ntraditional methods using sensors. Examining the case of real time scenarios,\nthe algorithm espoused should be steadfast and accurate. People counting\nalgorithm presented in this paper, is centered on blob assessment, devoted to\nyield the count of the people through a path along with the direction of\ntraversal. The system depicted is often ensconced at the entrance of a building\nso that the unmitigated frequency of visitors can be recorded. The core premise\nof this work is to extricate count of people inflow and outflow pertaining to a\nparticular area. The tot-up achieved can be exploited for purpose of statistics\nin the circumstances of any calamity occurrence in that zone. Relying upon the\ncount totaled, the population in that vicinity can be assimilated in order to\ntake on relevant measures to rescue the people.",
            "author": [
                "Satyanarayana Penke",
                "Gopikrishna Pavuluri",
                "Soukhya Kunda",
                "Satvik M",
                "CharanKumar Y"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03323v1",
                "http://arxiv.org/pdf/2311.03323v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03321v1",
            "title": "Exact Shortest Paths with Rational Weights on the Word RAM",
            "updated": "2023-11-06T18:17:53Z",
            "published": "2023-11-06T18:17:53Z",
            "summary": "Exact computation of shortest paths in weighted graphs has been traditionally\nstudied in one of two settings. First, one can assume that the edge weights are\nreal numbers and all the performed operations on reals (typically comparisons\nand additions) take constant time. Classical Dijkstra's and Bellman-Ford\nalgorithms have been described in this setting. More efficient exact shortest\npaths algorithms have been obtained for integer-weighted graphs. Integrality\nassumption not only enables faster algorithms but also allows implementing the\naforementioned algorithms in a much more realistic word RAM model where only\narithmetic operations on $O(\\log{n})$-bit integers are performed in constant\ntime. On the word RAM one can as efficiently exactly encode even\n\\emph{rational-weighted} instances with $O(\\log{n})$-bit numerators and\ndenominators. However, the known exact real-weighted shortest paths algorithms,\nrun on such a rational input, can easily encounter intermediate values of\n$\\Theta(n)$ bits if represented exactly. This leads to a factor-$\\Omega(n)$\nslowdown on the word RAM. At the same time, the scaling algorithms suited for\ninteger weights do not produce exact solutions for rational inputs without\ndramatically increasing their accuracy.\n  In this paper, we design randomized exact single-source shortest paths\nalgorithms for rational-weighted graphs on the word RAM. Most importantly, in\nthe non-negative case, we obtain a near-linear time algorithm matching\nDijkstra's algorithm running time up to polylogarithmic factors. In presence of\nnegative weights, we give an $\\tilde{O}(n^{2.5})$-time algorithm breaking\nthrough the best known strongly polynomial bound attained by Bellman-Ford for\nsufficiently dense graphs.",
            "author": [
                "Adam Karczmarz",
                "Wojciech Nadara",
                "Marek Soko\u0142owski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03321v1",
                "http://arxiv.org/pdf/2311.03321v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03320v1",
            "title": "Tackling Concept Shift in Text Classification using Entailment-style\n  Modeling",
            "updated": "2023-11-06T18:15:36Z",
            "published": "2023-11-06T18:15:36Z",
            "summary": "Pre-trained language models (PLMs) have seen tremendous success in text\nclassification (TC) problems in the context of Natural Language Processing\n(NLP). In many real-world text classification tasks, the class definitions\nbeing learned do not remain constant but rather change with time - this is\nknown as Concept Shift. Most techniques for handling concept shift rely on\nretraining the old classifiers with the newly labelled data. However, given the\namount of training data required to fine-tune large DL models for the new\nconcepts, the associated labelling costs can be prohibitively expensive and\ntime consuming. In this work, we propose a reformulation, converting vanilla\nclassification into an entailment-style problem that requires significantly\nless data to re-train the text classifier to adapt to new concepts. We\ndemonstrate the effectiveness of our proposed method on both real world &\nsynthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in\nfew-shot settings. Further, upon deployment, our solution also helped save 75%\nof labeling costs overall.",
            "author": [
                "Sumegh Roychowdhury",
                "Karan Gupta",
                "Siva Rajesh Kasa",
                "Prasanna Srinivasa Murthy",
                "Alok Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03320v1",
                "http://arxiv.org/pdf/2311.03320v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03319v1",
            "title": "DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase",
            "updated": "2023-11-06T18:12:55Z",
            "published": "2023-11-06T18:12:55Z",
            "summary": "In-Context Learning (ICL) combined with pre-trained large language models has\nachieved promising results on various NLP tasks. However, ICL requires\nhigh-quality annotated demonstrations which might not be available in\nreal-world scenarios. To overcome this limitation, we propose \\textbf{D}ata\n\\textbf{A}ugmentation for \\textbf{I}n-Context \\textbf{L}earning\n(\\textbf{DAIL}). DAIL leverages the intuition that large language models are\nmore familiar with the content generated by themselves. It first utilizes the\nlanguage model to generate paraphrases of the test sample and employs majority\nvoting to determine the final result based on individual predictions. Our\nextensive empirical evaluation shows that DAIL outperforms the standard ICL\nmethod and other ensemble-based methods in the low-resource scenario.\nAdditionally, we explore the use of voting consistency as a confidence score of\nthe model when the logits of predictions are inaccessible. We believe our work\nwill stimulate further research on ICL in low-resource settings.",
            "author": [
                "Dawei Li",
                "Yaxuan Li",
                "Dheeraj Mekala",
                "Shuyao Li",
                "Yulin wang",
                "Xueqi Wang",
                "William Hogan",
                "Jingbo Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03319v1",
                "http://arxiv.org/pdf/2311.03319v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03317v1",
            "title": "nNxB: a new coarse-grained model for RNA and DNA nanotechnology",
            "updated": "2023-11-06T18:11:56Z",
            "published": "2023-11-06T18:11:56Z",
            "summary": "The folding processes of RNA and DNA play crucial roles in biological systems\nand nanotechnology. However, studying these processes with high-resolution\nmodels is beyond current computational capabilities. In this article, we\npresent a new coarse-grained model for investigating the folding dynamics of\nnucleic acids. Our model represents n nucleotides using a single patchy\nparticle and is parametrized using well-established nearest-neighbor models. By\nsimplifying the system and interactions, our model allows for simulations at\ntimescales and length scales that are currently inaccessible to more detailed\nmodels. To validate the performance of our model, we conducted extensive\nsimulations of various single-stranded systems. We examined the thermodynamics\nof DNA hairpins, capturing their stability and structural transitions. We also\ninvestigated the folding of an MMTV pseudoknot, a complex RNA structure\ninvolved in viral replication. Furthermore, we explored the folding of a\nchallenging RNA tile containing a k-type pseudoknot. The new coarse-grained\nmodel accurately captures the folding behavior of diverse nucleic acid\nstructures, providing insights into their thermodynamics. The successful\nreproduction of experimental data and favorable comparisons with existing\ncoarse-grained models validate the effectiveness of our approach.",
            "author": [
                "F. Tosti Guerra",
                "E. Poppleton",
                "P. \u0160ulc",
                "L. Rovigatti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03317v1",
                "http://arxiv.org/pdf/2311.03317v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03314v1",
            "title": "FATE: Feature-Agnostic Transformer-based Encoder for learning\n  generalized embedding spaces in flow cytometry data",
            "updated": "2023-11-06T18:06:38Z",
            "published": "2023-11-06T18:06:38Z",
            "summary": "While model architectures and training strategies have become more generic\nand flexible with respect to different data modalities over the past years, a\npersistent limitation lies in the assumption of fixed quantities and\narrangements of input features. This limitation becomes particularly relevant\nin scenarios where the attributes captured during data acquisition vary across\ndifferent samples. In this work, we aim at effectively leveraging data with\nvarying features, without the need to constrain the input space to the\nintersection of potential feature sets or to expand it to their union. We\npropose a novel architecture that can directly process data without the\nnecessity of aligned feature modalities by learning a general embedding space\nthat captures the relationship between features across data samples with\nvarying sets of features. This is achieved via a set-transformer architecture\naugmented by feature-encoder layers, thereby enabling the learning of a shared\nlatent feature space from data originating from heterogeneous feature spaces.\nThe advantages of the model are demonstrated for automatic cancer cell\ndetection in acute myeloid leukemia in flow cytometry data, where the features\nmeasured during acquisition often vary between samples. Our proposed\narchitecture's capacity to operate seamlessly across incongruent feature spaces\nis particularly relevant in this context, where data scarcity arises from the\nlow prevalence of the disease. The code is available for research purposes at\nhttps://github.com/lisaweijler/FATE.",
            "author": [
                "Lisa Weijler",
                "Florian Kowarsch",
                "Michael Reiter",
                "Pedro Hermosilla",
                "Margarita Maurer-Granofszky",
                "Michael Dworzak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03314v1",
                "http://arxiv.org/pdf/2311.03314v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03312v2",
            "title": "A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose\n  Estimation",
            "updated": "2023-11-09T04:51:34Z",
            "published": "2023-11-06T18:04:13Z",
            "summary": "The dominant paradigm in 3D human pose estimation that lifts a 2D pose\nsequence to 3D heavily relies on long-term temporal clues (i.e., using a\ndaunting number of video frames) for improved accuracy, which incurs\nperformance saturation, intractable computation and the non-causal problem.\nThis can be attributed to their inherent inability to perceive spatial context\nas plain 2D joint coordinates carry no visual cues. To address this issue, we\npropose a straightforward yet powerful solution: leveraging the readily\navailable intermediate visual representations produced by off-the-shelf\n(pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed.\nThe key observation is that, while the pose detector learns to localize 2D\njoints, such representations (e.g., feature maps) implicitly encode the\njoint-centric spatial context thanks to the regional operations in backbone\nnetworks. We design a simple baseline named Context-Aware PoseFormer to\nshowcase its effectiveness. Without access to any temporal information, the\nproposed method significantly outperforms its context-agnostic counterpart,\nPoseFormer, and other state-of-the-art methods using up to hundreds of video\nframes regarding both speed and precision. Project page:\nhttps://qitaozhao.github.io/ContextAware-PoseFormer",
            "author": [
                "Qitao Zhao",
                "Ce Zheng",
                "Mengyuan Liu",
                "Chen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03312v2",
                "http://arxiv.org/pdf/2311.03312v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14692v1",
            "title": "COVID-19 Imposes Rethinking of Conferencing -- Environmental Impact\n  Assessment of Artificial Intelligence Conferences",
            "updated": "2023-11-06T18:04:02Z",
            "published": "2023-11-06T18:04:02Z",
            "summary": "It has been noticed that through COVID-19 greenhouse gas emissions had a\nsudden reduction. Based on this significant observation, we decided to conduct\na research to quantify the impact of scientific conferences' air-travelling,\nexplore and suggest alternative ways for greener conferences to re-duce the\nglobal carbon footprint. Specifically, we focused on the most popular\nconferences for the Artificial Intelligence community based on their scientific\nimpact factor, their scale, and the well-organized proceedings towards\nmeasuring the impact of air travelling participation. This is the first time\nthat systematic quantification of a state-of-the-art subject like Artificial\nIntelligence takes place to define its conferencing footprint in the broader\nframes of environmental awareness. Our findings highlight that the virtual way\nis the first on the list of green conferences' conduction although there are\nserious concerns about it. Alternatives to optimal conferences' location\nselection have demonstrated savings on air-travelling CO2 emissions of up to\n63.9%.",
            "author": [
                "Pavlina Mitsou",
                "Nikoleta-Victoria Tsakalidou",
                "Eleni Vrochidou",
                "George A. Papakostas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14692v1",
                "http://arxiv.org/pdf/2311.14692v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03311v1",
            "title": "Unraveling Downstream Gender Bias from Large Language Models: A Study on\n  AI Educational Writing Assistance",
            "updated": "2023-11-06T18:01:34Z",
            "published": "2023-11-06T18:01:34Z",
            "summary": "Large Language Models (LLMs) are increasingly utilized in educational tasks\nsuch as providing writing suggestions to students. Despite their potential,\nLLMs are known to harbor inherent biases which may negatively impact learners.\nPrevious studies have investigated bias in models and data representations\nseparately, neglecting the potential impact of LLM bias on human writing. In\nthis paper, we investigate how bias transfers through an AI writing support\npipeline. We conduct a large-scale user study with 231 students writing\nbusiness case peer reviews in German. Students are divided into five groups\nwith different levels of writing support: one classroom group with\nfeature-based suggestions and four groups recruited from Prolific -- a control\ngroup with no assistance, two groups with suggestions from fine-tuned GPT-2 and\nGPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using\nGenBit gender bias analysis, Word Embedding Association Tests (WEAT), and\nSentence Embedding Association Test (SEAT) we evaluate the gender bias at\nvarious stages of the pipeline: in model embeddings, in suggestions generated\nby the models, and in reviews written by students. Our results demonstrate that\nthere is no significant difference in gender bias between the resulting peer\nreviews of groups with and without LLM suggestions. Our research is therefore\noptimistic about the use of AI writing support in the classroom, showcasing a\ncontext where bias in LLMs does not transfer to students' responses.",
            "author": [
                "Thiemo Wambsganss",
                "Xiaotian Su",
                "Vinitra Swamy",
                "Seyed Parsa Neshaei",
                "Roman Rietsche",
                "Tanja K\u00e4ser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03311v1",
                "http://arxiv.org/pdf/2311.03311v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03308v1",
            "title": "Revisiting $\u03b1'$ corrections to heterotic two-charge black holes",
            "updated": "2023-11-06T17:57:57Z",
            "published": "2023-11-06T17:57:57Z",
            "summary": "We find solutions of the heterotic string effective action describing the\nfirst-order $\\alpha'$ corrections to two-charge black holes at finite\ntemperature. Making explicit use of these solutions, we compute the corrections\nto the thermodynamic quantities: temperature, chemical potentials, mass,\ncharges and entropy. We check that the first law of black hole mechanics is\nsatisfied and that the thermodynamics agrees with the one extracted from the\nEuclidean on-shell action. Finally, we show that our results are in agreement\nwith the corrections for the thermodynamics recently predicted by Chen,\nMaldacena and Witten.",
            "author": [
                "Stefano Massai",
                "Alejandro Ruip\u00e9rez",
                "Matteo Zatti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03308v1",
                "http://arxiv.org/pdf/2311.03308v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04238v1",
            "title": "Flexible Bayesian Inference on Partially Observed Epidemics",
            "updated": "2023-11-06T17:57:32Z",
            "published": "2023-11-06T17:57:32Z",
            "summary": "Individual-based models of contagious processes are useful for predicting\nepidemic trajectories and informing intervention strategies. In such models,\nthe incorporation of contact network information can capture the non-randomness\nand heterogeneity of realistic contact dynamics. In this paper, we consider\nBayesian inference on the spreading parameters of an SIR contagion on a known,\nstatic network, where information regarding individual disease status is known\nonly from a series of tests (positive or negative disease status). When the\ncontagion model is complex or information such as infection and removal times\nis missing, the posterior distribution can be difficult to sample from.\nPrevious work has considered the use of Approximate Bayesian Computation (ABC),\nwhich allows for simulation-based Bayesian inference on complex models.\nHowever, ABC methods usually require the user to select reasonable summary\nstatistics. Here, we consider an inference scheme based on the Mixture Density\nNetwork compressed ABC (MDN-ABC), which minimizes the expected posterior\nentropy in order to learn informative summary statistics. This allows us to\nconduct Bayesian inference on the parameters of a partially observed contagious\nprocess while also circumventing the need for manual summary statistic\nselection. This methodology can be extended to incorporate additional\nsimulation complexities, including behavioral change after positive tests or\nfalse test results.",
            "author": [
                "Maxwell H. Wang",
                "Jukka-Pekka Onnela"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04238v1",
                "http://arxiv.org/pdf/2311.04238v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03307v1",
            "title": "Improved Noisy Syndrome Decoding of Quantum LDPC Codes with Sliding\n  Window",
            "updated": "2023-11-06T17:56:49Z",
            "published": "2023-11-06T17:56:49Z",
            "summary": "Quantum error correction (QEC) with single-shot decoding enables reduction of\nerrors after every single round of noisy stabilizer measurement, easing the\ntime-overhead requirements for fault tolerance. Notably, several classes of\nquantum low-density-parity-check (qLDPC) codes are known which facilitate\nsingle-shot decoding, potentially giving them an additional overhead advantage.\nHowever, the perceived advantage of single-shot decoding is limited because it\ncan significantly degrade the effective code distance. This degradation may be\ncompensated for by using a much larger code size to achieve the desired target\nlogical error rate, at the cost of increasing the amount of syndrome\ninformation to be processed, as well as, increasing complexity of logical\noperations. Alternatively, in this work we study sliding-window decoding, which\ncorrects errors from previous syndrome measurement rounds while leaving the\nmost recent errors for future correction. We observe that sliding-window\ndecoding significantly improves the logical memory lifetime and hence the\neffective distance compared to single-shot decoding on hypergraph-product codes\nand lifted-product codes. Remarkably, we find that this improvement may not\ncost a larger decoding complexity. Thus, the sliding-window strategy can be\nmore desirable for fast and accurate decoding for fault-tolerant quantum\ncomputing with qLDPC codes.",
            "author": [
                "Shilin Huang",
                "Shruti Puri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03307v1",
                "http://arxiv.org/pdf/2311.03307v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03301v1",
            "title": "Ziya2: Data-centric Learning is All LLMs Need",
            "updated": "2023-11-06T17:49:34Z",
            "published": "2023-11-06T17:49:34Z",
            "summary": "Various large language models (LLMs) have been proposed in recent years,\nincluding closed- and open-source ones, continually setting new records on\nmultiple benchmarks. However, the development of LLMs still faces several\nissues, such as high cost of training models from scratch, and continual\npre-training leading to catastrophic forgetting, etc. Although many such issues\nare addressed along the line of research on LLMs, an important yet practical\nlimitation is that many studies overly pursue enlarging model sizes without\ncomprehensively analyzing and optimizing the use of pre-training data in their\nlearning process, as well as appropriate organization and leveraging of such\ndata in training LLMs under cost-effective settings. In this work, we propose\nZiya2, a model with 13 billion parameters adopting LLaMA2 as the foundation\nmodel, and further pre-trained on 700 billion tokens, where we focus on\npre-training techniques and use data-centric optimization to enhance the\nlearning process of Ziya2 on different stages. Experiments show that Ziya2\nsignificantly outperforms other models in multiple benchmarks especially with\npromising results compared to representative open-source ones. Ziya2 (Base) is\nreleased at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and\nhttps://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.",
            "author": [
                "Ruyi Gan",
                "Ziwei Wu",
                "Renliang Sun",
                "Junyu Lu",
                "Xiaojun Wu",
                "Dixiang Zhang",
                "Kunhao Pan",
                "Ping Yang",
                "Qi Yang",
                "Jiaxing Zhang",
                "Yan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03301v1",
                "http://arxiv.org/pdf/2311.03301v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03298v1",
            "title": "Lojasiewicz inequalities in a certain class of smooth functions",
            "updated": "2023-11-06T17:43:53Z",
            "published": "2023-11-06T17:43:53Z",
            "summary": "Let $f$ be a germ of a smooth function at the orirgin in $\\RR^n.$ We show\nthat if $f$ is Kouchnirenko's nondegenerate and satisfies the so called\nKamimoto--Nose condition then it admits the \\L ojasiewicz inequalities. We\ncompute the \\L ojasiewicz exponents for some special cases. In particular, if\n$f$ is a germ of a smooth convex Kouchnirenko's nondegenerate function and\nsatisfies the Kamimoto--Nose condition, then all its \\L ojasiewicz exponents\ncan be expressed very simply in terms of its Newton polyhedron.",
            "author": [
                "Ha Minh Lam",
                "Ha Huy Vui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03298v1",
                "http://arxiv.org/pdf/2311.03298v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03294v1",
            "title": "Indirect Quantum Approximate Optimization Algorithms: application to the\n  TSP",
            "updated": "2023-11-06T17:39:14Z",
            "published": "2023-11-06T17:39:14Z",
            "summary": "We propose an Indirect Quantum Approximate Optimization Algorithm (referred\nto as IQAOA) where the Quantum Alternating Operator Ansatz takes into\nconsideration a general parameterized family of unitary operators to\nefficiently model the Hamiltonian describing the set of string vectors. This\nalgorithm creates an efficient alternative to QAOA, where: 1) a Quantum\nparametrized circuit executed on a quantum machine models the set of string\nvectors; 2) a Classical meta-optimization loop executed on a classical machine;\n3) an estimation of the average cost of each string vector computing, using a\nwell know algorithm coming from the OR community that is problem dependent. The\nindirect encoding defined by dimensional string vector is mapped into a\nsolution by an efficient coding/decoding mechanism. The main advantage is to\nobtain a quantum circuit with a strongly limited number of gates that could be\nexecuted on the noisy current quantum machines. The numerical experiments\nachieved with IQAOA permits to solve 8-customer instances TSP using the IBM\nsimulator which are to the best of our knowledge the largest TSP ever solved\nusing a QAOA based approach.",
            "author": [
                "Eric Bourreau",
                "Gerard Fleury",
                "Philippe Lacomme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03294v1",
                "http://arxiv.org/pdf/2311.03294v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03292v2",
            "title": "Data Science from 1963 to 2012",
            "updated": "2023-11-07T12:58:38Z",
            "published": "2023-11-06T17:35:35Z",
            "summary": "Consensus on the definition of data science remains low despite the\nwidespread establishment of academic programs in the field and continued demand\nfor data scientists in industry. Definitions range from rebranded statistics to\ndata-driven science to the science of data to simply the application of machine\nlearning to so-called big data to solve real-world problems. Current efforts to\ntrace the history of the field in order to clarify its definition, such as\nDonoho's \"50 Years of Data Science\" (Donoho 2017), tend to focus on a short\nperiod when a small group of statisticians adopted the term in an unsuccessful\nattempt to rebrand their field in the face of the overshadowing effects of\ncomputational statistics and data mining. Using textual evidence from primary\nsources, this essay traces the history of the term to the 1960s, when it was\nfirst used by the US Air Force in a surprisingly similar way to its current\nusage, to 2012, the year that Harvard Business Review published the enormously\ninfluential article \"Data Scientist: The Sexiest Job of the 21st Century\"\n(Davenport and Patil 2012), while the American Statistical Association\nacknowledged a profound disconnect between statistics and data science. Among\nthe themes that emerge from this review are (1) the long-standing opposition\nbetween data analysts and data miners that continues to animate the field, (2)\nan established definition of the term as the practice of managing and\nprocessing scientific data that has been occluded by recent usage, and (3) the\nphenomenon of data impedance -- the disproportion between surplus data, indexed\nby phrases like data deluge and big data, and the limitations of computational\nmachinery and methods to process them. This persistent condition appears to\nhave motivated the use of the term and the field itself since its beginnings.",
            "author": [
                "Rafael C. Alvarado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03292v2",
                "http://arxiv.org/pdf/2311.03292v2"
            ],
            "primary_category": "cs.GL",
            "category": [
                "cs.GL",
                "cs.DL",
                "K.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03291v1",
            "title": "DISCO-DJ I: a differentiable Einstein-Boltzmann solver for cosmology",
            "updated": "2023-11-06T17:34:54Z",
            "published": "2023-11-06T17:34:54Z",
            "summary": "We present the Einstein-Boltzmann module of the DISCO-DJ (DIfferentiable\nSimulations for COsmology - Done with JAX) software package. This module\nimplements a fully differentiable solver for the linearised cosmological\nEinstein-Boltzmann equations in the JAX framework, and allows computing\nJacobian matrices of all solver output with respect to all input parameters\nusing automatic differentiation. This implies that along with the solution for\na given set of parameters, the tangent hyperplane in parameter space is known\nas well, which is a key ingredient for cosmological inference and forecasting\nproblems as well as for many other applications. We discuss our implementation\nand demonstrate that our solver agrees at the per-mille level with the existing\nnon-differentiable solvers CAMB and CLASS, including massive neutrinos and a\ndark energy fluid with parameterised equation of state. We illustrate the\ndependence of various summary statistics in large-scale structure cosmology on\nmodel parameters using the differentiable solver, and finally demonstrate how\nit can be easily used for Fisher forecasting. Since the implementation is\nsignificantly shorter and more modular than existing solvers, it is easy to\nextend our solver to include additional physics, such as additional dark energy\nmodels, modified gravity, or other non-standard physics.",
            "author": [
                "Oliver Hahn",
                "Florian List",
                "Natalia Porqueres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03291v1",
                "http://arxiv.org/pdf/2311.03291v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03426v1",
            "title": "GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys,\n  and Values",
            "updated": "2023-11-06T17:29:24Z",
            "published": "2023-11-06T17:29:24Z",
            "summary": "Massive transformer-based models face several challenges, including slow and\ncomputationally intensive pre-training and over-parametrization. This paper\naddresses these challenges by proposing a versatile method called GQKVA, which\ngeneralizes query, key, and value grouping techniques. GQKVA is designed to\nspeed up transformer pre-training while reducing the model size. Our\nexperiments with various GQKVA variants highlight a clear trade-off between\nperformance and model size, allowing for customized choices based on resource\nand time limitations. Our findings also indicate that the conventional\nmulti-head attention approach is not always the best choice, as there are\nlighter and faster alternatives available. We tested our method on ViT, which\nachieved an approximate 0.3% increase in accuracy while reducing the model size\nby about 4% in the task of image classification. Additionally, our most\naggressive model reduction experiment resulted in a reduction of approximately\n15% in model size, with only around a 1% drop in accuracy.",
            "author": [
                "Farnoosh Javadi",
                "Walid Ahmed",
                "Habib Hajimolahoseini",
                "Foozhan Ataiefard",
                "Mohammad Hassanpour",
                "Saina Asani",
                "Austin Wen",
                "Omar Mohamed Awad",
                "Kangling Liu",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03426v1",
                "http://arxiv.org/pdf/2311.03426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03288v1",
            "title": "Hydrodynamic modelling of dynamical tides dissipation in Jupiter's\n  interior as revealed by Juno",
            "updated": "2023-11-06T17:27:26Z",
            "published": "2023-11-06T17:27:26Z",
            "summary": "The Juno spacecraft has acquired exceptionally precise data on Jupiter's\ngravity field, offering invaluable insights into Jupiter's tidal response,\ninterior structure, and dynamics, establishing crucial constraints. We develop\na new model for calculating Jupiter's tidal response based on its latest\ninterior model, while also examining the significance of different dissipation\nprocesses for the evolution of its system. We study the dissipation of\ndynamical tides in Jupiter by thermal, viscous and molecular diffusivities\nacting on gravito-inertial waves in stably stratified zones and inertial waves\nin convection ones. We solve the linearised equations for the equilibrium tide.\nNext, we compute the dynamical tides using linear hydrodynamical simulations\nbased on a spectral method. The Coriolis force is fully taken into account, but\nthe centrifugal effect is neglected. We study the dynamical tides occurring in\nJupiter using internal structure models that respect Juno's constraints. We\nstudy specifically the dominant quadrupolar tidal components and our focus is\non the frequency range that corresponds to the tidal frequencies associated\nwith Jupiter's Galilean satellites. By incorporating the different dissipation\nmechanisms, we calculate the total dissipation and determine the imaginary part\nof the tidal Love number. We find a significant frequency dependence in\ndissipation spectra, indicating a strong relationship between dissipation and\nforcing frequency. Furthermore, our analysis reveals that, in the chosen\nparameter regime in which kinematic viscosity, thermal and molecular\ndiffusivities are equal, the dominant mechanism contributing to dissipation is\nviscosity, exceeding in magnitude both thermal and chemical dissipation. We\nfind that the presence of stably stratified zones plays an important role in\nexplaining the high dissipation observed in Jupiter.",
            "author": [
                "Hachem Dhouib",
                "Cl\u00e9ment Baruteau",
                "St\u00e9phane Mathis",
                "Florian Debras",
                "Aur\u00e9lie Astoul",
                "Michel Rieutord"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03288v1",
                "http://arxiv.org/pdf/2311.03288v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03287v2",
            "title": "Holistic Analysis of Hallucination in GPT-4V(ision): Bias and\n  Interference Challenges",
            "updated": "2023-11-07T02:18:48Z",
            "published": "2023-11-06T17:26:59Z",
            "summary": "While GPT-4V(ision) impressively models both visual and textual information\nsimultaneously, it's hallucination behavior has not been systematically\nassessed. To bridge this gap, we introduce a new benchmark, namely, the Bias\nand Interference Challenges in Visual Language Models (Bingo). This benchmark\nis designed to evaluate and shed light on the two common types of\nhallucinations in visual language models: bias and interference. Here, bias\nrefers to the model's tendency to hallucinate certain types of responses,\npossibly due to imbalance in its training data. Interference pertains to\nscenarios where the judgment of GPT-4V(ision) can be disrupted due to how the\ntext prompt is phrased or how the input image is presented. We identify a\nnotable regional bias, whereby GPT-4V(ision) is better at interpreting Western\nimages or images with English writing compared to images from other countries\nor containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to\nleading questions and is often confused when interpreting multiple images\ntogether. Popular mitigation approaches, such as self-correction and\nchain-of-thought reasoning, are not effective in resolving these challenges. We\nalso identified similar biases and interference vulnerabilities with LLaVA and\nBard. Our results characterize the hallucination challenges in GPT-4V(ision)\nand state-of-the-art visual-language models, and highlight the need for new\nsolutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.",
            "author": [
                "Chenhang Cui",
                "Yiyang Zhou",
                "Xinyu Yang",
                "Shirley Wu",
                "Linjun Zhang",
                "James Zou",
                "Huaxiu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03287v2",
                "http://arxiv.org/pdf/2311.03287v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03285v2",
            "title": "S-LoRA: Serving Thousands of Concurrent LoRA Adapters",
            "updated": "2023-11-07T06:59:33Z",
            "published": "2023-11-06T17:26:17Z",
            "summary": "The \"pretrain-then-finetune\" paradigm is commonly adopted in the deployment\nof large language models. Low-Rank Adaptation (LoRA), a parameter-efficient\nfine-tuning method, is often employed to adapt a base model to a multitude of\ntasks, resulting in a substantial collection of LoRA adapters derived from one\nbase model. We observe that this paradigm presents significant opportunities\nfor batched inference during serving. To capitalize on these opportunities, we\npresent S-LoRA, a system designed for the scalable serving of many LoRA\nadapters. S-LoRA stores all adapters in the main memory and fetches the\nadapters used by the currently running queries to the GPU memory. To\nefficiently use the GPU memory and reduce fragmentation, S-LoRA proposes\nUnified Paging. Unified Paging uses a unified memory pool to manage dynamic\nadapter weights with different ranks and KV cache tensors with varying sequence\nlengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and\nhighly optimized custom CUDA kernels for heterogeneous batching of LoRA\ncomputation. Collectively, these features enable S-LoRA to serve thousands of\nLoRA adapters on a single GPU or across multiple GPUs with a small overhead.\nCompared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with\nnaive support of LoRA serving), S-LoRA can improve the throughput by up to 4\ntimes and increase the number of served adapters by several orders of\nmagnitude. As a result, S-LoRA enables scalable serving of many task-specific\nfine-tuned models and offers the potential for large-scale customized\nfine-tuning services. The code is available at https://github.com/S-LoRA/S-LoRA",
            "author": [
                "Ying Sheng",
                "Shiyi Cao",
                "Dacheng Li",
                "Coleman Hooper",
                "Nicholas Lee",
                "Shuo Yang",
                "Christopher Chou",
                "Banghua Zhu",
                "Lianmin Zheng",
                "Kurt Keutzer",
                "Joseph E. Gonzalez",
                "Ion Stoica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03285v2",
                "http://arxiv.org/pdf/2311.03285v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03273v1",
            "title": "Tidal dissipation in stably stratified and semi-convective regions of\n  rotating giant planets: incorporating Coriolis forces",
            "updated": "2023-11-06T17:16:30Z",
            "published": "2023-11-06T17:16:30Z",
            "summary": "We study how stably stratified or semi-convective layers alter tidal\ndissipation rates associated with the generation of inertial, gravito-inertial,\ninterfacial and surface gravity waves in rotating giant planets. We explore\nscenarios in which stable (non-convective) layers contribute to the high rates\nof tidal dissipation observed for Jupiter and Saturn in our solar system. Our\nmodel is an idealised spherical Boussinesq system incorporating Coriolis forces\nto study effects of stable stratification and semi-convective layers on tidal\ndissipation. Our detailed numerical calculations consider realistic tidal\nforcing and compute the resulting viscous and thermal dissipation rates. The\npresence of an extended stably stratified fluid core significantly enhances\ntidal wave excitation of both inertial waves (due to rotation) in the\nconvective envelope and gravito-inertial waves in the dilute core. We show that\na sufficiently strongly stratified fluid core enhances inertial wave\ndissipation in a convective envelope much like a solid core does. We\ndemonstrate that efficient tidal dissipation rates (and associated tidal\nquality factors $Q'$) -- sufficient to explain the observed migration rates of\nSaturn's moons -- are predicted at the frequencies of the orbiting moons due to\nthe excitation of inertial or gravito-inertial waves in our models with stable\nlayers (without requiring resonance-locking). Stable layers could also be\nimportant for tidal evolution of hot and warm Jupiters, and hot Neptunes,\nproviding efficient tidal circularisation rates. Future work should study more\nsophisticated planetary models that also account for magnetism and differential\nrotation, as well as the interaction of inertial waves with turbulent\nconvection.",
            "author": [
                "Christina M. Pontin",
                "Adrian J. Barker",
                "Rainer Hollerbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03273v1",
                "http://arxiv.org/pdf/2311.03273v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03271v1",
            "title": "Automated Identification and Tracking of Deformation Twin Structures in\n  Molecular Dynamics Simulations",
            "updated": "2023-11-06T17:10:10Z",
            "published": "2023-11-06T17:10:10Z",
            "summary": "Deformation twinning significantly influences the microstructure, texture,\nand mechanical properties of metals, necessitating comprehensive studies of\ntwin formation and interactions. While experimental methods excel at analyzing\nindividual samples, they often lack the capability for temporal analysis of\ntwinned structures. Molecular dynamics simulations offer a temporal dimension,\nyet the absence of suitable tools for automated crystal twin identification has\nbeen a significant limitation. In this article, we introduce a novel\ncomputational tool integrated into the visualization and analysis software\nOVITO. Our tool automates the identification of coherent twin boundaries, links\nrelated twin boundaries, validates twin structures through orientation\nanalysis, and tracks twins over time, providing quantifiable data and enabling\nin-depth investigations. Validation on a copper single crystal under shear\nloading demonstrates successful tracking of various twins, revealing their\ngenesis and growth over multiple timesteps. This innovative approach promises\nto advance the computational materials science domain by facilitating the study\nof deformation twinning, offering profound insights into the behavior and\nmechanical performance of materials.",
            "author": [
                "H. J. Ehrich",
                "A. Dollmann",
                "P. G. Gr\u00fctzmacher",
                "C. Gachot",
                "S. J. Eder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03271v1",
                "http://arxiv.org/pdf/2311.03271v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03424v1",
            "title": "Using Symmetries to Lift Satisfiability Checking",
            "updated": "2023-11-06T17:08:08Z",
            "published": "2023-11-06T17:08:08Z",
            "summary": "We analyze how symmetries can be used to compress structures (also known as\ninterpretations) onto a smaller domain without loss of information. This\nanalysis suggests the possibility to solve satisfiability problems in the\ncompressed domain for better performance. Thus, we propose a 2-step novel\nmethod: (i) the sentence to be satisfied is automatically translated into an\nequisatisfiable sentence over a ``lifted'' vocabulary that allows domain\ncompression; (ii) satisfiability of the lifted sentence is checked by growing\nthe (initially unknown) compressed domain until a satisfying structure is\nfound. The key issue is to ensure that this satisfying structure can always be\nexpanded into an uncompressed structure that satisfies the original sentence to\nbe satisfied. We present an adequate translation for sentences in typed\nfirst-order logic extended with aggregates. Our experimental evaluation shows\nlarge speedups for generative configuration problems. The method also has\napplications in the verification of software operating on complex data\nstructures. Further refinements of the translation are left for future work.",
            "author": [
                "Pierre Carbonnelle",
                "Gottfried Schenner",
                "Maurice Bruynooghe",
                "Bart Bogaerts",
                "Marc Denecker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03424v1",
                "http://arxiv.org/pdf/2311.03424v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03266v1",
            "title": "Experimental certification of contextuality, coherence and dimension in\n  a programmable universal photonic processor",
            "updated": "2023-11-06T16:59:00Z",
            "published": "2023-11-06T16:59:00Z",
            "summary": "Quantum superposition of high-dimensional states enables both computational\nspeed-up and security in cryptographic protocols. However, the exponential\ncomplexity of tomographic processes makes certification of these properties a\nchallenging task. In this work, we experimentally certify coherence witnesses\ntailored for quantum systems of increasing dimension, using pairwise overlap\nmeasurements enabled by a six-mode universal photonic processor fabricated with\na femtosecond laser writing technology. In particular, we show the\neffectiveness of the proposed coherence and dimension witnesses for qudits of\ndimensions up to 5. We also demonstrate advantage in a quantum interrogation\ntask, and show it is fueled by quantum contextuality. Our experimental results\ntestify to the efficiency of this novel approach for the certification of\nquantum properties in programmable integrated photonic platforms",
            "author": [
                "Taira Giordani",
                "Rafael Wagner",
                "Chiara Esposito",
                "Anita Camillini",
                "Francesco Hoch",
                "Gonzalo Carvacho",
                "Ciro Pentangelo",
                "Francesco Ceccarelli",
                "Simone Piacentini",
                "Andrea Crespi",
                "Nicol\u00f2 Spagnolo",
                "Roberto Osellame",
                "Ernesto F. Galv\u00e3o",
                "Fabio Sciarrino"
            ],
            "link": [
                "http://dx.doi.org/10.1126/sciadv.adj4249",
                "http://arxiv.org/abs/2311.03266v1",
                "http://arxiv.org/pdf/2311.03266v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03257v1",
            "title": "GM-rule and its applications to impartial games",
            "updated": "2023-11-06T16:41:26Z",
            "published": "2023-11-06T16:41:26Z",
            "summary": "Given integer $n \\geq 1, \\ell \\geq 2$, and vector $x = (x_1, \\ldots, x_n)$\nthat has an entry which is a multiple of $\\ell$ and such that $x_1 \\leq \\ldots\n\\leq x_n$, the GM-rule is defined as follows: Keep the rightmost minimal entry\n$x_i$ of $x$, which is a multiple of $\\ell$ and reduce the remaining $n-1$\nentries of $x$ by~1. We will call such $i$ the {\\em pivot} and $x_i$ the {\\em\npivotal entry}. The GM-rule respects monotonicity of the entries. It uniquely\ndetermines a GM-move $x^0 \\to x^1$ and an infinite GM-sequence $S$ that\nconsists of successive GM-moves $x = x^0 \\to x^1 \\to \\ldots \\to x^j \\to \\ldots$\n. If $range(x) = x_n - x_1 \\leq \\ell$ then for all $j \\geq 0$:\n  (i) $range(x^j) \\leq \\ell$;\n  (ii) the pivot of $x^{j + \\ell}$ is one less than the pivot of $x^j$,\nassuming that $1 - 1 = 0 = n$.\n  (iii) $x_i^j - x_i^{j + n \\ell} = (n-1) \\ell$ for all $i = 1,\\ldots,n$.\n  Due to (iii), we compute $x^j$ in time linear in $n, \\ell, \\log(j)$, and\n$\\sum^n_{i=1}\\log(|x_i|+1)$. For $\\ell = 2$ a slighty modified version of the\nGM-rule was recently introduced by Gurvich, Martynov, Maximchuk, and Vyalyi,\n\"On Remoteness Functions of Exact Slow $k$-NIM with $k+1$ Piles\",\narXiv:2304.06498 (2023), where applications to impartial games were considered.",
            "author": [
                "Vladimir Gurvich",
                "Mariya Naumova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03257v1",
                "http://arxiv.org/pdf/2311.03257v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03255v3",
            "title": "Minimal Arrangements of Spherical Geodesics",
            "updated": "2023-12-04T01:25:39Z",
            "published": "2023-11-06T16:40:40Z",
            "summary": "We study arrangements of geodesic arcs on a sphere, where all arcs are\ninternally disjoint and each arc has its endpoints located within the interior\nof other arcs. We establish fundamental results concerning the minimum number\nof arcs in such arrangements, depending on local geometric constraints such as\n\"one-sidedness\" and \"k-orientation\".\n  En route to these results, we generalize and settle an open problem from CCCG\n2022, proving that any such arrangement has at least two \"clockwise swirls\" and\nat least two \"counterclockwise swirls\".",
            "author": [
                "Giovanni Viglietta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03255v3",
                "http://arxiv.org/pdf/2311.03255v3"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03254v1",
            "title": "Controlled Diffusions under Full, Partial and Decentralized Information:\n  Existence of Optimal Policies and Discrete-Time Approximations",
            "updated": "2023-11-06T16:40:31Z",
            "published": "2023-11-06T16:40:31Z",
            "summary": "We present existence and discrete-time approximation results on optimal\ncontrol policies for continuous-time stochastic control problems under a\nvariety of information structures. These include fully observed models,\npartially observed models and multi-agent models with decentralized information\nstructures. While there exist comprehensive existence and approximations\nresults for the fully observed setup in the literature, few prior research\nexists on discrete-time approximation results for partially observed models.\nFor decentralized models, even existence results have not received much\nattention except for specialized models and approximation has been an open\nproblem. Our existence and approximations results lead to the applicability of\nwell-established partially observed Markov decision processes and the\nrelatively more mature theory of discrete-time decentralized stochastic control\nto be applicable for computing near optimal solutions for continuous-time\nstochastic control.",
            "author": [
                "Somnath Pradhan",
                "Serdar Y\u00fcksel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03254v1",
                "http://arxiv.org/pdf/2311.03254v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "primary: 93E20, 93A14, 91A15 secondary: 49K45, 60J60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03253v1",
            "title": "Coherent Entity Disambiguation via Modeling Topic and Categorical\n  Dependency",
            "updated": "2023-11-06T16:40:13Z",
            "published": "2023-11-06T16:40:13Z",
            "summary": "Previous entity disambiguation (ED) methods adopt a discriminative paradigm,\nwhere prediction is made based on matching scores between mention context and\ncandidate entities using length-limited encoders. However, these methods often\nstruggle to capture explicit discourse-level dependencies, resulting in\nincoherent predictions at the abstract level (e.g. topic or category). We\npropose CoherentED, an ED system equipped with novel designs aimed at enhancing\nthe coherence of entity predictions. Our method first introduces an\nunsupervised variational autoencoder (VAE) to extract latent topic vectors of\ncontext sentences. This approach not only allows the encoder to handle longer\ndocuments more effectively, conserves valuable input space, but also keeps a\ntopic-level coherence. Additionally, we incorporate an external category\nmemory, enabling the system to retrieve relevant categories for undecided\nmentions. By employing step-by-step entity decisions, this design facilitates\nthe modeling of entity-entity interactions, thereby maintaining maximum\ncoherence at the category level. We achieve new state-of-the-art results on\npopular ED benchmarks, with an average improvement of 1.3 F1 points. Our model\ndemonstrates particularly outstanding performance on challenging long-text\nscenarios.",
            "author": [
                "Zilin Xiao",
                "Linjun Shou",
                "Xingyao Zhang",
                "Jie Wu",
                "Ming Gong",
                "Jian Pei",
                "Daxin Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03253v1",
                "http://arxiv.org/pdf/2311.03253v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03251v1",
            "title": "Interpretable multiscale Machine Learning-Based Parameterizations of\n  Convection for ICON",
            "updated": "2023-11-06T16:39:28Z",
            "published": "2023-11-06T16:39:28Z",
            "summary": "In order to improve climate projections, machine learning (ML)-based\nparameterizations have been developed for Earth System Models (ESMs) with the\ngoal to better represent subgrid-scale processes or to accelerate computations\nby emulating existent parameterizations. These data-driven models have shown\nsuccess in approximating subgrid-scale processes based on high-resolution\nstorm-resolving simulations. However, most studies have used a particular\nmachine learning method such as simple Multilayer Perceptrons (MLPs) or Random\nForest (RFs) to parameterize the subgrid tendencies or fluxes originating from\nthe compound effect of various small-scale processes (e.g., turbulence,\nradiation, convection, gravity waves). Here, we use a filtering technique to\nexplicitly separate convection from these processes in data produced by the\nIcosahedral Non-hydrostatic modelling framework (ICON) in a realistic setting.\nWe use a method improved by incorporating density fluctuations for computing\nthe subgrid fluxes and compare a variety of different machine learning\nalgorithms on their ability to predict the subgrid fluxes. We further examine\nthe predictions of the best performing non-deep learning model (Gradient\nBoosted Tree regression) and the U-Net. We discover that the U-Net can learn\nnon-causal relations between convective precipitation and convective subgrid\nfluxes and develop an ablated model excluding precipitating tracer species. We\nconnect the learned relations of the U-Net to physical processes in contrast to\nnon-deep learning-based algorithms. Our results suggest that architectures such\nas a U-Net are particularly well suited to parameterize multiscale problems\nlike convection, paying attention to the plausibility of the learned relations,\nthus providing a significant advance upon existing ML subgrid representation in\nESMs.",
            "author": [
                "Helge Heuer",
                "Mierk Schwabe",
                "Pierre Gentine",
                "Marco A. Giorgetta",
                "Veronika Eyring"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03251v1",
                "http://arxiv.org/pdf/2311.03251v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03250v1",
            "title": "Instructed Language Models with Retrievers Are Powerful Entity Linkers",
            "updated": "2023-11-06T16:38:51Z",
            "published": "2023-11-06T16:38:51Z",
            "summary": "Generative approaches powered by large language models (LLMs) have\ndemonstrated emergent abilities in tasks that require complex reasoning\nabilities. Yet the generative nature still makes the generated content suffer\nfrom hallucinations, thus unsuitable for entity-centric tasks like entity\nlinking (EL) requiring precise entity predictions over a large knowledge base.\nWe present Instructed Generative Entity Linker (INSGENEL), the first approach\nthat enables casual language models to perform entity linking over knowledge\nbases. Several methods to equip language models with EL capability were\nproposed in this work, including (i) a sequence-to-sequence training EL\nobjective with instruction-tuning, (ii) a novel generative EL framework based\non a light-weight potential mention retriever that frees the model from heavy\nand non-parallelizable decoding, achieving 4$\\times$ speedup without compromise\non linking metrics. INSGENEL outperforms previous generative alternatives with\n+6.8 F1 points gain on average, also with a huge advantage in training data\nefficiency and training compute consumption. In addition, our skillfully\nengineered in-context learning (ICL) framework for EL still lags behind\nINSGENEL significantly, reaffirming that the EL task remains a persistent\nhurdle for general LLMs.",
            "author": [
                "Zilin Xiao",
                "Ming Gong",
                "Jie Wu",
                "Xingyao Zhang",
                "Linjun Shou",
                "Jian Pei",
                "Daxin Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03250v1",
                "http://arxiv.org/pdf/2311.03250v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03243v1",
            "title": "Safurai-Csharp: Harnessing Synthetic Data to improve language-specific\n  Code LLM",
            "updated": "2023-11-06T16:31:48Z",
            "published": "2023-11-06T16:31:48Z",
            "summary": "This paper introduces Safurai-Csharp, an open-source model designed to\nspecialize in the generation, completion, and debugging of C# code.\nSafurai-Csharp is built upon the novel CodeLlama 34B model and leverages the\nEvolInstruct technique, creating a refined and expanded dataset for its\nfine-tuning process. The results of its performance, a notable score of 56.33%\non the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity\nto streamline developers' workflows and aid code learning. It shows promise in\nsetting new stakes in the landscape of open-source C# LLMs and hopes to inspire\nmore inclusive and wide-ranging development in the field of language-specific\nLLMs.",
            "author": [
                "Davide Cifarelli",
                "Leonardo Boiardi",
                "Alessandro Puppo",
                "Leon Jovanovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03243v1",
                "http://arxiv.org/pdf/2311.03243v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03240v1",
            "title": "Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive\n  Review",
            "updated": "2023-11-06T16:30:40Z",
            "published": "2023-11-06T16:30:40Z",
            "summary": "Tea leaf diseases are a major challenge to agricultural productivity, with\nfar-reaching implications for yield and quality in the tea industry. The rise\nof machine learning has enabled the development of innovative approaches to\ncombat these diseases. Early detection and diagnosis are crucial for effective\ncrop management. For predicting tea leaf disease, several automated systems\nhave already been developed using different image processing techniques. This\npaper delivers a systematic review of the literature on machine learning\nmethodologies applied to diagnose tea leaf disease via image classification. It\nthoroughly evaluates the strengths and constraints of various Vision\nTransformer models, including Inception Convolutional Vision Transformer\n(ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision\nTransformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews\nmodels like Dense Convolutional Network (DenseNet), Residual Neural Network\n(ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN,\nNon-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and\nLesion-Aware Visual Transformer. These machine-learning models have been tested\non various datasets, demonstrating their real-world applicability. This review\nstudy not only highlights current progress in the field but also provides\nvaluable insights for future research directions in the machine learning-based\ndetection and classification of tea leaf diseases.",
            "author": [
                "Faruk Ahmed",
                "Md. Taimur Ahad",
                "Yousuf Rayhan Emon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03240v1",
                "http://arxiv.org/pdf/2311.03240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03235v1",
            "title": "p-Laplacian Transformer",
            "updated": "2023-11-06T16:25:56Z",
            "published": "2023-11-06T16:25:56Z",
            "summary": "$p$-Laplacian regularization, rooted in graph and image signal processing,\nintroduces a parameter $p$ to control the regularization effect on these data.\nSmaller values of $p$ promote sparsity and interpretability, while larger\nvalues encourage smoother solutions. In this paper, we first show that the\nself-attention mechanism obtains the minimal Laplacian regularization ($p=2$)\nand encourages the smoothness in the architecture. However, the smoothness is\nnot suitable for the heterophilic structure of self-attention in transformers\nwhere attention weights between tokens that are in close proximity and\nnon-close ones are assigned indistinguishably. From that insight, we then\npropose a novel class of transformers, namely the $p$-Laplacian Transformer\n(p-LaT), which leverages $p$-Laplacian regularization framework to harness the\nheterophilic features within self-attention layers. In particular, low $p$\nvalues will effectively assign higher attention weights to tokens that are in\nclose proximity to the current token being processed. We empirically\ndemonstrate the advantages of p-LaT over the baseline transformers on a wide\nrange of benchmark datasets.",
            "author": [
                "Tuan Nguyen",
                "Tam Nguyen",
                "Vinh Nguyen",
                "Tan M. Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03235v1",
                "http://arxiv.org/pdf/2311.03235v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07584v1",
            "title": "Performance Prediction of Data-Driven Knowledge summarization of High\n  Entropy Alloys (HEAs) literature implementing Natural Language Processing\n  algorithms",
            "updated": "2023-11-06T16:22:32Z",
            "published": "2023-11-06T16:22:32Z",
            "summary": "The ability to interpret spoken language is connected to natural language\nprocessing. It involves teaching the AI how words relate to one another, how\nthey are meant to be used, and in what settings. The goal of natural language\nprocessing (NLP) is to get a machine intelligence to process words the same way\na human brain does. This enables machine intelligence to interpret, arrange,\nand comprehend textual data by processing the natural language. The technology\ncan comprehend what is communicated, whether it be through speech or writing\nbecause AI pro-cesses language more quickly than humans can. In the present\nstudy, five NLP algorithms, namely, Geneism, Sumy, Luhn, Latent Semantic\nAnalysis (LSA), and Kull-back-Liebler (KL) al-gorithm, are implemented for the\nfirst time for the knowledge summarization purpose of the High Entropy Alloys\n(HEAs). The performance prediction of these algorithms is made by using the\nBLEU score and ROUGE score. The results showed that the Luhn algorithm has the\nhighest accuracy score for the knowledge summarization tasks compared to the\nother used algorithms.",
            "author": [
                "Akshansh Mishra",
                "Vijaykumar S Jatti",
                "Vaishnavi More",
                "Anish Dasgupta",
                "Devarrishi Dixit",
                "Eyob Messele Sefene"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07584v1",
                "http://arxiv.org/pdf/2311.07584v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03233v1",
            "title": "Navigating Scaling Laws: Accelerating Vision Transformer's Training via\n  Adaptive Strategies",
            "updated": "2023-11-06T16:20:28Z",
            "published": "2023-11-06T16:20:28Z",
            "summary": "In recent years, the state-of-the-art in deep learning has been dominated by\nvery large models that have been pre-trained on vast amounts of data. The\nparadigm is very simple: Investing more computational resources (optimally)\nleads to better performance, and even predictably so; neural scaling laws have\nbeen derived that accurately forecast the performance of a network for a\ndesired level of compute. This leads to the notion of a \"compute-optimal\"\nmodel, i.e. a model that allocates a given level of compute during training\noptimally to maximise performance. In this work, we extend the concept of\noptimality by allowing for an \"adaptive\" model, i.e. a model that can change\nits shape during the course of training. By allowing the shape to adapt, we can\noptimally traverse between the underlying scaling laws, leading to a\nsignificant reduction in the required compute to reach a given target\nperformance. We focus on vision tasks and the family of Vision Transformers,\nwhere the patch size as well as the width naturally serve as adaptive shape\nparameters. We demonstrate that, guided by scaling laws, we can design\ncompute-optimal adaptive models that beat their \"static\" counterparts.",
            "author": [
                "Sotiris Anagnostidis",
                "Gregor Bachmann",
                "Thomas Hofmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03233v1",
                "http://arxiv.org/pdf/2311.03233v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03230v1",
            "title": "Balancing Notions of Equity: Approximation Algorithms for Fair Portfolio\n  of Solutions in Combinatorial Optimization",
            "updated": "2023-11-06T16:15:38Z",
            "published": "2023-11-06T16:15:38Z",
            "summary": "Inspired by equity considerations, we consider top-$k$ norm, ordered norm,\nand symmetric monotonic norm objectives for various combinatorial optimization\nproblems. Top-$k$ norms and ordered norms have natural interpretations in terms\nof minimizing the impact on individuals bearing largest costs. To model\ndecision-making with multiple equity criteria, we study the notion of\nportfolios of solutions with the property that each norm or equity criteria has\nan approximately optimal solution in this portfolio. We attempt to characterize\nportfolios by their sizes and approximation factor guarantees for various\ncombinatorial problems. For a given problem, we investigate whether (1) there\nexists a single solution that is approximately optimal for all norms, (2) there\nexists a small approximately optimal portfolio of size larger than 1, (3) there\nexist polynomial time algorithms to find these small portfolios. We study an\nalgorithmic framework to obtain single solutions that are approximately optimal\nfor all norms. We show the existence of such a solution for problems such as\n$k$-clustering, ordered set cover, scheduling for job completion time\nminimization, and scheduling for machine load minimization on identical\nmachines. We also give efficient algorithms to find these solutions in most\ncases, except set cover where we show there is a gap in terms of computational\ncomplexity. Our work improves upon the best-known approximation factor across\nall norms for a single solution in $k$-clustering. For uncapacitated facility\nlocation and scheduling for machine load minimization with identical jobs, we\nobtain logarithmic sized portfolios, also providing a matching lower bound in\nthe latter case. Our work results in new open combinatorial questions, which\nmight be of independent interest.",
            "author": [
                "Swati Gupta",
                "Jai Moondra",
                "Mohit Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03230v1",
                "http://arxiv.org/pdf/2311.03230v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "68W25",
                "F.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03228v1",
            "title": "An Efficient Self-Supervised Cross-View Training For Sentence Embedding",
            "updated": "2023-11-06T16:12:25Z",
            "published": "2023-11-06T16:12:25Z",
            "summary": "Self-supervised sentence representation learning is the task of constructing\nan embedding space for sentences without relying on human annotation efforts.\nOne straightforward approach is to finetune a pretrained language model (PLM)\nwith a representation learning method such as contrastive learning. While this\napproach achieves impressive performance on larger PLMs, the performance\nrapidly degrades as the number of parameters decreases. In this paper, we\npropose a framework called Self-supervised Cross-View Training (SCT) to narrow\nthe performance gap between large and small PLMs. To evaluate the effectiveness\nof SCT, we compare it to 5 baseline and state-of-the-art competitors on seven\nSemantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of\nparameters ranging from 4M to 340M. The experimental results show that STC\noutperforms the competitors for PLMs with less than 100M parameters in 18 of 21\ncases.",
            "author": [
                "Peerat Limkonchotiwat",
                "Wuttikorn Ponwitayarat",
                "Lalita Lowphansirikul",
                "Can Udomcharoenchaikit",
                "Ekapol Chuangsuwanich",
                "Sarana Nutanong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03228v1",
                "http://arxiv.org/pdf/2311.03228v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03227v1",
            "title": "Quantum-inspired anomaly detection, a QUBO formulation",
            "updated": "2023-11-06T16:12:15Z",
            "published": "2023-11-06T16:12:15Z",
            "summary": "Anomaly detection is a crucial task in machine learning that involves\nidentifying unusual patterns or events in data. It has numerous applications in\nvarious domains such as finance, healthcare, and cybersecurity. With the advent\nof quantum computing, there has been a growing interest in developing quantum\napproaches to anomaly detection. After reviewing traditional approaches to\nanomaly detection relying on statistical or distance-based methods, we will\npropose a Quadratic Unconstrained Binary Optimization (QUBO) model formulation\nof anomaly detection, compare it with classical methods, and discuss its\nscalability on current Quantum Processing Units (QPU).",
            "author": [
                "Julien Mellaerts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03227v1",
                "http://arxiv.org/pdf/2311.03227v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03226v1",
            "title": "LDM3D-VR: Latent Diffusion Model for 3D VR",
            "updated": "2023-11-06T16:12:10Z",
            "published": "2023-11-06T16:12:10Z",
            "summary": "Latent diffusion models have proven to be state-of-the-art in the creation\nand manipulation of visual outputs. However, as far as we know, the generation\nof depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite\nof diffusion models targeting virtual reality development that includes\nLDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD\nbased on textual prompts and the upscaling of low-resolution inputs to\nhigh-resolution RGBD, respectively. Our models are fine-tuned from existing\npretrained models on datasets containing panoramic/high-resolution RGB images,\ndepth maps and captions. Both models are evaluated in comparison to existing\nrelated methods.",
            "author": [
                "Gabriela Ben Melech Stan",
                "Diana Wofk",
                "Estelle Aflalo",
                "Shao-Yen Tseng",
                "Zhipeng Cai",
                "Michael Paulitsch",
                "Vasudev Lal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03226v1",
                "http://arxiv.org/pdf/2311.03226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03225v1",
            "title": "Dichotomies for Tree Minor Containment with Structural Parameters",
            "updated": "2023-11-06T16:11:37Z",
            "published": "2023-11-06T16:11:37Z",
            "summary": "The problem of determining whether a graph $G$ contains another graph $H$ as\na minor, referred to as the minor containment problem, is a fundamental problem\nin the field of graph algorithms. While it is NP-complete when $G$ and $H$ are\ngeneral graphs, it is sometimes tractable on more restricted graph classes.\nThis study focuses on the case where both $G$ and $H$ are trees, known as the\ntree minor containment problem. Even in this case, the problem is known to be\nNP-complete. In contrast, polynomial-time algorithms are known for the case\nwhen both trees are caterpillars or when the maximum degree of $H$ is a\nconstant. Our research aims to clarify the boundary of tractability and\nintractability for the tree minor containment problem. Specifically, we provide\ndichotomies for the computational complexities of the problem based on three\nstructural parameters: the diameter, pathwidth, and path eccentricity.",
            "author": [
                "Tatsuya Gima",
                "Soh Kumabe",
                "Kazuhiro Kurita",
                "Yuto Okada",
                "Yota Otachi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03225v1",
                "http://arxiv.org/pdf/2311.03225v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03221v1",
            "title": "Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds\n  Using PointNet",
            "updated": "2023-11-06T16:04:58Z",
            "published": "2023-11-06T16:04:58Z",
            "summary": "The integration of unmanned aerial vehicles (UAVs) into shared airspace for\nbeyond visual line of sight (BVLOS) operations presents significant challenges\nbut holds transformative potential for sectors like transportation,\nconstruction, energy and defense. A critical prerequisite for this integration\nis equipping UAVs with enhanced situational awareness to ensure safe\noperations. Current approaches mainly target single object detection or\nclassification, or simpler sensing outputs that offer limited perceptual\nunderstanding and lack the rapid end-to-end processing needed to convert sensor\ndata into safety-critical insights. In contrast, our study leverages radar\ntechnology for novel end-to-end semantic segmentation of aerial point clouds to\nsimultaneously identify multiple collision hazards. By adapting and optimizing\nthe PointNet architecture and integrating aerial domain insights, our framework\ndistinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and\nairplanes (Ikarus C42), and static returns (ground and infrastructure) which\nresults in enhanced situational awareness for UAVs. To our knowledge, this is\nthe first approach addressing simultaneous identification of multiple collision\nthreats in an aerial setting, achieving a robust 94% accuracy. This work\nhighlights the potential of radar technology to advance situational awareness\nin UAVs, facilitating safe and efficient BVLOS operations.",
            "author": [
                "Hector Arroyo",
                "Paul Kier",
                "Dylan Angus",
                "Santiago Matalonga",
                "Svetlozar Georgiev",
                "Mehdi Goli",
                "Gerard Dooly",
                "James Riordan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03221v1",
                "http://arxiv.org/pdf/2311.03221v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03220v2",
            "title": "ALYMPICS: Language Agents Meet Game Theory",
            "updated": "2023-11-16T05:43:22Z",
            "published": "2023-11-06T16:03:46Z",
            "summary": "This paper introduces Alympics, a platform that leverages Large Language\nModel (LLM) agents to facilitate investigations in game theory. By employing\nLLMs and autonomous agents to simulate human behavior and enable multi-agent\ncollaborations, we can construct realistic and dynamic models of human\ninteractions for game theory hypothesis formulating and testing. To demonstrate\nthis, we present and implement a survival game involving unequal competition\nfor limited resources. Through manipulation of resource availability and agent\npersonalities, we observe how different agents engage in the competition and\nadapt their strategies. The use of LLM agents in game theory research offers\nsignificant advantages, including simulating realistic behavior, providing a\ncontrolled, scalable, and reproducible environment. Our work highlights the\npotential of LLM agents in enhancing the understanding of strategic\ndecision-making within complex socioeconomic contexts. All codes are available\nat https://github.com/microsoft/Alympics",
            "author": [
                "Shaoguang Mao",
                "Yuzhe Cai",
                "Yan Xia",
                "Wenshan Wu",
                "Xun Wang",
                "Fengyi Wang",
                "Tao Ge",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03220v2",
                "http://arxiv.org/pdf/2311.03220v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03219v1",
            "title": "Current-induced spin polarization in chiral Tellurium: a\n  first-principles quantum transport study",
            "updated": "2023-11-06T16:03:43Z",
            "published": "2023-11-06T16:03:43Z",
            "summary": "Te is a naturally p-doped semiconductor with a chiral structure, where an\nelectrical current causes the conduction electrons to become spin polarized\nparallel to the transport direction. In this paper, we present a comprehensive\ntheoretical study of this effect by employing density functional theory (DFT)\ncombined with the non-equilibrium Green's functions (NEGF) technique for\nquantum transport. We suggest that the spin polarization can quantitatively be\nestimated in terms of two complementary quantities, namely the non-equilibrium\nmagnetic moments and the spin current density. The calculated magnetic moments\nare directly compared with the values from previous theoretical studies\nobtaining overall consistent results. On the other hand, the inspection of the\nspin current density provides insights of the magnetotransport properties of\nthe material. Specifically, we predict that the resistance along a Te wire\nchanges when an external magnetic field is applied parallel or antiparallel to\nthe charge current direction. The computed magnetoresistance is however quite\nsmall (~ 0.025%). Finally, we show that the description of the current-induced\nspin polarization in terms of the spin current establishes a straightforward\nconnection with the phenomenon called chiral-induced spin selectivity, recently\nobserved in several nano-junctions.",
            "author": [
                "Reena Gupta",
                "Andrea Droghetti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03219v1",
                "http://arxiv.org/pdf/2311.03219v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03217v2",
            "title": "Leveraging Transformers to Improve Breast Cancer Classification and Risk\n  Assessment with Multi-modal and Longitudinal Data",
            "updated": "2023-11-15T14:37:24Z",
            "published": "2023-11-06T16:01:42Z",
            "summary": "Breast cancer screening, primarily conducted through mammography, is often\nsupplemented with ultrasound for women with dense breast tissue. However,\nexisting deep learning models analyze each modality independently, missing\nopportunities to integrate information across imaging modalities and time. In\nthis study, we present Multi-modal Transformer (MMT), a neural network that\nutilizes mammography and ultrasound synergistically, to identify patients who\ncurrently have cancer and estimate the risk of future cancer for patients who\nare currently cancer-free. MMT aggregates multi-modal data through\nself-attention and tracks temporal tissue changes by comparing current exams to\nprior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 in\ndetecting existing cancers, surpassing strong uni-modal baselines. For 5-year\nrisk prediction, MMT attains an AUROC of 0.826, outperforming prior\nmammography-based risk models. Our research highlights the value of multi-modal\nand longitudinal imaging in cancer diagnosis and risk stratification.",
            "author": [
                "Yiqiu Shen",
                "Jungkyu Park",
                "Frank Yeung",
                "Eliana Goldberg",
                "Laura Heacock",
                "Farah Shamout",
                "Krzysztof J. Geras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03217v2",
                "http://arxiv.org/pdf/2311.03217v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03216v1",
            "title": "Mini Minds: Exploring Bebeshka and Zlata Baby Models",
            "updated": "2023-11-06T16:01:10Z",
            "published": "2023-11-06T16:01:10Z",
            "summary": "In this paper, we describe the University of Lyon 2 submission to the\nStrict-Small track of the BabyLM competition. The shared task is created with\nan emphasis on small-scale language modelling from scratch on limited-size data\nand human language acquisition. Dataset released for the Strict-Small track has\n10M words, which is comparable to children's vocabulary size. We approach the\ntask with an architecture search, minimizing masked language modelling loss on\nthe data of the shared task. Having found an optimal configuration, we\nintroduce two small-size language models (LMs) that were submitted for\nevaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder\nmodel with 12 heads which we term Bebeshka and Zlata, respectively. Despite\nbeing half the scale of the baseline LMs, our proposed models achieve\ncomparable performance. We further explore the applicability of small-scale\nlanguage models in tasks involving moral judgment, aligning their predictions\nwith human values. These findings highlight the potential of compact LMs in\naddressing practical language understanding tasks.",
            "author": [
                "Irina Proskurina",
                "Guillaume Metzler",
                "Julien Velcin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03216v1",
                "http://arxiv.org/pdf/2311.03216v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03210v1",
            "title": "Quantum Task Offloading with the OpenMP API",
            "updated": "2023-11-06T15:53:24Z",
            "published": "2023-11-06T15:53:24Z",
            "summary": "Most of the widely used quantum programming languages and libraries are not\ndesigned for the tightly coupled nature of hybrid quantum-classical algorithms,\nwhich run on quantum resources that are integrated on-premise with classical\nHPC infrastructure. We propose a programming model using the API provided by\nOpenMP to target quantum devices, which provides an easy-to-use and efficient\ninterface for HPC applications to utilize quantum compute resources. We have\nimplemented a variational quantum eigensolver using the programming model,\nwhich has been tested using a classical simulator. We are in the process of\ntesting on the quantum resources hosted at the Leibniz Supercomputing Centre\n(LRZ).",
            "author": [
                "Joseph K. L. Lee",
                "Oliver T. Brown",
                "Mark Bull",
                "Martin Ruefenacht",
                "Johannes Doerfert",
                "Michael Klemm",
                "Martin Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03210v1",
                "http://arxiv.org/pdf/2311.03210v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03207v1",
            "title": "Homogenization of Foil Windings with Globally Supported Polynomial Shape\n  Functions",
            "updated": "2023-11-06T15:50:45Z",
            "published": "2023-11-06T15:50:45Z",
            "summary": "In conventional finite element simulations, foil windings with thin foils and\nwith a large number of turns require many mesh elements. This renders models\nquickly computationally infeasible. This paper uses a homogenized foil winding\nmodel and approximates the voltage distribution in the foil winding domain by\nglobally supported polynomials. This way, the small-scale structure in the foil\nwinding domain does not have to be resolved by the finite element mesh. The\nmethod is validated successfully for a stand-alone foil winding example and for\na pot inductor example. Moreover, a transformer equipped with a foil winding at\nits primary side is simulated using a field-circuit coupled model.",
            "author": [
                "Jonas Bundschuh",
                "Yvonne Sp\u00e4ck-Leigsnering",
                "Herbert De Gersem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03207v1",
                "http://arxiv.org/pdf/2311.03207v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "35Q61",
                "G.1.8; J.2; G.1.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03205v1",
            "title": "PainSeeker: An Automated Method for Assessing Pain in Rats Through\n  Facial Expressions",
            "updated": "2023-11-06T15:49:11Z",
            "published": "2023-11-06T15:49:11Z",
            "summary": "In this letter, we aim to investigate whether laboratory rats' pain can be\nautomatically assessed through their facial expressions. To this end, we began\nby presenting a publicly available dataset called RatsPain, consisting of 1,138\nfacial images captured from six rats that underwent an orthodontic treatment\noperation. Each rat' facial images in RatsPain were carefully selected from\nvideos recorded either before or after the operation and well labeled by eight\nannotators according to the Rat Grimace Scale (RGS). We then proposed a novel\ndeep learning method called PainSeeker for automatically assessing pain in rats\nvia facial expressions. PainSeeker aims to seek pain-related facial local\nregions that facilitate learning both pain discriminative and head pose robust\nfeatures from facial expression images. To evaluate the PainSeeker, we\nconducted extensive experiments on the RatsPain dataset. The results\ndemonstrate the feasibility of assessing rats' pain from their facial\nexpressions and also verify the effectiveness of the proposed PainSeeker in\naddressing this emerging but intriguing problem. The RasPain dataset can be\nfreely obtained from https://github.com/xhzongyuan/RatsPain.",
            "author": [
                "Liu Liu",
                "Guang Li",
                "Dingfan Deng",
                "Jinhua Yu",
                "Yuan Zong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03205v1",
                "http://arxiv.org/pdf/2311.03205v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03201v1",
            "title": "Spatial Process Approximations: Assessing Their Necessity",
            "updated": "2023-11-06T15:46:03Z",
            "published": "2023-11-06T15:46:03Z",
            "summary": "In spatial statistics and machine learning, the kernel matrix plays a pivotal\nrole in prediction, classification, and maximum likelihood estimation. A\nthorough examination reveals that for large sample sizes, the kernel matrix\nbecomes ill-conditioned, provided the sampling locations are fairly evenly\ndistributed. This condition poses significant challenges to numerical\nalgorithms used in prediction and estimation computations and necessitates an\napproximation to prediction and the Gaussian likelihood. A review of current\nmethodologies for managing large spatial data indicates that some fail to\naddress this ill-conditioning problem. Such ill-conditioning often results in\nlow-rank approximations of the stochastic processes. This paper introduces\nvarious optimality criteria and provides solutions for each.",
            "author": [
                "Hao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03201v1",
                "http://arxiv.org/pdf/2311.03201v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04237v1",
            "title": "Online Learning Quantum States with the Logarithmic Loss via VB-FTRL",
            "updated": "2023-11-06T15:45:33Z",
            "published": "2023-11-06T15:45:33Z",
            "summary": "Online learning quantum states with the logarithmic loss (LL-OLQS) is a\nquantum generalization of online portfolio selection, a classic open problem in\nthe field of online learning for over three decades. The problem also emerges\nin designing randomized optimization algorithms for maximum-likelihood quantum\nstate tomography. Recently, Jezequel et al. (arXiv:2209.13932) proposed the\nVB-FTRL algorithm, the first nearly regret-optimal algorithm for OPS with\nmoderate computational complexity. In this note, we generalize VB-FTRL for\nLL-OLQS. Let $d$ denote the dimension and $T$ the number of rounds. The\ngeneralized algorithm achieves a regret rate of $O ( d^2 \\log ( d + T ) )$ for\nLL-OLQS. Each iteration of the algorithm consists of solving a semidefinite\nprogram that can be implemented in polynomial time by, e.g., cutting-plane\nmethods. For comparison, the best-known regret rate for LL-OLQS is currently $O\n( d^2 \\log T )$, achieved by the exponential weight method. However, there is\nno explicit implementation available for the exponential weight method for\nLL-OLQS. To facilitate the generalization, we introduce the notion of\nVB-convexity. VB-convexity is a sufficient condition for the logarithmic\nbarrier associated with any function to be convex and is of independent\ninterest.",
            "author": [
                "Wei-Fu Tseng",
                "Kai-Chun Chen",
                "Zi-Hong Xiao",
                "Yen-Huan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04237v1",
                "http://arxiv.org/pdf/2311.04237v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03198v1",
            "title": "LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for\n  Place Recognition",
            "updated": "2023-11-06T15:39:48Z",
            "published": "2023-11-06T15:39:48Z",
            "summary": "Place recognition is one of the most crucial modules for autonomous vehicles\nto identify places that were previously visited in GPS-invalid environments.\nSensor fusion is considered an effective method to overcome the weaknesses of\nindividual sensors. In recent years, multimodal place recognition fusing\ninformation from multiple sensors has gathered increasing attention. However,\nmost existing multimodal place recognition methods only use limited\nfield-of-view camera images, which leads to an imbalance between features from\ndifferent modalities and limits the effectiveness of sensor fusion. In this\npaper, we present a novel neural network named LCPR for robust multimodal place\nrecognition, which fuses LiDAR point clouds with multi-view RGB images to\ngenerate discriminative and yaw-rotation invariant representations of the\nenvironment. A multi-scale attention-based fusion module is proposed to fully\nexploit the panoramic views from different modalities of the environment and\ntheir correlations. We evaluate our method on the nuScenes dataset, and the\nexperimental results show that our method can effectively utilize multi-view\ncamera and LiDAR data to improve the place recognition performance while\nmaintaining strong robustness to viewpoint changes. Our open-source code and\npre-trained models are available at https://github.com/ZhouZijie77/LCPR .",
            "author": [
                "Zijie Zhou",
                "Jingyi Xu",
                "Guangming Xiong",
                "Junyi Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03198v1",
                "http://arxiv.org/pdf/2311.03198v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03197v3",
            "title": "Stable Linear Subspace Identification: A Machine Learning Approach",
            "updated": "2023-11-30T07:52:31Z",
            "published": "2023-11-06T15:39:05Z",
            "summary": "Machine Learning (ML) and linear System Identification (SI) have been\nhistorically developed independently. In this paper, we leverage\nwell-established ML tools - especially the automatic differentiation framework\n- to introduce SIMBa, a family of discrete linear multi-step-ahead state-space\nSI methods using backpropagation. SIMBa relies on a novel\nLinear-Matrix-Inequality-based free parametrization of Schur matrices to ensure\nthe stability of the identified model.\n  We show how SIMBa generally outperforms traditional linear state-space SI\nmethods, and sometimes significantly, although at the price of a higher\ncomputational burden. This performance gap is particularly remarkable compared\nto other SI methods with stability guarantees, where the gain is frequently\nabove 25% in our investigations, hinting at SIMBa's ability to simultaneously\nachieve state-of-the-art fitting performance and enforce stability.\nInterestingly, these observations hold for a wide variety of input-output\nsystems and on both simulated and real-world data, showcasing the flexibility\nof the proposed approach. We postulate that this new SI paradigm presents a\ngreat extension potential to identify structured nonlinear models from data,\nand we hence open-source SIMBa on https://github.com/Cemempamoi/simba.",
            "author": [
                "Loris Di Natale",
                "Muhammad Zakwan",
                "Bratislav Svetozarevic",
                "Philipp Heer",
                "Giancarlo Ferrari Trecate",
                "Colin N. Jones"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03197v3",
                "http://arxiv.org/pdf/2311.03197v3"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03196v1",
            "title": "Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition",
            "updated": "2023-11-06T15:37:14Z",
            "published": "2023-11-06T15:37:14Z",
            "summary": "One of the major challenges for developing automatic speech recognition (ASR)\nfor low-resource languages is the limited access to labeled data with\ndomain-specific variations. In this study, we propose a pseudo-labeling\napproach to develop a large-scale domain-agnostic ASR dataset. With the\nproposed methodology, we developed a 20k+ hours labeled Bangla speech dataset\ncovering diverse topics, speaking styles, dialects, noisy environments, and\nconversational scenarios. We then exploited the developed corpus to design a\nconformer-based ASR system. We benchmarked the trained ASR with publicly\navailable datasets and compared it with other available models. To investigate\nthe efficacy, we designed and developed a human-annotated domain-agnostic test\nset composed of news, telephony, and conversational data among others. Our\nresults demonstrate the efficacy of the model trained on psuedo-label data for\nthe designed test-set along with publicly-available Bangla datasets. The\nexperimental resources will be publicly\navailable.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)",
            "author": [
                "Rabindra Nath Nandi",
                "Mehadi Hasan Menon",
                "Tareq Al Muntasir",
                "Sagor Sarker",
                "Quazi Sarwar Muhtaseem",
                "Md. Tariqul Islam",
                "Shammur Absar Chowdhury",
                "Firoj Alam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03196v1",
                "http://arxiv.org/pdf/2311.03196v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T50",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03195v2",
            "title": "Some coordination problems are harder than others",
            "updated": "2023-11-18T12:10:49Z",
            "published": "2023-11-06T15:33:16Z",
            "summary": "In order to coordinate players in a game must first identify a target pattern\nof behaviour. In this paper we investigate the difficulty of identifying\nprominent outcomes in two kinds of binary action coordination problems in\nsocial networks: pure coordination games and anti-coordination games. For both\nenvironments, we determine the computational complexity of finding a strategy\nprofile that (i) maximises welfare, (ii) maximises welfare subject to being an\nequilibrium, and (iii) maximises potential. We show that the complexity of\nthese objectives can vary with the type of coordination problem. Objectives (i)\nand (iii) are tractable problems in pure coordination games, but for\nanti-coordination games are NP-hard. Objective (ii), finding the best Nash\nequilibrium, is NP-hard for both. Our results support the idea that\nenvironments in which actions are strategic complements (e.g., technology\nadoption) facilitate successful coordination more readily than those in which\nactions are strategic substitutes (e.g., public good provision).",
            "author": [
                "Argyrios Deligkas",
                "Eduard Eiben",
                "Gregory Gutin",
                "Philip R. Neary",
                "Anders Yeo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03195v2",
                "http://arxiv.org/pdf/2311.03195v2"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03194v1",
            "title": "Few-shot Learning using Data Augmentation and Time-Frequency\n  Transformation for Time Series Classification",
            "updated": "2023-11-06T15:32:50Z",
            "published": "2023-11-06T15:32:50Z",
            "summary": "Deep neural networks (DNNs) that tackle the time series classification (TSC)\ntask have provided a promising framework in signal processing. In real-world\napplications, as a data-driven model, DNNs are suffered from insufficient data.\nFew-shot learning has been studied to deal with this limitation. In this paper,\nwe propose a novel few-shot learning framework through data augmentation, which\ninvolves transformation through the time-frequency domain and the generation of\nsynthetic images through random erasing. Additionally, we develop a\nsequence-spectrogram neural network (SSNN). This neural network model composes\nof two sub-networks: one utilizing 1D residual blocks to extract features from\nthe input sequence while the other one employing 2D residual blocks to extract\nfeatures from the spectrogram representation. In the experiments, comparison\nstudies of different existing DNN models with/without data augmentation are\nconducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine\nfault (WTF) dataset. The experimental results manifest that our proposed method\nachieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48%\nF1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstrates\nits applicability of addressing the few-shot problems for time series\nclassification.",
            "author": [
                "Hao Zhang",
                "Zhendong Pang",
                "Jiangpeng Wang",
                "Teng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03194v1",
                "http://arxiv.org/pdf/2311.03194v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03192v2",
            "title": "Modelling and Optimization Based Control for Demand Response in Active\n  Distribution Networks",
            "updated": "2023-11-30T05:31:34Z",
            "published": "2023-11-06T15:30:14Z",
            "summary": "We explore how Demand Response (DR) can effectively provide electricity\nsystem services such as for the management of bi-directional power flows and\nthe control of voltage deviations in active distribution networks, without\ncompromising consumer comfort or adversely affecting grid operation in the\ntransmission network. By translating intricate power system physics into\nstraightforward control objectives, we design DR control algorithms that can\noperate within realistic computational time frames at scale. We conduct\nsimulation-based experiments and find that minimizing the Euclidean-Norm of the\ntotal residual load at transformer sub-stations is an effective objective for\nharnessing DR for the dispatch of renewable electricity grids. We show that\nthis control objective can be efficiently pursued in sequential order, without\noptimal power flow calculations or information about the topology of a grid.\nAdditionally, we find that pursuing this objective reduces the sum of peak\npower flows along all lines in active distribution networks, and can therefore\nenable both lower transmission losses and lower voltage deviations.",
            "author": [
                "Arsam Aryandoust"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03192v2",
                "http://arxiv.org/pdf/2311.03192v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03191v2",
            "title": "DeepInception: Hypnotize Large Language Model to Be Jailbreaker",
            "updated": "2023-12-05T07:35:24Z",
            "published": "2023-11-06T15:29:30Z",
            "summary": "Despite remarkable success in various applications, large language models\n(LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails\nvoid. However, previous studies for jailbreaks usually resort to brute-force\noptimization or extrapolations of a high computation cost, which might not be\npractical or effective. In this paper, inspired by the Milgram experiment that\nindividuals can harm another person if they are told to do so by an\nauthoritative figure, we disclose a lightweight method, termed as\nDeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock\nits misusing risks. Specifically, DeepInception leverages the personification\nability of LLM to construct a novel nested scene to behave, which realizes an\nadaptive way to escape the usage control in a normal scenario and provides the\npossibility for further direct jailbreaks. Empirically, we conduct\ncomprehensive experiments to show its efficacy. Our DeepInception can achieve\ncompetitive jailbreak success rates with previous counterparts and realize a\ncontinuous jailbreak in subsequent interactions, which reveals the critical\nweakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna,\nLlama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay\nmore attention to the safety aspects of LLMs and a stronger defense against\ntheir misuse risks. The code is publicly available at:\nhttps://github.com/tmlr-group/DeepInception.",
            "author": [
                "Xuan Li",
                "Zhanke Zhou",
                "Jianing Zhu",
                "Jiangchao Yao",
                "Tongliang Liu",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03191v2",
                "http://arxiv.org/pdf/2311.03191v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03188v1",
            "title": "Transition to turbulence in viscoelastic channel flow of dilute polymer\n  solutions",
            "updated": "2023-11-06T15:26:36Z",
            "published": "2023-11-06T15:26:36Z",
            "summary": "The transition to turbulence in a plane Poiseuille flow of dilute polymer\nsolutions is studied by direct numerical simulations of a FENE-P fluid. A range\nof Reynolds number ($Re$) in $2000 \\le Re \\le 5000$ is studied but with the\nsame level of elasticity in viscoelastic flows. The evolution of a\nfinite-amplitude perturbation and its effects on transition dynamics are\ninvestigated. A viscoelastic flow begins transition at an earlier time than its\nNewtonian counterparts, but the transition time appears to be insensitive to\npolymer concentration at dilute or semi-dilute regimes studied. Increasing\npolymer concentration, however, decreases the maximum attainable energy growth\nduring the transition process. The critical or minimum perturbation amplitude\nrequired to trigger transition is computed. Interestingly, both Newtonian and\nviscoelastic flows follow almost the same power-law scaling of $Re^\\gamma$ with\nthe critical exponent $\\gamma \\approx -1.25$, which is in close agreement with\nprevious studies. However, a shift downward is observed for viscoelastic flow,\nsuggesting that smaller perturbation amplitudes are required for the\ntransition. A mechanism of the early transition is investigated by the\nevolution of wall-normal and spanwise velocity fluctuations and flow structure.\nThe early growth of these fluctuations and formation of quasi-streamwise\nvortices around low-speed streaks are promoted by polymers, hence causing an\nearly transition. These vortical structures are found to support the critical\nexponent $\\gamma \\approx -1.25$. Once the transition process is completed,\npolymers play a role in dampening the wall-normal and spanwise velocity\nfluctuations and vortices to attain a drag-reduced state in viscoelastic\nturbulent flows.",
            "author": [
                "Alexia Martinez Ibarra",
                "Jae Sung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03188v1",
                "http://arxiv.org/pdf/2311.03188v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03186v1",
            "title": "Model-based Counterfactual Generator for Gender Bias Mitigation",
            "updated": "2023-11-06T15:25:30Z",
            "published": "2023-11-06T15:25:30Z",
            "summary": "Counterfactual Data Augmentation (CDA) has been one of the preferred\ntechniques for mitigating gender bias in natural language models. CDA\ntechniques have mostly employed word substitution based on dictionaries.\nAlthough such dictionary-based CDA techniques have been shown to significantly\nimprove the mitigation of gender bias, in this paper, we highlight some\nlimitations of such dictionary-based counterfactual data augmentation\ntechniques, such as susceptibility to ungrammatical compositions, and lack of\ngeneralization outside the set of predefined dictionary words. Model-based\nsolutions can alleviate these problems, yet the lack of qualitative parallel\ntraining data hinders development in this direction. Therefore, we propose a\ncombination of data processing techniques and a bi-objective training regime to\ndevelop a model-based solution for generating counterfactuals to mitigate\ngender bias. We implemented our proposed solution and performed an empirical\nevaluation which shows how our model alleviates the shortcomings of\ndictionary-based solutions.",
            "author": [
                "Ewoenam Kwaku Tokpo",
                "Toon Calders"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03186v1",
                "http://arxiv.org/pdf/2311.03186v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03422v1",
            "title": "Efficient and Low-Footprint Object Classification using Spatial Contrast",
            "updated": "2023-11-06T15:24:29Z",
            "published": "2023-11-06T15:24:29Z",
            "summary": "Event-based vision sensors traditionally compute temporal contrast that\noffers potential for low-power and low-latency sensing and computing. In this\nresearch, an alternative paradigm for event-based sensors using localized\nspatial contrast (SC) under two different thresholding techniques, relative and\nabsolute, is investigated. Given the slow maturity of spatial contrast in\ncomparison to temporal-based sensors, a theoretical simulated output of such a\nhardware sensor is explored. Furthermore, we evaluate traffic sign\nclassification using the German Traffic Sign dataset (GTSRB) with well-known\nDeep Neural Networks (DNNs). This study shows that spatial contrast can\neffectively capture salient image features needed for classification using a\nBinarized DNN with significant reduction in input data usage (at least 12X) and\nmemory resources (17.5X), compared to high precision RGB images and DNN, with\nonly a small loss (~2%) in macro F1-score. Binarized MicronNet achieves an\nF1-score of 94.4% using spatial contrast, compared to only 56.3% when using RGB\ninput images. Thus, SC offers great promise for deployment in power and\nresource constrained edge computing environments.",
            "author": [
                "Matthew Belding",
                "Daniel C. Stumpp",
                "Rajkumar Kubendran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03422v1",
                "http://arxiv.org/pdf/2311.03422v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.NE",
                "eess.IV",
                "I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03184v1",
            "title": "Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for\n  Propaganda and Disinformation Detection",
            "updated": "2023-11-06T15:24:18Z",
            "published": "2023-11-06T15:24:18Z",
            "summary": "The spread of disinformation and propagandistic content poses a threat to\nsocietal harmony, undermining informed decision-making and trust in reliable\nsources. Online platforms often serve as breeding grounds for such content, and\nmalicious actors exploit the vulnerabilities of audiences to shape public\nopinion. Although there have been research efforts aimed at the automatic\nidentification of disinformation and propaganda in social media content, there\nremain challenges in terms of performance. The ArAIEval shared task aims to\nfurther research on these particular issues within the context of the Arabic\nlanguage. In this paper, we discuss our participation in these shared tasks. We\ncompeted in subtasks 1A and 2A, where our submitted system secured positions\n9th and 10th, respectively. Our experiments consist of fine-tuning transformer\nmodels and using zero- and few-shot learning with GPT-4.",
            "author": [
                "Yunze Xiao",
                "Firoj Alam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03184v1",
                "http://arxiv.org/pdf/2311.03184v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SI",
                "68T50",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03179v1",
            "title": "ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection\n  in Arabic Text",
            "updated": "2023-11-06T15:21:19Z",
            "published": "2023-11-06T15:21:19Z",
            "summary": "We present an overview of the ArAIEval shared task, organized as part of the\nfirst ArabicNLP 2023 conference co-located with EMNLP 2023. ArAIEval offers two\ntasks over Arabic text: (i) persuasion technique detection, focusing on\nidentifying persuasion techniques in tweets and news articles, and (ii)\ndisinformation detection in binary and multiclass setups over tweets. A total\nof 20 teams participated in the final evaluation phase, with 14 and 16 teams\nparticipating in Tasks 1 and 2, respectively. Across both tasks, we observed\nthat fine-tuning transformer models such as AraBERT was at the core of the\nmajority of the participating systems. We provide a description of the task\nsetup, including a description of the dataset construction and the evaluation\nsetup. We further give a brief overview of the participating systems. All\ndatasets and evaluation scripts from the shared task are released to the\nresearch community. (https://araieval.gitlab.io/) We hope this will enable\nfurther research on these important tasks in Arabic.",
            "author": [
                "Maram Hasanain",
                "Firoj Alam",
                "Hamdy Mubarak",
                "Samir Abdaljalil",
                "Wajdi Zaghouani",
                "Preslav Nakov",
                "Giovanni Da San Martino",
                "Abed Alhakim Freihat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03179v1",
                "http://arxiv.org/pdf/2311.03179v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T50",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03177v1",
            "title": "1D-Convolutional transformer for Parkinson disease diagnosis from gait",
            "updated": "2023-11-06T15:17:17Z",
            "published": "2023-11-06T15:17:17Z",
            "summary": "This paper presents an efficient deep neural network model for diagnosing\nParkinson's disease from gait. More specifically, we introduce a hybrid\nConvNet-Transformer architecture to accurately diagnose the disease by\ndetecting the severity stage. The proposed architecture exploits the strengths\nof both Convolutional Neural Networks and Transformers in a single end-to-end\nmodel, where the former is able to extract relevant local features from\nVertical Ground Reaction Force (VGRF) signal, while the latter allows to\ncapture long-term spatio-temporal dependencies in data. In this manner, our\nhybrid architecture achieves an improved performance compared to using either\nmodels individually. Our experimental results show that our approach is\neffective for detecting the different stages of Parkinson's disease from gait\ndata, with a final accuracy of 88%, outperforming other state-of-the-art AI\nmethods on the Physionet gait dataset. Moreover, our method can be generalized\nand adapted for other classification problems to jointly address the feature\nrelevance and spatio-temporal dependency problems in 1D signals. Our source\ncode and pre-trained models are publicly available at\nhttps://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.",
            "author": [
                "Safwen Naimi",
                "Wassim Bouachir",
                "Guillaume-Alexandre Bilodeau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03177v1",
                "http://arxiv.org/pdf/2311.03177v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03175v1",
            "title": "Frequency Domain Decomposition Translation for Enhanced Medical Image\n  Translation Using GANs",
            "updated": "2023-11-06T15:09:39Z",
            "published": "2023-11-06T15:09:39Z",
            "summary": "Medical Image-to-image translation is a key task in computer vision and\ngenerative artificial intelligence, and it is highly applicable to medical\nimage analysis. GAN-based methods are the mainstream image translation methods,\nbut they often ignore the variation and distribution of images in the frequency\ndomain, or only take simple measures to align high-frequency information, which\ncan lead to distortion and low quality of the generated images. To solve these\nproblems, we propose a novel method called frequency domain decomposition\ntranslation (FDDT). This method decomposes the original image into a\nhigh-frequency component and a low-frequency component, with the high-frequency\ncomponent containing the details and identity information, and the\nlow-frequency component containing the style information. Next, the\nhigh-frequency and low-frequency components of the transformed image are\naligned with the transformed results of the high-frequency and low-frequency\ncomponents of the original image in the same frequency band in the spatial\ndomain, thus preserving the identity information of the image while destroying\nas little stylistic information of the image as possible. We conduct extensive\nexperiments on MRI images and natural images with FDDT and several mainstream\nbaseline models, and we use four evaluation metrics to assess the quality of\nthe generated images. Compared with the baseline models, optimally, FDDT can\nreduce Fr\\'echet inception distance by up to 24.4%, structural similarity by up\nto 4.4%, peak signal-to-noise ratio by up to 5.8%, and mean squared error by up\nto 31%. Compared with the previous method, optimally, FDDT can reduce Fr\\'echet\ninception distance by up to 23.7%, structural similarity by up to 1.8%, peak\nsignal-to-noise ratio by up to 6.8%, and mean squared error by up to 31.6%.",
            "author": [
                "Zhuhui Wang",
                "Jianwei Zuo",
                "Xuliang Deng",
                "Jiajia Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03175v1",
                "http://arxiv.org/pdf/2311.03175v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03421v3",
            "title": "Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain\n  State Decoding",
            "updated": "2023-11-10T16:52:26Z",
            "published": "2023-11-06T15:08:13Z",
            "summary": "The study of brain states, ranging from highly synchronous to asynchronous\nneuronal patterns like the sleep-wake cycle, is fundamental for assessing the\nbrain's spatiotemporal dynamics and their close connection to behavior.\nHowever, the development of new techniques to accurately identify them still\nremains a challenge, as these are often compromised by the presence of noise,\nartifacts, and suboptimal recording quality. In this study, we propose a\ntwo-stage computational framework combining Hopfield Networks for artifact data\npreprocessing with Convolutional Neural Networks (CNNs) for classification of\nbrain states in rat neural recordings under different levels of anesthesia. To\nevaluate the robustness of our framework, we deliberately introduced noise\nartifacts into the neural recordings. We evaluated our hybrid Hopfield-CNN\npipeline by benchmarking it against two comparative models: a standalone CNN\nhandling the same noisy inputs, and another CNN trained and tested on\nartifact-free data. Performance across various levels of data compression and\nnoise intensities showed that our framework can effectively mitigate artifacts,\nallowing the model to reach parity with the clean-data CNN at lower noise\nlevels. Although this study mainly benefits small-scale experiments, the\nfindings highlight the necessity for advanced deep learning and Hopfield\nNetwork models to improve scalability and robustness in diverse real-world\nsettings.",
            "author": [
                "Arnau Marin-Llobet",
                "Arnau Manasanch",
                "Maria V. Sanchez-Vives"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03421v3",
                "http://arxiv.org/pdf/2311.03421v3"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03168v1",
            "title": "Euclid Preparation. TBD. Impact of magnification on spectroscopic galaxy\n  clustering",
            "updated": "2023-11-06T15:01:57Z",
            "published": "2023-11-06T15:01:57Z",
            "summary": "In this paper we investigate the impact of lensing magnification on the\nanalysis of Euclid's spectroscopic survey, using the multipoles of the 2-point\ncorrelation function for galaxy clustering. We determine the impact of lensing\nmagnification on cosmological constraints, and the expected shift in the\nbest-fit parameters if magnification is ignored. We consider two cosmological\nanalyses: i) a full-shape analysis based on the $\\Lambda$CDM model and its\nextension $w_0w_a$CDM and ii) a model-independent analysis that measures the\ngrowth rate of structure in each redshift bin. We adopt two complementary\napproaches in our forecast: the Fisher matrix formalism and the Markov chain\nMonte Carlo method. The fiducial values of the local count slope (or\nmagnification bias), which regulates the amplitude of the lensing\nmagnification, have been estimated from the Euclid Flagship simulations. We use\nlinear perturbation theory and model the 2-point correlation function with the\npublic code coffe. For a $\\Lambda$CDM model, we find that the estimation of\ncosmological parameters is biased at the level of 0.4-0.7 standard deviations,\nwhile for a $w_0w_a$CDM dynamical dark energy model, lensing magnification has\na somewhat smaller impact, with shifts below 0.5 standard deviations. In a\nmodel-independent analysis aiming to measure the growth rate of structure, we\nfind that the estimation of the growth rate is biased by up to $1.2$ standard\ndeviations in the highest redshift bin. As a result, lensing magnification\ncannot be neglected in the spectroscopic survey, especially if we want to\ndetermine the growth factor, one of the most promising ways to test general\nrelativity with Euclid. We also find that, by including lensing magnification\nwith a simple template, this shift can be almost entirely eliminated with\nminimal computational overhead.",
            "author": [
                "Euclid Collaboration",
                "G. Jelic-Cizmek",
                "F. Sorrenti",
                "F. Lepori",
                "C. Bonvin",
                "S. Camera",
                "F. J. Castander",
                "R. Durrer",
                "P. Fosalba",
                "M. Kunz",
                "L. Lombriser",
                "I. Tutusaus",
                "C. Viglione",
                "Z. Sakr",
                "N. Aghanim",
                "A. Amara",
                "S. Andreon",
                "M. Baldi",
                "S. Bardelli",
                "C. Bodendorf",
                "D. Bonino",
                "E. Branchini",
                "M. Brescia",
                "J. Brinchmann",
                "V. Capobianco",
                "C. Carbone",
                "V. F. Cardone",
                "J. Carretero",
                "S. Casas",
                "M. Castellano",
                "S. Cavuoti",
                "A. Cimatti",
                "G. Congedo",
                "C. J. Conselice",
                "L. Conversi",
                "Y. Copin",
                "L. Corcione",
                "F. Courbin",
                "H. M. Courtois",
                "M. Cropper",
                "H. Degaudenzi",
                "A. M. Di Giorgio",
                "J. Dinis",
                "F. Dubath",
                "X. Dupac",
                "S. Dusini",
                "M. Farina",
                "S. Farrens",
                "S. Ferriol",
                "M. Frailis",
                "E. Franceschi",
                "M. Fumana",
                "S. Galeotta",
                "B. Garilli",
                "B. Gillis",
                "C. Giocoli",
                "A. Grazian",
                "F. Grupp",
                "S. V. H. Haugan",
                "H. Hoekstra",
                "W. Holmes",
                "F. Hormuth",
                "A. Hornstrup",
                "K. Jahnke",
                "E. Keih\u00e4nen",
                "S. Kermiche",
                "A. Kiessling",
                "M. Kilbinger",
                "B. Kubik",
                "H. Kurki-Suonio",
                "P. B. Lilje",
                "V. Lindholm",
                "I. Lloro",
                "O. Mansutti",
                "O. Marggraf",
                "K. Markovic",
                "N. Martinet",
                "F. Marulli",
                "R. Massey",
                "E. Medinaceli",
                "S. Mei",
                "M. Meneghetti",
                "E. Merlin",
                "G. Meylan",
                "L. Moscardini",
                "E. Munari",
                "S. -M. Niemi",
                "C. Padilla",
                "S. Paltani",
                "F. Pasian",
                "K. Pedersen",
                "W. J. Percival",
                "V. Pettorino",
                "G. Polenta",
                "M. Poncet",
                "L. A. Popa",
                "F. Raison",
                "R. Rebolo",
                "A. Renzi",
                "J. Rhodes",
                "G. Riccio",
                "E. Romelli",
                "M. Roncarelli",
                "E. Rossetti",
                "R. Saglia",
                "D. Sapone",
                "B. Sartoris",
                "P. Schneider",
                "T. Schrabback",
                "A. Secroun",
                "G. Seidel",
                "S. Serrano",
                "C. Sirignano",
                "G. Sirri",
                "L. Stanco",
                "J. -L. Starck",
                "C. Surace",
                "P. Tallada-Cresp\u00ed",
                "D. Tavagnacco",
                "A. N. Taylor",
                "I. Tereno",
                "R. Toledo-Moreo",
                "F. Torradeflot",
                "E. A. Valentijn",
                "L. Valenziano",
                "T. Vassallo",
                "A. Veropalumbo",
                "Y. Wang",
                "J. Weller",
                "G. Zamorani",
                "J. Zoubian",
                "E. Zucca",
                "A. Biviano",
                "A. Boucaud",
                "E. Bozzo",
                "C. Colodro-Conde",
                "D. Di Ferdinando",
                "J. Graci\u00e1-Carpio",
                "P. Liebing",
                "N. Mauri",
                "C. Neissner",
                "V. Scottez",
                "M. Tenti",
                "M. Viel",
                "M. Wiesmann",
                "Y. Akrami",
                "V. Allevato",
                "S. Anselmi",
                "C. Baccigalupi",
                "A. Balaguera-Antol\u00ednez",
                "M. Ballardini",
                "S. Bruton",
                "C. Burigana",
                "R. Cabanac",
                "A. Cappi",
                "C. S. Carvalho",
                "G. Castignani",
                "T. Castro",
                "G. Ca\\ {n}as-Herrera",
                "K. C. Chambers",
                "A. R. Cooray",
                "J. Coupon",
                "S. Davini",
                "S. de la Torre",
                "G. De Lucia",
                "G. Desprez",
                "S. Di Domizio",
                "H. Dole",
                "A. D\u00edaz-S\u00e1nchez",
                "J. A. Escartin Vigo",
                "S. Escoffier",
                "P. G. Ferreira",
                "I. Ferrero",
                "F. Finelli",
                "L. Gabarra",
                "K. Ganga",
                "J. Garc\u00eda-Bellido",
                "F. Giacomini",
                "G. Gozaliasl",
                "D. Guinet",
                "H. Hildebrandt",
                "S. Ili\u0107",
                "A. Jimenez Mu\\ {n}oz",
                "S. Joudaki",
                "J. J. E. Kajava",
                "V. Kansal",
                "C. C. Kirkpatrick",
                "L. Legrand",
                "A. Loureiro",
                "M. Magliocchetti",
                "G. Mainetti",
                "R. Maoli",
                "M. Martinelli",
                "C. J. A. P. Martins",
                "S. Matthew",
                "M. Maturi",
                "L. Maurin",
                "R. B. Metcalf",
                "M. Migliaccio",
                "P. Monaco",
                "G. Morgante",
                "S. Nadathur",
                "L. Patrizii",
                "A. Pezzotta",
                "V. Popa",
                "C. Porciani",
                "D. Potter",
                "M. P\u00f6ntinen",
                "P. Reimberg",
                "P. -F. Rocci",
                "A. G. S\u00e1nchez",
                "A. Schneider",
                "M. Schultheis",
                "E. Sefusatti",
                "M. Sereno",
                "A. Silvestri",
                "P. Simon",
                "A. Spurio Mancini",
                "J. Steinwagner",
                "G. Testera",
                "M. Tewes",
                "R. Teyssier",
                "S. Toft",
                "S. Tosi",
                "A. Troja",
                "M. Tucci",
                "J. Valiviita",
                "D. Vergani",
                "K. Tanidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03168v1",
                "http://arxiv.org/pdf/2311.03168v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03163v1",
            "title": "SurfFlow: high-throughput surface energy calculations for arbitrary\n  crystals",
            "updated": "2023-11-06T14:58:33Z",
            "published": "2023-11-06T14:58:33Z",
            "summary": "We introduce SurfFlow, an open-source high-throughput workflow package\ndesigned for automated first-principles calculations of surface energies in\narbitrary crystals. Our package offers a comprehensive solution capable of\nhandling multi-element crystals, nonstoichiometric compositions, and asymmetric\nslabs, for all potential terminations. To streamline the computational process,\nSurfFlow employs an efficient pre-screening method that discards surfaces with\nsuspected high surface energy before conducting resource-intensive density\nfunctional theory computations. The results generated are seamlessly compiled\ninto an optimade-compliant database, ensuring easy access and compatibility.\nAdditionally, a user-friendly web interface facilitates workflow submission and\nmanagement, provides result visualization, and enables the examination of Wulff\nshapes. SurfFlow represents a valuable tool for researchers looking to explore\nsurface energies and their implications in a diverse range of systems.",
            "author": [
                "Firat Yalcin",
                "Michael Wolloch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03163v1",
                "http://arxiv.org/pdf/2311.03163v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03162v1",
            "title": "Phase-field simulations of the effect of temperature and interface for\n  zirconium $\u03b4\\mbox{-}$hydrides",
            "updated": "2023-11-06T14:58:01Z",
            "published": "2023-11-06T14:58:01Z",
            "summary": "Hydride precipitation in zirconium cladding materials can damage their\nintegrity and durability.Service temperature and material defects have a\nsignificant effect on the dynamic growth of hydrides. In this study, we have\ndeveloped a phase field model based on the assumption of elastic behaviour\nwithin a specific temperature range (613-653K). This model allows us to study\nthe influence of temperature and interfacial effects on the morphology, stress,\nand average growth rate of zirconium hydride. The results suggest that changes\nin temperature and interfacial energy influence the aspect ratio and average\ngrowth rate of the hydride morphology. The ultimate determinant of hydride\norientation is the loss of interfacial coherence, primarily induced by\ninterfacial dislocation defects and quantifiable by the mismatch degree $q$. An\nescalation in interfacial coherence loss leads to a transition of hydride\ngrowth from horizontal to vertical, accompanied by the onset of redirection\nbehaviour. Interestingly, redirection occurs at a critical mismatch level,\ndenoted $q_c$, and remains unaffected by variations in temperature and\ninterfacial energy. However, this redirection leads to an increase in the\nmaximum stress, which may influence the direction of hydride crack propagation.\nThis research highlights the importance of interfacial coherence and provides\nvaluable insights into the morphology and growth kinetics of hydrides in\nzirconium alloys.",
            "author": [
                "Zi-Hang Chen",
                "Jie Sheng",
                "Yu Liu",
                "Xiao-Ming Shi",
                "Houbing Huang",
                "Ke Xu",
                "Yue-Chao Wang",
                "Shuai Wu",
                "Bo Sun",
                "Hai-Feng Liu",
                "Hai-Feng Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03162v1",
                "http://arxiv.org/pdf/2311.03162v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03153v1",
            "title": "Architectural Sweet Spots for Modeling Human Label Variation by the\n  Example of Argument Quality: It's Best to Relate Perspectives!",
            "updated": "2023-11-06T14:47:48Z",
            "published": "2023-11-06T14:47:48Z",
            "summary": "Many annotation tasks in natural language processing are highly subjective in\nthat there can be different valid and justified perspectives on what is a\nproper label for a given example. This also applies to the judgment of argument\nquality, where the assignment of a single ground truth is often questionable.\nAt the same time, there are generally accepted concepts behind argumentation\nthat form a common ground. To best represent the interplay of individual and\nshared perspectives, we consider a continuum of approaches ranging from models\nthat fully aggregate perspectives into a majority label to \"share\nnothing\"-architectures in which each annotator is considered in isolation from\nall other annotators. In between these extremes, inspired by models used in the\nfield of recommender systems, we investigate the extent to which architectures\nthat include layers to model the relations between different annotators are\nbeneficial for predicting single-annotator labels. By means of two tasks of\nargument quality classification (argument concreteness and validity/novelty of\nconclusions), we show that recommender architectures increase the averaged\nannotator-individual F$_1$-scores up to $43\\%$ over a majority label model. Our\nfindings indicate that approaches to subjectivity can benefit from relating\nindividual perspectives.",
            "author": [
                "Philipp Heinisch",
                "Matthias Orlikowski",
                "Julia Romberg",
                "Philipp Cimiano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03153v1",
                "http://arxiv.org/pdf/2311.03153v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03149v1",
            "title": "Asymmetric Masked Distillation for Pre-Training Small Foundation Models",
            "updated": "2023-11-06T14:44:34Z",
            "published": "2023-11-06T14:44:34Z",
            "summary": "Self-supervised foundation models have shown great potential in computer\nvision thanks to the pre-training paradigm of masked autoencoding. Scale is a\nprimary factor influencing the performance of these foundation models. However,\nthese large foundation models often result in high computational cost that\nmight limit their deployment. This paper focuses on pre-training relatively\nsmall vision transformer models that could be efficiently adapted to downstream\ntasks. Specifically, taking inspiration from knowledge distillation in model\ncompression, we propose a new asymmetric masked distillation(AMD) framework for\npre-training relatively small models with autoencoding. The core of AMD is to\ndevise an asymmetric masking strategy, where the teacher model is enabled to\nsee more context information with a lower masking ratio, while the student\nmodel still with high masking ratio to the original masked pre-training. We\ndesign customized multi-layer feature alignment between the teacher encoder and\nstudent encoder to regularize the pre-training of student MAE. To demonstrate\nthe effectiveness and versatility of AMD, we apply it to both ImageMAE and\nVideoMAE for pre-training relatively small ViT models. AMD achieved 84.6%\nclassification accuracy on IN1K using the ViT-B model. And AMD achieves 73.3%\nclassification accuracy using the ViT-B model on the Something-in-Something V2\ndataset, a 3.7% improvement over the original ViT-B model from VideoMAE. We\nalso transfer AMD pre-trained models to downstream tasks and obtain consistent\nperformance improvement over the standard pre-training.",
            "author": [
                "Zhiyu Zhao",
                "Bingkun Huang",
                "Sen Xing",
                "Gangshan Wu",
                "Yu Qiao",
                "Limin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03149v1",
                "http://arxiv.org/pdf/2311.03149v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03142v2",
            "title": "Plasmons in a layered strange metal using the gauge-gravity duality",
            "updated": "2023-11-09T12:55:06Z",
            "published": "2023-11-06T14:39:08Z",
            "summary": "In an attempt to understand the density-density response of the cuprate\nsuperconductors, we study plasmons in a layered strange metal using the\nGubser-Rocha model. The latter is a well-known bottom-up holographic model for\na strange metal that is used here to describe the strongly repulsive on-site\ninteractions between the electrons in each copper-oxide (CuO$_2$) layer,\nwhereas the long-range Coulomb interactions are incorporated by a so-called\ndouble-trace deformation. To be able to model the bilayer cuprates more\nrealistically, we consider in particular the case of two closely-spaced CuO$_2$\nlayers per unit cell. In the response we then obtain for vanishing out-of-plane\nmomentum both an optical and an acoustic plasmon, whereas for nonvanishing\nout-of-plane momentum there are two acoustic plasmon modes. We present the full\ndensity-density spectral functions with parameters typical for cuprates and\ndiscuss both the dispersion and the lifetime of these plasmon excitations.\nMoreover, we compute the conductivity after introducing disorder into the\nsystem. Finally, we also compute the loss function to facilitate a comparison\nwith experimental results from electron energy loss spectroscopy.",
            "author": [
                "S. T. Van den Eede",
                "T. J. N. van Stralen",
                "C. F. J. Flipse",
                "H. T. C. Stoof"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03142v2",
                "http://arxiv.org/pdf/2311.03142v2"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03140v1",
            "title": "Animating NeRFs from Texture Space: A Framework for Pose-Dependent\n  Rendering of Human Performances",
            "updated": "2023-11-06T14:34:36Z",
            "published": "2023-11-06T14:34:36Z",
            "summary": "Creating high-quality controllable 3D human models from multi-view RGB videos\nposes a significant challenge. Neural radiance fields (NeRFs) have demonstrated\nremarkable quality in reconstructing and free-viewpoint rendering of static as\nwell as dynamic scenes. The extension to a controllable synthesis of dynamic\nhuman performances poses an exciting research question. In this paper, we\nintroduce a novel NeRF-based framework for pose-dependent rendering of human\nperformances. In our approach, the radiance field is warped around an SMPL body\nmesh, thereby creating a new surface-aligned representation. Our representation\ncan be animated through skeletal joint parameters that are provided to the NeRF\nin addition to the viewpoint for pose dependent appearances. To achieve this,\nour representation includes the corresponding 2D UV coordinates on the mesh\ntexture map and the distance between the query point and the mesh. To enable\nefficient learning despite mapping ambiguities and random visual variations, we\nintroduce a novel remapping process that refines the mapped coordinates.\nExperiments demonstrate that our approach results in high-quality renderings\nfor novel-view and novel-pose synthesis.",
            "author": [
                "Paul Knoll",
                "Wieland Morgenstern",
                "Anna Hilsmann",
                "Peter Eisert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03140v1",
                "http://arxiv.org/pdf/2311.03140v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03135v1",
            "title": "Generalized integrals and point interactions",
            "updated": "2023-11-06T14:30:24Z",
            "published": "2023-11-06T14:30:24Z",
            "summary": "First we recall a method of computing scalar products of eigenfunctions of a\nSturm-Liouville operator. This method is then applied to Macdonald and\nGegenbauer functions, which are eigenfunctions of the Bessel, resp. Gegenbauer\noperators. The computed scalar products are well defined only for a limited\nrange of parameters. To extend the obtained formulas to a much larger range of\nparameters, we introduce the concept of a generalized integral. The (standard\nas well as generalized) integrals of Macdonald and Gegenbauer functions have\nimportant applications to operator theory. Macdonald functions can be used to\nexpress the integral kernels of the resolvent (Green functions) of the\nLaplacian on the Euclidean space in any dimension. Similarly, Gegenbauer\nfunctions appear in Green functions of the Laplacian on the sphere and the\nhyperbolic space. In dimensions 1,2,3 one can perturb these Laplacians with a\npoint potential, obtaining a well defined self-adjoint operator. Standard\nintegrals of Macdonald and Gegenbauer functions appear in the formulas for the\ncorresponding Green functions. In higher dimensions the Laplacian perturbed by\npoint potentials does not exist. However, the corresponding Green function can\nbe generalized to any dimension by using generalized integrals.",
            "author": [
                "Jan Derezi\u0144ski",
                "Christian Ga\u00df",
                "B\u0142a\u017cej Ruba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03135v1",
                "http://arxiv.org/pdf/2311.03135v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.CA",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03131v1",
            "title": "Reservoir-Computing Model for Mapping and Forecasting Neuronal\n  Interactions from Electrophysiological Data",
            "updated": "2023-11-06T14:28:11Z",
            "published": "2023-11-06T14:28:11Z",
            "summary": "Electrophysiological nature of neuronal networks allows to reveal various\ninteractions between different cell units at a very short time-scales. One of\nthe many challenges in analyzing these signals is to retrieve the morphology\nand functionality of a given network. In this work we developed a computational\nmodel, based on Reservoir Computing Network (RCN) architecture, which decodes\nthe spatio-temporal data from electro-physiological measurements of neuronal\ncultures and reconstructs the network structure on a macroscopic domain,\nrepresenting the connectivity between neuronal units. We demonstrate that the\nmodel can predict the connectivity map of the network with higher accuracy than\nthe common methods such as Cross-Correlation and Transfer-Entropy. In addition,\nwe experimentally demonstrate the ability of the model to predict a network\nresponse to a specific input, such as localized stimulus.",
            "author": [
                "Ilya Auslender",
                "Giorgio Letti",
                "Yasaman Heydari",
                "Lorenzo Pavesi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03131v1",
                "http://arxiv.org/pdf/2311.03131v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03130v1",
            "title": "Fully nonlinear transformations of the Weyl-Bondi-Metzner-Sachs\n  asymptotic symmetry group",
            "updated": "2023-11-06T14:27:47Z",
            "published": "2023-11-06T14:27:47Z",
            "summary": "The asymptotic symmetry group of general relativity in asymptotically flat\nspacetimes can be extended from the Bondi-Metzner-Sachs (BMS) group to the\ngeneralized BMS (GMBS) group suggested by Campiglia and Laddha, which includes\narbitrary diffeomorphisms of the celestial two-sphere. It can be further\nextended to the Weyl BMS (BMSW) group suggested by Freidel, Oliveri, Pranzetti\nand Speziale, which includes general conformal transformations. We compute the\naction of fully nonlinear BMSW transformations on the leading order Bondi-gauge\nmetric functions: specifically, the induced metric, Bondi mass aspect, angular\nmomentum aspect, and shear. These results generalize previous linearized\nresults in the BMSW context by Freidel et al., and also nonlinear results in\nthe BMS context by Chen, Wang, Wang and Yau. The transformation laws will be\nuseful for exploring implications of the BMSW group.",
            "author": [
                "Eanna E. Flanagan",
                "David A. Nichols"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03130v1",
                "http://arxiv.org/pdf/2311.03130v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03128v1",
            "title": "Benchmarking Differential Evolution on a Quantum Simulator",
            "updated": "2023-11-06T14:27:00Z",
            "published": "2023-11-06T14:27:00Z",
            "summary": "The use of Evolutionary Algorithms (EA) for solving\nMathematical/Computational Optimization Problems is inspired by the biological\nprocesses of Evolution. Few of the primitives involved in the Evolutionary\nprocess/paradigm are selection of 'Fit' individuals (from a population sample)\nfor retention, cloning, mutation, discarding, breeding, crossover etc. In the\nEvolutionary Algorithm abstraction, the individuals are deemed to be solution\ncandidates to an Optimization problem and additional solution(/sets) are built\nby applying analogies to the above primitives (cloning, mutation etc.) by means\nof evaluating a 'Fitness' function/criterion. One such algorithm is\nDifferential Evolution (DE) which can be used to compute the minima of\nfunctions such as the rastrigin function and rosenbrock function. This work is\nan attempt to study the result of applying the DE method on these functions\nwith candidate individuals generated on classical Turing modeled computation\nand comparing the same with those on state of the art Quantum computation.The\nstudy benchmarks the convergence of these functions by varying the parameters\ninitialized and reports timing, convergence, and resource utilization results.",
            "author": [
                "Parthasarathy Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03128v1",
                "http://arxiv.org/pdf/2311.03128v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03127v1",
            "title": "Findings of the WMT 2023 Shared Task on Discourse-Level Literary\n  Translation: A Fresh Orb in the Cosmos of LLMs",
            "updated": "2023-11-06T14:23:49Z",
            "published": "2023-11-06T14:23:49Z",
            "summary": "Translating literary works has perennially stood as an elusive dream in\nmachine translation (MT), a journey steeped in intricate challenges. To foster\nprogress in this domain, we hold a new shared task at WMT 2023, the first\nedition of the Discourse-Level Literary Translation. First, we (Tencent AI Lab\nand China Literature Ltd.) release a copyrighted and document-level\nChinese-English web novel corpus. Furthermore, we put forth an\nindustry-endorsed criteria to guide human evaluation process. This year, we\ntotally received 14 submissions from 7 academia and industry teams. We employ\nboth automatic and human evaluations to measure the performance of the\nsubmitted systems. The official ranking of the systems is based on the overall\nhuman judgments. In addition, our extensive analysis reveals a series of\ninteresting findings on literary and discourse-aware MT. We release data,\nsystem outputs, and leaderboard at\nhttp://www2.statmt.org/wmt23/literary-translation-task.html.",
            "author": [
                "Longyue Wang",
                "Zhaopeng Tu",
                "Yan Gu",
                "Siyou Liu",
                "Dian Yu",
                "Qingsong Ma",
                "Chenyang Lyu",
                "Liting Zhou",
                "Chao-Hong Liu",
                "Yufeng Ma",
                "Weiyu Chen",
                "Yvette Graham",
                "Bonnie Webber",
                "Philipp Koehn",
                "Andy Way",
                "Yulin Yuan",
                "Shuming Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03127v1",
                "http://arxiv.org/pdf/2311.03127v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03125v1",
            "title": "Charge and energy deposition in the McDIPPER framework",
            "updated": "2023-11-06T14:20:15Z",
            "published": "2023-11-06T14:20:15Z",
            "summary": "In this short note we present aspects of the energy and charge deposition\nwithin the McDIPPER, a novel 3D resolved model for the initial state of\nultrarelativistic Heavy-Ion collisions based on the $k_\\perp$-factorized Color\nGlass Condensate hybrid approach. This framework is a initial-state Monte Carlo\nevent generator which deposits the relevant conserved charges (energy, charge\nand baryon densities) both in the midrapidity and forward/backward regions of\nthe collision. The event-by-event generator computes the gluon and (anti-)\nquark phase-space densities using the IP-Sat model, from where the conserved\ncharges can be extracted directly. In this work we present the centrality and\ncollision energy dependence for the deposited conserved quantities at\nmidrapidity and the full event, the so-called $4\\pi$ solid angle range.",
            "author": [
                "Oscar Garcia-Montero",
                "S\u00f6ren Schlichting",
                "Hannah Elfner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03125v1",
                "http://arxiv.org/pdf/2311.03125v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03124v1",
            "title": "TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply\n  Chains",
            "updated": "2023-11-06T14:19:05Z",
            "published": "2023-11-06T14:19:05Z",
            "summary": "Due to the steadily rising amount of valuable goods in supply chains,\ntampering detection for parcels is becoming increasingly important. In this\nwork, we focus on the use-case last-mile delivery, where only a single RGB\nimage is taken and compared against a reference from an existing database to\ndetect potential appearance changes that indicate tampering. We propose a\ntampering detection pipeline that utilizes keypoint detection to identify the\neight corner points of a parcel. This permits applying a perspective\ntransformation to create normalized fronto-parallel views for each visible\nparcel side surface. These viewpoint-invariant parcel side surface\nrepresentations facilitate the identification of signs of tampering on parcels\nwithin the supply chain, since they reduce the problem to parcel side surface\nmatching with pair-wise appearance change detection. Experiments with multiple\nclassical and deep learning-based change detection approaches are performed on\nour newly collected TAMpering detection dataset for PARcels, called TAMPAR. We\nevaluate keypoint and change detection separately, as well as in a unified\nsystem for tampering detection. Our evaluation shows promising results for\nkeypoint (Keypoint AP 75.76) and tampering detection (81% accuracy, F1-Score\n0.83) on real images. Furthermore, a sensitivity analysis for tampering types,\nlens distortion and viewing angles is presented. Code and dataset are available\nat https://a-nau.github.io/tampar.",
            "author": [
                "Alexander Naumann",
                "Felix Hertlein",
                "Laura D\u00f6rr",
                "Kai Furmans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03124v1",
                "http://arxiv.org/pdf/2311.03124v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03123v1",
            "title": "Sculpting harmonic comb states in terahertz quantum cascade lasers by\n  controlled engineering",
            "updated": "2023-11-06T14:18:25Z",
            "published": "2023-11-06T14:18:25Z",
            "summary": "Optical frequency combs (FCs), that establish a rigid phase-coherent link\nbetween the microwave and optical domains of the electromagnetic spectrum, are\nemerging as a key high-precision tools for the development of quantum\ntechnology platforms. These include potential applications for communication,\ncomputation, information, sensing and metrology, and can extend from the\nnear-infrared with micro-resonator combs, up to the technologically attractive\nterahertz (THz) frequency range, with powerful and miniaturized quantum cascade\nlaser (QCL) FCs. The recently discovered ability of the QCLs to produce a\nharmonic frequency comb (HFC), a FC with large intermodal spacings, has\nattracted new interest in these devices for both applications and fundamental\nphysics, particularly for the generation of THz tones of high spectral purity\nfor high data rate wireless communication networks, for radiofrequency\narbitrary waveform synthesis, and for the development of quantum key\ndistributions. The controlled generation of harmonic states of a specific order\nremains, however, elusive in THz QCLs. Here we devise a strategy to obtain\nbroadband HFC emission of a pre-defined order in QCL, by design. By patterning\nn regularly spaced defects on the top-surface of a double-metal Fabry-Perot\nQCL, we demonstrate harmonic comb emission with modes spaced by (n+1) free\nspectral range and with a record optical power/mode of ~270 $\\mu W$.",
            "author": [
                "Elisa Riccardi",
                "M. Alejandro Justo Guerrero",
                "Valentino Pistore",
                "Lukas Seitner",
                "Christian Jirauschek",
                "Lianhe Li",
                "A. Giles Davies",
                "Edmund H. Linfield",
                "Miriam S. Vitiello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03123v1",
                "http://arxiv.org/pdf/2311.03123v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03420v1",
            "title": "Text Augmentations with R-drop for Classification of Tweets Self\n  Reporting Covid-19",
            "updated": "2023-11-06T14:18:16Z",
            "published": "2023-11-06T14:18:16Z",
            "summary": "This paper presents models created for the Social Media Mining for Health\n2023 shared task. Our team addressed the first task, classifying tweets that\nself-report Covid-19 diagnosis. Our approach involves a classification model\nthat incorporates diverse textual augmentations and utilizes R-drop to augment\ndata and mitigate overfitting, boosting model efficacy. Our leading model,\nenhanced with R-drop and augmentations like synonym substitution, reserved\nwords, and back translations, outperforms the task mean and median scores. Our\nsystem achieves an impressive F1 score of 0.877 on the test set.",
            "author": [
                "Sumam Francis",
                "Marie-Francine Moens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03420v1",
                "http://arxiv.org/pdf/2311.03420v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03117v1",
            "title": "Enriched Presheaf Model of Quantum FPC",
            "updated": "2023-11-06T14:10:19Z",
            "published": "2023-11-06T14:10:19Z",
            "summary": "Selinger gave a superoperator model of a first-order quantum programming\nlanguage and proved that it is fully definable and hence fully abstract. This\npaper proposes an extension of the superoperator model to higher-order programs\nbased on modules over superoperators or, equivalently, enriched presheaves over\nthe category of superoperators. The enriched presheaf category can be easily\nproved to be a model of intuitionistic linear logic with cofree exponential,\nfrom which one can cave out a model of classical linear logic by a kind of\nbi-orthogonality construction. Although the structures of an enriched presheaf\ncategory are usually rather complex, a morphism in the classical model can be\nexpressed simply as a matrix of completely positive maps. The model inherits\nmany desirable properties from the superoperator model. A conceptually\ninteresting property is that our model has only a state whose \"total\nprobability\" is bounded by 1, i.e. does not have a state where true and false\neach occur with probability 2/3. Another convenient property inherited from the\nsuperoperator model is a $\\omega$CPO-enrichment. Remarkably, our model has a\nsufficient structure to interpret arbitrary recursive types by the standard\ndomain theoretic technique. We introduce Quantum FPC, a quantum\n$\\lambda$-calculus with recursive types, and prove that our model is a fully\nabstract model of Quantum FPC.",
            "author": [
                "Takeshi Tsukada",
                "Kazuyuki Asada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03117v1",
                "http://arxiv.org/pdf/2311.03117v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LO",
                "F.3.2; F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03115v1",
            "title": "RELand: Risk Estimation of Landmines via Interpretable Invariant Risk\n  Minimization",
            "updated": "2023-11-06T14:07:47Z",
            "published": "2023-11-06T14:07:47Z",
            "summary": "Landmines remain a threat to war-affected communities for years after\nconflicts have ended, partly due to the laborious nature of demining tasks.\nHumanitarian demining operations begin by collecting relevant information from\nthe sites to be cleared, which is then analyzed by human experts to determine\nthe potential risk of remaining landmines. In this paper, we propose RELand\nsystem to support these tasks, which consists of three major components. We (1)\nprovide general feature engineering and label assigning guidelines to enhance\ndatasets for landmine risk modeling, which are widely applicable to global\ndemining routines, (2) formulate landmine presence as a classification problem\nand design a novel interpretable model based on sparse feature masking and\ninvariant risk minimization, and run extensive evaluation under proper\nprotocols that resemble real-world demining operations to show a significant\nimprovement over the state-of-the-art, and (3) build an interactive web\ninterface to suggest priority areas for demining organizations. We are\ncurrently collaborating with a humanitarian demining NGO in Colombia that is\nusing our system as part of their field operations in two areas recently\nprioritized for demining.",
            "author": [
                "Mateo Dulce Rubio",
                "Siqi Zeng",
                "Qi Wang",
                "Didier Alvarado",
                "Francisco Moreno",
                "Hoda Heidari",
                "Fei Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03115v1",
                "http://arxiv.org/pdf/2311.03115v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03113v1",
            "title": "Injecting Categorical Labels and Syntactic Information into Biomedical\n  NER",
            "updated": "2023-11-06T14:03:59Z",
            "published": "2023-11-06T14:03:59Z",
            "summary": "We present a simple approach to improve biomedical named entity recognition\n(NER) by injecting categorical labels and Part-of-speech (POS) information into\nthe model. We use two approaches, in the first approach, we first train a\nsequence-level classifier to classify the sentences into categories to obtain\nthe sentence-level tags (categorical labels). The sequence classifier is\nmodeled as an entailment problem by modifying the labels as a natural language\ntemplate. This helps to improve the accuracy of the classifier. Further, this\nlabel information is injected into the NER model. In this paper, we demonstrate\neffective ways to represent and inject these labels and POS attributes into the\nNER model. In the second approach, we jointly learn the categorical labels and\nNER labels. Here we also inject the POS tags into the model to increase the\nsyntactic context of the model. Experiments on three benchmark datasets show\nthat incorporating categorical label information with syntactic context is\nquite useful and outperforms baseline BERT-based models.",
            "author": [
                "Sumam Francis",
                "Marie-Francine Moens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03113v1",
                "http://arxiv.org/pdf/2311.03113v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03109v1",
            "title": "Tensor Golub Kahan based on Einstein product",
            "updated": "2023-11-06T13:58:54Z",
            "published": "2023-11-06T13:58:54Z",
            "summary": "The Singular Value Decomposition (SVD) of matrices is a widely used tool in\nscientific computing. In many applications of machine learning, data analysis,\nsignal and image processing, the large datasets are structured into tensors,\nfor which generalizations of SVD have already been introduced, for various\ntypes of tensor-tensor products. In this article, we present innovative methods\nfor approximating this generalization of SVD to tensors in the framework of the\nEinstein tensor product. These singular elements are called singular values and\nsingular tensors, respectively. The proposed method uses the tensor Lanczos\nbidiagonalization applied to the Einstein product. In most applications, as in\nthe matrix case, the extremal singular values are of special interest. To\nenhance the approximation of the largest or the smallest singular triplets\n(singular values and left and right singular tensors), a restarted method based\non Ritz augmentation is proposed. Numerical results are proposed to illustrate\nthe effectiveness of the presented method. In addition, applications to video\ncompression and facial recognition are presented.",
            "author": [
                "Anas El Hachimi",
                "Khalide Jbilou",
                "Mustapha Hached",
                "Ahmed Ratnani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03109v1",
                "http://arxiv.org/pdf/2311.03109v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03106v1",
            "title": "Unified Multi-modal Unsupervised Representation Learning for\n  Skeleton-based Action Understanding",
            "updated": "2023-11-06T13:56:57Z",
            "published": "2023-11-06T13:56:57Z",
            "summary": "Unsupervised pre-training has shown great success in skeleton-based action\nunderstanding recently. Existing works typically train separate\nmodality-specific models, then integrate the multi-modal information for action\nunderstanding by a late-fusion strategy. Although these approaches have\nachieved significant performance, they suffer from the complex yet redundant\nmulti-stream model designs, each of which is also limited to the fixed input\nskeleton modality. To alleviate these issues, in this paper, we propose a\nUnified Multimodal Unsupervised Representation Learning framework, called\nUmURL, which exploits an efficient early-fusion strategy to jointly encode the\nmulti-modal features in a single-stream manner. Specifically, instead of\ndesigning separate modality-specific optimization processes for uni-modal\nunsupervised learning, we feed different modality inputs into the same stream\nwith an early-fusion strategy to learn their multi-modal features for reducing\nmodel complexity. To ensure that the fused multi-modal features do not exhibit\nmodality bias, i.e., being dominated by a certain modality input, we further\npropose both intra- and inter-modal consistency learning to guarantee that the\nmulti-modal features contain the complete semantics of each modal via feature\ndecomposition and distinct alignment. In this manner, our framework is able to\nlearn the unified representations of uni-modal or multi-modal skeleton input,\nwhich is flexible to different kinds of modality input for robust action\nunderstanding in practical cases. Extensive experiments conducted on three\nlarge-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that\nUmURL is highly efficient, possessing the approximate complexity with the\nuni-modal methods, while achieving new state-of-the-art performance across\nvarious downstream task scenarios in skeleton-based action representation\nlearning.",
            "author": [
                "Shengkai Sun",
                "Daizong Liu",
                "Jianfeng Dong",
                "Xiaoye Qu",
                "Junyu Gao",
                "Xun Yang",
                "Xun Wang",
                "Meng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03106v1",
                "http://arxiv.org/pdf/2311.03106v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03105v2",
            "title": "Pelvic floor MRI segmentation based on semi-supervised deep learning",
            "updated": "2023-11-22T15:46:00Z",
            "published": "2023-11-06T13:54:52Z",
            "summary": "The semantic segmentation of pelvic organs via MRI has important clinical\nsignificance. Recently, deep learning-enabled semantic segmentation has\nfacilitated the three-dimensional geometric reconstruction of pelvic floor\norgans, providing clinicians with accurate and intuitive diagnostic results.\nHowever, the task of labeling pelvic floor MRI segmentation, typically\nperformed by clinicians, is labor-intensive and costly, leading to a scarcity\nof labels. Insufficient segmentation labels limit the precise segmentation and\nreconstruction of pelvic floor organs. To address these issues, we propose a\nsemi-supervised framework for pelvic organ segmentation. The implementation of\nthis framework comprises two stages. In the first stage, it performs\nself-supervised pre-training using image restoration tasks. Subsequently,\nfine-tuning of the self-supervised model is performed, using labeled data to\ntrain the segmentation model. In the second stage, the self-supervised\nsegmentation model is used to generate pseudo labels for unlabeled data.\nUltimately, both labeled and unlabeled data are utilized in semi-supervised\ntraining. Upon evaluation, our method significantly enhances the performance in\nthe semantic segmentation and geometric reconstruction of pelvic organs, Dice\ncoefficient can increase by 2.65% averagely. Especially for organs that are\ndifficult to segment, such as the uterus, the accuracy of semantic segmentation\ncan be improved by up to 3.70%.",
            "author": [
                "Jianwei Zuo",
                "Fei Feng",
                "Zhuhui Wang",
                "James A. Ashton-Miller",
                "John O. L. Delancey",
                "Jiajia Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03105v2",
                "http://arxiv.org/pdf/2311.03105v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03103v1",
            "title": "Parametric Resurgences of the Second Painlev\u00e9 Equation and Minimal\n  Superstrings",
            "updated": "2023-11-06T13:52:40Z",
            "published": "2023-11-06T13:52:40Z",
            "summary": "The aim of this paper is to study the resurgent transseries structure of the\ninhomogeneous and $q$-deformed Painlev\\'e II equations. Appearing in a variety\nof physical systems we here focus on their description of $(2,4)$-super minimal\nstring theory with either D-branes or RR-flux backgrounds. In this context they\nappear as double scaled string equations of matrix models, and we relate the\nresurgent transseries structures appearing in this way with explicit matrix\nmodel computations. The main body of the paper is focused on studying the\ntransseries structure of these equations as well as the corresponding\nresurgence analyses. Concretely, the aim will be to give a recursion relation\nfor the transseries sectors and obtain the non-perturbative transmonomials --\n{\\it i.e.}, the instanton actions of the systems. From the resurgence point of\nview, the goal is to obtain Stokes data. These encode how the transseries\nparameters jump at the Stokes lines when turning around the complex plane in\norder to produce a global transseries solution. The main result will be a\nconjectured form for the transition functions of these transseries parameters.\nWe explore how these equations are related to each other via the Miura map. In\nparticular, we focus on how their resurgent properties can be translated into\neach other. We study the special solutions of the inhomogeneous Painlev\\'e II\nequation and how these might be encoded in the transseries parameters.\nSpecifically, we have a discussion on the Hastings--McLeod solution and some\nresults on special function solutions. Finally, we discuss our results in the\ncontext of the matrix model and the (2,4)-minimal superstring theory.",
            "author": [
                "Roberto Vega"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03103v1",
                "http://arxiv.org/pdf/2311.03103v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math-ph",
                "math.MP",
                "nlin.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03099v1",
            "title": "Language Models are Super Mario: Absorbing Abilities from Homologous\n  Models as a Free Lunch",
            "updated": "2023-11-06T13:43:07Z",
            "published": "2023-11-06T13:43:07Z",
            "summary": "In this paper, we uncover that Language Models (LMs), either encoder- or\ndecoder-based, can obtain new capabilities by assimilating the parameters of\nhomologous models without retraining or GPUs. Typically, new abilities of LMs\ncan be imparted by Supervised Fine-Tuning (SFT), reflected in the disparity\nbetween fine-tuned and pre-trained parameters (i.e., delta parameters). We\ninitially observe that by introducing a novel operation called DARE (Drop And\nREscale), most delta parameters can be directly set to zeros without affecting\nthe capabilities of SFT LMs and larger models can tolerate a higher proportion\nof discarded parameters. Based on this observation, we further sparsify delta\nparameters of multiple SFT homologous models with DARE and subsequently merge\nthem into a single model by parameter averaging. We conduct experiments on\neight datasets from the GLUE benchmark with BERT and RoBERTa. We also merge\nWizardLM, WizardMath, and Code Alpaca based on Llama 2. Experimental results\nshow that: (1) The delta parameter value ranges for SFT models are typically\nsmall, often within 0.005, and DARE can eliminate 99% of them effortlessly.\nHowever, once the models are continuously pre-trained, the value ranges can\ngrow to around 0.03, making DARE impractical. We have also tried to remove\nfine-tuned instead of delta parameters and find that a 10% reduction can lead\nto drastically decreased performance (even to 0). This highlights that SFT\nmerely stimulates the abilities via delta parameters rather than injecting new\nabilities into LMs; (2) DARE can merge multiple task-specific LMs into one LM\nwith diverse abilities. For instance, the merger of WizardLM and WizardMath\nimproves the GSM8K zero-shot accuracy of WizardLM from 2.2 to 66.3, retaining\nits instruction-following ability while surpassing WizardMath's original 64.2\nperformance. Codes are available at https://github.com/yule-BUAA/MergeLM.",
            "author": [
                "Le Yu",
                "Bowen Yu",
                "Haiyang Yu",
                "Fei Huang",
                "Yongbin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03099v1",
                "http://arxiv.org/pdf/2311.03099v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03097v1",
            "title": "Quantum-Error-Mitigated Detectable Byzantine Agreement with Dynamical\n  Decoupling for Distributed Quantum Computing",
            "updated": "2023-11-06T13:39:26Z",
            "published": "2023-11-06T13:39:26Z",
            "summary": "In the burgeoning domain of distributed quantum computing, achieving\nconsensus amidst adversarial settings remains a pivotal challenge. We introduce\nan enhancement to the Quantum Byzantine Agreement (QBA) protocol, uniquely\nincorporating advanced error mitigation techniques: Twirled Readout Error\nExtinction (T-REx) and dynamical decoupling (DD). Central to this refined\napproach is the utilization of a Noisy Intermediate Scale Quantum (NISQ) source\ndevice for heightened performance. Extensive tests on both simulated and\nreal-world quantum devices, notably IBM's quantum computer, provide compelling\nevidence of the effectiveness of our T-REx and DD adaptations in mitigating\nprevalent quantum channel errors.\n  Subsequent to the entanglement distribution, our protocol adopts a\nverification method reminiscent of Quantum Key Distribution (QKD) schemes. The\nCommander then issues orders encoded in specific quantum states, like Retreat\nor Attack. In situations where received orders diverge, lieutenants engage in\nstructured games to reconcile discrepancies. Notably, the frequency of these\ngames is contingent upon the Commander's strategies and the overall network\nsize. Our empirical findings underscore the enhanced resilience and\neffectiveness of the protocol in diverse scenarios. Nonetheless, scalability\nemerges as a concern with the growth of the network size. To sum up, our\nresearch illuminates the considerable potential of fortified quantum consensus\nsystems in the NISQ era, highlighting the imperative for sustained research in\nbolstering quantum ecosystems.",
            "author": [
                "Matthew Prest",
                "Kuan-Cheng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03097v1",
                "http://arxiv.org/pdf/2311.03097v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03095v1",
            "title": "A Reduced Ideal MHD System for Nonlinear Magnetic Field Turbulence in\n  Plasmas with Approximate Flux Surfaces",
            "updated": "2023-11-06T13:37:05Z",
            "published": "2023-11-06T13:37:05Z",
            "summary": "This paper studies the nonlinear evolution of magnetic field turbulence in\nproximity of steady ideal MHD configurations characterized by a small electric\ncurrent, a small plasma flow, and approximate flux surfaces, a physical setting\nthat is relevant for plasma confinement in stellarators. The aim is to gather\ninsight on magnetic field dynamics, to elucidate accessibility and stability of\nthree-dimensional MHD equilibria, as well as to formulate practical methods to\ncompute them. Starting from the ideal MHD equations, a reduced dynamical system\nof two coupled nonlinear PDEs for the flux function and the angle variable\nassociated with the Clebsch representation of the magnetic field is obtained.\nIt is shown that under suitable boundary and gauge conditions such reduced\nsystem preserves magnetic energy, magnetic helicity, and total magnetic flux.\nThe noncanonical Hamiltonian structure of the reduced system is identified, and\nused to show the nonlinear stability of steady solutions against perturbations\ninvolving only one Clebsch potential. The Hamiltonian structure is also applied\nto construct a dissipative dynamical system through the method of double\nbrackets. This dissipative system enables the computation of MHD equilibria by\nminimizing energy until a critical point of the Hamiltonian is reached.\nFinally, an iterative scheme based on the alternate solution of the two steady\nequations in the reduced system is proposed as a further method to compute MHD\nequilibria. A theorem is proven which states that the iterative scheme\nconverges to a nontrivial MHD equilbrium as long as solutions exist at each\nstep of the iteration.",
            "author": [
                "Naoki Sato",
                "Michio Yamada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03095v1",
                "http://arxiv.org/pdf/2311.03095v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03092v1",
            "title": "We will DAG you",
            "updated": "2023-11-06T13:32:24Z",
            "published": "2023-11-06T13:32:24Z",
            "summary": "DAG-based protocols have been proposed as potential solutions to the latency\nand throughput limitations of traditional permissionless consensus protocols.\nHowever, their adoption has been hindered by security concerns and a lack of a\nsolid foundation to guarantee improvements in both throughput and latency. In\nthis paper, we present a construction that rigorously demonstrates how\nDAG-based protocols can achieve superior throughput and latency compared to\nchain-based consensus protocols, all while maintaining the same level of\nsecurity guarantees.",
            "author": [
                "Ignacio Amores-Sesar",
                "Christian Cachin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03092v1",
                "http://arxiv.org/pdf/2311.03092v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03087v1",
            "title": "Persistent homology for high-dimensional data based on spectral methods",
            "updated": "2023-11-06T13:18:08Z",
            "published": "2023-11-06T13:18:08Z",
            "summary": "Persistent homology is a popular computational tool for detecting non-trivial\ntopology of point clouds, such as the presence of loops or voids. However, many\nreal-world datasets with low intrinsic dimensionality reside in an ambient\nspace of much higher dimensionality. We show that in this case vanilla\npersistent homology becomes very sensitive to noise and fails to detect the\ncorrect topology. The same holds true for most existing refinements of\npersistent homology. As a remedy, we find that spectral distances on the\n$k$-nearest-neighbor graph of the data, such as diffusion distance and\neffective resistance, allow persistent homology to detect the correct topology\neven in the presence of high-dimensional noise. Furthermore, we derive a novel\nclosed-form expression for effective resistance in terms of the\neigendecomposition of the graph Laplacian, and describe its relation to\ndiffusion distances. Finally, we apply these methods to several\nhigh-dimensional single-cell RNA-sequencing datasets and show that spectral\ndistances on the $k$-nearest-neighbor graph allow robust detection of cell\ncycle loops.",
            "author": [
                "Sebastian Damrich",
                "Philipp Berens",
                "Dmitry Kobak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03087v1",
                "http://arxiv.org/pdf/2311.03087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03084v2",
            "title": "A Simple yet Efficient Ensemble Approach for AI-generated Text Detection",
            "updated": "2023-11-08T04:28:57Z",
            "published": "2023-11-06T13:11:02Z",
            "summary": "Recent Large Language Models (LLMs) have demonstrated remarkable capabilities\nin generating text that closely resembles human writing across wide range of\nstyles and genres. However, such capabilities are prone to potential abuse,\nsuch as fake news generation, spam email creation, and misuse in academic\nassignments. Hence, it is essential to build automated approaches capable of\ndistinguishing between artificially generated text and human-authored text. In\nthis paper, we propose a simple yet efficient solution to this problem by\nensembling predictions from multiple constituent LLMs. Compared to previous\nstate-of-the-art approaches, which are perplexity-based or uses ensembles with\na number of LLMs, our condensed ensembling approach uses only two constituent\nLLMs to achieve comparable performance. Experiments conducted on four benchmark\ndatasets for generative text classification show performance improvements in\nthe range of 0.5 to 100\\% compared to previous state-of-the-art approaches. We\nalso study the influence that the training data from individual LLMs have on\nmodel performance. We found that substituting commercially-restrictive\nGenerative Pre-trained Transformer (GPT) data with data generated from other\nopen language models such as Falcon, Large Language Model Meta AI (LLaMA2), and\nMosaic Pretrained Transformers (MPT) is a feasible alternative when developing\ngenerative text detectors. Furthermore, to demonstrate zero-shot\ngeneralization, we experimented with an English essays dataset, and results\nsuggest that our ensembling approach can handle new data effectively.",
            "author": [
                "Harika Abburi",
                "Kalyani Roy",
                "Michael Suesserman",
                "Nirmala Pudota",
                "Balaji Veeramani",
                "Edward Bowen",
                "Sanmitra Bhattacharya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03084v2",
                "http://arxiv.org/pdf/2311.03084v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03083v1",
            "title": "Quantifying the value of information transfer in population-based SHM",
            "updated": "2023-11-06T13:10:38Z",
            "published": "2023-11-06T13:10:38Z",
            "summary": "Population-based structural health monitoring (PBSHM), seeks to address some\nof the limitations associated with data scarcity that arise in traditional SHM.\nA tenet of the population-based approach to SHM is that information can be\nshared between sufficiently-similar structures in order to improve predictive\nmodels. Transfer learning techniques, such as domain adaptation, have been\nshown to be a highly-useful technology for sharing information between\nstructures when developing statistical classifiers for PBSHM. Nonetheless,\ntransfer-learning techniques are not without their pitfalls. In some\ncircumstances, for example if the data distributions associated with the\nstructures within a population are dissimilar, applying transfer-learning\nmethods can be detrimental to classification performance -- this phenomenon is\nknown as negative transfer. Given the potentially-severe consequences of\nnegative transfer, it is prudent for engineers to ask the question `when, what,\nand how should one transfer between structures?'.\n  The current paper aims to demonstrate a transfer-strategy decision process\nfor a classification task for a population of simulated structures in the\ncontext of a representative SHM maintenance problem, supported by domain\nadaptation. The transfer decision framework is based upon the concept of\nexpected value of information transfer. In order to compute the expected value\nof information transfer, predictions must be made regarding the classification\n(and decision performance) in the target domain following information transfer.\nIn order to forecast the outcome of transfers, a probabilistic regression is\nused here to predict classification performance from a proxy for structural\nsimilarity based on the modal assurance criterion.",
            "author": [
                "Aidan J. Hughes",
                "Jack Poole",
                "Nikolaos Dervilis",
                "Paul Gardner",
                "Keith Worden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03083v1",
                "http://arxiv.org/pdf/2311.03083v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03082v1",
            "title": "A survey and classification of face alignment methods based on face\n  models",
            "updated": "2023-11-06T13:09:04Z",
            "published": "2023-11-06T13:09:04Z",
            "summary": "A face model is a mathematical representation of the distinct features of a\nhuman face. Traditionally, face models were built using a set of fiducial\npoints or landmarks, each point ideally located on a facial feature, i.e.,\ncorner of the eye, tip of the nose, etc. Face alignment is the process of\nfitting the landmarks in a face model to the respective ground truth positions\nin an input image containing a face. Despite significant research on face\nalignment in the past decades, no review analyses various face models used in\nthe literature. Catering to three types of readers - beginners, practitioners\nand researchers in face alignment, we provide a comprehensive analysis of\ndifferent face models used for face alignment. We include the interpretation\nand training of the face models along with the examples of fitting the face\nmodel to a new face image. We found that 3D-based face models are preferred in\ncases of extreme face pose, whereas deep learning-based methods often use\nheatmaps. Moreover, we discuss the possible future directions of face models in\nthe field of face alignment.",
            "author": [
                "Jagmohan Meher",
                "Hector Allende-Cid",
                "Torbj\u00f6rn E. M. Nordling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03082v1",
                "http://arxiv.org/pdf/2311.03082v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03079v1",
            "title": "CogVLM: Visual Expert for Pretrained Language Models",
            "updated": "2023-11-06T13:04:39Z",
            "published": "2023-11-06T13:04:39Z",
            "summary": "We introduce CogVLM, a powerful open-source visual language foundation model.\nDifferent from the popular shallow alignment method which maps image features\ninto the input space of language model, CogVLM bridges the gap between the\nfrozen pretrained language model and image encoder by a trainable visual expert\nmodule in the attention and FFN layers. As a result, CogVLM enables deep fusion\nof vision language features without sacrificing any performance on NLP tasks.\nCogVLM-17B achieves state-of-the-art performance on 10 classic cross-modal\nbenchmarks, including NoCaps, Flicker30k captioning, RefCOCO, RefCOCO+,\nRefCOCOg, Visual7W, GQA, ScienceQA, VizWiz VQA and TDIUC, and ranks the 2nd on\nVQAv2, OKVQA, TextVQA, COCO captioning, etc., surpassing or matching PaLI-X\n55B. Codes and checkpoints are available at https://github.com/THUDM/CogVLM.",
            "author": [
                "Weihan Wang",
                "Qingsong Lv",
                "Wenmeng Yu",
                "Wenyi Hong",
                "Ji Qi",
                "Yan Wang",
                "Junhui Ji",
                "Zhuoyi Yang",
                "Lei Zhao",
                "Xixuan Song",
                "Jiazheng Xu",
                "Bin Xu",
                "Juanzi Li",
                "Yuxiao Dong",
                "Ming Ding",
                "Jie Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03079v1",
                "http://arxiv.org/pdf/2311.03079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03078v1",
            "title": "BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla\n  Lemmatizer",
            "updated": "2023-11-06T13:02:07Z",
            "published": "2023-11-06T13:02:07Z",
            "summary": "Lemmatization holds significance in both natural language processing (NLP)\nand linguistics, as it effectively decreases data density and aids in\ncomprehending contextual meaning. However, due to the highly inflected nature\nand morphological richness, lemmatization in Bangla text poses a complex\nchallenge. In this study, we propose linguistic rules for lemmatization and\nutilize a dictionary along with the rules to design a lemmatizer specifically\nfor Bangla. Our system aims to lemmatize words based on their parts of speech\nclass within a given sentence. Unlike previous rule-based approaches, we\nanalyzed the suffix marker occurrence according to the morpho-syntactic values\nand then utilized sequences of suffix markers instead of entire suffixes. To\ndevelop our rules, we analyze a large corpus of Bangla text from various\ndomains, sources, and time periods to observe the word formation of inflected\nwords. The lemmatizer achieves an accuracy of 96.36% when tested against a\nmanually annotated test dataset by trained linguists and demonstrates\ncompetitive performance on three previously published Bangla lemmatization\ndatasets. We are making the code and datasets publicly available at\nhttps://github.com/eblict-gigatech/BanLemma in order to contribute to the\nfurther advancement of Bangla NLP.",
            "author": [
                "Sadia Afrin",
                "Md. Shahad Mahmud Chowdhury",
                "Md. Ekramul Islam",
                "Faisal Ahamed Khan",
                "Labib Imam Chowdhury",
                "MD. Motahar Mahtab",
                "Nazifa Nuha Chowdhury",
                "Massud Forkan",
                "Neelima Kundu",
                "Hakim Arif",
                "Mohammad Mamun Or Rashid",
                "Mohammad Ruhul Amin",
                "Nabeel Mohammed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03078v1",
                "http://arxiv.org/pdf/2311.03078v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03077v1",
            "title": "Symplectic K-theory and a problem of Murthy",
            "updated": "2023-11-06T13:02:02Z",
            "published": "2023-11-06T13:02:02Z",
            "summary": "We compute low-dimensional K-groups of certain rings associated with the\nstudy of the Hermite ring conjecture. This includes a monoid ring whose\nlow-dimensional K-groups were recently computed by Krishna and Sarwar in the\ncase where the base ring is a regular ring containing the rationals. We are\nable to extend their result to an arbitrary regular base ring, thereby\ncompleting an answer to a question of Gubeladze. Our computation only relies on\ncertain conveniently chosen analytic patching diagrams.\n  These patching diagrams also allow us to investigate stably free modules\nappearing in a problem posed by Murthy. They make it possible to relate\nMurthy's problem to a stable question (about the relationship between\nsymplectic and ordinary K-theory). More precisely, we show that Murthy's\nproblem has a solution if the stable question has an affirmative answer, while\na negative answer to the stable question implies that there are counterexamples\nto the Hermite ring conjecture.\n  Since the module appearing in Murthy's problem has rank 2, the above\nmentioned argument relies on some theorems about patching with 2-by-2 matrices.\nThese use so-called pseudoelementary 2-by-2 matrices, a notion we introduce\nwhich makes it possible to extend certain results valid for larger matrices to\nthe case of 2-by-2 matrices (if we use pseudoelementary instead of elementary\nmatrices). For example, we prove that the analogue of Vorst's theorem about\nmatrices over polynomial extensions over a regular ring containing a field\nholds for 2-by-2 matrices.",
            "author": [
                "Daniel Sch\u00e4ppi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03077v1",
                "http://arxiv.org/pdf/2311.03077v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.KT",
                "13C10, 13B40, 19A13, 19B99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03076v2",
            "title": "SugarViT -- Multi-objective Regression of UAV Images with Vision\n  Transformers and Deep Label Distribution Learning Demonstrated on Disease\n  Severity Prediction in Sugar Beet",
            "updated": "2023-11-07T08:43:19Z",
            "published": "2023-11-06T13:01:17Z",
            "summary": "Remote sensing and artificial intelligence are pivotal technologies of\nprecision agriculture nowadays. The efficient retrieval of large-scale field\nimagery combined with machine learning techniques shows success in various\ntasks like phenotyping, weeding, cropping, and disease control. This work will\nintroduce a machine learning framework for automatized large-scale\nplant-specific trait annotation for the use case disease severity scoring for\nCercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label\nDistribution Learning (DLDL), special loss functions, and a tailored model\narchitecture, we develop an efficient Vision Transformer based model for\ndisease severity scoring called SugarViT. One novelty in this work is the\ncombination of remote sensing data with environmental parameters of the\nexperimental sites for disease severity prediction. Although the model is\nevaluated on this special use case, it is held as generic as possible to also\nbe applicable to various image-based classification and regression tasks. With\nour framework, it is even possible to learn models on multi-objective problems\nas we show by a pretraining on environmental metadata.",
            "author": [
                "Maurice G\u00fcnder",
                "Facundo Ram\u00f3n Ispizua Yamati",
                "Abel Andree Barreto Alc\u00e1ntara",
                "Anne-Katrin Mahlein",
                "Rafet Sifa",
                "Christian Bauckhage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03076v2",
                "http://arxiv.org/pdf/2311.03076v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03074v1",
            "title": "A Two-Stage Generative Model with CycleGAN and Joint Diffusion for\n  MRI-based Brain Tumor Detection",
            "updated": "2023-11-06T12:58:26Z",
            "published": "2023-11-06T12:58:26Z",
            "summary": "Accurate detection and segmentation of brain tumors is critical for medical\ndiagnosis. However, current supervised learning methods require extensively\nannotated images and the state-of-the-art generative models used in\nunsupervised methods often have limitations in covering the whole data\ndistribution. In this paper, we propose a novel framework Two-Stage Generative\nModel (TSGM) that combines Cycle Generative Adversarial Network (CycleGAN) and\nVariance Exploding stochastic differential equation using joint probability\n(VE-JP) to improve brain tumor detection and segmentation. The CycleGAN is\ntrained on unpaired data to generate abnormal images from healthy images as\ndata prior. Then VE-JP is implemented to reconstruct healthy images using\nsynthetic paired abnormal images as a guide, which alters only pathological\nregions but not regions of healthy. Notably, our method directly learned the\njoint probability distribution for conditional generation. The residual between\ninput and reconstructed images suggests the abnormalities and a thresholding\nmethod is subsequently applied to obtain segmentation results. Furthermore, the\nmultimodal results are weighted with different weights to improve the\nsegmentation accuracy further. We validated our method on three datasets, and\ncompared with other unsupervised methods for anomaly detection and\nsegmentation. The DSC score of 0.8590 in BraTs2020 dataset, 0.6226 in ITCS\ndataset and 0.7403 in In-house dataset show that our method achieves better\nsegmentation performance and has better generalization.",
            "author": [
                "Wenxin Wang",
                "Zhuo-Xu Cui",
                "Guanxun Cheng",
                "Chentao Cao",
                "Xi Xu",
                "Ziwei Liu",
                "Haifeng Wang",
                "Yulong Qi",
                "Dong Liang",
                "Yanjie Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03074v1",
                "http://arxiv.org/pdf/2311.03074v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03071v2",
            "title": "OrthoNets: Orthogonal Channel Attention Networks",
            "updated": "2023-11-07T02:23:30Z",
            "published": "2023-11-06T12:54:20Z",
            "summary": "Designing an effective channel attention mechanism implores one to find a\nlossy-compression method allowing for optimal feature representation. Despite\nrecent progress in the area, it remains an open problem. FcaNet, the current\nstate-of-the-art channel attention mechanism, attempted to find such an\ninformation-rich compression using Discrete Cosine Transforms (DCTs). One\ndrawback of FcaNet is that there is no natural choice of the DCT frequencies.\nTo circumvent this issue, FcaNet experimented on ImageNet to find optimal\nfrequencies. We hypothesize that the choice of frequency plays only a\nsupporting role and the primary driving force for the effectiveness of their\nattention filters is the orthogonality of the DCT kernels. To test this\nhypothesis, we construct an attention mechanism using randomly initialized\northogonal filters. Integrating this mechanism into ResNet, we create OrthoNet.\nWe compare OrthoNet to FcaNet (and other attention mechanisms) on Birds,\nMS-COCO, and Places356 and show superior performance. On the ImageNet dataset,\nour method competes with or surpasses the current state-of-the-art. Our results\nimply that an optimal choice of filter is elusive and generalization can be\nachieved with a sufficiently large number of orthogonal filters. We further\ninvestigate other general principles for implementing channel attention, such\nas its position in the network and channel groupings. Our code is publicly\navailable at https://github.com/hady1011/OrthoNets/",
            "author": [
                "Hadi Salman",
                "Caleb Parks",
                "Matthew Swan",
                "John Gauch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03071v2",
                "http://arxiv.org/pdf/2311.03071v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03067v1",
            "title": "Forest aboveground biomass estimation using GEDI and earth observation\n  data through attention-based deep learning",
            "updated": "2023-11-06T12:51:01Z",
            "published": "2023-11-06T12:51:01Z",
            "summary": "Accurate quantification of forest aboveground biomass (AGB) is critical for\nunderstanding carbon accounting in the context of climate change. In this\nstudy, we presented a novel attention-based deep learning approach for forest\nAGB estimation, primarily utilizing openly accessible EO data, including: GEDI\nLiDAR data, C-band Sentinel-1 SAR data, ALOS-2 PALSAR-2 data, and Sentinel-2\nmultispectral data. The attention UNet (AU) model achieved markedly higher\naccuracy for biomass estimation compared to the conventional RF algorithm.\nSpecifically, the AU model attained an R2 of 0.66, RMSE of 43.66 Mg ha-1, and\nbias of 0.14 Mg ha-1, while RF resulted in lower scores of R2 0.62, RMSE 45.87\nMg ha-1, and bias 1.09 Mg ha-1. However, the superiority of the deep learning\napproach was not uniformly observed across all tested models. ResNet101 only\nachieved an R2 of 0.50, an RMSE of 52.93 Mg ha-1, and a bias of 0.99 Mg ha-1,\nwhile the UNet reported an R2 of 0.65, an RMSE of 44.28 Mg ha-1, and a\nsubstantial bias of 1.84 Mg ha-1. Moreover, to explore the performance of AU in\nthe absence of spatial information, fully connected (FC) layers were employed\nto eliminate spatial information from the remote sensing data. AU-FC achieved\nintermediate R2 of 0.64, RMSE of 44.92 Mgha-1, and bias of -0.56 Mg ha-1,\noutperforming RF but underperforming AU model using spatial information. We\nalso generated 10m forest AGB maps across Guangdong for the year 2019 using AU\nand compared it with that produced by RF. The AGB distributions from both\nmodels showed strong agreement with similar mean values; the mean forest AGB\nestimated by AU was 102.18 Mg ha-1 while that of RF was 104.84 Mg ha-1.\nAdditionally, it was observed that the AGB map generated by AU provided\nsuperior spatial information. Overall, this research substantiates the\nfeasibility of employing deep learning for biomass estimation based on\nsatellite data.",
            "author": [
                "Wenquan Dong",
                "Edward T. A. Mitchard",
                "Hao Yu",
                "Steven Hancock",
                "Casey M. Ryan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03067v1",
                "http://arxiv.org/pdf/2311.03067v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03065v1",
            "title": "Statistical analysis of vortex condensate motion in two-dimensional\n  turbulence",
            "updated": "2023-11-06T12:50:10Z",
            "published": "2023-11-06T12:50:10Z",
            "summary": "An inverse turbulent cascade in a periodic square box produces a coherent\nsystem-sized vortex dipole. We study the statistics of its motion by carrying\nout direct numerical simulations performed for various bottom friction\n$\\alpha$, pumping intensity $\\varepsilon$, and fluid hyperviscosity $\\nu$. In\nthe main approximation, coherent vortices can be considered as point vortices,\nand within this model, they drift at the same dipole velocity, which is\ndetermined by their circulation and mutual arrangement. The characteristic\nvalue of the dipole velocity is more than an order of magnitude smaller than\nthe polar velocity inside coherent vortices. Turbulent fluctuations give rise\nto a relative velocity between the vortices, which changes the distance between\nthem. We found that for a strong condensate, the probability density function\nof the vector $\\bf \\rho$, describing the difference in the mutual arrangement\nof coherent vortices from half the diagonal of the computational domain, has\nthe form of a ring. The radius of the ring weakly depends on control parameters\nand the width of the ring is proportional to the dimensionless parameter\n$\\delta = \\epsilon^{-1/3} L^{2/3} \\alpha$, where $\\epsilon$ is the inverse\nenergy flux and $L$ is the system size. The random walk around the ring, caused\nby turbulent fluctuations, has superdiffusion behavior at intermediate times.\nIt results in a finite correlation time of the dipole velocity, which turns out\nto be of the order of turnover time $\\tau_K = L^{2/3} \\epsilon^{-1/3}$ of\nsystem-size eddies produced by an inverse turbulent cascade. The results\nobtained deepen the understanding of the processes governing the motion of\ncoherent vortices.",
            "author": [
                "Vladimir Parfenyev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03065v1",
                "http://arxiv.org/pdf/2311.03065v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03063v1",
            "title": "Multi-Step Optimal Tracking Control of Unknown Nonzero-Sum Games based\n  on Least Squares and Linear Programming: An Application to a Fully-Automated,\n  Dual-Hormone Artificial Pancreas",
            "updated": "2023-11-06T12:47:34Z",
            "published": "2023-11-06T12:47:34Z",
            "summary": "We consider the problem of optimal tracking control of unknown discrete-time\nnonlinear nonzero-sum games. The related state-of-art literature is mostly\nfocused on Policy Iteration algorithms and multiple neural network\napproximation, which may lead to practical implementation challenges and high\ncomputational burden. To overcome these problems, we propose a novel\nQ-function-based multi-step Value Iteration algorithm, which provides the\npotential to accelerate convergence speed and improve the quality of solutions,\nwith an easy-to-realize initialization condition. A critic-only least squares\nimplementation approach is then employed, which alleviates the computational\ncomplexity of commonly used multiple neural network-based methods. Afterwards,\nby introducing the coupled Bellman operator, a novel linear programming\napproach is derived, based on which Nash equilibria can be approximately\ncomputed by solving a set of tractable finite-dimensional optimization\nproblems. We evaluate the tracking control capabilities of the proposed\nalgorithms to the problem of fully-automated dual-hormone (i.e., insulin and\nglucagon) glucose control in Type 1 Diabetes Mellitus. The U.S. FDA-accepted\nDMMS.R simulator from the Epsilon Group is used to conduct extensive in-silico\nclinical studies on virtual patients under a variety of completely unannounced\nmeal and exercise scenarios. Simulation results demonstrate the high\nreliability and exceptional performance of the proposed multi-step algorithmic\nframework to critical complex systems.",
            "author": [
                "Alexandros Tanzanakis",
                "John Lygeros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03063v1",
                "http://arxiv.org/pdf/2311.03063v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03062v2",
            "title": "Imaging through multimode fibres with physical prior",
            "updated": "2023-11-14T02:00:20Z",
            "published": "2023-11-06T12:46:29Z",
            "summary": "Imaging through perturbed multimode fibres based on deep learning has been\nwidely researched. However, existing methods mainly use target-speckle pairs in\ndifferent configurations. It is challenging to reconstruct targets without\ntrained networks. In this paper, we propose a physics-assisted, unsupervised,\nlearning-based fibre imaging scheme. The role of the physical prior is to\nsimplify the mapping relationship between the speckle pattern and the target\nimage, thereby reducing the computational complexity. The unsupervised network\nlearns target features according to the optimized direction provided by the\nphysical prior. Therefore, the reconstruction process of the online learning\nonly requires a few speckle patterns and unpaired targets. The proposed scheme\nalso increases the generalization ability of the learning-based method in\nperturbed multimode fibres. Our scheme has the potential to extend the\napplication of multimode fibre imaging.",
            "author": [
                "Chuncheng Zhang",
                "Yingjie Shi",
                "Zheyi Yao",
                "Xiubao Sui",
                "Qian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03062v2",
                "http://arxiv.org/pdf/2311.03062v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03059v1",
            "title": "Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations",
            "updated": "2023-11-06T12:41:21Z",
            "published": "2023-11-06T12:41:21Z",
            "summary": "In this article, we study the inconsistency of a system of $\\max-T$ fuzzy\nrelational equations of the form $A \\Box_{T}^{\\max} x = b$, where $T$ is a\nt-norm among $\\min$, the product or Lukasiewicz's t-norm. For an inconsistent\n$\\max-T$ system, we directly construct a canonical maximal consistent subsystem\n(w.r.t the inclusion order). The main tool used to obtain it is the analytical\nformula which compute the Chebyshev distance $\\Delta = \\inf_{c \\in \\mathcal{C}}\n\\Vert b - c \\Vert$ associated to the inconsistent $\\max-T$ system, where\n$\\mathcal{C}$ is the set of second members of consistent systems defined with\nthe same matrix $A$. Based on the same analytical formula, we give, for an\ninconsistent $\\max-\\min$ system, an efficient method to obtain all its\nconsistent subsystems, and we show how to iteratively get all its maximal\nconsistent subsystems.",
            "author": [
                "Isma\u00efl Baaj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03059v1",
                "http://arxiv.org/pdf/2311.03059v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03058v1",
            "title": "Zero-shot Bilingual App Reviews Mining with Large Language Models",
            "updated": "2023-11-06T12:36:46Z",
            "published": "2023-11-06T12:36:46Z",
            "summary": "App reviews from app stores are crucial for improving software requirements.\nA large number of valuable reviews are continually being posted, describing\nsoftware problems and expected features. Effectively utilizing user reviews\nnecessitates the extraction of relevant information, as well as their\nsubsequent summarization. Due to the substantial volume of user reviews, manual\nanalysis is arduous. Various approaches based on natural language processing\n(NLP) have been proposed for automatic user review mining. However, the\nmajority of them requires a manually crafted dataset to train their models,\nwhich limits their usage in real-world scenarios. In this work, we propose\nMini-BAR, a tool that integrates large language models (LLMs) to perform\nzero-shot mining of user reviews in both English and French. Specifically,\nMini-BAR is designed to (i) classify the user reviews, (ii) cluster similar\nreviews together, (iii) generate an abstractive summary for each cluster and\n(iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we\ncreated a dataset containing 6,000 English and 6,000 French annotated user\nreviews and conducted extensive experiments. Preliminary results demonstrate\nthe effectiveness and efficiency of Mini-BAR in requirement engineering by\nanalyzing bilingual app reviews. (Replication package containing the code,\ndataset, and experiment setups on https://github.com/Jl-wei/mini-bar )",
            "author": [
                "Jialiang Wei",
                "Anne-Lise Courbis",
                "Thomas Lambolais",
                "Binbin Xu",
                "Pierre Louis Bernard",
                "G\u00e9rard Dray"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03058v1",
                "http://arxiv.org/pdf/2311.03058v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03419v1",
            "title": "Personalizing Keyword Spotting with Speaker Information",
            "updated": "2023-11-06T12:16:06Z",
            "published": "2023-11-06T12:16:06Z",
            "summary": "Keyword spotting systems often struggle to generalize to a diverse population\nwith various accents and age groups. To address this challenge, we propose a\nnovel approach that integrates speaker information into keyword spotting using\nFeature-wise Linear Modulation (FiLM), a recent method for learning from\nmultiple sources of information. We explore both Text-Dependent and\nText-Independent speaker recognition systems to extract speaker information,\nand we experiment on extracting this information from both the input audio and\npre-enrolled user audio. We evaluate our systems on a diverse dataset and\nachieve a substantial improvement in keyword detection accuracy, particularly\namong underrepresented speaker groups. Moreover, our proposed approach only\nrequires a small 1% increase in the number of parameters, with a minimum impact\non latency and computational cost, which makes it a practical solution for\nreal-world applications.",
            "author": [
                "Beltr\u00e1n Labrador",
                "Pai Zhu",
                "Guanlong Zhao",
                "Angelo Scorza Scarpati",
                "Quan Wang",
                "Alicia Lozano-Diez",
                "Alex Park",
                "Ignacio L\u00f3pez Moreno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03419v1",
                "http://arxiv.org/pdf/2311.03419v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03054v3",
            "title": "AnyText: Multilingual Visual Text Generation And Editing",
            "updated": "2023-11-30T12:54:05Z",
            "published": "2023-11-06T12:10:43Z",
            "summary": "Diffusion model based Text-to-Image has achieved impressive achievements\nrecently. Although current technology for synthesizing images is highly\nadvanced and capable of generating images with high fidelity, it is still\npossible to give the show away when focusing on the text area in the generated\nimage. To address this issue, we introduce AnyText, a diffusion-based\nmultilingual visual text generation and editing model, that focuses on\nrendering accurate and coherent text in the image. AnyText comprises a\ndiffusion pipeline with two primary elements: an auxiliary latent module and a\ntext embedding module. The former uses inputs like text glyph, position, and\nmasked image to generate latent features for text generation or editing. The\nlatter employs an OCR model for encoding stroke data as embeddings, which blend\nwith image caption embeddings from the tokenizer to generate texts that\nseamlessly integrate with the background. We employed text-control diffusion\nloss and text perceptual loss for training to further enhance writing accuracy.\nAnyText can write characters in multiple languages, to the best of our\nknowledge, this is the first work to address multilingual visual text\ngeneration. It is worth mentioning that AnyText can be plugged into existing\ndiffusion models from the community for rendering or editing text accurately.\nAfter conducting extensive evaluation experiments, our method has outperformed\nall other approaches by a significant margin. Additionally, we contribute the\nfirst large-scale multilingual text images dataset, AnyWord-3M, containing 3\nmillion image-text pairs with OCR annotations in multiple languages. Based on\nAnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual\ntext generation accuracy and quality. Our project will be open-sourced on\nhttps://github.com/tyxsspa/AnyText to improve and promote the development of\ntext generation technology.",
            "author": [
                "Yuxiang Tuo",
                "Wangmeng Xiang",
                "Jun-Yan He",
                "Yifeng Geng",
                "Xuansong Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03054v3",
                "http://arxiv.org/pdf/2311.03054v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03053v1",
            "title": "Masking Hyperspectral Imaging Data with Pretrained Models",
            "updated": "2023-11-06T12:08:35Z",
            "published": "2023-11-06T12:08:35Z",
            "summary": "The presence of undesired background areas associated with potential noise\nand unknown spectral characteristics degrades the performance of hyperspectral\ndata processing. Masking out unwanted regions is key to addressing this issue.\nProcessing only regions of interest yields notable improvements in terms of\ncomputational costs, required memory, and overall performance. The proposed\nprocessing pipeline encompasses two fundamental parts: regions of interest mask\ngeneration, followed by the application of hyperspectral data processing\ntechniques solely on the newly masked hyperspectral cube. The novelty of our\nwork lies in the methodology adopted for the preliminary image segmentation. We\nemploy the Segment Anything Model (SAM) to extract all objects within the\ndataset, and subsequently refine the segments with a zero-shot Grounding Dino\nobject detector, followed by intersection and exclusion filtering steps,\nwithout the need for fine-tuning or retraining. To illustrate the efficacy of\nthe masking procedure, the proposed method is deployed on three challenging\napplications scenarios that demand accurate masking; shredded plastics\ncharacterization, drill core scanning, and litter monitoring. The numerical\nevaluation of the proposed masking method on the three applications is provided\nalong with the used hyperparameters. The scripts for the method will be\navailable at https://github.com/hifexplo/Masking.",
            "author": [
                "Elias Arbash",
                "Andr\u00e9a de Lima Ribeiro",
                "Sam Thiele",
                "Nina Gnann",
                "Behnood Rasti",
                "Margret Fuchs",
                "Pedram Ghamisi",
                "Richard Gloaguen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03053v1",
                "http://arxiv.org/pdf/2311.03053v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03052v1",
            "title": "MixUp-MIL: A Study on Linear & Multilinear Interpolation-Based Data\n  Augmentation for Whole Slide Image Classification",
            "updated": "2023-11-06T12:00:53Z",
            "published": "2023-11-06T12:00:53Z",
            "summary": "For classifying digital whole slide images in the absence of pixel level\nannotation, typically multiple instance learning methods are applied. Due to\nthe generic applicability, such methods are currently of very high interest in\nthe research community, however, the issue of data augmentation in this context\nis rarely explored. Here we investigate linear and multilinear interpolation\nbetween feature vectors, a data augmentation technique, which proved to be\ncapable of improving the generalization performance classification networks and\nalso for multiple instance learning. Experiments, however, have been performed\non only two rather small data sets and one specific feature extraction approach\nso far and a strong dependence on the data set has been identified. Here we\nconduct a large study incorporating 10 different data set configurations, two\ndifferent feature extraction approaches (supervised and self-supervised), stain\nnormalization and two multiple instance learning architectures. The results\nshowed an extraordinarily high variability in the effect of the method. We\nidentified several interesting aspects to bring light into the darkness and\nidentified novel promising fields of research.",
            "author": [
                "Michael Gadermayr",
                "Lukas Koller",
                "Maximilian Tschuchnig",
                "Lea Maria Stangassinger",
                "Christina Kreutzer",
                "Sebastien Couillard-Despres",
                "Gertie Janneke Oostingh",
                "Anton Hittmair"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03052v1",
                "http://arxiv.org/pdf/2311.03052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03039v2",
            "title": "Bridging the gap between agent based models and continuous opinion\n  dynamics",
            "updated": "2023-11-15T11:59:43Z",
            "published": "2023-11-06T11:20:23Z",
            "summary": "There is a rich literature on microscopic models for opinion dynamics; most\nof them fall into one of two categories - agent-based models or differential\nequation models - with a general understanding that the two are connected in\ncertain scaling limits. In this paper we show rigorously this is indeed the\ncase. In particular we show that DEMs can be obtained from ABMs by\nsimultaneously rescaling time and the distance an agent updates their opinion\nafter an interaction. This approach provides a pathway to analyse much more\ndiverse modelling paradigms, for example: the motivation behind several\npossible multiplicative noise terms in stochastic differential equation models;\nthe connection between selection noise and the mollification of the\ndiscontinuous bounded confidence interaction function; and how the method for\nselecting interacting pairs can determine the normalisation in the\ncorresponding differential equation. Our computational experiments confirm our\nfindings, showing excellent agreement of solutions to the two classes of models\nin a variety of settings.",
            "author": [
                "Andrew Nugent",
                "Susana N Gomes",
                "Marie-Therese Wolfram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03039v2",
                "http://arxiv.org/pdf/2311.03039v2"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03035v1",
            "title": "GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation",
            "updated": "2023-11-06T11:14:19Z",
            "published": "2023-11-06T11:14:19Z",
            "summary": "Vision Transformers (ViTs) have revolutionized the field of computer vision,\nyet their deployments on resource-constrained devices remain challenging due to\nhigh computational demands. To expedite pre-trained ViTs, token pruning and\ntoken merging approaches have been developed, which aim at reducing the number\nof tokens involved in the computation. However, these methods still have some\nlimitations, such as image information loss from pruned tokens and inefficiency\nin the token-matching process. In this paper, we introduce a novel Graph-based\nToken Propagation (GTP) method to resolve the challenge of balancing model\nefficiency and information preservation for efficient ViTs. Inspired by graph\nsummarization algorithms, GTP meticulously propagates less significant tokens'\ninformation to spatially and semantically connected tokens that are of greater\nimportance. Consequently, the remaining few tokens serve as a summarization of\nthe entire token graph, allowing the method to reduce computational complexity\nwhile preserving essential information of eliminated tokens. Combined with an\ninnovative token selection strategy, GTP can efficiently identify image tokens\nto be propagated. Extensive experiments have validated GTP's effectiveness,\ndemonstrating both efficiency and performance improvements. Specifically, GTP\ndecreases the computational complexity of both DeiT-S and DeiT-B by up to 26%\nwith only a minimal 0.3% accuracy drop on ImageNet-1K without finetuning, and\nremarkably surpasses the state-of-the-art token merging method on various\nbackbones at an even faster inference speed. The source code is available at\nhttps://github.com/Ackesnal/GTP-ViT.",
            "author": [
                "Xuwei Xu",
                "Sen Wang",
                "Yudong Chen",
                "Yanping Zheng",
                "Zhewei Wei",
                "Jiajun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03035v1",
                "http://arxiv.org/pdf/2311.03035v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03034v1",
            "title": "Byzantine Consensus in Abstract MAC Layer",
            "updated": "2023-11-06T11:14:01Z",
            "published": "2023-11-06T11:14:01Z",
            "summary": "This paper studies the design of Byzantine consensus algorithms in an\n\\textit{asynchronous }single-hop network equipped with the \"abstract MAC layer\"\n[DISC09], which captures core properties of modern wireless MAC protocols.\nNewport [PODC14], Newport and Robinson [DISC18], and Tseng and Zhang [PODC22]\nstudy crash-tolerant consensus in the model. In our setting, a Byzantine faulty\nnode may behave arbitrarily, but it cannot break the guarantees provided by the\nunderlying abstract MAC layer. To our knowledge, we are the first to study\nByzantine faults in this model.\n  We harness the power of the abstract MAC layer to develop a Byzantine\napproximate consensus algorithm and a Byzantine randomized binary consensus\nalgorithm. Both of our algorithms require \\textit{only} the knowledge of the\nupper bound on the number of faulty nodes $f$, and do \\textit{not} require the\nknowledge of the number of nodes $n$. This demonstrates the \"power\" of the\nabstract MAC layer, as consensus algorithms in traditional message-passing\nmodels require the knowledge of \\textit{both} $n$ and $f$. Additionally, we\nshow that it is necessary to know $f$ in order to reach consensus. Hence, from\nthis perspective, our algorithms require the minimal knowledge.\n  The lack of knowledge of $n$ brings the challenge of identifying a quorum\nexplicitly, which is a common technique in traditional message-passing\nalgorithms. A key technical novelty of our algorithms is to identify \"implicit\nquorums\" which have the necessary information for reaching consensus. The\nquorums are implicit because nodes do not know the identity of the quorums --\nsuch notion is only used in the analysis.",
            "author": [
                "Lewis Tseng",
                "Callie Sardina"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03034v1",
                "http://arxiv.org/pdf/2311.03034v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03029v1",
            "title": "Obstacle- and Occlusion-Responsive Visual Tracking Control for Redundant\n  Manipulators using Reachability Measure",
            "updated": "2023-11-06T11:07:40Z",
            "published": "2023-11-06T11:07:40Z",
            "summary": "A vision system attached to a manipulator excels at tracing a moving target\nobject while effectively handling obstacles, overcoming limitations arising\nfrom the camera's confined field of view and occluded line of sight. Meanwhile,\nthe manipulator may encounter certain challenges, including restricted motion\ndue to kinematic constraints and the risk of colliding with external obstacles.\nThese challenges are typically addressed by assigning multiple task objectives\nto the manipulator. However, doing so can cause an increased risk of driving\nthe manipulator to its kinematic limits, leading to failures in object tracking\nor obstacle avoidance. To address this issue, we propose a novel visual\ntracking control method for a redundant manipulator that takes the kinematic\nconstraints into account via a reachability measure. Our method employs an\noptimization-based controller that considers object tracking, occlusion\navoidance, collision avoidance, and the kinematic constraints represented by\nthe reachability measure. Subsequently, it determines a suitable joint\nconfiguration through real-time inverse kinematics, accounting for dynamic\nobstacle avoidance and the continuity of joint configurations. To validate our\napproach, we conducted simulations and hardware experiments involving a moving\ntarget and dynamic obstacles. The results of our evaluations highlight the\nsignificance of incorporating the reachability measure.",
            "author": [
                "Mincheul Kang",
                "Junhyoung Ha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03029v1",
                "http://arxiv.org/pdf/2311.03029v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03026v1",
            "title": "Detecting Agreement in Multi-party Conversational AI",
            "updated": "2023-11-06T11:04:39Z",
            "published": "2023-11-06T11:04:39Z",
            "summary": "Today, conversational systems are expected to handle conversations in\nmulti-party settings, especially within Socially Assistive Robots (SARs).\nHowever, practical usability remains difficult as there are additional\nchallenges to overcome, such as speaker recognition, addressee recognition, and\ncomplex turn-taking. In this paper, we present our work on a multi-party\nconversational system, which invites two users to play a trivia quiz game. The\nsystem detects users' agreement or disagreement on a final answer and responds\naccordingly. Our evaluation includes both performance and user assessment\nresults, with a focus on detecting user agreement. Our annotated transcripts\nand the code for the proposed system have been released open-source on GitHub.",
            "author": [
                "Laura Schauer",
                "Jason Sweeney",
                "Charlie Lyttle",
                "Zein Said",
                "Aron Szeles",
                "Cale Clark",
                "Katie McAskill",
                "Xander Wickham",
                "Tom Byars",
                "Daniel Hern\u00e1ndez Garcia",
                "Nancie Gunson",
                "Angus Addlesee",
                "Oliver Lemon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03026v1",
                "http://arxiv.org/pdf/2311.03026v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03021v1",
            "title": "Detecting agreement in multi-party dialogue: evaluating speaker\n  diarisation versus a procedural baseline to enhance user engagement",
            "updated": "2023-11-06T11:00:44Z",
            "published": "2023-11-06T11:00:44Z",
            "summary": "Conversational agents participating in multi-party interactions face\nsignificant challenges in dialogue state tracking, since the identity of the\nspeaker adds significant contextual meaning. It is common to utilise\ndiarisation models to identify the speaker. However, it is not clear if these\nare accurate enough to correctly identify specific conversational events such\nas agreement or disagreement during a real-time interaction. This study uses a\ncooperative quiz, where the conversational agent acts as quiz-show host, to\ndetermine whether diarisation or a frequency-and-proximity-based method is more\naccurate at determining agreement, and whether this translates to feelings of\nengagement from the players. Experimental results show that our procedural\nsystem was more engaging to players, and was more accurate at detecting\nagreement, reaching an average accuracy of 0.44 compared to 0.28 for the\ndiarised system.",
            "author": [
                "Angus Addlesee",
                "Daniel Denley",
                "Andy Edmondson",
                "Nancie Gunson",
                "Daniel Hern\u00e1ndez Garcia",
                "Alexandre Kha",
                "Oliver Lemon",
                "James Ndubuisi",
                "Neil O'Reilly",
                "Lia Perochaud",
                "Rapha\u00ebl Valeri",
                "Miebaka Worika"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03021v1",
                "http://arxiv.org/pdf/2311.03021v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03019v1",
            "title": "Optimal Control of Linear Cost Networks",
            "updated": "2023-11-06T10:58:03Z",
            "published": "2023-11-06T10:58:03Z",
            "summary": "We present a method for optimal control with respect to a linear cost\nfunction for positive linear systems with coupled input constraints. We show\nthat the optimal cost function and resulting sparse state feedback for these\nsystems can be computed by linear programming. Our framework admits a range of\nnetwork routing problems with underlying linear dynamics. These dynamics can be\nused to model traditional graph-theoretical problems like shortest path as a\nspecial case, but can also capture more complex behaviors. We provide an\nasynchronous and distributed value iteration algorithm for obtaining the\noptimal cost function and control law.",
            "author": [
                "David Ohlin",
                "Emma Tegling",
                "Anders Rantzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03019v1",
                "http://arxiv.org/pdf/2311.03019v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03017v1",
            "title": "COLA: COarse-LAbel multi-source LiDAR semantic segmentation for\n  autonomous driving",
            "updated": "2023-11-06T10:49:12Z",
            "published": "2023-11-06T10:49:12Z",
            "summary": "LiDAR semantic segmentation for autonomous driving has been a growing field\nof interest in the past few years. Datasets and methods have appeared and\nexpanded very quickly, but methods have not been updated to exploit this new\navailability of data and continue to rely on the same classical datasets.\n  Different ways of performing LIDAR semantic segmentation training and\ninference can be divided into several subfields, which include the following:\ndomain generalization, the ability to segment data coming from unseen domains ;\nsource-to-source segmentation, the ability to segment data coming from the\ntraining domain; and pre-training, the ability to create re-usable geometric\nprimitives.\n  In this work, we aim to improve results in all of these subfields with the\nnovel approach of multi-source training. Multi-source training relies on the\navailability of various datasets at training time and uses them together rather\nthan relying on only one dataset.\n  To overcome the common obstacles found for multi-source training, we\nintroduce the coarse labels and call the newly created multi-source dataset\nCOLA. We propose three applications of this new dataset that display systematic\nimprovement over single-source strategies: COLA-DG for domain generalization\n(up to +10%), COLA-S2S for source-to-source segmentation (up to +5.3%), and\nCOLA-PT for pre-training (up to +12%).",
            "author": [
                "Jules Sanchez",
                "Jean-Emmanuel Deschaud",
                "Fran\u00e7ois Goulette"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03017v1",
                "http://arxiv.org/pdf/2311.03017v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03015v2",
            "title": "Higher order Kirk invariants of link maps",
            "updated": "2023-11-21T07:55:06Z",
            "published": "2023-11-06T10:43:30Z",
            "summary": "We define numerical link-homotopy invariants of link maps of any number of\ncomponents, which naturally generalize the Kirk invariant. The Kirk invariant\nis a link-homotopy invariant of 2-component link maps given by linking numbers\nof loops based at self-singularities of each component with the other spherical\ncomponent; our invariants use instead ingredients from Milnor's higher order\nlink invariants, and are extracted from the reduced fundamental groups of the\nexterior. We provide practical algorithms to compute these invariants from an\nappropriate cross-section, as well as families of examples that are therewith\ndetected. The main proofs use the combinatorial theory of cut-diagrams\npreviously developed by the authors.",
            "author": [
                "Benjamin Audoux",
                "Jean-Baptiste Meilhan",
                "Akira Yasuhara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03015v2",
                "http://arxiv.org/pdf/2311.03015v2"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03010v1",
            "title": "A New Extrapolation Economy Cascadic Multigrid Method for Image\n  Restoration Problems",
            "updated": "2023-11-06T10:28:17Z",
            "published": "2023-11-06T10:28:17Z",
            "summary": "In this paper, a new extrapolation economy cascadic multigrid method is\nproposed to solve the image restoration model. The new method combines the new\nextrapolation formula and quadratic interpolation to design a nonlinear\nprolongation operator, which provides more accurate initial values for the fine\ngrid level. An edge preserving denoising operator is constructed to remove\nnoise and preserve image edges. The local smoothing operator reduces the\ninfluence of staircase effect. The experiment results show that the new method\nnot only improves the computational efficiency but also ensures good recovery\nquality.",
            "author": [
                "Zhaoteng Chu",
                "Ziqi Yan",
                "Chenliang Li"
            ],
            "link": [
                "http://dx.doi.org/10.4236/ajcm.2023.132016.",
                "http://arxiv.org/abs/2311.03010v1",
                "http://arxiv.org/pdf/2311.03010v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65F10, 65N55"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03008v1",
            "title": "Exploring the Capability of Text-to-Image Diffusion Models with\n  Structural Edge Guidance for Multi-Spectral Satellite Image Inpainting",
            "updated": "2023-11-06T10:25:26Z",
            "published": "2023-11-06T10:25:26Z",
            "summary": "The paper investigates the utility of text-to-image inpainting models for\nsatellite image data. Two technical challenges of injecting structural guiding\nsignals into the generative process as well as translating the inpainted RGB\npixels to a wider set of MSI bands are addressed by introducing a novel\ninpainting framework based on StableDiffusion and ControlNet as well as a novel\nmethod for RGB-to-MSI translation. The results on a wider set of data suggest\nthat the inpainting synthesized via StableDiffusion suffers from undesired\nartefacts and that a simple alternative of self-supervised internal inpainting\nachieves higher quality of synthesis.",
            "author": [
                "Mikolaj Czerkawski",
                "Christos Tachtatzis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03008v1",
                "http://arxiv.org/pdf/2311.03008v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03000v1",
            "title": "Strong statistical parity through fair synthetic data",
            "updated": "2023-11-06T10:06:30Z",
            "published": "2023-11-06T10:06:30Z",
            "summary": "AI-generated synthetic data, in addition to protecting the privacy of\noriginal data sets, allows users and data consumers to tailor data to their\nneeds. This paper explores the creation of synthetic data that embodies\nFairness by Design, focusing on the statistical parity fairness definition. By\nequalizing the learned target probability distributions of the synthetic data\ngenerator across sensitive attributes, a downstream model trained on such\nsynthetic data provides fair predictions across all thresholds, that is, strong\nfair predictions even when inferring from biased, original data. This fairness\nadjustment can be either directly integrated into the sampling process of a\nsynthetic generator or added as a post-processing step. The flexibility allows\ndata consumers to create fair synthetic data and fine-tune the trade-off\nbetween accuracy and fairness without any previous assumptions on the data or\nre-training the synthetic data generator.",
            "author": [
                "Ivona Krchova",
                "Michael Platzer",
                "Paul Tiwald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03000v1",
                "http://arxiv.org/pdf/2311.03000v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02999v1",
            "title": "Bayesian Time-Lapse Full Waveform Inversion using Hamiltonian Monte\n  Carlo",
            "updated": "2023-11-06T10:06:11Z",
            "published": "2023-11-06T10:06:11Z",
            "summary": "Time-lapse images carry out important information about dynamic changes in\nEarth's interior which can be inferred using different Full Waveform Inversion\n(FWI) schemes. The estimation process is performed by manipulating more than\none seismic dataset, associated with the baseline and monitors surveys. The\ntime-lapse variations can be so minute and localised that quantifying the\nuncertainties becomes fundamental to assessing the reliability of the results.\nThe Bayesian formulation of the FWI problem naturally provides levels of\nconfidence in the solution, but evaluating the uncertainty of time-lapse\nseismic inversion remains a challenge due to the ill-posedness and high\ndimensionality of the problem. The Hamiltonian Monte Carlo (HMC) can be used to\neffectively sample over high dimensional distributions with affordable\ncomputational efforts. In this context, we propose a probabilistic Bayesian\nsequential approach for time-lapse FWI using the HMC method. Our approach\nrelies on the integration of the baseline survey information as prior knowledge\nin the monitor estimation. We compare the proposed methodology with a parallel\nscheme in perfect and perturbed acquisition geometry scenarios. We also\ninvestigate the correlation effect between baseline and monitor samples in the\npropagated uncertainties. The results show that our strategy provides accurate\ntimes-lapse estimates with errors of similar magnitude to the parallel\nmethodology.",
            "author": [
                "Paulo Douglas S. de Lima",
                "Mauro S. Ferreira",
                "Gilberto Corso",
                "Jo\u00e3o M. de Ara\u00fajo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02999v1",
                "http://arxiv.org/pdf/2311.02999v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cond-mat.stat-mech",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02998v1",
            "title": "One-loop form factors for $h\\rightarrow e^-e^+\u03b3$ and\n  $e^-e^+\\rightarrow h\u03b3$ in $U(1)_{B-L}$ extension of the standard model",
            "updated": "2023-11-06T10:06:10Z",
            "published": "2023-11-06T10:06:10Z",
            "summary": "One-loop form factors for $h\\rightarrow e^-e^+\\gamma$ and $e^-e^+\\rightarrow\nh\\gamma$ in $U(1)_{B-L}$ extension of the standard model are presented in this\nwork. The computations are performed in 't Hooft-Veltman gauge. Analytical\nresults are then expressed in terms of Passarino-Veltman functions following\nthe standard notations of {\\tt LoopTools}. As a results, one-loop form factors\ncan be evaluated numerically by using {\\tt LoopTools}. In phenomenological\nresults, the signal strengths of $e^-e^+\\rightarrow h\\gamma$, defined as ratio\nof cross sections computed in $U(1)_{B-L}$ extension models to the\ncorresponding ones in the standard model, are analyzed at future lepton\ncolliders. The signal strengths for both vector and chiral $B-L$ models are\nscanned in physical parameter space. We find that the effects of charged Higgs\nin the chiral $B-L$ model can be probed easily with the help of the initial\npolarization beams at future lepton colliders.",
            "author": [
                "Dzung Tri Tran",
                "Thanh Huy Nguyen",
                "Khiem Hong Phan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02998v1",
                "http://arxiv.org/pdf/2311.02998v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02995v1",
            "title": "Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition",
            "updated": "2023-11-06T09:57:48Z",
            "published": "2023-11-06T09:57:48Z",
            "summary": "Two difficulties here make low-light image enhancement a challenging task;\nfirstly, it needs to consider not only luminance restoration but also image\ncontrast, image denoising and color distortion issues simultaneously. Second,\nthe effectiveness of existing low-light enhancement methods depends on paired\nor unpaired training data with poor generalization performance.\n  To solve these difficult problems, we propose in this paper a new\nlearning-based Retinex decomposition of zero-shot low-light enhancement method,\ncalled ZERRINNet. To this end, we first designed the N-Net network, together\nwith the noise loss term, to be used for denoising the original low-light image\nby estimating the noise of the low-light image. Moreover, RI-Net is used to\nestimate the reflection component and illumination component, and in order to\nsolve the color distortion and contrast, we use the texture loss term and\nsegmented smoothing loss to constrain the reflection component and illumination\ncomponent. Finally, our method is a zero-reference enhancement method that is\nnot affected by the training data of paired and unpaired datasets, so our\ngeneralization performance is greatly improved, and in the paper, we have\neffectively validated it with a homemade real-life low-light dataset and\nadditionally with advanced vision tasks, such as face detection, target\nrecognition, and instance segmentation. We conducted comparative experiments on\na large number of public datasets and the results show that the performance of\nour method is competitive compared to the current state-of-the-art methods. The\ncode is available at:https://github.com/liwenchao0615/ZERRINNet",
            "author": [
                "Wenchao Li",
                "Bangshu Xiong",
                "Qiaofeng Ou",
                "Xiaoyun Long",
                "Jinhao Zhu",
                "Jiabao Chen",
                "Shuyuan Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02995v1",
                "http://arxiv.org/pdf/2311.02995v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02994v1",
            "title": "Evolution of Collective Decision-Making Mechanisms for Collective\n  Perception",
            "updated": "2023-11-06T09:56:33Z",
            "published": "2023-11-06T09:56:33Z",
            "summary": "Autonomous robot swarms must be able to make fast and accurate collective\ndecisions, but speed and accuracy are known to be conflicting goals. While\ncollective decision-making is widely studied in swarm robotics research, only\nfew works on using methods of evolutionary computation to generate collective\ndecision-making mechanisms exist. These works use task-specific fitness\nfunctions rewarding the accomplishment of the respective collective\ndecision-making task. But task-independent rewards, such as for prediction\nerror minimization, may promote the emergence of diverse and innovative\nsolutions. We evolve collective decision-making mechanisms using a\ntask-specific fitness function rewarding correct robot opinions, a\ntask-independent reward for prediction accuracy, and a hybrid fitness function\ncombining the two previous. In our simulations, we use the collective\nperception scenario, that is, robots must collectively determine which of two\nenvironmental features is more frequent. We show that evolution successfully\noptimizes fitness in all three scenarios, but that only the task-specific\nfitness function and the hybrid fitness function lead to the emergence of\ncollective decision-making behaviors. In benchmark experiments, we show the\ncompetitiveness of the evolved decision-making mechanisms to the voter model\nand the majority rule and analyze the scalability of the decision-making\nmechanisms with problem difficulty.",
            "author": [
                "Tanja Katharina Kaiser",
                "Tristan Potten",
                "Heiko Hamann"
            ],
            "link": [
                "http://dx.doi.org/10.1109/CEC53210.2023.10253996",
                "http://arxiv.org/abs/2311.02994v1",
                "http://arxiv.org/pdf/2311.02994v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.NE",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02992v1",
            "title": "NEURO HAND: A weakly supervised Hierarchical Attention Network for\n  neuroimaging abnormality Detection",
            "updated": "2023-11-06T09:55:19Z",
            "published": "2023-11-06T09:55:19Z",
            "summary": "Clinical neuroimaging data is naturally hierarchical. Different magnetic\nresonance imaging (MRI) sequences within a series, different slices covering\nthe head, and different regions within each slice all confer different\ninformation. In this work we present a hierarchical attention network for\nabnormality detection using MRI scans obtained in a clinical hospital setting.\nThe proposed network is suitable for non-volumetric data (i.e. stacks of\nhigh-resolution MRI slices), and can be trained from binary examination-level\nlabels. We show that this hierarchical approach leads to improved\nclassification, while providing interpretability through either coarse inter-\nand intra-slice abnormality localisation, or giving importance scores for\ndifferent slices and sequences, making our model suitable for use as an\nautomated triaging system in radiology departments.",
            "author": [
                "David A. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02992v1",
                "http://arxiv.org/pdf/2311.02992v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02991v1",
            "title": "Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware\n  Structure Encoding",
            "updated": "2023-11-06T09:54:47Z",
            "published": "2023-11-06T09:54:47Z",
            "summary": "Deep learning (DL) has successfully automated dose distribution prediction in\nradiotherapy planning, enhancing both efficiency and quality. However, existing\nmethods suffer from the over-smoothing problem for their commonly used L1 or L2\nloss with posterior average calculations. To alleviate this limitation, we\npropose a diffusion model-based method (DiffDose) for predicting the\nradiotherapy dose distribution of cancer patients. Specifically, the DiffDose\nmodel contains a forward process and a reverse process. In the forward process,\nDiffDose transforms dose distribution maps into pure Gaussian noise by\ngradually adding small noise and a noise predictor is simultaneously trained to\nestimate the noise added at each timestep. In the reverse process, it removes\nthe noise from the pure Gaussian noise in multiple steps with the well-trained\nnoise predictor and finally outputs the predicted dose distribution maps...",
            "author": [
                "Zhenghao Feng",
                "Lu Wen",
                "Jianghong Xiao",
                "Yuanyuan Xu",
                "Xi Wu",
                "Jiliu Zhou",
                "Xingchen Peng",
                "Yan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02991v1",
                "http://arxiv.org/pdf/2311.02991v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02986v1",
            "title": "Hacking Cryptographic Protocols with Advanced Variational Quantum\n  Attacks",
            "updated": "2023-11-06T09:46:16Z",
            "published": "2023-11-06T09:46:16Z",
            "summary": "Here we introduce an improved approach to Variational Quantum Attack\nAlgorithms (VQAA) on crytographic protocols. Our methods provide robust quantum\nattacks to well-known cryptographic algorithms, more efficiently and with\nremarkably fewer qubits than previous approaches. We implement simulations of\nour attacks for symmetric-key protocols such as S-DES, S-AES and Blowfish. For\ninstance, we show how our attack allows a classical simulation of a small\n8-qubit quantum computer to find the secret key of one 32-bit Blowfish instance\nwith 24 times fewer number of iterations than a brute-force attack. Our work\nalso shows improvements in attack success rates for lightweight ciphers such as\nS-DES and S-AES. Further applications beyond symmetric-key cryptography are\nalso discussed, including asymmetric-key protocols and hash functions. In\naddition, we also comment on potential future improvements of our methods. Our\nresults bring one step closer assessing the vulnerability of large-size\nclassical cryptographic protocols with Noisy Intermediate-Scale Quantum (NISQ)\ndevices, and set the stage for future research in quantum cybersecurity.",
            "author": [
                "Borja Aizpurua",
                "Pablo Bermejo",
                "Josu Etxezarreta Martinez",
                "Roman Orus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02986v1",
                "http://arxiv.org/pdf/2311.02986v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02985v2",
            "title": "Towards a Transformer-Based Reverse Dictionary Model for Quality\n  Estimation of Definitions",
            "updated": "2023-11-08T15:00:19Z",
            "published": "2023-11-06T09:42:44Z",
            "summary": "In the last years, several variants of transformers have emerged. In this\npaper, we compare different transformer-based models for solving the reverse\ndictionary task and explore their use in the context of a serious game called\nThe Dictionary Game.",
            "author": [
                "Julien Guit\u00e9-Vinet",
                "Alexandre Blondin Mass\u00e9",
                "Fatiha Sadat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02985v2",
                "http://arxiv.org/pdf/2311.02985v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03414v1",
            "title": "A Generative Neural Network Approach for 3D Multi-Criteria Design\n  Generation and Optimization of an Engine Mount for an Unmanned Air Vehicle",
            "updated": "2023-11-06T09:33:56Z",
            "published": "2023-11-06T09:33:56Z",
            "summary": "One of the most promising developments in computer vision in recent years is\nthe use of generative neural networks for functionality condition-based 3D\ndesign reconstruction and generation. Here, neural networks learn dependencies\nbetween functionalities and a geometry in a very effective way. For a neural\nnetwork the functionalities are translated in conditions to a certain geometry.\nBut the more conditions the design generation needs to reflect, the more\ndifficult it is to learn clear dependencies. This leads to a multi criteria\ndesign problem due various conditions, which are not considered in the neural\nnetwork structure so far.\n  In this paper, we address this multi-criteria challenge for a 3D design use\ncase related to an unmanned aerial vehicle (UAV) motor mount. We generate\n10,000 abstract 3D designs and subject them all to simulations for three\nphysical disciplines: mechanics, thermodynamics, and aerodynamics. Then, we\ntrain a Conditional Variational Autoencoder (CVAE) using the geometry and\ncorresponding multicriteria functional constraints as input. We use our trained\nCVAE as well as the Marching cubes algorithm to generate meshes for simulation\nbased evaluation. The results are then evaluated with the generated UAV\ndesigns. Subsequently, we demonstrate the ability to generate optimized designs\nunder self-defined functionality conditions using the trained neural network.",
            "author": [
                "Christoph Petroll",
                "Sebastian Eilermann",
                "Philipp Hoefer",
                "Oliver Niggemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03414v1",
                "http://arxiv.org/pdf/2311.03414v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02979v1",
            "title": "Modeling blazar broadband emission with convolutional neural networks --\n  I. Synchrotron self-Compton model",
            "updated": "2023-11-06T09:31:29Z",
            "published": "2023-11-06T09:31:29Z",
            "summary": "Modeling the multiwavelength spectral energy distributions (SEDs) of blazars\nprovides key insights into the underlying physical processes responsible for\nthe emission. While SED modeling with self-consistent models is computationally\ndemanding, it is essential for a comprehensive understanding of these\nastrophysical objects. We introduce a novel, efficient method for modeling the\nSEDs of blazars by the mean of a convolutional neural network (CNN). In this\npaper, we trained the CNN on a leptonic model that incorporates synchrotron and\ninverse Compton emissions, as well as self-consistent electron cooling and pair\ncreation-annihilation processes. The CNN is capable of reproducing the\nradiative signatures of blazars with high accuracy. This approach significantly\nreduces computational time, thereby enabling real-time fitting to\nmulti-wavelength datasets. As a demonstration, we used the trained CNN with\nMultiNest to fit the broadband SEDs of Mrk 421 and 1ES 1959+650, successfully\nobtaining their parameter posterior distributions. This novel framework for\nfitting the SEDs of blazars will be further extended to incorporate more\nsophisticated models based on external Compton and hadronic scenarios, allowing\nfor multi-messenger constraints in the analysis. The models will be made\npublicly available via a web interface, the Markarian Multiwavelength\nDatacenter, to facilitate self-consistent modeling of multi-messenger data from\nblazar observations.",
            "author": [
                "Damien B\u00e9gu\u00e9",
                "Narek Sahakyan",
                "H\u00fcsne Dereli B\u00e9gu\u00e9",
                "Paolo Giommi",
                "Sargis Gasparyan",
                "Mher Khachatryan",
                "Andrea Casotto",
                "Asaf Pe'er"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02979v1",
                "http://arxiv.org/pdf/2311.02979v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02963v1",
            "title": "Cyclic structure, vertex degree and number of linear vertices in Minimal\n  Strong Digraphs",
            "updated": "2023-11-06T09:05:27Z",
            "published": "2023-11-06T09:05:27Z",
            "summary": "Minimal Strong Digraphs (MSDs) can be regarded as a generalization of the\nconcept of tree to directed graphs. Their cyclic structure and some spectral\nproperties have been studied in several articles. In this work, we further\nstudy some properties of MSDs that have to do with bounding the length of the\nlongest cycle (regarding the number of linear vertices, or the maximal in- or\noutdegree of vertices); studying whatever consequences from the spectral point\nof view; and giving some insight about the circumstances in which an efficient\nalgorithm to find the longest cycle contained in an MSD can be formulated.\nAmong other properties, we show that the number of linear vertices contained in\nan MSD is greater or equal to the maximal (resp. minimal) in- or outdegree of\nany vertex of the MSD and that the maximal length of a cycle contained in an\nMSD is lesser or equal to 2n-m, where n,m are the order and the size of the MSD\nrespectively; we have found a bound for the coefficients of the characteristic\npolynomial of an MSD, extending the result in a previous work of Lacalle,\nMarijuan and Pozo, and finally, we prove that computing the longest cycle\ncontained in an MSD is an NP-Hard problem.",
            "author": [
                "Miguel Arcos Argudo",
                "Jesus Lacalle",
                "Luis Miguel Pozo Coronado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02963v1",
                "http://arxiv.org/pdf/2311.02963v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C75 (Primary), 05C20, 05C7, 05C38, 05C40, 68Q25 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02962v1",
            "title": "Retrieval-Augmented Code Generation for Universal Information Extraction",
            "updated": "2023-11-06T09:03:21Z",
            "published": "2023-11-06T09:03:21Z",
            "summary": "Information Extraction (IE) aims to extract structural knowledge (e.g.,\nentities, relations, events) from natural language texts, which brings\nchallenges to existing methods due to task-specific schemas and complex text\nexpressions. Code, as a typical kind of formalized language, is capable of\ndescribing structural knowledge under various schemas in a universal way. On\nthe other hand, Large Language Models (LLMs) trained on both codes and texts\nhave demonstrated powerful capabilities of transforming texts into codes, which\nprovides a feasible solution to IE tasks. Therefore, in this paper, we propose\na universal retrieval-augmented code generation framework based on LLMs, called\nCode4UIE, for IE tasks. Specifically, Code4UIE adopts Python classes to define\ntask-specific schemas of various structural knowledge in a universal way. By so\ndoing, extracting knowledge under these schemas can be transformed into\ngenerating codes that instantiate the predefined Python classes with the\ninformation in texts. To generate these codes more precisely, Code4UIE adopts\nthe in-context learning mechanism to instruct LLMs with examples. In order to\nobtain appropriate examples for different tasks, Code4UIE explores several\nexample retrieval strategies, which can retrieve examples semantically similar\nto the given texts. Extensive experiments on five representative IE tasks\nacross nine datasets demonstrate the effectiveness of the Code4UIE framework.",
            "author": [
                "Yucan Guo",
                "Zixuan Li",
                "Xiaolong Jin",
                "Yantao Liu",
                "Yutao Zeng",
                "Wenxuan Liu",
                "Xiang Li",
                "Pan Yang",
                "Long Bai",
                "Jiafeng Guo",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02962v1",
                "http://arxiv.org/pdf/2311.02962v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02961v1",
            "title": "Adapting Pre-trained Generative Models for Extractive Question Answering",
            "updated": "2023-11-06T09:01:02Z",
            "published": "2023-11-06T09:01:02Z",
            "summary": "Pre-trained Generative models such as BART, T5, etc. have gained prominence\nas a preferred method for text generation in various natural language\nprocessing tasks, including abstractive long-form question answering (QA) and\nsummarization. However, the potential of generative models in extractive QA\ntasks, where discriminative models are commonly employed, remains largely\nunexplored. Discriminative models often encounter challenges associated with\nlabel sparsity, particularly when only a small portion of the context contains\nthe answer. The challenge is more pronounced for multi-span answers. In this\nwork, we introduce a novel approach that uses the power of pre-trained\ngenerative models to address extractive QA tasks by generating indexes\ncorresponding to context tokens or sentences that form part of the answer.\nThrough comprehensive evaluations on multiple extractive QA datasets, including\nMultiSpanQA, BioASQ, MASHQA, and WikiQA, we demonstrate the superior\nperformance of our proposed approach compared to existing state-of-the-art\nmodels.",
            "author": [
                "Prabir Mallick",
                "Tapas Nayak",
                "Indrajit Bhattacharya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02961v1",
                "http://arxiv.org/pdf/2311.02961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02960v1",
            "title": "Understanding Deep Representation Learning via Layerwise Feature\n  Compression and Discrimination",
            "updated": "2023-11-06T09:00:38Z",
            "published": "2023-11-06T09:00:38Z",
            "summary": "Over the past decade, deep learning has proven to be a highly effective tool\nfor learning meaningful features from raw data. However, it remains an open\nquestion how deep networks perform hierarchical feature learning across layers.\nIn this work, we attempt to unveil this mystery by investigating the structures\nof intermediate features. Motivated by our empirical findings that linear\nlayers mimic the roles of deep layers in nonlinear networks for feature\nlearning, we explore how deep linear networks transform input data into output\nby investigating the output (i.e., features) of each layer after training in\nthe context of multi-class classification problems. Toward this goal, we first\ndefine metrics to measure within-class compression and between-class\ndiscrimination of intermediate features, respectively. Through theoretical\nanalysis of these two metrics, we show that the evolution of features follows a\nsimple and quantitative pattern from shallow to deep layers when the input data\nis nearly orthogonal and the network weights are minimum-norm, balanced, and\napproximate low-rank: Each layer of the linear network progressively compresses\nwithin-class features at a geometric rate and discriminates between-class\nfeatures at a linear rate with respect to the number of layers that data have\npassed through. To the best of our knowledge, this is the first quantitative\ncharacterization of feature evolution in hierarchical representations of deep\nlinear networks. Empirically, our extensive experiments not only validate our\ntheoretical results numerically but also reveal a similar pattern in deep\nnonlinear networks which aligns well with recent empirical studies. Moreover,\nwe demonstrate the practical implications of our results in transfer learning.\nOur code is available at \\url{https://github.com/Heimine/PNC_DLN}.",
            "author": [
                "Peng Wang",
                "Xiao Li",
                "Can Yaras",
                "Zhihui Zhu",
                "Laura Balzano",
                "Wei Hu",
                "Qing Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02960v1",
                "http://arxiv.org/pdf/2311.02960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02957v3",
            "title": "Safe and Efficient Trajectory Optimization for Autonomous Vehicles using\n  B-spline with Incremental Path Flattening",
            "updated": "2023-11-29T09:49:44Z",
            "published": "2023-11-06T08:52:18Z",
            "summary": "B-spline-based trajectory optimization is widely used for robot navigation\ndue to its computational efficiency and convex-hull property (ensures dynamic\nfeasibility), especially as quadrotors, which have circular body shapes (enable\nefficient movement) and freedom to move each axis (enables convex-hull property\nutilization). However, using the B-spline curve for trajectory optimization is\nchallenging for autonomous vehicles (AVs) because of their vehicle kinodynamics\n(rectangular body shapes and constraints to move each axis). In this study, we\npropose a novel trajectory optimization approach for AVs to circumvent this\ndifficulty using an incremental path flattening (IPF), a disc type swept volume\n(SV) estimation method, and kinodynamic feasibility constraints. IPF is a new\nmethod that can find a collision-free path for AVs by flattening path and\nreducing SV using iteratively increasing curvature penalty around vehicle\ncollision points. Additionally, we develop a disc type SV estimation method to\nreduce SV over-approximation and enable AVs to pass through a narrow corridor\nefficiently. Furthermore, a clamped B-spline curvature constraint, which\nsimplifies a B-spline curvature constraint, is added to dynamical feasibility\nconstraints (e.g., velocity and acceleration) for obtaining the kinodynamic\nfeasibility constraints. Our experimental results demonstrate that our method\noutperforms state-of-the-art baselines in various simulated environments. We\nalso conducted a real-world experiment using an AV, and our results validate\nthe simulated tracking performance of the proposed approach.",
            "author": [
                "Jongseo Choi",
                "Hyuntai Chin",
                "Hyunwoo Park",
                "Daehyeok Kwon",
                "Sanghyun Lee",
                "Doosan Baek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02957v3",
                "http://arxiv.org/pdf/2311.02957v3"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02956v1",
            "title": "In-Context Learning for Knowledge Base Question Answering for Unmanned\n  Systems based on Large Language Models",
            "updated": "2023-11-06T08:52:11Z",
            "published": "2023-11-06T08:52:11Z",
            "summary": "Knowledge Base Question Answering (KBQA) aims to answer factoid questions\nbased on knowledge bases. However, generating the most appropriate knowledge\nbase query code based on Natural Language Questions (NLQ) poses a significant\nchallenge in KBQA. In this work, we focus on the CCKS2023 Competition of\nQuestion Answering with Knowledge Graph Inference for Unmanned Systems.\nInspired by the recent success of large language models (LLMs) like ChatGPT and\nGPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL)\ngeneration framework to generate the most appropriate CQL based on the given\nNLQ. Our generative framework contains six parts: an auxiliary model predicting\nthe syntax-related information of CQL based on the given NLQ, a proper noun\nmatcher extracting proper nouns from the given NLQ, a demonstration example\nselector retrieving similar examples of the input sample, a prompt constructor\ndesigning the input template of ChatGPT, a ChatGPT-based generation model\ngenerating the CQL, and an ensemble model to obtain the final answers from\ndiversified outputs. With our ChatGPT-based CQL generation framework, we\nachieved the second place in the CCKS 2023 Question Answering with Knowledge\nGraph Inference for Unmanned Systems competition, achieving an F1-score of\n0.92676.",
            "author": [
                "Yunlong Chen",
                "Yaming Zhang",
                "Jianfei Yu",
                "Li Yang",
                "Rui Xia"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-7224-1_26",
                "http://arxiv.org/abs/2311.02956v1",
                "http://arxiv.org/pdf/2311.02956v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02955v1",
            "title": "An operator-splitting optimization approach for phase-field simulation\n  of equilibrium shapes of crystals",
            "updated": "2023-11-06T08:50:34Z",
            "published": "2023-11-06T08:50:34Z",
            "summary": "Computing equilibrium shapes of crystals (ESC) is a challenging problem in\nmaterials science that involves minimizing an orientation-dependent (i.e.,\nanisotropic) surface energy functional subject to a prescribed mass constraint.\nThe highly nonlinear and singular anisotropic terms in the problem make it very\nchallenging from both the analytical and numerical aspects. Especially, when\nthe strength of anisotropy is very strong (i.e., strongly anisotropic cases),\nthe ESC will form some singular, sharp corners even if the surface energy\nfunction is smooth. Traditional numerical approaches, such as the $H^{-1}$\ngradient flow, are unable to produce true sharp corners due to the necessary\naddition of a high-order regularization term that penalizes sharp corners and\nrounds them off. In this paper, we propose a new numerical method based on the\nDavis-Yin splitting (DYS) optimization algorithm to predict the ESC instead of\nusing gradient flow approaches. We discretize the infinite-dimensional\nphase-field energy functional in the absence of regularization terms and\ntransform it into a finite-dimensional constraint minimization problem. The\nresulting optimization problem is solved using the DYS method which\nautomatically guarantees the mass-conservation and bound-preserving properties.\nWe also prove the global convergence of the proposed algorithm. These desired\nproperties are numerically observed. In particular, the proposed method can\nproduce real sharp corners with satisfactory accuracy. Finally, we present\nnumerous numerical results to demonstrate that the ESC can be well simulated\nunder different types of anisotropic surface energies, which also confirms the\neffectiveness and efficiency of the proposed method.",
            "author": [
                "Zeyu Zhou",
                "Wen Huang",
                "Wei Jiang",
                "Zhen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02955v1",
                "http://arxiv.org/pdf/2311.02955v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "74G15, 74G65, 65Z05",
                "J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04235v1",
            "title": "Can LLMs Follow Simple Rules?",
            "updated": "2023-11-06T08:50:29Z",
            "published": "2023-11-06T08:50:29Z",
            "summary": "As Large Language Models (LLMs) are deployed with increasing real-world\nresponsibilities, it is important to be able to specify and constrain the\nbehavior of these systems in a reliable manner. Model developers may wish to\nset explicit rules for the model, such as \"do not generate abusive content\",\nbut these may be circumvented by jailbreaking techniques. Evaluating how well\nLLMs follow developer-provided rules in the face of adversarial inputs\ntypically requires manual review, which slows down monitoring and methods\ndevelopment. To address this issue, we propose Rule-following Language\nEvaluation Scenarios (RuLES), a programmatic framework for measuring\nrule-following ability in LLMs. RuLES consists of 15 simple text scenarios in\nwhich the model is instructed to obey a set of rules in natural language while\ninteracting with the human user. Each scenario has a concise evaluation program\nto determine whether the model has broken any rules in a conversation. Through\nmanual exploration of model behavior in our scenarios, we identify 6 categories\nof attack strategies and collect two suites of test cases: one consisting of\nunique conversations from manual testing and one that systematically implements\nstrategies from the 6 categories. Across various popular proprietary and open\nmodels such as GPT-4 and Llama 2, we find that all models are susceptible to a\nwide variety of adversarial hand-crafted user inputs, though GPT-4 is the\nbest-performing model. Additionally, we evaluate open models under\ngradient-based attacks and find significant vulnerabilities. We propose RuLES\nas a challenging new setting for research into exploring and defending against\nboth manual and automatic attacks on LLMs.",
            "author": [
                "Norman Mu",
                "Sarah Chen",
                "Zifan Wang",
                "Sizhe Chen",
                "David Karamardian",
                "Lulwa Aljeraisy",
                "Dan Hendrycks",
                "David Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04235v1",
                "http://arxiv.org/pdf/2311.04235v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14691v1",
            "title": "Real-time Digital Twins",
            "updated": "2023-11-06T08:46:48Z",
            "published": "2023-11-06T08:46:48Z",
            "summary": "We live in a world of exploding complexity driven by technical evolution as\nwell as highly volatile socio-economic environments. Managing complexity is a\nkey issue in everyday decision making such as providing safe, sustainable, and\nefficient industrial control solutions as well as solving today's global grand\nchallenges such as the climate change. However, the level of complexity has\nwell reached our cognitive capability to take informed decisions. Digital\nTwins, tightly integrating the real and the digital world, are a key enabler to\nsupport decision making for complex systems. They allow informing operational\nas well as strategic decisions upfront through accepted virtual predictions and\noptimizations of their real-world counter parts. Here we focus on real-time\nDigital Twins for online prediction and optimization of highly dynamic\nindustrial assets and processes. They offer significant opportunities in the\ncontext of the industrial Internet of Things for novel and more effective\ncontrol and optimization concepts. Thereby, they meet the Internet of Things\nneeds for novel technologies to overcome today's limitations in terms of data\navailability in industrial contexts. Integrating today's seemingly\ncomplementary technologies of model-based and data-based, as well as edge-based\nand cloud-based approaches has the potential to re-imagine industrial process\nperformance optimization solutions.",
            "author": [
                "Dirk Hartmann"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.5470479",
                "http://arxiv.org/abs/2311.14691v1",
                "http://arxiv.org/pdf/2311.14691v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02947v1",
            "title": "Multi-view learning for automatic classification of multi-wavelength\n  auroral images",
            "updated": "2023-11-06T08:30:24Z",
            "published": "2023-11-06T08:30:24Z",
            "summary": "Auroral classification plays a crucial role in polar research. However,\ncurrent auroral classification studies are predominantly based on images taken\nat a single wavelength, typically 557.7 nm. Images obtained at other\nwavelengths have been comparatively overlooked, and the integration of\ninformation from multiple wavelengths remains an underexplored area. This\nlimitation results in low classification rates for complex auroral patterns.\nFurthermore, these studies, whether employing traditional machine learning or\ndeep learning approaches, have not achieved a satisfactory trade-off between\naccuracy and speed. To address these challenges, this paper proposes a\nlightweight auroral multi-wavelength fusion classification network, MLCNet,\nbased on a multi-view approach. Firstly, we develop a lightweight feature\nextraction backbone, called LCTNet, to improve the classification rate and cope\nwith the increasing amount of auroral observation data. Secondly, considering\nthe existence of multi-scale spatial structures in auroras, we design a novel\nmulti-scale reconstructed feature module named MSRM. Finally, to highlight the\ndiscriminative information between auroral classes, we propose a lightweight\nattention feature enhancement module called LAFE. The proposed method is\nvalidated using observational data from the Arctic Yellow River Station during\n2003-2004. Experimental results demonstrate that the fusion of multi-wavelength\ninformation effectively improves the auroral classification performance. In\nparticular, our approach achieves state-of-the-art classification accuracy\ncompared to previous auroral classification studies, and superior results in\nterms of accuracy and computational efficiency compared to existing multi-view\nmethods.",
            "author": [
                "Qiuju Yang",
                "Hang Su",
                "Lili Liu",
                "Yixuan Wang",
                "Ze-Jun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02947v1",
                "http://arxiv.org/pdf/2311.02947v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00019v1",
            "title": "The theoretical limits of biometry",
            "updated": "2023-11-06T08:28:12Z",
            "published": "2023-11-06T08:28:12Z",
            "summary": "Biometry has proved its capability in terms of recognition accuracy. Now, it\nis widely used for automated border control with the biometric passport, to\nunlock a smartphone or a computer with a fingerprint or a face recognition\nalgorithm. While identity verification is widely democratized, pure\nidentification with no additional clues is still a work in progress. The\nidentification difficulty depends on the population size, as the larger the\ngroup is, the larger the confusion risk. For collision prevention, biometric\ntraits must be sufficiently distinguishable to scale to considerable groups,\nand algorithms should be able to capture their differences accurately.\n  Most biometric works are purely experimental, and it is impossible to\nextrapolate the results to a smaller or a larger group. In this work, we\npropose a theoretical analysis of the distinguishability problem, which governs\nthe error rates of biometric systems. We demonstrate simple relationships\nbetween the population size and the number of independent bits necessary to\nprevent collision in the presence of noise. This work provides the lowest lower\nbound for memory requirements. The results are very encouraging, as the\nbiometry of the whole Earth population can fit in a regular disk, leaving some\nspace for noise and redundancy.",
            "author": [
                "Ga\u00eblle Candel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00019v1",
                "http://arxiv.org/pdf/2312.00019v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.IT",
                "math.IT",
                "68P30",
                "E.4; I.2.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02945v1",
            "title": "PhoGPT: Generative Pre-training for Vietnamese",
            "updated": "2023-11-06T08:26:14Z",
            "published": "2023-11-06T08:26:14Z",
            "summary": "We open-source a state-of-the-art 7.5B-parameter generative model series\nnamed PhoGPT for Vietnamese, which includes the base pre-trained monolingual\nmodel PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct. In\naddition, we also demonstrate its superior performance compared to previous\nopen-source models through a human evaluation experiment. GitHub:\nhttps://github.com/VinAIResearch/PhoGPT",
            "author": [
                "Dat Quoc Nguyen",
                "Linh The Nguyen",
                "Chi Tran",
                "Dung Ngoc Nguyen",
                "Nhung Nguyen",
                "Thien Huu Nguyen",
                "Dinh Phung",
                "Hung Bui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02945v1",
                "http://arxiv.org/pdf/2311.02945v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02941v1",
            "title": "Optical pumping of ${\\mathrm{5s4d} ^1\\mathrm{D}_2}$ strontium atoms for\n  laser cooling and imaging",
            "updated": "2023-11-06T08:17:39Z",
            "published": "2023-11-06T08:17:39Z",
            "summary": "We present a faster repumping scheme for strontium magneto-optical traps\noperating on the broad ${\\mathrm{5s^2} ^1\\mathrm{S}_0} - {\\mathrm{5s5p}\n^1\\mathrm{P}_1}$ laser cooling transition. Contrary to existing repumping\nschemes, we directly address lost atoms that spontaneously decayed to the\n${\\mathrm{5s4d} ^1\\mathrm{D}_2}$ state, sending them back into the laser\ncooling cycle by optical pumping on the ${\\mathrm{5s4d} ^1\\mathrm{D}_2} -\n{\\mathrm{5s8p} ^1\\mathrm{P}_1}$ transition. We thus avoid the $\\sim 100 \\,\n\\mathrm{\\mu s}$-slow decay path from ${\\mathrm{5s4d} ^1\\mathrm{D}_2}$ to the\n${\\mathrm{5s5p} ^3\\mathrm{P}_{1,2}}$ states that is part of other repumping\nschemes. Using one low-cost external-cavity diode laser emitting at $448 \\,\n\\mathrm{nm}$, we show our scheme increases the flux out of a 2D magneto-optical\ntrap by $60 \\, \\%$ compared to without repumping. Furthermore, we perform\nspectroscopy on the ${\\mathrm{5s4d} ^1\\mathrm{D}_2} - {\\mathrm{5s8p}\n^1\\mathrm{P}_1}$ transition and measure its frequency $\\nu_{\\mathrm{^{88}Sr}} =\n(668917515.3 \\pm 4.0 \\pm 25) \\, \\mathrm{MHz}$. We also measure the frequency\nshifts between the four stable isotopes of strontium and infer the specific\nmass and field shift factors, $\\delta \\nu_\\text{SMS} ^{88,86} = -267(45) \\,\n\\mathrm{MHz}$ and $\\delta \\nu_\\text{FS} ^{88,86} = 2(42) \\, \\mathrm{MHz}$.\nFinally, we measure the hyperfine splitting of the ${\\mathrm{5s8p}\n^1\\mathrm{P}_1}$ state in fermionic strontium, and deduce the magnetic dipole\nand electric quadrupole coupling coefficients $A = -4(5) \\, \\mathrm{MHz}$ and\n$B = 5(35) \\, \\mathrm{MHz}$. Our experimental demonstration shows that this\nsimple and very fast scheme could improve the laser cooling and imaging\nperformance of cold strontium atom devices, such as quantum computers based on\nstrontium atoms in arrays of optical tweezers.",
            "author": [
                "Jens Samland",
                "Shayne Bennetts",
                "Chun-Chia Chen",
                "Rodrigo Gonz\u00e1lez Escudero",
                "Florian Schreck",
                "Benjamin Pasquiou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02941v1",
                "http://arxiv.org/pdf/2311.02941v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02926v2",
            "title": "Deep Image Semantic Communication Model for Artificial Intelligent\n  Internet of Things",
            "updated": "2023-11-08T07:47:28Z",
            "published": "2023-11-06T07:43:42Z",
            "summary": "With the rapid development of Artificial Intelligent Internet of Things\n(AIoT), the image data from AIoT devices has been witnessing the explosive\nincreasing. In this paper, a novel deep image semantic communication model is\nproposed for the efficient image communication in AIoT. Particularly, at the\ntransmitter side, a high-precision image semantic segmentation algorithm is\nproposed to extract the semantic information of the image to achieve\nsignificant compression of the image data. At the receiver side, a semantic\nimage restoration algorithm based on Generative Adversarial Network (GAN) is\nproposed to convert the semantic image to a real scene image with detailed\ninformation. Simulation results demonstrate that the proposed image semantic\ncommunication model can improve the image compression ratio and recovery\naccuracy by 71.93% and 25.07% on average in comparison with WebP and CycleGAN,\nrespectively. More importantly, our demo experiment shows that the proposed\nmodel reduces the total delay by 95.26% in the image communication, when\ncomparing with the original image transmission.",
            "author": [
                "Li Ping Qian",
                "Yi Zhang",
                "Sikai Lyu",
                "Huijie Zhu",
                "Yuan Wu",
                "Xuemin Sherman Shen",
                "Xiaoniu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02926v2",
                "http://arxiv.org/pdf/2311.02926v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02924v1",
            "title": "AttentioNet: Monitoring Student Attention Type in Learning with\n  EEG-Based Measurement System",
            "updated": "2023-11-06T07:43:15Z",
            "published": "2023-11-06T07:43:15Z",
            "summary": "Student attention is an indispensable input for uncovering their goals,\nintentions, and interests, which prove to be invaluable for a multitude of\nresearch areas, ranging from psychology to interactive systems. However, most\nexisting methods to classify attention fail to model its complex nature. To\nbridge this gap, we propose AttentioNet, a novel Convolutional Neural\nNetwork-based approach that utilizes Electroencephalography (EEG) data to\nclassify attention into five states: Selective, Sustained, Divided,\nAlternating, and relaxed state. We collected a dataset of 20 subjects through\nstandard neuropsychological tasks to elicit different attentional states. The\naverage across-student accuracy of our proposed model at this configuration is\n92.3% (SD=3.04), which is well-suited for end-user applications. Our transfer\nlearning-based approach for personalizing the model to individual subjects\neffectively addresses the issue of individual variability in EEG signals,\nresulting in improved performance and adaptability of the model for real-world\napplications. This represents a significant advancement in the field of\nEEG-based classification. Experimental results demonstrate that AttentioNet\noutperforms a popular EEGnet baseline (p-value < 0.05) in both\nsubject-independent and subject-dependent settings, confirming the\neffectiveness of our proposed approach despite the limitations of our dataset.\nThese results highlight the promising potential of AttentioNet for attention\nclassification using EEG data.",
            "author": [
                "Dhruv Verma",
                "Sejal Bhalla",
                "S. V. Sai Santosh",
                "Saumya Yadav",
                "Aman Parnami",
                "Jainendra Shukla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02924v1",
                "http://arxiv.org/pdf/2311.02924v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "I.2.6; K.3.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02922v1",
            "title": "Truly Scale-Equivariant Deep Nets with Fourier Layers",
            "updated": "2023-11-06T07:32:27Z",
            "published": "2023-11-06T07:32:27Z",
            "summary": "In computer vision, models must be able to adapt to changes in image\nresolution to effectively carry out tasks such as image segmentation; This is\nknown as scale-equivariance. Recent works have made progress in developing\nscale-equivariant convolutional neural networks, e.g., through weight-sharing\nand kernel resizing. However, these networks are not truly scale-equivariant in\npractice. Specifically, they do not consider anti-aliasing as they formulate\nthe down-scaling operation in the continuous domain. To address this\nshortcoming, we directly formulate down-scaling in the discrete domain with\nconsideration of anti-aliasing. We then propose a novel architecture based on\nFourier layers to achieve truly scale-equivariant deep nets, i.e., absolute\nzero equivariance-error. Following prior works, we test this model on\nMNIST-scale and STL-10 datasets. Our proposed model achieves competitive\nclassification performance while maintaining zero equivariance-error.",
            "author": [
                "Md Ashiqur Rahman",
                "Raymond A. Yeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02922v1",
                "http://arxiv.org/pdf/2311.02922v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05644v1",
            "title": "On the tractability of Nash equilibrium",
            "updated": "2023-11-06T07:19:58Z",
            "published": "2023-11-06T07:19:58Z",
            "summary": "In this paper, we propose a method for solving a PPAD-complete problem\n[Papadimitriou, 1994]. Given is the payoff matrix $C$ of a symmetric bimatrix\ngame $(C, C^T)$ and our goal is to compute a Nash equilibrium of $(C, C^T)$. In\nthis paper, we devise a nonlinear replicator dynamic (whose right-hand-side can\nbe obtained by solving a pair of convex optimization problems) with the\nfollowing property: Under any invertible $0 \\leq C \\leq 1$, every orbit of our\ndynamic starting at an interior strategy of the standard simplex approaches a\nset of strategies of $(C, C^T)$ such that, for each strategy in this set, a\nsymmetric Nash equilibrium strategy can be computed by solving the\naforementioned convex mathematical programs. We prove convergence using\nprevious results in analysis (the analytic implicit function theorem),\nnonlinear optimization theory (duality theory, Berge's maximum principle, and a\ntheorem of Robinson [1980] on the Lipschitz continuity of parametric nonlinear\nprograms), and dynamical systems theory (a theorem of Losert and Akin [1983]\nrelated to the LaSalle invariance principle that is stronger under a stronger\nassumption).",
            "author": [
                "Ioannis Avramopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05644v1",
                "http://arxiv.org/pdf/2311.05644v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02919v1",
            "title": "An Iwahori theoretic mod $p$ Local Langlands Correspondence",
            "updated": "2023-11-06T07:12:37Z",
            "published": "2023-11-06T07:12:37Z",
            "summary": "We extend a comparison theorem of Anandavardhanan-Borisagar between the\nquotient of the induction of a mod $p$ character by the image of an\nIwahori-Hecke operator and compact induction of a weight to the case of the\ntrivial character. This involves studying the corresponding non-commutative\nIwahori-Hecke algebra. We use this to give an Iwahori theoretic reformulation\nof the (semi-simple) mod $p$ Local Langlands Correspondence discovered by\nBreuil and reformulated functorially by Colmez. This version of the\ncorrespondence is expected to have applications to computing the mod $p$\nreductions of semi-stable Galois representations.",
            "author": [
                "Anand Chitrao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02919v1",
                "http://arxiv.org/pdf/2311.02919v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.RT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02912v1",
            "title": "Imitation Learning based Alternative Multi-Agent Proximal Policy\n  Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance",
            "updated": "2023-11-06T06:58:16Z",
            "published": "2023-11-06T06:58:16Z",
            "summary": "Multi-Robot System (MRS) has garnered widespread research interest and\nfostered tremendous interesting applications, especially in cooperative control\nfields. Yet little light has been shed on the compound ability of formation,\nmonitoring and defence in decentralized large-scale MRS for pursuit avoidance,\nwhich puts stringent requirements on the capability of coordination and\nadaptability. In this paper, we put forward a decentralized Imitation learning\nbased Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm\nto provide a flexible and communication-economic solution to execute the\npursuit avoidance task in well-formed swarm. In particular, a\npolicy-distillation based MAPPO executor is firstly devised to capably\naccomplish and swiftly switch between multiple formations in a centralized\nmanner. Furthermore, we utilize imitation learning to decentralize the\nformation controller, so as to reduce the communication overheads and enhance\nthe scalability. Afterwards, alternative training is leveraged to compensate\nthe performance loss incurred by decentralization. The simulation results\nvalidate the effectiveness of IA-MAPPO and extensive ablation experiments\nfurther show the performance comparable to a centralized solution with\nsignificant decrease in communication overheads.",
            "author": [
                "Sizhao Li",
                "Yuming Xiang",
                "Rongpeng Li",
                "Zhifeng Zhao",
                "Honggang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02912v1",
                "http://arxiv.org/pdf/2311.02912v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02911v1",
            "title": "Goal-Oriented Wireless Communication Resource Allocation for\n  Cyber-Physical Systems",
            "updated": "2023-11-06T06:57:09Z",
            "published": "2023-11-06T06:57:09Z",
            "summary": "The proliferation of novel industrial applications at the wireless edge, such\nas smart grids and vehicle networks, demands the advancement of cyber-physical\nsystems. The performance of CPSs is closely linked to the last-mile wireless\ncommunication networks, which often become bottlenecks due to their inherent\nlimited resources. Current CPS operations often treat wireless communication\nnetworks as unpredictable and uncontrollable variables, ignoring the potential\nadaptability of wireless networks, which results in inefficient and overly\nconservative CPS operations. Meanwhile, current wireless communications often\nfocus more on throughput and other transmission-related metrics instead of CPS\ngoals. In this study, we introduce the framework of goal-oriented wireless\ncommunication resource allocations, accounting for the semantics and\nsignificance of data for CPS operation goals. This guarantees optimal CPS\nperformance from a cybernetic standpoint. We formulate a bandwidth allocation\nproblem aimed at maximizing the information utility gain of transmitted data\nbrought to CPS operation goals. Since the goal-oriented bandwidth allocation\nproblem is a large-scale combinational problem, we propose a divide-and-conquer\nand greedy solution algorithm. The information utility gain is first\napproximately decomposed into marginal utility information gains and computed\nin a parallel manner. Subsequently, the bandwidth allocation problem is\nreformulated as a knapsack problem, which can be further solved greedily with a\nguaranteed sub-optimality gap. We further demonstrate how our proposed\ngoal-oriented bandwidth allocation algorithm can be applied in four potential\nCPS applications, including data-driven decision-making, edge learning,\nfederated learning, and distributed optimization.",
            "author": [
                "Cheng Feng",
                "Kedi Zheng",
                "Yi Wang",
                "Kaibin Huang",
                "Qixin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02911v1",
                "http://arxiv.org/pdf/2311.02911v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02910v1",
            "title": "Benchmarking Deep Facial Expression Recognition: An Extensive Protocol\n  with Balanced Dataset in the Wild",
            "updated": "2023-11-06T06:48:49Z",
            "published": "2023-11-06T06:48:49Z",
            "summary": "Facial expression recognition (FER) is a crucial part of human-computer\ninteraction. Existing FER methods achieve high accuracy and generalization\nbased on different open-source deep models and training approaches. However,\nthe performance of these methods is not always good when encountering practical\nsettings, which are seldom explored. In this paper, we collected a new\nin-the-wild facial expression dataset for cross-domain validation. Twenty-three\ncommonly used network architectures were implemented and evaluated following a\nuniform protocol. Moreover, various setups, in terms of input resolutions,\nclass balance management, and pre-trained strategies, were verified to show the\ncorresponding performance contribution. Based on extensive experiments on three\nlarge-scale FER datasets and our practical cross-validation, we ranked network\narchitectures and summarized a set of recommendations on deploying deep FER\nmethods in real scenarios. In addition, potential ethical rules, privacy\nissues, and regulations were discussed in practical FER applications such as\nmarketing, education, and entertainment business.",
            "author": [
                "Gianmarco Ipinze Tutuianu",
                "Yang Liu",
                "Ari Alam\u00e4ki",
                "Janne Kauttonen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02910v1",
                "http://arxiv.org/pdf/2311.02910v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02909v1",
            "title": "Distributed Matrix-Based Sampling for Graph Neural Network Training",
            "updated": "2023-11-06T06:40:43Z",
            "published": "2023-11-06T06:40:43Z",
            "summary": "The primary contribution of this paper is new methods for reducing\ncommunication in the sampling step for distributed GNN training. Here, we\npropose a matrix-based bulk sampling approach that expresses sampling as a\nsparse matrix multiplication (SpGEMM) and samples multiple minibatches at once.\nWhen the input graph topology does not fit on a single device, our method\ndistributes the graph and use communication-avoiding SpGEMM algorithms to scale\nGNN minibatch sampling, enabling GNN training on much larger graphs than those\nthat can fit into a single device memory. When the input graph topology (but\nnot the embeddings) fits in the memory of one GPU, our approach (1) performs\nsampling without communication, (2) amortizes the overheads of sampling a\nminibatch, and (3) can represent multiple sampling algorithms by simply using\ndifferent matrix constructions. In addition to new methods for sampling, we\nshow that judiciously replicating feature data with a simple all-to-all\nexchange can outperform current methods for the feature extraction step in\ndistributed GNN training. We provide experimental results on the largest Open\nGraph Benchmark (OGB) datasets on $128$ GPUs, and show that our pipeline is\n$2.5\\times$ faster Quiver (a distributed extension to PyTorch-Geometric) on a\n$3$-layer GraphSAGE network. On datasets outside of OGB, we show a $8.46\\times$\nspeedup on $128$ GPUs in-per epoch time. Finally, we show scaling when the\ngraph is distributed across GPUs and scaling for both node-wise and layer-wise\nsampling algorithms",
            "author": [
                "Alok Tripathy",
                "Katherine Yelick",
                "Aydin Buluc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02909v1",
                "http://arxiv.org/pdf/2311.02909v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02901v3",
            "title": "Pseudorandom Isometries",
            "updated": "2023-11-11T03:04:28Z",
            "published": "2023-11-06T06:27:14Z",
            "summary": "We introduce a new notion called ${\\cal Q}$-secure pseudorandom isometries\n(PRI). A pseudorandom isometry is an efficient quantum circuit that maps an\n$n$-qubit state to an $(n+m)$-qubit state in an isometric manner. In terms of\nsecurity, we require that the output of a $q$-fold PRI on $\\rho$, for $ \\rho\n\\in {\\cal Q}$, for any polynomial $q$, should be computationally\nindistinguishable from the output of a $q$-fold Haar isometry on $\\rho$. By\nfine-tuning ${\\cal Q}$, we recover many existing notions of pseudorandomness.\nWe present a construction of PRIs and assuming post-quantum one-way functions,\nwe prove the security of ${\\cal Q}$-secure pseudorandom isometries (PRI) for\ndifferent interesting settings of ${\\cal Q}$. We also demonstrate many\ncryptographic applications of PRIs, including, length extension theorems for\nquantum pseudorandomness notions, message authentication schemes for quantum\nstates, multi-copy secure public and private encryption schemes, and succinct\nquantum commitments.",
            "author": [
                "Prabhanjan Ananth",
                "Aditya Gulati",
                "Fatih Kaleoglu",
                "Yao-Ting Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02901v3",
                "http://arxiv.org/pdf/2311.02901v3"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02899v2",
            "title": "Stochastic Pairwise Preference Convergence in Bayesian Agents",
            "updated": "2023-11-07T17:32:03Z",
            "published": "2023-11-06T06:21:11Z",
            "summary": "Beliefs inform the behavior of forward-thinking agents in complex\nenvironments. Recently, sequential Bayesian inference has emerged as a\nmechanism to study belief formation among agents adapting to dynamical\nconditions. However, we lack critical theory to explain how preferences evolve\nin cases of simple agent interactions. In this paper, we derive a Gaussian,\npairwise agent interaction model to study how preferences converge when driven\nby observation of each other's behaviors. We show that the dynamics of\nconvergence resemble an Ornstein-Uhlenbeck process, a common model in\nnonequilibrium stochastic dynamics. Using standard analytical and computational\ntechniques, we find that the hyperprior magnitudes, representing the learning\ntime, determine the convergence value and the asymptotic entropy of the\npreferences across pairs of agents. We also show that the dynamical variance in\npreferences is characterized by a relaxation time $t^\\star$, and compute its\nasymptotic upper bound. This formulation enhances the existing toolkit for\nmodeling stochastic, interactive agents by formalizing leading theories in\nlearning theory, and builds towards more comprehensive models of open problems\nin principal-agent and market theory.",
            "author": [
                "Jordan T Kemp",
                "Max-Olivier Hongler",
                "Olivier Gallay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02899v2",
                "http://arxiv.org/pdf/2311.02899v2"
            ],
            "primary_category": "nlin.AO",
            "category": [
                "nlin.AO",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02892v1",
            "title": "Human as Points: Explicit Point-based 3D Human Reconstruction from\n  Single-view RGB Images",
            "updated": "2023-11-06T05:52:29Z",
            "published": "2023-11-06T05:52:29Z",
            "summary": "The latest trends in the research field of single-view human reconstruction\ndevote to learning deep implicit functions constrained by explicit body shape\npriors. Despite the remarkable performance improvements compared with\ntraditional processing pipelines, existing learning approaches still show\ndifferent aspects of limitations in terms of flexibility, generalizability,\nrobustness, and/or representation capability. To comprehensively address the\nabove issues, in this paper, we investigate an explicit point-based human\nreconstruction framework called HaP, which adopts point clouds as the\nintermediate representation of the target geometric structure. Technically, our\napproach is featured by fully-explicit point cloud estimation, manipulation,\ngeneration, and refinement in the 3D geometric space, instead of an implicit\nlearning process that can be ambiguous and less controllable. The overall\nworkflow is carefully organized with dedicated designs of the corresponding\nspecialized learning components as well as processing procedures. Extensive\nexperiments demonstrate that our framework achieves quantitative performance\nimprovements of 20% to 40% over current state-of-the-art methods, and better\nqualitative results. Our promising results may indicate a paradigm rollback to\nthe fully-explicit and geometry-centric algorithm design, which enables to\nexploit various powerful point cloud modeling architectures and processing\ntechniques. We will make our code and data publicly available at\nhttps://github.com/yztang4/HaP.",
            "author": [
                "Yingzhi Tang",
                "Qijian Zhang",
                "Junhui Hou",
                "Yebin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02892v1",
                "http://arxiv.org/pdf/2311.02892v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02888v1",
            "title": "Deciphering core-exciton dynamics in CaF$_2$ with attosecond\n  spectroscopy",
            "updated": "2023-11-06T05:39:37Z",
            "published": "2023-11-06T05:39:37Z",
            "summary": "Core excitons in solids have garnered increasing interest, yet their behavior\nand decay mechanisms are not fully understood. Here, we use attosecond extreme\nultraviolet (XUV) transient absorption spectroscopy, performed with a broadband\n25-45 eV sub-fs XUV pump pulse and a 500-1000 nm sub 5 fs near-infrared (NIR)\nsupercontinuum probe pulse to monitor the excitation, dynamics, and decay of\ncore excitons in CaF$_2$ at the Ca$^{2+}$ M$_{2,3}$ edge. The XUV pulses are\nused to excite core excitons in CaF$_2$ based around the Ca$^{2+}$ and the\npolarization of the medium is subsequently perturbed by the time-delayed NIR\npulses to measure the spectral changes and decays. A number of features are\nidentified in the transient absorption spectrum, which suggest transfer between\nexcitonic states, Stark shifts, and the emergence of light-induced states. We\nfind that various core excitons identified exhibit coherence lifetimes spanning\n3-7 fs. Furthermore, a NIR-intensity-dependent analysis finds a negative\ncorrelation with the coherence lifetime of various identified excitonic\nfeatures, supporting a phonon-mediated mechanism as responsible for the core\nexciton decoherence. We present a computational band structure projection\nanalysis strategy to estimate the orbital structure of the core excitons and\ndetermine which core excitonic transitions should be allowed by selection rules\nwith the probe beam. This strategy is found to successfully describe the\nobserved spectroscopic data. The outlined joint spectroscopic and computational\ninvestigation of core excitons is a powerful technique that explains the\ncomplex behavior of core excitons in solid-state materials.",
            "author": [
                "Rafael Quintero-Bermudez Stephen R. Leone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02888v1",
                "http://arxiv.org/pdf/2311.02888v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02887v1",
            "title": "Stacked Autoencoder Based Feature Extraction and Superpixel Generation\n  for Multifrequency PolSAR Image Classification",
            "updated": "2023-11-06T05:37:03Z",
            "published": "2023-11-06T05:37:03Z",
            "summary": "In this paper we are proposing classification algorithm for multifrequency\nPolarimetric Synthetic Aperture Radar (PolSAR) image. Using PolSAR\ndecomposition algorithms 33 features are extracted from each frequency band of\nthe given image. Then, a two-layer autoencoder is used to reduce the\ndimensionality of input feature vector while retaining useful features of the\ninput. This reduced dimensional feature vector is then applied to generate\nsuperpixels using simple linear iterative clustering (SLIC) algorithm. Next, a\nrobust feature representation is constructed using both pixel as well as\nsuperpixel information. Finally, softmax classifier is used to perform\nclassification task. The advantage of using superpixels is that it preserves\nspatial information between neighbouring PolSAR pixels and therefore minimises\nthe effect of speckle noise during classification. Experiments have been\nconducted on Flevoland dataset and the proposed method was found to be superior\nto other methods available in the literature.",
            "author": [
                "Tushar Gadhiya",
                "Sumanth Tangirala",
                "Anil K. Roy"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-030-34872-4_37",
                "http://arxiv.org/abs/2311.02887v1",
                "http://arxiv.org/pdf/2311.02887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03411v1",
            "title": "ViDa: Visualizing DNA hybridization trajectories with\n  biophysics-informed deep graph embeddings",
            "updated": "2023-11-06T05:27:29Z",
            "published": "2023-11-06T05:27:29Z",
            "summary": "Visualization tools can help synthetic biologists and molecular programmers\nunderstand the complex reactive pathways of nucleic acid reactions, which can\nbe designed for many potential applications and can be modelled using a\ncontinuous-time Markov chain (CTMC). Here we present ViDa, a new visualization\napproach for DNA reaction trajectories that uses a 2D embedding of the\nsecondary structure state space underlying the CTMC model. To this end, we\nintegrate a scattering transform of the secondary structure adjacency, a\nvariational autoencoder, and a nonlinear dimensionality reduction method. We\naugment the training loss with domain-specific supervised terms that capture\nboth thermodynamic and kinetic features. We assess ViDa on two well-studied DNA\nhybridization reactions. Our results demonstrate that the domain-specific\nfeatures lead to significant quality improvements over the state-of-the-art in\nDNA state space visualization, successfully separating different folding\npathways and thus providing useful insights into dominant reaction mechanisms.",
            "author": [
                "Chenwei Zhang",
                "Jordan Lovrod",
                "Boyan Beronov",
                "Khanh Dao Duc",
                "Anne Condon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03411v1",
                "http://arxiv.org/pdf/2311.03411v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02883v1",
            "title": "SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data",
            "updated": "2023-11-06T05:24:06Z",
            "published": "2023-11-06T05:24:06Z",
            "summary": "Text-to-SQL aims to automate the process of generating SQL queries on a\ndatabase from natural language text. In this work, we propose \"SQLPrompt\",\ntailored to improve the few-shot prompting capabilities of Text-to-SQL for\nLarge Language Models (LLMs). Our methods include innovative prompt design,\nexecution-based consistency decoding strategy which selects the SQL with the\nmost consistent execution outcome among other SQL proposals, and a method that\naims to improve performance by diversifying the SQL proposals during\nconsistency selection with different prompt designs (\"MixPrompt\") and\nfoundation models (\"MixLLMs\"). We show that \\emph{SQLPrompt} outperforms\nprevious approaches for in-context learning with few labeled data by a large\nmargin, closing the gap with finetuning state-of-the-art with thousands of\nlabeled data.",
            "author": [
                "Ruoxi Sun",
                "Sercan \u00d6. Arik",
                "Rajarishi Sinha",
                "Hootan Nakhost",
                "Hanjun Dai",
                "Pengcheng Yin",
                "Tomas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02883v1",
                "http://arxiv.org/pdf/2311.02883v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02881v1",
            "title": "Fluctuation in the Fidelity of Information Recovery from Hawking\n  Radiation",
            "updated": "2023-11-06T05:21:04Z",
            "published": "2023-11-06T05:21:04Z",
            "summary": "The interior of a pure-state black hole is known to be reconstructed from the\nPetz map by collecting a sufficiently large amount of the emitted Hawking\nradiation. This was established based on the Euclidean replica wormhole, which\ncomes from an ensemble averaging over gravitational theories. On the other\nhand, this means that the Page curve and the interior reconstruction are both\nensemble averages; thus, there is a possibility of large errors. In the\nprevious study \\cite{Bousso:2023efc}, it was shown that the entropy of the\nHawking radiation has fluctuation of order $e^{-S_{\\mathbf{BH}}}$, thus is\ntypical in the ensemble. In the present article, we show that the fluctuations\nof the relative entropy difference in the encoding map and the entanglement\nfidelity of the Petz map are both suppressed by $e^{-S_{\\mathbf{BH}}}$ compared\nto the signals, establishing the typicality in the ensemble. In addition, we\nalso compute the entanglement loss of the encoding map.",
            "author": [
                "Masamichi Miyaji",
                "Kazuyoshi Yano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02881v1",
                "http://arxiv.org/pdf/2311.02881v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.stat-mech",
                "gr-qc",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02880v1",
            "title": "MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for\n  Traffic Forecast via Structural Entropy Optimization",
            "updated": "2023-11-06T05:19:06Z",
            "published": "2023-11-06T05:19:06Z",
            "summary": "Traffic forecasting is a complex multivariate time-series regression task of\nparamount importance for traffic management and planning. However, existing\napproaches often struggle to model complex multi-range dependencies using local\nspatiotemporal features and road network hierarchical knowledge. To address\nthis, we propose MultiSPANS. First, considering that an individual recording\npoint cannot reflect critical spatiotemporal local patterns, we design\nmulti-filter convolution modules for generating informative ST-token embeddings\nto facilitate attention computation. Then, based on ST-token and\nspatial-temporal position encoding, we employ the Transformers to capture\nlong-range temporal and spatial dependencies. Furthermore, we introduce\nstructural entropy theory to optimize the spatial attention mechanism.\nSpecifically, The structural entropy minimization algorithm is used to generate\noptimal road network hierarchies, i.e., encoding trees. Based on this, we\npropose a relative structural entropy-based position encoding and a multi-head\nattention masking scheme based on multi-layer encoding trees. Extensive\nexperiments demonstrate the superiority of the presented framework over several\nstate-of-the-art methods in real-world traffic datasets, and the longer\nhistorical windows are effectively utilized. The code is available at\nhttps://github.com/SELGroup/MultiSPANS.",
            "author": [
                "Dongcheng Zou",
                "Senzhang Wang",
                "Xuefeng Li",
                "Hao Peng",
                "Yuandong Wang",
                "Chunyang Liu",
                "Kehua Sheng",
                "Bo Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02880v1",
                "http://arxiv.org/pdf/2311.02880v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02878v1",
            "title": "Trajectory Extending Kinetic Monte Carlo Simulations to Evaluate Pure\n  and Gas Mixture Diffusivities through a Dense Polymeric Membrane",
            "updated": "2023-11-06T05:15:38Z",
            "published": "2023-11-06T05:15:38Z",
            "summary": "With renewed interest in CO2 separations, carbon molecular sieving (CMS)\nmembrane performance evaluation requires diffusion coefficients as inputs to\nhave reliable estimate of the permeability. An optimal material is desired to\nhave both high selectivity and permeability. Gases diffusing through dense, CMS\nand polymeric membranes experience extended sub-diffusive regimes which hinders\nreliable extraction of diffusion coefficients from mean squared displacement\ndata. We improve the sampling of the diffusive landscape by implementing the\ntrajectory extending kinetic Monte Carlo (TEKMC) technique to efficiently\nextend MD trajectories from ns to {\\mu}s timescales. The obtained\nself-diffusion coefficient of pure CO2 in CMS membranes derived from\n6FDA/BPDA-DAM precursor polymer melt is found in agreement with previous\nexperimental findings. We also extend the TEKMC algorithm to evaluate the\nmixture diffusivities in binary mixtures to determine the permselectivity of\nCO2 in CH4 and N2 mixtures. The mixture diffusion coefficient of CO2 ranges\nfrom 1.3-7 x 10^{-6} cm6{2}s^{-1} in binary mixture CO2:CH4 which is\nsignificantly higher than the pure gas diffusion coefficient. Robeson plot\ncomparisons show that the permselectivity obtained from pure gas diffusion data\nare significantly lower than that predicted using mixture diffusivity data.\nSpecifically in the case of the CO2:N2 mixture we find that using mixture\ndiffusivities led to permeslectivites lying above the Robeson limit\nhighlighting the importance of using mixture diffusivity data for an accurate\nevaluation of the membrane performance. Combined with gas solubilities obtained\nfrom grand-canonical Monte Carlo simulations, our work shows that simulations\nwith the TEKMC method can be used to reliably evaluate the performance of\nmaterials for gas separations.",
            "author": [
                "Subhadeep Dasgupta",
                "Arun K. S",
                "K. Ganapathy Ayappa",
                "Prabal K. Maiti"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acs.jpcb.3c05661",
                "http://arxiv.org/abs/2311.02878v1",
                "http://arxiv.org/pdf/2311.02878v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.stat-mech",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02877v4",
            "title": "Inner-IoU: More Effective Intersection over Union Loss with Auxiliary\n  Bounding Box",
            "updated": "2023-11-14T09:49:38Z",
            "published": "2023-11-06T05:14:24Z",
            "summary": "With the rapid development of detectors, Bounding Box Regression (BBR) loss\nfunction has constantly updated and optimized. However, the existing IoU-based\nBBR still focus on accelerating convergence by adding new loss terms, ignoring\nthe limitations of IoU loss term itself. Although theoretically IoU loss can\neffectively describe the state of bounding box regression,in practical\napplications, it cannot adjust itself according to different detectors and\ndetection tasks, and does not have strong generalization. Based on the above,\nwe first analyzed the BBR model and concluded that distinguishing different\nregression samples and using different scales of auxiliary bounding boxes to\ncalculate losses can effectively accelerate the bounding box regression\nprocess. For high IoU samples, using smaller auxiliary bounding boxes to\ncalculate losses can accelerate convergence, while larger auxiliary bounding\nboxes are suitable for low IoU samples. Then, we propose Inner-IoU loss, which\ncalculates IoU loss through auxiliary bounding boxes. For different datasets\nand detectors, we introduce a scaling factor ratio to control the scale size of\nthe auxiliary bounding boxes for calculating losses. Finally, integrate\nInner-IoU into the existing IoU-based loss functions for simulation and\ncomparative experiments. The experiment result demonstrate a further\nenhancement in detection performance with the utilization of the method\nproposed in this paper, verifying the effectiveness and generalization ability\nof Inner-IoU loss. Code is available at\nhttps://github.com/malagoutou/Inner-IoU.",
            "author": [
                "Hao Zhang",
                "Cong Xu",
                "Shuaijie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02877v4",
                "http://arxiv.org/pdf/2311.02877v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14690v1",
            "title": "Evolutionary City: Towards a Flexible, Agile and Symbiotic System",
            "updated": "2023-11-06T05:10:33Z",
            "published": "2023-11-06T05:10:33Z",
            "summary": "Urban growth sometimes leads to rigid infrastructure that struggles to adapt\nto changing demand. This paper introduces a novel approach, aiming to enable\ncities to evolve and respond more effectively to such dynamic demand. It\nidentifies the limitations arising from the complexity and inflexibility of\nexisting urban systems. A framework is presented for enhancing the city's\nadaptability perception through advanced sensing technologies, conducting\nparallel simulation via graph-based techniques, and facilitating autonomous\ndecision-making across domains through decentralized and autonomous\norganization and operation. Notably, a symbiotic mechanism is employed to\nimplement these technologies practically, thereby making urban management more\nagile and responsive. In the case study, we explore how this approach can\noptimize traffic flow by adjusting lane allocations. This case not only\nenhances traffic efficiency but also reduces emissions. The proposed\nevolutionary city offers a new perspective on sustainable urban development,\nhighliting the importance of integrated intelligence within urban systems.",
            "author": [
                "Xi Chen",
                "Wei Hu",
                "Jingru Yu",
                "Ding Wang",
                "Shengyue Yao",
                "Yilun Lin",
                "Fei-Yue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14690v1",
                "http://arxiv.org/pdf/2311.14690v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02874v1",
            "title": "Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series",
            "updated": "2023-11-06T05:01:58Z",
            "published": "2023-11-06T05:01:58Z",
            "summary": "We present a method for fast biomedical image atlas construction using neural\nfields. Atlases are key to biomedical image analysis tasks, yet conventional\nand deep network estimation methods remain time-intensive. In this preliminary\nwork, we frame subject-specific atlas building as learning a neural field of\ndeformable spatiotemporal observations. We apply our method to learning\nsubject-specific atlases and motion stabilization of dynamic BOLD MRI\ntime-series of fetuses in utero. Our method yields high-quality atlases of\nfetal BOLD time-series with $\\sim$5-7$\\times$ faster convergence compared to\nexisting work. While our method slightly underperforms well-tuned baselines in\nterms of anatomical overlap, it estimates templates significantly faster, thus\nenabling rapid processing and stabilization of large databases of 4D dynamic\nMRI acquisitions. Code is available at\nhttps://github.com/Kidrauh/neural-atlasing",
            "author": [
                "Zeen Chi",
                "Zhongxiao Cong",
                "Clinton J. Wang",
                "Yingcheng Liu",
                "Esra Abaci Turk",
                "P. Ellen Grant",
                "S. Mazdak Abulnaga",
                "Polina Golland",
                "Neel Dey"
            ],
            "link": [
                "http://dx.doi.org/10.48550/arXiv.2311.02874",
                "http://arxiv.org/abs/2311.02874v1",
                "http://arxiv.org/pdf/2311.02874v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02873v1",
            "title": "OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D\n  Data",
            "updated": "2023-11-06T05:00:00Z",
            "published": "2023-11-06T05:00:00Z",
            "summary": "This work presents OVIR-3D, a straightforward yet effective method for\nopen-vocabulary 3D object instance retrieval without using any 3D data for\ntraining. Given a language query, the proposed method is able to return a\nranked set of 3D object instance segments based on the feature similarity of\nthe instance and the text query. This is achieved by a multi-view fusion of\ntext-aligned 2D region proposals into 3D space, where the 2D region proposal\nnetwork could leverage 2D datasets, which are more accessible and typically\nlarger than 3D datasets. The proposed fusion process is efficient as it can be\nperformed in real-time for most indoor 3D scenes and does not require\nadditional training in 3D space. Experiments on public datasets and a real\nrobot show the effectiveness of the method and its potential for applications\nin robot navigation and manipulation.",
            "author": [
                "Shiyang Lu",
                "Haonan Chang",
                "Eric Pu Jing",
                "Abdeslam Boularias",
                "Kostas Bekris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02873v1",
                "http://arxiv.org/pdf/2311.02873v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02872v1",
            "title": "FocusTune: Tuning Visual Localization through Focus-Guided Sampling",
            "updated": "2023-11-06T04:58:47Z",
            "published": "2023-11-06T04:58:47Z",
            "summary": "We propose FocusTune, a focus-guided sampling technique to improve the\nperformance of visual localization algorithms. FocusTune directs a scene\ncoordinate regression model towards regions critical for 3D point triangulation\nby exploiting key geometric constraints. Specifically, rather than uniformly\nsampling points across the image for training the scene coordinate regression\nmodel, we instead re-project 3D scene coordinates onto the 2D image plane and\nsample within a local neighborhood of the re-projected points. While our\nproposed sampling strategy is generally applicable, we showcase FocusTune by\nintegrating it with the recently introduced Accelerated Coordinate Encoding\n(ACE) model. Our results demonstrate that FocusTune both improves or matches\nstate-of-the-art performance whilst keeping ACE's appealing low storage and\ncompute requirements, for example reducing translation error from 25 to 19 and\n17 to 15 cm for single and ensemble models, respectively, on the Cambridge\nLandmarks dataset. This combination of high performance and low compute and\nstorage requirements is particularly promising for applications in areas like\nmobile robotics and augmented reality. We made our code available at\n\\url{https://github.com/sontung/focus-tune}.",
            "author": [
                "Son Tung Nguyen",
                "Alejandro Fontan",
                "Michael Milford",
                "Tobias Fischer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02872v1",
                "http://arxiv.org/pdf/2311.02872v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02869v4",
            "title": "Lightweight equivariant interaction graph neural network for accurate\n  and efficient interatomic potential and force predictions",
            "updated": "2023-11-17T15:36:42Z",
            "published": "2023-11-06T04:49:09Z",
            "summary": "In modern computational materials science, deep learning has shown the\ncapability to predict interatomic potentials, thereby supporting and\naccelerating conventional simulations. However, existing models typically\nsacrifice either accuracy or efficiency. Moreover, lightweight models are\nhighly demanded for offering simulating systems on a considerably larger scale\nat reduced computational costs. A century ago, Felix Bloch demonstrated how\nleveraging the equivariance of the translation operation on a crystal lattice\n(with geometric symmetry) could significantly reduce the computational cost of\ndetermining wavefunctions and accurately calculate material properties. Here,\nwe introduce a lightweight equivariant interaction graph neural network\n(LEIGNN) that can enable accurate and efficient interatomic potential and force\npredictions in crystals. Rather than relying on higher-order representations,\nLEIGNN employs a scalar-vector dual representation to encode equivariant\nfeatures. By extracting both local and global structures from vector\nrepresentations and learning geometric symmetry information, our model remains\nlightweight while ensuring prediction accuracy and robustness through the\nequivariance. Our results show that LEIGNN consistently outperforms the\nprediction performance of the representative baselines and achieves significant\nefficiency across diverse datasets, which include catalysts, molecules, and\norganic isomers. Finally, to further validate the predicted interatomic\npotentials from our model, we conduct classical molecular dynamics (MD) and ab\ninitio MD simulation across various systems, including solid, liquid, and gas.\nIt is found that LEIGNN can achieve the accuracy of ab initio MD and retain the\ncomputational efficiency of classical MD across all examined systems,\ndemonstrating its accuracy, efficiency, and universality.",
            "author": [
                "Ziduo Yang",
                "Xian Wang",
                "Yifan Li",
                "Qiujie Lv",
                "Calvin Yu-Chian Chen",
                "Lei Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02869v4",
                "http://arxiv.org/pdf/2311.02869v4"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02863v1",
            "title": "Temporal Shift -- Multi-Objective Loss Function for Improved Anomaly\n  Fall Detection",
            "updated": "2023-11-06T04:29:12Z",
            "published": "2023-11-06T04:29:12Z",
            "summary": "Falls are a major cause of injuries and deaths among older adults worldwide.\nAccurate fall detection can help reduce potential injuries and additional\nhealth complications. Different types of video modalities can be used in a home\nsetting to detect falls, including RGB, Infrared, and Thermal cameras. Anomaly\ndetection frameworks using autoencoders and their variants can be used for fall\ndetection due to the data imbalance that arises from the rarity and diversity\nof falls. However, the use of reconstruction error in autoencoders can limit\nthe application of networks' structures that propagate information. In this\npaper, we propose a new multi-objective loss function called Temporal Shift,\nwhich aims to predict both future and reconstructed frames within a window of\nsequential frames. The proposed loss function is evaluated on a\nsemi-naturalistic fall detection dataset containing multiple camera modalities.\nThe autoencoders were trained on normal activities of daily living (ADL)\nperformed by older adults and tested on ADLs and falls performed by young\nadults. Temporal shift shows significant improvement to a baseline 3D\nConvolutional autoencoder, an attention U-Net CAE, and a multi-modal neural\nnetwork. The greatest improvement was observed in an attention U-Net model\nimproving by 0.20 AUC ROC for a single camera when compared to reconstruction\nalone. With significant improvement across different models, this approach has\nthe potential to be widely adopted and improve anomaly detection capabilities\nin other settings besides fall detection.",
            "author": [
                "Stefan Denkovski",
                "Shehroz S. Khan",
                "Alex Mihailidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02863v1",
                "http://arxiv.org/pdf/2311.02863v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02861v1",
            "title": "Less than One-shot: Named Entity Recognition via Extremely Weak\n  Supervision",
            "updated": "2023-11-06T04:20:42Z",
            "published": "2023-11-06T04:20:42Z",
            "summary": "We study the named entity recognition (NER) problem under the extremely weak\nsupervision (XWS) setting, where only one example entity per type is given in a\ncontext-free way. While one can see that XWS is lighter than one-shot in terms\nof the amount of supervision, we propose a novel method X-NER that can\noutperform the state-of-the-art one-shot NER methods. We first mine entity\nspans that are similar to the example entities from an unlabelled training\ncorpus. Instead of utilizing entity span representations from language models,\nwe find it more effective to compare the context distributions before and after\nthe span is replaced by the entity example. We then leverage the top-ranked\nspans as pseudo-labels to train an NER tagger. Extensive experiments and\nanalyses on 4 NER datasets show the superior end-to-end NER performance of\nX-NER, outperforming the state-of-the-art few-shot methods with 1-shot\nsupervision and ChatGPT annotations significantly. Finally, our X-NER possesses\nseveral notable properties, such as inheriting the cross-lingual abilities of\nthe underlying language models.",
            "author": [
                "Letian Peng",
                "Zihan Wang",
                "Jingbo Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02861v1",
                "http://arxiv.org/pdf/2311.02861v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02857v1",
            "title": "Bottomonia in quark-antiquark confining potential",
            "updated": "2023-11-06T04:18:02Z",
            "published": "2023-11-06T04:18:02Z",
            "summary": "In this paper, we comprehensively explore bottomonia mass spectra and their\ndecay properties by solving the non-relativistic Schrodinger wave equation\nnumerically with approximate quark-antiquark potential form. We also\nincorporate spin-dependent terms - spin-spin, spin-orbit, and tensor terms to\nremove mass degeneracy and to obtain excited states ($nS, nP, nD, nF, n = 1, 2,\n3, 4, 5$) mass spectra. By using Van Royen - Weisskopf formula, we investigate\nleptonic decay constants, di-leptonic, di-gamma, tri-gamma, di-gluon decay\nwidths and also incorporate first-order radiative corrections. We also computed\nradiative transition widths, which give a better insight into the\nnon-perturbative aspects of QCD. The present results for mass spectroscopy and\ndecay properties are in tune with available experimental values and other\ntheoretical predictions. Our results may provide better insight to upcoming\nexperimental information in the near future.",
            "author": [
                "Ritu Garg",
                "K. K Vishwakarma",
                "Alka Upadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02857v1",
                "http://arxiv.org/pdf/2311.02857v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02855v1",
            "title": "Neural-based Compression Scheme for Solar Image Data",
            "updated": "2023-11-06T04:13:58Z",
            "published": "2023-11-06T04:13:58Z",
            "summary": "Studying the solar system and especially the Sun relies on the data gathered\ndaily from space missions. These missions are data-intensive and compressing\nthis data to make them efficiently transferable to the ground station is a\ntwofold decision to make. Stronger compression methods, by distorting the data,\ncan increase data throughput at the cost of accuracy which could affect\nscientific analysis of the data. On the other hand, preserving subtle details\nin the compressed data requires a high amount of data to be transferred,\nreducing the desired gains from compression. In this work, we propose a neural\nnetwork-based lossy compression method to be used in NASA's data-intensive\nimagery missions. We chose NASA's SDO mission which transmits 1.4 terabytes of\ndata each day as a proof of concept for the proposed algorithm. In this work,\nwe propose an adversarially trained neural network, equipped with local and\nnon-local attention modules to capture both the local and global structure of\nthe image resulting in a better trade-off in rate-distortion (RD) compared to\nconventional hand-engineered codecs. The RD variational autoencoder used in\nthis work is jointly trained with a channel-dependent entropy model as a shared\nprior between the analysis and synthesis transforms to make the entropy coding\nof the latent code more effective. Our neural image compression algorithm\noutperforms currently-in-use and state-of-the-art codecs such as JPEG and\nJPEG-2000 in terms of the RD performance when compressing extreme-ultraviolet\n(EUV) data. As a proof of concept for use of this algorithm in SDO data\nanalysis, we have performed coronal hole (CH) detection using our compressed\nimages, and generated consistent segmentations, even at a compression rate of\n$\\sim0.1$ bits per pixel (compared to 8 bits per pixel on the original data)\nusing EUV data from SDO.",
            "author": [
                "Ali Zafari",
                "Atefeh Khoshkhahtinat",
                "Jeremy A. Grajeda",
                "Piyush M. Mehta",
                "Nasser M. Nasrabadi",
                "Laura E. Boucheron",
                "Barbara J. Thompson",
                "Michael S. F. Kirk",
                "Daniel da Silva"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TAES.2023.3332056",
                "http://arxiv.org/abs/2311.02855v1",
                "http://arxiv.org/pdf/2311.02855v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03408v1",
            "title": "Training Multi-layer Neural Networks on Ising Machine",
            "updated": "2023-11-06T04:09:15Z",
            "published": "2023-11-06T04:09:15Z",
            "summary": "As a dedicated quantum device, Ising machines could solve large-scale binary\noptimization problems in milliseconds. There is emerging interest in utilizing\nIsing machines to train feedforward neural networks due to the prosperity of\ngenerative artificial intelligence. However, existing methods can only train\nsingle-layer feedforward networks because of the complex nonlinear network\ntopology. This paper proposes an Ising learning algorithm to train quantized\nneural network (QNN), by incorporating two essential techinques, namely binary\nrepresentation of topological network and order reduction of loss function. As\nfar as we know, this is the first algorithm to train multi-layer feedforward\nnetworks on Ising machines, providing an alternative to gradient-based\nbackpropagation. Firstly, training QNN is formulated as a quadratic constrained\nbinary optimization (QCBO) problem by representing neuron connection and\nactivation function as equality constraints. All quantized variables are\nencoded by binary bits based on binary encoding protocol. Secondly, QCBO is\nconverted to a quadratic unconstrained binary optimization (QUBO) problem, that\ncan be efficiently solved on Ising machines. The conversion leverages both\npenalty function and Rosenberg order reduction, who together eliminate equality\nconstraints and reduce high-order loss function into a quadratic one. With some\nassumptions, theoretical analysis shows the space complexity of our algorithm\nis $\\mathcal{O}(H^2L + HLN\\log H)$, quantifying the required number of Ising\nspins. Finally, the algorithm effectiveness is validated with a simulated Ising\nmachine on MNIST dataset. After annealing 700 ms, the classification accuracy\nachieves 98.3%. Among 100 runs, the success probability of finding the optimal\nsolution is 72%. Along with the increasing number of spins on Ising machine,\nour algorithm has the potential to train deeper neural networks.",
            "author": [
                "Xujie Song",
                "Tong Liu",
                "Shengbo Eben Li",
                "Jingliang Duan",
                "Wenxuan Wang",
                "Keqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03408v1",
                "http://arxiv.org/pdf/2311.03408v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02854v1",
            "title": "A distributed multi-GPU ab initio density matrix renormalization group\n  algorithm with applications to the P-cluster of nitrogenase",
            "updated": "2023-11-06T04:01:26Z",
            "published": "2023-11-06T04:01:26Z",
            "summary": "The presence of many degenerate $d/f$ orbitals makes polynuclear transition\nmetal compounds such as iron-sulfur clusters in nitrogenase challenging for\nstate-of-the-art quantum chemistry methods. To address this challenge, we\npresent the first distributed multi-GPU (Graphics Processing Unit) ab initio\ndensity matrix renormalization (DMRG) algorithm, suitable for modern\nhigh-performance computing (HPC) infrastructures. The central idea is to\nparallelize the most computationally intensive part - the multiplication of\n$O(K^2)$ operators with a trial wavefunction, where $K$ is the number of\nspatial orbitals, by combining operator parallelism for distributing the\nworkload with a batched algorithm for performing contractions on GPU. With this\nnew implementation, we are able to reach an unprecedented accuracy (1\nmilli-Hartree per metal) for the ground-state energy of an active space model\n(114 electrons in 73 active orbitals) of the P-cluster with a bond dimension\n$D=14000$ on 48 GPUs (NVIDIA A100 80 GB SXM), which is nearly three times\nlarger than the bond dimensions reported in previous DMRG calculations for the\nsame system using only CPUs.",
            "author": [
                "Chunyang Xiang",
                "Weile Jia",
                "Wei-Hai Fang",
                "Zhendong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02854v1",
                "http://arxiv.org/pdf/2311.02854v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02853v1",
            "title": "Constraints on the Neutron-Star Structure from the Clocked X-Ray Burster\n  1RXS J180408.9$-$342058",
            "updated": "2023-11-06T03:48:26Z",
            "published": "2023-11-06T03:48:26Z",
            "summary": "Type-I X-ray bursts are rapid-brightening transient phenomena on the surfaces\nof accreting neutron stars (NSs). Some X-ray bursts, called {\\it clocked\nbursters}, exhibit regular behavior with similar light curve profiles in their\nburst sequences. The periodic nature of clocked bursters has the advantage of\nconstraining X-ray binary parameters and physics inside the NS. In the present\nstudy, we compute numerical models, based on different equations of state and\nNS masses, which are compared with the observation of a recently identified\nclocked burster, 1RXS J180408.9$-$342058. We find that the relation between\naccretion rate and recurrence time is highly sensitive to the NS mass and\nradius. We determine, in particular, that 1RXS J180408.9$-$342058 appears to\npossess a mass less than $1.7M_{\\odot}$ and favors a stiffer nuclear equation\nof state (with an NS radius $\\gtrsim12.7{\\rm km}$). Consequently, the\nobservations of this new clocked burster may provide additional constraints for\nprobing the structure of NSs.",
            "author": [
                "Akira Dohi",
                "Wataru Iwakiri",
                "Nobuya Nishimura",
                "Tsuneo Noda",
                "Shigehiro Nagataki",
                "Masa-aki Hashimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02853v1",
                "http://arxiv.org/pdf/2311.02853v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02851v1",
            "title": "Improving Machine Translation with Large Language Models: A Preliminary\n  Study with Cooperative Decoding",
            "updated": "2023-11-06T03:41:57Z",
            "published": "2023-11-06T03:41:57Z",
            "summary": "Contemporary translation engines built upon the encoder-decoder framework\nhave reached a high level of development, while the emergence of Large Language\nModels (LLMs) has disrupted their position by offering the potential for\nachieving superior translation quality. Therefore, it is crucial to understand\nin which scenarios LLMs outperform traditional NMT systems and how to leverage\ntheir strengths. In this paper, we first conduct a comprehensive analysis to\nassess the strengths and limitations of various commercial NMT systems and\nMT-oriented LLMs. Our findings indicate that neither NMT nor MT-oriented LLMs\nalone can effectively address all the translation issues, but MT-oriented LLMs\ncan serve as a promising complement to the NMT systems. Building upon these\ninsights, we explore hybrid methods and propose Cooperative Decoding (CoDec),\nwhich treats NMT systems as a pretranslation model and MT-oriented LLMs as a\nsupplemental solution to handle complex scenarios beyond the capability of NMT\nalone. The results on the WMT22 test sets and a newly collected test set\nWebCrawl demonstrate the effectiveness and efficiency of CoDec, highlighting\nits potential as a robust solution for combining NMT systems with MT-oriented\nLLMs in machine translation.",
            "author": [
                "Jiali Zeng",
                "Fandong Meng",
                "Yongjing Yin",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02851v1",
                "http://arxiv.org/pdf/2311.02851v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02849v2",
            "title": "Co-training and Co-distillation for Quality Improvement and Compression\n  of Language Models",
            "updated": "2023-11-07T18:41:55Z",
            "published": "2023-11-06T03:29:00Z",
            "summary": "Knowledge Distillation (KD) compresses computationally expensive pre-trained\nlanguage models (PLMs) by transferring their knowledge to smaller models,\nallowing their use in resource-constrained or real-time settings. However, most\nsmaller models fail to surpass the performance of the original larger model,\nresulting in sacrificing performance to improve inference speed. To address\nthis issue, we propose Co-Training and Co-Distillation (CTCD), a novel\nframework that improves performance and inference speed together by co-training\ntwo models while mutually distilling knowledge. The CTCD framework successfully\nachieves this based on two significant findings: 1) Distilling knowledge from\nthe smaller model to the larger model during co-training improves the\nperformance of the larger model. 2) The enhanced performance of the larger\nmodel further boosts the performance of the smaller model. The CTCD framework\nshows promise as it can be combined with existing techniques like architecture\ndesign or data augmentation, replacing one-way KD methods, to achieve further\nperformance improvement. Extensive ablation studies demonstrate the\neffectiveness of CTCD, and the small model distilled by CTCD outperforms the\noriginal larger model by a significant margin of 1.66 on the GLUE benchmark.",
            "author": [
                "Hayeon Lee",
                "Rui Hou",
                "Jongpil Kim",
                "Davis Liang",
                "Hongbo Zhang",
                "Sung Ju Hwang",
                "Alexander Min"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02849v2",
                "http://arxiv.org/pdf/2311.02849v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02848v1",
            "title": "Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from\n  Monocular Video",
            "updated": "2023-11-06T03:26:43Z",
            "published": "2023-11-06T03:26:43Z",
            "summary": "In this paper, we present Consistent4D, a novel approach for generating 4D\ndynamic objects from uncalibrated monocular videos. Uniquely, we cast the\n360-degree dynamic object reconstruction as a 4D generation problem,\neliminating the need for tedious multi-view data collection and camera\ncalibration. This is achieved by leveraging the object-level 3D-aware image\ndiffusion model as the primary supervision signal for training Dynamic Neural\nRadiance Fields (DyNeRF). Specifically, we propose a Cascade DyNeRF to\nfacilitate stable convergence and temporal continuity under the supervision\nsignal which is discrete along the time axis. To achieve spatial and temporal\nconsistency, we further introduce an Interpolation-driven Consistency Loss. It\nis optimized by minimizing the discrepancy between rendered frames from DyNeRF\nand interpolated frames from a pre-trained video interpolation model. Extensive\nexperiments show that our Consistent4D can perform competitively to prior art\nalternatives, opening up new possibilities for 4D dynamic object generation\nfrom monocular videos, whilst also demonstrating advantage for conventional\ntext-to-3D generation tasks. Our project page is\nhttps://consistent4d.github.io/.",
            "author": [
                "Yanqin Jiang",
                "Li Zhang",
                "Jin Gao",
                "Weimin Hu",
                "Yao Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02848v1",
                "http://arxiv.org/pdf/2311.02848v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14689v1",
            "title": "Analyze Factors Influencing Drivers' Cell Phone Online Ride-hailing\n  Software Using While driving: A Case Study in China",
            "updated": "2023-11-06T03:17:02Z",
            "published": "2023-11-06T03:17:02Z",
            "summary": "The road safety of traffic is greatly affected by the driving performance of\nonline ride-hailing, which has become an increasingly popular travel option for\nmany people. Little attention has been paid to the fact that the use of cell\nphone online ride-hailing software by drivers to accept orders while driving is\none of the causes of traffic accidents involving online ride-hailing. This\npaper, adopting the extended theory of planned behavior, investigates the\nfactors that factors influencing the behavior of Chinese online ride-hailing\ndrivers cell phone ride-hailing software usage to accept orders while driving.\nResults showed that attitudes, subjective norms, and perceived behavioral\ncontrol have a significant and positive effect on behavioral intentions.\nBehavioral intention is most strongly influenced by attitude. There is no\ndirect and significant impact of group norms on behavioral intention.\nNonetheless, group norms exert a substantial and beneficial influence on\nattitude, subjective norms, and perceived behavioral control. This study has\ndiscovered, through a mediating effect test, that attitude, subjective norm,\nand perceived behavioral control play a mediating and moderating role in the\nimpact of group norm on behavioral intention. These findings can offer\ntheoretical guidance to relevant departments in developing effective measures\nfor promoting safe driving among online ride-hailing drivers.",
            "author": [
                "Xiangnan Song",
                "Xianghong Li",
                "Kai Yin",
                "Huimin Qi",
                "Xufei Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14689v1",
                "http://arxiv.org/pdf/2311.14689v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "F.1.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04234v1",
            "title": "Leveraging sinusoidal representation networks to predict fMRI signals\n  from EEG",
            "updated": "2023-11-06T03:16:18Z",
            "published": "2023-11-06T03:16:18Z",
            "summary": "In modern neuroscience, functional magnetic resonance imaging (fMRI) has been\na crucial and irreplaceable tool that provides a non-invasive window into the\ndynamics of whole-brain activity. Nevertheless, fMRI is limited by hemodynamic\nblurring as well as high cost, immobility, and incompatibility with metal\nimplants. Electroencephalography (EEG) is complementary to fMRI and can\ndirectly record the cortical electrical activity at high temporal resolution,\nbut has more limited spatial resolution and is unable to recover information\nabout deep subcortical brain structures. The ability to obtain fMRI information\nfrom EEG would enable cost-effective, imaging across a wider set of brain\nregions. Further, beyond augmenting the capabilities of EEG, cross-modality\nmodels would facilitate the interpretation of fMRI signals. However, as both\nEEG and fMRI are high-dimensional and prone to artifacts, it is currently\nchallenging to model fMRI from EEG. To address this challenge, we propose a\nnovel architecture that can predict fMRI signals directly from multi-channel\nEEG without explicit feature engineering. Our model achieves this by\nimplementing a Sinusoidal Representation Network (SIREN) to learn frequency\ninformation in brain dynamics from EEG, which serves as the input to a\nsubsequent encoder-decoder to effectively reconstruct the fMRI signal from a\nspecific brain region. We evaluate our model using a simultaneous EEG-fMRI\ndataset with 8 subjects and investigate its potential for predicting\nsubcortical fMRI signals. The present results reveal that our model outperforms\na recent state-of-the-art model, and indicates the potential of leveraging\nperiodic activation functions in deep neural networks to model functional\nneuroimaging data.",
            "author": [
                "Yamin Li",
                "Ange Lou",
                "Catie Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04234v1",
                "http://arxiv.org/pdf/2311.04234v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02840v1",
            "title": "Saturn: Efficient Multi-Large-Model Deep Learning",
            "updated": "2023-11-06T02:59:49Z",
            "published": "2023-11-06T02:59:49Z",
            "summary": "In this paper, we propose Saturn, a new data system to improve the efficiency\nof multi-large-model training (e.g., during model selection/hyperparameter\noptimization). We first identify three key interconnected systems challenges\nfor users building large models in this setting -- parallelism technique\nselection, distribution of GPUs over jobs, and scheduling. We then formalize\nthese as a joint problem, and build a new system architecture to tackle these\nchallenges simultaneously. Our evaluations show that our joint-optimization\napproach yields 39-49% lower model selection runtimes than typical current DL\npractice.",
            "author": [
                "Kabir Nagrecha",
                "Arun Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02840v1",
                "http://arxiv.org/pdf/2311.02840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02839v1",
            "title": "Cell-Probe Lower Bound for Accessible Interval Graphs",
            "updated": "2023-11-06T02:59:44Z",
            "published": "2023-11-06T02:59:44Z",
            "summary": "We spot a hole in the area of succinct data structures for graph classes from\na universe of size at most $n^n$. Very often, the input graph is labeled by the\nuser in an arbitrary and easy-to-use way, and the data structure for the graph\nrelabels the input graph in some way. For any access, the user needs to store\nthese labels or compute the new labels in an online manner. This might require\nmore bits than the information-theoretic minimum of the original graph class,\nhence, defeating the purpose of succinctness. Given this, the data structure\ndesigner must allow the user to access the data structure with the original\nlabels, i.e., relabeling is not allowed. We call such a graph data structure\n``accessible''. In this paper, we study the complexity of such accessible data\nstructures for interval graphs, a graph class with information-theoretic\nminimum less than $n\\log n$ bits.\n  - We formalize the concept of \"accessibility\" (which was implicitly assumed),\nand propose the \"universal interval representation\", for interval graphs.\n  - Any data structure for interval graphs in universal interval\nrepresentation, which supports both adjacency and degree query simultaneously\nwith time cost $t_1$ and $t_2$ respectively, must consume at least\n$\\log_2(n!)+n/(\\log n)^{O(t_1+t_2)}$ bits of space. This is also the first\nlower bound for graph classes with information-theoretic minimum less than\n$n\\log_2n$ bits.\n  - We provide efficient succinct data structures for interval graphs in\nuniversal interval representation supporting adjacency query and degree query\nindividually in constant time and space costs. Therefore, two upper bounds\ntogether with the lower bound show that the two elementary queries for interval\ngraphs are incompatible with each other in the context of succinct data\nstructure. To the best of our knowledge, this is the first proof of such\nincompatibility phenomenon.",
            "author": [
                "Sankardeep Chakraborty",
                "Christian Engels",
                "Seungbum Jo",
                "Mingmou Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02839v1",
                "http://arxiv.org/pdf/2311.02839v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "68P05, 68P30, 68Q17",
                "E.1; F.1.3; F.2.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02835v1",
            "title": "Flexible Multi-Generator Model with Fused Spatiotemporal Graph for\n  Trajectory Prediction",
            "updated": "2023-11-06T02:46:05Z",
            "published": "2023-11-06T02:46:05Z",
            "summary": "Trajectory prediction plays a vital role in automotive radar systems,\nfacilitating precise tracking and decision-making in autonomous driving.\nGenerative adversarial networks with the ability to learn a distribution over\nfuture trajectories tend to predict out-of-distribution samples, which\ntypically occurs when the distribution of forthcoming paths comprises a blend\nof various manifolds that may be disconnected. To address this issue, we\npropose a trajectory prediction framework, which can capture the social\ninteraction variations and model disconnected manifolds of pedestrian\ntrajectories. Our framework is based on a fused spatiotemporal graph to better\nmodel the complex interactions of pedestrians in a scene, and a multi-generator\narchitecture that incorporates a flexible generator selector network on\ngenerated trajectories to learn a distribution over multiple generators. We\nshow that our framework achieves state-of-the-art performance compared with\nseveral baselines on different challenging datasets.",
            "author": [
                "Peiyuan Zhu",
                "Fengxia Han",
                "Hao Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02835v1",
                "http://arxiv.org/pdf/2311.02835v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02832v1",
            "title": "Prioritized Propagation in Graph Neural Networks",
            "updated": "2023-11-06T02:38:35Z",
            "published": "2023-11-06T02:38:35Z",
            "summary": "Graph neural networks (GNNs) have recently received significant attention.\nLearning node-wise message propagation in GNNs aims to set personalized\npropagation steps for different nodes in the graph. Despite the success,\nexisting methods ignore node priority that can be reflected by node influence\nand heterophily. In this paper, we propose a versatile framework PPro, which\ncan be integrated with most existing GNN models and aim to learn prioritized\nnode-wise message propagation in GNNs. Specifically, the framework consists of\nthree components: a backbone GNN model, a propagation controller to determine\nthe optimal propagation steps for nodes, and a weight controller to compute the\npriority scores for nodes. We design a mutually enhanced mechanism to compute\nnode priority, optimal propagation step and label prediction. We also propose\nan alternative optimization strategy to learn the parameters in the backbone\nGNN model and two parametric controllers. We conduct extensive experiments to\ncompare our framework with other 11 state-of-the-art competitors on 8 benchmark\ndatasets. Experimental results show that our framework can lead to superior\nperformance in terms of propagation strategies and node representations.",
            "author": [
                "Yao Cheng",
                "Minjie Chen",
                "Xiang Li",
                "Caihua Shan",
                "Ming Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02832v1",
                "http://arxiv.org/pdf/2311.02832v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02831v3",
            "title": "SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based\n  on Quadric-Level Object Map",
            "updated": "2023-11-09T12:55:34Z",
            "published": "2023-11-06T02:30:30Z",
            "summary": "Loop closure, as one of the crucial components in SLAM, plays an essential\nrole in correcting the accumulated errors. Traditional appearance-based\nmethods, such as bag-of-words models, are often limited by local 2D features\nand the volume of training data, making them less versatile and robust in\nreal-world scenarios, leading to missed detections or false positives\ndetections in loop closure. To address these issues, we first propose a\nobject-level data association method based on multi-level verification, which\ncan associate 2D semantic features of current frame with 3D objects landmarks\nof map. Next, taking advantage of these association relations, we introduce a\nsemantic loop closure method based on quadric-level object map topology, which\nrepresents scenes through the topological graph of objects and achieves\naccurate loop closure at a wide field of view by comparing differences in the\ntopological graphs. Finally, we integrate these two methods into a complete\nobject-aware SLAM system. Qualitative experiments and ablation studies\ndemonstrate the effectiveness and robustness of the proposed object-level data\nassociation algorithm. Quantitative experiments show that our semantic loop\nclosure method outperforms existing state-of-the-art methods in terms of\nprecision, recall and localization accuracy metrics.",
            "author": [
                "Zhenzhong Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02831v3",
                "http://arxiv.org/pdf/2311.02831v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02826v1",
            "title": "InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image",
            "updated": "2023-11-06T02:21:11Z",
            "published": "2023-11-06T02:21:11Z",
            "summary": "With the success of Neural Radiance Field (NeRF) in 3D-aware portrait\nediting, a variety of works have achieved promising results regarding both\nquality and 3D consistency. However, these methods heavily rely on per-prompt\noptimization when handling natural language as editing instructions. Due to the\nlack of labeled human face 3D datasets and effective architectures, the area of\nhuman-instructed 3D-aware editing for open-world portraits in an end-to-end\nmanner remains under-explored. To solve this problem, we propose an end-to-end\ndiffusion-based framework termed InstructPix2NeRF, which enables instructed\n3D-aware portrait editing from a single open-world image with human\ninstructions. At its core lies a conditional latent 3D diffusion process that\nlifts 2D editing to 3D space by learning the correlation between the paired\nimages' difference and the instructions via triplet data. With the help of our\nproposed token position randomization strategy, we could even achieve\nmulti-semantic editing through one single pass with the portrait identity\nwell-preserved. Besides, we further propose an identity consistency module that\ndirectly modulates the extracted identity signals into our diffusion process,\nwhich increases the multi-view 3D identity consistency. Extensive experiments\nverify the effectiveness of our method and show its superiority against strong\nbaselines quantitatively and qualitatively.",
            "author": [
                "Jianhui Li",
                "Shilong Liu",
                "Zidong Liu",
                "Yikai Wang",
                "Kaiwen Zheng",
                "Jinghui Xu",
                "Jianmin Li",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02826v1",
                "http://arxiv.org/pdf/2311.02826v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02820v1",
            "title": "Mesh Neural Cellular Automata",
            "updated": "2023-11-06T01:54:37Z",
            "published": "2023-11-06T01:54:37Z",
            "summary": "Modeling and synthesizing textures are essential for enhancing the realism of\nvirtual environments. Methods that directly synthesize textures in 3D offer\ndistinct advantages to the UV-mapping-based methods as they can create seamless\ntextures and align more closely with the ways textures form in nature. We\npropose Mesh Neural Cellular Automata (MeshNCA), a method for directly\nsynthesizing dynamic textures on 3D meshes without requiring any UV maps.\nMeshNCA is a generalized type of cellular automata that can operate on a set of\ncells arranged on a non-grid structure such as vertices of a 3D mesh. While\nonly being trained on an Icosphere mesh, MeshNCA shows remarkable\ngeneralization and can synthesize textures on any mesh in real time after the\ntraining. Additionally, it accommodates multi-modal supervision and can be\ntrained using different targets such as images, text prompts, and motion vector\nfields. Moreover, we conceptualize a way of grafting trained MeshNCA instances,\nenabling texture interpolation. Our MeshNCA model enables real-time 3D texture\nsynthesis on meshes and allows several user interactions including texture\ndensity/orientation control, a grafting brush, and motion speed/direction\ncontrol. Finally, we implement the forward pass of our MeshNCA model using the\nWebGL shading language and showcase our trained models in an online interactive\ndemo which is accessible on personal computers and smartphones. Our demo and\nthe high resolution version of this PDF are available at\nhttps://meshnca.github.io/.",
            "author": [
                "Ehsan Pajouheshgar",
                "Yitao Xu",
                "Alexander Mordvintsev",
                "Eyvind Niklasson",
                "Tong Zhang",
                "Sabine S\u00fcsstrunk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02820v1",
                "http://arxiv.org/pdf/2311.02820v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02819v1",
            "title": "An Exploration of Multimodality and Data Augmentation for Dementia\n  Classification",
            "updated": "2023-11-06T01:54:32Z",
            "published": "2023-11-06T01:54:32Z",
            "summary": "Dementia is a progressive neurological disorder that profoundly affects the\ndaily lives of older adults, impairing abilities such as verbal communication\nand cognitive function. Early diagnosis is essential for enhancing both\nlifespan and quality of life for affected individuals. Despite its importance,\ndiagnosing dementia is complex and often necessitates a multimodal approach\nincorporating diverse clinical data types. In this study, we fine-tune Wav2vec\nand Word2vec baseline models using two distinct data types: audio recordings\nand text transcripts. We experiment with four conditions: original datasets\nversus datasets purged of short sentences, each with and without data\naugmentation. Our results indicate that synonym-based text data augmentation\ngenerally enhances model performance, underscoring the importance of data\nvolume for achieving generalizable performance. Additionally, models trained on\ntext data frequently excel and can further improve the performance of other\nmodalities when combined. Audio and timestamp data sometimes offer marginal\nimprovements. We provide a qualitative error analysis of the sentence\narchetypes that tend to be misclassified under each condition, providing\ninsights into the effects of altering data modality and augmentation decisions.",
            "author": [
                "Kaiying Lin",
                "Peter Washington"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02819v1",
                "http://arxiv.org/pdf/2311.02819v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02817v1",
            "title": "Safe-VLN: Collision Avoidance for Vision-and-Language Navigation of\n  Autonomous Robots Operating in Continuous Environments",
            "updated": "2023-11-06T01:39:14Z",
            "published": "2023-11-06T01:39:14Z",
            "summary": "The task of vision-and-language navigation in continuous environments\n(VLN-CE) aims at training an autonomous agent to perform low-level actions to\nnavigate through 3D continuous surroundings using visual observations and\nlanguage instructions. The significant potential of VLN-CE for mobile robots\nhas been demonstrated across a large number of studies. However, most existing\nworks in VLN-CE focus primarily on transferring the standard discrete\nvision-and-language navigation (VLN) methods to continuous environments,\noverlooking the problem of collisions. Such oversight often results in the\nagent deviating from the planned path or, in severe instances, the agent being\ntrapped in obstacle areas and failing the navigational task. To address the\nabove-mentioned issues, this paper investigates various collision scenarios\nwithin VLN-CE and proposes a classification method to predicate the underlying\ncauses of collisions. Furthermore, a new VLN-CE algorithm, named Safe-VLN, is\nproposed to bolster collision avoidance capabilities including two key\ncomponents, i.e., a waypoint predictor and a navigator. In particular, the\nwaypoint predictor leverages a simulated 2D LiDAR occupancy mask to prevent the\npredicted waypoints from being situated in obstacle-ridden areas. The\nnavigator, on the other hand, employs the strategy of `re-selection after\ncollision' to prevent the robot agent from becoming ensnared in a cycle of\nperpetual collisions. The proposed Safe-VLN is evaluated on the R2R-CE, the\nresults of which demonstrate an enhanced navigational performance and a\nstatistically significant reduction in collision incidences.",
            "author": [
                "Lu Yue",
                "Dongliang Zhou",
                "Liang Xie",
                "Feitian Zhang",
                "Ye Yan",
                "Erwei Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02817v1",
                "http://arxiv.org/pdf/2311.02817v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02816v1",
            "title": "APGL4SR: A Generic Framework with Adaptive and Personalized Global\n  Collaborative Information in Sequential Recommendation",
            "updated": "2023-11-06T01:33:24Z",
            "published": "2023-11-06T01:33:24Z",
            "summary": "The sequential recommendation system has been widely studied for its\npromising effectiveness in capturing dynamic preferences buried in users'\nsequential behaviors. Despite the considerable achievements, existing methods\nusually focus on intra-sequence modeling while overlooking exploiting global\ncollaborative information by inter-sequence modeling, resulting in inferior\nrecommendation performance. Therefore, previous works attempt to tackle this\nproblem with a global collaborative item graph constructed by pre-defined\nrules. However, these methods neglect two crucial properties when capturing\nglobal collaborative information, i.e., adaptiveness and personalization,\nyielding sub-optimal user representations. To this end, we propose a\ngraph-driven framework, named Adaptive and Personalized Graph Learning for\nSequential Recommendation (APGL4SR), that incorporates adaptive and\npersonalized global collaborative information into sequential recommendation\nsystems. Specifically, we first learn an adaptive global graph among all items\nand capture global collaborative information with it in a self-supervised\nfashion, whose computational burden can be further alleviated by the proposed\nSVD-based accelerator. Furthermore, based on the graph, we propose to extract\nand utilize personalized item correlations in the form of relative positional\nencoding, which is a highly compatible manner of personalizing the utilization\nof global collaborative information. Finally, the entire framework is optimized\nin a multi-task learning paradigm, thus each part of APGL4SR can be mutually\nreinforced. As a generic framework, APGL4SR can outperform other baselines with\nsignificant margins. The code is available at\nhttps://github.com/Graph-Team/APGL4SR.",
            "author": [
                "Mingjia Yin",
                "Hao Wang",
                "Xiang Xu",
                "Likang Wu",
                "Sirui Zhao",
                "Wei Guo",
                "Yong Liu",
                "Ruiming Tang",
                "Defu Lian",
                "Enhong Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614781",
                "http://arxiv.org/abs/2311.02816v1",
                "http://arxiv.org/pdf/2311.02816v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02815v1",
            "title": "Efficient, Self-Supervised Human Pose Estimation with Inductive Prior\n  Tuning",
            "updated": "2023-11-06T01:19:57Z",
            "published": "2023-11-06T01:19:57Z",
            "summary": "The goal of 2D human pose estimation (HPE) is to localize anatomical\nlandmarks, given an image of a person in a pose. SOTA techniques make use of\nthousands of labeled figures (finetuning transformers or training deep CNNs),\nacquired using labor-intensive crowdsourcing. On the other hand,\nself-supervised methods re-frame the HPE task as a reconstruction problem,\nenabling them to leverage the vast amount of unlabeled visual data, though at\nthe present cost of accuracy. In this work, we explore ways to improve\nself-supervised HPE. We (1) analyze the relationship between reconstruction\nquality and pose estimation accuracy, (2) develop a model pipeline that\noutperforms the baseline which inspired our work, using less than one-third the\namount of training data, and (3) offer a new metric suitable for\nself-supervised settings that measures the consistency of predicted body part\nlength proportions. We show that a combination of well-engineered\nreconstruction losses and inductive priors can help coordinate pose learning\nalongside reconstruction in a self-supervised paradigm.",
            "author": [
                "Nobline Yoo",
                "Olga Russakovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02815v1",
                "http://arxiv.org/pdf/2311.02815v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02811v2",
            "title": "Contour Algorithm for Connectivity",
            "updated": "2023-11-07T02:42:27Z",
            "published": "2023-11-06T01:02:44Z",
            "summary": "Finding connected components in a graph is a fundamental problem in graph\nanalysis. In this work, we present a novel minimum-mapping based Contour\nalgorithm to efficiently solve the connectivity problem. We prove that the\nContour algorithm with two or higher order operators can identify all connected\ncomponents of an undirected graph within $\\mathcal{O}(\\log d_{max})$\niterations, with each iteration involving $\\mathcal{O}(m)$ work, where\n$d_{max}$ represents the largest diameter among all components in the given\ngraph, and $m$ is the total number of edges in the graph. Importantly, each\niteration is highly parallelizable, making use of the efficient minimum-mapping\noperator applied to all edges. To further enhance its practical performance, we\noptimize the Contour algorithm through asynchronous updates, early convergence\nchecking, eliminating atomic operations, and choosing more efficient mapping\noperators. Our implementation of the Contour algorithm has been integrated into\nthe open-source framework Arachne. Arachne extends Arkouda for large-scale\ninteractive graph analytics, providing a Python API powered by the\nhigh-productivity parallel language Chapel. Experimental results on both\nreal-world and synthetic graphs demonstrate the superior performance of our\nproposed Contour algorithm compared to state-of-the-art large-scale parallel\nalgorithm FastSV and the fastest shared memory algorithm ConnectIt. On average,\nContour achieves a speedup of 7.3x and 1.4x compared to FastSV and ConnectIt,\nrespectively. All code for the Contour algorithm and the Arachne framework is\npublicly available on GitHub ( https://github.com/Bears-R-Us/arkouda-njit ),\nensuring transparency and reproducibility of our work.",
            "author": [
                "Zhihui Du",
                "Oliver Alvarado Rodriguez",
                "Fuhuan Li",
                "Mohammad Dindoost",
                "David A. Bader"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02811v2",
                "http://arxiv.org/pdf/2311.02811v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02807v1",
            "title": "QualEval: Qualitative Evaluation for Model Improvement",
            "updated": "2023-11-06T00:21:44Z",
            "published": "2023-11-06T00:21:44Z",
            "summary": "Quantitative evaluation metrics have traditionally been pivotal in gauging\nthe advancements of artificial intelligence systems, including large language\nmodels (LLMs). However, these metrics have inherent limitations. Given the\nintricate nature of real-world tasks, a single scalar to quantify and compare\nis insufficient to capture the fine-grained nuances of model behavior. Metrics\nserve only as a way to compare and benchmark models, and do not yield\nactionable diagnostics, thus making the model improvement process challenging.\nModel developers find themselves amid extensive manual efforts involving\nsifting through vast datasets and attempting hit-or-miss adjustments to\ntraining data or setups. In this work, we address the shortcomings of\nquantitative metrics by proposing QualEval, which augments quantitative scalar\nmetrics with automated qualitative evaluation as a vehicle for model\nimprovement. QualEval uses a powerful LLM reasoner and our novel flexible\nlinear programming solver to generate human-readable insights that when\napplied, accelerate model improvement. The insights are backed by a\ncomprehensive dashboard with fine-grained visualizations and\nhuman-interpretable analyses. We corroborate the faithfulness of QualEval by\ndemonstrating that leveraging its insights, for example, improves the absolute\nperformance of the Llama 2 model by up to 15% points relative on a challenging\ndialogue task (DialogSum) when compared to baselines. QualEval successfully\nincreases the pace of model development, thus in essence serving as a\ndata-scientist-in-a-box. Given the focus on critiquing and improving current\nevaluation metrics, our method serves as a refreshingly new technique for both\nmodel evaluation and improvement.",
            "author": [
                "Vishvak Murahari",
                "Ameet Deshpande",
                "Peter Clark",
                "Tanmay Rajpurohit",
                "Ashish Sabharwal",
                "Karthik Narasimhan",
                "Ashwin Kalyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02807v1",
                "http://arxiv.org/pdf/2311.02807v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02805v1",
            "title": "Tailoring Self-Rationalizers with Multi-Reward Distillation",
            "updated": "2023-11-06T00:20:11Z",
            "published": "2023-11-06T00:20:11Z",
            "summary": "Large language models (LMs) are capable of generating free-text rationales to\naid question answering. However, prior work 1) suggests that useful\nself-rationalization is emergent only at significant scales (e.g., 175B\nparameter GPT-3); and 2) focuses largely on downstream performance, ignoring\nthe semantics of the rationales themselves, e.g., are they faithful, true, and\nhelpful for humans? In this work, we enable small-scale LMs (approx. 200x\nsmaller than GPT-3) to generate rationales that not only improve downstream\ntask performance, but are also more plausible, consistent, and diverse,\nassessed both by automatic and human evaluation. Our method, MaRio\n(Multi-rewArd RatIOnalization), is a multi-reward conditioned\nself-rationalization algorithm that optimizes multiple distinct properties like\nplausibility, diversity and consistency. Results on five difficult\nquestion-answering datasets StrategyQA, QuaRel, OpenBookQA, NumerSense and QASC\nshow that not only does MaRio improve task accuracy, but it also improves the\nself-rationalization quality of small LMs across the aforementioned axes better\nthan a supervised fine-tuning (SFT) baseline. Extensive human evaluations\nconfirm that MaRio rationales are preferred vs. SFT rationales, as well as\nqualitative improvements in plausibility and consistency.",
            "author": [
                "Sahana Ramnath",
                "Brihi Joshi",
                "Skyler Hallinan",
                "Ximing Lu",
                "Liunian Harold Li",
                "Aaron Chan",
                "Jack Hessel",
                "Yejin Choi",
                "Xiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02805v1",
                "http://arxiv.org/pdf/2311.02805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02804v1",
            "title": "Last fall degree of semi-local polynomial systems",
            "updated": "2023-11-06T00:11:40Z",
            "published": "2023-11-06T00:11:40Z",
            "summary": "We study the last fall degrees of {\\em semi-local} polynomial systems, and\nthe computational complexity of solving such systems for closed-point and\nrational-point solutions, where the systems are defined over a finite field. A\nsemi-local polynomial system specifies an algebraic set which is the image of a\nglobal linear transformation of a direct product of local affine algebraic\nsets. As a special but interesting case, polynomial systems that arise from\nWeil restriction of algebraic sets in an affine space of low dimension are\nsemi-local. Such systems have received considerable attention due to their\napplication in cryptography. Our main results bound the last fall degree of a\nsemi-local polynomial system in terms of the number of closed point solutions,\nand yield an efficient algorithm for finding all rational-point solutions when\nthe prime characteristic of the finite field and the number of rational\nsolutions are small. Our results on solving semi-local systems imply an\nimprovement on a previously known polynomial-time attack on the HFE (Hidden\nField Equations) cryptosystems. The attacks implied in our results extend to\npublic key encryption functions which are based on semi-local systems where\neither the number of closed point solutions is small, or the characteristic of\nthe field is small. It remains plausible to construct public key cryptosystems\nbased on semi-local systems over a finite field of large prime characteristic\nwith exponential number of closed point solutions. Such a method is presented\nin the paper, followed by further cryptanalysis involving the isomorphism of\npolynomials (IP) problem, as well as a concrete public key encryption scheme\nwhich is secure against all the attacks discussed in this paper.",
            "author": [
                "Ming-Deh A. Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02804v1",
                "http://arxiv.org/pdf/2311.02804v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02803v1",
            "title": "Fast and Interpretable Face Identification for Out-Of-Distribution Data\n  Using Vision Transformers",
            "updated": "2023-11-06T00:11:24Z",
            "published": "2023-11-06T00:11:24Z",
            "summary": "Most face identification approaches employ a Siamese neural network to\ncompare two images at the image embedding level. Yet, this technique can be\nsubject to occlusion (e.g. faces with masks or sunglasses) and\nout-of-distribution data. DeepFace-EMD (Phan et al. 2022) reaches\nstate-of-the-art accuracy on out-of-distribution data by first comparing two\nimages at the image level, and then at the patch level. Yet, its later\npatch-wise re-ranking stage admits a large $O(n^3 \\log n)$ time complexity (for\n$n$ patches in an image) due to the optimal transport optimization. In this\npaper, we propose a novel, 2-image Vision Transformers (ViTs) that compares two\nimages at the patch level using cross-attention. After training on 2M pairs of\nimages on CASIA Webface (Yi et al. 2014), our model performs at a comparable\naccuracy as DeepFace-EMD on out-of-distribution data, yet at an inference speed\nmore than twice as fast as DeepFace-EMD (Phan et al. 2022). In addition, via a\nhuman study, our model shows promising explainability through the visualization\nof cross-attention. We believe our work can inspire more explorations in using\nViTs for face identification.",
            "author": [
                "Hai Phan",
                "Cindy Le",
                "Vu Le",
                "Yihui He",
                "Anh Totti Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02803v1",
                "http://arxiv.org/pdf/2311.02803v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02802v2",
            "title": "Incorporating Worker Perspectives into MTurk Annotation Practices for\n  NLP",
            "updated": "2023-11-16T01:13:57Z",
            "published": "2023-11-06T00:06:11Z",
            "summary": "Current practices regarding data collection for natural language processing\non Amazon Mechanical Turk (MTurk) often rely on a combination of studies on\ndata quality and heuristics shared among NLP researchers. However, without\nconsidering the perspectives of MTurk workers, these approaches are susceptible\nto issues regarding workers' rights and poor response quality. We conducted a\ncritical literature review and a survey of MTurk workers aimed at addressing\nopen questions regarding best practices for fair payment, worker privacy, data\nquality, and considering worker incentives. We found that worker preferences\nare often at odds with received wisdom among NLP researchers. Surveyed workers\npreferred reliable, reasonable payments over uncertain, very high payments;\nreported frequently lying on demographic questions; and expressed frustration\nat having work rejected with no explanation. We also found that workers view\nsome quality control methods, such as requiring minimum response times or\nMaster's qualifications, as biased and largely ineffective. Based on the survey\nresults, we provide recommendations on how future NLP studies may better\naccount for MTurk workers' experiences in order to respect workers' rights and\nimprove data quality.",
            "author": [
                "Olivia Huang",
                "Eve Fleisig",
                "Dan Klein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02802v2",
                "http://arxiv.org/pdf/2311.02802v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02800v1",
            "title": "Kivi: Verification for Cluster Management",
            "updated": "2023-11-06T00:03:02Z",
            "published": "2023-11-06T00:03:02Z",
            "summary": "Modern cloud infrastructure is powered by cluster management systems such as\nKubernetes and Docker Swarm. While these systems seek to minimize users'\noperational burden, the complex, dynamic, and non-deterministic nature of these\nsystems makes them hard to reason about, potentially leading to failures\nranging from performance degradation to outages. We present Kivi, the first\nsystem for verifying controllers and their configurations in cluster management\nsystems. Kivi focuses on the popular system Kubernetes, and models its\ncontrollers and events into processes whereby their interleavings are\nexhaustively checked via model checking. Central to handling autoscaling and\nlarge-scale deployments is our design that seeks to find violations in a\nsmaller and reduced topology. We also develop several model optimizations in\nKivi to scale to large clusters. We show that Kivi is effective and accurate in\nfinding issues in realistic and complex scenarios and showcase two new issues\nin Kubernetes controller source code.",
            "author": [
                "Bingzhe Liu",
                "Gangmuk Lim",
                "Ryan Beckett",
                "P. Brighten Godfrey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02800v1",
                "http://arxiv.org/pdf/2311.02800v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05643v1",
            "title": "Fundamentally New Coupled Approach to Contact Mechanics via the\n  Dirichlet-Neumann Schwarz Alternating Method",
            "updated": "2023-11-05T23:58:17Z",
            "published": "2023-11-05T23:58:17Z",
            "summary": "Contact phenomena are essential in understanding the behavior of mechanical\nsystems. Existing computational approaches for simulating mechanical contact\noften encounter numerical issues, such as inaccurate physical predictions,\nenergy conservation errors, and unwanted oscillations. We introduce an\nalternative technique, rooted in the non-overlapping Schwarz alternating\nmethod, originally developed for domain decomposition. In multi-body contact\nscenarios, this method treats each body as a separate, non-overlapping domain\nand prevents interpenetration using an alternating Dirichlet-Neumann iterative\nprocess. This approach has a strong theoretical foundation, eliminates the need\nfor contact constraints, and offers flexibility, making it well-suited for\nmultiscale and multi-physics applications.\n  We conducted a numerical comparison between the Schwarz method and\ntraditional methods like Lagrange multiplier and penalty methods, focusing on a\nbenchmark impact problem. Our results indicate that the Schwarz alternating\nmethod surpasses traditional methods in several key areas: it provides more\naccurate predictions for various measurable quantities and demonstrates\nexceptional energy conservation capabilities. To address the issue of unwanted\noscillations in contact velocities and forces, we explored various algorithms\nand stabilization techniques, ultimately opting for the naive-stabilized\nNewmark scheme for its simplicity and effectiveness. Furthermore, we validated\nthe efficiency of the Schwarz method in a three-dimensional impact problem,\nhighlighting its innate capacity to accommodate different mesh topologies, time\nintegration schemes, and time steps for each interacting body.",
            "author": [
                "A. Mota",
                "D. Koliesnikova",
                "I. Tezaur",
                "J. Hoy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05643v1",
                "http://arxiv.org/pdf/2311.05643v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.NA",
                "math.AP",
                "math.NA",
                "70",
                "J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02791v1",
            "title": "MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual\n  Camera Calibration",
            "updated": "2023-11-05T23:25:21Z",
            "published": "2023-11-05T23:25:21Z",
            "summary": "In this paper, we present the novel task of estimating the extrinsic\nparameters of a virtual camera with respect to a real camera with one single\nfixed planar mirror. This task poses a significant challenge in cases where\nobjects captured lack overlapping views from both real and mirrored cameras. To\naddress this issue, prior knowledge of a human body and 2D joint locations are\nutilized to estimate the camera extrinsic parameters when a person is in front\nof a mirror. We devise a modified eight-point algorithm to obtain an initial\nestimation from 2D joint locations. The 2D joint locations are then refined\nsubject to human body constraints. Finally, a RANSAC algorithm is employed to\nremove outliers by comparing their epipolar distances to a predetermined\nthreshold. MirrorCalib is evaluated on both synthetic and real datasets and\nachieves a rotation error of 0.62{\\deg}/1.82{\\deg} and a translation error of\n37.33/69.51 mm on the synthetic/real dataset, which outperforms the\nstate-of-art method.",
            "author": [
                "Longyun Liao",
                "Andrew Mitchell",
                "Rong Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02791v1",
                "http://arxiv.org/pdf/2311.02791v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02790v1",
            "title": "CausalCite: A Causal Formulation of Paper Citations",
            "updated": "2023-11-05T23:09:39Z",
            "published": "2023-11-05T23:09:39Z",
            "summary": "Evaluating the significance of a paper is pivotal yet challenging for the\nscientific community. While the citation count is the most commonly used proxy\nfor this purpose, they are widely criticized for failing to accurately reflect\na paper's true impact. In this work, we propose a causal inference method,\nTextMatch, which adapts the traditional matching framework to high-dimensional\ntext embeddings. Specifically, we encode each paper using the text embeddings\nby large language models (LLMs), extract similar samples by cosine similarity,\nand synthesize a counterfactual sample by the weighted average of similar\npapers according to their similarity values. We apply the resulting metric,\ncalled CausalCite, as a causal formulation of paper citations. We show its\neffectiveness on various criteria, such as high correlation with paper impact\nas reported by scientific experts on a previous dataset of 1K papers,\n(test-of-time) awards for past papers, and its stability across various\nsub-fields of AI. We also provide a set of findings that can serve as suggested\nways for future researchers to use our metric for a better understanding of a\npaper's quality. Our code and data are at\nhttps://github.com/causalNLP/causal-cite.",
            "author": [
                "Ishan Kumar",
                "Zhijing Jin",
                "Ehsan Mokhtarian",
                "Siyuan Guo",
                "Yuen Chen",
                "Negar Kiyavash",
                "Mrinmaya Sachan",
                "Bernhard Schoelkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02790v1",
                "http://arxiv.org/pdf/2311.02790v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02786v1",
            "title": "Mobility as a Resource (MaaR) for resilient human-centric automation: a\n  vision paper",
            "updated": "2023-11-05T22:31:07Z",
            "published": "2023-11-05T22:31:07Z",
            "summary": "As a consequence of commoditization, mobility is moving from a product (i.e.,\ntraditional modes and vehicles), to a service (i.e., Mobility as a Service,\nMaaS); MaaS is the current state of transport research and emerging practice.\nHowever, as it is observed in other fields (e.g. computing) we argue that\nmobility will evolve from a service to a resource (Mobility as a Resource,\nMaaR); MaaR is the envisioned inevitable state, which will emerge for societal\nmovement. Further, due to increasing scarcity of shared mobility spaces across\ntraditional and emerging modes of mobility, the commoditization process must be\nviewed within the critical need for ethical and equitable solutions for the\ntraveling public (i.e., research is needed to avoid hyper-market driven\noutcomes for society from the ongoing commoditization process). The evolution\nof mobility into a resource requires novel conceptual frameworks, technologies,\nprocesses and perspectives of analysis. A key component of the future MaaR\nsystem is the technological capacity to observe, allocate and manage (in\nreal-time) the smallest envisionable units of mobility (i.e., atomic units of\nmobility capacity) while providing prioritized attention to human movement and\nethical metrics related to access, consumption and impact. This paper proposes\nan initial design of new paradigms which synthesize and advance methodologies\nrelating to highly dynamic capacity reservation systems for automated travel\nintegrated with the mixed interaction of non-automated traffic flow management,\ntravel network optimization, demand behavior forecasting, and progressive\nmobility planning that spans equity, sustainability, and resilience.",
            "author": [
                "S. Travis Waller",
                "Amalia Polydoropoulou",
                "Leandros Tassiulas",
                "Athanasios Ziliaskopoulos",
                "Sisi Jian",
                "Susann Wagenknecht",
                "Georg Hirte",
                "Tomasz Bednarz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02786v1",
                "http://arxiv.org/pdf/2311.02786v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02784v1",
            "title": "An algorithm to recognize echelon subgroups of a free group",
            "updated": "2023-11-05T22:25:32Z",
            "published": "2023-11-05T22:25:32Z",
            "summary": "We provide an algorithm that, given a finite set of generators for a subgroup\n$H$ of a finitely generated free group $F$, determines whether $H$ is echelon\nor not and, in case of affirmative answer, also computes a basis with respect\nto which $H$ is in echelon form. This answers to a question of A. Rosenmann. We\nalso prove, by means of a counterexample, that intersection of two echelon\nsubgroups needs not to be echelon, answering to another question of A.\nRosenmann.",
            "author": [
                "Dario Ascari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02784v1",
                "http://arxiv.org/pdf/2311.02784v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "20E05, 20E07 (Primary) 20F65 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03709v1",
            "title": "UID as a Guiding Metric for Automated Authorship Obfuscation",
            "updated": "2023-11-05T22:16:37Z",
            "published": "2023-11-05T22:16:37Z",
            "summary": "Protecting the anonymity of authors has become a difficult task given the\nrise of automated authorship attributors. These attributors are capable of\nattributing the author of a text amongst a pool of authors with great accuracy.\nIn order to counter the rise of these automated attributors, there has also\nbeen a rise of automated obfuscators. These obfuscators are capable of taking\nsome text, perturbing the text in some manner, and, if successful, deceive an\nautomated attributor in misattributing the wrong author. We devised three novel\nauthorship obfuscation methods that utilized a Psycho-linguistic theory known\nas Uniform Information Density (UID) theory. This theory states that humans\nevenly distribute information amongst speech or text so as to maximize\nefficiency. Utilizing this theory in our three obfuscation methods, we\nattempted to see how successfully we could deceive two separate attributors.\nObfuscating 50 human and 50 GPT-3 generated articles from the TuringBench\ndataset, we observed how well each method did on deceiving the attributors.\nWhile the quality of the obfuscation in terms of semantic preservation and\nsensical changes was high, we were not able to find any evidence to indicate\nUID was a viable guiding metric for obfuscation. However, due to restrictions\nin time we were unable to test a large enough sample of article or tune the\nparameters for our attributors to comment conclusively on UID in obfuscation.",
            "author": [
                "Nicholas Abegg"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03709v1",
                "http://arxiv.org/pdf/2312.03709v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04930v1",
            "title": "Large language models implicitly learn to straighten neural sentence\n  trajectories to construct a predictive representation of natural language",
            "updated": "2023-11-05T22:16:21Z",
            "published": "2023-11-05T22:16:21Z",
            "summary": "Predicting upcoming events is critical to our ability to interact with our\nenvironment. Transformer models, trained on next-word prediction, appear to\nconstruct representations of linguistic input that can support diverse\ndownstream tasks. But how does a predictive objective shape such\nrepresentations? Inspired by recent work in vision (Henaff et al., 2019), we\ntest a hypothesis about predictive representations of autoregressive\ntransformers. In particular, we test whether the neural trajectory of a\nsentence becomes progressively straighter as it passes through the network\nlayers. The key insight is that straighter trajectories should facilitate\nprediction via linear extrapolation. We quantify straightness using a\n1-dimensional curvature metric, and present four findings in support of the\ntrajectory straightening hypothesis: i) In trained models, the curvature\ndecreases from the early to the deeper layers of the network. ii) Models that\nperform better on the next-word prediction objective exhibit greater decreases\nin curvature, suggesting that this improved ability to straighten sentence\ntrajectories may be the driver of better language modeling performance. iii)\nGiven the same linguistic context, the sequences that are generated by the\nmodel have lower curvature than the actual continuations observed in a language\ncorpus, suggesting that the model favors straighter trajectories for making\npredictions. iv) A consistent relationship holds between the average curvature\nand the average surprisal of sentences in the deep model layers, such that\nsentences with straighter trajectories also have lower surprisal. Importantly,\nuntrained models do not exhibit these behaviors. In tandem, these results\nsupport the trajectory straightening hypothesis and provide a possible\nmechanism for how the geometry of the internal representations of\nautoregressive models supports next word prediction.",
            "author": [
                "Eghbal A. Hosseini",
                "Evelina Fedorenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04930v1",
                "http://arxiv.org/pdf/2311.04930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02782v3",
            "title": "Towards Generic Anomaly Detection and Understanding: Large-scale\n  Visual-linguistic Model (GPT-4V) Takes the Lead",
            "updated": "2023-11-16T09:10:22Z",
            "published": "2023-11-05T22:13:12Z",
            "summary": "Anomaly detection is a crucial task across different domains and data types.\nHowever, existing anomaly detection models are often designed for specific\ndomains and modalities. This study explores the use of GPT-4V(ision), a\npowerful visual-linguistic model, to address anomaly detection tasks in a\ngeneric manner. We investigate the application of GPT-4V in multi-modality,\nmulti-domain anomaly detection tasks, including image, video, point cloud, and\ntime series data, across multiple application areas, such as industrial,\nmedical, logical, video, 3D anomaly detection, and localization tasks. To\nenhance GPT-4V's performance, we incorporate different kinds of additional cues\nsuch as class information, human expertise, and reference images as\nprompts.Based on our experiments, GPT-4V proves to be highly effective in\ndetecting and explaining global and fine-grained semantic patterns in\nzero/one-shot anomaly detection. This enables accurate differentiation between\nnormal and abnormal instances. Although we conducted extensive evaluations in\nthis study, there is still room for future evaluation to further exploit\nGPT-4V's generic anomaly detection capacity from different aspects. These\ninclude exploring quantitative metrics, expanding evaluation benchmarks,\nincorporating multi-round interactions, and incorporating human feedback loops.\nNevertheless, GPT-4V exhibits promising performance in generic anomaly\ndetection and understanding, thus opening up a new avenue for anomaly\ndetection.",
            "author": [
                "Yunkang Cao",
                "Xiaohao Xu",
                "Chen Sun",
                "Xiaonan Huang",
                "Weiming Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02782v3",
                "http://arxiv.org/pdf/2311.02782v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02778v1",
            "title": "MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction\n  and Novel View Synthesis",
            "updated": "2023-11-05T21:46:12Z",
            "published": "2023-11-05T21:46:12Z",
            "summary": "Metaverse technologies demand accurate, real-time, and immersive modeling on\nconsumer-grade hardware for both non-human perception (e.g.,\ndrone/robot/autonomous car navigation) and immersive technologies like AR/VR,\nrequiring both structural accuracy and photorealism. However, there exists a\nknowledge gap in how to apply geometric reconstruction and photorealism\nmodeling (novel view synthesis) in a unified framework.\n  To address this gap and promote the development of robust and immersive\nmodeling and rendering with consumer-grade devices, first, we propose a\nreal-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents\nexciting challenges and requires state-of-the-art methods to be cost-effective,\nrobust to noisy data and devices, and can jointly learn 3D reconstruction and\nnovel view synthesis, instead of treating them as separate tasks, making them\nideal for real-world applications. Second, we benchmark several famous\npipelines on our dataset for joint 3D mesh reconstruction and novel view\nsynthesis. Finally, in order to further improve the overall performance, we\npropose a new method that achieves a good trade-off between the two tasks. Our\ndataset and benchmark show great potential in promoting the improvements for\nfusing 3D reconstruction and high-quality rendering in a robust and\ncomputationally efficient end-to-end fashion.",
            "author": [
                "Xuqian Ren",
                "Wenjia Wang",
                "Dingding Cai",
                "Tuuli Tuominen",
                "Juho Kannala",
                "Esa Rahtu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02778v1",
                "http://arxiv.org/pdf/2311.02778v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02777v1",
            "title": "Robust Generalization Strategies for Morpheme Glossing in an Endangered\n  Language Documentation Context",
            "updated": "2023-11-05T21:45:57Z",
            "published": "2023-11-05T21:45:57Z",
            "summary": "Generalization is of particular importance in resource-constrained settings,\nwhere the available training data may represent only a small fraction of the\ndistribution of possible texts. We investigate the ability of morpheme labeling\nmodels to generalize by evaluating their performance on unseen genres of text,\nand we experiment with strategies for closing the gap between performance on\nin-distribution and out-of-distribution data. Specifically, we use weight decay\noptimization, output denoising, and iterative pseudo-labeling, and achieve a 2%\nimprovement on a test set containing texts from unseen genres. All experiments\nare performed using texts written in the Mayan language Uspanteko.",
            "author": [
                "Michael Ginn",
                "Alexis Palmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02777v1",
                "http://arxiv.org/pdf/2311.02777v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02775v2",
            "title": "ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using\n  Open-Source LLMs",
            "updated": "2023-11-13T16:03:15Z",
            "published": "2023-11-05T21:43:02Z",
            "summary": "Responding to the thousands of student questions on online QA platforms each\nsemester has a considerable human cost, particularly in computing courses with\nrapidly growing enrollments. To address the challenges of scalable and\nintelligent question-answering (QA), we introduce an innovative solution that\nleverages open-source Large Language Models (LLMs) from the LLaMA-2 family to\nensure data privacy. Our approach combines augmentation techniques such as\nretrieval augmented generation (RAG), supervised fine-tuning (SFT), and\nlearning from human preferences data using Direct Preference Optimization\n(DPO). Through extensive experimentation on a Piazza dataset from an\nintroductory CS course, comprising 10,000 QA pairs and 1,500 pairs of\npreference data, we demonstrate a significant 30% improvement in the quality of\nanswers, with RAG being a particularly impactful addition. Our contributions\ninclude the development of a novel architecture for educational QA, extensive\nevaluations of LLM performance utilizing both human assessments and LLM-based\nmetrics, and insights into the challenges and future directions of educational\ndata processing. This work paves the way for the development of CHATA, an\nintelligent QA assistant customizable for courses with an online QA platform",
            "author": [
                "Yann Hicke",
                "Anmol Agarwal",
                "Qianou Ma",
                "Paul Denny"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02775v2",
                "http://arxiv.org/pdf/2311.02775v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02774v1",
            "title": "A stronger connection between the asymptotic rank conjecture and the set\n  cover conjecture",
            "updated": "2023-11-05T21:32:26Z",
            "published": "2023-11-05T21:32:26Z",
            "summary": "We give a short proof that Strassen's asymptotic rank conjecture implies that\nfor every $\\varepsilon > 0$ there exists a $(3/2^{2/3} + \\varepsilon)^n$-time\nalgorithm for set cover on a universe of size $n$ with sets of bounded size.\nThis strengthens and simplifies a recent result of Bj\\\"orklund and Kaski that\nStrassen's asymptotic rank conjecture implies that the set cover conjecture is\nfalse. From another perspective, we show that the set cover conjecture implies\nthat a particular family of tensors $T_n \\in \\mathbb{C}^N \\otimes \\mathbb{C}^N\n\\otimes \\mathbb{C}^N$ has asymptotic rank greater than $N^{1.08}$. Furthermore,\nif one could improve a known upper bound of $\\frac{1}{2}8^n$ on the tensor rank\nof $T_n$ to $\\frac{2}{9 \\cdot n}8^n$ for any $n$, then the set cover conjecture\nis false.",
            "author": [
                "Kevin Pratt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02774v1",
                "http://arxiv.org/pdf/2311.02774v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02772v1",
            "title": "Attention or Convolution: Transformer Encoders in Audio Language Models\n  for Inference Efficiency",
            "updated": "2023-11-05T21:30:10Z",
            "published": "2023-11-05T21:30:10Z",
            "summary": "In this paper, we show that a simple self-supervised pre-trained audio model\ncan achieve comparable inference efficiency to more complicated pre-trained\nmodels with speech transformer encoders. These speech transformers rely on\nmixing convolutional modules with self-attention modules. They achieve\nstate-of-the-art performance on ASR with top efficiency. We first show that\nemploying these speech transformers as an encoder significantly improves the\nefficiency of pre-trained audio models as well. However, our study shows that\nwe can achieve comparable efficiency with advanced self-attention solely. We\ndemonstrate that this simpler approach is particularly beneficial with a\nlow-bit weight quantization technique of a neural network to improve\nefficiency. We hypothesize that it prevents propagating the errors between\ndifferent quantized modules compared to recent speech transformers mixing\nquantized convolution and the quantized self-attention modules.",
            "author": [
                "Sungho Jeon",
                "Ching-Feng Yeh",
                "Hakan Inan",
                "Wei-Ning Hsu",
                "Rashi Rungta",
                "Yashar Mehdad",
                "Daniel Bikel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02772v1",
                "http://arxiv.org/pdf/2311.02772v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02766v2",
            "title": "Riemannian Laplace Approximation with the Fisher Metric",
            "updated": "2023-11-08T00:31:22Z",
            "published": "2023-11-05T20:51:03Z",
            "summary": "The Laplace's method approximates a target density with a Gaussian\ndistribution at its mode. It is computationally efficient and asymptotically\nexact for Bayesian inference due to the Bernstein-von Mises theorem, but for\ncomplex targets and finite-data posteriors it is often too crude an\napproximation. A recent generalization of the Laplace Approximation transforms\nthe Gaussian approximation according to a chosen Riemannian geometry providing\na richer approximation family, while still retaining computational efficiency.\nHowever, as shown here, its properties heavily depend on the chosen metric,\nindeed the metric adopted in previous work results in approximations that are\noverly narrow as well as being biased even at the limit of infinite data. We\ncorrect this shortcoming by developing the approximation family further,\nderiving two alternative variants that are exact at the limit of infinite data,\nextending the theoretical analysis of the method, and demonstrating practical\nimprovements in a range of experiments.",
            "author": [
                "Hanlin Yu",
                "Marcelo Hartmann",
                "Bernardo Williams",
                "Mark Girolami",
                "Arto Klami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02766v2",
                "http://arxiv.org/pdf/2311.02766v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02765v1",
            "title": "Rule Learning as Machine Translation using the Atomic Knowledge Bank",
            "updated": "2023-11-05T20:48:54Z",
            "published": "2023-11-05T20:48:54Z",
            "summary": "Machine learning models, and in particular language models, are being applied\nto various tasks that require reasoning. While such models are good at\ncapturing patterns their ability to reason in a trustable and controlled manner\nis frequently questioned. On the other hand, logic-based rule systems allow for\ncontrolled inspection and already established verification methods. However it\nis well-known that creating such systems manually is time-consuming and prone\nto errors. We explore the capability of transformers to translate sentences\nexpressing rules in natural language into logical rules. We see reasoners as\nthe most reliable tools for performing logical reasoning and focus on\ntranslating language into the format expected by such tools. We perform\nexperiments using the DKET dataset from the literature and create a dataset for\nlanguage to logic translation based on the Atomic knowledge bank.",
            "author": [
                "Kristoffer \u00c6s\u00f8y",
                "Ana Ozaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02765v1",
                "http://arxiv.org/pdf/2311.02765v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02762v2",
            "title": "Fast Sparse 3D Convolution Network with VDB",
            "updated": "2023-11-15T04:38:09Z",
            "published": "2023-11-05T20:43:46Z",
            "summary": "We proposed a new Convolution Neural Network implementation optimized for\nsparse 3D data inference. This implementation uses NanoVDB as the data\nstructure to store the sparse tensor. It leaves a relatively small memory\nfootprint while maintaining high performance. We demonstrate that this\narchitecture is around 20 times faster than the state-of-the-art dense CNN\nmodel on a high-resolution 3D object classification network.",
            "author": [
                "Fangjun Zhou",
                "Anyong Mao",
                "Eftychios Sifakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02762v2",
                "http://arxiv.org/pdf/2311.02762v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02761v1",
            "title": "One-Shot Strategic Classification Under Unknown Costs",
            "updated": "2023-11-05T20:43:08Z",
            "published": "2023-11-05T20:43:08Z",
            "summary": "A primary goal in strategic classification is to learn decision rules which\nare robust to strategic input manipulation. Earlier works assume that strategic\nresponses are known; while some recent works address the important challenge of\nunknown responses, they exclusively study sequential settings which allow\nmultiple model deployments over time. But there are many\ndomains$\\unicode{x2014}$particularly in public policy, a common motivating\nuse-case$\\unicode{x2014}$where multiple deployments are unrealistic, or where\neven a single bad round is undesirable. To address this gap, we initiate the\nstudy of strategic classification under unknown responses in the one-shot\nsetting, which requires committing to a single classifier once. Focusing on the\nusers' cost function as the source of uncertainty, we begin by proving that for\na broad class of costs, even a small mis-estimation of the true cost can entail\narbitrarily low accuracy in the worst case. In light of this, we frame the\none-shot task as a minimax problem, with the goal of identifying the classifier\nwith the smallest worst-case risk over an uncertainty set of possible costs.\nOur main contribution is efficient algorithms for both the full-batch and\nstochastic settings, which we prove converge (offline) to the minimax optimal\nsolution at the dimension-independent rate of\n$\\tilde{\\mathcal{O}}(T^{-\\frac{1}{2}})$. Our analysis reveals important\nstructure stemming from the strategic nature of user responses, particularly\nthe importance of dual norm regularization with respect to the cost function.",
            "author": [
                "Elan Rosenfeld",
                "Nir Rosenfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02761v1",
                "http://arxiv.org/pdf/2311.02761v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02758v1",
            "title": "M4BRAM: Mixed-Precision Matrix-Matrix Multiplication in FPGA Block RAMs",
            "updated": "2023-11-05T20:29:47Z",
            "published": "2023-11-05T20:29:47Z",
            "summary": "Mixed-precision quantization is a popular approach for compressing deep\nneural networks (DNNs). However, it is challenging to scale the performance\nefficiently with mixed-precision DNNs given the current FPGA architecture and\nconventional accelerator dataflows. In this work, we enhance the FPGA's\ncapability for accelerating mixed-precision DNNs by proposing M4BRAM, a novel\ncompute-in-block RAM (BRAM) architecture that can compute mixed-precision\nmatrix-matrix multiplication. On the precision side, M4BRAM supports a wide\nrange of mixed-precision DNN configurations -- the weight precision can be\n2/4/8 bits while the activation precision can vary from 2 to 8 bits. On the\ndataflow side, M4BRAM leverages a novel in-BRAM data duplication scheme to\nachieve high hardware utilization. Moreover, during M4BRAM computation, other\nFPGA resources can seamlessly access its data without the need for a separate\nbuffer. Hence, unlike prior compute-in-BRAM proposals, M4BRAM can\nsimultaneously perform mixed-precision computation and maintain full\nfunctionality as a memory unit to \\textit{truly} complement the existing\ncompute resources on FPGAs. Experiments show that adding M4BRAM to a tiled DNN\naccelerator can achieve an average speedup of 2.16$\\times$ across various DNNs\non the ImageNet classification task while incurring a negligible accuracy loss\nof $<$ 0.5%. Compared to the same tiled accelerator that employs a prior\ncompute-in-BRAM architecture, M4BRAM delivers 1.43$\\times$ higher performance\non average across various DNNs.",
            "author": [
                "Yuzong Chen",
                "Jordan Dotzel",
                "Mohamed S. Abdelfattah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02758v1",
                "http://arxiv.org/pdf/2311.02758v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02754v1",
            "title": "Revisiting primordial black holes formation from preheating\n  instabilities: the case of Starobinsky inflation",
            "updated": "2023-11-05T20:14:39Z",
            "published": "2023-11-05T20:14:39Z",
            "summary": "The primordial black holes (PBHs) formation in the early universe\ninflationary cosmology has received a lot of attention in recent years. One of\nthe ways PBHs formation can be a possibility is the preheating stage after\ninflation and this particular scenario does not require any ad-hoc fine tuning\nof the scalar field potential. In this paper, we focus on the growth of\nprimordial density perturbation and the consequent possibility of PBHs\nformation in the preheating stage of the Starobinsky model for inflation. The\ntypical mechanism for PBH formation during preheating is based on the collapse\nof primordial fluctuations that become super-horizon during inflation (type I)\nand re-enter the particle horizon in the different phases of cosmic expansion.\nIn this work, we show that there exists a certain range of modes that remain in\nthe sub-horizon (not exited) during inflation (type II modes). Those can, in\nthe later phase of evolution, lead to large density perturbation above the\nthreshold and can potentially also contribute to the PBH formation. We obtain\nin detail the conditions that determine the possible collapse of type I and/or\ntype II modes. Since the preheating stage is an 'inflaton' (approximately)\nmatter-dominated phase with the equation of state $w\\ll 1$, we follow the\nframework of the critical collapse of fluctuations and compute the mass\nfraction using the well-known Press-Schechter and the Khlopov-Polnarev\nformalisms, and compare the two. Finally, we comment on the implications of our\nstudy for the investigations concerned with primordial accretion and consequent\nPBH contribution to the dark matter.",
            "author": [
                "Daniel del-Corral",
                "Paolo Gondolo",
                "K. Sravan Kumar",
                "Jo\u00e3o Marto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02754v1",
                "http://arxiv.org/pdf/2311.02754v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02749v1",
            "title": "Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking",
            "updated": "2023-11-05T19:59:36Z",
            "published": "2023-11-05T19:59:36Z",
            "summary": "The world around us is full of soft objects that we as humans learn to\nperceive and deform with dexterous hand movements from a young age. In order\nfor a Robotic hand to be able to control soft objects, it needs to acquire\nonline state feedback of the deforming object. While RGB-D cameras can collect\noccluded information at a rate of 30 Hz, the latter does not represent a\ncontinuously trackable object surface. Hence, in this work, we developed a\nmethod that can create deforming meshes of deforming point clouds at a speed of\nabove 50 Hz for different categories of objects. The reconstruction of meshes\nfrom point clouds has been long studied in the field of Computer graphics under\n3D reconstruction and 4D reconstruction, however both lack the speed and\ngeneralizability needed for robotics applications. Our model is designed using\na point cloud auto-encoder and a Real-NVP architecture. The latter is a\ncontinuous flow neural network with manifold-preservation properties. Our model\ntakes a template mesh which is the mesh of an object in its canonical state and\nthen deforms the template mesh to match a deformed point cloud of the object.\nOur method can perform mesh reconstruction and tracking at a rate of 58 Hz for\ndeformations of six different ycb categories. An instance of a downstream\napplication can be the control algorithm for a robotic hand that requires\nonline feedback from the state of a manipulated object which would allow online\ngrasp adaptation in a closed-loop manner. Furthermore, the tracking capacity\nthat our method provides can help in the system identification of deforming\nobjects in a marker-free approach. In future work, we will extend our method to\nmore categories of objects and real world deforming point clouds",
            "author": [
                "Elham Amin Mansour",
                "Hehui Zheng",
                "Robert K. Katzschmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02749v1",
                "http://arxiv.org/pdf/2311.02749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02748v1",
            "title": "Pyclipse, a library for deidentification of free-text clinical notes",
            "updated": "2023-11-05T19:56:58Z",
            "published": "2023-11-05T19:56:58Z",
            "summary": "Automated deidentification of clinical text data is crucial due to the high\ncost of manual deidentification, which has been a barrier to sharing clinical\ntext and the advancement of clinical natural language processing. However,\ncreating effective automated deidentification tools faces several challenges,\nincluding issues in reproducibility due to differences in text processing,\nevaluation methods, and a lack of consistency across clinical domains and\ninstitutions. To address these challenges, we propose the pyclipse framework, a\nunified and configurable evaluation procedure to streamline the comparison of\ndeidentification algorithms. Pyclipse serves as a single interface for running\nopen-source deidentification algorithms on local clinical data, allowing for\ncontext-specific evaluation. To demonstrate the utility of pyclipse, we compare\nsix deidentification algorithms across four public and two private clinical\ntext datasets. We find that algorithm performance consistently falls short of\nthe results reported in the original papers, even when evaluated on the same\nbenchmark dataset. These discrepancies highlight the complexity of accurately\nassessing and comparing deidentification algorithms, emphasizing the need for a\nreproducible, adjustable, and extensible framework like pyclipse. Our framework\nlays the foundation for a unified approach to evaluate and improve\ndeidentification tools, ultimately enhancing patient protection in clinical\nnatural language processing.",
            "author": [
                "Callandra Moore",
                "Jonathan Ranisau",
                "Walter Nelson",
                "Jeremy Petch",
                "Alistair Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02748v1",
                "http://arxiv.org/pdf/2311.02748v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02747v2",
            "title": "Attention Modules Improve Image-Level Anomaly Detection for Industrial\n  Inspection: A DifferNet Case Study",
            "updated": "2023-11-07T15:54:41Z",
            "published": "2023-11-05T19:48:50Z",
            "summary": "Within (semi-)automated visual industrial inspection, learning-based\napproaches for assessing visual defects, including deep neural networks, enable\nthe processing of otherwise small defect patterns in pixel size on\nhigh-resolution imagery. The emergence of these often rarely occurring defect\npatterns explains the general need for labeled data corpora. To alleviate this\nissue and advance the current state of the art in unsupervised visual\ninspection, this work proposes a DifferNet-based solution enhanced with\nattention modules: AttentDifferNet. It improves image-level detection and\nclassification capabilities on three visual anomaly detection datasets for\nindustrial inspection: InsPLAD-fault, MVTec AD, and Semiconductor Wafer. In\ncomparison to the state of the art, AttentDifferNet achieves improved results,\nwhich are, in turn, highlighted throughout our quali-quantitative study. Our\nquantitative evaluation shows an average improvement - compared to DifferNet -\nof 1.77 +/- 0.25 percentage points in overall AUROC considering all three\ndatasets, reaching SOTA results in InsPLAD-fault, an industrial inspection\nin-the-wild dataset. As our variants to AttentDifferNet show great prospects in\nthe context of currently investigated approaches, a baseline is formulated,\nemphasizing the importance of attention for industrial anomaly detection both\nin the wild and in controlled environments.",
            "author": [
                "Andr\u00e9 Luiz Buarque Vieira e Silva",
                "Francisco Sim\u00f5es",
                "Danny Kowerko",
                "Tobias Schlosser",
                "Felipe Battisti",
                "Veronica Teichrieb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02747v2",
                "http://arxiv.org/pdf/2311.02747v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02745v1",
            "title": "The madness of people: rational learning in feedback-evolving games",
            "updated": "2023-11-05T19:33:25Z",
            "published": "2023-11-05T19:33:25Z",
            "summary": "The replicator equation in evolutionary game theory describes the change in a\npopulation's behaviors over time given suitable incentives. It arises when\nindividuals make decisions using a simple learning process - imitation. A\nrecent emerging framework builds upon this standard model by incorporating\ngame-environment feedback, in which the population's actions affect a shared\nenvironment, and in turn, the changing environment shapes incentives for future\nbehaviors. In this paper, we investigate game-environment feedback when\nindividuals instead use a boundedly rational learning rule known as logit\nlearning. We characterize the resulting system's complete set of fixed points\nand their local stability properties, and how the level of rationality\ndetermines overall environmental outcomes in comparison to imitative learning\nrules. We identify a large parameter space for which logit learning exhibits a\nwide range of dynamics as the rationality parameter is increased from low to\nhigh. Notably, we identify a bifurcation point at which the system exhibits\nstable limit cycles. When the population is highly rational, the limit cycle\ncollapses and a tragedy of the commons becomes stable.",
            "author": [
                "Keith Paarporn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02745v1",
                "http://arxiv.org/pdf/2311.02745v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.SY",
                "eess.SY",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02743v1",
            "title": "Linear extensions of finite posets",
            "updated": "2023-11-05T19:19:46Z",
            "published": "2023-11-05T19:19:46Z",
            "summary": "We give a broad survey of inequalities for the number of linear extensions of\nfinite posets. We review many examples, discuss open problems, and present\nrecent results on the subject. We emphasize the bounds, the equality conditions\nof the inequalities, and the computational complexity aspects of the results.",
            "author": [
                "Swee Hong Chan",
                "Igor Pak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02743v1",
                "http://arxiv.org/pdf/2311.02743v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02742v2",
            "title": "Analytic and numerical bootstrap for the long-range Ising model",
            "updated": "2023-12-01T17:31:17Z",
            "published": "2023-11-05T19:14:18Z",
            "summary": "We combine perturbation theory with analytic and numerical bootstrap\ntechniques to study the critical point of the long-range Ising (LRI) model in\ntwo and three dimensions. This model interpolates between short-range Ising\n(SRI) and mean-field behaviour. We use the Lorentzian inversion formula to\ncompute infinitely many three-loop corrections in the two-dimensional LRI near\nthe mean-field end. We further exploit the exact OPE relations that follow from\nbulk locality of the LRI to compute infinitely many two-loop corrections near\nthe mean-field end, as well as some one-loop corrections near SRI. By including\nsuch exact OPE relations in the crossing equations for LRI we set up a very\nconstrained bootstrap problem, which we solve numerically using SDPB. We find a\nfamily of sharp kinks for two- and three-dimensional theories which compare\nfavourably to perturbative predictions, as well as some Monte Carlo simulations\nfor the two-dimensional LRI.",
            "author": [
                "Connor Behan",
                "Edoardo Lauria",
                "Maria Nocchi",
                "Philine van Vliet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02742v2",
                "http://arxiv.org/pdf/2311.02742v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.stat-mech",
                "cond-mat.str-el",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14688v1",
            "title": "Procedural Fairness Through Decoupling Objectionable Data Generating\n  Components",
            "updated": "2023-11-05T19:07:40Z",
            "published": "2023-11-05T19:07:40Z",
            "summary": "We reveal and address the frequently overlooked yet important issue of\ndisguised procedural unfairness, namely, the potentially inadvertent\nalterations on the behavior of neutral (i.e., not problematic) aspects of data\ngenerating process, and/or the lack of procedural assurance of the greatest\nbenefit of the least advantaged individuals. Inspired by John Rawls's advocacy\nfor pure procedural justice, we view automated decision-making as a microcosm\nof social institutions, and consider how the data generating process itself can\nsatisfy the requirements of procedural fairness. We propose a framework that\ndecouples the objectionable data generating components from the neutral ones by\nutilizing reference points and the associated value instantiation rule. Our\nfindings highlight the necessity of preventing disguised procedural unfairness,\ndrawing attention not only to the objectionable data generating components that\nwe aim to mitigate, but also more importantly, to the neutral components that\nwe intend to keep unaffected.",
            "author": [
                "Zeyu Tang",
                "Jialu Wang",
                "Yang Liu",
                "Peter Spirtes",
                "Kun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14688v1",
                "http://arxiv.org/pdf/2311.14688v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02738v2",
            "title": "Scenario Diffusion: Controllable Driving Scenario Generation With\n  Diffusion",
            "updated": "2023-11-16T23:25:25Z",
            "published": "2023-11-05T19:04:25Z",
            "summary": "Automated creation of synthetic traffic scenarios is a key part of validating\nthe safety of autonomous vehicles (AVs). In this paper, we propose Scenario\nDiffusion, a novel diffusion-based architecture for generating traffic\nscenarios that enables controllable scenario generation. We combine latent\ndiffusion, object detection and trajectory regression to generate distributions\nof synthetic agent poses, orientations and trajectories simultaneously. To\nprovide additional control over the generated scenario, this distribution is\nconditioned on a map and sets of tokens describing the desired scenario. We\nshow that our approach has sufficient expressive capacity to model diverse\ntraffic patterns and generalizes to different geographical regions.",
            "author": [
                "Ethan Pronovost",
                "Meghana Reddy Ganesina",
                "Noureldin Hendy",
                "Zeyu Wang",
                "Andres Morales",
                "Kai Wang",
                "Nicholas Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02738v2",
                "http://arxiv.org/pdf/2311.02738v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02736v1",
            "title": "JRDB-Traj: A Dataset and Benchmark for Trajectory Forecasting in Crowds",
            "updated": "2023-11-05T18:59:31Z",
            "published": "2023-11-05T18:59:31Z",
            "summary": "Predicting future trajectories is critical in autonomous navigation,\nespecially in preventing accidents involving humans, where a predictive agent's\nability to anticipate in advance is of utmost importance. Trajectory\nforecasting models, employed in fields such as robotics, autonomous vehicles,\nand navigation, face challenges in real-world scenarios, often due to the\nisolation of model components. To address this, we introduce a novel dataset\nfor end-to-end trajectory forecasting, facilitating the evaluation of models in\nscenarios involving less-than-ideal preceding modules such as tracking. This\ndataset, an extension of the JRDB dataset, provides comprehensive data,\nincluding the locations of all agents, scene images, and point clouds, all from\nthe robot's perspective. The objective is to predict the future positions of\nagents relative to the robot using raw sensory input data. It bridges the gap\nbetween isolated models and practical applications, promoting a deeper\nunderstanding of navigation dynamics. Additionally, we introduce a novel metric\nfor assessing trajectory forecasting models in real-world scenarios where\nground-truth identities are inaccessible, addressing issues related to\nundetected or over-detected agents. Researchers are encouraged to use our\nbenchmark for model evaluation and benchmarking.",
            "author": [
                "Saeed Saadatnejad",
                "Yang Gao",
                "Hamid Rezatofighi",
                "Alexandre Alahi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02736v1",
                "http://arxiv.org/pdf/2311.02736v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02734v1",
            "title": "ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation\n  and Re-Identification",
            "updated": "2023-11-05T18:51:33Z",
            "published": "2023-11-05T18:51:33Z",
            "summary": "Most object-level mapping systems in use today make use of an upstream\nlearned object instance segmentation model. If we want to teach them about a\nnew object or segmentation class, we need to build a large dataset and retrain\nthe system. To build spatial AI systems that can quickly be taught about new\nobjects, we need to effectively solve the problem of single-shot object\ndetection, instance segmentation and re-identification. So far there is neither\na method fulfilling all of these requirements in unison nor a benchmark that\ncould be used to test such a method. Addressing this, we propose ISAR, a\nbenchmark and baseline method for single- and few-shot object Instance\nSegmentation And Re-identification, in an effort to accelerate the development\nof algorithms that can robustly detect, segment, and re-identify objects from a\nsingle or a few sparse training examples. We provide a semi-synthetic dataset\nof video sequences with ground-truth semantic annotations, a standardized\nevaluation pipeline, and a baseline method. Our benchmark aligns with the\nemerging research trend of unifying Multi-Object Tracking, Video Object\nSegmentation, and Re-identification.",
            "author": [
                "Nicolas Gorlo",
                "Kenneth Blomqvist",
                "Francesco Milano",
                "Roland Siegwart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02734v1",
                "http://arxiv.org/pdf/2311.02734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10753v1",
            "title": "Automating Source Code Refactoring in the Classroom",
            "updated": "2023-11-05T18:46:00Z",
            "published": "2023-11-05T18:46:00Z",
            "summary": "Refactoring is the practice of improving software quality without altering\nits external behavior. Developers intuitively refactor their code for multiple\npurposes, such as improving program comprehension, reducing code complexity,\ndealing with technical debt, and removing code smells. However, no prior\nstudies have exposed the students to an experience of the process of\nantipatterns detection and refactoring correction, and provided students with\ntoolset to practice it. To understand and increase the awareness of refactoring\nconcepts, in this paper, we aim to reflect on our experience with teaching\nrefactoring and how it helps students become more aware of bad programming\npractices and the importance of correcting them via refactoring. This paper\ndiscusses the results of an experiment in the classroom that involved carrying\nout various refactoring activities for the purpose of removing antipatterns\nusing JDeodorant, an Eclipse plugin that supports antipatterns detection and\nrefactoring. The results of the quantitative and qualitative analysis with 171\nstudents show that students tend to appreciate the idea of learning refactoring\nand are satisfied with various aspects of the JDeodorant plugin's operation.\nThrough this experiment, refactoring can turn into a vital part of the\ncomputing educational plan. We envision our findings enabling educators to\nsupport students with refactoring tools tuned towards safer and trustworthy\nrefactoring.",
            "author": [
                "Eman Abdullah AlOmar",
                "Mohamed Wiem Mkaouer",
                "Ali Ouni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10753v1",
                "http://arxiv.org/pdf/2311.10753v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02733v1",
            "title": "AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency\n  for Video Deepfake Detection",
            "updated": "2023-11-05T18:35:03Z",
            "published": "2023-11-05T18:35:03Z",
            "summary": "Multimodal manipulations (also known as audio-visual deepfakes) make it\ndifficult for unimodal deepfake detectors to detect forgeries in multimedia\ncontent. To avoid the spread of false propaganda and fake news, timely\ndetection is crucial. The damage to either modality (i.e., visual or audio) can\nonly be discovered through multi-modal models that can exploit both pieces of\ninformation simultaneously. Previous methods mainly adopt uni-modal video\nforensics and use supervised pre-training for forgery detection. This study\nproposes a new method based on a multi-modal self-supervised-learning (SSL)\nfeature extractor to exploit inconsistency between audio and visual modalities\nfor multi-modal video forgery detection. We use the transformer-based SSL\npre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic\nfeature extractor and a multi-scale temporal convolutional neural network to\ncapture the temporal correlation between the audio and visual modalities. Since\nAV-HuBERT only extracts visual features from the lip region, we also adopt\nanother transformer-based video model to exploit facial features and capture\nspatial and temporal artifacts caused during the deepfake generation process.\nExperimental results show that our model outperforms all existing models and\nachieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT\ndatasets.",
            "author": [
                "Sahibzada Adil Shahzad",
                "Ammarah Hashmi",
                "Yan-Tsung Peng",
                "Yu Tsao",
                "Hsin-Min Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02733v1",
                "http://arxiv.org/pdf/2311.02733v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02732v1",
            "title": "Solving High Dimensional Partial Differential Equations Using Tensor\n  Neural Network and A Posteriori Error Estimators",
            "updated": "2023-11-05T18:31:04Z",
            "published": "2023-11-05T18:31:04Z",
            "summary": "In this paper, we first propose a new type of tensor neural network and the\ncorresponding machine learning method to solve high-dimensional boundary value\nproblems with Dirichlet or Neumann type of boundary conditions and eigenvalue\nproblems of the second order elliptic operator. The most important advantage of\nthe proposed network is that when calculating the loss function, the high\ndimensional integration can be computed with high accuracy using fixed\nquadrature points within tolerable computational complexity. Based on the\ntheory of a posteriori error estimation, a machine learning method which use a\nposteriori error estimator as the loss function is designed to select optimal\nnetwork parameters adaptively. The theoretical analysis and numerical examples\nare provided to validate the proposed methods.",
            "author": [
                "Yifan Wang",
                "Zhongshuo Lin",
                "Yangfei Liao",
                "Haochen Liu",
                "Hehu Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02732v1",
                "http://arxiv.org/pdf/2311.02732v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "68T07, 65L70, 65N25, 65B99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02730v1",
            "title": "Spontaneous baryogenesis and generation of gravitational waves in a new\n  model of quintessential $\u03b1$-attractor",
            "updated": "2023-11-05T18:30:38Z",
            "published": "2023-11-05T18:30:38Z",
            "summary": "We apply a new version of quintessential $\\alpha$-attractor inflaton\npotential (arXiv: 2305.00230 [gr-qc]) to make a detailed analysis of the\nphenomenon of \\emph{spontaneous baryogenesis} in the post-inflationary kination\nperiod. In this context, we compute various temperatures, their respective\nnumber of e-folds, densities and the freeze-out values of baryon-to-entropy\nratio ($\\eta_F$) at different mass scales, as functions of $\\alpha$. The\nnumerical calculations show that the baryon-to-entropy ratio is obtained as:\nfor $\\alpha = 0.29 - 0.30$, $\\eta_F = 8.7\\times 10^{-11} - 8.5\\times 10^{-11}$\nand for $\\alpha = 4.2 - 4.3$, $\\eta_F = 8.5\\times 10^{-11} - 8.6\\times\n10^{-11}$. The results are found to satisfy experimental bounds quite\nsatisfactorily. We also find a blue-tilted spectrum of relic gravitational\nwaves (GW) of frequencies lying in two narrow bands corresponding to the two\nregions of $\\alpha$, indicated above, \\emph{viz.,} $f_{\\mathrm{end}} =\n2.00\\times 10^{10} - 2.10\\times 10^{10}$ Hz for lower region of $\\alpha$ and\n$f_{\\mathrm{end}} = 2.12\\times 10^{10} - 2.11\\times 10^{10}$ Hz for higher\nregion of $\\alpha$, during transition from inflation to kination, which is\nsupported by current literature. The present-day peak values of the amplitudes\nof GWs emitted during radiation domination,\n($(\\Omega_{\\mathrm{GW},0}^{(\\mathrm{RD})})_{\\mathrm{peak}}$), are found to be\n$\\sim 10^{-7}$, which is consistent with the requirement for nucleosynthesis\nand the associated root-mean-square values,\n($\\Omega_{\\mathrm{GW},0}^{(\\mathrm{RD})}\\sim 10^{-18}$), conform to the\ncharacteristic strain of the ongoing GW-detectors. In this way, a unified\npicture of the roles of quintessential $\\alpha$-attractor model, considered\nhere, in inflation, quintessence, spontaneous baryogenesis and the\ngravitational waves production, emerges from the present study.",
            "author": [
                "Arunoday Sarkar",
                "Buddhadeb Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02730v1",
                "http://arxiv.org/pdf/2311.02730v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16143v1",
            "title": "Ransomware Detection and Classification using Machine Learning",
            "updated": "2023-11-05T18:16:53Z",
            "published": "2023-11-05T18:16:53Z",
            "summary": "Vicious assaults, malware, and various ransomware pose a cybersecurity\nthreat, causing considerable damage to computer structures, servers, and mobile\nand web apps across various industries and businesses. These safety concerns\nare important and must be addressed immediately. Ransomware detection and\nclassification are critical for guaranteeing rapid reaction and prevention.\nThis study uses the XGBoost classifier and Random Forest (RF) algorithms to\ndetect and classify ransomware attacks. This approach involves analyzing the\nbehaviour of ransomware and extracting relevant features that can help\ndistinguish between different ransomware families. The models are evaluated on\na dataset of ransomware attacks and demonstrate their effectiveness in\naccurately detecting and classifying ransomware. The results show that the\nXGBoost classifier, Random Forest Classifiers, can effectively detect and\nclassify different ransomware attacks with high accuracy, thereby providing a\nvaluable tool for enhancing cybersecurity.",
            "author": [
                "Kavitha Kunku",
                "ANK Zaman",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16143v1",
                "http://arxiv.org/pdf/2311.16143v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02726v1",
            "title": "For how many iterations should we run Markov chain Monte Carlo?",
            "updated": "2023-11-05T18:11:59Z",
            "published": "2023-11-05T18:11:59Z",
            "summary": "Standard Markov chain Monte Carlo (MCMC) admits three fundamental control\nparameters: the number of chains, the length of the warmup phase, and the\nlength of the sampling phase. These control parameters play a large role in\ndetermining the amount of computation we deploy. In practice, we need to walk a\nline between achieving sufficient precision and not wasting precious\ncomputational resources and time. We review general strategies to check the\nlength of the warmup and sampling phases, and examine the three control\nparameters of MCMC in the contexts of CPU- and GPU-based hardware. Our\ndiscussion centers around three tasks: (1) inference about a latent variable,\n(2) computation of expectation values and quantiles, and (3) diagnostics to\ncheck the reliability of the estimators.\n  This chapter begins with general recommendations on the control parameters of\nMCMC, which have been battle-tested over the years and often motivate defaults\nin Bayesian statistical software. Usually we do not know ahead of time how a\nsampler will interact with a target distribution, and so the choice of MCMC\nalgorithm and its control parameters, tend to be based on experience,\nre-evaluated after simulations have been obtained and analyzed. The second part\nof this chapter provides a theoretical motivation for our recommended approach,\nwith pointers to some concerns and open problems. We also examine recent\ndevelopments on the algorithmic and hardware fronts, which motivate new\ncomputational approaches to MCMC.",
            "author": [
                "Charles C. Margossian",
                "Andrew Gelman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02726v1",
                "http://arxiv.org/pdf/2311.02726v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02719v1",
            "title": "Uncertainty Estimation for Safety-critical Scene Segmentation via\n  Fine-grained Reward Maximization",
            "updated": "2023-11-05T17:43:37Z",
            "published": "2023-11-05T17:43:37Z",
            "summary": "Uncertainty estimation plays an important role for future reliable deployment\nof deep segmentation models in safety-critical scenarios such as medical\napplications. However, existing methods for uncertainty estimation have been\nlimited by the lack of explicit guidance for calibrating the prediction risk\nand model confidence. In this work, we propose a novel fine-grained reward\nmaximization (FGRM) framework, to address uncertainty estimation by directly\nutilizing an uncertainty metric related reward function with a reinforcement\nlearning based model tuning algorithm. This would benefit the model uncertainty\nestimation through direct optimization guidance for model calibration.\nSpecifically, our method designs a new uncertainty estimation reward function\nusing the calibration metric, which is maximized to fine-tune an evidential\nlearning pre-trained segmentation model for calibrating prediction risk.\nImportantly, we innovate an effective fine-grained parameter update scheme,\nwhich imposes fine-grained reward-weighting of each network parameter according\nto the parameter importance quantified by the fisher information matrix. To the\nbest of our knowledge, this is the first work exploring reward optimization for\nmodel uncertainty estimation in safety-critical vision tasks. The effectiveness\nof our method is demonstrated on two large safety-critical surgical scene\nsegmentation datasets under two different uncertainty estimation settings. With\nreal-time one forward pass at inference, our method outperforms\nstate-of-the-art methods by a clear margin on all the calibration metrics of\nuncertainty estimation, while maintaining a high task accuracy for the\nsegmentation results. Code is available at\n\\url{https://github.com/med-air/FGRM}.",
            "author": [
                "Hongzheng Yang",
                "Cheng Chen",
                "Yueyao Chen",
                "Markus Scheppach",
                "Hon Chi Yip",
                "Qi Dou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02719v1",
                "http://arxiv.org/pdf/2311.02719v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03402v2",
            "title": "CycleCL: Self-supervised Learning for Periodic Videos",
            "updated": "2023-11-13T13:09:49Z",
            "published": "2023-11-05T17:40:10Z",
            "summary": "Analyzing periodic video sequences is a key topic in applications such as\nautomatic production systems, remote sensing, medical applications, or physical\ntraining. An example is counting repetitions of a physical exercise. Due to the\ndistinct characteristics of periodic data, self-supervised methods designed for\nstandard image datasets do not capture changes relevant to the progression of\nthe cycle and fail to ignore unrelated noise. They thus do not work well on\nperiodic data. In this paper, we propose CycleCL, a self-supervised learning\nmethod specifically designed to work with periodic data. We start from the\ninsight that a good visual representation for periodic data should be sensitive\nto the phase of a cycle, but be invariant to the exact repetition, i.e. it\nshould generate identical representations for a specific phase throughout all\nrepetitions. We exploit the repetitions in videos to design a novel contrastive\nlearning method based on a triplet loss that optimizes for these desired\nproperties. Our method uses pre-trained features to sample pairs of frames from\napproximately the same phase and negative pairs of frames from different\nphases. Then, we iterate between optimizing a feature encoder and resampling\ntriplets, until convergence. By optimizing a model this way, we are able to\nlearn features that have the mentioned desired properties. We evaluate CycleCL\non an industrial and multiple human actions datasets, where it significantly\noutperforms previous video-based self-supervised learning methods on all tasks.",
            "author": [
                "Matteo Destro",
                "Michael Gygli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03402v2",
                "http://arxiv.org/pdf/2311.03402v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02712v1",
            "title": "Complete set of bounds for the technical moduli in 3D anisotropic\n  elasticity",
            "updated": "2023-11-05T17:05:22Z",
            "published": "2023-11-05T17:05:22Z",
            "summary": "The paper addresses the problem of finding the necessary and sufficient\nconditions to be satisfied by the engineering moduli of an anisotropic material\nfor the elastic energy to be positive for each state of strain or stress. The\nproblem is solved first in the most general case of a triclinic material and\nthen each possible case of elastic syngony is treated as a special case. The\nmethod of analysis is based upon a rather forgotten theorem of linear algebra\nand, in the most general case, the calculations, too much involved, are carried\nout using a formal computation code. New, specific bounds, concerning some of\nthe technical constants, are also found.",
            "author": [
                "Paolo Vannucci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02712v1",
                "http://arxiv.org/pdf/2311.02712v1"
            ],
            "primary_category": "physics.class-ph",
            "category": [
                "physics.class-ph",
                "74B05, 74E10, 74G45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02709v1",
            "title": "Benchmarking a Benchmark: How Reliable is MS-COCO?",
            "updated": "2023-11-05T16:55:40Z",
            "published": "2023-11-05T16:55:40Z",
            "summary": "Benchmark datasets are used to profile and compare algorithms across a\nvariety of tasks, ranging from image classification to segmentation, and also\nplay a large role in image pretraining algorithms. Emphasis is placed on\nresults with little regard to the actual content within the dataset. It is\nimportant to question what kind of information is being learned from these\ndatasets and what are the nuances and biases within them. In the following\nwork, Sama-COCO, a re-annotation of MS-COCO, is used to discover potential\nbiases by leveraging a shape analysis pipeline. A model is trained and\nevaluated on both datasets to examine the impact of different annotation\nconditions. Results demonstrate that annotation styles are important and that\nannotation pipelines should closely consider the task of interest. The dataset\nis made publicly available at https://www.sama.com/sama-coco-dataset/ .",
            "author": [
                "Eric Zimmermann",
                "Justin Szeto",
                "Jerome Pasquero",
                "Frederic Ratle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02709v1",
                "http://arxiv.org/pdf/2311.02709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02707v1",
            "title": "An Empirical Study of Uncertainty in Polygon Annotation and the Impact\n  of Quality Assurance",
            "updated": "2023-11-05T16:44:53Z",
            "published": "2023-11-05T16:44:53Z",
            "summary": "Polygons are a common annotation format used for quickly annotating objects\nin instance segmentation tasks. However, many real-world annotation projects\nrequest near pixel-perfect labels. While strict pixel guidelines may appear to\nbe the solution to a successful project, practitioners often fail to assess the\nfeasibility of the work requested, and overlook common factors that may\nchallenge the notion of quality. This paper aims to examine and quantify the\ninherent uncertainty for polygon annotations and the role that quality\nassurance plays in minimizing its effect. To this end, we conduct an analysis\non multi-rater polygon annotations for several objects from the MS-COCO\ndataset. The results demonstrate that the reliability of a polygon annotation\nis dependent on a reviewing procedure, as well as the scene and shape\ncomplexity.",
            "author": [
                "Eric Zimmermann",
                "Justin Szeto",
                "Frederic Ratle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02707v1",
                "http://arxiv.org/pdf/2311.02707v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02704v1",
            "title": "A Goal-Driven Approach to Systems Neuroscience",
            "updated": "2023-11-05T16:37:53Z",
            "published": "2023-11-05T16:37:53Z",
            "summary": "Humans and animals exhibit a range of interesting behaviors in dynamic\nenvironments, and it is unclear how our brains actively reformat this dense\nsensory information to enable these behaviors. Experimental neuroscience is\nundergoing a revolution in its ability to record and manipulate hundreds to\nthousands of neurons while an animal is performing a complex behavior. As these\nparadigms enable unprecedented access to the brain, a natural question that\narises is how to distill these data into interpretable insights about how\nneural circuits give rise to intelligent behaviors. The classical approach in\nsystems neuroscience has been to ascribe well-defined operations to individual\nneurons and provide a description of how these operations combine to produce a\ncircuit-level theory of neural computations. While this approach has had some\nsuccess for small-scale recordings with simple stimuli, designed to probe a\nparticular circuit computation, often times these ultimately lead to disparate\ndescriptions of the same system across stimuli. Perhaps more strikingly, many\nresponse profiles of neurons are difficult to succinctly describe in words,\nsuggesting that new approaches are needed in light of these experimental\nobservations. In this thesis, we offer a different definition of\ninterpretability that we show has promise in yielding unified structural and\nfunctional models of neural circuits, and describes the evolutionary\nconstraints that give rise to the response properties of the neural population,\nincluding those that have previously been difficult to describe individually.\nWe demonstrate the utility of this framework across multiple brain areas and\nspecies to study the roles of recurrent processing in the primate ventral\nvisual pathway; mouse visual processing; heterogeneity in rodent medial\nentorhinal cortex; and facilitating biological learning.",
            "author": [
                "Aran Nayebi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02704v1",
                "http://arxiv.org/pdf/2311.02704v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02702v1",
            "title": "Extraction of Atypical Aspects from Customer Reviews: Datasets and\n  Experiments with Language Models",
            "updated": "2023-11-05T16:15:50Z",
            "published": "2023-11-05T16:15:50Z",
            "summary": "A restaurant dinner may become a memorable experience due to an unexpected\naspect enjoyed by the customer, such as an origami-making station in the\nwaiting area. If aspects that are atypical for a restaurant experience were\nknown in advance, they could be leveraged to make recommendations that have the\npotential to engender serendipitous experiences, further increasing user\nsatisfaction. Although relatively rare, whenever encountered, atypical aspects\noften end up being mentioned in reviews due to their memorable quality.\nCorrespondingly, in this paper we introduce the task of detecting atypical\naspects in customer reviews. To facilitate the development of extraction\nmodels, we manually annotate benchmark datasets of reviews in three domains -\nrestaurants, hotels, and hair salons, which we use to evaluate a number of\nlanguage models, ranging from fine-tuning the instruction-based text-to-text\ntransformer Flan-T5 to zero-shot and few-shot prompting of GPT-3.5.",
            "author": [
                "Smita Nannaware",
                "Erfan Al-Hossami",
                "Razvan Bunescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02702v1",
                "http://arxiv.org/pdf/2311.02702v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02700v1",
            "title": "A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth\n  Draping",
            "updated": "2023-11-05T16:12:48Z",
            "published": "2023-11-05T16:12:48Z",
            "summary": "RGB cloth generation has been deeply studied in the related literature,\nhowever, 3D garment generation remains an open problem. In this paper, we build\na conditional variational autoencoder for 3D garment generation and draping. We\npropose a pyramid network to add garment details progressively in a canonical\nspace, i.e. unposing and unshaping the garments w.r.t. the body. We study\nconditioning the network on surface normal UV maps, as an intermediate\nrepresentation, which is an easier problem to optimize than 3D coordinates. Our\nresults on two public datasets, CLOTH3D and CAPE, show that our model is\nrobust, controllable in terms of detail generation by the use of\nmulti-resolution pyramids, and achieves state-of-the-art results that can\nhighly generalize to unseen garments, poses, and shapes even when training with\nsmall amounts of data.",
            "author": [
                "Hunor Laczk\u00f3",
                "Meysam Madadi",
                "Sergio Escalera",
                "Jordi Gonzalez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02700v1",
                "http://arxiv.org/pdf/2311.02700v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02699v1",
            "title": "Nepali Video Captioning using CNN-RNN Architecture",
            "updated": "2023-11-05T16:09:40Z",
            "published": "2023-11-05T16:09:40Z",
            "summary": "This article presents a study on Nepali video captioning using deep neural\nnetworks. Through the integration of pre-trained CNNs and RNNs, the research\nfocuses on generating precise and contextually relevant captions for Nepali\nvideos. The approach involves dataset collection, data preprocessing, model\nimplementation, and evaluation. By enriching the MSVD dataset with Nepali\ncaptions via Google Translate, the study trains various CNN-RNN architectures.\nThe research explores the effectiveness of CNNs (e.g., EfficientNetB0,\nResNet101, VGG16) paired with different RNN decoders like LSTM, GRU, and\nBiLSTM. Evaluation involves BLEU and METEOR metrics, with the best model being\nEfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score\nof 17 and METEOR score of 46. The article also outlines challenges and future\ndirections for advancing Nepali video captioning, offering a crucial resource\nfor further research in this area.",
            "author": [
                "Bipesh Subedi",
                "Saugat Singh",
                "Bal Krishna Bal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02699v1",
                "http://arxiv.org/pdf/2311.02699v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG",
                "I.2.7; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02692v1",
            "title": "ChEF: A Comprehensive Evaluation Framework for Standardized Assessment\n  of Multimodal Large Language Models",
            "updated": "2023-11-05T16:01:40Z",
            "published": "2023-11-05T16:01:40Z",
            "summary": "Multimodal Large Language Models (MLLMs) have shown impressive abilities in\ninteracting with visual content with myriad potential downstream tasks.\nHowever, even though a list of benchmarks has been proposed, the capabilities\nand limitations of MLLMs are still not comprehensively understood, due to a\nlack of a standardized and holistic evaluation framework. To this end, we\npresent the first Comprehensive Evaluation Framework (ChEF) that can\nholistically profile each MLLM and fairly compare different MLLMs. First, we\nstructure ChEF as four modular components, i.e., Scenario as scalable\nmultimodal datasets, Instruction as flexible instruction retrieving formulae,\nInferencer as reliable question answering strategies, and Metric as indicative\ntask-specific score functions. Based on them, ChEF facilitates versatile\nevaluations in a standardized framework, and new evaluations can be built by\ndesigning new Recipes (systematic selection of these four components). Notably,\ncurrent MLLM benchmarks can be readily summarized as recipes of ChEF. Second,\nwe introduce 6 new recipes to quantify competent MLLMs' desired capabilities\n(or called desiderata, i.e., calibration, in-context learning, instruction\nfollowing, language performance, hallucination, and robustness) as reliable\nagents that can perform real-world multimodal interactions. Third, we conduct a\nlarge-scale evaluation of 9 prominent MLLMs on 9 scenarios and 6 desiderata.\nOur evaluation summarized over 20 valuable observations concerning the\ngeneralizability of MLLMs across various scenarios and the composite capability\nof MLLMs required for multimodal interactions. We will publicly release all the\ndetailed implementations for further analysis, as well as an easy-to-use\nmodular toolkit for the integration of new recipes and models, so that ChEF can\nbe a growing evaluation framework for the MLLM community.",
            "author": [
                "Zhelun Shi",
                "Zhipin Wang",
                "Hongxing Fan",
                "Zhenfei Yin",
                "Lu Sheng",
                "Yu Qiao",
                "Jing Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02692v1",
                "http://arxiv.org/pdf/2311.02692v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14687v1",
            "title": "Does Explainable AI Have Moral Value?",
            "updated": "2023-11-05T15:59:27Z",
            "published": "2023-11-05T15:59:27Z",
            "summary": "Explainable AI (XAI) aims to bridge the gap between complex algorithmic\nsystems and human stakeholders. Current discourse often examines XAI in\nisolation as either a technological tool, user interface, or policy mechanism.\nThis paper proposes a unifying ethical framework grounded in moral duties and\nthe concept of reciprocity. We argue that XAI should be appreciated not merely\nas a right, but as part of our moral duties that helps sustain a reciprocal\nrelationship between humans affected by AI systems. This is because, we argue,\nexplanations help sustain constitutive symmetry and agency in AI-led\ndecision-making processes. We then assess leading XAI communities and reveal\ngaps between the ideal of reciprocity and practical feasibility. Machine\nlearning offers useful techniques but overlooks evaluation and adoption\nchallenges. Human-computer interaction provides preliminary insights but\noversimplifies organizational contexts. Policies espouse accountability but\nlack technical nuance. Synthesizing these views exposes barriers to\nimplementable, ethical XAI. Still, positioning XAI as a moral duty transcends\nrights-based discourse to capture a more robust and complete moral picture.\nThis paper provides an accessible, detailed analysis elucidating the moral\nvalue of explainability.",
            "author": [
                "Joshua L. M. Brand",
                "Luca Nannini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14687v1",
                "http://arxiv.org/pdf/2311.14687v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02685v1",
            "title": "Computing Remoteness Functions of Moore, Wythoff, and Euclid's games",
            "updated": "2023-11-05T15:49:43Z",
            "published": "2023-11-05T15:49:43Z",
            "summary": "We study remoteness function $\\mathcal R$ of impartial games introduced by\nSmith in 1966. The player who moves from a position $x$ can win if and only if\n$\\mathcal R(x)$ is odd. The odd values of $\\mathcal R(x)$ show how soon the\nwinner can win, while even values show how long the loser can resist, provided\nboth players play optimally. This function can be applied to the conjunctive\ncompounds of impartial games, in the same way as the Sprague-Grundy function is\napplicable to their disjunctive compounds.\n  We provide polynomial algorithms computing $\\mathcal R(x)$ for games Euclid\nand generalized Wythoff. For Moore's NIM we give a simple explicit formula for\n$\\mathcal R(x)$ if it is even and show that computing it becomes an NP-hard\nproblem for the odd values.",
            "author": [
                "Endre Boros",
                "Vladimir Gurvich",
                "Kazuhisa Makino",
                "Michael Vyalyi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02685v1",
                "http://arxiv.org/pdf/2311.02685v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.GT",
                "91A05, 91A46, 91A68"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02684v1",
            "title": "Octavius: Mitigating Task Interference in MLLMs via MoE",
            "updated": "2023-11-05T15:48:29Z",
            "published": "2023-11-05T15:48:29Z",
            "summary": "Recent studies have demonstrated Large Language Models (LLMs) can extend\ntheir zero-shot generalization capabilities to multimodal learning through\ninstruction tuning. As more modalities and downstream tasks are introduced,\nnegative conflicts and interference may have a worse impact on performance.\nWhile this phenomenon has been overlooked in previous work, we propose a novel\nand extensible framework, called \\mname, for comprehensive studies and\nexperimentation on multimodal learning with Multimodal Large Language Models\n(MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and\none of the representative PEFT techniques, \\emph{i.e.,} LoRA, designing a novel\nLLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental\nresults (about 20\\% improvement) have shown the effectiveness and versatility\nof our design in various 2D and 3D downstream tasks. Code and corresponding\ndataset will be available soon.",
            "author": [
                "Zeren Chen",
                "Ziqin Wang",
                "Zhen Wang",
                "Huayang Liu",
                "Zhenfei Yin",
                "Si Liu",
                "Lu Sheng",
                "Wanli Ouyang",
                "Yu Qiao",
                "Jing Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02684v1",
                "http://arxiv.org/pdf/2311.02684v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03400v1",
            "title": "QOMIC: Quantum optimization for motif identification",
            "updated": "2023-11-05T14:48:12Z",
            "published": "2023-11-05T14:48:12Z",
            "summary": "Network motif identification problem aims to find topological patterns in\nbiological networks. Identifying non-overlapping motifs is a computationally\nchallenging problem using classical computers. Quantum computers enable solving\nhigh complexity problems which do not scale using classical computers. In this\npaper, we develop the first quantum solution, called QOMIC (Quantum\nOptimization for Motif IdentifiCation), to the motif identification problem.\nQOMIC transforms the motif identification problem using a integer model, which\nserves as the foundation to develop our quantum solution. We develop and\nimplement the quantum circuit to find motif locations in the given network\nusing this model. Our experiments demonstrate that QOMIC outperforms the\nexisting solutions developed for the classical computer, in term of motif\ncounts. We also observe that QOMIC can efficiently find motifs in human\nregulatory networks associated with five neurodegenerative diseases:\nAlzheimers, Parkinsons, Huntingtons, Amyotrophic Lateral Sclerosis (ALS), and\nMotor Neurone Disease (MND).",
            "author": [
                "Hoang M. Ngo",
                "Tamim Khatib",
                "My T. Thai",
                "Tamer Kahveci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03400v1",
                "http://arxiv.org/pdf/2311.03400v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09239v1",
            "title": "On the impossibility of using analogue machines to calculate\n  non-computable functions",
            "updated": "2023-11-05T14:39:13Z",
            "published": "2023-11-05T14:39:13Z",
            "summary": "A number of examples have been given of physical systems (both classical and\nquantum mechanical) which when provided with a (continuously variable)\ncomputable input will give a non-computable output. It has been suggested that\nthese systems might allow one to design analogue machines which would calculate\nthe values of some number-theoretic non-computable function. Analysis of the\nexamples show that the suggestion is wrong. In Section 4 I claim that given a\nreasonable definition of analogue machine it will always be wrong. The claim is\nto be read not so much as a dogmatic assertion, but rather as a challenge.\n  In Sections 1 and 2 I discuss analogue machines, and lay down some conditions\nwhich I believe they must satisfy. In Section I discuss the particular forms\nwhich a paradigm undecidable problem (or non-computable function) may take. In\nSections 5 and 6 I justify any claim for two particular examples lying within\nthe range of classical physics, and in Section 7 I justify it for two (closely\nconnected) examples from quantum mechanics, and discuss, very briefly, other\npossible quantum mechanical situations. Section 8 contains various remarks and\ncomments. In Section 9 I consider the suggestion made by Penrose that a\n(future) theory of quantum gravity may predict non-locally-determined, and\nperhaps non-computable patterns of growth for microsopic structures. My\nconclusion is that such a theory will have to have non-computability built into\nit.",
            "author": [
                "R. O. Gandy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09239v1",
                "http://arxiv.org/pdf/2311.09239v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "math.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13603v1",
            "title": "Cross-layer scheme for low latency multiple description video streaming\n  over Vehicular Ad-hoc NETworks (VANETs)",
            "updated": "2023-11-05T14:34:58Z",
            "published": "2023-11-05T14:34:58Z",
            "summary": "There is nowadays a growing demand in vehicular communications for real-time\napplications requiring video assistance. The new state-of-the-art\nhigh-efficiency video coding (HEVC) standard is very promising for real-time\nvideo streaming. It offers high coding efficiency, as well as dedicated low\ndelay coding structures. Among these, the all intra (AI) coding structure\nguarantees minimal coding time at the expense of higher video bitrates, which\ntherefore penalizes transmission performances. In this work, we propose an\noriginal cross-layer system in order to enhance received video quality in\nvehicular communications. The system is low complex and relies on a multiple\ndescription coding (MDC) approach. It is based on an adaptive mapping mechanism\napplied at the IEEE 802.11p standard medium access control (MAC) layer.\nSimulation results in a realistic vehicular environment demonstrate that for\nlow delay video communications, the proposed method provides significant video\nquality improvements on the receiver side.",
            "author": [
                "Mohamed Aymen Labiod",
                "Mohamed Gharbi",
                "Francois-Xavier Coudoux",
                "Patrick Corlay",
                "Noureddine Doghmane"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.aeue.2019.03.001.",
                "http://arxiv.org/abs/2311.13603v1",
                "http://arxiv.org/pdf/2311.13603v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "cs.NI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02667v1",
            "title": "Race Against the Machine: a Fully-annotated, Open-design Dataset of\n  Autonomous and Piloted High-speed Flight",
            "updated": "2023-11-05T14:22:44Z",
            "published": "2023-11-05T14:22:44Z",
            "summary": "Unmanned aerial vehicles, and multi-rotors in particular, can now perform\ndexterous tasks in impervious environments, from infrastructure monitoring to\nemergency deliveries. Autonomous drone racing has emerged as an ideal benchmark\nto develop and evaluate these capabilities. Its challenges include accurate and\nrobust visual-inertial odometry during aggressive maneuvers, complex\naerodynamics, and constrained computational resources. As researchers\nincreasingly channel their efforts into it, they also need the tools to timely\nand equitably compare their results and advances. With this dataset, we want to\n(i) support the development of new methods and (ii) establish quantitative\ncomparisons for approaches coming from the broader robotics, controls, and\nartificial intelligence communities. We want to provide a one-stop resource\nthat is comprehensive of (i) aggressive autonomous and piloted flight, (ii)\nhigh-resolution, high-frequency visual, inertial, and motion capture data,\n(iii) commands and control inputs, (iv) multiple light settings, and (v)\ncorner-level labeling of drone racing gates. We also release the complete\nspecifications to recreate our flight platform, using commercial off-the-shelf\ncomponents and the open-source flight controller Betaflight. Our dataset,\nopen-source scripts, and drone design are available at:\nhttps://github.com/tii-racing/drone-racing-dataset.",
            "author": [
                "Michael Bosello",
                "Davide Aguiari",
                "Yvo Keuter",
                "Enrico Pallotta",
                "Sara Kiade",
                "Gyordan Caminati",
                "Flavio Pinzarrone",
                "Junaid Halepota",
                "Jacopo Panerati",
                "Giovanni Pau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02667v1",
                "http://arxiv.org/pdf/2311.02667v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02665v1",
            "title": "Digital Typhoon: Long-term Satellite Image Dataset for the\n  Spatio-Temporal Modeling of Tropical Cyclones",
            "updated": "2023-11-05T14:22:13Z",
            "published": "2023-11-05T14:22:13Z",
            "summary": "This paper presents the official release of the Digital Typhoon dataset, the\nlongest typhoon satellite image dataset for 40+ years aimed at benchmarking\nmachine learning models for long-term spatio-temporal data. To build the\ndataset, we developed a workflow to create an infrared typhoon-centered image\nfor cropping using Lambert azimuthal equal-area projection referring to the\nbest track data. We also address data quality issues such as inter-satellite\ncalibration to create a homogeneous dataset. To take advantage of the dataset,\nwe organized machine learning tasks by the types and targets of inference, with\nother tasks for meteorological analysis, societal impact, and climate change.\nThe benchmarking results on the analysis, forecasting, and reanalysis for the\nintensity suggest that the dataset is challenging for recent deep learning\nmodels, due to many choices that affect the performance of various models. This\ndataset reduces the barrier for machine learning researchers to meet\nlarge-scale real-world events called tropical cyclones and develop machine\nlearning models that may contribute to advancing scientific knowledge on\ntropical cyclones as well as solving societal and sustainability issues such as\ndisaster reduction and climate change. The dataset is publicly available at\nhttp://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and\nhttps://github.com/kitamoto-lab/digital-typhoon/.",
            "author": [
                "Asanobu Kitamoto",
                "Jared Hwang",
                "Bastien Vuillod",
                "Lucas Gautier",
                "Yingtao Tian",
                "Tarin Clanuwat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02665v1",
                "http://arxiv.org/pdf/2311.02665v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02664v1",
            "title": "Enhanced adaptive cross-layer scheme for low latency HEVC streaming over\n  Vehicular Ad-hoc Networks (VANETs)",
            "updated": "2023-11-05T14:19:38Z",
            "published": "2023-11-05T14:19:38Z",
            "summary": "Vehicular communication has become a reality guided by various applications.\nAmong those, high video quality delivery with low latency constraints required\nby real-time applications constitutes a very challenging task. By dint of its\nnever-before-achieved compression level, the new High-Efficiency Video Coding\n(HEVC) is very promising for real-time video streaming through Vehicular Ad-hoc\nNetworks (VANET). However, these networks have variable channel quality and\nlimited bandwidth. Therefore, ensuring satisfactory video quality on such\nnetworks is a major challenge. In this work, a low complexity cross-layer\nmechanism is proposed to improve end-to-end performances of HEVC video\nstreaming in VANET under low delay constraints. The idea is to assign to each\npacket of the transmitted video the most appropriate Access Category (AC) queue\non the Medium Access Control (MAC) layer, considering the temporal prediction\nstructure of the video encoding process, the importance of the frame and the\nstate of the network traffic load. Simulation results demonstrate that for\ndifferent targeted low-delay video communication scenarios, the proposed\nmechanism offers significant improvements regarding video quality at the\nreception and end-to-end delay compared to the Enhanced Distributed Channel\nAccess (EDCA) adopted in the 802.11p. Both Quality of Service (QoS) and Quality\nof Experience (QoE) evaluations have been also carried out to validate the\nproposed approach.",
            "author": [
                "Mohamed Aymen Labiod",
                "Mohamed Gharbi",
                "Fran\u00e7ois-Xavier Coudoux",
                "Patrick Corlay",
                "Noureddine Doghmane"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.vehcom.2018.11.004",
                "http://arxiv.org/abs/2311.02664v1",
                "http://arxiv.org/pdf/2311.02664v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02663v1",
            "title": "Towards finite element exterior calculus over manifolds: commuting\n  projections, geometric variational crimes, and approximation errors",
            "updated": "2023-11-05T14:16:38Z",
            "published": "2023-11-05T14:16:38Z",
            "summary": "We survey recent contributions to finite element exterior calculus over\nmanifolds and surfaces within a comprehensive formalism for the error analysis\nof vector-valued partial differential equations over manifolds. Our primary\nfocus is on uniformly bounded commuting projections over manifolds: these\nprojections map from Sobolev de Rham complexes onto finite element de Rham\ncomplexes, commute with the differential operators, and satisfy uniform bounds\nin Lebesgue norms. They enable the Galerkin theory of Hilbert complexes for a\nlarge range of intrinsic finite element methods over manifolds. However, these\nintrinsic finite element methods are generally not computable and thus\nprimarily of theoretical interest. This leads to our second point: estimating\nthe geometric variational crime incurred by transitioning to computable\napproximate problems. Lastly, our third point addresses how to estimate the\napproximation error of the intrinsic finite element method in terms of the mesh\nsize. If the solution is not continuous, then such an estimate is achieved via\nmodified Cl\\'ement or Scott-Zhang interpolants that facilitate a broken\nBramble--Hilbert lemma.",
            "author": [
                "Martin W. Licht"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02663v1",
                "http://arxiv.org/pdf/2311.02663v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02661v1",
            "title": "CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine\n  Context-Guided Motion Reasoning",
            "updated": "2023-11-05T14:14:24Z",
            "published": "2023-11-05T14:14:24Z",
            "summary": "Attention-based motion aggregation concepts have recently shown their\nusefulness in optical flow estimation, in particular when it comes to handling\noccluded regions. However, due to their complexity, such concepts have been\nmainly restricted to coarse-resolution single-scale approaches that fail to\nprovide the detailed outcome of high-resolution multi-scale networks. In this\npaper, we hence propose CCMR: a high-resolution coarse-to-fine approach that\nleverages attention-based motion grouping concepts to multi-scale optical flow\nestimation. CCMR relies on a hierarchical two-step attention-based\ncontext-motion grouping strategy that first computes global multi-scale context\nfeatures and then uses them to guide the actual motion grouping. As we iterate\nboth steps over all coarse-to-fine scales, we adapt cross covariance image\ntransformers to allow for an efficient realization while maintaining\nscale-dependent properties. Experiments and ablations demonstrate that our\nefforts of combining multi-scale and attention-based concepts pay off. By\nproviding highly detailed flow fields with strong improvements in both occluded\nand non-occluded regions, our CCMR approach not only outperforms both the\ncorresponding single-scale attention-based and multi-scale attention-free\nbaselines by up to 23.0% and 21.6%, respectively, it also achieves\nstate-of-the-art results, ranking first on KITTI 2015 and second on MPI Sintel\nClean and Final. Code and trained models are available at\nhttps://github.com/cv-stuttgart /CCMR.",
            "author": [
                "Azin Jahedi",
                "Maximilian Luz",
                "Marc Rivinius",
                "Andr\u00e9s Bruhn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02661v1",
                "http://arxiv.org/pdf/2311.02661v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02660v1",
            "title": "LLM-enhanced Self-training for Cross-domain Constituency Parsing",
            "updated": "2023-11-05T14:13:29Z",
            "published": "2023-11-05T14:13:29Z",
            "summary": "Self-training has proven to be an effective approach for cross-domain tasks,\nand in this study, we explore its application to cross-domain constituency\nparsing. Traditional self-training methods rely on limited and potentially\nlow-quality raw corpora. To overcome this limitation, we propose enhancing\nself-training with the large language model (LLM) to generate domain-specific\nraw corpora iteratively. For the constituency parsing, we introduce grammar\nrules that guide the LLM in generating raw corpora and establish criteria for\nselecting pseudo instances. Our experimental results demonstrate that\nself-training for constituency parsing, equipped with an LLM, outperforms\ntraditional methods regardless of the LLM's performance. Moreover, the\ncombination of grammar rules and confidence criteria for pseudo-data selection\nyields the highest performance in the cross-domain constituency parsing.",
            "author": [
                "Jianling Li",
                "Meishan Zhang",
                "Peiming Guo",
                "Min Zhang",
                "Yue Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02660v1",
                "http://arxiv.org/pdf/2311.02660v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02659v1",
            "title": "Patterned non-determinism in communication complexity",
            "updated": "2023-11-05T14:06:35Z",
            "published": "2023-11-05T14:06:35Z",
            "summary": "We define and study the model of patterned non-determinism in bipartite\ncommunication complexity, denoted by $PNP^{X\\leftrightarrow Y}$. It generalises\nthe known models $UP^{X\\leftrightarrow Y}$ and $FewP^{X\\leftrightarrow Y}$\nthrough relaxing the constraints on the witnessing structure of the underlying\n$NP^{X\\leftrightarrow Y}$-protocol. It is shown that for the case of total\nfunctions $PNP^{X\\leftrightarrow Y}$ equals $P^{X\\leftrightarrow Y}$ (similarly\nto $UP^{X\\leftrightarrow Y}$ and $FewP^{X\\leftrightarrow Y}$). Moreover, the\ncorresponding exhaustive witness-searching problem -- determining the full set\nof witnesses that lead to the acceptance of a given input pair -- also has an\nefficient deterministic protocol.\n  The possibility of efficient exhaustive $PNP^{X\\leftrightarrow Y}$-search is\nused to analyse certain three-party communication regime (under the \"number in\nhand\" input partition): The corresponding three-party model is shown to be as\nstrong qualitatively as the weakest among its two-party amplifications obtained\nby allowing free communication between a pair of players.",
            "author": [
                "Dmytro Gavinsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02659v1",
                "http://arxiv.org/pdf/2311.02659v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02657v1",
            "title": "GSC: Generalizable Service Coordination",
            "updated": "2023-11-05T14:04:09Z",
            "published": "2023-11-05T14:04:09Z",
            "summary": "Services with distributed and interdependent components are becoming a\npopular option for harnessing dispersed resources available on cloud and edge\nnetworks. However, effective deployment and management of these services,\nnamely service coordination, is a challenging task. Service coordination\ncomprises the placement and scalability of components and scheduling incoming\ntraffic requesting for services between deployed instances. Due to the online\nnature of the problem and the success of Deep Reinforcement Learning (DRL)\nmethods, previous works considered DRL agents for solving service coordination\nproblems, yet these solutions have to be retrained for every unseen scenario.\nOther works have tried to tackle this shortcoming by incorporating Graph Neural\nNetworks (GNN) into their solutions, but they often focus on specific aspects\n(and disregard others) or cannot operate in dynamic and practical situations\nwhere there is no labeled dataset and feedback from the network might be\ndelayed. In response to these challenges, we present GSC, a generalizable\nservice coordinator that jointly considers service placement, scaling, and\ntraffic scheduling. GSC can operate in unseen situations without significant\nperformance degradation and outperforms existing state-of-the-art solutions by\n40%, as determined by simulating real-world network situations.",
            "author": [
                "Farzad Mohammadi",
                "Vahid Shah-Mansouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02657v1",
                "http://arxiv.org/pdf/2311.02657v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02656v1",
            "title": "Region of Interest (ROI) based adaptive cross-layer system for real-time\n  video streaming over Vehicular Ad-hoc NETworks (VANETs)",
            "updated": "2023-11-05T13:56:04Z",
            "published": "2023-11-05T13:56:04Z",
            "summary": "Nowadays, real-time vehicle applications increasingly rely on video\nacquisition and processing to detect or even identify vehicles and obstacles in\nthe driving environment. In this letter, we propose an algorithm that allows\nreinforcing these operations by improving end-to-end video transmission quality\nin a vehicular context. The proposed low complexity solution gives highest\npriority to the scene regions of interest (ROI) on which the perception of the\ndriving environment is based on. This is done by applying an adaptive\ncross-layer mapping of the ROI visual data packets at the IEEE 802.11p MAC\nlayer. Realistic VANET simulation results demonstrate that for HEVC compressed\nvideo communications, the proposed system offers PSNR gains up to 11dB on the\nROI part.",
            "author": [
                "Mohamed Aymen Labiod",
                "Mohamed Gharbi",
                "Fran\u00e7ois-Xavier Coudoux",
                "Patrick Corlay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02656v1",
                "http://arxiv.org/pdf/2311.02656v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02651v4",
            "title": "Compute at Scale: A Broad Investigation into the Data Center Industry",
            "updated": "2023-11-22T23:02:32Z",
            "published": "2023-11-05T13:39:59Z",
            "summary": "This report characterizes the data center industry and its importance for AI\ndevelopment. Data centers are industrial facilities that efficiently provide\ncompute at scale and thus constitute the engine rooms of today's digital\neconomy. As large-scale AI training and inference become increasingly\ncomputationally expensive, they are dominantly executed from this designated\ninfrastructure. Key features of data centers include large-scale compute\nclusters that require extensive cooling and consume large amounts of power, the\nneed for fast connectivity both within the data center and to the internet, and\nan emphasis on security and reliability. The global industry is valued at\napproximately $250B and is expected to double over the next seven years. There\nare likely about 500 large (above 10 MW) data centers globally, with the US,\nEurope, and China constituting the most important markets. The report further\ncovers important actors, business models, main inputs, and typical locations of\ndata centers.",
            "author": [
                "Konstantin Pilz",
                "Lennart Heim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02651v4",
                "http://arxiv.org/pdf/2311.02651v4"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02650v1",
            "title": "Ephemeral Rollups are All you Need",
            "updated": "2023-11-05T13:37:15Z",
            "published": "2023-11-05T13:37:15Z",
            "summary": "In the realm of open and composable gaming, we envision platforms where users\nactively expand, create, engage, and immerse themselves in a rich world of\nentertainment. One promising avenue for achieving this vision is through fully\non-chain (FOC) games, where both game state and logic reside on the blockchain,\nmaximizing composability. However, we must grapple with inherent limitations\nand trade-offs, particularly in terms of costs and scalability. This paper\nproposes BOLT, a framework that leverages the Solana Virtual Machine (SVM) to\nscale FOC games without state fragmentation or compromised trust assumptions.\nThe framework introduces a systematic approach for discovering, utilizing, and\npublishing modular pieces of logic as components deeply rooted in the\nEntity-Component-System (ECS) pattern. To enhance scalability and resource\noptimization, we introduce the concept of Ephemeral Rollups (ERs) that overcome\nthe tradeoffs of L2s horizontal scaling. These dedicated runtimes can be\ncustomized to provide higher operational speed, configurable ticking\nmechanisms, provable sessions and gasless transactions without\ncomposability-scalability tradeoffs.",
            "author": [
                "Gabriele Picco",
                "Andrea Fortugno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02650v1",
                "http://arxiv.org/pdf/2311.02650v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02649v1",
            "title": "Generative Face Video Coding Techniques and Standardization Efforts: A\n  Review",
            "updated": "2023-11-05T13:32:51Z",
            "published": "2023-11-05T13:32:51Z",
            "summary": "Generative Face Video Coding (GFVC) techniques can exploit the compact\nrepresentation of facial priors and the strong inference capability of deep\ngenerative models, achieving high-quality face video communication in ultra-low\nbandwidth scenarios. This paper conducts a comprehensive survey on the recent\nadvances of the GFVC techniques and standardization efforts, which could be\napplicable to ultra low bitrate communication, user-specified\nanimation/filtering and metaverse-related functionalities. In particular, we\ngeneralize GFVC systems within one coding framework and summarize different\nGFVC algorithms with their corresponding visual representations. Moreover, we\nreview the GFVC standardization activities that are specified with supplemental\nenhancement information messages. Finally, we discuss fundamental challenges\nand broad applications on GFVC techniques and their standardization potentials,\nas well as envision their future trends. The project page can be found at\nhttps://github.com/Berlin0610/Awesome-Generative-Face-Video-Coding.",
            "author": [
                "Bolin Chen",
                "Jie Chen",
                "Shiqi Wang",
                "Yan Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02649v1",
                "http://arxiv.org/pdf/2311.02649v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02647v1",
            "title": "New Approach for an Affective Computing-Driven Quality of Experience\n  (QoE) Prediction",
            "updated": "2023-11-05T13:21:07Z",
            "published": "2023-11-05T13:21:07Z",
            "summary": "In human interactions, emotion recognition is crucial. For this reason, the\ntopic of computer-vision approaches for automatic emotion recognition is\ncurrently being extensively researched. Processing multi-channel\nelectroencephalogram (EEG) information is one of the most researched methods\nfor automatic emotion recognition. This paper presents a new model for an\naffective computing-driven Quality of Experience (QoE) prediction. In order to\nvalidate the proposed model, a publicly available dataset is used. The dataset\ncontains EEG, ECG, and respiratory data and is focused on a multimedia QoE\nassessment context. The EEG data are retained on which the differential entropy\nand the power spectral density are calculated with an observation window of\nthree seconds. These two features were extracted to train several deep-learning\nmodels to investigate the possibility of predicting QoE with five different\nfactors. The performance of these models is compared, and the best model is\noptimized to improve the results. The best results were obtained with an\nLSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the\nmodel and its features shows that the Delta frequency band is the least\nnecessary, that two electrodes have a higher importance, and that two other\nelectrodes have a very low impact on the model's performances.",
            "author": [
                "Joshua B\u00e8gue",
                "Mohamed Aymen Labiod",
                "Abdelhamid Melloulk"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MCOM.002.2200870.",
                "http://arxiv.org/abs/2311.02647v1",
                "http://arxiv.org/pdf/2311.02647v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02644v1",
            "title": "Some Results on Random Mixed SAT Problems",
            "updated": "2023-11-05T13:04:55Z",
            "published": "2023-11-05T13:04:55Z",
            "summary": "In this short paper we present a survey of some results concerning the random\nSAT problems. To elaborate, the Boolean Satisfiability (SAT) Problem refers to\nthe problem of determining whether a given set of $m$ Boolean constraints over\n$n$ variables can be simultaneously satisfied, i.e. all evaluate to $1$ under\nsome interpretation of the variables in $\\{ 0,1\\}$. If we choose the $m$\nconstraints i.i.d. uniformly at random among the set of disjunctive clauses of\nlength $k$, then the problem is known as the random $k$-SAT problem. It is\nconjectured that this problem undergoes a structural phase transition; taking\n$m=\\alpha n$ for $\\alpha>0$, it is believed that the probability of there\nexisting a satisfying assignment tends in the large $n$ limit to $1$ if\n$\\alpha<\\alpha_\\mathrm{sat}(k)$, and to $0$ if $\\alpha>\\alpha_\\mathrm{sat}(k)$,\nfor some critical value $\\alpha_\\mathrm{sat}(k)$ depending on $k$. We review\nsome of the progress made towards proving this and consider similar conjectures\nand results for the more general case where the clauses are chosen with varying\nlengths, i.e. for the so-called random mixed SAT problems.",
            "author": [
                "Andreas Basse-O'Connor",
                "Tobias Lindhardt Overgaard",
                "Mette Skj\u00f8tt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02644v1",
                "http://arxiv.org/pdf/2311.02644v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.CC",
                "60K35 (Primary) 82B44, 68R99 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02642v1",
            "title": "An Approach for Multi-Object Tracking with Two-Stage Min-Cost Flow",
            "updated": "2023-11-05T13:01:11Z",
            "published": "2023-11-05T13:01:11Z",
            "summary": "The minimum network flow algorithm is widely used in multi-target tracking.\nHowever, the majority of the present methods concentrate exclusively on\nminimizing cost functions whose values may not indicate accurate solutions\nunder occlusions. In this paper, by exploiting the properties of tracklets\nintersections and low-confidence detections, we develop a two-stage tracking\npipeline with an intersection mask that can accurately locate inaccurate\ntracklets which are corrected in the second stage. Specifically, we employ the\nminimum network flow algorithm with high-confidence detections as input in the\nfirst stage to obtain the candidate tracklets that need correction. Then we\nleverage the intersection mask to accurately locate the inaccurate parts of\ncandidate tracklets. The second stage utilizes low-confidence detections that\nmay be attributed to occlusions for correcting inaccurate tracklets. This\nprocess constructs a graph of nodes in inaccurate tracklets and low-confidence\nnodes and uses it for the second round of minimum network flow calculation. We\nperform sufficient experiments on popular MOT benchmark datasets and achieve\n78.4 MOTA on the test set of MOT16, 79.2 on MOT17, and 76.4 on MOT20, which\nshows that the proposed method is effective.",
            "author": [
                "Huining Li",
                "Yalong Jiang",
                "Xianlin Zeng",
                "Feng Li",
                "Zhipeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02642v1",
                "http://arxiv.org/pdf/2311.02642v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02641v1",
            "title": "PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic\n  Segmentation",
            "updated": "2023-11-05T12:57:05Z",
            "published": "2023-11-05T12:57:05Z",
            "summary": "Pothole detection is crucial for road safety and maintenance, traditionally\nrelying on 2D image segmentation. However, existing 3D Semantic Pothole\nSegmentation research often overlooks point cloud sparsity, leading to\nsuboptimal local feature capture and segmentation accuracy. Our research\npresents an innovative point cloud-based pothole segmentation architecture. Our\nmodel efficiently identifies hidden features and uses a feedback mechanism to\nenhance local characteristics, improving feature presentation. We introduce a\nlocal relationship learning module to understand local shape relationships,\nenhancing structural insights. Additionally, we propose a lightweight adaptive\nstructure for refining local point features using the K nearest neighbor\nalgorithm, addressing point cloud density differences and domain selection.\nShared MLP Pooling is integrated to learn deep aggregation features,\nfacilitating semantic data exploration and segmentation guidance. Extensive\nexperiments on three public datasets confirm PotholeGuard's superior\nperformance over state-of-the-art methods. Our approach offers a promising\nsolution for robust and accurate 3D pothole segmentation, with applications in\nroad maintenance and safety.",
            "author": [
                "Sahil Nawale",
                "Dhruv Khut",
                "Daksh Dave",
                "Gauransh Sawhney",
                "Pushkar Aggrawal",
                "Dr. Kailas Devadakar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02641v1",
                "http://arxiv.org/pdf/2311.02641v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07583v1",
            "title": "Cross-Dialect Sentence Transformation: A Comparative Analysis of\n  Language Models for Adapting Sentences to British English",
            "updated": "2023-11-05T12:56:28Z",
            "published": "2023-11-05T12:56:28Z",
            "summary": "This study explores linguistic distinctions among American, Indian, and Irish\nEnglish dialects and assesses various Language Models (LLMs) in their ability\nto generate British English translations from these dialects. Using cosine\nsimilarity analysis, the study measures the linguistic proximity between\noriginal British English translations and those produced by LLMs for each\ndialect. The findings reveal that Indian and Irish English translations\nmaintain notably high similarity scores, suggesting strong linguistic alignment\nwith British English. In contrast, American English exhibits slightly lower\nsimilarity, reflecting its distinct linguistic traits. Additionally, the choice\nof LLM significantly impacts translation quality, with Llama-2-70b consistently\ndemonstrating superior performance. The study underscores the importance of\nselecting the right model for dialect translation, emphasizing the role of\nlinguistic expertise and contextual understanding in achieving accurate\ntranslations.",
            "author": [
                "Shruti Dutta",
                "Shashwat Mookherjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07583v1",
                "http://arxiv.org/pdf/2311.07583v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02636v1",
            "title": "Compact Data Structures for Network Telemetry",
            "updated": "2023-11-05T12:45:16Z",
            "published": "2023-11-05T12:45:16Z",
            "summary": "Collecting and analyzing of network traffic data (network telemetry) plays a\ncritical role in managing modern networks. Network administrators analyze their\ntraffic to troubleshoot performance and reliability problems, and to detect and\nblock cyberattacks. However, conventional traffic-measurement techniques offer\nlimited visibility into network conditions and rely on offline analysis.\nFortunately, network devices such as switches and network interface cards, are\nincreasingly programmable at the packet level, enabling flexible analysis of\nthe traffic in place, as the packets fly by. However, to operate at high speed,\nthese devices have limited memory and computational resources, leading to\ntrade-offs between accuracy and overhead. In response, an exciting research\narea emerged, bringing ideas from compact data structures and streaming\nalgorithms to bear on important networking telemetry applications and the\nunique characteristics of high-speed network devices. In this paper, we review\nthe research on compact data structures for network telemetry and discuss\npromising directions for future research.",
            "author": [
                "Shir Landau Feibish",
                "Zaoxing Liu",
                "Jennifer Rexford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02636v1",
                "http://arxiv.org/pdf/2311.02636v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02633v1",
            "title": "The Background Also Matters: Background-Aware Motion-Guided Objects\n  Discovery",
            "updated": "2023-11-05T12:35:47Z",
            "published": "2023-11-05T12:35:47Z",
            "summary": "Recent works have shown that objects discovery can largely benefit from the\ninherent motion information in video data. However, these methods lack a proper\nbackground processing, resulting in an over-segmentation of the non-object\nregions into random segments. This is a critical limitation given the\nunsupervised setting, where object segments and noise are not distinguishable.\nTo address this limitation we propose BMOD, a Background-aware Motion-guided\nObjects Discovery method. Concretely, we leverage masks of moving objects\nextracted from optical flow and design a learning mechanism to extend them to\nthe true foreground composed of both moving and static objects. The background,\na complementary concept of the learned foreground class, is then isolated in\nthe object discovery process. This enables a joint learning of the objects\ndiscovery task and the object/non-object separation. The conducted experiments\non synthetic and real-world datasets show that integrating our background\nhandling with various cutting-edge methods brings each time a considerable\nimprovement. Specifically, we improve the objects discovery performance with a\nlarge margin, while establishing a strong baseline for object/non-object\nseparation.",
            "author": [
                "Sandra Kara",
                "Hejer Ammar",
                "Florian Chabot",
                "Quoc-Cuong Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02633v1",
                "http://arxiv.org/pdf/2311.02633v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16141v1",
            "title": "Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking\n  Neural Networks",
            "updated": "2023-11-05T12:20:29Z",
            "published": "2023-11-05T12:20:29Z",
            "summary": "Spiking Neural Networks (SNNs) have been an attractive option for deployment\non devices with limited computing resources and lower power consumption because\nof the event-driven computing characteristic. As such devices have limited\ncomputing and storage resources, pruning for SNNs has been widely focused\nrecently. However, the binary and non-differentiable property of spike signals\nmake pruning deep SNNs challenging, so existing methods require high time\noverhead to make pruning decisions. In this paper, inspired by critical brain\nhypothesis in neuroscience, we design a regeneration mechanism based on\ncriticality to efficiently obtain the critical pruned networks. Firstly, we\npropose a low-cost metric for the criticality of pruning structures. Then we\nre-rank the pruned structures after pruning and regenerate those with higher\ncriticality. We evaluate our method using VGG-16 and ResNet-19 for both\nunstructured pruning and structured pruning. Our method achieves higher\nperformance compared to current state-of-the-art (SOTA) method with the same\ntime overhead. We also achieve comparable performances (even better on VGG-16)\ncompared to the SOTA method with 11.3x and 15.5x acceleration. Moreover, we\ninvestigate underlying mechanism of our method and find that it efficiently\nselects potential structures, learns the consistent feature representations and\nreduces the overfitting during the recovery phase.",
            "author": [
                "Shuo Chen",
                "Boxiao Liu",
                "Haihang You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16141v1",
                "http://arxiv.org/pdf/2311.16141v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05642v1",
            "title": "A protein network refinement method based on module discovery and\n  biological information",
            "updated": "2023-11-05T12:11:59Z",
            "published": "2023-11-05T12:11:59Z",
            "summary": "The identification of essential proteins can help in understanding the\nminimum requirements for cell survival and development. Network-based\ncentrality approaches are commonly used to identify essential proteins from\nprotein-protein interaction networks (PINs). Unfortunately, these approaches\nare limited by the poor quality of the underlying PIN data. To overcome this\nproblem, researchers have focused on the prediction of essential proteins by\ncombining PINs with other biological data. In this paper, we proposed a network\nrefinement method based on module discovery and biological information to\nobtain a higher quality PIN. First, to extract the maximal connected subgraph\nin the PIN and to divide it into different modules by using Fast-unfolding\nalgorithm; then, to detect critical modules based on the homology information,\nsubcellular localization information and topology information within each\nmodule, and to construct a more refined network (CM-PIN). To evaluate the\neffectiveness of the proposed method, we used 10 typical network-based\ncentrality methods (LAC, DC, DMNC, NC, TP, LID, CC, BC, PR, LR) to compare the\noverall performance of the CM-PIN with those the refined dynamic protein\nnetwork (RD-PIN). The experimental results showed that the CM-PIN was optimal\nin terms of precision-recall curve, jackknife curve and other criteria, and can\nhelp to identify essential proteins more accurately.",
            "author": [
                "Li Pan",
                "Haoyue Wang",
                "Jing Sun",
                "Bin Li",
                "Bo Yang",
                "Wenbin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05642v1",
                "http://arxiv.org/pdf/2311.05642v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02630v1",
            "title": "The New Frontier of Cybersecurity: Emerging Threats and Innovations",
            "updated": "2023-11-05T12:08:20Z",
            "published": "2023-11-05T12:08:20Z",
            "summary": "In today's digitally interconnected world, cybersecurity threats have reached\nunprecedented levels, presenting a pressing concern for individuals,\norganizations, and governments. This study employs a qualitative research\napproach to comprehensively examine the diverse threats of cybersecurity and\ntheir impacts across various sectors. Four primary categories of threats are\nidentified and analyzed, encompassing malware attacks, social engineering\nattacks, network vulnerabilities, and data breaches. The research delves into\nthe consequences of these threats on individuals, organizations, and society at\nlarge. The findings reveal a range of key emerging threats in cybersecurity,\nincluding advanced persistent threats, ransomware attacks, Internet of Things\n(IoT) vulnerabilities, and social engineering exploits. Consequently, it is\nevident that emerging cybersecurity threats pose substantial risks to both\norganizations and individuals. The sophistication and diversity of these\nemerging threats necessitate a multi-layered approach to cybersecurity. This\napproach should include robust security measures, comprehensive employee\ntraining, and regular security audits. The implications of these emerging\nthreats are extensive, with potential consequences such as financial loss,\nreputational damage, and compromised personal information. This study\nemphasizes the importance of implementing effective measures to mitigate these\nthreats. It highlights the significance of using strong passwords, encryption\nmethods, and regularly updating software to bolster cyber defenses.",
            "author": [
                "Daksh Dave",
                "Gauransh Sawhney",
                "Pushkar Aggarwal",
                "Nitish Silswal",
                "Dhruv Khut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02630v1",
                "http://arxiv.org/pdf/2311.02630v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06295v1",
            "title": "Gradual Optimization Learning for Conformational Energy Minimization",
            "updated": "2023-11-05T11:48:08Z",
            "published": "2023-11-05T11:48:08Z",
            "summary": "Molecular conformation optimization is crucial to computer-aided drug\ndiscovery and materials design. Traditional energy minimization techniques rely\non iterative optimization methods that use molecular forces calculated by a\nphysical simulator (oracle) as anti-gradients. However, this is a\ncomputationally expensive approach that requires many interactions with a\nphysical simulator. One way to accelerate this procedure is to replace the\nphysical simulator with a neural network. Despite recent progress in neural\nnetworks for molecular conformation energy prediction, such models are prone to\ndistribution shift, leading to inaccurate energy minimization. We find that the\nquality of energy minimization with neural networks can be improved by\nproviding optimization trajectories as additional training data. Still, it\ntakes around $5 \\times 10^5$ additional conformations to match the physical\nsimulator's optimization quality. In this work, we present the Gradual\nOptimization Learning Framework (GOLF) for energy minimization with neural\nnetworks that significantly reduces the required additional data. The framework\nconsists of an efficient data-collecting scheme and an external optimizer. The\nexternal optimizer utilizes gradients from the energy prediction model to\ngenerate optimization trajectories, and the data-collecting scheme selects\nadditional training data to be processed by the physical simulator. Our results\ndemonstrate that the neural network trained with GOLF performs on par with the\noracle on a benchmark of diverse drug-like molecules using $50$x less\nadditional data.",
            "author": [
                "Artem Tsypin",
                "Leonid Ugadiarov",
                "Kuzma Khrabrov",
                "Manvel Avetisian",
                "Alexander Telepov",
                "Egor Rumiantsev",
                "Alexey Skrynnik",
                "Aleksandr I. Panov",
                "Dmitry Vetrov",
                "Elena Tutubalina",
                "Artur Kadurin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06295v1",
                "http://arxiv.org/pdf/2311.06295v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02622v1",
            "title": "Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity\n  Bias",
            "updated": "2023-11-05T11:27:03Z",
            "published": "2023-11-05T11:27:03Z",
            "summary": "Neural networks exhibit simplicity bias; they rely on simpler features while\nignoring equally predictive but more complex features. In this work, we\nintroduce a novel approach termed imbalanced label coupling to investigate\nscenarios where simple and complex features exhibit different levels of\npredictive power. In these cases, complex features still contribute to\npredictions. The trained networks make predictions in alignment with the\nascending complexity of input features according to how they correlate with the\nlabel in the training set, irrespective of the underlying predictive power. For\ninstance, even when simple spurious features distort predictions in CIFAR-10,\nmost cats are predicted to be dogs, and most trucks are predicted to be\nautomobiles! This observation provides direct evidence that the neural network\nlearns core features in the presence of spurious features. We empirically show\nthat last-layer retraining with target data distribution is effective, yet\ninsufficient to fully recover core features when spurious features are\nperfectly correlated with the target labels in our synthetic dataset. We hope\nour research contributes to a deeper understanding of the implicit bias of\nneural networks.",
            "author": [
                "Zhehang Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02622v1",
                "http://arxiv.org/pdf/2311.02622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03398v1",
            "title": "Generalized Werner's formula and the connection between trigonometry\n  with target sum problems",
            "updated": "2023-11-05T10:55:32Z",
            "published": "2023-11-05T10:55:32Z",
            "summary": "This paper introduces the target sum function along with its characteristics.\nThe target sum function takes a list of integers and a specific target integer\nas input values and expresses the number of ways to obtain the target sum by\neither adding or subtracting all of the integers from the given list. This\nfunction is rooted in the target sum problem which is explored in the fields of\ncomputer science and combinatorics. This paper, following the establishment of\nthe generalized Werner's formula, will propose a link between the target sum\nfunction and the definite integral of the product of sine and cosine functions\nbased on the formula.",
            "author": [
                "Hayato Isa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03398v1",
                "http://arxiv.org/pdf/2311.03398v1"
            ],
            "primary_category": "math.GM",
            "category": [
                "math.GM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02617v1",
            "title": "TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for\n  Improved Building Footprint Extraction",
            "updated": "2023-11-05T10:52:16Z",
            "published": "2023-11-05T10:52:16Z",
            "summary": "This paper considers the problem of extracting building footprints from\nsatellite imagery -- a task that is critical for many urban planning and\ndecision-making applications. While recent advancements in deep learning have\nmade great strides in automated detection of building footprints,\nstate-of-the-art methods available in existing literature often generate\nerroneous results for areas with densely connected buildings. Moreover, these\nmethods do not incorporate the context of neighborhood images during training\nthus generally resulting in poor performance at image boundaries. In light of\nthese gaps, we propose a novel Tuning Fork Network (TFNet) design for deep\nsemantic segmentation that not only performs well for widely-spaced building\nbut also has good performance for buildings that are closely packed together.\nThe novelty of TFNet architecture lies in a a single encoder followed by two\nparallel decoders to separately reconstruct the building footprint and the\nbuilding edge. In addition, the TFNet design is coupled with a novel\nmethodology of incorporating neighborhood information at the tile boundaries\nduring the training process. This methodology further improves performance,\nespecially at the tile boundaries. For performance comparisons, we utilize the\nSpaceNet2 and WHU datasets, as well as a dataset from an area in Lahore,\nPakistan that captures closely connected buildings. For all three datasets, the\nproposed methodology is found to significantly outperform benchmark methods.",
            "author": [
                "Muhammad Ahmad Waseem",
                "Muhammad Tahir",
                "Zubair Khalid",
                "Momin Uppal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02617v1",
                "http://arxiv.org/pdf/2311.02617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02616v1",
            "title": "Divide & Conquer for Entailment-aware Multi-hop Evidence Retrieval",
            "updated": "2023-11-05T10:31:40Z",
            "published": "2023-11-05T10:31:40Z",
            "summary": "Lexical and semantic matches are commonly used as relevance measurements for\ninformation retrieval. Together they estimate the semantic equivalence between\nthe query and the candidates. However, semantic equivalence is not the only\nrelevance signal that needs to be considered when retrieving evidences for\nmulti-hop questions. In this work, we demonstrate that textual entailment\nrelation is another important relevance dimension that should be considered. To\nretrieve evidences that are either semantically equivalent to or entailed by\nthe question simultaneously, we divide the task of evidence retrieval for\nmulti-hop question answering (QA) into two sub-tasks, i.e., semantic textual\nsimilarity and inference similarity retrieval. We propose two ensemble models,\nEAR and EARnest, which tackle each of the sub-tasks separately and then jointly\nre-rank sentences with the consideration of the diverse relevance signals.\nExperimental results on HotpotQA verify that our models not only significantly\noutperform all the single retrieval models it is based on, but is also more\neffective than two intuitive ensemble baseline models.",
            "author": [
                "Fan Luo",
                "Mihai Surdeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02616v1",
                "http://arxiv.org/pdf/2311.02616v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02612v1",
            "title": "Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot\n  Anomaly Detection",
            "updated": "2023-11-05T10:01:18Z",
            "published": "2023-11-05T10:01:18Z",
            "summary": "Large Multimodal Model (LMM) GPT-4V(ision) endows GPT-4 with visual grounding\ncapabilities, making it possible to handle certain tasks through the Visual\nQuestion Answering (VQA) paradigm. This paper explores the potential of\nVQA-oriented GPT-4V in the recently popular visual Anomaly Detection (AD) and\nis the first to conduct qualitative and quantitative evaluations on the popular\nMVTec AD and VisA datasets. Considering that this task requires both\nimage-/pixel-level evaluations, the proposed GPT-4V-AD framework contains three\ncomponents: 1) Granular Region Division, 2) Prompt Designing, 3)\nText2Segmentation for easy quantitative evaluation, and have made some\ndifferent attempts for comparative analysis. The results show that GPT-4V can\nachieve certain results in the zero-shot AD task through a VQA paradigm, such\nas achieving image-level 77.1/88.0 and pixel-level 68.0/76.6 AU-ROCs on MVTec\nAD and VisA datasets, respectively. However, its performance still has a\ncertain gap compared to the state-of-the-art zero-shot method, e.g., WinCLIP\nann CLIP-AD, and further research is needed. This study provides a baseline\nreference for the research of VQA-oriented LMM in the zero-shot AD task, and we\nalso post several possible future works. Code is available at\n\\url{https://github.com/zhangzjn/GPT-4V-AD}.",
            "author": [
                "Jiangning Zhang",
                "Xuhai Chen",
                "Zhucun Xue",
                "Yabiao Wang",
                "Chengjie Wang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02612v1",
                "http://arxiv.org/pdf/2311.02612v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02609v1",
            "title": "Dock Assignment and Truck Scheduling Problem; Consideration of Multiple\n  Scenarios with Resource Allocation Constraints",
            "updated": "2023-11-05T09:32:18Z",
            "published": "2023-11-05T09:32:18Z",
            "summary": "The notion of 'resource' plays an important role in the overall efficiency\nand performance of most cross-docks. The processing time can often be described\nin terms of the resources allocated to different trucks. Conversely, for a\ngiven processing time, different combinations of resources can be prescribed.\nWe study the problem of truck scheduling and dock assignment in the presence of\nresource constraints. In the absence of a closed-form (or well-defined) linear\nformulation describing the processing times as a function of resources, expert'\nknowledge has been mobilised to enable modelling of the problem as an integer\nlinear model. Two cases are taken into account: In the first one, the expert\nbelieves in his/her estimation of the processing time for every truck and only\nproposes a different combination of resources for his/her estimation, while in\nthe second one the expert proposes a limited number of resource deployment\nscenarios for serving trucks, each of which has a different combination of\nresources and different processing times. We propose a novel compact integer\nprogramming formulation for the problem, which is particularly designed with an\nembedded structure that can be exploited in dual decomposition techniques with\na remarkably computationally efficient column generation approach in this case.\nThe case in which a scenario with invariant processing time is considered and\nmodelled as a special case of the proposed model. Since a direct application of\ncommercial solvers such as CPLEX to solve instances of this problem is not\nrealistic, we propose a branch-and-price framework and, moreover, several\nclasses of valid inequalities. Our extensive computational experiments confirm\nthat the proposed exact solution framework is very efficient and viable in\nsolving real-size instances of the practice and in a reasonable amount of time.",
            "author": [
                "Rahimeh Neamatian Monemia",
                "Shahin Gelareh"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.cor.2022.106074",
                "http://arxiv.org/abs/2311.02609v1",
                "http://arxiv.org/pdf/2311.02609v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02608v1",
            "title": "Deep Learning-based 3D Point Cloud Classification: A Systematic Survey\n  and Outlook",
            "updated": "2023-11-05T09:28:43Z",
            "published": "2023-11-05T09:28:43Z",
            "summary": "In recent years, point cloud representation has become one of the research\nhotspots in the field of computer vision, and has been widely used in many\nfields, such as autonomous driving, virtual reality, robotics, etc. Although\ndeep learning techniques have achieved great success in processing regular\nstructured 2D grid image data, there are still great challenges in processing\nirregular, unstructured point cloud data. Point cloud classification is the\nbasis of point cloud analysis, and many deep learning-based methods have been\nwidely used in this task. Therefore, the purpose of this paper is to provide\nresearchers in this field with the latest research progress and future trends.\nFirst, we introduce point cloud acquisition, characteristics, and challenges.\nSecond, we review 3D data representations, storage formats, and commonly used\ndatasets for point cloud classification. We then summarize deep learning-based\nmethods for point cloud classification and complement recent research work.\nNext, we compare and analyze the performance of the main methods. Finally, we\ndiscuss some challenges and future directions for point cloud classification.",
            "author": [
                "Huang Zhang",
                "Changshuo Wang",
                "Shengwei Tian",
                "Baoli Lu",
                "Liping Zhang",
                "Xin Ning",
                "Xiao Bai"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.displa.2023.102456",
                "http://arxiv.org/abs/2311.02608v1",
                "http://arxiv.org/pdf/2311.02608v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02602v1",
            "title": "Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close\n  the Healthcare Loop",
            "updated": "2023-11-05T08:57:59Z",
            "published": "2023-11-05T08:57:59Z",
            "summary": "To facilitate the advancement of research in healthcare robots without human\nintervention or commands, we introduce the Autonomous Helping Challenge, along\nwith a crowd-sourcing large-scale dataset. The goal is to create healthcare\nrobots that possess the ability to determine when assistance is necessary,\ngenerate useful sub-tasks to aid in planning, carry out these plans through a\nphysical robot, and receive feedback from the environment in order to generate\nnew tasks and continue the process. Besides the general challenge in open-ended\nscenarios, Autonomous Helping focuses on three specific challenges: autonomous\ntask generation, the gap between the current scene and static commonsense, and\nthe gap between language instruction and the real world. Additionally, we\npropose Helpy, a potential approach to close the healthcare loop in the\nlearning-free setting.",
            "author": [
                "Jiaxin Shen",
                "Yanyao Liu",
                "Ziming Wang",
                "Ziyuan Jiao",
                "Yufeng Chen",
                "Wenjuan Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02602v1",
                "http://arxiv.org/pdf/2311.02602v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02601v1",
            "title": "Optimizing Implicit Neural Representations from Point Clouds via\n  Energy-Based Models",
            "updated": "2023-11-05T08:57:22Z",
            "published": "2023-11-05T08:57:22Z",
            "summary": "Reconstructing a continuous surface from an unoritented 3D point cloud is a\nfundamental task in 3D shape processing. In recent years, several methods have\nbeen proposed to address this problem using implicit neural representations\n(INRs). In this study, we propose a method to optimize INRs using energy-based\nmodels (EBMs). By employing the absolute value of the coordinate-based neural\nnetworks as the energy function, the INR can be optimized through the\nestimation of the point cloud distribution by the EBM. In addition, appropriate\nparameter settings of the EBM enable the model to consider the magnitude of\npoint cloud noise. Our experiments confirmed that the proposed method is more\nrobust against point cloud noise than conventional surface reconstruction\nmethods.",
            "author": [
                "Ryutaro Yamauchi",
                "Jinya Sakurai",
                "Ryo Furukawa",
                "Tatsushi Matsubayashi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02601v1",
                "http://arxiv.org/pdf/2311.02601v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02599v1",
            "title": "Learning Class and Domain Augmentations for Single-Source Open-Domain\n  Generalization",
            "updated": "2023-11-05T08:53:07Z",
            "published": "2023-11-05T08:53:07Z",
            "summary": "Single-source open-domain generalization (SS-ODG) addresses the challenge of\nlabeled source domains with supervision during training and unlabeled novel\ntarget domains during testing. The target domain includes both known classes\nfrom the source domain and samples from previously unseen classes. Existing\ntechniques for SS-ODG primarily focus on calibrating source-domain classifiers\nto identify open samples in the target domain. However, these methods struggle\nwith visually fine-grained open-closed data, often misclassifying open samples\nas closed-set classes. Moreover, relying solely on a single source domain\nrestricts the model's ability to generalize. To overcome these limitations, we\npropose a novel framework called SODG-Net that simultaneously synthesizes novel\ndomains and generates pseudo-open samples using a learning-based objective, in\ncontrast to the ad-hoc mixing strategies commonly found in the literature. Our\napproach enhances generalization by diversifying the styles of known class\nsamples using a novel metric criterion and generates diverse pseudo-open\nsamples to train a unified and confident multi-class classifier capable of\nhandling both open and closed-set data. Extensive experimental evaluations\nconducted on multiple benchmarks consistently demonstrate the superior\nperformance of SODG-Net compared to the literature.",
            "author": [
                "Prathmesh Bele",
                "Valay Bundele",
                "Avigyan Bhattacharya",
                "Ankit Jha",
                "Gemma Roig",
                "Biplab Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02599v1",
                "http://arxiv.org/pdf/2311.02599v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02598v1",
            "title": "Automated Camera Calibration via Homography Estimation with GNNs",
            "updated": "2023-11-05T08:45:26Z",
            "published": "2023-11-05T08:45:26Z",
            "summary": "Over the past few decades, a significant rise of camera-based applications\nfor traffic monitoring has occurred. Governments and local administrations are\nincreasingly relying on the data collected from these cameras to enhance road\nsafety and optimize traffic conditions. However, for effective data\nutilization, it is imperative to ensure accurate and automated calibration of\nthe involved cameras. This paper proposes a novel approach to address this\nchallenge by leveraging the topological structure of intersections. We propose\na framework involving the generation of a set of synthetic intersection\nviewpoint images from a bird's-eye-view image, framed as a graph of virtual\ncameras to model these images. Using the capabilities of Graph Neural Networks,\nwe effectively learn the relationships within this graph, thereby facilitating\nthe estimation of a homography matrix. This estimation leverages the\nneighbourhood representation for any real-world camera and is enhanced by\nexploiting multiple images instead of a single match. In turn, the homography\nmatrix allows the retrieval of extrinsic calibration parameters. As a result,\nthe proposed framework demonstrates superior performance on both synthetic\ndatasets and real-world cameras, setting a new state-of-the-art benchmark.",
            "author": [
                "Giacomo D'Amicantonio",
                "Egor Bondarev",
                "Peter H. N. De With"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02598v1",
                "http://arxiv.org/pdf/2311.02598v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02597v1",
            "title": "FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented\n  Generation with an LLM",
            "updated": "2023-11-05T08:34:26Z",
            "published": "2023-11-05T08:34:26Z",
            "summary": "Fast disaster impact reporting is crucial in planning humanitarian\nassistance. Large Language Models (LLMs) are well known for their ability to\nwrite coherent text and fulfill a variety of tasks relevant to impact\nreporting, such as question answering or text summarization. However, LLMs are\nconstrained by the knowledge within their training data and are prone to\ngenerating inaccurate, or \"hallucinated\", information. To address this, we\nintroduce a sophisticated pipeline embodied in our tool FloodBrain\n(floodbrain.com), specialized in generating flood disaster impact reports by\nextracting and curating information from the web. Our pipeline assimilates\ninformation from web search results to produce detailed and accurate reports on\nflood events. We test different LLMs as backbones in our tool and compare their\ngenerated reports to human-written reports on different metrics. Similar to\nother studies, we find a notable correlation between the scores assigned by\nGPT-4 and the scores given by human evaluators when comparing our generated\nreports to human-authored ones. Additionally, we conduct an ablation study to\ntest our single pipeline components and their relevancy for the final reports.\nWith our tool, we aim to advance the use of LLMs for disaster impact reporting\nand reduce the time for coordination of humanitarian efforts in the wake of\nflood disasters.",
            "author": [
                "Grace Colverd",
                "Paul Darm",
                "Leonard Silverberg",
                "Noah Kasmanoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02597v1",
                "http://arxiv.org/pdf/2311.02597v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02595v1",
            "title": "Nonlinear wavefront reconstruction from a pyramid sensor using neural\n  networks",
            "updated": "2023-11-05T08:28:55Z",
            "published": "2023-11-05T08:28:55Z",
            "summary": "The pyramid wavefront sensor (PyWFS) has become increasingly popular to use\nin adaptive optics (AO) systems due to its high sensitivity. The main drawback\nof the PyWFS is that it is inherently nonlinear, which means that classic\nlinear wavefront reconstruction techniques face a significant reduction in\nperformance at high wavefront errors, particularly when the pyramid is\nunmodulated. In this paper, we consider the potential use of neural networks\n(NNs) to replace the widely used matrix vector multiplication (MVM) control. We\naim to test the hypothesis that the neural network (NN)'s ability to model\nnonlinearities will give it a distinct advantage over MVM control. We compare\nthe performance of a MVM linear reconstructor against a dense NN, using daytime\ndata acquired on the Subaru Coronagraphic Extreme Adaptive Optics system\n(SCExAO) instrument. In a first set of experiments, we produce wavefronts\ngenerated from 14 Zernike modes and the PyWFS responses at different modulation\nradii (25, 50, 75, and 100 mas). We find that the NN allows for a far more\nprecise wavefront reconstruction at all modulations, with differences in\nperformance increasing in the regime where the PyWFS nonlinearity becomes\nsignificant. In a second set of experiments, we generate a dataset of\natmosphere-like wavefronts, and confirm that the NN outperforms the linear\nreconstructor. The SCExAO real-time computer software is used as baseline for\nthe latter. These results suggest that NNs are well positioned to improve upon\nlinear reconstructors and stand to bring about a leap forward in AO performance\nin the near future.",
            "author": [
                "Alison P. Wong",
                "Barnaby R. M. Norris",
                "Vincent Deo",
                "Peter G. Tuthill",
                "Richard Scalzo",
                "David Sweeney",
                "Kyohoon Ahn",
                "Julien Lozi",
                "Sebastien Vievard",
                "Olivier Guyon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02595v1",
                "http://arxiv.org/pdf/2311.02595v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02590v1",
            "title": "A Markovian approach to the Prandtl-Tomlinson frictional model",
            "updated": "2023-11-05T08:11:57Z",
            "published": "2023-11-05T08:11:57Z",
            "summary": "We consider the Prandtl-Tomlinson model in the case of a constant driving\nforce and in the presence of thermal fluctuations. We show that the system\ndynamics is well reproduced by a simplified description obtained through a\nMarkov process, even in the case of potentials with several minima. After\nestimating the chain parameters by numerical simulation, we compute the average\nvelocity and friction at varying driving force and temperature. Then we take\nadvantage of this approach for calculating the entropy produced by the system\nand, in the case of a single minimum potential, to derive its explicit relation\nwith the external force and the mobility at low temperatures. We observe that\nthe coefficient relating the entropy production to the force is not a monotonic\nfunction of the temperature.",
            "author": [
                "Dario Lucente",
                "Alberto Petri",
                "Angelo Vulpiani"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.physa.2021.125899",
                "http://arxiv.org/abs/2311.02590v1",
                "http://arxiv.org/pdf/2311.02590v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02589v1",
            "title": "Impossibilities for Obviously Strategy-Proof Mechanisms",
            "updated": "2023-11-05T08:11:53Z",
            "published": "2023-11-05T08:11:53Z",
            "summary": "We explore the approximation power of deterministic obviously strategy-proof\nmechanisms in auctions, where the objective is welfare maximization. A trivial\nascending auction on the grand bundle guarantees an approximation of\n$\\min\\{m,n\\}$ for all valuation classes, where $m$ is the number of items and\n$n$ is the number of bidders. We focus on two classes of valuations considered\n\"simple\": additive valuations and unit-demand valuations. For additive\nvaluations, Bade and Gonczarowski [EC'17] have shown that exact welfare\nmaximization is impossible. No impossibilities are known for unit-demand\nvaluations.\n  We show that if bidders' valuations are additive or unit-demand, then no\nobviously strategy-proof mechanism gives an approximation better than\n$\\min\\{m,n\\}$. Thus, the aforementioned trivial ascending auction on the grand\nbundle is the optimal obviously strategy-proof mechanism. These results\nillustrate a stark separation between the power of dominant-strategy and\nobviously strategy-proof mechanisms. The reason for it is that for both of\nthese classes the dominant-strategy VCG mechanism does not only optimize the\nwelfare exactly, but is also \"easy\" both from a computation and communication\nperspective.\n  In addition, we prove tight impossibilities for unknown single-minded bidders\nin a multi-unit auction and in a combinatorial auction. We show that in these\nenvironments as well, a trivial ascending auction on the grand bundle is\noptimal.",
            "author": [
                "Shiri Ron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02589v1",
                "http://arxiv.org/pdf/2311.02589v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02586v1",
            "title": "Synthetic Tumor Manipulation: With Radiomics Features",
            "updated": "2023-11-05T08:07:50Z",
            "published": "2023-11-05T08:07:50Z",
            "summary": "We introduce RadiomicsFill, a synthetic tumor generator conditioned on\nradiomics features, enabling detailed control and individual manipulation of\ntumor subregions. This conditioning leverages conventional high-dimensional\nfeatures of the tumor (i.e., radiomics features) and thus is biologically\nwell-grounded. Our model combines generative adversarial networks,\nradiomics-feature conditioning, and multi-task learning. Through experiments\nwith glioma patients, RadiomicsFill demonstrated its capability to generate\ndiverse, realistic tumors and its fine-tuning ability for specific radiomics\nfeatures like 'Pixel Surface' and 'Shape Sphericity'. The ability of\nRadiomicsFill to generate an unlimited number of realistic synthetic tumors\noffers notable prospects for both advancing medical imaging research and\npotential clinical applications.",
            "author": [
                "Inye Na",
                "Jonghun Kim",
                "Hyunjin Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02586v1",
                "http://arxiv.org/pdf/2311.02586v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02583v1",
            "title": "SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain\n  Generalization in Medical Image Segmentation",
            "updated": "2023-11-05T07:44:40Z",
            "published": "2023-11-05T07:44:40Z",
            "summary": "Deep learning-based medical image segmentation is an essential yet\nchallenging task in clinical practice, which arises from restricted access to\nannotated data coupled with the occurrence of domain shifts. Previous attempts\nhave focused on isolated solutions, while disregarding their\ninter-connectedness. In this paper, we rethink the relationship between\nsemi-supervised learning (SSL) and domain generalization (DG), which are the\ncutting-edge approaches to address the annotated data-driven constraints and\nthe domain shift issues. Inspired by class-level representation, we show that\nunseen target data can be represented by a linear combination of source data,\nwhich can be achieved by simple data augmentation. The augmented data enrich\ndomain distributions while having semantic consistency, aligning with the\nprinciples of consistency-based SSL. Accordingly, we propose SSL-DG, fusing DG\nand SSL, to achieve cross-domain generalization with limited annotations.\nSpecifically, the global and focal region augmentation, together with an\naugmentation scale-balancing mechanism, are used to construct a mask-based\ndomain diffusion augmentation module to significantly enrich domain diversity.\nIn order to obtain consistent predictions for the same source data in different\nnetworks, we use uncertainty estimation and a deep mutual learning strategy to\nenforce the consistent constraint. Extensive experiments including ablation\nstudies are designed to validate the proposed SSL-DG. The results demonstrate\nthat our SSL-DG significantly outperforms state-of-the-art solutions in two\nchallenging DG tasks with limited annotations. Code is available at\nhttps://github.com/yezanting/SSL-DG.",
            "author": [
                "Zanting Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02583v1",
                "http://arxiv.org/pdf/2311.02583v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02582v1",
            "title": "RecAGT: Shard Testable Codes with Adaptive Group Testing for Malicious\n  Nodes Identification in Sharding Permissioned Blockchain",
            "updated": "2023-11-05T07:43:48Z",
            "published": "2023-11-05T07:43:48Z",
            "summary": "Recently, permissioned blockchain has been extensively explored in various\nfields, such as asset management, supply chain, healthcare, and many others.\nMany scholars are dedicated to improving its verifiability, scalability, and\nperformance based on sharding techniques, including grouping nodes and handling\ncross-shard transactions. However, they ignore the node vulnerability problem,\ni.e., there is no guarantee that nodes will not be maliciously controlled\nthroughout their life cycle. Facing this challenge, we propose RecAGT, a novel\nidentification scheme aimed at reducing communication overhead and identifying\npotential malicious nodes. First, shard testable codes are designed to encode\nthe original data in case of a leak of confidential data. Second, a new\nidentity proof protocol is presented as evidence against malicious behavior.\nFinally, adaptive group testing is chosen to identify malicious nodes. Notably,\nour work focuses on the internal operation within the committee and can thus be\napplied to any sharding permissioned blockchains. Simulation results show that\nour proposed scheme can effectively identify malicious nodes with low\ncommunication and computational costs.",
            "author": [
                "Dongyang Yu",
                "Jin Wang",
                "Lingzhi Li",
                "Wei Jiang",
                "Can Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02582v1",
                "http://arxiv.org/pdf/2311.02582v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02580v1",
            "title": "High-resolution 3D phase-contrast imaging beyond the depth of field\n  limit via ptychographic multi-slice electron tomography",
            "updated": "2023-11-05T07:10:21Z",
            "published": "2023-11-05T07:10:21Z",
            "summary": "Resolving single atoms in large-scale volumes has been a goal for atomic\nresolution microscopy for a long time. Electron microscopy has come close to\nthis goal using a combination of advanced electron optics and computational\nimaging algorithms. However, atomic-resolution 3D imaging in volumes larger\nthan the depth of field limit of the electron optics has so far been out of\nreach. Electron ptychography, a computational imaging method allowing to solve\nthe multiple-scattering problem from position- and momentum-resolved\nmeasurements, provides the opportunity to surpass this limit. Here, we\nexperimentally demonstrate atomic resolution three-dimensional phase-contrast\nimaging in a volume surpassing the depth of field limits using multi-slice\nptychographic electron tomography. We reconstruct tilt-series 4D-STEM\nmeasurements of a Co3O4 nanocube, yielding 1.75 {\\AA} resolution in a\nreconstructed volume of (18.2nm)^3.",
            "author": [
                "Andrey Romanov",
                "Min Gee Cho",
                "Mary Cooper Scott",
                "Colin Ophus",
                "Philipp Pelz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02580v1",
                "http://arxiv.org/pdf/2311.02580v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.app-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02579v1",
            "title": "mahaNLP: A Marathi Natural Language Processing Library",
            "updated": "2023-11-05T06:59:59Z",
            "published": "2023-11-05T06:59:59Z",
            "summary": "We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .",
            "author": [
                "Vidula Magdum",
                "Omkar Dhekane",
                "Sharayu Hiwarkhedkar",
                "Saloni Mittal",
                "Raviraj Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02579v1",
                "http://arxiv.org/pdf/2311.02579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02578v1",
            "title": "Temporal Sequencing of Documents",
            "updated": "2023-11-05T06:51:04Z",
            "published": "2023-11-05T06:51:04Z",
            "summary": "We outline an unsupervised method for temporal rank ordering of sets of\nhistorical documents, namely American State of the Union Addresses and DEEDS, a\ncorpus of medieval English property transfer documents. Our method relies upon\neffectively capturing the gradual change in word usage via a bandwidth estimate\nfor the non-parametric Generalized Linear Models (Fan, Heckman, and Wand,\n1995). The number of possible rank orders needed to search through possible\ncost functions related to the bandwidth can be quite large, even for a small\nset of documents. We tackle this problem of combinatorial optimization using\nthe Simulated Annealing algorithm, which allows us to obtain the optimal\ndocument temporal orders. Our rank ordering method significantly improved the\ntemporal sequencing of both corpora compared to a randomly sequenced baseline.\nThis unsupervised approach should enable the temporal ordering of undated\ndocument sets.",
            "author": [
                "Michael Gervers",
                "Gelila Tilahun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02578v1",
                "http://arxiv.org/pdf/2311.02578v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03395v1",
            "title": "Newvision: application for helping blind people using deep learning",
            "updated": "2023-11-05T06:23:10Z",
            "published": "2023-11-05T06:23:10Z",
            "summary": "As able-bodied people, we often take our vision for granted. For people who\nare visually impaired, however, their disability can have a significant impact\non their daily lives. We are developing proprietary headgear that will help\nvisually impaired people navigate their surroundings, identify objects and\npeople, read text, and avoid obstacles. The headgear will use a combination of\ncomputer vision, distance estimation with ultrasonic sensors, voice\nrecognition, and voice assistants to provide users with real-time information\nabout their environment. Users will be able to interact with the headgear\nthrough voice commands, such as ''What is that?'' to identify an object or\n''Navigate to the front door'' to find their way around. The headgear will then\nprovide the user with a verbal description of the object or spoken navigation\ninstructions. We believe that this headgear has the potential to make a\nsignificant difference in the lives of visually impaired people, allowing them\nto live more independently and participate more fully in society.",
            "author": [
                "Kumar Srinivas Bobba",
                "Kartheeban K",
                "Vamsi Krishna Sai Boddu",
                "Vijaya Mani Surendra Bolla",
                "Dinesh Bugga"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03395v1",
                "http://arxiv.org/pdf/2311.03395v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "I.2; I.4; I.7; C.3; J.7; J.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02573v1",
            "title": "Group Testing for Accurate and Efficient Range-Based Near Neighbor\n  Search : An Adaptive Binary Splitting Approach",
            "updated": "2023-11-05T06:12:03Z",
            "published": "2023-11-05T06:12:03Z",
            "summary": "This work presents an adaptive group testing framework for the range-based\nhigh dimensional near neighbor search problem. The proposed method detects\nhigh-similarity vectors from an extensive collection of high dimensional\nvectors, where each vector represents an image descriptor. Our method\nefficiently marks each item in the collection as neighbor or non-neighbor on\nthe basis of a cosine distance threshold without exhaustive search. Like other\nmethods in the domain of large scale retrieval, our approach exploits the\nassumption that most of the items in the collection are unrelated to the query.\nUnlike other methods, it does not assume a large difference between the cosine\nsimilarity of the query vector with the least related neighbor and that with\nthe least unrelated non-neighbor. Following the procedure of binary splitting,\na multi-stage adaptive group testing algorithm, we split the set of items to be\nsearched into half at each step, and perform dot product tests on smaller and\nsmaller subsets, many of which we are able to prune away. We experimentally\nshow that our method achieves a speed-up over exhaustive search by a factor of\nmore than ten with an accuracy same as that of exhaustive search, on a variety\nof large datasets. We present a theoretical analysis of the expected number of\ndistance computations per query and the probability that a pool with a certain\nnumber of members will be pruned. In this way, our method exploits very useful\nand practical distributional properties unlike other methods. In our method,\nall required data structures are created purely offline. Moreover, our method\ndoes not impose any strong assumptions on the number of true near neighbors, is\nadaptible to streaming settings where new vectors are dynamically added to the\ndatabase, and does not require any parameter tuning.",
            "author": [
                "Kashish Mittal",
                "Harsh Shah",
                "Ajit Rajwade"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02573v1",
                "http://arxiv.org/pdf/2311.02573v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02572v1",
            "title": "Multiple Object Tracking based on Occlusion-Aware Embedding Consistency\n  Learning",
            "updated": "2023-11-05T06:08:58Z",
            "published": "2023-11-05T06:08:58Z",
            "summary": "The Joint Detection and Embedding (JDE) framework has achieved remarkable\nprogress for multiple object tracking. Existing methods often employ extracted\nembeddings to re-establish associations between new detections and previously\ndisrupted tracks. However, the reliability of embeddings diminishes when the\nregion of the occluded object frequently contains adjacent objects or clutters,\nespecially in scenarios with severe occlusion. To alleviate this problem, we\npropose a novel multiple object tracking method based on visual embedding\nconsistency, mainly including: 1) Occlusion Prediction Module (OPM) and 2)\nOcclusion-Aware Association Module (OAAM). The OPM predicts occlusion\ninformation for each true detection, facilitating the selection of valid\nsamples for consistency learning of the track's visual embedding. The OAAM\nleverages occlusion cues and visual embeddings to generate two separate\nembeddings for each track, guaranteeing consistency in both unoccluded and\noccluded detections. By integrating these two modules, our method is capable of\naddressing track interruptions caused by occlusion in online tracking\nscenarios. Extensive experimental results demonstrate that our approach\nachieves promising performance levels in both unoccluded and occluded tracking\nscenarios.",
            "author": [
                "Yaoqi Hu",
                "Axi Niu",
                "Yu Zhu",
                "Qingsen Yan",
                "Jinqiu Sun",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02572v1",
                "http://arxiv.org/pdf/2311.02572v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02570v1",
            "title": "BanMANI: A Dataset to Identify Manipulated Social Media News in Bangla",
            "updated": "2023-11-05T05:49:57Z",
            "published": "2023-11-05T05:49:57Z",
            "summary": "Initial work has been done to address fake news detection and\nmisrepresentation of news in the Bengali language. However, no work in Bengali\nyet addresses the identification of specific claims in social media news that\nfalsely manipulates a related news article. At this point, this problem has\nbeen tackled in English and a few other languages, but not in the Bengali\nlanguage. In this paper, we curate a dataset of social media content labeled\nwith information manipulation relative to reference articles, called BanMANI.\nThe dataset collection method we describe works around the limitations of the\navailable NLP tools in Bangla. We expect these techniques will carry over to\nbuilding similar datasets in other low-resource languages. BanMANI forms the\nbasis both for evaluating the capabilities of existing NLP systems and for\ntraining or fine-tuning new models specifically on this task. In our analysis,\nwe find that this task challenges current LLMs both under zero-shot and\nfine-tuned settings.",
            "author": [
                "Mahammed Kamruzzaman",
                "Md. Minul Islam Shovon",
                "Gene Louis Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02570v1",
                "http://arxiv.org/pdf/2311.02570v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02566v1",
            "title": "Topic model based on co-occurrence word networks for unbalanced short\n  text datasets",
            "updated": "2023-11-05T04:44:23Z",
            "published": "2023-11-05T04:44:23Z",
            "summary": "We propose a straightforward solution for detecting scarce topics in\nunbalanced short-text datasets. Our approach, named CWUTM (Topic model based on\nco-occurrence word networks for unbalanced short text datasets), Our approach\naddresses the challenge of sparse and unbalanced short text topics by\nmitigating the effects of incidental word co-occurrence. This allows our model\nto prioritize the identification of scarce topics (Low-frequency topics).\nUnlike previous methods, CWUTM leverages co-occurrence word networks to capture\nthe topic distribution of each word, and we enhanced the sensitivity in\nidentifying scarce topics by redefining the calculation of node activity and\nnormalizing the representation of both scarce and abundant topics to some\nextent. Moreover, CWUTM adopts Gibbs sampling, similar to LDA, making it easily\nadaptable to various application scenarios. Our extensive experimental\nvalidation on unbalanced short-text datasets demonstrates the superiority of\nCWUTM compared to baseline approaches in discovering scarce topics. According\nto the experimental results the proposed model is effective in early and\naccurate detection of emerging topics or unexpected events on social platforms.",
            "author": [
                "Chengjie Ma",
                "Junping Du",
                "Meiyu Liang",
                "Zeli Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02566v1",
                "http://arxiv.org/pdf/2311.02566v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02564v1",
            "title": "Relation Extraction Model Based on Semantic Enhancement Mechanism",
            "updated": "2023-11-05T04:40:39Z",
            "published": "2023-11-05T04:40:39Z",
            "summary": "Relational extraction is one of the basic tasks related to information\nextraction in the field of natural language processing, and is an important\nlink and core task in the fields of information extraction, natural language\nunderstanding, and information retrieval. None of the existing relation\nextraction methods can effectively solve the problem of triple overlap. The\nCasAug model proposed in this paper based on the CasRel framework combined with\nthe semantic enhancement mechanism can solve this problem to a certain extent.\nThe CasAug model enhances the semantics of the identified possible subjects by\nadding a semantic enhancement mechanism, First, based on the semantic coding of\npossible subjects, pre-classify the possible subjects, and then combine the\nsubject lexicon to calculate the semantic similarity to obtain the similar\nvocabulary of possible subjects. According to the similar vocabulary obtained,\neach word in different relations is calculated through the attention mechanism.\nFor the contribution of the possible subject, finally combine the relationship\npre-classification results to weight the enhanced semantics of each\nrelationship to find the enhanced semantics of the possible subject, and send\nthe enhanced semantics combined with the possible subject to the object and\nrelationship extraction module. Complete the final relation triplet extraction.\nThe experimental results show that, compared with the baseline model, the\nCasAug model proposed in this paper has improved the effect of relation\nextraction, and CasAug's ability to deal with overlapping problems and extract\nmultiple relations is also better than the baseline model, indicating that the\nsemantic enhancement mechanism proposed in this paper It can further reduce the\njudgment of redundant relations and alleviate the problem of triple overlap.",
            "author": [
                "Peiyu Liu",
                "Junping Du",
                "Yingxia Shao",
                "Zeli Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02564v1",
                "http://arxiv.org/pdf/2311.02564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03393v2",
            "title": "Sketching Multidimensional Time Series for Fast Discord Mining",
            "updated": "2023-12-06T01:01:49Z",
            "published": "2023-11-05T04:17:34Z",
            "summary": "Time series discords are a useful primitive for time series anomaly\ndetection, and the matrix profile is capable of capturing discord effectively.\nThere exist many research efforts to improve the scalability of discord\ndiscovery with respect to the length of time series. However, there is\nsurprisingly little work focused on reducing the time complexity of matrix\nprofile computation associated with dimensionality of a multidimensional time\nseries. In this work, we propose a sketch for discord mining among\nmulti-dimensional time series. After an initial pre-processing of the sketch as\nfast as reading the data, the discord mining has runtime independent of the\ndimensionality of the original data. On several real world examples from water\ntreatment and transportation, the proposed algorithm improves the throughput by\nat least an order of magnitude (50X) and only has minimal impact on the quality\nof the approximated solution. Additionally, the proposed method can handle the\ndynamic addition or deletion of dimensions inconsequential overhead. This\nallows a data analyst to consider \"what-if\" scenarios in real time while\nexploring the data.",
            "author": [
                "Chin-Chia Michael Yeh",
                "Yan Zheng",
                "Menghai Pan",
                "Huiyuan Chen",
                "Zhongfang Zhuang",
                "Junpeng Wang",
                "Liang Wang",
                "Wei Zhang",
                "Jeff M. Phillips",
                "Eamonn Keogh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03393v2",
                "http://arxiv.org/pdf/2311.03393v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02559v1",
            "title": "Rotation Invariant Transformer for Recognizing Object in UAVs",
            "updated": "2023-11-05T03:55:08Z",
            "published": "2023-11-05T03:55:08Z",
            "summary": "Recognizing a target of interest from the UAVs is much more challenging than\nthe existing object re-identification tasks across multiple city cameras. The\nimages taken by the UAVs usually suffer from significant size difference when\ngenerating the object bounding boxes and uncertain rotation variations.\nExisting methods are usually designed for city cameras, incapable of handing\nthe rotation issue in UAV scenarios. A straightforward solution is to perform\nthe image-level rotation augmentation, but it would cause loss of useful\ninformation when inputting the powerful vision transformer as patches. This\nmotivates us to simulate the rotation operation at the patch feature level,\nproposing a novel rotation invariant vision transformer (RotTrans). This\nstrategy builds on high-level features with the help of the specificity of the\nvision transformer structure, which enhances the robustness against large\nrotation differences. In addition, we design invariance constraint to establish\nthe relationship between the original feature and the rotated features,\nachieving stronger rotation invariance. Our proposed transformer tested on the\nlatest UAV datasets greatly outperforms the current state-of-the-arts, which is\n5.9\\% and 4.8\\% higher than the highest mAP and Rank1. Notably, our model also\nperforms competitively for the person re-identification task on traditional\ncity cameras. In particular, our solution wins the first place in the UAV-based\nperson re-recognition track in the Multi-Modal Video Reasoning and Analyzing\nCompetition held in ICCV 2021. Code is available at\nhttps://github.com/whucsy/RotTrans.",
            "author": [
                "Shuoyi Chen",
                "Mang Ye",
                "Bo Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02559v1",
                "http://arxiv.org/pdf/2311.02559v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02558v1",
            "title": "Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity\n  with Free-Flying Robots",
            "updated": "2023-11-05T03:53:42Z",
            "published": "2023-11-05T03:53:42Z",
            "summary": "Assistive free-flyer robots autonomously caring for future crewed outposts --\nsuch as NASA's Astrobee robots on the International Space Station (ISS) -- must\nbe able to detect day-to-day interior changes to track inventory, detect and\ndiagnose faults, and monitor the outpost status. This work presents a framework\nfor multi-agent cooperative mapping and change detection to enable robotic\nmaintenance of space outposts. One agent is used to reconstruct a 3D model of\nthe environment from sequences of images and corresponding depth information.\nAnother agent is used to periodically scan the environment for inconsistencies\nagainst the 3D model. Change detection is validated after completing the\nsurveys using real image and pose data collected by Astrobee robots in a ground\ntesting environment and from microgravity aboard the ISS. This work outlines\nthe objectives, requirements, and algorithmic modules for the multi-agent\nreconstruction system, including recommendations for its use by assistive\nfree-flyers aboard future microgravity outposts.",
            "author": [
                "Holly Dinkel",
                "Julia Di",
                "Jamie Santos",
                "Keenan Albee",
                "Paulo Borges",
                "Marina Moreira",
                "Oleg Alexandrov",
                "Brian Coltin",
                "Trey Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02558v1",
                "http://arxiv.org/pdf/2311.02558v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07582v1",
            "title": "Evaluating the Potential of Leading Large Language Models in Reasoning\n  Biology Questions",
            "updated": "2023-11-05T03:34:17Z",
            "published": "2023-11-05T03:34:17Z",
            "summary": "Recent advances in Large Language Models (LLMs) have presented new\nopportunities for integrating Artificial General Intelligence (AGI) into\nbiological research and education. This study evaluated the capabilities of\nleading LLMs, including GPT-4, GPT-3.5, PaLM2, Claude2, and SenseNova, in\nanswering conceptual biology questions. The models were tested on a\n108-question multiple-choice exam covering biology topics in molecular biology,\nbiological techniques, metabolic engineering, and synthetic biology. Among the\nmodels, GPT-4 achieved the highest average score of 90 and demonstrated the\ngreatest consistency across trials with different prompts. The results\nindicated GPT-4's proficiency in logical reasoning and its potential to aid\nbiology research through capabilities like data analysis, hypothesis\ngeneration, and knowledge integration. However, further development and\nvalidation are still required before the promise of LLMs in accelerating\nbiological discovery can be realized.",
            "author": [
                "Xinyu Gong",
                "Jason Holmes",
                "Yiwei Li",
                "Zhengliang Liu",
                "Qi Gan",
                "Zihao Wu",
                "Jianli Zhang",
                "Yusong Zou",
                "Yuxi Teng",
                "Tian Jiang",
                "Hongtu Zhu",
                "Wei Liu",
                "Tianming Liu",
                "Yajun Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07582v1",
                "http://arxiv.org/pdf/2311.07582v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02557v1",
            "title": "Fast Minimization of Expected Logarithmic Loss via Stochastic Dual\n  Averaging",
            "updated": "2023-11-05T03:33:44Z",
            "published": "2023-11-05T03:33:44Z",
            "summary": "Consider the problem of minimizing an expected logarithmic loss over either\nthe probability simplex or the set of quantum density matrices. This problem\nencompasses tasks such as solving the Poisson inverse problem, computing the\nmaximum-likelihood estimate for quantum state tomography, and approximating\npositive semi-definite matrix permanents with the currently tightest\napproximation ratio. Although the optimization problem is convex, standard\niteration complexity guarantees for first-order methods do not directly apply\ndue to the absence of Lipschitz continuity and smoothness in the loss function.\n  In this work, we propose a stochastic first-order algorithm named $B$-sample\nstochastic dual averaging with the logarithmic barrier. For the Poisson inverse\nproblem, our algorithm attains an $\\varepsilon$-optimal solution in $\\tilde{O}\n(d^2/\\varepsilon^2)$ time, matching the state of the art. When computing the\nmaximum-likelihood estimate for quantum state tomography, our algorithm yields\nan $\\varepsilon$-optimal solution in $\\tilde{O} (d^3/\\varepsilon^2)$ time,\nwhere $d$ denotes the dimension. This improves on the time complexities of\nexisting stochastic first-order methods by a factor of $d^{\\omega-2}$ and those\nof batch methods by a factor of $d^2$, where $\\omega$ denotes the matrix\nmultiplication exponent. Numerical experiments demonstrate that empirically,\nour algorithm outperforms existing methods with explicit complexity guarantees.",
            "author": [
                "Chung-En Tsai",
                "Hao-Chung Cheng",
                "Yen-Huan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02557v1",
                "http://arxiv.org/pdf/2311.02557v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02552v1",
            "title": "IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D\n  Reconstruction",
            "updated": "2023-11-05T03:01:36Z",
            "published": "2023-11-05T03:01:36Z",
            "summary": "Reconstruction of 3D open surfaces (e.g., non-watertight meshes) is an\nunderexplored area of computer vision. Recent learning-based implicit\ntechniques have removed previous barriers by enabling reconstruction in\narbitrary resolutions. Yet, such approaches often rely on distinguishing\nbetween the inside and outside of a surface in order to extract a zero level\nset when reconstructing the target. In the case of open surfaces, this\ndistinction often leads to artifacts such as the artificial closing of surface\ngaps. However, real-world data may contain intricate details defined by salient\nsurface gaps. Implicit functions that regress an unsigned distance field have\nshown promise in reconstructing such open surfaces. Nonetheless, current\nunsigned implicit methods rely on a discretized representation of the raw data.\nThis not only bounds the learning process to the representation's resolution,\nbut it also introduces outliers in the reconstruction. To enable accurate\nreconstruction of open surfaces without introducing outliers, we propose a\nlearning-based implicit point-voxel model (IPVNet). IPVNet predicts the\nunsigned distance between a surface and a query point in 3D space by leveraging\nboth raw point cloud data and its discretized voxel counterpart. Experiments on\nsynthetic and real-world public datasets demonstrates that IPVNet outperforms\nthe state of the art while producing far fewer outliers in the resulting\nreconstruction.",
            "author": [
                "Mohammad Samiul Arshad",
                "William J. Beksi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02552v1",
                "http://arxiv.org/pdf/2311.02552v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02551v1",
            "title": "High-dimensional Bid Learning for Energy Storage Bidding in Energy\n  Markets",
            "updated": "2023-11-05T02:59:53Z",
            "published": "2023-11-05T02:59:53Z",
            "summary": "With the growing penetration of renewable energy resource, electricity market\nprices have exhibited greater volatility. Therefore, it is important for Energy\nStorage Systems(ESSs) to leverage the multidimensional nature of energy market\nbids to maximize profitability. However, current learning methods cannot fully\nutilize the high-dimensional price-quantity bids in the energy markets. To\naddress this challenge, we modify the common reinforcement learning(RL) process\nby proposing a new bid representation method called Neural Network Embedded\nBids (NNEBs). NNEBs refer to market bids that are represented by monotonic\nneural networks with discrete outputs. To achieve effective learning of NNEBs,\nwe first learn a neural network as a strategic mapping from the market price to\nESS power output with RL. Then, we re-train the network with two training\nmodifications to make the network output monotonic and discrete. Finally, the\nneural network is equivalently converted into a high-dimensional bid for\nbidding. We conducted experiments over real-world market datasets. Our studies\nshow that the proposed method achieves 18% higher profit than the baseline and\nup to 78% profit of the optimal market bidder.",
            "author": [
                "Jinyu Liu",
                "Hongye Guo",
                "Qinghu Tang",
                "En Lu",
                "Qiuna Cai",
                "Qixin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02551v1",
                "http://arxiv.org/pdf/2311.02551v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.GT",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02549v1",
            "title": "3D-Aware Talking-Head Video Motion Transfer",
            "updated": "2023-11-05T02:50:45Z",
            "published": "2023-11-05T02:50:45Z",
            "summary": "Motion transfer of talking-head videos involves generating a new video with\nthe appearance of a subject video and the motion pattern of a driving video.\nCurrent methodologies primarily depend on a limited number of subject images\nand 2D representations, thereby neglecting to fully utilize the multi-view\nappearance features inherent in the subject video. In this paper, we propose a\nnovel 3D-aware talking-head video motion transfer network, Head3D, which fully\nexploits the subject appearance information by generating a\nvisually-interpretable 3D canonical head from the 2D subject frames with a\nrecurrent network. A key component of our approach is a self-supervised 3D head\ngeometry learning module, designed to predict head poses and depth maps from 2D\nsubject video frames. This module facilitates the estimation of a 3D head in\ncanonical space, which can then be transformed to align with driving video\nframes. Additionally, we employ an attention-based fusion network to combine\nthe background and other details from subject frames with the 3D subject head\nto produce the synthetic target video. Our extensive experiments on two public\ntalking-head video datasets demonstrate that Head3D outperforms both 2D and 3D\nprior arts in the practical cross-identity setting, with evidence showing it\ncan be readily adapted to the pose-controllable novel view synthesis task.",
            "author": [
                "Haomiao Ni",
                "Jiachen Liu",
                "Yuan Xue",
                "Sharon X. Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02549v1",
                "http://arxiv.org/pdf/2311.02549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02543v1",
            "title": "Pairwise likelihood estimation and limited information goodness-of-fit\n  test statistics for binary factor analysis models under complex survey\n  sampling",
            "updated": "2023-11-05T02:05:48Z",
            "published": "2023-11-05T02:05:48Z",
            "summary": "This paper discusses estimation and limited information goodness-of-fit test\nstatistics in factor models for binary data using pairwise likelihood\nestimation and sampling weights. The paper extends the applicability of\npairwise likelihood estimation for factor models with binary data to\naccommodate complex sampling designs. Additionally, it introduces two key\nlimited information test statistics: the Pearson chi-squared test and the Wald\ntest. To enhance computational efficiency, the paper introduces modifications\nto both test statistics. The performance of the estimation and the proposed\ntest statistics under simple random sampling and unequal probability sampling\nis evaluated using simulated data.",
            "author": [
                "Haziq Jamil",
                "Irini Moustaki",
                "Chris Skinner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02543v1",
                "http://arxiv.org/pdf/2311.02543v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02542v1",
            "title": "VR-NeRF: High-Fidelity Virtualized Walkable Spaces",
            "updated": "2023-11-05T02:03:14Z",
            "published": "2023-11-05T02:03:14Z",
            "summary": "We present an end-to-end system for the high-fidelity capture, model\nreconstruction, and real-time rendering of walkable spaces in virtual reality\nusing neural radiance fields. To this end, we designed and built a custom\nmulti-camera rig to densely capture walkable spaces in high fidelity and with\nmulti-view high dynamic range images in unprecedented quality and density. We\nextend instant neural graphics primitives with a novel perceptual color space\nfor learning accurate HDR appearance, and an efficient mip-mapping mechanism\nfor level-of-detail rendering with anti-aliasing, while carefully optimizing\nthe trade-off between quality and speed. Our multi-GPU renderer enables\nhigh-fidelity volume rendering of our neural radiance field model at the full\nVR resolution of dual 2K$\\times$2K at 36 Hz on our custom demo machine. We\ndemonstrate the quality of our results on our challenging high-fidelity\ndatasets, and compare our method and datasets to existing baselines. We release\nour dataset on our project website.",
            "author": [
                "Linning Xu",
                "Vasu Agrawal",
                "William Laney",
                "Tony Garcia",
                "Aayush Bansal",
                "Changil Kim",
                "Samuel Rota Bul\u00f2",
                "Lorenzo Porzi",
                "Peter Kontschieder",
                "Alja\u017e Bo\u017ei\u010d",
                "Dahua Lin",
                "Michael Zollh\u00f6fer",
                "Christian Richardt"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618139",
                "http://arxiv.org/abs/2311.02542v1",
                "http://arxiv.org/pdf/2311.02542v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02541v1",
            "title": "Reduced tensor network formulation for non-Abelian gauge theories in\n  arbitrary dimensions",
            "updated": "2023-11-05T02:00:10Z",
            "published": "2023-11-05T02:00:10Z",
            "summary": "Formulating non-Abelian gauge theories as a tensor network is known to be\nchallenging due to the internal degrees of freedom that result in the\ndegeneracy in the singular value spectrum. In two dimensions, it is\nstraightforward to 'trace out' these degrees of freedom with the use of\ncharacter expansion, giving a reduced tensor network where the degeneracy\nassociated with the internal symmetry is eliminated. In this work, we show that\nsuch an index loop also exists in higher dimensions in the form of a closed\ntensor network we call the 'armillary sphere'. This allows us to completely\neliminate the matrix indices and reduce the overall size of the tensors in the\nsame way as is possible in two dimensions. This formulation allows us to\ninclude significantly more representations with the same tensor size, thus\nmaking it possible to reach a greater level of numerical accuracy in the tensor\nrenormalization group computations.",
            "author": [
                "Atis Yosprakob"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02541v1",
                "http://arxiv.org/pdf/2311.02541v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02538v1",
            "title": "Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation\n  Protocols",
            "updated": "2023-11-05T01:45:31Z",
            "published": "2023-11-05T01:45:31Z",
            "summary": "Untrimmed videos have interrelated events, dependencies, context, overlapping\nevents, object-object interactions, domain specificity, and other semantics\nthat are worth highlighting while describing a video in natural language. Owing\nto such a vast diversity, a single sentence can only correctly describe a\nportion of the video. Dense Video Captioning (DVC) aims at detecting and\ndescribing different events in a given video. The term DVC originated in the\n2017 ActivityNet challenge, after which considerable effort has been made to\naddress the challenge. Dense Video Captioning is divided into three sub-tasks:\n(1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and\n(3) Dense Caption Generation (DCG). This review aims to discuss all the studies\nthat claim to perform DVC along with its sub-tasks and summarize their results.\nWe also discuss all the datasets that have been used for DVC. Lastly, we\nhighlight some emerging challenges and future trends in the field.",
            "author": [
                "Iqra Qasim",
                "Alexander Horsch",
                "Dilip K. Prasad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02538v1",
                "http://arxiv.org/pdf/2311.02538v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02537v1",
            "title": "Contract Design With Safety Inspections",
            "updated": "2023-11-05T01:23:43Z",
            "published": "2023-11-05T01:23:43Z",
            "summary": "We study the role of regulatory inspections in a contract design problem in\nwhich a principal interacts separately with multiple agents. Each agent's\nhidden action includes a dimension that determines whether they undertake an\nextra costly step to adhere to safety protocols. The principal's objective is\nto use payments combined with a limited budget for random inspections to\nincentivize agents towards safety-compliant actions that maximize the\nprincipal's utility. We first focus on the single-agent setting with linear\ncontracts and present an efficient algorithm that characterizes the optimal\nlinear contract, which includes both payment and random inspection. We further\ninvestigate how the optimal contract changes as the inspection cost or the cost\nof adhering to safety protocols vary. Notably, we demonstrate that the agent's\ncompensation increases if either of these costs escalates. However, while the\nprobability of inspection decreases with rising inspection costs, it\ndemonstrates nonmonotonic behavior as a function of the safety action costs.\nLastly, we explore the multi-agent setting, where the principal's challenge is\nto determine the best distribution of inspection budgets among all agents. We\npropose an efficient approach based on dynamic programming to find an\napproximately optimal allocation of inspection budget across contracts. We also\ndesign a random sequential scheme to determine the inspector's assignments,\nensuring each agent is inspected at most once and at the desired probability.\nFinally, we present a case study illustrating that a mere difference in the\ncost of inspection across various agents can drive the principal's decision to\nforego inspecting a significant fraction of them, concentrating its entire\nbudget on those that are less costly to inspect.",
            "author": [
                "Alireza Fallah",
                "Michael I. Jordan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02537v1",
                "http://arxiv.org/pdf/2311.02537v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02536v1",
            "title": "Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation\n  for Grounding-Based Vision and Language Models",
            "updated": "2023-11-05T01:14:02Z",
            "published": "2023-11-05T01:14:02Z",
            "summary": "Grounding-based vision and language models have been successfully applied to\nlow-level vision tasks, aiming to precisely locate objects referred in\ncaptions. The effectiveness of grounding representation learning heavily relies\non the scale of the training dataset. Despite being a useful data enrichment\nstrategy, data augmentation has received minimal attention in existing vision\nand language tasks as augmentation for image-caption pairs is non-trivial. In\nthis study, we propose a robust phrase grounding model trained with\ntext-conditioned and text-unconditioned data augmentations. Specifically, we\napply text-conditioned color jittering and horizontal flipping to ensure\nsemantic consistency between images and captions. To guarantee image-caption\ncorrespondence in the training samples, we modify the captions according to\npre-defined keywords when applying horizontal flipping. Additionally, inspired\nby recent masked signal reconstruction, we propose to use pixel-level masking\nas a novel form of data augmentation. While we demonstrate our data\naugmentation method with MDETR framework, the proposed approach is applicable\nto common grounding-based vision and language tasks with other frameworks.\nFinally, we show that image encoder pretrained on large-scale image and\nlanguage datasets (such as CLIP) can further improve the results. Through\nextensive experiments on three commonly applied datasets: Flickr30k, referring\nexpressions and GQA, our method demonstrates advanced performance over the\nstate-of-the-arts with various metrics. Code can be found in\nhttps://github.com/amzn/augment-the-pairs-wacv2024.",
            "author": [
                "Jingru Yi",
                "Burak Uzkent",
                "Oana Ignat",
                "Zili Li",
                "Amanmeet Garg",
                "Xiang Yu",
                "Linda Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02536v1",
                "http://arxiv.org/pdf/2311.02536v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02535v1",
            "title": "TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged\n  Object Detection Via Learnable Token Selection",
            "updated": "2023-11-05T01:09:07Z",
            "published": "2023-11-05T01:09:07Z",
            "summary": "The area of Video Camouflaged Object Detection (VCOD) presents unique\nchallenges in the field of computer vision due to texture similarities between\ntarget objects and their surroundings, as well as irregular motion patterns\ncaused by both objects and camera movement. In this paper, we introduce\nTokenMotion (TMNet), which employs a transformer-based model to enhance VCOD by\nextracting motion-guided features using a learnable token selection. Evaluated\non the challenging MoCA-Mask dataset, TMNet achieves state-of-the-art\nperformance in VCOD. It outperforms the existing state-of-the-art method by a\n12.8% improvement in weighted F-measure, an 8.4% enhancement in S-measure, and\na 10.7% boost in mean IoU. The results demonstrate the benefits of utilizing\nmotion-guided features via learnable token selection within a transformer-based\nframework to tackle the intricate task of VCOD.",
            "author": [
                "Zifan Yu",
                "Erfan Bank Tavakoli",
                "Meida Chen",
                "Suya You",
                "Raghuveer Rao",
                "Sanjeev Agarwal",
                "Fengbo Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02535v1",
                "http://arxiv.org/pdf/2311.02535v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02533v1",
            "title": "Precision ground-state energy calculation for the water molecule on a\n  superconducting quantum processor",
            "updated": "2023-11-05T01:05:58Z",
            "published": "2023-11-05T01:05:58Z",
            "summary": "The accurate computation of properties of large molecular systems is\nclassically infeasible and is one of the applications in which it is hoped that\nquantum computers will demonstrate an advantage over classical devices.\nHowever, due to the limitations of present-day quantum hardware,\nvariational-hybrid algorithms introduced to tackle these problems struggle to\nmeet the accuracy and precision requirements of chemical applications. Here, we\napply the Quantum Computed Moments (QCM) approach combined with a variety of\nnoise-mitigation techniques to an 8 qubit/spin-orbital representation of the\nwater molecule (H$_2$O). A noise-stable improvement on the variational result\nfor a 4-excitation trial-state (circuit depth 25, 22 CNOTs) was obtained, with\nthe ground-state energy computed to be within $1.4\\pm1.2$ mHa of exact\ndiagonalisation in the 14 spin-orbital basis. Thus, the QCM approach, despite\nan increased number of measurements and noisy quantum hardware (CNOT error\nrates c.1% corresponding to expected error rates on the trial-state circuit of\norder 20%), is able to determine the ground-state energy of a non-trivial\nmolecular system at the required accuracy (c.0.1%). To the best of our\nknowledge, these results are the largest calculations performed on a physical\nquantum computer to date in terms of encoding individual spin-orbitals\nproducing chemically relevant accuracy, and a promising indicator of how such\nhybrid approaches might scale to problems of interest in the\nlow-error/fault-tolerant regimes as quantum computers develop.",
            "author": [
                "Michael A. Jones",
                "Harish J. Vallury",
                "Lloyd C. L. Hollenberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02533v1",
                "http://arxiv.org/pdf/2311.02533v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02525v1",
            "title": "QOCO: A QoE-Oriented Computation Offloading Algorithm based on Deep\n  Reinforcement Learning for Mobile Edge Computing",
            "updated": "2023-11-04T23:22:42Z",
            "published": "2023-11-04T23:22:42Z",
            "summary": "In the realm of mobile edge computing (MEC), efficient computation task\noffloading plays a pivotal role in ensuring a seamless quality of experience\n(QoE) for users. Maintaining a high QoE is paramount in today's interconnected\nworld, where users demand responsive and reliable services. This challenge\nstands as one of the most primary key factors contributing to handling dynamic\nand uncertain mobile environment. In this study, we delve into computation\noffloading in MEC systems, where strict task processing deadlines and energy\nconstraints can adversely affect the system performance. We formulate the\ncomputation task offloading problem as a Markov decision process (MDP) to\nmaximize the long-term QoE of each user individually. We propose a\ndecentralized QoE-oriented computation offloading (QOCO) algorithm based on\ndeep reinforcement learning (DRL) that empowers mobile devices to make their\noffloading decisions without requiring knowledge of decisions made by other\ndevices. Through numerical studies, we evaluate the performance of QOCO.\nSimulation results validate that the QOCO algorithm efficiently exploits the\ncomputational resources of edge nodes. Consequently, it can complete 14% more\ntasks and reduce task delay and energy consumption by 9% and 6%, respectively.\nThese together contribute to a significant improvement of at least 37% in\naverage QoE compared to an existing algorithm.",
            "author": [
                "Iman Rahmati",
                "Hamed Shah-Mansouri",
                "Ali Movaghar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02525v1",
                "http://arxiv.org/pdf/2311.02525v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02523v1",
            "title": "UniTSFace: Unified Threshold Integrated Sample-to-Sample Loss for Face\n  Recognition",
            "updated": "2023-11-04T23:00:40Z",
            "published": "2023-11-04T23:00:40Z",
            "summary": "Sample-to-class-based face recognition models can not fully explore the\ncross-sample relationship among large amounts of facial images, while\nsample-to-sample-based models require sophisticated pairing processes for\ntraining. Furthermore, neither method satisfies the requirements of real-world\nface verification applications, which expect a unified threshold separating\npositive from negative facial pairs. In this paper, we propose a unified\nthreshold integrated sample-to-sample based loss (USS loss), which features an\nexplicit unified threshold for distinguishing positive from negative pairs.\nInspired by our USS loss, we also derive the sample-to-sample based softmax and\nBCE losses, and discuss their relationship. Extensive evaluation on multiple\nbenchmark datasets, including MFR, IJB-C, LFW, CFP-FP, AgeDB, and MegaFace,\ndemonstrates that the proposed USS loss is highly efficient and can work\nseamlessly with sample-to-class-based losses. The embedded loss (USS and\nsample-to-class Softmax loss) overcomes the pitfalls of previous approaches and\nthe trained facial model UniTSFace exhibits exceptional performance,\noutperforming state-of-the-art methods, such as CosFace, ArcFace, VPL,\nAnchorFace, and UNPG. Our code is available.",
            "author": [
                "Qiufu Li",
                "Xi Jia",
                "Jiancan Zhou",
                "Linlin Shen",
                "Jinming Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02523v1",
                "http://arxiv.org/pdf/2311.02523v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02522v1",
            "title": "Comparison of Different Machine Learning Approaches to Predict Viscosity\n  of Tri-n-Butyl Phosphate Mixtures Using Experimental Data",
            "updated": "2023-11-04T22:46:50Z",
            "published": "2023-11-04T22:46:50Z",
            "summary": "Tri-n-butyl phosphate (TBP) is a solvent that is commonly used in a variety\nof industries, including the nuclear and chemical industries, for its ability\nto dissolve and purify various inorganic acids and metals. It is often used in\nhydrometallurgical processes to separate and purify these substances. Machine\nlearning models offer a promising alternative to traditional methods for\npredicting the viscosity of TBP mixtures. By training machine learning models\non a dataset of viscosity measurements, it is possible to accurately predict\nthe viscosity of TBP mixtures at different compositions, densities, and\ntemperatures, which can save time and resources and reduce the risk of exposure\nto toxic solvents. This paper aimed at proposing Machine Learning (ML)\ntechniques to automatically predict the viscosity of TBP mixtures using\nexperimental data. For comparison peruses, we trained five different ML\nalgorithms including Support Vector Regressor (SVR), Random Forest (RF),\nLogistic Regression (LR), Gradient Boosted Decision Trees (XGBoost), and Neural\nNetwork (NN). We collected a total of 511 measurements for TBP mixtures with\ntemperature-based density, at different compositions, containing hexane,\ndodecane, cyclohexane, n-heptane, toluene, and ethylbenzene measured at\ntemperatures of T= (288.15, 293.15, 298.15, 303.15, 308.15, 313.15, 318.15,\n323.15, and 328.15) K. The results revealed that the NN model with 25 and 50\nneurons in the hidden layers could achieve the best viscosity predictions for a\nsystem of TBP mixtures. The NN model outperformed other regular ML models in\nterms of Mean Square Error (MSE) of 0.157 % and adjusted R2 of 99.72 % on the\ntest data set. This paper demonstrated that the NN model can be an appropriate\noption to accurately predict the viscosity of TBP + Ethylbenzene with a margin\nof deviation as low as 0.049 %.",
            "author": [
                "Faranak Hatami",
                "Mousa Moradi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02522v1",
                "http://arxiv.org/pdf/2311.02522v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02516v1",
            "title": "Forward $\u03c7^2$ Divergence Based Variational Importance Sampling",
            "updated": "2023-11-04T21:46:28Z",
            "published": "2023-11-04T21:46:28Z",
            "summary": "Maximizing the log-likelihood is a crucial aspect of learning latent variable\nmodels, and variational inference (VI) stands as the commonly adopted method.\nHowever, VI can encounter challenges in achieving a high log-likelihood when\ndealing with complicated posterior distributions. In response to this\nlimitation, we introduce a novel variational importance sampling (VIS) approach\nthat directly estimates and maximizes the log-likelihood. VIS leverages the\noptimal proposal distribution, achieved by minimizing the forward $\\chi^2$\ndivergence, to enhance log-likelihood estimation. We apply VIS to various\npopular latent variable models, including mixture models, variational\nauto-encoders, and partially observable generalized linear models. Results\ndemonstrate that our approach consistently outperforms state-of-the-art\nbaselines, both in terms of log-likelihood and model parameter estimation.",
            "author": [
                "Chengrui Li",
                "Yule Wang",
                "Weihan Li",
                "Anqi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02516v1",
                "http://arxiv.org/pdf/2311.02516v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02510v2",
            "title": "Anthropomorphic Grasping with Neural Object Shape Completion",
            "updated": "2023-11-09T15:06:38Z",
            "published": "2023-11-04T21:05:26Z",
            "summary": "The progressive prevalence of robots in human-suited environments has given\nrise to a myriad of object manipulation techniques, in which dexterity plays a\nparamount role. It is well-established that humans exhibit extraordinary\ndexterity when handling objects. Such dexterity seems to derive from a robust\nunderstanding of object properties (such as weight, size, and shape), as well\nas a remarkable capacity to interact with them. Hand postures commonly\ndemonstrate the influence of specific regions on objects that need to be\ngrasped, especially when objects are partially visible. In this work, we\nleverage human-like object understanding by reconstructing and completing their\nfull geometry from partial observations, and manipulating them using a 7-DoF\nanthropomorphic robot hand. Our approach has significantly improved the\ngrasping success rates of baselines with only partial reconstruction by nearly\n30% and achieved over 150 successful grasps with three different object\ncategories. This demonstrates our approach's consistent ability to predict and\nexecute grasping postures based on the completed object shapes from various\ndirections and positions in real-world scenarios. Our work opens up new\npossibilities for enhancing robotic applications that require precise grasping\nand manipulation skills of real-world reconstructed objects.",
            "author": [
                "Diego Hidalgo-Carvajal",
                "Hanzhi Chen",
                "Gemma C. Bettelani",
                "Jaesug Jung",
                "Melissa Zavaglia",
                "Laura Busse",
                "Abdeldjallil Naceri",
                "Stefan Leutenegger",
                "Sami Haddadin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02510v2",
                "http://arxiv.org/pdf/2311.02510v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02508v1",
            "title": "Dissipative quadratizations of polynomial ODE systems",
            "updated": "2023-11-04T21:00:51Z",
            "published": "2023-11-04T21:00:51Z",
            "summary": "Quadratization refers to a transformation of an arbitrary system of\npolynomial ordinary differential equations to a system with at most quadratic\nright-hand side. Such a transformation unveils new variables and model\nstructures that facilitate model analysis, simulation, and control and offers a\nconvenient parameterization for data-driven approaches. Quadratization\ntechniques have found applications in diverse fields, including systems theory,\nfluid mechanics, chemical reaction modeling, and mathematical analysis.\n  In this study, we focus on quadratizations that preserve the stability\nproperties of the original model, specifically dissipativity at given\nequilibria. This preservation is desirable in many applications of\nquadratization including reachability analysis and synthetic biology. We\nestablish the existence of dissipativity-preserving quadratizations, develop an\nalgorithm for their computation, and demonstrate it in several case studies.",
            "author": [
                "Yubo Cai",
                "Gleb Pogudin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02508v1",
                "http://arxiv.org/pdf/2311.02508v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.NA",
                "cs.SC",
                "cs.SY",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02502v1",
            "title": "MAAIP: Multi-Agent Adversarial Interaction Priors for imitation from\n  fighting demonstrations for physics-based characters",
            "updated": "2023-11-04T20:40:39Z",
            "published": "2023-11-04T20:40:39Z",
            "summary": "Simulating realistic interaction and motions for physics-based characters is\nof great interest for interactive applications, and automatic secondary\ncharacter animation in the movie and video game industries. Recent works in\nreinforcement learning have proposed impressive results for single character\nsimulation, especially the ones that use imitation learning based techniques.\nHowever, imitating multiple characters interactions and motions requires to\nalso model their interactions. In this paper, we propose a novel Multi-Agent\nGenerative Adversarial Imitation Learning based approach that generalizes the\nidea of motion imitation for one character to deal with both the interaction\nand the motions of the multiple physics-based characters. Two unstructured\ndatasets are given as inputs: 1) a single-actor dataset containing motions of a\nsingle actor performing a set of motions linked to a specific application, and\n2) an interaction dataset containing a few examples of interactions between\nmultiple actors. Based on these datasets, our system trains control policies\nallowing each character to imitate the interactive skills associated with each\nactor, while preserving the intrinsic style. This approach has been tested on\ntwo different fighting styles, boxing and full-body martial art, to demonstrate\nthe ability of the method to imitate different styles.",
            "author": [
                "Mohamed Younes",
                "Ewa Kijak",
                "Richard Kulpa",
                "Simon Malinowski",
                "Franck Multon"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3606926",
                "http://arxiv.org/abs/2311.02502v1",
                "http://arxiv.org/pdf/2311.02502v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.RO",
                "68U99",
                "I.3.8; I.3.m"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02501v1",
            "title": "Single-electron qubits based on ring-shaped surface states on solid neon",
            "updated": "2023-11-04T20:36:34Z",
            "published": "2023-11-04T20:36:34Z",
            "summary": "Recent experiments demonstrate that a charge qubit consisting of a single\nelectron bound to a solid neon surface exhibits an exceptionally long coherence\ntime, making it a promising platform for quantum computing. However, some\nobservations cast doubt on the direct correlation between the electron's\nbinding mechanism and quantum states with the applied electric trapping\npotential. In this study, we introduce a theoretical framework to examine the\nelectron's interactions with neon surface topography, such as bumps and\nvalleys. By evaluating the surface charges induced by the electron, we\ndemonstrate its strong perpendicular binding to the neon surface. The\nSchrodinger equation for the electron's lateral motion on the curved 2D surface\nis then solved for extensive topographical variations. Our results reveal that\nsurface bumps can naturally bind an electron, forming unique ring-shaped\nquantum states that align with experimental observations. We also show that the\nelectron's excitation energy can be smoothly tuned using an magnetic field to\nfacilitate qubit operation. This study offers a leap in our understanding of\ne-neon qubit properties, laying the groundwork to guide its design and\noptimization for advancing quantum computing architectures.",
            "author": [
                "Toshiaki Kanai",
                "Dafei Jin",
                "Wei Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02501v1",
                "http://arxiv.org/pdf/2311.02501v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02500v1",
            "title": "Active Laser-Camera Scanning for High-Precision Fruit Localization in\n  Robotic Harvesting: System Design and Calibration",
            "updated": "2023-11-04T20:26:53Z",
            "published": "2023-11-04T20:26:53Z",
            "summary": "Robust and effective fruit detection and localization is essential for\nrobotic harvesting systems. While extensive research efforts have been devoted\nto improving fruit detection, less emphasis has been placed on the fruit\nlocalization aspect, which is a crucial yet challenging task due to limited\ndepth accuracy from existing sensor measurements in the natural orchard\nenvironment with variable lighting conditions and foliage/branch occlusions. In\nthis paper, we present the system design and calibration of an Active\nLAser-Camera Scanner (ALACS), a novel perception module for robust and\nhigh-precision fruit localization. The hardware of ALACS mainly consists of a\nred line laser, an RGB camera, and a linear motion slide, which are seamlessly\nintegrated into an active scanning scheme where a dynamic-targeting\nlaser-triangulation principle is employed. A high-fidelity extrinsic model is\ndeveloped to pair the laser illumination and the RGB camera, enabling precise\ndepth computation when the target is captured by both sensors. A random sample\nconsensus-based robust calibration scheme is then designed to calibrate the\nmodel parameters based on collected data. Comprehensive evaluations are\nconducted to validate the system model and calibration scheme. The results show\nthat the proposed calibration method can detect and remove data outliers to\nachieve robust parameter computation, and the calibrated ALACS system is able\nto achieve high-precision localization with millimeter-level accuracy.",
            "author": [
                "Kaixiang Zhang",
                "Pengyu Chu",
                "Kyle Lammers",
                "Zhaojian Li",
                "Renfu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02500v1",
                "http://arxiv.org/pdf/2311.02500v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02499v1",
            "title": "Can Chat GPT solve a Linguistics Exam?",
            "updated": "2023-11-04T20:02:57Z",
            "published": "2023-11-04T20:02:57Z",
            "summary": "The present study asks if ChatGPT4, the version of ChatGPT which uses the\nlanguage model GPT4, can successfully solve introductory linguistic exams.\nPrevious exam questions of an Introduction to Linguistics course at a German\nuniversity are used to test this. The exam questions were fed into ChatGPT4\nwith only minimal preprocessing. The results show that the language model is\nvery successful in the interpretation even of complex and nested tasks. It\nproved surprisingly successful in the task of broad phonetic transcription, but\nperformed less well in the analysis of morphemes and phrases. In simple cases\nit performs sufficiently well, but rarer cases, particularly with missing\none-to-one correspondence, are currently treated with mixed results. The model\nis not yet able to deal with visualisations, such as the analysis or generation\nof syntax trees. More extensive preprocessing, which translates these tasks\ninto text data, allow the model to also solve these tasks successfully.",
            "author": [
                "Patricia Ronan",
                "Gerold Schneider"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02499v1",
                "http://arxiv.org/pdf/2311.02499v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "J.5; K.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02488v1",
            "title": "Neural Network Reconstruction of the Left Atrium using Sparse Catheter\n  Paths",
            "updated": "2023-11-04T19:21:24Z",
            "published": "2023-11-04T19:21:24Z",
            "summary": "Catheter based radiofrequency ablation for pulmonary vein isolation has\nbecome the first line of treatment for atrial fibrillation in recent years.\nThis requires a rather accurate map of the left atrial sub-endocardial surface\nincluding the ostia of the pulmonary veins, which requires dense sampling of\nthe surface and takes more than 10 minutes. The focus of this work is to\nprovide left atrial visualization early in the procedure to ease procedure\ncomplexity and enable further workflows, such as using catheters that have\ndifficulty sampling the surface. We propose a dense encoder-decoder network\nwith a novel regularization term to reconstruct the shape of the left atrium\nfrom partial data which is derived from simple catheter maneuvers. To train the\nnetwork, we acquire a large dataset of 3D atria shapes and generate\ncorresponding catheter trajectories. Once trained, we show that the suggested\nnetwork can sufficiently approximate the atrium shape based on a given\ntrajectory. We compare several network solutions for the 3D atrium\nreconstruction. We demonstrate that the solution proposed produces realistic\nvisualization using partial acquisition within a 3-minute time interval.\nSynthetic and human clinical cases are shown.",
            "author": [
                "Alon Baram",
                "Moshe Safran",
                "Tomer Noy",
                "Naveh Geri",
                "Hayit Greenspan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02488v1",
                "http://arxiv.org/pdf/2311.02488v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02485v1",
            "title": "Uncertainty Quantification of Deep Learning for Spatiotemporal Data:\n  Challenges and Opportunities",
            "updated": "2023-11-04T19:11:25Z",
            "published": "2023-11-04T19:11:25Z",
            "summary": "With the advancement of GPS, remote sensing, and computational simulations,\nlarge amounts of geospatial and spatiotemporal data are being collected at an\nincreasing speed. Such emerging spatiotemporal big data assets, together with\nthe recent progress of deep learning technologies, provide unique opportunities\nto transform society. However, it is widely recognized that deep learning\nsometimes makes unexpected and incorrect predictions with unwarranted\nconfidence, causing severe consequences in high-stake decision-making\napplications (e.g., disaster management, medical diagnosis, autonomous\ndriving). Uncertainty quantification (UQ) aims to estimate a deep learning\nmodel's confidence. This paper provides a brief overview of UQ of deep learning\nfor spatiotemporal data, including its unique challenges and existing methods.\nWe particularly focus on the importance of uncertainty sources. We identify\nseveral future research directions for spatiotemporal data.",
            "author": [
                "Wenchong He",
                "Zhe Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02485v1",
                "http://arxiv.org/pdf/2311.02485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02480v1",
            "title": "A Strictly Bounded Deep Network for Unpaired Cyclic Translation of\n  Medical Images",
            "updated": "2023-11-04T18:43:31Z",
            "published": "2023-11-04T18:43:31Z",
            "summary": "Medical image translation is an ill-posed problem. Unlike existing paired\nunbounded unidirectional translation networks, in this paper, we consider\nunpaired medical images and provide a strictly bounded network that yields a\nstable bidirectional translation. We propose a patch-level concatenated cyclic\nconditional generative adversarial network (pCCGAN) embedded with adaptive\ndictionary learning. It consists of two cyclically connected CGANs of 47 layers\neach; where both generators (each of 32 layers) are conditioned with\nconcatenation of alternate unpaired patches from input and target modality\nimages (not ground truth) of the same organ. The key idea is to exploit\ncross-neighborhood contextual feature information that bounds the translation\nspace and boosts generalization. The generators are further equipped with\nadaptive dictionaries learned from the contextual patches to reduce possible\ndegradation. Discriminators are 15-layer deep networks that employ minimax\nfunction to validate the translated imagery. A combined loss function is\nformulated with adversarial, non-adversarial, forward-backward cyclic, and\nidentity losses that further minimize the variance of the proposed learning\nmachine. Qualitative, quantitative, and ablation analysis show superior results\non real CT and MRI.",
            "author": [
                "Swati Rai",
                "Jignesh S. Bhatt",
                "Sarat Kumar Patra"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SSP53291.2023.10207960",
                "http://arxiv.org/abs/2311.02480v1",
                "http://arxiv.org/pdf/2311.02480v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02476v2",
            "title": "Forecasting Success of Computer Science Professors and Students Based on\n  Their Academic and Personal Backgrounds",
            "updated": "2023-11-22T07:12:36Z",
            "published": "2023-11-04T18:30:24Z",
            "summary": "After completing their undergraduate studies, many computer science (CS)\nstudents apply for competitive graduate programs in North America. Their\nlong-term goal is often to be hired by one of the big five tech companies or to\nbecome a faculty member. Therefore, being aware of the role of admission\ncriteria may help them choose the best path towards their goals. In this paper,\nwe analyze the influence of students' previous universities on their chances of\nbeing accepted to prestigious North American universities and returning to\nacademia as professors in the future. Our findings demonstrate that the ranking\nof their prior universities is a significant factor in achieving their goals.\nWe then illustrate that there is a bias in the undergraduate institutions of\nstudents admitted to the top 25 computer science programs. Finally, we employ\nmachine learning models to forecast the success of professors at these\nuniversities. We achieved an RMSE of 7.85 for this prediction task.",
            "author": [
                "Ghazal Kalhor",
                "Behnam Bahrak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02476v2",
                "http://arxiv.org/pdf/2311.02476v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02471v1",
            "title": "Efficient Large-Scale Simulation of Fish Schooling Behavior Using\n  Voronoi Tessellations and Fuzzy Clustering",
            "updated": "2023-11-04T18:11:09Z",
            "published": "2023-11-04T18:11:09Z",
            "summary": "This paper introduces an efficient approach to reduce the computational cost\nof simulating collective behaviors, such as fish schooling, using\nIndividual-Based Models (IBMs). The proposed technique employs adaptive and\ndynamic load-balancing domain partitioning, which utilizes unsupervised\nmachine-learning models to cluster a large number of simulated individuals into\nsub-schools based on their spatial-temporal locations. It also utilizes Voronoi\ntessellations to construct non-overlapping simulation subdomains. This approach\nminimizes agent-to-agent communication and balances the load both spatially and\ntemporally, ultimately resulting in reduced computational complexity.\n  Experimental simulations demonstrate that this partitioning approach\noutperforms the standard regular grid-based domain decomposition, achieving a\nreduction in computational cost while maintaining spatial and temporal load\nbalance. The approach presented in this paper has the potential to be applied\nto other collective behavior simulations requiring large-scale simulations with\na substantial number of individuals.",
            "author": [
                "Salah Alrabeei",
                "Talal Rahman",
                "Sam Subbey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02471v1",
                "http://arxiv.org/pdf/2311.02471v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "68T05, 92D50, 65M50, 90B10",
                "I.3.7; I.6.5; I.6.8; I.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02461v1",
            "title": "SPHEAR: Spherical Head Registration for Complete Statistical 3D Modeling",
            "updated": "2023-11-04T17:38:20Z",
            "published": "2023-11-04T17:38:20Z",
            "summary": "We present \\emph{SPHEAR}, an accurate, differentiable parametric statistical\n3D human head model, enabled by a novel 3D registration method based on\nspherical embeddings. We shift the paradigm away from the classical Non-Rigid\nRegistration methods, which operate under various surface priors, increasing\nreconstruction fidelity and minimizing required human intervention.\nAdditionally, SPHEAR is a \\emph{complete} model that allows not only to sample\ndiverse synthetic head shapes and facial expressions, but also gaze directions,\nhigh-resolution color textures, surface normal maps, and hair cuts represented\nin detail, as strands. SPHEAR can be used for automatic realistic visual data\ngeneration, semantic annotation, and general reconstruction tasks. Compared to\nstate-of-the-art approaches, our components are fast and memory efficient, and\nexperiments support the validity of our design choices and the accuracy of\nregistration, reconstruction and generation techniques.",
            "author": [
                "Eduard Gabriel Bazavan",
                "Andrei Zanfir",
                "Thiemo Alldieck",
                "Teodor Alexandru Szente",
                "Mihai Zanfir",
                "Cristian Sminchisescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02461v1",
                "http://arxiv.org/pdf/2311.02461v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02460v1",
            "title": "Extracting Network Structures from Corporate Organization Charts Using\n  Heuristic Image Processing",
            "updated": "2023-11-04T17:32:50Z",
            "published": "2023-11-04T17:32:50Z",
            "summary": "Organizational structure of corporations has potential to provide\nimplications for dynamics and performance of corporate operations. However,\nthis subject has remained unexplored because of the lack of readily available\norganization network datasets. To overcome the this gap, we developed a new\nheuristic image-processing method to extract and reconstruct organization\nnetwork data from published organization charts. Our method analyzes a PDF file\nof a corporate organization chart and detects text labels, boxes, connecting\nlines, and other objects through multiple steps of heuristically implemented\nimage processing. The detected components are reorganized together into a\nPython's NetworkX Graph object for visualization, validation and further\nnetwork analysis. We applied the developed method to the organization charts of\nall the listed firms in Japan shown in the ``Organization Chart/System Diagram\nHandbook'' published by Diamond, Inc., from 2008 to 2011. Out of the 10,008\norganization chart PDF files, our method was able to reconstruct 4,606\norganization networks (data acquisition success rate: 46%). For each\nreconstructed organization network, we measured several network diagnostics,\nwhich will be used for further statistical analysis to investigate their\npotential correlations with corporate behavior and performance.",
            "author": [
                "Hiroki Sayama",
                "Junichi Yamanoi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02460v1",
                "http://arxiv.org/pdf/2311.02460v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02455v1",
            "title": "Attention-based Multi-instance Mixed Models",
            "updated": "2023-11-04T16:42:42Z",
            "published": "2023-11-04T16:42:42Z",
            "summary": "Predicting patient features from single-cell data can unveil cellular states\nimplicated in health and disease. Linear models and average cell type\nexpressions are typically favored for this task for their efficiency and\nrobustness, but they overlook the rich cell heterogeneity inherent in\nsingle-cell data. To address this gap, we introduce GMIL, a framework\nintegrating Generalized Linear Mixed Models (GLMM) and Multiple Instance\nLearning (MIL), upholding the advantages of linear models while modeling\ncell-state heterogeneity. By leveraging predefined cell embeddings, GMIL\nenhances computational efficiency and aligns with recent advancements in\nsingle-cell representation learning. Our empirical results reveal that GMIL\noutperforms existing MIL models in single-cell datasets, uncovering new\nassociations and elucidating biological mechanisms across different domains.",
            "author": [
                "Jan P. Engelmann",
                "Alessandro Palma",
                "Jakub M. Tomczak",
                "Fabian J Theis",
                "Francesco Paolo Casale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02455v1",
                "http://arxiv.org/pdf/2311.02455v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN",
                "q-bio.QM",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02443v1",
            "title": "PIPO-Net: A Penalty-based Independent Parameters Optimization Deep\n  Unfolding Network",
            "updated": "2023-11-04T15:57:54Z",
            "published": "2023-11-04T15:57:54Z",
            "summary": "Compressive sensing (CS) has been widely applied in signal and image\nprocessing fields. Traditional CS reconstruction algorithms have a complete\ntheoretical foundation but suffer from the high computational complexity, while\nfashionable deep network-based methods can achieve high-accuracy reconstruction\nof CS but are short of interpretability. These facts motivate us to develop a\ndeep unfolding network named the penalty-based independent parameters\noptimization network (PIPO-Net) to combine the merits of the above mentioned\ntwo kinds of CS methods. Each module of PIPO-Net can be viewed separately as an\noptimization problem with respective penalty function. The main characteristic\nof PIPO-Net is that, in each round of training, the learnable parameters in one\nmodule are updated independently from those of other modules. This makes the\nnetwork more flexible to find the optimal solutions of the corresponding\nproblems. Moreover, the mean-subtraction sampling and the high-frequency\ncomplementary blocks are developed to improve the performance of PIPO-Net.\nExperiments on reconstructing CS images demonstrate the effectiveness of the\nproposed PIPO-Net.",
            "author": [
                "Xiumei Li",
                "Zhijie Zhang",
                "Huang Bai",
                "Ljubi\u0161a Stankovi\u0107",
                "Junpeng Hao",
                "Junmei Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02443v1",
                "http://arxiv.org/pdf/2311.02443v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02442v1",
            "title": "Quantum transport on networks for supervised classification",
            "updated": "2023-11-04T15:57:43Z",
            "published": "2023-11-04T15:57:43Z",
            "summary": "Classification, the computational process of categorizing an input into\npre-existing classes, is now a cornerstone in modern computation in the era of\nmachine learning. Here we propose a new type of quantum classifier, based on\nquantum transport of particles in a trained quantum network. The classifier is\nbased on sending a quantum particle into a network and measuring the particle's\nexit point, which serves as a \"class\" and can be determined by changing the\nnetwork parameters. Using this scheme, we demonstrate three examples of\nclassification; in the first, wave functions are classified according to their\noverlap with predetermined (random) groups. In the second, we classify\nwave-functions according to their level of localization. Both examples use\nsmall training sets and achieve over 90\\% precision and recall. The third\nclassification scheme is a \"real-world problem\", concerning classification of\ncatalytic aromatic-aldehyde substrates according to their reactivity. Using\nexperimental data, the quantum classifier reaches an average 86\\%\nclassification accuracy. We show that the quantum classifier outperforms its\nclassical counterpart for these examples, thus demonstrating quantum advantage,\nespecially in the regime of \"small data\". These results pave the way for a\nnovel classification scheme, which can be implemented as an algorithm, and\npotentially realized experimentally on quantum hardware such as photonic\nnetworks.",
            "author": [
                "Shmuel Lorber",
                "Oded Zimron",
                "Inbal Lorena Zak",
                "Anat Milo",
                "Yonatan Dubi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02442v1",
                "http://arxiv.org/pdf/2311.02442v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02436v1",
            "title": "Optimal Power Flow Solutions via Noise-Resilient Quantum-Inspired\n  Interior-Point Methods",
            "updated": "2023-11-04T15:32:09Z",
            "published": "2023-11-04T15:32:09Z",
            "summary": "This paper presents three quantum interior-point methods (QIPMs) tailored to\ntackle the DC optimal power flow (DCOPF) problem using noisy intermediate-scale\nquantum devices. The optimization model is redefined as a linearly constrained\nquadratic optimization. By incorporating the Harrow-Hassidim-Lloyd (HHL)\nquantum algorithm into the IPM framework, Newton's direction is determined\nthrough the resolution of linear equation systems. To mitigate the impact of\nHHL error and quantum noise on Newton's direction calculation, we present a\nnoise-tolerant quantum IPM (NT-QIPM) approach. This approach provides\nhigh-quality OPF solutions even in scenarios where inexact solutions to the\nlinear equation systems result in approximated Newton's directions. Moreover,\nto enhance performance in cases of slow convergence and uphold the feasibility\nof OPF outcomes upon convergence, we propose a hybrid strategy, classically\naugmented NT-QIPM. This technique is designed to expedite convergence relative\nto classical IPM while maintaining the solution accuracy. The efficacy of the\nproposed quantum IPM variants is studied through comprehensive simulations and\nerror analyses on 3-bus, 5-bus, 118-bus, and 300-bus systems, highlighting\ntheir potential and promise in addressing challenging OPF scenarios. By\nmodeling the errors and incorporating quantum computer noise, we simulate the\nproposed algorithms on both Qiskit and classical computers to gain a deeper\nunderstanding of the effectiveness and feasibility of our methods under\nrealistic conditions.",
            "author": [
                "Farshad Amani",
                "Amin Kargarian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02436v1",
                "http://arxiv.org/pdf/2311.02436v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02433v1",
            "title": "Can ChatGPT support software verification?",
            "updated": "2023-11-04T15:25:18Z",
            "published": "2023-11-04T15:25:18Z",
            "summary": "Large language models have become increasingly effective in software\nengineering tasks such as code generation, debugging and repair. Language\nmodels like ChatGPT can not only generate code, but also explain its inner\nworkings and in particular its correctness. This raises the question whether we\ncan utilize ChatGPT to support formal software verification.\n  In this paper, we take some first steps towards answering this question. More\nspecifically, we investigate whether ChatGPT can generate loop invariants. Loop\ninvariant generation is a core task in software verification, and the\ngeneration of valid and useful invariants would likely help formal verifiers.\nTo provide some first evidence on this hypothesis, we ask ChatGPT to annotate\n106 C programs with loop invariants. We check validity and usefulness of the\ngenerated invariants by passing them to two verifiers, Frama-C and CPAchecker.\nOur evaluation shows that ChatGPT is able to produce valid and useful\ninvariants allowing Frama-C to verify tasks that it could not solve before.\nBased on our initial insights, we propose ways of combining ChatGPT (or large\nlanguage models in general) and software verifiers, and discuss current\nlimitations and open issues.",
            "author": [
                "Christian Jan\u00dfen",
                "Cedric Richter",
                "Heike Wehrheim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02433v1",
                "http://arxiv.org/pdf/2311.02433v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.FL",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02432v1",
            "title": "P-Age: Pexels Dataset for Robust Spatio-Temporal Apparent Age\n  Classification",
            "updated": "2023-11-04T15:23:21Z",
            "published": "2023-11-04T15:23:21Z",
            "summary": "Age estimation is a challenging task that has numerous applications. In this\npaper, we propose a new direction for age classification that utilizes a\nvideo-based model to address challenges such as occlusions, low-resolution, and\nlighting conditions. To address these challenges, we propose AgeFormer which\nutilizes spatio-temporal information on the dynamics of the entire body\ndominating face-based methods for age classification. Our novel two-stream\narchitecture uses TimeSformer and EfficientNet as backbones, to effectively\ncapture both facial and body dynamics information for efficient and accurate\nage estimation in videos. Furthermore, to fill the gap in predicting age in\nreal-world situations from videos, we construct a video dataset called Pexels\nAge (P-Age) for age classification. The proposed method achieves superior\nresults compared to existing face-based age estimation methods and is evaluated\nin situations where the face is highly occluded, blurred, or masked. The method\nis also cross-tested on a variety of challenging video datasets such as\nCharades, Smarthome, and Thumos-14.",
            "author": [
                "Abid Ali",
                "Ashish Marisetty",
                "Francois Bremond"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02432v1",
                "http://arxiv.org/pdf/2311.02432v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02430v1",
            "title": "Fr\u00f6berg's Theorem, vertex splittability and higher independence\n  complexes",
            "updated": "2023-11-04T15:17:23Z",
            "published": "2023-11-04T15:17:23Z",
            "summary": "A celebrated theorem of Fr\\\"oberg gives a complete combinatorial\nclassification of quadratic square-free monomial ideals with a linear\nresolution. A generalization of this theorem to higher degree square-free\nmonomial ideals is an active area of research. The existence of a linear\nresolution of such ideals often depends on the field over which the polynomial\nring is defined. Hence, it is too much to expect that in the higher degree case\na linear resolution can be identified purely using a combinatorial feature of\nan associated combinatorial structure. However, some classes of ideals having\nlinear resolutions have been identified using combinatorial structures. In the\npresent paper, we use the notion of $r$-independence to construct an\n$r$-uniform hypergraph from the given graph. We then show that when the\nunderlying graph is co-chordal, the corresponding edge ideal is vertex\nsplittable, a condition stronger than having a linear resolution. We use this\nresult to explicitly compute graded Betti numbers for various graph classes.\nFinally, we give a different proof for the existence of a linear resolution\nusing the topological notion of $r$-collapsibility.",
            "author": [
                "Priyavrat Deshpande",
                "Amit Roy",
                "Anurag Singh",
                "Adam Van Tuyl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02430v1",
                "http://arxiv.org/pdf/2311.02430v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.CO",
                "13F55, 05E45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02428v1",
            "title": "Task Arithmetic with LoRA for Continual Learning",
            "updated": "2023-11-04T15:12:24Z",
            "published": "2023-11-04T15:12:24Z",
            "summary": "Continual learning refers to the problem where the training data is available\nin sequential chunks, termed \"tasks\". The majority of progress in continual\nlearning has been stunted by the problem of catastrophic forgetting, which is\ncaused by sequential training of the model on streams of data. Moreover, it\nbecomes computationally expensive to sequentially train large models multiple\ntimes. To mitigate both of these problems at once, we propose a novel method to\ncontinually train transformer-based vision models using low-rank adaptation and\ntask arithmetic. Our method completely bypasses the problem of catastrophic\nforgetting, as well as reducing the computational requirement for training\nmodels on each task. When aided with a small memory of 10 samples per class,\nour method achieves performance close to full-set finetuning. We present\nrigorous ablations to support the prowess of our method.",
            "author": [
                "Rajas Chitale",
                "Ankit Vaidya",
                "Aditya Kane",
                "Archana Ghotkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02428v1",
                "http://arxiv.org/pdf/2311.02428v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02423v1",
            "title": "Payoff-based learning with matrix multiplicative weights in quantum\n  games",
            "updated": "2023-11-04T14:56:17Z",
            "published": "2023-11-04T14:56:17Z",
            "summary": "In this paper, we study the problem of learning in quantum games - and other\nclasses of semidefinite games - with scalar, payoff-based feedback. For\nconcreteness, we focus on the widely used matrix multiplicative weights (MMW)\nalgorithm and, instead of requiring players to have full knowledge of the game\n(and/or each other's chosen states), we introduce a suite of\nminimal-information matrix multiplicative weights (3MW) methods tailored to\ndifferent information frameworks. The main difficulty to attaining convergence\nin this setting is that, in contrast to classical finite games, quantum games\nhave an infinite continuum of pure states (the quantum equivalent of pure\nstrategies), so standard importance-weighting techniques for estimating payoff\nvectors cannot be employed. Instead, we borrow ideas from bandit convex\noptimization and we design a zeroth-order gradient sampler adapted to the\nsemidefinite geometry of the problem at hand. As a first result, we show that\nthe 3MW method with deterministic payoff feedback retains the\n$\\mathcal{O}(1/\\sqrt{T})$ convergence rate of the vanilla, full information MMW\nalgorithm in quantum min-max games, even though the players only observe a\nsingle scalar. Subsequently, we relax the algorithm's information requirements\neven further and we provide a 3MW method that only requires players to observe\na random realization of their payoff observable, and converges to equilibrium\nat an $\\mathcal{O}(T^{-1/4})$ rate. Finally, going beyond zero-sum games, we\nshow that a regularized variant of the proposed 3MW method guarantees local\nconvergence with high probability to all equilibria that satisfy a certain\nfirst-order stability condition.",
            "author": [
                "Kyriakos Lotidis",
                "Panayotis Mertikopoulos",
                "Nicholas Bambos",
                "Jose Blanchet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02423v1",
                "http://arxiv.org/pdf/2311.02423v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "math.OC",
                "quant-ph",
                "Primary 91A10, 91A26, 37N40, secondary 68Q32, 81Q93"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02421v1",
            "title": "Digital Twins for Human-Robot Collaboration: A Future Perspective",
            "updated": "2023-11-04T14:45:12Z",
            "published": "2023-11-04T14:45:12Z",
            "summary": "As collaborative robot (Cobot) adoption in many sectors grows, so does the\ninterest in integrating digital twins in human-robot collaboration (HRC).\nVirtual representations of physical systems (PT) and assets, known as digital\ntwins, can revolutionize human-robot collaboration by enabling real-time\nsimulation, monitoring, and control. In this article, we present a review of\nthe state-of-the-art and our perspective on the future of digital twins (DT) in\nhuman-robot collaboration. We argue that DT will be crucial in increasing the\nefficiency and effectiveness of these systems by presenting compelling evidence\nand a concise vision of the future of DT in human-robot collaboration, as well\nas insights into the possible advantages and challenges associated with their\nintegration.",
            "author": [
                "Mohamad Shaaban",
                "Alessandro Carf\u00ec",
                "Fulvio Mastrogiovanni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02421v1",
                "http://arxiv.org/pdf/2311.02421v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02415v1",
            "title": "Time-Division Based Integrated Sensing, Communication, and Computing in\n  Integrated Satellite-Terrestrial Networks",
            "updated": "2023-11-04T14:37:51Z",
            "published": "2023-11-04T14:37:51Z",
            "summary": "In this paper, we investigate time-division based framework for integrated\nsensing, communication, and computing in integrated satellite-terrestrial\nnetworks. We consider a scenario, where Internet-of-Things devices on the\nground operate with sensing and communication in a time-division manner, and\ncan process the sensing results locally, at the edge, or in the cloud via the\nsatellite communication link. Based on the proposed framework, we formulate a\nmulti-dimensional optimization problem to maximize the utility performance of\nsensing, communication, and computing abilities. After decomposing the original\noptimization problem into two subproblems, we first derive the closed-form\nsolution of the optimal task partitioning strategy for terrestrial users and\nsatellite users. Then, we develop the joint subframe allocation and task\npartitioning strategy to optimize the overall performance, by means of which\nthe Pareto optimal solutions can be obtained along the Pareto frontier.\nExtensive simulations are provided to demonstrated the effectiveness of the\nproposed strategy, which is 10% to 60% superior compared with the benchmarks.\nAlso, the trade-off between the multidimensional resource and multi-functional\nperformance is analyzed from the perspective of network design.",
            "author": [
                "Xiangming Zhu",
                "Hua Wang",
                "Zhaohui Yang",
                "Quoc-Viet Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02415v1",
                "http://arxiv.org/pdf/2311.02415v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02413v1",
            "title": "P2O-Calib: Camera-LiDAR Calibration Using Point-Pair Spatial Occlusion\n  Relationship",
            "updated": "2023-11-04T14:32:55Z",
            "published": "2023-11-04T14:32:55Z",
            "summary": "The accurate and robust calibration result of sensors is considered as an\nimportant building block to the follow-up research in the autonomous driving\nand robotics domain. The current works involving extrinsic calibration between\n3D LiDARs and monocular cameras mainly focus on target-based and target-less\nmethods. The target-based methods are often utilized offline because of\nrestrictions, such as additional target design and target placement limits. The\ncurrent target-less methods suffer from feature indeterminacy and feature\nmismatching in various environments. To alleviate these limitations, we propose\na novel target-less calibration approach which is based on the 2D-3D edge point\nextraction using the occlusion relationship in 3D space. Based on the extracted\n2D-3D point pairs, we further propose an occlusion-guided point-matching method\nthat improves the calibration accuracy and reduces computation costs. To\nvalidate the effectiveness of our approach, we evaluate the method performance\nqualitatively and quantitatively on real images from the KITTI dataset. The\nresults demonstrate that our method outperforms the existing target-less\nmethods and achieves low error and high robustness that can contribute to the\npractical applications relying on high-quality Camera-LiDAR calibration.",
            "author": [
                "Su Wang",
                "Shini Zhang",
                "Xuchong Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02413v1",
                "http://arxiv.org/pdf/2311.02413v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16140v1",
            "title": "Adapting Segment Anything Model (SAM) through Prompt-based Learning for\n  Enhanced Protein Identification in Cryo-EM Micrographs",
            "updated": "2023-11-04T14:20:08Z",
            "published": "2023-11-04T14:20:08Z",
            "summary": "Cryo-electron microscopy (cryo-EM) remains pivotal in structural biology, yet\nthe task of protein particle picking, integral for 3D protein structure\nconstruction, is laden with manual inefficiencies. While recent AI tools such\nas Topaz and crYOLO are advancing the field, they do not fully address the\nchallenges of cryo-EM images, including low contrast, complex shapes, and\nheterogeneous conformations. This study explored prompt-based learning to adapt\nthe state-of-the-art image segmentation foundation model Segment Anything Model\n(SAM) for cryo-EM. This focus was driven by the desire to optimize model\nperformance with a small number of labeled data without altering pre-trained\nparameters, aiming for a balance between adaptability and foundational\nknowledge retention. Through trials with three prompt-based learning\nstrategies, namely head prompt, prefix prompt, and encoder prompt, we observed\nenhanced performance and reduced computational requirements compared to the\nfine-tuning approach. This work not only highlights the potential of prompting\nSAM in protein identification from cryo-EM micrographs but also suggests its\nbroader promise in biomedical image segmentation and object detection.",
            "author": [
                "Fei He",
                "Zhiyuan Yang",
                "Mingyue Gao",
                "Biplab Poudel",
                "Newgin Sam Ebin Sam Dhas",
                "Rajan Gyawali",
                "Ashwin Dhakal",
                "Jianlin Cheng",
                "Dong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16140v1",
                "http://arxiv.org/pdf/2311.16140v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02408v3",
            "title": "Citance-Contextualized Summarization of Scientific Papers",
            "updated": "2023-11-13T08:40:04Z",
            "published": "2023-11-04T14:08:15Z",
            "summary": "Current approaches to automatic summarization of scientific papers generate\ninformative summaries in the form of abstracts. However, abstracts are not\nintended to show the relationship between a paper and the references cited in\nit. We propose a new contextualized summarization approach that can generate an\ninformative summary conditioned on a given sentence containing the citation of\na reference (a so-called \"citance\"). This summary outlines the content of the\ncited paper relevant to the citation location. Thus, our approach extracts and\nmodels the citances of a paper, retrieves relevant passages from cited papers,\nand generates abstractive summaries tailored to each citance. We evaluate our\napproach using $\\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing\n540K~computer science papers and 4.6M~citances therein.",
            "author": [
                "Shahbaz Syed",
                "Ahmad Dawar Hakimi",
                "Khalid Al-Khatib",
                "Martin Potthast"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02408v3",
                "http://arxiv.org/pdf/2311.02408v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02407v1",
            "title": "The equivalence of dynamic and strategic stability under regularized\n  learning in games",
            "updated": "2023-11-04T14:07:33Z",
            "published": "2023-11-04T14:07:33Z",
            "summary": "In this paper, we examine the long-run behavior of regularized, no-regret\nlearning in finite games. A well-known result in the field states that the\nempirical frequencies of no-regret play converge to the game's set of coarse\ncorrelated equilibria; however, our understanding of how the players' actual\nstrategies evolve over time is much more limited - and, in many cases,\nnon-existent. This issue is exacerbated further by a series of recent results\nshowing that only strict Nash equilibria are stable and attracting under\nregularized learning, thus making the relation between learning and pointwise\nsolution concepts particularly elusive. In lieu of this, we take a more general\napproach and instead seek to characterize the \\emph{setwise} rationality\nproperties of the players' day-to-day play. To that end, we focus on one of the\nmost stringent criteria of setwise strategic stability, namely that any\nunilateral deviation from the set in question incurs a cost to the deviator - a\nproperty known as closedness under better replies (club). In so doing, we\nobtain a far-reaching equivalence between strategic and dynamic stability: a\nproduct of pure strategies is closed under better replies if and only if its\nspan is stable and attracting under regularized learning. In addition, we\nestimate the rate of convergence to such sets, and we show that methods based\non entropic regularization (like the exponential weights algorithm) converge at\na geometric rate, while projection-based methods converge within a finite\nnumber of iterations, even with bandit, payoff-based feedback.",
            "author": [
                "Victor Boone",
                "Panayotis Mertikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02407v1",
                "http://arxiv.org/pdf/2311.02407v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "math.OC",
                "Primary 91A10, 91A26, secondary 68Q32, 62L20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02404v1",
            "title": "Towards Finding the Second Best Einstein Metric in Low Dimensions",
            "updated": "2023-11-04T13:48:34Z",
            "published": "2023-11-04T13:48:34Z",
            "summary": "In the following work we investigate the structure of Einstein manifolds with\npositive scalar curvature whose curvature operator is sufficiently close to the\nidentity operator in dimensions below 12. An Einstein manifold with positive\nscalar curvature, that is not locally isometric to the round sphere, is called\nthe second best Einstein manifold if its curvature operator minimizes the angle\nto the identity operator among all of these manifolds. In dimensions above 11\nthe search for the second best Einstein manifold turns out to be of purely\nalgebraic nature and is, by a conjecture of B\\\"ohm and Wilking, locally\nisometric to the product of spheres of a certain dimension. In lower dimensions\nthe angle of the curvature operator of the complex projective plane to the\nidentity operator is an obstruction for proving the same result with algebraic\nmethods. We show that, assuming a conjecture of B\\\"ohm and Wilking, there\nexists an angle slightly smaller than the angle of the product of spheres to\nthe identity operator such that any simply connected Einstein manifold with\npositive scalar curvature whose angle of the curvature operator to the identity\nis smaller than this angle is isometric to the round sphere. We will also be\nable to compute this angle explicitely.",
            "author": [
                "Kevin Poljsak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02404v1",
                "http://arxiv.org/pdf/2311.02404v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02402v1",
            "title": "Hybrid quantum image classification and federated learning for hepatic\n  steatosis diagnosis",
            "updated": "2023-11-04T13:28:06Z",
            "published": "2023-11-04T13:28:06Z",
            "summary": "With the maturity achieved by deep learning techniques, intelligent systems\nthat can assist physicians in the daily interpretation of clinical images can\nplay a very important role. In addition, quantum techniques applied to deep\nlearning can enhance this performance, and federated learning techniques can\nrealize privacy-friendly collaborative learning among different participants,\nsolving privacy issues due to the use of sensitive data and reducing the number\nof data to be collected for each individual participant. We present in this\nstudy a hybrid quantum neural network that can be used to quantify\nnon-alcoholic liver steatosis and could be useful in the diagnostic process to\ndetermine a liver's suitability for transplantation; at the same time, we\npropose a federated learning approach based on a classical deep learning\nsolution to solve the same problem, but using a reduced data set in each part.\nThe liver steatosis image classification accuracy of the hybrid quantum neural\nnetwork, the hybrid quantum ResNet model, consisted of 5 qubits and more than\n100 variational gates, reaches 97%, which is 1.8% higher than its classical\ncounterpart, ResNet. Crucially, that even with a reduced dataset, our hybrid\napproach consistently outperformed its classical counterpart, indicating\nsuperior generalization and less potential for overfitting in medical\napplications. In addition, a federated approach with multiple clients, up to\n32, despite the lower accuracy, but still higher than 90%, would allow using,\nfor each participant, a very small dataset, i.e., up to one-thirtieth. Our\nwork, based over real-word clinical data can be regarded as a scalable and\ncollaborative starting point, could thus fulfill the need for an effective and\nreliable computer-assisted system that facilitates the daily diagnostic work of\nthe clinical pathologist.",
            "author": [
                "Luca Lusnig",
                "Asel Sagingalieva",
                "Mikhail Surmach",
                "Tatjana Protasevich",
                "Ovidiu Michiu",
                "Joseph McLoughlin",
                "Christopher Mansell",
                "Graziano de' Petris",
                "Deborah Bonazza",
                "Fabrizio Zanconati",
                "Alexey Melnikov",
                "Fabio Cavalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02402v1",
                "http://arxiv.org/pdf/2311.02402v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02400v1",
            "title": "From Plate to Production: Artificial Intelligence in Modern\n  Consumer-Driven Food Systems",
            "updated": "2023-11-04T13:13:44Z",
            "published": "2023-11-04T13:13:44Z",
            "summary": "Global food systems confront the urgent challenge of supplying sustainable,\nnutritious diets in the face of escalating demands. The advent of Artificial\nIntelligence (AI) is bringing in a personal choice revolution, wherein\nAI-driven individual decisions transform food systems from dinner tables, to\nthe farms, and back to our plates. In this context, AI algorithms refine\npersonal dietary choices, subsequently shaping agricultural outputs, and\npromoting an optimized feedback loop from consumption to cultivation.\nInitially, we delve into AI tools and techniques spanning the food supply\nchain, and subsequently assess how AI subfields$\\unicode{x2013}$encompassing\nmachine learning, computer vision, and speech recognition$\\unicode{x2013}$are\nharnessed within the AI-enabled Food System (AIFS) framework, which\nincreasingly leverages Internet of Things, multimodal sensors and real-time\ndata exchange. We spotlight the AIFS framework, emphasizing its fusion of AI\nwith technologies such as digitalization, big data analytics, biotechnology,\nand IoT extensively used in modern food systems in every component. This\nparadigm shifts the conventional \"farm to fork\" narrative to a cyclical\n\"consumer-driven farm to fork\" model for better achieving sustainable,\nnutritious diets. This paper explores AI's promise and the intrinsic challenges\nit poses within the food domain. By championing stringent AI governance,\nuniform data architectures, and cross-disciplinary partnerships, we argue that\nAI, when synergized with consumer-centric strategies, holds the potential to\nsteer food systems toward a sustainable trajectory. We furnish a comprehensive\nsurvey for the state-of-the-art in diverse facets of food systems, subsequently\npinpointing gaps and advocating for the judicious and efficacious deployment of\nemergent AI methodologies.",
            "author": [
                "Weiqing Min",
                "Pengfei Zhou",
                "Leyi Xu",
                "Tao Liu",
                "Tianhao Li",
                "Mingyu Huang",
                "Ying Jin",
                "Yifan Yi",
                "Min Wen",
                "Shuqiang Jiang",
                "Ramesh Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02400v1",
                "http://arxiv.org/pdf/2311.02400v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02399v1",
            "title": "Entropy Aware Training for Fast and Accurate Distributed GNN",
            "updated": "2023-11-04T13:11:49Z",
            "published": "2023-11-04T13:11:49Z",
            "summary": "Several distributed frameworks have been developed to scale Graph Neural\nNetworks (GNNs) on billion-size graphs. On several benchmarks, we observe that\nthe graph partitions generated by these frameworks have heterogeneous data\ndistributions and class imbalance, affecting convergence, and resulting in\nlower performance than centralized implementations. We holistically address\nthese challenges and develop techniques that reduce training time and improve\naccuracy. We develop an Edge-Weighted partitioning technique to improve the\nmicro average F1 score (accuracy) by minimizing the total entropy. Furthermore,\nwe add an asynchronous personalization phase that adapts each compute-host's\nmodel to its local data distribution. We design a class-balanced sampler that\nconsiderably speeds up convergence. We implemented our algorithms on the\nDistDGL framework and observed that our training techniques scale much better\nthan the existing training approach. We achieved a (2-3x) speedup in training\ntime and 4\\% improvement on average in micro-F1 scores on 5 large graph\nbenchmarks compared to the standard baselines.",
            "author": [
                "Dhruv Deshmukh",
                "Gagan Raj Gupta",
                "Manisha Chawla",
                "Vishwesh Jatala",
                "Anirban Haldar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02399v1",
                "http://arxiv.org/pdf/2311.02399v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "I.5.1; I.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02396v1",
            "title": "Precise Robotic Needle-Threading with Tactile Perception and\n  Reinforcement Learning",
            "updated": "2023-11-04T12:45:08Z",
            "published": "2023-11-04T12:45:08Z",
            "summary": "This work presents a novel tactile perception-based method, named T-NT, for\nperforming the needle-threading task, an application of deformable linear\nobject (DLO) manipulation. This task is divided into two main stages: Tail-end\nFinding and Tail-end Insertion. In the first stage, the agent traces the\ncontour of the thread twice using vision-based tactile sensors mounted on the\ngripper fingers. The two-run tracing is to locate the tail-end of the thread.\n  In the second stage, it employs a tactile-guided reinforcement learning (RL)\nmodel to drive the robot to insert the thread into the target needle eyelet.\nThe RL model is trained in a Unity-based simulated environment. The simulation\nenvironment supports tactile rendering which can produce realistic tactile\nimages and thread modeling. During insertion, the position of the poke point\nand the center of the eyelet are obtained through a pre-trained segmentation\nmodel, Grounded-SAM, which predicts the masks for both the needle eye and\nthread imprints. These positions are then fed into the reinforcement learning\nmodel, aiding in a smoother transition to real-world applications. Extensive\nexperiments on real robots are conducted to demonstrate the efficacy of our\nmethod. More experiments and videos can be found in the supplementary materials\nand on the website: https://sites.google.com/view/tac-needlethreading.",
            "author": [
                "Zhenjun Yu",
                "Wenqiang Xu",
                "Siqiong Yao",
                "Jieji Ren",
                "Tutian Tang",
                "Yutong Li",
                "Guoying Gu",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02396v1",
                "http://arxiv.org/pdf/2311.02396v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02394v1",
            "title": "NeuroEvoBench: Benchmarking Evolutionary Optimizers for Deep Learning\n  Applications",
            "updated": "2023-11-04T12:42:38Z",
            "published": "2023-11-04T12:42:38Z",
            "summary": "Recently, the Deep Learning community has become interested in evolutionary\noptimization (EO) as a means to address hard optimization problems, e.g.\nmeta-learning through long inner loop unrolls or optimizing non-differentiable\noperators. One core reason for this trend has been the recent innovation in\nhardware acceleration and compatible software - making distributed population\nevaluations much easier than before. Unlike for gradient descent-based methods\nthough, there is a lack of hyperparameter understanding and best practices for\nEO - arguably due to severely less 'graduate student descent' and benchmarking\nbeing performed for EO methods. Additionally, classical benchmarks from the\nevolutionary community provide few practical insights for Deep Learning\napplications. This poses challenges for newcomers to hardware-accelerated EO\nand hinders significant adoption. Hence, we establish a new benchmark of EO\nmethods (NeuroEvoBench) tailored toward Deep Learning applications and\nexhaustively evaluate traditional and meta-learned EO. We investigate core\nscientific questions including resource allocation, fitness shaping,\nnormalization, regularization & scalability of EO. The benchmark is\nopen-sourced at https://github.com/neuroevobench/neuroevobench under Apache-2.0\nlicense.",
            "author": [
                "Robert Tjarko Lange",
                "Yujin Tang",
                "Yingtao Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02394v1",
                "http://arxiv.org/pdf/2311.02394v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02393v1",
            "title": "Continual Learning of Unsupervised Monocular Depth from Videos",
            "updated": "2023-11-04T12:36:07Z",
            "published": "2023-11-04T12:36:07Z",
            "summary": "Spatial scene understanding, including monocular depth estimation, is an\nimportant problem in various applications, such as robotics and autonomous\ndriving. While improvements in unsupervised monocular depth estimation have\npotentially allowed models to be trained on diverse crowdsourced videos, this\nremains underexplored as most methods utilize the standard training protocol,\nwherein the models are trained from scratch on all data after new data is\ncollected. Instead, continual training of models on sequentially collected data\nwould significantly reduce computational and memory costs. Nevertheless, naive\ncontinual training leads to catastrophic forgetting, where the model\nperformance deteriorates on older domains as it learns on newer domains,\nhighlighting the trade-off between model stability and plasticity. While\nseveral techniques have been proposed to address this issue in image\nclassification, the high-dimensional and spatiotemporally correlated outputs of\ndepth estimation make it a distinct challenge. To the best of our knowledge, no\nframework or method currently exists focusing on the problem of continual\nlearning in depth estimation. Thus, we introduce a framework that captures the\nchallenges of continual unsupervised depth estimation (CUDE), and define the\nnecessary metrics to evaluate model performance. We propose a rehearsal-based\ndual-memory method, MonoDepthCL, which utilizes spatiotemporal consistency for\ncontinual learning in depth estimation, even when the camera intrinsics are\nunknown.",
            "author": [
                "Hemang Chawla",
                "Arnav Varma",
                "Elahe Arani",
                "Bahram Zonooz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02393v1",
                "http://arxiv.org/pdf/2311.02393v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02392v1",
            "title": "Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot\n  Classification",
            "updated": "2023-11-04T12:28:04Z",
            "published": "2023-11-04T12:28:04Z",
            "summary": "The conventional few-shot classification aims at learning a model on a large\nlabeled base dataset and rapidly adapting to a target dataset that is from the\nsame distribution as the base dataset. However, in practice, the base and the\ntarget datasets of few-shot classification are usually from different domains,\nwhich is the problem of cross-domain few-shot classification. We tackle this\nproblem by making a small proportion of unlabeled images in the target domain\naccessible in the training stage. In this setup, even though the base data are\nsufficient and labeled, the large domain shift still makes transferring the\nknowledge from the base dataset difficult. We meticulously design a cross-level\nknowledge distillation method, which can strengthen the ability of the model to\nextract more discriminative features in the target dataset by guiding the\nnetwork's shallow layers to learn higher-level information. Furthermore, in\norder to alleviate the overfitting in the evaluation stage, we propose a\nfeature denoising operation which can reduce the feature redundancy and\nmitigate overfitting. Our approach can surpass the previous state-of-the-art\nmethod, Dynamic-Distillation, by 5.44% on 1-shot and 1.37% on 5-shot\nclassification tasks on average in the BSCD-FSL benchmark. The implementation\ncode will be available at https://github.com/jarucezh/cldfd.",
            "author": [
                "Hao Zheng",
                "Runqi Wang",
                "Jianzhuang Liu",
                "Asako Kanezaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02392v1",
                "http://arxiv.org/pdf/2311.02392v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02389v1",
            "title": "Multiplayer Homicidal Chauffeur Reach-Avoid Games: A Pursuit Enclosure\n  Function Approach",
            "updated": "2023-11-04T12:10:10Z",
            "published": "2023-11-04T12:10:10Z",
            "summary": "This paper presents a multiplayer Homicidal Chauffeur reach-avoid\ndifferential game, which involves Dubins-car pursuers and simple-motion\nevaders. The goal of the pursuers is to cooperatively protect a planar convex\nregion from the evaders, who strive to reach the region. We propose a\ncooperative strategy for the pursuers based on subgames for multiple pursuers\nagainst one evader and optimal task allocation. We introduce pursuit enclosure\nfunctions (PEFs) and propose a new enclosure region pursuit (ERP) winning\napproach that supports forward analysis for the strategy synthesis in the\nsubgames. We show that if a pursuit coalition is able to defend the region\nagainst an evader under the ERP winning, then no more than two pursuers in the\ncoalition are necessarily needed. We also propose a steer-to-ERP approach to\ncertify the ERP winning and synthesize the ERP winning strategy. To implement\nthe strategy, we introduce a positional PEF and provide the necessary\nparameters, states, and strategies that ensure the ERP winning for both one\npursuer and two pursuers against one evader. Additionally, we formulate a\nbinary integer program using the subgame outcomes to maximize the captured\nevaders in the ERP winning for the pursuit task allocation. Finally, we propose\na multiplayer receding-horizon strategy where the ERP winnings are checked in\neach horizon, the task is allocated, and the strategies of the pursuers are\ndetermined. Numerical examples are provided to illustrate the results.",
            "author": [
                "Rui Yan",
                "Xiaoming Duan",
                "Rui Zou",
                "Xin He",
                "Zongying Shi",
                "Francesco Bullo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02389v1",
                "http://arxiv.org/pdf/2311.02389v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.GT",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02388v1",
            "title": "A theoretical expansion of the Sprout game",
            "updated": "2023-11-04T12:09:36Z",
            "published": "2023-11-04T12:09:36Z",
            "summary": "Sprout is a two-player pen and paper game which starts with $n$ vertices, and\nthe players take turns to join two pre-existing dots by a subdivided edge while\nkeeping the graph sub-cubic planar at all times. The first player not being\nable to move loses. A major conjecture claims that Player 1 has a winning\nstrategy if and only if $n \\equiv 3,4,5$ ($\\bmod~6$). The conjecture is\nverified until $44$, and a few isolated values of $n$, usually with the help of\na computer. However, to the best of our understanding, not too much progress\ncould be made towards finding a theoretical proof of the conjecture till now.\n  In this article, we try to take a bottom-up approach and start building a\ntheory around the problem. We start by expanding a related game called Brussels\nSprout (where dots are replaced by crosses) introduced by Conway, possibly to\nhelp the understanding of Sprout. In particular, we introduce and study a\ngeneralized version of Brussels Sprout where crosses are replaced by a dot\nhaving an arbitrary number of ``partial edges'' (say, general cross) coming\nout, and planar graphs are replaced by any (pre-decided) hereditary class of\ngraphs. We study the game for forests, graphs on surfaces, and sparse planar\ngraphs. We also do a nimber characterization of the game when the hereditary\nclass is taken to be triangle-free planar graphs, and we have started the game\nwith two arbitrary generalized crosses. Moreover, while studying this\nparticular case, we naturally stumble upon a circular version of the same game\nand solve a difficult nimber characterization using the method of structural\ninduction. The above mentioned proof may potentially be one approach to solving\nthe Sprout conjecture.",
            "author": [
                "Soura Sena Das",
                "Zin Mar Myint",
                "Soumen Nandi",
                "Sagnik Sen",
                "\u00c9ric Sopena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02388v1",
                "http://arxiv.org/pdf/2311.02388v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02385v1",
            "title": "There is no perfect Mondrian partition for squares of side lengths less\n  than 1001",
            "updated": "2023-11-04T11:46:09Z",
            "published": "2023-11-04T11:46:09Z",
            "summary": "In mathematics, a dissection of a square (or rectangle) into non-congruent\nrectangles is a Mondrian partition. If all the rectangles have the same area,\nit is called a perfect Mondrian partition. In this paper, we present a\ncomputational result by which we can affirm that there is no perfect Mondrian\npartition of a length $n$ square for $n\\leq 1000$. Using the same algorithm we\nhave been able to establish that there is no perfect Mondrian partition of a $n\n\\times m$ rectangle for $n,m \\leq 400$.",
            "author": [
                "Natalia Garc\u00eda-Col\u00edn",
                "Dimitri Leemans",
                "Mia M\u00fc\u00dfig",
                "\u00c9rika Rold\u00e1n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02385v1",
                "http://arxiv.org/pdf/2311.02385v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "52C20, 52-08"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04231v1",
            "title": "A Practical Large-Scale Roadside Multi-View Multi-Sensor Spatial\n  Synchronization Framework for Intelligent Transportation Systems",
            "updated": "2023-11-04T11:43:31Z",
            "published": "2023-11-04T11:43:31Z",
            "summary": "Spatial synchronization in roadside scenarios is essential for integrating\ndata from multiple sensors at different locations. Current methods using\ncascading spatial transformation (CST) often lead to cumulative errors in\nlarge-scale deployments. Manual camera calibration is insufficient and requires\nextensive manual work, and existing methods are limited to controlled or\nsingle-view scenarios. To address these challenges, our research introduces a\nparallel spatial transformation (PST)-based framework for large-scale,\nmulti-view, multi-sensor scenarios. PST parallelizes sensor coordinate system\ntransformation, reducing cumulative errors. We incorporate deep learning for\nprecise roadside monocular global localization, reducing manual work.\nAdditionally, we use geolocation cues and an optimization algorithm for\nimproved synchronization accuracy. Our framework has been tested in real-world\nscenarios, outperforming CST-based methods. It significantly enhances\nlarge-scale roadside multi-perspective, multi-sensor spatial synchronization,\nreducing deployment costs.",
            "author": [
                "Yong Li",
                "Zhiguo Zhao",
                "Yunli Chen",
                "Rui Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04231v1",
                "http://arxiv.org/pdf/2311.04231v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02382v2",
            "title": "Ultra-Long Sequence Distributed Transformer",
            "updated": "2023-11-08T17:04:27Z",
            "published": "2023-11-04T11:38:53Z",
            "summary": "Transformer models trained on long sequences often achieve higher accuracy\nthan short sequences. Unfortunately, conventional transformers struggle with\nlong sequence training due to the overwhelming computation and memory\nrequirements. Existing methods for long sequence training offer limited speedup\nand memory reduction, and may compromise accuracy. This paper presents a novel\nand efficient distributed training method, the Long Short-Sequence Transformer\n(LSS Transformer), for training transformer with long sequences. It distributes\na long sequence into segments among GPUs, with each GPU computing a partial\nself-attention for its segment. Then, it uses a fused communication and a novel\ndouble gradient averaging technique to avoid the need to aggregate partial\nself-attention and minimize communication overhead. We evaluated the\nperformance between LSS Transformer and the state-of-the-art Nvidia sequence\nparallelism on a Wikipedia enwik8 dataset. Results show that our proposed\nmethod lead to 5.6x faster and 10.2x more memory-efficient implementation\ncompared to state-of-the-art sequence parallelism on 144 Nvidia V100 GPUs.\nMoreover, our algorithm scales to an extreme sequence length of 50,112 at 3,456\nGPUs, achieving 161% super-linear parallel efficiency and a throughput of 32\npetaflops.",
            "author": [
                "Xiao Wang",
                "Isaac Lyngaas",
                "Aristeidis Tsaris",
                "Peng Chen",
                "Sajal Dash",
                "Mayanka Chandra Shekar",
                "Tao Luo",
                "Hong-Jun Yoon",
                "Mohamed Wahib",
                "John Gouley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02382v2",
                "http://arxiv.org/pdf/2311.02382v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02380v1",
            "title": "On implicit interpolation models for nonlinear anisotropic magnetic\n  material behavior",
            "updated": "2023-11-04T11:25:31Z",
            "published": "2023-11-04T11:25:31Z",
            "summary": "Implicit models for magnetic coenergy have been proposed by Pera et al. to\ndescribe the anisotropic nonlinear material behavior of electrical steel\nsheets. This approach aims at predicting magnetic response for any direction of\nexcitation by interpolating measured of B--H curves in the rolling and\ntransverse directions. In an analogous manner, an implicit model for magnetic\nenergy is proposed. We highlight some mathematical properties of these implicit\nmodels and discuss their numerical realization, outline the computation of\nmagnetic material laws via implicit differentiation, and discuss the potential\nuse for finite element analysis in the context of nonlinear magnetostatics.",
            "author": [
                "Michael Mandlmayr",
                "Herbert Egger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02380v1",
                "http://arxiv.org/pdf/2311.02380v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06293v1",
            "title": "Quantum Neural Networks for Power Flow Analysis",
            "updated": "2023-11-04T11:25:31Z",
            "published": "2023-11-04T11:25:31Z",
            "summary": "This paper explores the potential application of quantum and hybrid\nquantum-classical neural networks in power flow analysis. Experiments are\nconducted using two small-size datasets based on the IEEE 4-bus and 33-bus test\nsystems. A systematic performance comparison is also conducted among quantum,\nhybrid quantum-classical, and classical neural networks. The comparison is\nbased on (i) generalization ability, (ii) robustness, (iii) training dataset\nsize needed, (iv) training error. (v) training computational time, and (vi)\ntraining process stability. The results show that the developed\nquantum-classical neural network outperforms both quantum and classical neural\nnetworks, and hence can improve deep learning-based power flow analysis in the\nnoisy-intermediate-scale quantum (NISQ) era.",
            "author": [
                "Zeynab Kaseb",
                "Matthias Moller",
                "Giorgio Tosti Balducci",
                "Peter Palensky",
                "Pedro P. Vergara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06293v1",
                "http://arxiv.org/pdf/2311.06293v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02378v1",
            "title": "MTS-DVGAN: Anomaly Detection in Cyber-Physical Systems using a Dual\n  Variational Generative Adversarial Network",
            "updated": "2023-11-04T11:19:03Z",
            "published": "2023-11-04T11:19:03Z",
            "summary": "Deep generative models are promising in detecting novel cyber-physical\nattacks, mitigating the vulnerability of Cyber-physical systems (CPSs) without\nrelying on labeled information. Nonetheless, these generative models face\nchallenges in identifying attack behaviors that closely resemble normal data,\nor deviate from the normal data distribution but are in close proximity to the\nmanifold of the normal cluster in latent space. To tackle this problem, this\narticle proposes a novel unsupervised dual variational generative adversarial\nmodel named MST-DVGAN, to perform anomaly detection in multivariate time series\ndata for CPS security. The central concept is to enhance the model's\ndiscriminative capability by widening the distinction between reconstructed\nabnormal samples and their normal counterparts. Specifically, we propose an\naugmented module by imposing contrastive constraints on the reconstruction\nprocess to obtain a more compact embedding. Then, by exploiting the\ndistribution property and modeling the normal patterns of multivariate time\nseries, a variational autoencoder is introduced to force the generative\nadversarial network (GAN) to generate diverse samples. Furthermore, two\naugmented loss functions are designed to extract essential characteristics in a\nself-supervised manner through mutual guidance between the augmented samples\nand original samples. Finally, a specific feature center loss is introduced for\nthe generator network to enhance its stability. Empirical experiments are\nconducted on three public datasets, namely SWAT, WADI and NSL_KDD. Comparing\nwith the state-of-the-art methods, the evaluation results show that the\nproposed MTS-DVGAN is more stable and can achieve consistent performance\nimprovement.",
            "author": [
                "Haili Sun",
                "Yan Huang",
                "Lansheng Han",
                "Cai Fu",
                "Hongle Liu",
                "Xiang Long"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.cose.2023.103570",
                "http://arxiv.org/abs/2311.02378v1",
                "http://arxiv.org/pdf/2311.02378v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02370v1",
            "title": "FIRE 6.5: Feynman Integral Reduction with New Simplification Library",
            "updated": "2023-11-04T10:49:10Z",
            "published": "2023-11-04T10:49:10Z",
            "summary": "FIRE is a program which performs integration-by-parts (IBP) reduction of\nFeynman integrals. Originally, the C++ version of FIRE relies on the computer\nalgebra system Fermat by Robert Lewis to simplify rational functions. We\npresent an upgrade of FIRE which incorporates a new library FUEL initially\ndescribed in a separate publication, which enables a flexible choice of\nthird-party computer algebra systems as simplifiers, as well as efficient\ncommunications with some of the simplifiers as C++ libraries rather than\nthrough Unix pipes. We achieve significant speedups for IBP reduction of\nFeynman integrals involving many kinematic variables, when using an open source\nbackend based on FLINT newly added in this work, or the Symbolica backend\ndeveloped by Ben Ruijl as a potential successor of FORM.",
            "author": [
                "Alexander V. Smirnov",
                "Mao Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02370v1",
                "http://arxiv.org/pdf/2311.02370v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03390v1",
            "title": "FPGA-QHAR: Throughput-Optimized for Quantized Human Action Recognition\n  on The Edge",
            "updated": "2023-11-04T10:38:21Z",
            "published": "2023-11-04T10:38:21Z",
            "summary": "Accelerating Human Action Recognition (HAR) efficiently for real-time\nsurveillance and robotic systems on edge chips remains a challenging research\nfield, given its high computational and memory requirements. This paper\nproposed an integrated end-to-end HAR scalable HW/SW accelerator co-design\nbased on an enhanced 8-bit quantized Two-Stream SimpleNet-PyTorch CNN\narchitecture. Our network accelerator was trained on UCF101 and UCF24 datasets\nand implemented on edge SoC-FPGA. Our development uses partially streaming\ndataflow architecture to achieve higher throughput versus network design and\nresource utilization trade-off. We also fused all convolutional, batch-norm,\nand ReLU operations into a single homogeneous layer and utilized the\nLucas-Kanade motion flow method to enable a high parallelism accelerator design\nand optimized on-chip engine computing.Furthermore, our proposed methodology\nachieved nearly 81% prediction accuracy with an approximately 24 FPS real-time\ninference throughput at 187MHz on ZCU104, which is 1.7x - 1.9x higher than the\nprior research. Lastly, the designed framework was benchmarked against several\nhardware chips for higher throughput and performance measurements and is now\navailable as an open-source project on GitHub for training and implementation\non edge platforms.",
            "author": [
                "Azzam Alhussain",
                "Mingjie Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03390v1",
                "http://arxiv.org/pdf/2311.03390v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02365v1",
            "title": "Evolution of reciprocity with limited payoff memory",
            "updated": "2023-11-04T10:26:06Z",
            "published": "2023-11-04T10:26:06Z",
            "summary": "Direct reciprocity is a mechanism for the evolution of cooperation in\nrepeated social interactions. According to this literature, individuals\nnaturally learn to adopt conditionally cooperative strategies if they have\nmultiple encounters with their partner. Corresponding models have greatly\nfacilitated our understanding of cooperation, yet they often make strong\nassumptions on how individuals remember and process payoff information. For\nexample, when strategies are updated through social learning, it is commonly\nassumed that individuals compare their average payoffs. This would require them\nto compute (or remember) their payoffs against everyone else in the population.\nTo understand how more realistic constraints influence direct reciprocity, we\nconsider the evolution of conditional behaviors when individuals learn based on\nmore recent experiences. Even in the most extreme case that they only take into\naccount their very last interaction, we find that cooperation can still evolve.\nHowever, such individuals adopt less generous strategies, and they tend to\ncooperate less often than in the classical setup with average payoffs.\nInterestingly, once individuals remember the payoffs of two or three recent\ninteractions, cooperation rates quickly approach the classical limit. These\nfindings contribute to a literature that explores which kind of cognitive\ncapabilities are required for reciprocal cooperation. While our results suggest\nthat some rudimentary form of payoff memory is necessary, it already suffices\nto remember a few interactions.",
            "author": [
                "Nikoleta E. Glynatsi",
                "Alex McAvoy",
                "Christian Hilbe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02365v1",
                "http://arxiv.org/pdf/2311.02365v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02358v3",
            "title": "Domain Transfer in Latent Space (DTLS) Wins on Image Super-Resolution --\n  a Non-Denoising Model",
            "updated": "2023-11-20T08:15:57Z",
            "published": "2023-11-04T09:57:50Z",
            "summary": "Large scale image super-resolution is a challenging computer vision task,\nsince vast information is missing in a highly degraded image, say for example\nforscale x16 super-resolution. Diffusion models are used successfully in recent\nyears in extreme super-resolution applications, in which Gaussian noise is used\nas a means to form a latent photo-realistic space, and acts as a link between\nthe space of latent vectors and the latent photo-realistic space. There are\nquite a few sophisticated mathematical derivations on mapping the statistics of\nGaussian noises making Diffusion Models successful. In this paper we propose a\nsimple approach which gets away from using Gaussian noise but adopts some basic\nstructures of diffusion models for efficient image super-resolution.\nEssentially, we propose a DNN to perform domain transfer between neighbor\ndomains, which can learn the differences in statistical properties to\nfacilitate gradual interpolation with results of reasonable quality. Further\nquality improvement is achieved by conditioning the domain transfer with\nreference to the input LR image. Experimental results show that our method\noutperforms not only state-of-the-art large scale super resolution models, but\nalso the current diffusion models for image super-resolution. The approach can\nreadily be extended to other image-to-image tasks, such as image enlightening,\ninpainting, denoising, etc.",
            "author": [
                "Chun-Chuen Hui",
                "Wan-Chi Siu",
                "Ngai-Fong Law"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02358v3",
                "http://arxiv.org/pdf/2311.02358v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02356v1",
            "title": "MATA*: Combining Learnable Node Matching with A* Algorithm for\n  Approximate Graph Edit Distance Computation",
            "updated": "2023-11-04T09:33:08Z",
            "published": "2023-11-04T09:33:08Z",
            "summary": "Graph Edit Distance (GED) is a general and domain-agnostic metric to measure\ngraph similarity, widely used in graph search or retrieving tasks. However, the\nexact GED computation is known to be NP-complete. For instance, the widely used\nA* algorithms explore the entire search space to find the optimal solution\nwhich inevitably suffers scalability issues. Learning-based methods apply graph\nrepresentation techniques to learn the GED by formulating a regression task,\nwhich can not recover the edit path and lead to inaccurate GED approximation\n(i.e., the predicted GED is smaller than the exact). To this end, in this work,\nwe present a data-driven hybrid approach MATA* for approximate GED computation\nbased on Graph Neural Networks (GNNs) and A* algorithms, which models from the\nperspective of learning to match nodes instead of directly regressing GED.\nSpecifically, aware of the structure-dominant operations (i.e.,node and edge\ninsertion/deletion) property in GED computation, a structure-enhanced GNN is\nfirstly designed to jointly learn local and high-order structural information\nfor node embeddings for node matchings. Second, top-k candidate nodes are\nproduced via a differentiable top-k operation to enable the training for node\nmatchings, which is adhering to another property of GED, i.e., multiple optimal\nnode matchings. Third, benefiting from the candidate nodes, MATA* only performs\non the promising search directions, reaching the solution efficiently. Finally,\nextensive experiments show the superiority of MATA* as it significantly\noutperforms the combinatorial search-based, learning-based and hybrid methods\nand scales well to large-size graphs.",
            "author": [
                "Junfeng Liu",
                "Min Zhou",
                "Shuai Ma",
                "Lujia Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02356v1",
                "http://arxiv.org/pdf/2311.02356v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02355v1",
            "title": "TreeSwap: Data Augmentation for Machine Translation via Dependency\n  Subtree Swapping",
            "updated": "2023-11-04T09:27:40Z",
            "published": "2023-11-04T09:27:40Z",
            "summary": "Data augmentation methods for neural machine translation are particularly\nuseful when limited amount of training data is available, which is often the\ncase when dealing with low-resource languages. We introduce a novel\naugmentation method, which generates new sentences by swapping objects and\nsubjects across bisentences. This is performed simultaneously based on the\ndependency parse trees of the source and target sentences. We name this method\nTreeSwap. Our results show that TreeSwap achieves consistent improvements over\nbaseline models in 4 language pairs in both directions on resource-constrained\ndatasets. We also explore domain-specific corpora, but find that our method\ndoes not make significant improvements on law, medical and IT data. We report\nthe scores of similar augmentation methods and find that TreeSwap performs\ncomparably. We also analyze the generated sentences qualitatively and find that\nthe augmentation produces a correct translation in most cases. Our code is\navailable on Github.",
            "author": [
                "Attila Nagy",
                "Dorina Lakatos",
                "Botond Barta",
                "Judit \u00c1cs"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02355v1",
                "http://arxiv.org/pdf/2311.02355v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02351v1",
            "title": "Software in P2P way: a software model without central software and\n  enabling any software to join or leave freely",
            "updated": "2023-11-04T08:37:52Z",
            "published": "2023-11-04T08:37:52Z",
            "summary": "The P2P model encompasses a network of equal peers, whether in hardware or\nsoftware, operating autonomously without central control, allowing individual\npeer failure while ensuring high availability. Nevertheless, current P2P\ntechnologies primarily focus on hardware-level resilience, often referred to as\nP2P networks, which do not safeguard against software failures. This paper\nintroduces a pioneering Peer-to-Peer (P2P) software model aimed at enhancing\nsoftware-level high availability. Diverging from prevalent hardware-centric P2P\ntechnologies, this model accentuates the decentralized nature of various\nsoftware components, or \"software peers,\" which function independently,\nenabling seamless network entry and exit without relying on central software.\nThe model's collaborative approach cultivates a network topology with multiple\nautonomous processing paths, ensuring continuous operation through dynamic task\nallocation in a distributed manner. By surpassing the limitations of\ntraditional redundancy methods, this P2P model provides an adaptive and\nscalable solution for achieving robust availability. Validation results\nunderscore the model's effectiveness in enhancing the probabilities of\nsuccessful task processing while ensuring high availability.",
            "author": [
                "Hong Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02351v1",
                "http://arxiv.org/pdf/2311.02351v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02349v1",
            "title": "Sample Complexity of Opinion Formation on Networks",
            "updated": "2023-11-04T08:28:33Z",
            "published": "2023-11-04T08:28:33Z",
            "summary": "Consider public health officials aiming to spread awareness about a new\nvaccine in a community interconnected by a social network. How can they\ndistribute information with minimal resources, ensuring community-wide\nunderstanding that aligns with the actual facts? This concern mirrors numerous\nreal-world situations. In this paper, we initialize the study of sample\ncomplexity in opinion formation to solve this problem. Our model is built on\nthe recognized opinion formation game, where we regard each agent's opinion as\na data-derived model parameter, not just a real number as in prior studies.\nSuch an extension offers a wider understanding of opinion formation and ties\nclosely with federated learning. Through this formulation, we characterize the\nsample complexity bounds for any network and also show asymptotically tight\nbounds for specific network structures. Intriguingly, we discover optimal\nstrategies often allocate samples inversely to the degree, hinting at vital\npolicy implications. Our findings are empirically validated on both synthesized\nand real-world networks.",
            "author": [
                "Haolin Liu",
                "Rajmohan Rajaraman",
                "Ravi Sundaram",
                "Anil Vullikanti",
                "Omer Wasim",
                "Haifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02349v1",
                "http://arxiv.org/pdf/2311.02349v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02345v1",
            "title": "Perturbation-based Active Learning for Question Answering",
            "updated": "2023-11-04T08:07:23Z",
            "published": "2023-11-04T08:07:23Z",
            "summary": "Building a question answering (QA) model with less annotation costs can be\nachieved by utilizing active learning (AL) training strategy. It selects the\nmost informative unlabeled training data to update the model effectively.\nAcquisition functions for AL are used to determine how informative each\ntraining example is, such as uncertainty or diversity based sampling. In this\nwork, we propose a perturbation-based active learning acquisition strategy and\ndemonstrate it is more effective than existing commonly used strategies.",
            "author": [
                "Fan Luo",
                "Mihai Surdeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02345v1",
                "http://arxiv.org/pdf/2311.02345v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02344v1",
            "title": "You Only Forward Once: Prediction and Rationalization in A Single\n  Forward Pass",
            "updated": "2023-11-04T08:04:28Z",
            "published": "2023-11-04T08:04:28Z",
            "summary": "Unsupervised rationale extraction aims to extract concise and contiguous text\nsnippets to support model predictions without any annotated rationale. Previous\nstudies have used a two-phase framework known as the Rationalizing Neural\nPrediction (RNP) framework, which follows a generate-then-predict paradigm.\nThey assumed that the extracted explanation, called rationale, should be\nsufficient to predict the golden label. However, the assumption above deviates\nfrom the original definition and is too strict to perform well. Furthermore,\nthese two-phase models suffer from the interlocking problem and spurious\ncorrelations. To solve the above problems, we propose a novel single-phase\nframework called You Only Forward Once (YOFO), derived from a relaxed version\nof rationale where rationales aim to support model predictions rather than make\npredictions. In our framework, A pre-trained language model like BERT is\ndeployed to simultaneously perform prediction and rationalization with less\nimpact from interlocking or spurious correlations. Directly choosing the\nimportant tokens in an unsupervised manner is intractable. Instead of directly\nchoosing the important tokens, YOFO gradually removes unimportant tokens during\nforward propagation. Through experiments on the BeerAdvocate and Hotel Review\ndatasets, we demonstrate that our model is able to extract rationales and make\npredictions more accurately compared to RNP-based models. We observe an\nimprovement of up to 18.4\\% in token-level F1 compared to previous\nstate-of-the-art methods. We also conducted analyses and experiments to explore\nthe extracted rationales and token decay strategies. The results show that YOFO\ncan extract precise and important rationales while removing unimportant tokens\nin the middle part of the model.",
            "author": [
                "Han Jiang",
                "Junwen Duan",
                "Zhe Qu",
                "Jianxin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02344v1",
                "http://arxiv.org/pdf/2311.02344v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02343v1",
            "title": "Stable Diffusion Reference Only: Image Prompt and Blueprint Jointly\n  Guided Multi-Condition Diffusion Model for Secondary Painting",
            "updated": "2023-11-04T07:53:59Z",
            "published": "2023-11-04T07:53:59Z",
            "summary": "Stable Diffusion and ControlNet have achieved excellent results in the field\nof image generation and synthesis. However, due to the granularity and method\nof its control, the efficiency improvement is limited for professional artistic\ncreations such as comics and animation production whose main work is secondary\npainting. In the current workflow, fixing characters and image styles often\nneed lengthy text prompts, and even requires further training through\nTextualInversion, DreamBooth or other methods, which is very complicated and\nexpensive for painters. Therefore, we present a new method in this paper,\nStable Diffusion Reference Only, a images-to-image self-supervised model that\nuses only two types of conditional images for precise control generation to\naccelerate secondary painting. The first type of conditional image serves as an\nimage prompt, supplying the necessary conceptual and color information for\ngeneration. The second type is blueprint image, which controls the visual\nstructure of the generated image. It is natively embedded into the original\nUNet, eliminating the need for ControlNet. We released all the code for the\nmodule and pipeline, and trained a controllable character line art coloring\nmodel at https://github.com/aihao2000/stable-diffusion-reference-only, that\nachieved state-of-the-art results in this field. This verifies the\neffectiveness of the structure and greatly improves the production efficiency\nof animations, comics, and fanworks.",
            "author": [
                "Hao Ai",
                "Lu Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02343v1",
                "http://arxiv.org/pdf/2311.02343v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02342v1",
            "title": "Proposal-Level Unsupervised Domain Adaptation for Open World Unbiased\n  Detector",
            "updated": "2023-11-04T07:46:45Z",
            "published": "2023-11-04T07:46:45Z",
            "summary": "Open World Object Detection (OWOD) combines open-set object detection with\nincremental learning capabilities to handle the challenge of the open and\ndynamic visual world. Existing works assume that a foreground predictor trained\non the seen categories can be directly transferred to identify the unseen\ncategories' locations by selecting the top-k most confident foreground\npredictions. However, the assumption is hardly valid in practice. This is\nbecause the predictor is inevitably biased to the known categories, and fails\nunder the shift in the appearance of the unseen categories. In this work, we\naim to build an unbiased foreground predictor by re-formulating the task under\nUnsupervised Domain Adaptation, where the current biased predictor helps form\nthe domains: the seen object locations and confident background locations as\nthe source domain, and the rest ambiguous ones as the target domain. Then, we\nadopt the simple and effective self-training method to learn a predictor based\non the domain-invariant foreground features, hence achieving unbiased\nprediction robust to the shift in appearance between the seen and unseen\ncategories. Our approach's pipeline can adapt to various detection frameworks\nand UDA methods, empirically validated by OWOD evaluation, where we achieve\nstate-of-the-art performance.",
            "author": [
                "Xuanyi Liu",
                "Zhongqi Yue",
                "Xian-Sheng Hua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02342v1",
                "http://arxiv.org/pdf/2311.02342v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02341v1",
            "title": "Enhancing English Writing Proficiency in China's Polytechnic Students An\n  In-Depth Literature Review on the Application of the Input Hypothesis",
            "updated": "2023-11-04T07:41:12Z",
            "published": "2023-11-04T07:41:12Z",
            "summary": "Having good English writing skills is extremely important for students in\npolytechnic institutions. However, a lot of students in technical schools have\ndifficulties in reaching high levels of skill. The Input Hypothesis, created by\nStephen Krashen, suggests that people learn languages well when they receive\ninformation that's a little harder than what they already know but still\nunderstandable. This research paper wants to study how the Input Hypothesis can\nhelp polytechnic students improve their English writing skills. The study will\ninclude real-life observations and experiments from the previous research. We\nwill look at data from polytechnic students who are receiving special writing\ninstruction to see if the Input Hypothesis actually helps improve their writing\nskills. The paper can better inform polytechnic students, faculty members, and\nsupport staff and even members of the larger community about the attributions,\nthe processes, and the possible outcomes of second language development for\npolytechnic students.\n  Keywords: English writing skills, Polytechnic students, Input hypothesis,\nComprehensible input",
            "author": [
                "Wei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02341v1",
                "http://arxiv.org/pdf/2311.02341v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02340v1",
            "title": "MC-Stereo: Multi-peak Lookup and Cascade Search Range for Stereo\n  Matching",
            "updated": "2023-11-04T07:26:27Z",
            "published": "2023-11-04T07:26:27Z",
            "summary": "Stereo matching is a fundamental task in scene comprehension. In recent\nyears, the method based on iterative optimization has shown promise in stereo\nmatching. However, the current iteration framework employs a single-peak\nlookup, which struggles to handle the multi-peak problem effectively.\nAdditionally, the fixed search range used during the iteration process limits\nthe final convergence effects. To address these issues, we present a novel\niterative optimization architecture called MC-Stereo. This architecture\nmitigates the multi-peak distribution problem in matching through the\nmulti-peak lookup strategy, and integrates the coarse-to-fine concept into the\niterative framework via the cascade search range. Furthermore, given that\nfeature representation learning is crucial for successful learnbased stereo\nmatching, we introduce a pre-trained network to serve as the feature extractor,\nenhancing the front end of the stereo matching pipeline. Based on these\nimprovements, MC-Stereo ranks first among all publicly available methods on the\nKITTI-2012 and KITTI-2015 benchmarks, and also achieves state-of-the-art\nperformance on ETH3D. The code will be open sourced after the publication of\nthis paper.",
            "author": [
                "Miaojie Feng",
                "Junda Cheng",
                "Hao Jia",
                "Longliang Liu",
                "Gangwei Xu",
                "Xin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02340v1",
                "http://arxiv.org/pdf/2311.02340v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02339v1",
            "title": "Progress Metrics in DAG-based Consensus",
            "updated": "2023-11-04T07:23:44Z",
            "published": "2023-11-04T07:23:44Z",
            "summary": "Lachesis protocol~\\cite{lachesis2021} leverages a DAG of events to allow\nnodes to reach fast consensus of events. This work introduces DAG progress\nmetrics to drive the nodes to emit new events more effectively. With these\nmetrics, nodes can select event timing and can choose previous events as\nparents for their own new events. Our results show that our event timing and\nparent selection methods can help reaching consensus quicker and thus can\nreduce lower time to finality significantly.",
            "author": [
                "Quan Nguyen",
                "James Henderson",
                "Egor Lysenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02339v1",
                "http://arxiv.org/pdf/2311.02339v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02338v1",
            "title": "Potato Leaf Disease Classification using Deep Learning: A Convolutional\n  Neural Network Approach",
            "updated": "2023-11-04T07:16:37Z",
            "published": "2023-11-04T07:16:37Z",
            "summary": "In this study, a Convolutional Neural Network (CNN) is used to classify\npotato leaf illnesses using Deep Learning. The suggested approach entails\npreprocessing the leaf image data, training a CNN model on that data, and\nassessing the model's success on a test set. The experimental findings show\nthat the CNN model, with an overall accuracy of 99.1%, is highly accurate in\nidentifying two kinds of potato leaf diseases, including Early Blight, Late\nBlight, and Healthy. The suggested method may offer a trustworthy and effective\nremedy for identifying potato diseases, which is essential for maintaining food\nsecurity and minimizing financial losses in agriculture. The model can\naccurately recognize the various disease types even when there are severe\ninfections present. This work highlights the potential of deep learning methods\nfor categorizing potato diseases, which can help with effective and automated\ndisease management in potato farming.",
            "author": [
                "Utkarsh Yashwant Tambe",
                "A. Shobanadevi",
                "A. Shanthini",
                "Hsiu-Chun Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02338v1",
                "http://arxiv.org/pdf/2311.02338v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02337v1",
            "title": "STOW: Discrete-Frame Segmentation and Tracking of Unseen Objects for\n  Warehouse Picking Robots",
            "updated": "2023-11-04T06:52:38Z",
            "published": "2023-11-04T06:52:38Z",
            "summary": "Segmentation and tracking of unseen object instances in discrete frames pose\na significant challenge in dynamic industrial robotic contexts, such as\ndistribution warehouses. Here, robots must handle object rearrangement,\nincluding shifting, removal, and partial occlusion by new items, and track\nthese items after substantial temporal gaps. The task is further complicated\nwhen robots encounter objects not learned in their training sets, which\nrequires the ability to segment and track previously unseen items. Considering\nthat continuous observation is often inaccessible in such settings, our task\ninvolves working with a discrete set of frames separated by indefinite periods\nduring which substantial changes to the scene may occur. This task also\ntranslates to domestic robotic applications, such as rearrangement of objects\non a table. To address these demanding challenges, we introduce new synthetic\nand real-world datasets that replicate these industrial and household\nscenarios. We also propose a novel paradigm for joint segmentation and tracking\nin discrete frames along with a transformer module that facilitates efficient\ninter-frame communication. The experiments we conduct show that our approach\nsignificantly outperforms recent methods. For additional results and videos,\nplease visit \\href{https://sites.google.com/view/stow-corl23}{website}. Code\nand dataset will be released.",
            "author": [
                "Yi Li",
                "Muru Zhang",
                "Markus Grotz",
                "Kaichun Mo",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02337v1",
                "http://arxiv.org/pdf/2311.02337v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02332v3",
            "title": "Multimodal Machine Learning in Image-Based and Clinical Biomedicine:\n  Survey and Prospects",
            "updated": "2023-11-20T20:55:29Z",
            "published": "2023-11-04T05:42:51Z",
            "summary": "Machine learning (ML) applications in medical artificial intelligence (AI)\nsystems have shifted from traditional and statistical methods to increasing\napplication of deep learning models. This survey navigates the current\nlandscape of multimodal ML, focusing on its profound impact on medical image\nanalysis and clinical decision support systems. Emphasizing challenges and\ninnovations in addressing multimodal representation, fusion, translation,\nalignment, and co-learning, the paper explores the transformative potential of\nmultimodal models for clinical predictions. It also questions practical\nimplementation of such models, bringing attention to the dynamics between\ndecision support systems and healthcare providers. Despite advancements,\nchallenges such as data biases and the scarcity of \"big data\" in many\nbiomedical domains persist. We conclude with a discussion on effective\ninnovation and collaborative efforts to further the miss",
            "author": [
                "Elisa Warner",
                "Joonsang Lee",
                "William Hsu",
                "Tanveer Syeda-Mahmood",
                "Charles Kahn",
                "Olivier Gevaert",
                "Arvind Rao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02332v3",
                "http://arxiv.org/pdf/2311.02332v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02331v1",
            "title": "NODLINK: An Online System for Fine-Grained APT Attack Detection and\n  Investigation",
            "updated": "2023-11-04T05:36:59Z",
            "published": "2023-11-04T05:36:59Z",
            "summary": "Advanced Persistent Threats (APT) attacks have plagued modern enterprises,\ncausing significant financial losses. To counter these attacks, researchers\npropose techniques that capture the complex and stealthy scenarios of APT\nattacks by using provenance graphs to model system entities and their\ndependencies. Particularly, to accelerate attack detection and reduce financial\nlosses, online provenance-based detection systems that detect and investigate\nAPT attacks under the constraints of timeliness and limited resources are in\ndire need. Unfortunately, existing online systems usually sacrifice detection\ngranularity to reduce computational complexity and produce provenance graphs\nwith more than 100,000 nodes, posing challenges for security admins to\ninterpret the detection results. In this paper, we design and implement\nNodLink, the first online detection system that maintains high detection\naccuracy without sacrificing detection granularity. Our insight is that the APT\nattack detection process in online provenance-based detection systems can be\nmodeled as a Steiner Tree Problem (STP), which has efficient online\napproximation algorithms that recover concise attack-related provenance graphs\nwith a theoretically bounded error. To utilize STP approximation algorithm\nframeworks for APT attack detection, we propose a novel design of in-memory\ncache, an efficient attack screening method, and a new STP approximation\nalgorithm that is more efficient than the conventional one in APT attack\ndetection while maintaining the same complexity. We evaluate NodLink in a\nproduction environment. The open-world experiment shows that NodLink\noutperforms two state-of-the-art (SOTA) online provenance analysis systems by\nachieving magnitudes higher detection and investigation accuracy while having\nthe same or higher throughput.",
            "author": [
                "Shaofei Li",
                "Feng Dong",
                "Xusheng Xiao",
                "Haoyu Wang",
                "Fei Shao",
                "Jiedong Chen",
                "Yao Guo",
                "Xiangqun Chen",
                "Ding Li"
            ],
            "link": [
                "http://dx.doi.org/10.14722/ndss.2024.23204",
                "http://arxiv.org/abs/2311.02331v1",
                "http://arxiv.org/pdf/2311.02331v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02329v2",
            "title": "Complex Organ Mask Guided Radiology Report Generation",
            "updated": "2023-11-10T04:24:35Z",
            "published": "2023-11-04T05:34:24Z",
            "summary": "The goal of automatic report generation is to generate a clinically accurate\nand coherent phrase from a single given X-ray image, which could alleviate the\nworkload of traditional radiology reporting. However, in a real-world scenario,\nradiologists frequently face the challenge of producing extensive reports\nderived from numerous medical images, thereby medical report generation from\nmulti-image perspective is needed. In this paper, we propose the Complex Organ\nMask Guided (termed as COMG) report generation model, which incorporates masks\nfrom multiple organs (e.g., bones, lungs, heart, and mediastinum), to provide\nmore detailed information and guide the model's attention to these crucial body\nregions. Specifically, we leverage prior knowledge of the disease corresponding\nto each organ in the fusion process to enhance the disease identification phase\nduring the report generation process. Additionally, cosine similarity loss is\nintroduced as target function to ensure the convergence of cross-modal\nconsistency and facilitate model optimization.Experimental results on two\npublic datasets show that COMG achieves a 11.4% and 9.7% improvement in terms\nof BLEU@4 scores over the SOTA model KiUT on IU-Xray and MIMIC, respectively.\nThe code is publicly available at https://github.com/GaryGuTC/COMG_model.",
            "author": [
                "Tiancheng Gu",
                "Dongnan Liu",
                "Zhiyuan Li",
                "Weidong Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02329v2",
                "http://arxiv.org/pdf/2311.02329v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02328v1",
            "title": "An Operator Learning Framework for Spatiotemporal Super-resolution of\n  Scientific Simulations",
            "updated": "2023-11-04T05:33:23Z",
            "published": "2023-11-04T05:33:23Z",
            "summary": "In numerous contexts, high-resolution solutions to partial differential\nequations are required to capture faithfully essential dynamics which occur at\nsmall spatiotemporal scales, but these solutions can be very difficult and slow\nto obtain using traditional methods due to limited computational resources. A\nrecent direction to circumvent these computational limitations is to use\nmachine learning techniques for super-resolution, to reconstruct\nhigh-resolution numerical solutions from low-resolution simulations which can\nbe obtained more efficiently. The proposed approach, the Super Resolution\nOperator Network (SROpNet), frames super-resolution as an operator learning\nproblem and draws inspiration from existing architectures to learn continuous\nrepresentations of solutions to parametric differential equations from\nlow-resolution approximations, which can then be evaluated at any desired\nlocation. In addition, no restrictions are imposed on the locations of (the\nfixed number of) spatiotemporal sensors at which the low-resolution\napproximations are provided, thereby enabling the consideration of a broader\nspectrum of problems arising in practice, for which many existing\nsuper-resolution approaches are not well-suited.",
            "author": [
                "Valentin Duruisseaux",
                "Amit Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02328v1",
                "http://arxiv.org/pdf/2311.02328v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02326v1",
            "title": "FragXsiteDTI: Revealing Responsible Segments in Drug-Target Interaction\n  with Transformer-Driven Interpretation",
            "updated": "2023-11-04T04:57:13Z",
            "published": "2023-11-04T04:57:13Z",
            "summary": "Drug-Target Interaction (DTI) prediction is vital for drug discovery, yet\nchallenges persist in achieving model interpretability and optimizing\nperformance. We propose a novel transformer-based model, FragXsiteDTI, that\naims to address these challenges in DTI prediction. Notably, FragXsiteDTI is\nthe first DTI model to simultaneously leverage drug molecule fragments and\nprotein pockets. Our information-rich representations for both proteins and\ndrugs offer a detailed perspective on their interaction. Inspired by the\nPerceiver IO framework, our model features a learnable latent array, initially\ninteracting with protein binding site embeddings using cross-attention and\nlater refined through self-attention and used as a query to the drug fragments\nin the drug's cross-attention transformer block. This learnable query array\nserves as a mediator and enables seamless information translation, preserving\ncritical nuances in drug-protein interactions. Our computational results on\nthree benchmarking datasets demonstrate the superior predictive power of our\nmodel over several state-of-the-art models. We also show the interpretability\nof our model in terms of the critical components of both target proteins and\ndrug molecules within drug-target pairs.",
            "author": [
                "Ali Khodabandeh Yalabadi",
                "Mehdi Yazdani-Jahromi",
                "Niloofar Yousefi",
                "Aida Tayebi",
                "Sina Abdidizaji",
                "Ozlem Ozmen Garibay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02326v1",
                "http://arxiv.org/pdf/2311.02326v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02324v1",
            "title": "Bounded and Unbiased Composite Differential Privacy",
            "updated": "2023-11-04T04:43:47Z",
            "published": "2023-11-04T04:43:47Z",
            "summary": "The objective of differential privacy (DP) is to protect privacy by producing\nan output distribution that is indistinguishable between any two neighboring\ndatabases. However, traditional differentially private mechanisms tend to\nproduce unbounded outputs in order to achieve maximum disturbance range, which\nis not always in line with real-world applications. Existing solutions attempt\nto address this issue by employing post-processing or truncation techniques to\nrestrict the output results, but at the cost of introducing bias issues. In\nthis paper, we propose a novel differentially private mechanism which uses a\ncomposite probability density function to generate bounded and unbiased outputs\nfor any numerical input data. The composition consists of an activation\nfunction and a base function, providing users with the flexibility to define\nthe functions according to the DP constraints. We also develop an optimization\nalgorithm that enables the iterative search for the optimal hyper-parameter\nsetting without the need for repeated experiments, which prevents additional\nprivacy overhead. Furthermore, we evaluate the utility of the proposed\nmechanism by assessing the variance of the composite probability density\nfunction and introducing two alternative metrics that are simpler to compute\nthan variance estimation. Our extensive evaluation on three benchmark datasets\ndemonstrates consistent and significant improvement over the traditional\nLaplace and Gaussian mechanisms. The proposed bounded and unbiased composite\ndifferentially private mechanism will underpin the broader DP arsenal and\nfoster future privacy-preserving studies.",
            "author": [
                "Kai Zhang",
                "Yanjun Zhang",
                "Ruoxi Sun",
                "Pei-Wei Tsai",
                "Muneeb Ul Hassan",
                "Xin Yuan",
                "Minhui Xue",
                "Jinjun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02324v1",
                "http://arxiv.org/pdf/2311.02324v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02321v1",
            "title": "Identifying Context-Dependent Translations for Evaluation Set Production",
            "updated": "2023-11-04T04:29:08Z",
            "published": "2023-11-04T04:29:08Z",
            "summary": "A major impediment to the transition to context-aware machine translation is\nthe absence of good evaluation metrics and test sets. Sentences that require\ncontext to be translated correctly are rare in test sets, reducing the utility\nof standard corpus-level metrics such as COMET or BLEU. On the other hand,\ndatasets that annotate such sentences are also rare, small in scale, and\navailable for only a few languages. To address this, we modernize, generalize,\nand extend previous annotation pipelines to produce CTXPRO, a tool that\nidentifies subsets of parallel documents containing sentences that require\ncontext to correctly translate five phenomena: gender, formality, and animacy\nfor pronouns, verb phrase ellipsis, and ambiguous noun inflections. The input\nto the pipeline is a set of hand-crafted, per-language, linguistically-informed\nrules that select contextual sentence pairs using coreference, part-of-speech,\nand morphological features provided by state-of-the-art tools. We apply this\npipeline to seven languages pairs (EN into and out-of DE, ES, FR, IT, PL, PT,\nand RU) and two datasets (OpenSubtitles and WMT test sets), and validate its\nperformance using both overlap with previous work and its ability to\ndiscriminate a contextual MT system from a sentence-based one. We release the\nCTXPRO pipeline and data as open source.",
            "author": [
                "Rachel Wicks",
                "Matt Post"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02321v1",
                "http://arxiv.org/pdf/2311.02321v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02318v1",
            "title": "The connecting homomorphism for Hermitian $K$-theory",
            "updated": "2023-11-04T04:01:11Z",
            "published": "2023-11-04T04:01:11Z",
            "summary": "We provide a geometric interpretation for the connecting homomorphism in the\nlocalization sequence of Hermitian $K$-theory. As an application, we compute\nthe Hermitian $K$-theory of projective bundles and Grassmannians in the regular\ncase. To achieve this, we develop pushforwards and pullbacks in Hermitian\n$K$-theory using Grothendieck's residue complexes, and we establish fundamental\ntheorems for those pushforwards and pullbacks, including base change,\nprojection, and excess intersection formulas.",
            "author": [
                "Tao Huang",
                "Heng Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02318v1",
                "http://arxiv.org/pdf/2311.02318v1"
            ],
            "primary_category": "math.KT",
            "category": [
                "math.KT",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02316v1",
            "title": "Self-Supervised Learning of Representations for Space Generates\n  Multi-Modular Grid Cells",
            "updated": "2023-11-04T03:59:37Z",
            "published": "2023-11-04T03:59:37Z",
            "summary": "To solve the spatial problems of mapping, localization and navigation, the\nmammalian lineage has developed striking spatial representations. One important\nspatial representation is the Nobel-prize winning grid cells: neurons that\nrepresent self-location, a local and aperiodic quantity, with seemingly bizarre\nnon-local and spatially periodic activity patterns of a few discrete periods.\nWhy has the mammalian lineage learnt this peculiar grid representation?\nMathematical analysis suggests that this multi-periodic representation has\nexcellent properties as an algebraic code with high capacity and intrinsic\nerror-correction, but to date, there is no satisfactory synthesis of core\nprinciples that lead to multi-modular grid cells in deep recurrent neural\nnetworks. In this work, we begin by identifying key insights from four families\nof approaches to answering the grid cell question: coding theory, dynamical\nsystems, function optimization and supervised deep learning. We then leverage\nour insights to propose a new approach that combines the strengths of all four\napproaches. Our approach is a self-supervised learning (SSL) framework -\nincluding data, data augmentations, loss functions and a network architecture -\nmotivated from a normative perspective, without access to supervised position\ninformation or engineering of particular readout representations as needed in\nprevious approaches. We show that multiple grid cell modules can emerge in\nnetworks trained on our SSL framework and that the networks and emergent\nrepresentations generalize well outside their training distribution. This work\ncontains insights for neuroscientists interested in the origins of grid cells\nas well as machine learning researchers interested in novel SSL frameworks.",
            "author": [
                "Rylan Schaeffer",
                "Mikail Khona",
                "Tzuhsuan Ma",
                "Crist\u00f3bal Eyzaguirre",
                "Sanmi Koyejo",
                "Ila Rani Fiete"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02316v1",
                "http://arxiv.org/pdf/2311.02316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02315v1",
            "title": "Counting Manatee Aggregations using Deep Neural Networks and Anisotropic\n  Gaussian Kernel",
            "updated": "2023-11-04T03:58:24Z",
            "published": "2023-11-04T03:58:24Z",
            "summary": "Manatees are aquatic mammals with voracious appetites. They rely on sea grass\nas the main food source, and often spend up to eight hours a day grazing. They\nmove slow and frequently stay in group (i.e. aggregations) in shallow water to\nsearch for food, making them vulnerable to environment change and other risks.\nAccurate counting manatee aggregations within a region is not only biologically\nmeaningful in observing their habit, but also crucial for designing safety\nrules for human boaters, divers, etc., as well as scheduling nursing,\nintervention, and other plans. In this paper, we propose a deep learning based\ncrowd counting approach to automatically count number of manatees within a\nregion, by using low quality images as input. Because manatees have unique\nshape and they often stay in shallow water in groups, water surface reflection,\nocclusion, camouflage etc. making it difficult to accurately count manatee\nnumbers. To address the challenges, we propose to use Anisotropic Gaussian\nKernel (AGK), with tunable rotation and variances, to ensure that density\nfunctions can maximally capture shapes of individual manatees in different\naggregations. After that, we apply AGK kernel to different types of deep neural\nnetworks primarily designed for crowd counting, including VGG, SANet, Congested\nScene Recognition network (CSRNet), MARUNet etc. to learn manatee densities and\ncalculate number of manatees in the scene. By using generic low quality images\nextracted from surveillance videos, our experiment results and comparison show\nthat AGK kernel based manatee counting achieves minimum Mean Absolute Error\n(MAE) and Root Mean Square Error (RMSE). The proposed method works particularly\nwell for counting manatee aggregations in environments with complex background.",
            "author": [
                "Zhiqiang Wang",
                "Yiran Pang",
                "Cihan Ulus",
                "Xingquan Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-45507-3",
                "http://arxiv.org/abs/2311.02315v1",
                "http://arxiv.org/pdf/2311.02315v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02314v1",
            "title": "Thermal Face Image Classification using Deep Learning Techniques",
            "updated": "2023-11-04T03:56:40Z",
            "published": "2023-11-04T03:56:40Z",
            "summary": "Thermal images have various applications in security, medical and industrial\ndomains. This paper proposes a practical deep-learning approach for thermal\nimage classification. Accurate and efficient classification of thermal images\nposes a significant challenge across various fields due to the complex image\ncontent and the scarcity of annotated datasets. This work uses a convolutional\nneural network (CNN) architecture, specifically ResNet-50 and VGGNet-19, to\nextract features from thermal images. This work also applied Kalman filter on\nthermal input images for image denoising. The experimental results demonstrate\nthe effectiveness of the proposed approach in terms of accuracy and efficiency.",
            "author": [
                "Prosenjit Chatterjee",
                "ANK Zaman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02314v1",
                "http://arxiv.org/pdf/2311.02314v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02313v1",
            "title": "LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields\n  for Large-Scale 3D Scenes",
            "updated": "2023-11-04T03:55:38Z",
            "published": "2023-11-04T03:55:38Z",
            "summary": "Large-scale semantic mapping is crucial for outdoor autonomous agents to\nfulfill high-level tasks such as planning and navigation. This paper proposes a\nnovel method for large-scale 3D semantic reconstruction through implicit\nrepresentations from LiDAR measurements alone. We firstly leverages an\noctree-based and hierarchical structure to store implicit features, then these\nimplicit features are decoded to semantic information and signed distance value\nthrough shallow Multilayer Perceptrons (MLPs). We adopt off-the-shelf\nalgorithms to predict the semantic labels and instance IDs of point cloud. Then\nwe jointly optimize the implicit features and MLPs parameters with\nself-supervision paradigm for point cloud geometry and pseudo-supervision\npradigm for semantic and panoptic labels. Subsequently, Marching Cubes\nalgorithm is exploited to subdivide and visualize the scenes in the inferring\nstage. For scenarios with memory constraints, a map stitching strategy is also\ndeveloped to merge sub-maps into a complete map. As far as we know, our method\nis the first work to reconstruct semantic implicit scenes from LiDAR-only\ninput. Experiments on three real-world datasets, SemanticKITTI, SemanticPOSS\nand nuScenes, demonstrate the effectiveness and efficiency of our framework\ncompared to current state-of-the-art 3D mapping methods.",
            "author": [
                "Jianyuan Zhang",
                "Zhiliu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02313v1",
                "http://arxiv.org/pdf/2311.02313v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02310v1",
            "title": "Narrowing the Gap between Zero- and Few-shot Machine Translation by\n  Matching Styles",
            "updated": "2023-11-04T03:18:45Z",
            "published": "2023-11-04T03:18:45Z",
            "summary": "Large language models trained primarily in a monolingual setting have\ndemonstrated their ability to generalize to machine translation using zero- and\nfew-shot examples with in-context learning. However, even though zero-shot\ntranslations are relatively good, there remains a discernible gap comparing\ntheir performance with the few-shot setting. In this paper, we investigate the\nfactors contributing to this gap and find that this gap can largely be closed\n(for about 70%) by matching the writing styles of the target corpus.\nAdditionally, we explore potential approaches to enhance zero-shot baselines\nwithout the need for parallel demonstration examples, providing valuable\ninsights into how these methods contribute to improving translation metrics.",
            "author": [
                "Weiting Tan",
                "Haoran Xu",
                "Lingfeng Shen",
                "Shuyue Stella Li",
                "Kenton Murray",
                "Philipp Koehn",
                "Benjamin Van Durme",
                "Yunmo Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02310v1",
                "http://arxiv.org/pdf/2311.02310v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02308v1",
            "title": "Kernel-based sensitivity indices for any model behavior and screening",
            "updated": "2023-11-04T02:58:47Z",
            "published": "2023-11-04T02:58:47Z",
            "summary": "Complex models are often used to understand interactions and drivers of\nhuman-induced and/or natural phenomena. It is worth identifying the input\nvariables that drive the model output(s) in a given domain and/or govern\nspecific model behaviors such as contextual indicators based on\nsocio-environmental models. Using the theory of multivariate weighted\ndistributions to characterize specific model behaviors, we propose new measures\nof association between inputs and such behaviors. Our measures rely on\nsensitivity functionals (SFs) and kernel methods, including variance-based\nsensitivity analysis. The proposed $\\ell_1$-based kernel indices account for\ninteractions among inputs, higher-order moments of SFs, and their upper bounds\nare somehow equivalent to the Morris-type screening measures, including\ndependent elementary effects. Empirical kernel-based indices are derived,\nincluding their statistical properties for the computational issues, and\nnumerical results are provided.",
            "author": [
                "Matieyendou Lamboni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02308v1",
                "http://arxiv.org/pdf/2311.02308v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.PR",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02306v1",
            "title": "Heteroskedastic Tensor Clustering",
            "updated": "2023-11-04T02:50:40Z",
            "published": "2023-11-04T02:50:40Z",
            "summary": "Tensor clustering, which seeks to extract underlying cluster structures from\nnoisy tensor observations, has gained increasing attention. One extensively\nstudied model for tensor clustering is the tensor block model, which postulates\nthe existence of clustering structures along each mode and has found broad\napplications in areas like multi-tissue gene expression analysis and multilayer\nnetwork analysis. However, currently available computationally feasible methods\nfor tensor clustering either are limited to handling i.i.d. sub-Gaussian noise\nor suffer from suboptimal statistical performance, which restrains their\nutility in applications that have to deal with heteroskedastic data and/or low\nsignal-to-noise-ratio (SNR).\n  To overcome these challenges, we propose a two-stage method, named\n$\\mathsf{High\\text{-}order~HeteroClustering}$ ($\\mathsf{HHC}$), which starts by\nperforming tensor subspace estimation via a novel spectral algorithm called\n$\\mathsf{Thresholded~Deflated\\text{-}HeteroPCA}$, followed by approximate\n$k$-means to obtain cluster nodes. Encouragingly, our algorithm provably\nachieves exact clustering as long as the SNR exceeds the computational limit\n(ignoring logarithmic factors); here, the SNR refers to the ratio of the\npairwise disparity between nodes to the noise level, and the computational\nlimit indicates the lowest SNR that enables exact clustering with polynomial\nruntime. Comprehensive simulation and real-data experiments suggest that our\nalgorithm outperforms existing algorithms across various settings, delivering\nmore reliable clustering performance.",
            "author": [
                "Yuchen Zhou",
                "Yuxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02306v1",
                "http://arxiv.org/pdf/2311.02306v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02305v1",
            "title": "OSM vs HD Maps: Map Representations for Trajectory Prediction",
            "updated": "2023-11-04T02:43:32Z",
            "published": "2023-11-04T02:43:32Z",
            "summary": "While High Definition (HD) Maps have long been favored for their precise\ndepictions of static road elements, their accessibility constraints and\nsusceptibility to rapid environmental changes impede the widespread deployment\nof autonomous driving, especially in the motion forecasting task. In this\ncontext, we propose to leverage OpenStreetMap (OSM) as a promising alternative\nto HD Maps for long-term motion forecasting. The contributions of this work are\nthreefold: firstly, we extend the application of OSM to long-horizon\nforecasting, doubling the forecasting horizon compared to previous studies.\nSecondly, through an expanded receptive field and the integration of\nintersection priors, our OSM-based approach exhibits competitive performance,\nnarrowing the gap with HD Map-based models. Lastly, we conduct an exhaustive\ncontext-aware analysis, providing deeper insights in motion forecasting across\ndiverse scenarios as well as conducting class-aware comparisons. This research\nnot only advances long-term motion forecasting with coarse map representations\nbut additionally offers a potential scalable solution within the domain of\nautonomous driving.",
            "author": [
                "Jing-Yan Liao",
                "Parth Doshi",
                "Zihan Zhang",
                "David Paz",
                "Henrik Christensen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02305v1",
                "http://arxiv.org/pdf/2311.02305v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02294v1",
            "title": "LLMs grasp morality in concept",
            "updated": "2023-11-04T01:37:41Z",
            "published": "2023-11-04T01:37:41Z",
            "summary": "Work in AI ethics and fairness has made much progress in regulating LLMs to\nreflect certain values, such as fairness, truth, and diversity. However, it has\ntaken the problem of how LLMs might 'mean' anything at all for granted. Without\naddressing this, it is not clear what imbuing LLMs with such values even means.\nIn response, we provide a general theory of meaning that extends beyond humans.\nWe use this theory to explicate the precise nature of LLMs as meaning-agents.\nWe suggest that the LLM, by virtue of its position as a meaning-agent, already\ngrasps the constructions of human society (e.g. morality, gender, and race) in\nconcept. Consequently, under certain ethical frameworks, currently popular\nmethods for model alignment are limited at best and counterproductive at worst.\nMoreover, unaligned models may help us better develop our moral and social\nphilosophy.",
            "author": [
                "Mark Pock",
                "Andre Ye",
                "Jared Moore"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02294v1",
                "http://arxiv.org/pdf/2311.02294v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02293v1",
            "title": "SMIwiz: An integrated toolbox for multidimensional seismic modelling and\n  imaging",
            "updated": "2023-11-04T01:25:07Z",
            "published": "2023-11-04T01:25:07Z",
            "summary": "This paper contributes an open source software - SMIwiz, which integrates\nseismic modelling, reverse time migration (RTM), and full waveform inversion\n(FWI) into a unified computer implementation. SMIwiz has the machinery to do\nboth 2D and 3D simulation in a consistent manner. The package features a number\nof computational recipes for efficient calculation of imaging condition and\ninversion gradient: a dynmaic evolving computing box to limit the simulation\ncube and a well-designed wavefield reconstruction strategy to reduce the memory\nconsumption when dealing with 3D problems. The modelling in SMIwiz runs\nindependently: each shot corresponds to one processor in a bijective manner to\nmaximize the scalability. A batchwise job scheduling strategy is designed to\nhandle large 3D imaging tasks on computer with limited number of cores. The\nviability of SMIwiz is demonstrated by a number of applications on benchmark\nmodels.",
            "author": [
                "Pengliang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02293v1",
                "http://arxiv.org/pdf/2311.02293v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02289v1",
            "title": "Fidelity and variability in the interlayer electronic structure of the\n  kagome superconductor CsV3Sb5",
            "updated": "2023-11-04T01:11:24Z",
            "published": "2023-11-04T01:11:24Z",
            "summary": "The AV3Sb5 (A = K, Rb, Cs) kagome materials host an interplay of emergent\nphenomena including superconductivity, charge density wave states, and\nnon-trivial electronic structure topology. The band structures of these\nmaterials exhibit a rich variety of features like Dirac crossings, saddle\npoints associated with van Hove singularities, and flat bands prompting\nsignificant investigations into the in-plane electronic behavior. However,\nrecent findings including the charge density wave ordering and effects due to\npressure or chemical doping point to the importance of understanding\ninteractions between kagome layers. Probing this c-axis electronic structure\nvia experimental methods remains challenging due to limitations of the crystals\nand, therefore, rigorous computational approaches are necessary to study the\ninterlayer interactions. Here we use first-principles approaches to study the\nelectronic structure of CsV3Sb5 with emphasis on the kz dispersion. We find\nthat the inclusion of nonlocal and dynamical many-body correlation has a\nsubstantial impact on the interlayer band structure. We present new band\nbehavior that additionally supports the integration of symmetry in accurately\nplotting electronic structures and influences further analysis like the\ncalculation of topological invariants.",
            "author": [
                "Aurland K. Watkins",
                "Dirk Johrendt",
                "Vojtech Vlcek",
                "Stephen D. Wilson",
                "Ram Seshadri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02289v1",
                "http://arxiv.org/pdf/2311.02289v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02283v1",
            "title": "Objectives Are All You Need: Solving Deceptive Problems Without Explicit\n  Diversity Maintenance",
            "updated": "2023-11-04T00:09:48Z",
            "published": "2023-11-04T00:09:48Z",
            "summary": "Navigating deceptive domains has often been a challenge in machine learning\ndue to search algorithms getting stuck at sub-optimal local optima. Many\nalgorithms have been proposed to navigate these domains by explicitly\nmaintaining diversity or equivalently promoting exploration, such as Novelty\nSearch or other so-called Quality Diversity algorithms. In this paper, we\npresent an approach with promise to solve deceptive domains without explicit\ndiversity maintenance by optimizing a potentially large set of defined\nobjectives. These objectives can be extracted directly from the environment by\nsub-aggregating the raw performance of individuals in a variety of ways. We use\nlexicase selection to optimize for these objectives as it has been shown to\nimplicitly maintain population diversity. We compare this technique with a\nvarying number of objectives to a commonly used quality diversity algorithm,\nMAP-Elites, on a set of discrete optimization as well as reinforcement learning\ndomains with varying degrees of deception. We find that decomposing objectives\ninto many objectives and optimizing them outperforms MAP-Elites on the\ndeceptive domains that we explore. Furthermore, we find that this technique\nresults in competitive performance on the diversity-focused metrics of QD-Score\nand Coverage, without explicitly optimizing for these things. Our ablation\nstudy shows that this technique is robust to different subaggregation\ntechniques. However, when it comes to non-deceptive, or ``illumination\"\ndomains, quality diversity techniques generally outperform our objective-based\nframework with respect to exploration (but not exploitation), hinting at\npotential directions for future work.",
            "author": [
                "Ryan Boldi",
                "Li Ding",
                "Lee Spector"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02283v1",
                "http://arxiv.org/pdf/2311.02283v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02279v1",
            "title": "Algorithms for Proportional Representation in Parliament in Divisor and\n  Multiplicative Form",
            "updated": "2023-11-04T00:00:23Z",
            "published": "2023-11-04T00:00:23Z",
            "summary": "We consider three algorithms for allocating parliamentary seats by\nproportional representation. The usual approach to describing such algorithms\nis to compute a quota of votes that each party uses to \"acquire''\nrepresentatives. This kind of description follows a divisor method, since the\nnumber of representatives for a party is equal to the number of votes for that\nparty, divided by the quota. We show that a simple multiplicative form with\ndifferent rounding methods produces algorithms equivalent to the divisor\nmethods. The multiplicative form is intuitive and easier to understand for a\nwider audience.",
            "author": [
                "Raul Rojas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02279v1",
                "http://arxiv.org/pdf/2311.02279v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02274v1",
            "title": "Patch-based Selection and Refinement for Early Object Detection",
            "updated": "2023-11-03T23:41:13Z",
            "published": "2023-11-03T23:41:13Z",
            "summary": "Early object detection (OD) is a crucial task for the safety of many dynamic\nsystems. Current OD algorithms have limited success for small objects at a long\ndistance. To improve the accuracy and efficiency of such a task, we propose a\nnovel set of algorithms that divide the image into patches, select patches with\nobjects at various scales, elaborate the details of a small object, and detect\nit as early as possible. Our approach is built upon a transformer-based network\nand integrates the diffusion model to improve the detection accuracy. As\ndemonstrated on BDD100K, our algorithms enhance the mAP for small objects from\n1.03 to 8.93, and reduce the data volume in computation by more than 77\\%. The\nsource code is available at\n\\href{https://github.com/destiny301/dpr}{https://github.com/destiny301/dpr}",
            "author": [
                "Tianyi Zhang",
                "Kishore Kasichainula",
                "Yaoxin Zhuo",
                "Baoxin Li",
                "Jae-Sun Seo",
                "Yu Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02274v1",
                "http://arxiv.org/pdf/2311.02274v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02272v1",
            "title": "Enabling Cross-Language Data Integration and Scalable Analytics in\n  Decentralized Finance",
            "updated": "2023-11-03T23:36:07Z",
            "published": "2023-11-03T23:36:07Z",
            "summary": "With the agile development process of most academic and corporate entities,\ndesigning a robust computational back-end system that can support their\never-changing data needs is a constantly evolving challenge. We propose the\nimplementation of a data and language-agnostic system design that handles\ndifferent data schemes and sources while subsequently providing researchers and\ndevelopers a way to connect to it that is supported by a vast majority of\nprogramming languages. To validate the efficacy of a system with this proposed\narchitecture, we integrate various data sources throughout the decentralized\nfinance (DeFi) space, specifically from DeFi lending protocols, retrieving tens\nof millions of data points to perform analytics through this system. We then\naccess and process the retrieved data through several different programming\nlanguages (R-Lang, Python, and Java). Finally, we analyze the performance of\nthe proposed architecture in relation to other high-performance systems and\nexplore how this system performs under a high computational load.",
            "author": [
                "Conor Flynn",
                "Kristin P. Bennett",
                "John S. Erickson",
                "Aaron Green",
                "Oshani Seneviratne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02272v1",
                "http://arxiv.org/pdf/2311.02272v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "C.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02271v2",
            "title": "FaMeSumm: Investigating and Improving Faithfulness of Medical\n  Summarization",
            "updated": "2023-11-08T22:54:33Z",
            "published": "2023-11-03T23:25:53Z",
            "summary": "Summaries of medical text shall be faithful by being consistent and factual\nwith source inputs, which is an important but understudied topic for safety and\nefficiency in healthcare. In this paper, we investigate and improve\nfaithfulness in summarization on a broad range of medical summarization tasks.\nOur investigation reveals that current summarization models often produce\nunfaithful outputs for medical input text. We then introduce FaMeSumm, a\nframework to improve faithfulness by fine-tuning pre-trained language models\nbased on medical knowledge. FaMeSumm performs contrastive learning on designed\nsets of faithful and unfaithful summaries, and it incorporates medical terms\nand their contexts to encourage faithful generation of medical terms. We\nconduct comprehensive experiments on three datasets in two languages: health\nquestion and radiology report summarization datasets in English, and a\npatient-doctor dialogue dataset in Chinese. Results demonstrate that FaMeSumm\nis flexible and effective by delivering consistent improvements over mainstream\nlanguage models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art\nperformances on metrics for faithfulness and general quality. Human evaluation\nby doctors also shows that FaMeSumm generates more faithful outputs. Our code\nis available at https://github.com/psunlpgroup/FaMeSumm .",
            "author": [
                "Nan Zhang",
                "Yusen Zhang",
                "Wu Guo",
                "Prasenjit Mitra",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02271v2",
                "http://arxiv.org/pdf/2311.02271v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02266v1",
            "title": "Multi-task Learning for Optical Coherence Tomography Angiography (OCTA)\n  Vessel Segmentation",
            "updated": "2023-11-03T23:10:56Z",
            "published": "2023-11-03T23:10:56Z",
            "summary": "Optical Coherence Tomography Angiography (OCTA) is a non-invasive imaging\ntechnique that provides high-resolution cross-sectional images of the retina,\nwhich are useful for diagnosing and monitoring various retinal diseases.\nHowever, manual segmentation of OCTA images is a time-consuming and\nlabor-intensive task, which motivates the development of automated segmentation\nmethods. In this paper, we propose a novel multi-task learning method for OCTA\nsegmentation, called OCTA-MTL, that leverages an image-to-DT (Distance\nTransform) branch and an adaptive loss combination strategy. The image-to-DT\nbranch predicts the distance from each vessel voxel to the vessel surface,\nwhich can provide useful shape prior and boundary information for the\nsegmentation task. The adaptive loss combination strategy dynamically adjusts\nthe loss weights according to the inverse of the average loss values of each\ntask, to balance the learning process and avoid the dominance of one task over\nthe other. We evaluate our method on the ROSE-2 dataset its superiority in\nterms of segmentation performance against two baseline methods: a single-task\nsegmentation method and a multi-task segmentation method with a fixed loss\ncombination.",
            "author": [
                "Can Koz",
                "Onat Dalmaz",
                "Mertay Dayanc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02266v1",
                "http://arxiv.org/pdf/2311.02266v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02265v2",
            "title": "Not all layers are equally as important: Every Layer Counts BERT",
            "updated": "2023-11-07T21:36:11Z",
            "published": "2023-11-03T23:08:50Z",
            "summary": "This paper introduces a novel modification of the transformer architecture,\ntailored for the data-efficient pretraining of language models. This aspect is\nevaluated by participating in the BabyLM challenge, where our solution won both\nthe strict and strict-small tracks. Our approach allows each transformer layer\nto select which outputs of previous layers to process. The empirical results\nverify the potential of this simple modification and show that not all layers\nare equally as important.",
            "author": [
                "Lucas Georges Gabriel Charpentier",
                "David Samuel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02265v2",
                "http://arxiv.org/pdf/2311.02265v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02262v1",
            "title": "Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs",
            "updated": "2023-11-03T22:56:43Z",
            "published": "2023-11-03T22:56:43Z",
            "summary": "In human-written articles, we often leverage the subtleties of text style,\nsuch as bold and italics, to guide the attention of readers. These textual\nemphases are vital for the readers to grasp the conveyed information. When\ninteracting with large language models (LLMs), we have a similar need -\nsteering the model to pay closer attention to user-specified information, e.g.,\nan instruction. Existing methods, however, are constrained to process plain\ntext and do not support such a mechanism. This motivates us to introduce PASTA\n- Post-hoc Attention STeering Approach, a method that allows LLMs to read text\nwith user-specified emphasis marks. To this end, PASTA identifies a small\nsubset of attention heads and applies precise attention reweighting on them,\ndirecting the model attention to user-specified parts. Like prompting, PASTA is\napplied at inference time and does not require changing any model parameters.\nExperiments demonstrate that PASTA can substantially enhance an LLM's ability\nto follow user instructions or integrate new knowledge from user inputs,\nleading to a significant performance improvement on a variety of tasks, e.g.,\nan average accuracy improvement of 22% for LLAMA-7B. Our code is publicly\navailable at https://github.com/QingruZhang/PASTA .",
            "author": [
                "Qingru Zhang",
                "Chandan Singh",
                "Liyuan Liu",
                "Xiaodong Liu",
                "Bin Yu",
                "Jianfeng Gao",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02262v1",
                "http://arxiv.org/pdf/2311.02262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02259v1",
            "title": "Vanquishing volumetric locking in quadratic NURBS-based discretizations\n  of nearly-incompressible linear elasticity: CAS elements",
            "updated": "2023-11-03T22:33:24Z",
            "published": "2023-11-03T22:33:24Z",
            "summary": "Quadratic NURBS-based discretizations of the Galerkin method suffer from\nvolumetric locking when applied to nearly-incompressible linear elasticity.\nVolumetric locking causes not only smaller displacements than expected, but\nalso large-amplitude spurious oscillations of normal stresses.\nContinuous-assumed-strain (CAS) elements have been recently introduced to\nremove membrane locking in quadratic NURBS-based discretizations of linear\nplane curved Kirchhoff rods (Casquero et al., CMAME, 2022). In this work, we\npropose two generalizations of CAS elements (named CAS1 and CAS2 elements) to\novercome volumetric locking in quadratic NURBS-based discretizations of\nnearly-incompressible linear elasticity. CAS1 elements linearly interpolate the\nstrains at the knots in each direction for the term in the variational form\ninvolving the first Lam\\'e parameter while CAS2 elements linearly interpolate\nthe dilatational strains at the knots in each direction. For both element\ntypes, a displacement vector with C1 continuity across element boundaries\nresults in assumed strains with C0 continuity across element boundaries. In\naddition, the implementation of the two locking treatments proposed in this\nwork does not require any additional global or element matrix operations such\nas matrix inversions or matrix multiplications. The locking treatments are\napplied at the element level and the nonzero pattern of the global stiffness\nmatrix is preserved. The numerical examples solved in this work show that CAS1\nand CAS2 elements, using either two or three Gauss-Legrendre quadrature points\nper direction, are effective locking treatments since they not only result in\nmore accurate displacements for coarse meshes, but also remove the spurious\noscillations of normal stresses.",
            "author": [
                "Hugo Casquero",
                "Mahmoud Golestanian"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s00466-023-02409-5",
                "http://arxiv.org/abs/2311.02259v1",
                "http://arxiv.org/pdf/2311.02259v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02256v2",
            "title": "Image Recognition of Oil Leakage Area Based on Logical Semantic\n  Discrimination",
            "updated": "2023-11-17T06:58:21Z",
            "published": "2023-11-03T22:13:58Z",
            "summary": "Implementing precise detection of oil leaks in peak load equipment through\nimage analysis can significantly enhance inspection quality and ensure the\nsystem's safety and reliability. However, challenges such as varying shapes of\noil-stained regions, background noise, and fluctuating lighting conditions\ncomplicate the detection process. To address this, the integration of logical\nrule-based discrimination into image recognition has been proposed. This\napproach involves recognizing the spatial relationships among objects to\nsemantically segment images of oil spills using a Mask RCNN network. The\nprocess begins with histogram equalization to enhance the original image,\nfollowed by the use of Mask RCNN to identify the preliminary positions and\noutlines of oil tanks, the ground, and areas of potential oil contamination.\nSubsequent to this identification, the spatial relationships between these\nobjects are analyzed. Logical rules are then applied to ascertain whether the\nsuspected areas are indeed oil spills. This method's effectiveness has been\nconfirmed by testing on images captured from peak power equipment in the field.\nThe results indicate that this approach can adeptly tackle the challenges in\nidentifying oil-contaminated areas, showing a substantial improvement in\naccuracy compared to existing methods.",
            "author": [
                "Weiying Lin",
                "Che Liu",
                "Xin Zhang",
                "Zhen Wei",
                "Sizhe Li",
                "Xun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02256v2",
                "http://arxiv.org/pdf/2311.02256v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02255v1",
            "title": "Decks of rooted binary trees",
            "updated": "2023-11-03T22:12:53Z",
            "published": "2023-11-03T22:12:53Z",
            "summary": "We consider extremal problems related to decks and multidecks of rooted\nbinary trees (a.k.a. rooted phylogenetic tree shapes). Here, the deck (resp.\nmultideck) of a tree $T$ refers to the set (resp. multiset) of leaf induced\nbinary subtrees of $T$. On the one hand, we consider the reconstruction of\ntrees from their (multi)decks. We give lower and upper bounds on the minimum\n(multi)deck size required to uniquely encode a rooted binary tree on $n$\nleaves. On the other hand, we consider problems related to deck cardinalities.\nIn particular, we characterize trees with minimum-size as well as maximum-size\ndecks. Finally, we present some exhaustive computations for $k$-universal\ntrees, i.e., rooted binary trees that contain all $k$-leaf rooted binary trees\nas induced subtrees.",
            "author": [
                "Ann Clifton",
                "Eva Czabarka",
                "Audace Dossou-Olory",
                "Kevin Liu",
                "Sarah Loeb",
                "Utku Okur",
                "Laszlo Szekely",
                "Kristina Wicke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02255v1",
                "http://arxiv.org/pdf/2311.02255v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05C05, 05C35, 05C60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02254v1",
            "title": "Learning-Based and Quality Preserving Super-Resolution of Noisy Images",
            "updated": "2023-11-03T22:00:50Z",
            "published": "2023-11-03T22:00:50Z",
            "summary": "Several applications require the super-resolution of noisy images and the\npreservation of geometrical and texture features. State-of-the-art\nsuper-resolution methods do not account for noise and generally enhance the\noutput image's artefacts (e.g., aliasing, blurring). We propose a\nlearning-based method that accounts for the presence of noise and preserves the\nproperties of the input image, as measured by quantitative metrics (e.g.,\nnormalised crossed correlation, normalised mean squared error,\npeak-signal-to-noise-ration, structural similarity feature-based similarity,\nuniversal image quality). We train our network to up-sample a low-resolution\nnoisy image while preserving its properties. We perform our tests on the Cineca\nMarconi100 cluster, at the 26th position in the top500 list. The experimental\nresults show that our method outperforms learning-based methods, has comparable\nresults with standard methods, preserves the properties of the input image as\ncontours, brightness, and textures, and reduces the artefacts. As average\nquantitative metrics, our method has a PSNR value of 23.81 on the\nsuper-resolution of Gaussian noise images with a 2X up-sampling factor. In\ncontrast, previous work has a PSNR value of 23.09 (standard method) and 21.78\n(learning-based method). Our learning-based and quality-preserving\nsuper-resolution improves the high-resolution prediction of noisy images with\nrespect to state-of-the-art methods with different noise types and up-sampling\nfactors.",
            "author": [
                "Simone Cammarasana",
                "Giuseppe Patan\u00e8"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02254v1",
                "http://arxiv.org/pdf/2311.02254v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02249v1",
            "title": "Monitoring Inactivity of Single Older Adults at Home",
            "updated": "2023-11-03T21:51:33Z",
            "published": "2023-11-03T21:51:33Z",
            "summary": "A new application for real-time monitoring of the lack of movement in older\nadults' own homes is proposed, aiming to support people's lives and\nindependence in their later years. A lightweight camera monitoring system,\nbased on an RGB-D camera and a compact computer processor, was developed and\npiloted in community homes to observe the daily behavior of older adults.\nInstances of body inactivity were detected in everyday scenarios anonymously\nand unobtrusively. These events can be explained at a higher level, such as a\nloss of consciousness or physiological deterioration. The accuracy of the\ninactivity monitoring system is assessed, and statistics of inactivity events\nrelated to the daily behavior of the older adults are provided. The results\ndemonstrate that our method performs accurately in inactivity detection across\nvarious environments, including low room lighting, TV flickering, and different\ncamera views.",
            "author": [
                "Longfei Chen",
                "Robert B. Fisher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02249v1",
                "http://arxiv.org/pdf/2311.02249v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4; I.5; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02248v1",
            "title": "COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning",
            "updated": "2023-11-03T21:47:03Z",
            "published": "2023-11-03T21:47:03Z",
            "summary": "We present a data and cost efficient way of incorporating the speech modality\ninto a large language model (LLM). The resulting multi-modal LLM is a\nCOntextual Speech Model with Instruction-following/in-context-learning\nCapabilities - COSMIC. Speech comprehension test question-answer (SQA) pairs\nare generated using GPT-3.5 based on the speech transcriptions as a part of the\nsupervision for the instruction tuning. With fewer than 20M trainable\nparameters and as little as 450 hours of English speech data for SQA\ngeneration, COSMIC exhibits emergent instruction-following and in-context\nlearning capabilities in speech-to-text tasks. The model is able to follow the\ngiven text instructions to generate text response even on the unseen EN$\\to$X\nspeech-to-text translation (S2TT) task with zero-shot setting. We evaluate the\nmodel's in-context learning via various tasks such as EN$\\to$X S2TT and\nfew-shot domain adaptation. And instruction-following capabilities are\nevaluated through a contextual biasing benchmark. Our results demonstrate the\nefficacy of the proposed low cost recipe for building a speech LLM and that\nwith the new instruction-tuning data.",
            "author": [
                "Jing Pan",
                "Jian Wu",
                "Yashesh Gaur",
                "Sunit Sivasankaran",
                "Zhuo Chen",
                "Shujie Liu",
                "Jinyu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02248v1",
                "http://arxiv.org/pdf/2311.02248v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02242v1",
            "title": "Democratic Policy Development using Collective Dialogues and AI",
            "updated": "2023-11-03T21:12:57Z",
            "published": "2023-11-03T21:12:57Z",
            "summary": "We design and test an efficient democratic process for developing policies\nthat reflect informed public will. The process combines AI-enabled collective\ndialogues that make deliberation democratically viable at scale with\nbridging-based ranking for automated consensus discovery. A GPT4-powered\npipeline translates points of consensus into representative policy clauses from\nwhich an initial policy is assembled. The initial policy is iteratively refined\nwith the input of experts and the public before a final vote and evaluation. We\ntest the process three times with the US public, developing policy guidelines\nfor AI assistants related to medical advice, vaccine information, and wars &\nconflicts. We show the process can be run in two weeks with 1500+ participants\nfor around $10,000, and that it generates policy guidelines with strong public\nsupport across demographic divides. We measure 75-81% support for the policy\nguidelines overall, and no less than 70-75% support across demographic splits\nspanning age, gender, religion, race, education, and political party. Overall,\nthis work demonstrates an end-to-end proof of concept for a process we believe\ncan help AI labs develop common-ground policies, governing bodies break\npolitical gridlock, and diplomats accelerate peace deals.",
            "author": [
                "Andrew Konya",
                "Lisa Schirch",
                "Colin Irwin",
                "Aviv Ovadya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02242v1",
                "http://arxiv.org/pdf/2311.02242v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02241v1",
            "title": "Rolling spheres and the Willmore energy",
            "updated": "2023-11-03T21:10:31Z",
            "published": "2023-11-03T21:10:31Z",
            "summary": "The Willmore energy plays a central role in the conformal geometry of\nsurfaces in the conformal 3-sphere \\(S^3\\). It also arises as the leading term\nin variational problems ranging from black holes, to elasticity, and cell\nbiology. In the computational setting a discrete version of the Willmore energy\nis desired. Ideally it should have the same symmetries as the smooth\nformulation. Such a M\\\"obius invariant discrete Willmore energy for simplicial\nsurfaces was introduced by Bobenko.\n  In the present paper we provide a new geometric interpretation of the\ndiscrete energy as the curvature of a rolling spheres connection in analogy to\nthe smooth setting where the curvature of a connection induced by the mean\ncurvature sphere congruence gives the Willmore integrand. We also show that the\nuse of a particular projective quaternionic representation of all relevant\nquantities gives clear geometric interpretations which are manifestly M\\\"obius\ninvariant.",
            "author": [
                "Felix Kn\u00f6ppel",
                "Ulrich Pinkall",
                "Peter Schr\u00f6der",
                "Yousuf Soliman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02241v1",
                "http://arxiv.org/pdf/2311.02241v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "math.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02240v1",
            "title": "Towards Machine Unlearning Benchmarks: Forgetting the Personal\n  Identities in Facial Recognition Systems",
            "updated": "2023-11-03T21:00:32Z",
            "published": "2023-11-03T21:00:32Z",
            "summary": "Machine unlearning is a crucial tool for enabling a classification model to\nforget specific data that are used in the training time. Recently, various\nstudies have presented machine unlearning algorithms and evaluated their\nmethods on several datasets. However, most of the current machine unlearning\nalgorithms have been evaluated solely on traditional computer vision datasets\nsuch as CIFAR-10, MNIST, and SVHN. Furthermore, previous studies generally\nevaluate the unlearning methods in the class-unlearning setup. Most previous\nwork first trains the classification models and then evaluates the machine\nunlearning performance of machine unlearning algorithms by forgetting selected\nimage classes (categories) in the experiments. Unfortunately, these\nclass-unlearning settings might not generalize to real-world scenarios. In this\nwork, we propose a machine unlearning setting that aims to unlearn specific\ninstance that contains personal privacy (identity) while maintaining the\noriginal task of a given model. Specifically, we propose two machine unlearning\nbenchmark datasets, MUFAC and MUCAC, that are greatly useful to evaluate the\nperformance and robustness of a machine unlearning algorithm. In our benchmark\ndatasets, the original model performs facial feature recognition tasks: face\nage estimation (multi-class classification) and facial attribute classification\n(binary class classification), where a class does not depend on any single\ntarget subject (personal identity), which can be a realistic setting. Moreover,\nwe also report the performance of the state-of-the-art machine unlearning\nmethods on our proposed benchmark datasets. All the datasets, source codes, and\ntrained models are publicly available at\nhttps://github.com/ndb796/MachineUnlearning.",
            "author": [
                "Dasol Choi",
                "Dongbin Na"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02240v1",
                "http://arxiv.org/pdf/2311.02240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02239v1",
            "title": "Using DUCK-Net for Polyp Image Segmentation",
            "updated": "2023-11-03T20:58:44Z",
            "published": "2023-11-03T20:58:44Z",
            "summary": "This paper presents a novel supervised convolutional neural network\narchitecture, \"DUCK-Net\", capable of effectively learning and generalizing from\nsmall amounts of medical images to perform accurate segmentation tasks. Our\nmodel utilizes an encoder-decoder structure with a residual downsampling\nmechanism and a custom convolutional block to capture and process image\ninformation at multiple resolutions in the encoder segment. We employ data\naugmentation techniques to enrich the training set, thus increasing our model's\nperformance. While our architecture is versatile and applicable to various\nsegmentation tasks, in this study, we demonstrate its capabilities specifically\nfor polyp segmentation in colonoscopy images. We evaluate the performance of\nour method on several popular benchmark datasets for polyp segmentation,\nKvasir-SEG, CVC-ClinicDB, CVC-ColonDB, and ETIS-LARIBPOLYPDB showing that it\nachieves state-of-the-art results in terms of mean Dice coefficient, Jaccard\nindex, Precision, Recall, and Accuracy. Our approach demonstrates strong\ngeneralization capabilities, achieving excellent performance even with limited\ntraining data. The code is publicly available on GitHub:\nhttps://github.com/RazvanDu/DUCK-Net",
            "author": [
                "Razvan-Gabriel Dumitru",
                "Darius Peteleaza",
                "Catalin Craciun"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-36940-5",
                "http://arxiv.org/abs/2311.02239v1",
                "http://arxiv.org/pdf/2311.02239v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.2; I.4; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02237v1",
            "title": "Explainable Authorship Identification in Cultural Heritage Applications:\n  Analysis of a New Perspective",
            "updated": "2023-11-03T20:51:15Z",
            "published": "2023-11-03T20:51:15Z",
            "summary": "While a substantial amount of work has recently been devoted to enhance the\nperformance of computational Authorship Identification (AId) systems, little to\nno attention has been paid to endowing AId systems with the ability to explain\nthe reasons behind their predictions. This lacking substantially hinders the\npractical employment of AId methodologies, since the predictions returned by\nsuch systems are hardly useful unless they are supported with suitable\nexplanations. In this paper, we explore the applicability of existing\ngeneral-purpose eXplainable Artificial Intelligence (XAI) techniques to AId,\nwith a special focus on explanations addressed to scholars working in cultural\nheritage. In particular, we assess the relative merits of three different types\nof XAI techniques (feature ranking, probing, factuals and counterfactual\nselection) on three different AId tasks (authorship attribution, authorship\nverification, same-authorship verification) by running experiments on real AId\ndata. Our analysis shows that, while these techniques make important first\nsteps towards explainable Authorship Identification, more work remains to be\ndone in order to provide tools that can be profitably integrated in the\nworkflows of scholars.",
            "author": [
                "Mattia Setzu",
                "Silvia Corbara",
                "Anna Monreale",
                "Alejandro Moreo",
                "Fabrizio Sebastiani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02237v1",
                "http://arxiv.org/pdf/2311.02237v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02236v1",
            "title": "Robust Fine-Tuning of Vision-Language Models for Domain Generalization",
            "updated": "2023-11-03T20:50:40Z",
            "published": "2023-11-03T20:50:40Z",
            "summary": "Transfer learning enables the sharing of common knowledge among models for a\nvariety of downstream tasks, but traditional methods suffer in limited training\ndata settings and produce narrow models incapable of effectively generalizing\nunder distribution shifts. Foundation models have recently demonstrated\nimpressive zero-shot inference capabilities and robustness under distribution\nshifts. However, zero-shot evaluation for these models has been predominantly\nconfined to benchmarks with simple distribution shifts, limiting our\nunderstanding of their effectiveness under the more realistic shifts found in\npractice. Moreover, common fine-tuning methods for these models have yet to be\nevaluated against vision models in few-shot scenarios where training data is\nlimited. To address these gaps, we present a new recipe for few-shot\nfine-tuning of the popular vision-language foundation model CLIP and evaluate\nits performance on challenging benchmark datasets with realistic distribution\nshifts from the WILDS collection. Our experimentation demonstrates that, while\nzero-shot CLIP fails to match performance of trained vision models on more\ncomplex benchmarks, few-shot CLIP fine-tuning outperforms its vision-only\ncounterparts in terms of in-distribution and out-of-distribution accuracy at\nall levels of training data availability. This provides a strong incentive for\nadoption of foundation models within few-shot learning applications operating\nwith real-world data. Code is available at\nhttps://github.com/mit-ll/robust-vision-language-finetuning",
            "author": [
                "Kevin Vogt-Lowell",
                "Noah Lee",
                "Theodoros Tsiligkaridis",
                "Marc Vaillant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02236v1",
                "http://arxiv.org/pdf/2311.02236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02232v1",
            "title": "Modeling Cancer Progression: An Integrated Workflow Extending\n  Data-Driven Kinetic Models to Bio-Mechanical PDE Models",
            "updated": "2023-11-03T20:42:34Z",
            "published": "2023-11-03T20:42:34Z",
            "summary": "Computational modeling of cancer can help unveil dynamics and interactions\nthat are hard to replicate experimentally. Thanks to the advancement in cancer\ndatabases and data analysis technologies, these models have become more robust\nthan ever. There are many mathematical models which investigate cancer through\ndifferent approaches, from sub-cellular to tissue scale, and from treatment to\ndiagnostic points of view. In this study, we lay out a step-by-step methodology\nfor a data-driven mechanistic model of the tumor microenvironment. We discuss\ndata acquisition strategies, data preparation, parameter estimation, and\nsensitivity analysis techniques. Furthermore, we propose a possible approach to\nextend mechanistic ODE models to PDE models coupled with mechanical growth. The\nworkflow discussed in this article can help understand the complex temporal and\nspatial interactions between cells and cytokines in the tumor microenvironment\nand their effect on tumor growth.",
            "author": [
                "Navid Mohammad Mirzaei",
                "Leili Shahriyari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02232v1",
                "http://arxiv.org/pdf/2311.02232v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02228v1",
            "title": "Towards Behavioral-aware Crowd Management System",
            "updated": "2023-11-03T20:33:41Z",
            "published": "2023-11-03T20:33:41Z",
            "summary": "Instances of casualties resulting from large crowds persist, highlighting the\nexisting limitations of current crowd management practices. One notable\ndrawback is the insufficient provision for disadvantaged individuals who may\nrequire additional time to evacuate due to their slower running speed.\nMoreover, the existing escape strategies may fall short of ensuring the safety\nof all individuals during a crowd surge. To address these pressing concerns,\nthis paper proposes two crowd management methodologies. Firstly, we advocate\nfor the implementation of a fair evacuation strategy following a surge event,\nwhich takes into account the diverse needs of all individuals, ensuring\ninclusivity and mitigating potential risks. Secondly, we propose a preventative\napproach involving the adjustment of attraction locations and switching between\nstage performances in large-crowded events to minimize the occurrence of surges\nand enhance crowd dispersion. To assess the effectiveness of our proposals, we\nused high-fidelity crowd management simulators. Our findings demonstrate the\npositive impact of the fair evacuation strategy on safety measures and\ninclusivity, which increases fairness by 41.8% on average. Furthermore, the\nadjustment of attraction locations and stage performances has shown a\nsignificant reduction in the incidence of surges by 34% on average, thereby\nenhancing overall crowd safety.",
            "author": [
                "Yixin Zhang",
                "Tianyu Zhao",
                "Salma Elmalaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02228v1",
                "http://arxiv.org/pdf/2311.02228v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02225v1",
            "title": "Multi-scale Time-stepping of Partial Differential Equations with\n  Transformers",
            "updated": "2023-11-03T20:26:43Z",
            "published": "2023-11-03T20:26:43Z",
            "summary": "Developing fast surrogates for Partial Differential Equations (PDEs) will\naccelerate design and optimization in almost all scientific and engineering\napplications. Neural networks have been receiving ever-increasing attention and\ndemonstrated remarkable success in computational modeling of PDEs, however;\ntheir prediction accuracy is not at the level of full deployment. In this work,\nwe utilize the transformer architecture, the backbone of numerous\nstate-of-the-art AI models, to learn the dynamics of physical systems as the\nmixing of spatial patterns learned by a convolutional autoencoder. Moreover, we\nincorporate the idea of multi-scale hierarchical time-stepping to increase the\nprediction speed and decrease accumulated error over time. Our model achieves\nsimilar or better results in predicting the time-evolution of Navier-Stokes\nequations compared to the powerful Fourier Neural Operator (FNO) and two\ntransformer-based neural operators OFormer and Galerkin Transformer.",
            "author": [
                "AmirPouya Hemmasian",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02225v1",
                "http://arxiv.org/pdf/2311.02225v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02224v1",
            "title": "Structural Properties of Search Trees with 2-way Comparisons",
            "updated": "2023-11-03T20:21:59Z",
            "published": "2023-11-03T20:21:59Z",
            "summary": "Optimal 3-way comparison search trees (3WCST's) can be computed using\nstandard dynamic programming in time O(n^3), and this can be further improved\nto O(n^2) by taking advantage of the Monge property. In contrast, the fastest\nalgorithm in the literature for computing optimal 2-way comparison search trees\n(2WCST's) runs in time O(n^4). To shed light on this discrepancy, we study\nstructure properties of 2WCST's. On one hand, we show some new threshold bounds\ninvolving key weights that can be helpful in deciding which type of comparison\nshould be at the root of the optimal tree. On the other hand, we also show that\nthe standard techniques for speeding up dynamic programming (the Monge property\n/ quadrangle inequality) do not apply to 2WCST's.",
            "author": [
                "Sunny Atalig",
                "Marek Chrobak",
                "Erfan Mousavian",
                "Jiri Sgall",
                "Pavel Vesely"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02224v1",
                "http://arxiv.org/pdf/2311.02224v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02222v1",
            "title": "Lessons learned while developing the Serenity-S1 ATCA card",
            "updated": "2023-11-03T20:16:53Z",
            "published": "2023-11-03T20:16:53Z",
            "summary": "The Serenity-S1 is a Xilinx Virtex Ultrascale+ based Advanced\nTelecommunications Computing Architecture (ATCA) processing blade that has been\noptimised for production. It incorporates many developments from the Serenity-A\nand Serenity-Z prototype cards and, where possible, adopts solutions being used\nacross CERN. It also uses many new parts because commonly used parts have\ndisappeared from the market during the semiconductor crisis, with only some\nreturning.\n  Improvements to simplify manufacture, the performance of new components, some\nof the more difficult aspects of procurement, the performance of\nproduction-grade Samtec 25\\,Gb/s optical firefly parts, and issues with the\nrack cooling infrastructure are discussed.",
            "author": [
                "T. Mehner",
                "L. E. Ardila-Perez",
                "M. Balzer",
                "G. Fedi",
                "M. Fuchs",
                "A. Howard",
                "G. Iles",
                "M. Loutit",
                "S. Mansbridge",
                "F. Palla",
                "D. Parker",
                "M. Pesaresi",
                "A. Rose",
                "M. Saleh",
                "O. Sander",
                "M. Schleicher",
                "C. Strohman",
                "D. Tcherniakhovski",
                "T. Williams",
                "J. Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02222v1",
                "http://arxiv.org/pdf/2311.02222v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02220v1",
            "title": "A geometric approach to the relative de Rham-Witt complex in the smooth,\n  $\\mathbb{Z}$-torsion free case",
            "updated": "2023-11-03T20:14:28Z",
            "published": "2023-11-03T20:14:28Z",
            "summary": "Let $X$ be a smooth scheme over a finitely generated flat $\\mathbb{Z}$-,\n$\\mathbb{Z}_{(p)}$- or $\\mathbb{Z}_p$-algebra $R$. Evaluated at finite\ntruncation sets $S$, the relative de Rham-Witt complex\n$W_S\\Omega_{X/R}^{\\bullet}$ is a quotient of the de Rham complex\n$\\Omega^{\\bullet}_{W_S(X)/W_S(R)}$, which can be computed affine locally via\nexplicit, but complicated relations. In this paper we prove that\n$W_S\\Omega_{X/R}^{\\bullet}$ is the torsionless quotient of the usual de Rham\ncomplex $\\Omega^{\\bullet}_{W_S(X)/W_S(R)}$ on the singular scheme $W_S(X)$.\nThis result was suggested by comparison with a similar modification of the de\nRham complex in the theory of singular varieties.",
            "author": [
                "Maria L\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02220v1",
                "http://arxiv.org/pdf/2311.02220v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "14A15, 14F10, 13F35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02219v1",
            "title": "On the dimension of the solution space of linear difference equations\n  over the ring of infinite sequences",
            "updated": "2023-11-03T20:13:55Z",
            "published": "2023-11-03T20:13:55Z",
            "summary": "For a linear difference equation with the coefficients being computable\nsequences, we establish algorithmic undecidability of the problem of\ndetermining the dimension of the solution space including the case when some\nadditional prior information on the dimension is available.",
            "author": [
                "Sergei Abramov",
                "Gleb Pogudin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02219v1",
                "http://arxiv.org/pdf/2311.02219v1"
            ],
            "primary_category": "cs.SC",
            "category": [
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02217v1",
            "title": "Linear difference operators with sequence coefficients having\n  infinite-dimentional solution spaces",
            "updated": "2023-11-03T20:08:02Z",
            "published": "2023-11-03T20:08:02Z",
            "summary": "The notion of lacunary infinite numerical sequence is introduced. It is shown\nthat for an arbitrary linear difference operator L with coefficients belonging\nto the set R of infinite numerical sequences, a criterion (i.e., a necessary\nand sufficient condition) for the infinite dimensionality of its space $V_L$ of\nsolutions belonging to R is the presence of a lacunary sequence in $V_L$.",
            "author": [
                "Sergei Abramov",
                "Gleb Pogudin"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610377.3610378",
                "http://arxiv.org/abs/2311.02217v1",
                "http://arxiv.org/pdf/2311.02217v1"
            ],
            "primary_category": "cs.SC",
            "category": [
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02216v1",
            "title": "Exploring the Numerical Reasoning Capabilities of Language Models: A\n  Comprehensive Analysis on Tabular Data",
            "updated": "2023-11-03T20:05:30Z",
            "published": "2023-11-03T20:05:30Z",
            "summary": "Numbers are crucial for various real-world domains such as finance,\neconomics, and science. Thus, understanding and reasoning with numbers are\nessential skills for language models to solve different tasks. While different\nnumerical benchmarks have been introduced in recent years, they are limited to\nspecific numerical aspects mostly. In this paper, we propose a hierarchical\ntaxonomy for numerical reasoning skills with more than ten reasoning types\nacross four levels: representation, number sense, manipulation, and complex\nreasoning. We conduct a comprehensive evaluation of state-of-the-art models to\nidentify reasoning challenges specific to them. Henceforth, we develop a\ndiverse set of numerical probes employing a semi-automated approach. We focus\non the tabular Natural Language Inference (TNLI) task as a case study and\nmeasure models' performance shifts. Our results show that no model consistently\nexcels across all numerical reasoning types. Among the probed models, FlanT5\n(few-/zero-shot) and GPT-3.5 (few-shot) demonstrate strong overall numerical\nreasoning skills compared to other models. Label-flipping probes indicate that\nmodels often exploit dataset artifacts to predict the correct labels.",
            "author": [
                "Mubashara Akhtar",
                "Abhilash Shankarampeta",
                "Vivek Gupta",
                "Arpit Patil",
                "Oana Cocarascu",
                "Elena Simperl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02216v1",
                "http://arxiv.org/pdf/2311.02216v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02215v1",
            "title": "Towards model-free RL algorithms that scale well with unstructured data",
            "updated": "2023-11-03T20:03:54Z",
            "published": "2023-11-03T20:03:54Z",
            "summary": "Conventional reinforcement learning (RL) algorithms exhibit broad generality\nin their theoretical formulation and high performance on several challenging\ndomains when combined with powerful function approximation. However, developing\nRL algorithms that perform well across problems with unstructured observations\nat scale remains challenging because most function approximation methods rely\non externally provisioned knowledge about the structure of the input for good\nperformance (e.g. convolutional networks, graph neural networks, tile-coding).\nA common practice in RL is to evaluate algorithms on a single problem, or on\nproblems with limited variation in the observation scale. RL practitioners lack\na systematic way to study how well a single RL algorithm performs when\ninstantiated across a range of problem scales, and they lack function\napproximation techniques that scale well with unstructured observations.\n  We address these limitations by providing environments and algorithms to\nstudy scaling for unstructured observation vectors and flat action spaces. We\nintroduce a family of combinatorial RL problems with an exponentially large\nstate space and high-dimensional dynamics but where linear computation is\nsufficient to learn a (nonlinear) value function estimate for performant\ncontrol. We provide an algorithm that constructs reward-relevant general value\nfunction (GVF) questions to find and exploit predictive structure directly from\nthe experience stream. In an empirical evaluation of the approach on synthetic\nproblems, we observe a sample complexity that scales linearly with the\nobservation size. The proposed algorithm reliably outperforms a conventional\ndeep RL algorithm on these scaling problems, and they exhibit several desirable\nauxiliary properties. These results suggest new algorithmic mechanisms by which\nalgorithms can learn at scale from unstructured data.",
            "author": [
                "Joseph Modayil",
                "Zaheer Abbas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02215v1",
                "http://arxiv.org/pdf/2311.02215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02211v1",
            "title": "Rock Climbing Route Generation and Grading as Computational Creativity",
            "updated": "2023-11-03T19:50:31Z",
            "published": "2023-11-03T19:50:31Z",
            "summary": "In this paper, we bridge work in rock climbing route generation and grading\ninto the computational creativity community. We provide the necessary\nbackground to situate that literature and demonstrate the domain's intellectual\nmerit in the computational creativity community. We provide a guiding set of\ndesiderata for future work in this area. We propose an approach to\ncomputational route grading. Finally, we identify important gaps in the\nliterature and consider how they may be filled. This paper thus also serves as\na pilot study, planting a flag for our ongoing research in this domain.",
            "author": [
                "Jesse Roberts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02211v1",
                "http://arxiv.org/pdf/2311.02211v1"
            ],
            "primary_category": "cs.OH",
            "category": [
                "cs.OH",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04929v1",
            "title": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
            "updated": "2023-11-03T19:41:09Z",
            "published": "2023-11-03T19:41:09Z",
            "summary": "In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.",
            "author": [
                "James Boyko",
                "Joseph Cohen",
                "Nathan Fox",
                "Maria Han Veiga",
                "Jennifer I-Hsiu Li",
                "Jing Liu",
                "Bernardo Modenesi",
                "Andreas H. Rauch",
                "Kenneth N. Reid",
                "Soumi Tribedi",
                "Anastasia Visheratina",
                "Xin Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04929v1",
                "http://arxiv.org/pdf/2311.04929v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02209v1",
            "title": "A Model-Based Synthetic Stock Price Time Series Generation Framework",
            "updated": "2023-11-03T19:40:32Z",
            "published": "2023-11-03T19:40:32Z",
            "summary": "The Ornstein-Uhlenbeck (OU) process, a mean-reverting stochastic process, has\nbeen widely applied as a time series model in various domains. This paper\ndescribes the design and implementation of a model-based synthetic time series\nmodel based on a multivariate OU process and the Arbitrage Pricing Theory (APT)\nfor generating synthetic pricing data for a complex market of interacting\nstocks. The objective is to create a group of synthetic stock price time series\nthat reflects the correlation between individual stocks and clusters of stocks\nin how a real market behaves. We demonstrate the method using the Standard and\nPoor's (S&P) 500 universe of stocks as an example.",
            "author": [
                "Haibei Zhu",
                "Svitlana Vyetrenko",
                "Tucker Balch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02209v1",
                "http://arxiv.org/pdf/2311.02209v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02206v1",
            "title": "GDlog: A GPU-Accelerated Deductive Engine",
            "updated": "2023-11-03T19:35:06Z",
            "published": "2023-11-03T19:35:06Z",
            "summary": "Modern deductive database engines (e.g., LogicBlox and Souffl\\'e) enable\ntheir users to write declarative queries which compute recursive deductions\nover extensional data, leaving their high-performance operationalization (query\nplanning, semi-na\\\"ive evaluation, and parallelization) to the engine. Such\nengines form the backbone of modern high-throughput applications in static\nanalysis, security auditing, social-media mining, and business analytics.\nState-of-the-art engines are built upon nested loop joins over explicit\nrepresentations (e.g., BTrees and tries) and ubiquitously employ range indexing\nto accelerate iterated joins. In this work, we present GDlog: a GPU-based\ndeductive analytics engine (implemented as a CUDA library) which achieves\nsignificant performance improvements (5--10x or more) versus prior systems.\nGDlog is powered by a novel range-indexed SIMD datastructure: the hash-indexed\nsorted array (HISA). We perform extensive evaluation on GDlog, comparing it\nagainst both CPU and GPU-based hash tables and Datalog engines, and using it to\nsupport a range of large-scale deductive queries including reachability, same\ngeneration, and context-sensitive program analysis. Our experiments show that\nGDlog achieves performance competitive with modern SIMD hash tables and beats\nprior work by an order of magnitude in runtime while offering more favorable\nmemory footprint.",
            "author": [
                "Yihao Sun",
                "Ahmedur Rahman Shovon",
                "Thomas Gilray",
                "Kristopher Micinski",
                "Sidharth Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02206v1",
                "http://arxiv.org/pdf/2311.02206v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02205v2",
            "title": "An Introduction to Natural Language Processing Techniques and Framework\n  for Clinical Implementation in Radiation Oncology",
            "updated": "2023-11-08T11:51:16Z",
            "published": "2023-11-03T19:32:35Z",
            "summary": "Natural Language Processing (NLP) is a key technique for developing Medical\nArtificial Intelligence (AI) systems that leverage Electronic Health Record\n(EHR) data to build diagnostic and prognostic models. NLP enables the\nconversion of unstructured clinical text into structured data that can be fed\ninto AI algorithms. The emergence of the transformer architecture and large\nlanguage models (LLMs) has led to remarkable advances in NLP for various\nhealthcare tasks, such as entity recognition, relation extraction, sentence\nsimilarity, text summarization, and question answering. In this article, we\nreview the major technical innovations that underpin modern NLP models and\npresent state-of-the-art NLP applications that employ LLMs in radiation\noncology research. However, these LLMs are prone to many errors such as\nhallucinations, biases, and ethical violations, which necessitate rigorous\nevaluation and validation before clinical deployment. As such, we propose a\ncomprehensive framework for assessing the NLP models based on their purpose and\nclinical fit, technical performance, bias and trust, legal and ethical\nimplications, and quality assurance, prior to implementation in clinical\nradiation oncology. Our article aims to provide guidance and insights for\nresearchers and clinicians who are interested in developing and using NLP\nmodels in clinical radiation oncology.",
            "author": [
                "Reza Khanmohammadi",
                "Mohammad M. Ghassemi",
                "Kyle Verdecchia",
                "Ahmed I. Ghanem",
                "Luo Bing",
                "Indrin J. Chetty",
                "Hassan Bagher-Ebadian",
                "Farzan Siddiqui",
                "Mohamed Elshaikh",
                "Benjamin Movsas",
                "Kundan Thind"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02205v2",
                "http://arxiv.org/pdf/2311.02205v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    }
]