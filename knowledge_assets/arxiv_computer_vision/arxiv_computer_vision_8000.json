[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02202v1",
            "title": "Neural Collage Transfer: Artistic Reconstruction via Material\n  Manipulation",
            "updated": "2023-11-03T19:10:37Z",
            "published": "2023-11-03T19:10:37Z",
            "summary": "Collage is a creative art form that uses diverse material scraps as a base\nunit to compose a single image. Although pixel-wise generation techniques can\nreproduce a target image in collage style, it is not a suitable method due to\nthe solid stroke-by-stroke nature of the collage form. While some previous\nworks for stroke-based rendering produced decent sketches and paintings,\ncollages have received much less attention in research despite their popularity\nas a style. In this paper, we propose a method for learning to make collages\nvia reinforcement learning without the need for demonstrations or collage\nartwork data. We design the collage Markov Decision Process (MDP), which allows\nthe agent to handle various materials and propose a model-based soft\nactor-critic to mitigate the agent's training burden derived from the\nsophisticated dynamics of collage. Moreover, we devise additional techniques\nsuch as active material selection and complexity-based multi-scale collage to\nhandle target images at any size and enhance the results' aesthetics by placing\nrelatively more scraps in areas of high complexity. Experimental results show\nthat the trained agent appropriately selected and pasted materials to\nregenerate the target image into a collage and obtained a higher evaluation\nscore on content and style than pixel-wise generation methods. Code is\navailable at https://github.com/northadventure/CollageRL.",
            "author": [
                "Ganghun Lee",
                "Minji Kim",
                "Yunsu Lee",
                "Minsu Lee",
                "Byoung-Tak Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02202v1",
                "http://arxiv.org/pdf/2311.02202v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02194v1",
            "title": "AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline\n  Multi-Agent RL via Alternating Stationary Distribution Correction Estimation",
            "updated": "2023-11-03T18:56:48Z",
            "published": "2023-11-03T18:56:48Z",
            "summary": "One of the main challenges in offline Reinforcement Learning (RL) is the\ndistribution shift that arises from the learned policy deviating from the data\ncollection policy. This is often addressed by avoiding out-of-distribution\n(OOD) actions during policy improvement as their presence can lead to\nsubstantial performance degradation. This challenge is amplified in the offline\nMulti-Agent RL (MARL) setting since the joint action space grows exponentially\nwith the number of agents. To avoid this curse of dimensionality, existing MARL\nmethods adopt either value decomposition methods or fully decentralized\ntraining of individual agents. However, even when combined with standard\nconservatism principles, these methods can still result in the selection of OOD\njoint actions in offline MARL. To this end, we introduce AlberDICE, an offline\nMARL algorithm that alternatively performs centralized training of individual\nagents based on stationary distribution optimization. AlberDICE circumvents the\nexponential complexity of MARL by computing the best response of one agent at a\ntime while effectively avoiding OOD joint action selection. Theoretically, we\nshow that the alternating optimization procedure converges to Nash policies. In\nthe experiments, we demonstrate that AlberDICE significantly outperforms\nbaseline algorithms on a standard suite of MARL benchmarks.",
            "author": [
                "Daiki E. Matsunaga",
                "Jongmin Lee",
                "Jaeseok Yoon",
                "Stefanos Leonardos",
                "Pieter Abbeel",
                "Kee-Eung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02194v1",
                "http://arxiv.org/pdf/2311.02194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02192v1",
            "title": "Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI)\n  Privacy Policy Annotations with Large Language Models",
            "updated": "2023-11-03T18:49:05Z",
            "published": "2023-11-03T18:49:05Z",
            "summary": "Identifying contextual integrity (CI) and governing knowledge commons (GKC)\nparameters in privacy policy texts can facilitate normative privacy analysis.\nHowever, GKC-CI annotation has heretofore required manual or crowdsourced\neffort. This paper demonstrates that high-accuracy GKC-CI parameter annotation\nof privacy policies can be performed automatically using large language models.\nWe fine-tune 18 open-source and proprietary models on 21,588 GKC-CI annotations\nfrom 16 ground truth privacy policies. Our best-performing model (fine-tuned\nGPT-3.5 Turbo with prompt engineering) has an accuracy of 86%, exceeding the\nperformance of prior crowdsourcing approaches despite the complexity of privacy\npolicy texts and the nuance of the GKC-CI annotation task. We apply our\nbest-performing model to privacy policies from 164 popular online services,\ndemonstrating the effectiveness of scaling GKC-CI annotation for data\nexploration. We make all annotated policies as well as the training data and\nscripts needed to fine-tune our best-performing model publicly available for\nfuture research.",
            "author": [
                "Jake Chanenson",
                "Madison Pickering",
                "Noah Apthorpe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02192v1",
                "http://arxiv.org/pdf/2311.02192v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02190v1",
            "title": "The Tensor as an Informational Resource",
            "updated": "2023-11-03T18:47:39Z",
            "published": "2023-11-03T18:47:39Z",
            "summary": "A tensor is a multidimensional array of numbers that can be used to store\ndata, encode a computational relation and represent quantum entanglement. In\nthis sense a tensor can be viewed as valuable resource whose transformation can\nlead to an understanding of structure in data, computational complexity and\nquantum information.\n  In order to facilitate the understanding of this resource, we propose a\nfamily of information-theoretically constructed preorders on tensors, which can\nbe used to compare tensors with each other and to assess the existence of\ntransformations between them. The construction places copies of a given tensor\nat the edges of a hypergraph and allows transformations at the vertices. A\npreorder is then induced by the transformations possible in a given growing\nsequence of hypergraphs. The new family of preorders generalises the asymptotic\nrestriction preorder which Strassen defined in order to study the computational\ncomplexity of matrix multiplication.\n  We derive general properties of the preorders and their associated asymptotic\nnotions of tensor rank and view recent results on tensor rank non-additivity,\ntensor networks and algebraic complexity in this unifying frame. We hope that\nthis work will provide a useful vantage point for exploring tensors in applied\nmathematics, physics and computer science, but also from a purely mathematical\npoint of view.",
            "author": [
                "Matthias Christandl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02190v1",
                "http://arxiv.org/pdf/2311.02190v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC",
                "math.AG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03708v1",
            "title": "Abstraction via exemplars? A representational case study on lexical\n  category inference in BERT",
            "updated": "2023-11-03T18:45:19Z",
            "published": "2023-11-03T18:45:19Z",
            "summary": "Exemplar based accounts are often considered to be in direct opposition to\npure linguistic abstraction in explaining language learners' ability to\ngeneralize to novel expressions. However, the recent success of neural network\nlanguage models on linguistically sensitive tasks suggests that perhaps\nabstractions can arise via the encoding of exemplars. We provide empirical\nevidence for this claim by adapting an existing experiment that studies how an\nLM (BERT) generalizes the usage of novel tokens that belong to lexical\ncategories such as Noun/Verb/Adjective/Adverb from exposure to only a single\ninstance of their usage. We analyze the representational behavior of the novel\ntokens in these experiments, and find that BERT's capacity to generalize to\nunseen expressions involving the use of these novel tokens constitutes the\nmovement of novel token representations towards regions of known category\nexemplars in two-dimensional space. Our results suggest that learners' encoding\nof exemplars can indeed give rise to abstraction like behavior.",
            "author": [
                "Kanishka Misra",
                "Najoung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03708v1",
                "http://arxiv.org/pdf/2312.03708v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02189v1",
            "title": "FairSeg: A Large-scale Medical Image Segmentation Dataset for Fairness\n  Learning with Fair Error-Bound Scaling",
            "updated": "2023-11-03T18:44:21Z",
            "published": "2023-11-03T18:44:21Z",
            "summary": "Fairness in artificial intelligence models has gained significantly more\nattention in recent years, especially in the area of medicine, as fairness in\nmedical models is critical to people's well-being and lives. High-quality\nmedical fairness datasets are needed to promote fairness learning research.\nExisting medical fairness datasets are all for classification tasks, and no\nfairness datasets are available for medical segmentation, while medical\nsegmentation is an equally important clinical task as classifications, which\ncan provide detailed spatial information on organ abnormalities ready to be\nassessed by clinicians. In this paper, we propose the first fairness dataset\nfor medical segmentation named FairSeg with 10,000 subject samples. In\naddition, we propose a fair error-bound scaling approach to reweight the loss\nfunction with the upper error-bound in each identity group. We anticipate that\nthe segmentation performance equity can be improved by explicitly tackling the\nhard cases with high training errors in each identity group. To facilitate fair\ncomparisons, we propose new equity-scaled segmentation performance metrics,\nsuch as the equity-scaled Dice coefficient, which is calculated as the overall\nDice coefficient divided by one plus the standard deviation of group Dice\ncoefficients. Through comprehensive experiments, we demonstrate that our fair\nerror-bound scaling approach either has superior or comparable fairness\nperformance to the state-of-the-art fairness learning models. The dataset and\ncode are publicly accessible via\n\\url{https://github.com/Harvard-Ophthalmology-AI-Lab/FairSeg}.",
            "author": [
                "Yu Tian",
                "Min Shi",
                "Yan Luo",
                "Ava Kouhana",
                "Tobias Elze",
                "Mengyu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02189v1",
                "http://arxiv.org/pdf/2311.02189v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02183v2",
            "title": "A New Fine-grained Alignment Method for Image-text Matching",
            "updated": "2023-12-07T08:48:37Z",
            "published": "2023-11-03T18:27:43Z",
            "summary": "Image-text retrieval is a widely studied topic in the field of computer\nvision due to the exponential growth of multimedia data, whose core concept is\nto measure the similarity between images and text. However, most existing\nretrieval methods heavily rely on cross-attention mechanisms for cross-modal\nfine-grained alignment, which takes into account excessive irrelevant regions\nand treats prominent and non-significant words equally, thereby limiting\nretrieval accuracy. This paper aims to investigate an alignment approach that\nreduces the involvement of non-significant fragments in images and text while\nenhancing the alignment of prominent segments. For this purpose, we introduce\nthe Cross-Modal Prominent Fragments Enhancement Aligning Network(CPFEAN), which\nachieves improved retrieval accuracy by diminishing the participation of\nirrelevant regions during alignment and relatively increasing the alignment\nsimilarity of prominent words. Additionally, we incorporate prior textual\ninformation into image regions to reduce misalignment occurrences. In practice,\nwe first design a novel intra-modal fragments relationship reasoning method,\nand subsequently employ our proposed alignment mechanism to compute the\nsimilarity between images and text. Extensive quantitative comparative\nexperiments on MS-COCO and Flickr30K datasets demonstrate that our approach\noutperforms state-of-the-art methods by about 5% to 10% in the rSum metric.",
            "author": [
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02183v2",
                "http://arxiv.org/pdf/2311.02183v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04928v1",
            "title": "Leveraging Large Language Models for Collective Decision-Making",
            "updated": "2023-11-03T18:27:21Z",
            "published": "2023-11-03T18:27:21Z",
            "summary": "In various work contexts, such as meeting scheduling, collaborating, and\nproject planning, collective decision-making is essential but often challenging\ndue to diverse individual preferences, varying work focuses, and power dynamics\namong members. To address this, we propose a system leveraging Large Language\nModels (LLMs) to facilitate group decision-making by managing conversations and\nbalancing preferences among individuals. Our system extracts individual\npreferences and suggests options that satisfy a significant portion of the\nmembers. We apply this system to corporate meeting scheduling. We create\nsynthetic employee profiles and simulate conversations at scale, leveraging\nLLMs to evaluate the system. Our results indicate efficient coordination with\nreduced interactions between members and the LLM-based system. The system also\neffectively refines proposed options over time, ensuring their quality and\nequity. Finally, we conduct a survey study involving human participants to\nassess our system's ability to aggregate preferences and reasoning. Our\nfindings show that the system exhibits strong performance in both dimensions.",
            "author": [
                "Marios Papachristou",
                "Longqi Yang",
                "Chin-Chia Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04928v1",
                "http://arxiv.org/pdf/2311.04928v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02181v1",
            "title": "Joint Problems in Learning Multiple Dynamical Systems",
            "updated": "2023-11-03T18:16:00Z",
            "published": "2023-11-03T18:16:00Z",
            "summary": "Clustering of time series is a well-studied problem, with applications\nranging from quantitative, personalized models of metabolism obtained from\nmetabolite concentrations to state discrimination in quantum information\ntheory. We consider a variant, where given a set of trajectories and a number\nof parts, we jointly partition the set of trajectories and learn linear\ndynamical system (LDS) models for each part, so as to minimize the maximum\nerror across all the models. We present globally convergent methods and EM\nheuristics, accompanied by promising computational results.",
            "author": [
                "Mengjia Niu",
                "Xiaoyu He",
                "Petr Rysavy",
                "Quan Zhou",
                "Jakub Marecek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02181v1",
                "http://arxiv.org/pdf/2311.02181v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03387v1",
            "title": "Determination of droplet size from wide-angle light scattering image\n  data using convolutional neural networks",
            "updated": "2023-11-03T18:05:47Z",
            "published": "2023-11-03T18:05:47Z",
            "summary": "Wide-angle light scattering (WALS) offers the possibility of a highly\ntemporally and spatially resolved measurement of droplets in spray-based\nmethods for nanoparticle synthesis. The size of these droplets is a critical\nvariable affecting the final properties of synthesized materials such as\nhetero-aggregates. However, conventional methods for determining droplet sizes\nfrom WALS image data are labor-intensive and may introduce biases, particularly\nwhen applied to complex systems like spray flame synthesis (SFS). To address\nthese challenges, we introduce a fully automatic machine learning-based\napproach that employs convolutional neural networks (CNNs) in order to\nstreamline the droplet sizing process. This CNN-based methodology offers\nfurther advantages: it requires few manual labels and can utilize transfer\nlearning, making it a promising alternative to conventional methods,\nspecifically with respect to efficiency. To evaluate the performance of our\nmachine learning models, we consider WALS data from an ethanol spray flame\nprocess at various heights above the burner surface (HABs), where the models\nare trained and cross-validated on a large dataset comprising nearly 35000 WALS\nimages.",
            "author": [
                "Tom Kirstein",
                "Simon A\u00dfmann",
                "Orkun Furat",
                "Stefan Will",
                "Volker Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03387v1",
                "http://arxiv.org/pdf/2311.03387v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02174v1",
            "title": "Non-perturbative method for particle detectors with continuous\n  interactions",
            "updated": "2023-11-03T18:04:04Z",
            "published": "2023-11-03T18:04:04Z",
            "summary": "We show that detector switching profiles consisting of trains of delta\ncouplings are a useful computational tool to efficiently approximate results\ninvolving continuous switching functions, both in setups involving a single\ndetector and multiple ones. The rapid convergence to the continuous results at\nall orders in perturbation theory for sufficiently regular switchings means\nthat this tool can be used to obtain non-perturbative results for general\nparticle detector phenomena with continuous switching functions.",
            "author": [
                "Jos\u00e9 Polo-G\u00f3mez",
                "Eduardo Mart\u00edn-Mart\u00ednez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02174v1",
                "http://arxiv.org/pdf/2311.02174v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02172v1",
            "title": "Fast and Accurate Approximations of the Optimal Transport in\n  Semi-Discrete and Discrete Settings",
            "updated": "2023-11-03T18:02:15Z",
            "published": "2023-11-03T18:02:15Z",
            "summary": "Given a $d$-dimensional continuous (resp. discrete) probability distribution\n$\\mu$ and a discrete distribution $\\nu$, the semi-discrete (resp. discrete)\nOptimal Transport (OT) problem asks for computing a minimum-cost plan to\ntransport mass from $\\mu$ to $\\nu$; we assume $n$ to be the size of the support\nof the discrete distributions, and we assume we have access to an oracle\noutputting the mass of $\\mu$ inside a constant-complexity region in $O(1)$\ntime. In this paper, we present three approximation algorithms for the OT\nproblem.\n  (i) Semi-discrete additive approximation: For any $\\epsilon>0$, we present an\nalgorithm that computes a semi-discrete transport plan with $\\epsilon$-additive\nerror in $n^{O(d)}\\log\\frac{C_{\\max}}{\\epsilon}$ time; here, $C_{\\max}$ is the\ndiameter of the supports of $\\mu$ and $\\nu$.\n  (ii) Semi-discrete relative approximation: For any $\\epsilon>0$, we present\nan algorithm that computes a $(1+\\epsilon)$-approximate semi-discrete transport\nplan in $n\\epsilon^{-O(d)}\\log(n)\\log^{O(d)}(\\log n)$ time; here, we assume the\nground distance is any $L_p$ norm.\n  (iii) Discrete relative approximation: For any $\\epsilon>0$, we present a\nMonte-Carlo $(1+\\epsilon)$-approximation algorithm that computes a transport\nplan under any $L_p$ norm in $n\\epsilon^{-O(d)}\\log(n)\\log^{O(d)}(\\log n)$\ntime; here, we assume that the spread of the supports of $\\mu$ and $\\nu$ is\npolynomially bounded.",
            "author": [
                "Pankaj K. Agarwal",
                "Sharath Raghvendra",
                "Pouyan Shirzadian",
                "Keegan Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02172v1",
                "http://arxiv.org/pdf/2311.02172v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02159v1",
            "title": "Boosting photocatalytic water splitting of polymeric C$_{60}$ by reduced\n  dimensionality from 2D monolayer to 1D chain",
            "updated": "2023-11-03T18:00:01Z",
            "published": "2023-11-03T18:00:01Z",
            "summary": "Recent synthesis of 2D fullerene networks [$Nature$ 606, 507 (2022) &\n$Nature$ 613, 71 (2023)] provides new opportunities for photovoltaics and\nphotocatalysis because of their versatile crystal structures for further\ntailoring of electronic, optical and chemical function. To shed light on the\nstructural aspects of photocatalytic water splitting performance of fullerene\nnanomaterials, we compare the photocatalytic properties of individual polymeric\nfullerene chains and monolayer fullerene networks from first principles\ncalculations. It is found that the photocatalytic efficiency can be further\noptimised by reducing dimensionality from 2D to 1D. The conduction band edge of\nthe polymeric C$_{60}$ chain provides a much higher external potential for the\nhydrogen reduction reaction than its monolayer counterparts over a wider range\nof pH values, and the surface active sites in the 1D chain are two times more\nthan those in the 2D networks from a thermodynamic perspective. These\nobservations render the 1D fullerene polymer a more promising candidate as a\nphotocatalyst for the hydrogen evolution reaction than monolayer fullerene\nnetworks.",
            "author": [
                "Cory Jones",
                "Bo Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02159v1",
                "http://arxiv.org/pdf/2311.02159v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "physics.app-ph",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02077v1",
            "title": "EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via\n  Self-Supervision",
            "updated": "2023-11-03T17:59:55Z",
            "published": "2023-11-03T17:59:55Z",
            "summary": "We present EmerNeRF, a simple yet powerful approach for learning\nspatial-temporal representations of dynamic driving scenes. Grounded in neural\nfields, EmerNeRF simultaneously captures scene geometry, appearance, motion,\nand semantics via self-bootstrapping. EmerNeRF hinges upon two core components:\nFirst, it stratifies scenes into static and dynamic fields. This decomposition\nemerges purely from self-supervision, enabling our model to learn from general,\nin-the-wild data sources. Second, EmerNeRF parameterizes an induced flow field\nfrom the dynamic field and uses this flow field to further aggregate\nmulti-frame features, amplifying the rendering precision of dynamic objects.\nCoupling these three fields (static, dynamic, and flow) enables EmerNeRF to\nrepresent highly-dynamic scenes self-sufficiently, without relying on ground\ntruth object annotations or pre-trained models for dynamic object segmentation\nor optical flow estimation. Our method achieves state-of-the-art performance in\nsensor simulation, significantly outperforming previous methods when\nreconstructing static (+2.93 PSNR) and dynamic (+3.70 PSNR) scenes. In\naddition, to bolster EmerNeRF's semantic generalization, we lift 2D visual\nfoundation model features into 4D space-time and address a general positional\nbias in modern Transformers, significantly boosting 3D perception performance\n(e.g., 37.50% relative improvement in occupancy prediction accuracy on\naverage). Finally, we construct a diverse and challenging 120-sequence dataset\nto benchmark neural fields under extreme and highly-dynamic settings.",
            "author": [
                "Jiawei Yang",
                "Boris Ivanovic",
                "Or Litany",
                "Xinshuo Weng",
                "Seung Wook Kim",
                "Boyi Li",
                "Tong Che",
                "Danfei Xu",
                "Sanja Fidler",
                "Marco Pavone",
                "Yue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02077v1",
                "http://arxiv.org/pdf/2311.02077v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02075v1",
            "title": "Envy-Free Cake-Cutting for Four Agents",
            "updated": "2023-11-03T17:58:14Z",
            "published": "2023-11-03T17:58:14Z",
            "summary": "In the envy-free cake-cutting problem we are given a resource, usually called\na cake and represented as the $[0,1]$ interval, and a set of $n$ agents with\nheterogeneous preferences over pieces of the cake. The goal is to divide the\ncake among the $n$ agents such that no agent is envious of any other agent.\nEven under a very general preferences model, this fundamental fair division\nproblem is known to always admit an exact solution where each agent obtains a\nconnected piece of the cake; we study the complexity of finding an approximate\nsolution, i.e., a connected $\\varepsilon$-envy-free allocation.\n  For monotone valuations of cake pieces, Deng, Qi, and Saberi (2012) gave an\nefficient ($\\textsf{poly}(\\log(1/\\varepsilon))$ queries) algorithm for three\nagents and posed the open problem of four (or more) monotone agents. Even for\nthe special case of additive valuations, Br\\^anzei and Nisan (2022) conjectured\nan $\\Omega(1/\\varepsilon)$ lower bound on the number of queries for four\nagents. We provide the first efficient algorithm for finding a connected\n$\\varepsilon$-envy-free allocation with four monotone agents.\n  We also prove that as soon as valuations are allowed to be non-monotone, the\nproblem becomes hard: it becomes PPAD-hard, requires\n$\\textsf{poly}(1/\\varepsilon)$ queries in the black-box model, and even\n$\\textsf{poly}(1/\\varepsilon)$ communication complexity. This constitutes, to\nthe best of our knowledge, the first intractability result for any version of\nthe cake-cutting problem in the communication complexity model.",
            "author": [
                "Alexandros Hollender",
                "Aviad Rubinstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02075v1",
                "http://arxiv.org/pdf/2311.02075v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02146v1",
            "title": "Bayesian Optimization of Function Networks with Partial Evaluations",
            "updated": "2023-11-03T17:55:08Z",
            "published": "2023-11-03T17:55:08Z",
            "summary": "Bayesian optimization is a framework for optimizing functions that are costly\nor time-consuming to evaluate. Recent work has considered Bayesian optimization\nof function networks (BOFN), where the objective function is computed via a\nnetwork of functions, each taking as input the output of previous nodes in the\nnetwork and additional parameters. Exploiting this network structure has been\nshown to yield significant performance improvements. Existing BOFN algorithms\nfor general-purpose networks are required to evaluate the full network at each\niteration. However, many real-world applications allow evaluating nodes\nindividually. To take advantage of this opportunity, we propose a novel\nknowledge gradient acquisition function for BOFN that chooses which node to\nevaluate as well as the inputs for that node in a cost-aware fashion. This\napproach can dramatically reduce query costs by allowing the evaluation of part\nof the network at a lower cost relative to evaluating the entire network. We\nprovide an efficient approach to optimizing our acquisition function and show\nit outperforms existing BOFN methods and other benchmarks across several\nsynthetic and real-world problems. Our acquisition function is the first to\nenable cost-aware optimization of a broad class of function networks.",
            "author": [
                "Poompol Buathong",
                "Jiayue Wan",
                "Samuel Daulton",
                "Raul Astudillo",
                "Maximilian Balandat",
                "Peter I. Frazier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02146v1",
                "http://arxiv.org/pdf/2311.02146v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02072v1",
            "title": "Learning Historical Status Prompt for Accurate and Robust Visual\n  Tracking",
            "updated": "2023-11-03T17:54:59Z",
            "published": "2023-11-03T17:54:59Z",
            "summary": "Most trackers perform template and search region similarity matching to find\nthe most similar object to the template during tracking. However, they struggle\nto make prediction when the target appearance changes due to the limited\nhistorical information introduced by roughly cropping the current search region\nbased on the predicted result of previous frame. In this paper, we identify\nthat the central impediment to improving the performance of existing trackers\nis the incapacity to integrate abundant and effective historical information.\nTo address this issue, we propose a Historical Information Prompter (HIP) to\nenhance the provision of historical information. We also build HIPTrack upon\nHIP module. HIP is a plug-and-play module that make full use of search region\nfeatures to introduce historical appearance information. It also incorporates\nhistorical position information by constructing refined mask of the target. HIP\nis a lightweight module to generate historical information prompts. By\nintegrating historical information prompts, HIPTrack significantly enhances the\ntracking performance without the need to retrain the backbone. Experimental\nresults demonstrate that our method outperforms all state-of-the-art approaches\non LaSOT, LaSOT ext, GOT10k and NfS. Futhermore, HIP module exhibits strong\ngenerality and can be seamlessly integrated into trackers to improve tracking\nperformance. The source code and models will be released for further research.",
            "author": [
                "Wenrui Cai",
                "Qingjie Liu",
                "Yunhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02072v1",
                "http://arxiv.org/pdf/2311.02072v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02069v1",
            "title": "Grounded Intuition of GPT-Vision's Abilities with Scientific Images",
            "updated": "2023-11-03T17:53:43Z",
            "published": "2023-11-03T17:53:43Z",
            "summary": "GPT-Vision has impressed us on a range of vision-language tasks, but it comes\nwith the familiar new challenge: we have little idea of its capabilities and\nlimitations. In our study, we formalize a process that many have instinctively\nbeen trying already to develop \"grounded intuition\" of this new model. Inspired\nby the recent movement away from benchmarking in favor of example-driven\nqualitative evaluation, we draw upon grounded theory and thematic analysis in\nsocial science and human-computer interaction to establish a rigorous framework\nfor qualitative evaluation in natural language processing. We use our technique\nto examine alt text generation for scientific figures, finding that GPT-Vision\nis particularly sensitive to prompting, counterfactual text in images, and\nrelative spatial relationships. Our method and analysis aim to help researchers\nramp up their own grounded intuitions of new models while exposing how\nGPT-Vision can be applied to make information more accessible.",
            "author": [
                "Alyssa Hwang",
                "Andrew Head",
                "Chris Callison-Burch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02069v1",
                "http://arxiv.org/pdf/2311.02069v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02067v1",
            "title": "Solving Woeginger's Hiking Problem: Wonderful Partitions in Anonymous\n  Hedonic Games",
            "updated": "2023-11-03T17:52:09Z",
            "published": "2023-11-03T17:52:09Z",
            "summary": "A decade ago, Gerhard Woeginger posed an open problem that became well-known\nas \"Gerhard's Hiking Problem\": Consider a group of $n$ people that want to go\nhiking; everyone expresses preferences over the size of their hiking group in\nthe form of an interval between $1$ and $n$. Is it possible to efficiently\nassign the $n$ people to a set of hiking subgroups so that every person\napproves the size of their assigned subgroup? The problem is also known as\nefficiently deciding if an instance of an anonymous Hedonic Game with interval\napproval preferences admits a wonderful partition.\n  We resolve the open problem in the affirmative by presenting an $O(n^5)$ time\nalgorithm for Gerhard's Hiking Problem. Our solution is based on employing a\ndynamic programming approach for a specific rectangle stabbing problem from\ncomputational geometry. Moreover, we propose natural more demanding extensions\nof the problem, e.g., maximizing the number of satisfied people, and show that\nthey are also efficiently solvable. Additionally, we precisely map the boundary\nof tractability for the wonderful partition problem by proving that finding\nsuch a partition becomes NP-hard if non-interval approval size sets of size two\nare allowed. This closes a gap in the complexity landscape, since hardness was\nonly known for the case with non-interval approval size sets of size at most 3.\nLast but not least, we employ our solution to efficiently compute a partition\nthat maximizes the egalitarian welfare for anonymous single-peaked Hedonic\nGames.",
            "author": [
                "Andrei Constantinescu",
                "Pascal Lenzner",
                "Rebecca Reiffenh\u00e4user",
                "Daniel Schmand",
                "Giovanna Varricchio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02067v1",
                "http://arxiv.org/pdf/2311.02067v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02060v2",
            "title": "Revealing Local Field Effects at the Electrical Double Layer with\n  Efficient Open Boundary Simulations under Potential Control",
            "updated": "2023-11-06T15:02:49Z",
            "published": "2023-11-03T17:43:25Z",
            "summary": "A major challenge in modelling interfacial processes in electrochemical (EC)\ndevices is performing simulations at constant potential. This requires an\nopen-boundary description of the electrons, so that they can enter and leave\nthe computational cell. To enable realistic modelling of EC processes under\npotential control we have interfaced Density Functional Theory with the Hairy\nProbe method in the weak coupling limit (DOI: 10.1103/PhysRevB.97.045116). Our\nimplementation was systematically tested using simple parallel-plate capacitor\nmodels with pristine surfaces and a single layer of adsorbed water molecules.\nRemarkably, our code's efficiency is comparable with a standard DFT\ncalculation. We reveal that local field effects at the electrical double layer\ninduced by the change of applied potential can significantly affect the\nenergies of chemical steps in heterogeneous electrocatalysis. Our results\ndemonstrate the importance of an explicit modelling of the applied potential in\na simulation and provide an efficient tool to control this critical parameter.",
            "author": [
                "Margherita Buraschi",
                "Andrew P. Horsfield",
                "Clotilde S. Cucinotta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02060v2",
                "http://arxiv.org/pdf/2311.02060v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02058v2",
            "title": "LOTUS: Continual Imitation Learning for Robot Manipulation Through\n  Unsupervised Skill Discovery",
            "updated": "2023-11-17T08:26:16Z",
            "published": "2023-11-03T17:38:35Z",
            "summary": "We introduce LOTUS, a continual imitation learning algorithm that empowers a\nphysical robot to continuously and efficiently learn to solve new manipulation\ntasks throughout its lifespan. The core idea behind LOTUS is constructing an\never-growing skill library from a sequence of new tasks with a small number of\nhuman demonstrations. LOTUS starts with a continual skill discovery process\nusing an open-vocabulary vision model, which extracts skills as recurring\npatterns presented in unsegmented demonstrations. Continual skill discovery\nupdates existing skills to avoid catastrophic forgetting of previous tasks and\nadds new skills to solve novel tasks. LOTUS trains a meta-controller that\nflexibly composes various skills to tackle vision-based manipulation tasks in\nthe lifelong learning process. Our comprehensive experiments show that LOTUS\noutperforms state-of-the-art baselines by over 11% in success rate, showing its\nsuperior knowledge transfer ability compared to prior methods. More results and\nvideos can be found on the project website:\nhttps://ut-austin-rpl.github.io/Lotus/.",
            "author": [
                "Weikang Wan",
                "Yifeng Zhu",
                "Rutav Shah",
                "Yuke Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02058v2",
                "http://arxiv.org/pdf/2311.02058v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02052v1",
            "title": "Extreme Axions Unveiled: a Novel Fluid Approach for Cosmological\n  Modeling",
            "updated": "2023-11-03T17:29:51Z",
            "published": "2023-11-03T17:29:51Z",
            "summary": "Axion-like particles (ALPs) are a well-motivated dark matter candidate that\nsolve some of the problems in the clustering of large scale structure in\ncosmology. ALPs are often described by a simplified quadratic potential to\nspecify the dynamics of the axion field, and are included in cosmological\nanalysis codes using a modified fluid prescription. In this paper we consider\nthe extreme axion: a version of the axion with a high initial field angle that\nproduces an enhancement (rather than a suppression) of structure on small\nscales around the Jeans length, which can be probed by measurements of\nclustering such as the eBOSS DR14 Ly-$\\alpha$ forest. We present a novel method\nof modeling the extreme axion as a cosmological fluid, combining the\nGeneralized Dark Matter model with the effective fluid approach presented in\nthe \\texttt{axionCAMB} software, as well as implementing a series of\ncomputational innovations to efficiently simulate the extreme axions. We find\nthat for axion masses between $10^{-23} \\text{ eV} \\lesssim m_a \\lesssim\n10^{-22.5} \\text{ eV}$, constraints on the axion fraction imposed by the eBOSS\nDR14 Ly-$\\alpha$ forest can be significantly weakened by allowing them to be in\nthe form of extreme axions with a starting angle between $\\pi - 10^{-1}\n\\lesssim \\theta_0 \\lesssim \\pi - 10^{-2}$. This work motivates and enables a\nmore robust hydrodynamical analysis of extreme axions in order to compare them\nto high-resolution Ly-$\\alpha$ forest data in the future.",
            "author": [
                "Harrison Winch",
                "Renee Hlozek",
                "David J. E. Marsh",
                "Daniel Grin",
                "Keir Rogers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02052v1",
                "http://arxiv.org/pdf/2311.02052v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03386v1",
            "title": "A Simple and Efficient Baseline for Data Attribution on Images",
            "updated": "2023-11-03T17:29:46Z",
            "published": "2023-11-03T17:29:46Z",
            "summary": "Data attribution methods play a crucial role in understanding machine\nlearning models, providing insight into which training data points are most\nresponsible for model outputs during deployment. However, current\nstate-of-the-art approaches require a large ensemble of as many as 300,000\nmodels to accurately attribute model predictions. These approaches therefore\ncome at a high computational cost, are memory intensive, and are hard to scale\nto large models or datasets. In this work, we focus on a minimalist baseline,\nutilizing the feature space of a backbone pretrained via self-supervised\nlearning to perform data attribution. Our method is model-agnostic and scales\neasily to large datasets. We show results on CIFAR-10 and ImageNet, achieving\nstrong performance that rivals or outperforms state-of-the-art approaches at a\nfraction of the compute or memory cost. Contrary to prior work, our results\nreinforce the intuition that a model's prediction on one image is most impacted\nby visually similar training samples. Our approach serves as a simple and\nefficient baseline for data attribution on images.",
            "author": [
                "Vasu Singla",
                "Pedro Sandoval-Segura",
                "Micah Goldblum",
                "Jonas Geiping",
                "Tom Goldstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03386v1",
                "http://arxiv.org/pdf/2311.03386v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02145v1",
            "title": "AdS black hole thermodynamics and microstructures from $f(Q)$\n  gravitation",
            "updated": "2023-11-03T17:29:32Z",
            "published": "2023-11-03T17:29:32Z",
            "summary": "The significant properties and phase transition of charged Anti-de Sitter\n(AdS) black holes have been extensively studied in a variety of modified\ntheories of gravity in the presence of numerous matter fields. The goal of our\ncurrent research is to investigate the AdS black hole's thermodynamics under\nthe impact of $f(Q)$ gravity. Additionally, this paper explores the black\nhole's local stability and phase structure under the relevant gravity. Besides,\nwe use Ruppeiner geometry to look into the AdS black hole's microscopic\nstructure. We have numerically computed the Ricci curvature scalar $R$ to\nexplain the interactions between the AdS black hole's microscopic particles\nunder the influence of $f(Q)$ gravity.",
            "author": [
                "Oleksii Sokoliuk",
                "Sneha Pradhan",
                "Alexander Baransky",
                "P. K. Sahoo"
            ],
            "link": [
                "http://dx.doi.org/10.1002/prop.202300043",
                "http://arxiv.org/abs/2311.02145v1",
                "http://arxiv.org/pdf/2311.02145v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02050v1",
            "title": "Fast Approximation Algorithms for Piercing Boxes by Points",
            "updated": "2023-11-03T17:27:07Z",
            "published": "2023-11-03T17:27:07Z",
            "summary": "$ \\newcommand{\\Re}{\\mathbb{R}} \\newcommand{\\BX}{\\mathcal{B}}\n\\newcommand{\\bb}{\\mathsf{b}} \\newcommand{\\eps}{\\varepsilon}\n\\newcommand{\\polylog}{\\mathrm{polylog}} $\n  Let $\\BX=\\{\\bb_1, \\ldots ,\\bb_n\\}$ be a set of $n$ axis-aligned boxes in\n$\\Re^d$ where $d\\geq2$ is a constant. The piercing problem is to compute a\nsmallest set of points $N \\subset \\Re^d$ that hits every box in $\\BX$, i.e.,\n$N\\cap \\bb_i\\neq \\emptyset$, for $i=1,\\ldots, n$. The problem is known to be\nNP-Hard. Let $\\psi:=\\psi(\\BX)$, the \\emph{piercing number} be the minimum size\nof a piercing set of $\\BX$. We first present a randomized $O(\\log\\log\n\\psi)$-approximation algorithm with expected running time $O(n^{d/2}\\polylog\n(n))$. Next, we show that the expected running time can be improved to\nnear-linear using a sampling-based technique, if $\\psi = O(n^{1/(d-1)})$.\nSpecifically, in the plane, the improved running time is $O(n \\log \\psi)$,\nassuming $\\psi < n/\\log^{\\Omega(1)} n$. Finally, we study the dynamic version\nof the piercing problem where boxes can be inserted or deleted. For boxes in\n$\\Re^2$, we obtain a randomized $O(\\log\\log\\psi)$-approximation algorithm with\n$O(n^{1/2}\\polylog (n))$ amortized expected update time for insertion or\ndeletion of boxes. For squares in $\\Re^2$, the update time can be improved to\n$O(n^{1/3}\\polylog (n))$.\n  Our algorithms are based on the multiplicative weight-update (MWU) method and\nrequire the construction of a weak $\\eps$-net for a point set with respect to\nboxes. A key idea of our work is to exploit the duality between the piercing\nset and independent set (for boxes) to speed up our MWU. We also present a\nsimpler and slightly more efficient algorithm for constructing a weak\n$\\eps$-net than in [Ezr10], which is of independent interest. Our approach also\nyields a simpler algorithm for constructing (regular) $\\eps$-nets with respect\nto boxes for $d=2,3$.",
            "author": [
                "Pankaj K. Agarwal",
                "Sariel Har-Peled",
                "Rahul Raychaudhury",
                "Stavros Sintos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02050v1",
                "http://arxiv.org/pdf/2311.02050v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02049v1",
            "title": "Post Turing: Mapping the landscape of LLM Evaluation",
            "updated": "2023-11-03T17:24:50Z",
            "published": "2023-11-03T17:24:50Z",
            "summary": "In the rapidly evolving landscape of Large Language Models (LLMs),\nintroduction of well-defined and standardized evaluation methodologies remains\na crucial challenge. This paper traces the historical trajectory of LLM\nevaluations, from the foundational questions posed by Alan Turing to the modern\nera of AI research. We categorize the evolution of LLMs into distinct periods,\neach characterized by its unique benchmarks and evaluation criteria. As LLMs\nincreasingly mimic human-like behaviors, traditional evaluation proxies, such\nas the Turing test, have become less reliable. We emphasize the pressing need\nfor a unified evaluation system, given the broader societal implications of\nthese models. Through an analysis of common evaluation methodologies, we\nadvocate for a qualitative shift in assessment approaches, underscoring the\nimportance of standardization and objective criteria. This work serves as a\ncall for the AI community to collaboratively address the challenges of LLM\nevaluation, ensuring their reliability, fairness, and societal benefit.",
            "author": [
                "Alexey Tikhonov",
                "Ivan P. Yamshchikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02049v1",
                "http://arxiv.org/pdf/2311.02049v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02044v1",
            "title": "Occlusion-Aware 2D and 3D Centerline Detection for Urban Driving via\n  Automatic Label Generation",
            "updated": "2023-11-03T17:20:34Z",
            "published": "2023-11-03T17:20:34Z",
            "summary": "This research work seeks to explore and identify strategies that can\ndetermine road topology information in 2D and 3D under highly dynamic urban\ndriving scenarios. To facilitate this exploration, we introduce a substantial\ndataset comprising nearly one million automatically labeled data frames. A key\ncontribution of our research lies in developing an automatic label-generation\nprocess and an occlusion handling strategy. This strategy is designed to model\na wide range of occlusion scenarios, from mild disruptions to severe blockages.\nFurthermore, we present a comprehensive ablation study wherein multiple\ncenterline detection methods are developed and evaluated. This analysis not\nonly benchmarks the performance of various approaches but also provides\nvaluable insights into the interpretability of these methods. Finally, we\ndemonstrate the practicality of our methods and assess their adaptability\nacross different sensor configurations, highlighting their versatility and\nrelevance in real-world scenarios. Our dataset and experimental models are\npublicly available.",
            "author": [
                "David Paz",
                "Narayanan E. Ranganatha",
                "Srinidhi K. Srinivas",
                "Yunchao Yao",
                "Henrik I. Christensen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02044v1",
                "http://arxiv.org/pdf/2311.02044v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02043v1",
            "title": "Bayesian Quantile Regression with Subset Selection: A Posterior\n  Summarization Perspective",
            "updated": "2023-11-03T17:19:31Z",
            "published": "2023-11-03T17:19:31Z",
            "summary": "Quantile regression is a powerful tool for inferring how covariates affect\nspecific percentiles of the response distribution. Existing methods either\nestimate conditional quantiles separately for each quantile of interest or\nestimate the entire conditional distribution using semi- or non-parametric\nmodels. The former often produce inadequate models for real data and do not\nshare information across quantiles, while the latter are characterized by\ncomplex and constrained models that can be difficult to interpret and\ncomputationally inefficient. Further, neither approach is well-suited for\nquantile-specific subset selection. Instead, we pose the fundamental problems\nof linear quantile estimation, uncertainty quantification, and subset selection\nfrom a Bayesian decision analysis perspective. For any Bayesian regression\nmodel, we derive optimal and interpretable linear estimates and uncertainty\nquantification for each model-based conditional quantile. Our approach\nintroduces a quantile-focused squared error loss, which enables efficient,\nclosed-form computing and maintains a close relationship with Wasserstein-based\ndensity estimation. In an extensive simulation study, our methods demonstrate\nsubstantial gains in quantile estimation accuracy, variable selection, and\ninference over frequentist and Bayesian competitors. We apply these tools to\nidentify the quantile-specific impacts of social and environmental stressors on\neducational outcomes for a large cohort of children in North Carolina.",
            "author": [
                "Joseph Feldman",
                "Daniel Kowal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02043v1",
                "http://arxiv.org/pdf/2311.02043v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.AP",
                "stat.CO",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02042v1",
            "title": "A Data-Driven Approach to Coarse-Graining Simple Liquids in Confinement",
            "updated": "2023-11-03T17:19:14Z",
            "published": "2023-11-03T17:19:14Z",
            "summary": "We propose a data-driven framework for identifying coarse-grained (CG)\nLennard-Jones (LJ) potential parameters in confined systems for simple liquids.\nOur approach involves the use of a Deep Neural Network (DNN) that is trained to\napproximate the solution of the Inverse Liquid State (ILST) problem for\nconfined systems. The DNN model inherently incorporates essential physical\ncharacteristics specific to confined fluids, enabling accurate prediction of\ninhomogeneity effects. By utilizing transfer learning, we predict single-site\nLJ potentials of simple multiatomic liquids confined in a slit-like channel,\nwhich effectively replicate both the fluid structure and molecular force of the\ntarget All-Atom (AA) system when the electrostatic interactions are not\ndominant. In addition, we showcase the synergy between the data-driven approach\nand the well-known Bottom-Up coarse-graining method utilizing Relative-Entropy\n(RE) Minimization. Through sequential utilization of these two methods, the\nrobustness of the iterative RE method is significantly augmented, leading to a\nremarkable enhancement in convergence.",
            "author": [
                "Ishan Nadkarni",
                "Haiyi Wu",
                "Narayana. R. Aluru"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acs.jctc.3c00633",
                "http://arxiv.org/abs/2311.02042v1",
                "http://arxiv.org/pdf/2311.02042v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02041v1",
            "title": "Quantum circuit synthesis with diffusion models",
            "updated": "2023-11-03T17:17:08Z",
            "published": "2023-11-03T17:17:08Z",
            "summary": "Quantum computing has recently emerged as a transformative technology. Yet,\nits promised advantages rely on efficiently translating quantum operations into\nviable physical realizations. In this work, we use generative machine learning\nmodels, specifically denoising diffusion models (DMs), to facilitate this\ntransformation. Leveraging text-conditioning, we steer the model to produce\ndesired quantum operations within gate-based quantum circuits. Notably, DMs\nallow to sidestep during training the exponential overhead inherent in the\nclassical simulation of quantum dynamics -- a consistent bottleneck in\npreceding ML techniques. We demonstrate the model's capabilities across two\ntasks: entanglement generation and unitary compilation. The model excels at\ngenerating new circuits and supports typical DM extensions such as masking and\nediting to, for instance, align the circuit generation to the constraints of\nthe targeted quantum device. Given their flexibility and generalization\nabilities, we envision DMs as pivotal in quantum circuit synthesis, enhancing\nboth practical applications but also insights into theoretical quantum\ncomputation.",
            "author": [
                "Florian F\u00fcrrutter",
                "Gorka Mu\u00f1oz-Gil",
                "Hans J. Briegel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02041v1",
                "http://arxiv.org/pdf/2311.02041v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02039v1",
            "title": "HPC-based Solvers of Minimisation Problems for Signal Processing",
            "updated": "2023-11-03T17:13:28Z",
            "published": "2023-11-03T17:13:28Z",
            "summary": "Several physics and engineering applications involve the solution of a\nminimisation problem to compute an approximation of the input signal. Modern\ncomputing hardware and software apply high-performance computing to solve and\nconsiderably reduce the execution time. We compare and analyse different\nminimisation methods in terms of functional computation, convergence, execution\ntime, and scalability properties, for the solution of two minimisation problems\n(i.e., approximation and denoising) with different constraints that involve\ncomputationally expensive operations. These problems are attractive due to\ntheir numerical and analytical properties, and our general analysis can be\nextended to most signal-processing problems. We perform our tests on the Cineca\nMarconi100 cluster, at the 26th position in the top500 list. Our experimental\nresults show that PRAXIS is the best optimiser in terms of minima computation:\nthe efficiency of the approximation is 38% with 256 processes, while the\ndenoising has 46% with 32 processes.",
            "author": [
                "Simone Cammarasana",
                "Giuseppe Patan\u00e8"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02039v1",
                "http://arxiv.org/pdf/2311.02039v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.GR",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02143v2",
            "title": "Pairing-based graph neural network for simulating quantum materials",
            "updated": "2023-11-21T15:54:28Z",
            "published": "2023-11-03T17:12:29Z",
            "summary": "We develop a pairing-based graph neural network for simulating quantum\nmany-body systems. Our architecture augments a BCS-type geminal wavefunction\nwith a generalized pair amplitude parameterized by a graph neural network.\nVariational Monte Carlo with our neural network simultaneously provides an\naccurate, flexible, and scalable method for simulating many-electron systems.\nWe apply this method to two-dimensional semiconductor electron-hole bilayers\nand obtain accurate results on a variety of interaction-induced phases,\nincluding the exciton Bose-Einstein condensate, electron-hole superconductor,\nand bilayer Wigner crystal. Our study demonstrates the potential of\nphysically-motivated neural network wavefunctions for quantum materials\nsimulations.",
            "author": [
                "Di Luo",
                "David D. Dai",
                "Liang Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02143v2",
                "http://arxiv.org/pdf/2311.02143v2"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.dis-nn",
                "cs.LG",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04927v1",
            "title": "Contextualizing the Limits of Model & Evaluation Dataset Curation on\n  Semantic Similarity Classification Tasks",
            "updated": "2023-11-03T17:12:07Z",
            "published": "2023-11-03T17:12:07Z",
            "summary": "This paper demonstrates how the limitations of pre-trained models and open\nevaluation datasets factor into assessing the performance of binary semantic\nsimilarity classification tasks. As (1) end-user-facing documentation around\nthe curation of these datasets and pre-trained model training regimes is often\nnot easily accessible and (2) given the lower friction and higher demand to\nquickly deploy such systems in real-world contexts, our study reinforces prior\nwork showing performance disparities across datasets, embedding techniques and\ndistance metrics, while highlighting the importance of understanding how data\nis collected, curated and analyzed in semantic similarity classification.",
            "author": [
                "Daniel Theron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04927v1",
                "http://arxiv.org/pdf/2311.04927v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02037v1",
            "title": "An Efficient Framework for Global Non-Convex Polynomial Optimization\n  with Nonlinear Polynomial Constraints",
            "updated": "2023-11-03T17:10:26Z",
            "published": "2023-11-03T17:10:26Z",
            "summary": "We present an efficient framework for solving constrained global non-convex\npolynomial optimization problems. We prove the existence of an equivalent\nnonlinear reformulation of such problems that possesses essentially no spurious\nlocal minima. We show through numerical experiments that polynomial scaling in\ndimension and degree is achievable for computing the optimal value and location\nof previously intractable global constrained polynomial optimization problems\nin high dimension.",
            "author": [
                "Mitchell Tong Harris",
                "Pierre-David Letourneau",
                "Dalton Jones",
                "M. Harper Langston"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02037v1",
                "http://arxiv.org/pdf/2311.02037v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.MS",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02036v1",
            "title": "Pits on Jupiter Family Comets and the age of cometary surfaces",
            "updated": "2023-11-03T17:09:35Z",
            "published": "2023-11-03T17:09:35Z",
            "summary": "Large and deep depressions, also known as pits, are observed at the surface\nof all Jupiter Family Comets (JFCs) imaged by spacecraft missions. They offer\nthe opportunity to glimpse into sub-surface characteristics of comet nuclei,\nand study the complex interplay between surface structures and cometary\nactivity. This work investigates the evolution of pits at the surface of\n81P/Wild 2, 9P/Tempel 1 and 103P/Hartley 2, in continuation of the work by\nBenseguane et al. (2022), on 67P/Churyumov-Gerasimenko. Pits are selected\nacross the surface of each nucleus, and high-resolution shape models are used\nto compute the energy they receive. A thermal evolution model is applied to\nconstrain how cometary activity sustained under current illumination conditions\ncould modify them. Similarly to what was found for 67P, we show erosion\nresulting from water-driven activity is primarily controlled by seasonal\npatterns, unique to each comet as a consequence of their shape and rotational\nproperties. However, progressive erosion sustained after multiple perihelion\npassages is not able to carve any of the observed pits. Instead, cometary\nactivity tends to erase sharp morphological features: they become wider and\nshallower over time. Our results reinforce the evolutionary sequence evidenced\nfrom independent measurables to transform \"young\" cometary surfaces, with sharp\nsurface topography prone to outbursts, into \"old\" cometary surfaces. Finally,\nwe suggest that the mechanism at the origin of pits on JFCs should be able to\ncarve these structures in a region of the solar system where water ice does not\nsublimate: the Centaur phase thus appears critical to understand JFCs surface\nproperties.",
            "author": [
                "Aur\u00e9lie Guilbert-Lepoutre",
                "Selma Benseguane",
                "Laurine Martinien",
                "J\u00e9r\u00e9mie Lasue",
                "S\u00e9bastien Besse",
                "Bj\u00f6rn Grieger",
                "Arnaud Beth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02036v1",
                "http://arxiv.org/pdf/2311.02036v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01623v1",
            "title": "VQPy: An Object-Oriented Approach to Modern Video Analytics",
            "updated": "2023-11-03T16:58:10Z",
            "published": "2023-11-03T16:58:10Z",
            "summary": "Video analytics is widely used in contemporary systems and services. At the\nforefront of video analytics are video queries that users develop to find\nobjects of particular interest. Building upon the insight that video objects\n(e.g., human, animals, cars, etc.), the center of video analytics, are similar\nin spirit to objects modeled by traditional object-oriented languages, we\npropose to develop an object-oriented approach to video analytics. This\napproach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant\nwith constructs that make it easy for users to express video objects and their\ninteractions$\\unicode{x2015}$as well as an extensible backend that can\nautomatically construct and optimize pipelines based on video objects. We have\nimplemented and open-sourced VQPy, which has been productized in Cisco as part\nof its DeepVision framework.",
            "author": [
                "Shan Yu",
                "Zhenting Zhu",
                "Yu Chen",
                "Hanchen Xu",
                "Pengzhan Zhao",
                "Yang Wang",
                "Arthi Padmanabhan",
                "Hugo Latapie",
                "Harry Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01623v1",
                "http://arxiv.org/pdf/2311.01623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16138v1",
            "title": "After-Stroke Arm Paresis Detection using Kinematic Data",
            "updated": "2023-11-03T16:56:02Z",
            "published": "2023-11-03T16:56:02Z",
            "summary": "This paper presents an approach for detecting unilateral arm\nparalysis/weakness using kinematic data. Our method employs temporal\nconvolution networks and recurrent neural networks, guided by knowledge\ndistillation, where we use inertial measurement units attached to the body to\ncapture kinematic information such as acceleration, rotation, and flexion of\nbody joints during an action. This information is then analyzed to recognize\nbody actions and patterns. Our proposed network achieves a high paretic\ndetection accuracy of 97.99\\%, with an action classification accuracy of\n77.69\\%, through knowledge sharing. Furthermore, by incorporating causal\nreasoning, we can gain additional insights into the patient's condition, such\nas their Fugl-Meyer assessment score or impairment level based on the machine\nlearning result. Overall, our approach demonstrates the potential of using\nkinematic data and machine learning for detecting arm paralysis/weakness. The\nresults suggest that our method could be a useful tool for clinicians and\nhealthcare professionals working with patients with this condition.",
            "author": [
                "Kenneth Lai",
                "Mohammed Almekhlafi",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16138v1",
                "http://arxiv.org/pdf/2311.16138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14686v1",
            "title": "Causal Models Applied to the Patterns of Human Migration due to Climate\n  Change",
            "updated": "2023-11-03T16:54:16Z",
            "published": "2023-11-03T16:54:16Z",
            "summary": "The impacts of mass migration, such as crisis induced by climate change,\nextend beyond environmental concerns and can greatly affect social\ninfrastructure and public services, such as education, healthcare, and\nsecurity. These crises exacerbate certain elements like cultural barriers, and\ndiscrimination by amplifying the challenges faced by these affected\ncommunities. This paper proposes an innovative approach to address migration\ncrises in the context of crisis management through a combination of modeling\nand imbalance assessment tools. By employing deep learning for forecasting and\nintegrating causal reasoning via Bayesian networks, this methodology enables\nthe evaluation of imbalances and risks in the socio-technological landscape,\nproviding crucial insights for informed decision-making. Through this\nframework, critical systems can be analyzed to understand how fluctuations in\nmigration levels may impact them, facilitating effective crisis governance\nstrategies.",
            "author": [
                "Kenneth Lai",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14686v1",
                "http://arxiv.org/pdf/2311.14686v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03385v1",
            "title": "Intelligent Stress Assessment for e-Coaching",
            "updated": "2023-11-03T16:51:44Z",
            "published": "2023-11-03T16:51:44Z",
            "summary": "This paper considers the adaptation of the e-coaching concept at times of\nemergencies and disasters, through aiding the e-coaching with intelligent tools\nfor monitoring humans' affective state. The states such as anxiety, panic,\navoidance, and stress, if properly detected, can be mitigated using the\ne-coaching tactic and strategy. In this work, we focus on a stress monitoring\nassistant tool developed on machine learning techniques. We provide the results\nof an experimental study using the proposed method.",
            "author": [
                "Kenneth Lai",
                "Svetlana Yanushkevich",
                "Vlad Shmerko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03385v1",
                "http://arxiv.org/pdf/2311.03385v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02025v1",
            "title": "Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive\n  Language Detection",
            "updated": "2023-11-03T16:51:07Z",
            "published": "2023-11-03T16:51:07Z",
            "summary": "Cross-lingual transfer learning from high-resource to medium and low-resource\nlanguages has shown encouraging results. However, the scarcity of resources in\ntarget languages remains a challenge. In this work, we resort to data\naugmentation and continual pre-training for domain adaptation to improve\ncross-lingual abusive language detection. For data augmentation, we analyze two\nexisting techniques based on vicinal risk minimization and propose MIXAG, a\nnovel data augmentation method which interpolates pairs of instances based on\nthe angle of their representations. Our experiments involve seven languages\ntypologically distinct from English and three different domains. The results\nreveal that the data augmentation strategies can enhance few-shot cross-lingual\nabusive language detection. Specifically, we observe that consistently in all\ntarget languages, MIXAG improves significantly in multidomain and multilingual\nenvironments. Finally, we show through an error analysis how the domain\nadaptation can favour the class of abusive texts (reducing false negatives),\nbut at the same time, declines the precision of the abusive language detection\nmodel.",
            "author": [
                "Gretel Liz De la Pe\u00f1a Sarrac\u00e9n",
                "Paolo Rosso",
                "Robert Litschko",
                "Goran Glava\u0161",
                "Simone Paolo Ponzetto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02025v1",
                "http://arxiv.org/pdf/2311.02025v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02142v1",
            "title": "Sparse Training of Discrete Diffusion Models for Graph Generation",
            "updated": "2023-11-03T16:50:26Z",
            "published": "2023-11-03T16:50:26Z",
            "summary": "Generative models for graphs often encounter scalability challenges due to\nthe inherent need to predict interactions for every node pair. Despite the\nsparsity often exhibited by real-world graphs, the unpredictable sparsity\npatterns of their adjacency matrices, stemming from their unordered nature,\nleads to quadratic computational complexity. In this work, we introduce\nSparseDiff, a denoising diffusion model for graph generation that is able to\nexploit sparsity during its training phase. At the core of SparseDiff is a\nmessage-passing neural network tailored to predict only a subset of edges\nduring each forward pass. When combined with a sparsity-preserving noise model,\nthis model can efficiently work with edge lists representations of graphs,\npaving the way for scalability to much larger structures. During the sampling\nphase, SparseDiff iteratively populates the adjacency matrix from its prior\nstate, ensuring prediction of the full graph while controlling memory\nutilization. Experimental results show that SparseDiff simultaneously matches\nstate-of-the-art in generation performance on both small and large graphs,\nhighlighting the versatility of our method.",
            "author": [
                "Yiming Qin",
                "Clement Vignac",
                "Pascal Frossard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02142v1",
                "http://arxiv.org/pdf/2311.02142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02018v1",
            "title": "Active Reasoning in an Open-World Environment",
            "updated": "2023-11-03T16:24:34Z",
            "published": "2023-11-03T16:24:34Z",
            "summary": "Recent advances in vision-language learning have achieved notable success on\ncomplete-information question-answering datasets through the integration of\nextensive world knowledge. Yet, most models operate passively, responding to\nquestions based on pre-stored knowledge. In stark contrast, humans possess the\nability to actively explore, accumulate, and reason using both newfound and\nexisting information to tackle incomplete-information questions. In response to\nthis gap, we introduce $Conan$, an interactive open-world environment devised\nfor the assessment of active reasoning. $Conan$ facilitates active exploration\nand promotes multi-round abductive inference, reminiscent of rich, open-world\nsettings like Minecraft. Diverging from previous works that lean primarily on\nsingle-round deduction via instruction following, $Conan$ compels agents to\nactively interact with their surroundings, amalgamating new evidence with prior\nknowledge to elucidate events from incomplete observations. Our analysis on\n$Conan$ underscores the shortcomings of contemporary state-of-the-art models in\nactive exploration and understanding complex scenarios. Additionally, we\nexplore Abduction from Deduction, where agents harness Bayesian rules to recast\nthe challenge of abduction as a deductive process. Through $Conan$, we aim to\ngalvanize advancements in active reasoning and set the stage for the next\ngeneration of artificial intelligence agents adept at dynamically engaging in\nenvironments.",
            "author": [
                "Manjie Xu",
                "Guangyuan Jiang",
                "Wei Liang",
                "Chi Zhang",
                "Yixin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02018v1",
                "http://arxiv.org/pdf/2311.02018v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02014v1",
            "title": "Bi-Level-Based Inverse Stochastic Optimal Control",
            "updated": "2023-11-03T16:19:58Z",
            "published": "2023-11-03T16:19:58Z",
            "summary": "In this paper, we propose a new algorithm to solve the Inverse Stochastic\nOptimal Control (ISOC) problem of the linear-quadratic sensorimotor (LQS)\ncontrol model. The LQS model represents the current state-of-the-art in\ndescribing goal-directed human movements. The ISOC problem aims at determining\nthe cost function and noise scaling matrices of the LQS model from measurement\ndata since both parameter types influence the statistical moments predicted by\nthe model and are unknown in practice. We prove global convergence for our new\nalgorithm and at a numerical example, validate the theoretical assumptions of\nour method. By comprehensive simulations, the influence of the tuning\nparameters of our algorithm on convergence behavior and computation time is\nanalyzed. The new algorithm computes ISOC solutions nearly 33 times faster than\nthe single previously existing ISOC algorithm.",
            "author": [
                "Philipp Karg",
                "Manuel Hess",
                "Balint Varga",
                "S\u00f6ren Hohmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02014v1",
                "http://arxiv.org/pdf/2311.02014v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02010v1",
            "title": "A cast of thousands: How the IDEAS Productivity project has advanced\n  software productivity and sustainability",
            "updated": "2023-11-03T16:14:17Z",
            "published": "2023-11-03T16:14:17Z",
            "summary": "Computational and data-enabled science and engineering are revolutionizing\nadvances throughout science and society, at all scales of computing. For\nexample, teams in the U.S. DOE Exascale Computing Project have been tackling\nnew frontiers in modeling, simulation, and analysis by exploiting unprecedented\nexascale computing capabilities-building an advanced software ecosystem that\nsupports next-generation applications and addresses disruptive changes in\ncomputer architectures. However, concerns are growing about the productivity of\nthe developers of scientific software, its sustainability, and the\ntrustworthiness of the results that it produces. Members of the IDEAS project\nserve as catalysts to address these challenges through fostering software\ncommunities, incubating and curating methodologies and resources, and\ndisseminating knowledge to advance developer productivity and software\nsustainability. This paper discusses how these synergistic activities are\nadvancing scientific discovery-mitigating technical risks by building a firmer\nfoundation for reproducible, sustainable science at all scales of computing,\nfrom laptops to clusters to exascale and beyond.",
            "author": [
                "Lois Curfman McInnes",
                "Michael Heroux",
                "David E. Bernholdt",
                "Anshu Dubey",
                "Elsa Gonsiorowski",
                "Rinku Gupta",
                "Osni Marques",
                "J. David Moulton",
                "Hai Ah Nam",
                "Boyana Norris",
                "Elaine M. Raybourn",
                "Jim Willenbring",
                "Ann Almgren",
                "Ross Bartlett",
                "Kita Cranfill",
                "Stephen Fickas",
                "Don Frederick",
                "William Godoy",
                "Patricia Grubel",
                "Rebecca Hartman-Baker",
                "Axel Huebl",
                "Rose Lynch",
                "Addi Malviya Thakur",
                "Reed Milewicz",
                "Mark C. Miller",
                "Miranda Mundt",
                "Erik Palmer",
                "Suzanne Parete-Koon",
                "Megan Phinney",
                "Katherine Riley",
                "David M. Rogers",
                "Ben Sims",
                "Deborah Stevens",
                "Gregory R. Watson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02010v1",
                "http://arxiv.org/pdf/2311.02010v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02007v1",
            "title": "Towards Unsupervised Object Detection From LiDAR Point Clouds",
            "updated": "2023-11-03T16:12:01Z",
            "published": "2023-11-03T16:12:01Z",
            "summary": "In this paper, we study the problem of unsupervised object detection from 3D\npoint clouds in self-driving scenes. We present a simple yet effective method\nthat exploits (i) point clustering in near-range areas where the point clouds\nare dense, (ii) temporal consistency to filter out noisy unsupervised\ndetections, (iii) translation equivariance of CNNs to extend the auto-labels to\nlong range, and (iv) self-supervision for improving on its own. Our approach,\nOYSTER (Object Discovery via Spatio-Temporal Refinement), does not impose\nconstraints on data collection (such as repeated traversals of the same\nlocation), is able to detect objects in a zero-shot manner without supervised\nfinetuning (even in sparse, distant regions), and continues to self-improve\ngiven more rounds of iterative self-training. To better measure model\nperformance in self-driving scenarios, we propose a new planning-centric\nperception metric based on distance-to-collision. We demonstrate that our\nunsupervised object detector significantly outperforms unsupervised baselines\non PandaSet and Argoverse 2 Sensor dataset, showing promise that\nself-supervision combined with object priors can enable object discovery in the\nwild. For more information, visit the project website:\nhttps://waabi.ai/research/oyster",
            "author": [
                "Lunjun Zhang",
                "Anqi Joyce Yang",
                "Yuwen Xiong",
                "Sergio Casas",
                "Bin Yang",
                "Mengye Ren",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02007v1",
                "http://arxiv.org/pdf/2311.02007v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02004v1",
            "title": "Investigation of Random Laser in the Machine Learning Approach",
            "updated": "2023-11-03T16:07:24Z",
            "published": "2023-11-03T16:07:24Z",
            "summary": "Machine Learning and Deep Learning are computational tools that fall within\nthe domain of artificial intelligence. In recent years, numerous research works\nhave advanced the application of machine and deep learning in various fields,\nincluding optics and photonics. In this article, we employ machine learning\nalgorithms to investigate the feasibility of predicting a stochastic phenomena:\nrandom laser emissions. Our results indicate that machine and deep learning\nhave the capacity to accurately reproduce fluctuations characteristic of random\nlasers. By employing simple supervised learning algorithms, we demonstrate that\nthe random laser intensity fluctuations can be predicted using spontaneous\nemission and pump intensity as input parameters in the models. Applications\nbased on the demonstrated results are discussed.\n  Keywords: Machine Learning, Deep Learning, Random Laser.",
            "author": [
                "Emanuel P. Santos",
                "Rodrigo F. Silva",
                "C\u00e9lio V. T. Maciel",
                "Daniel F. Luz",
                "Pedro F. A. Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02004v1",
                "http://arxiv.org/pdf/2311.02004v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02003v1",
            "title": "A Structured Pruning Algorithm for Model-based Deep Learning",
            "updated": "2023-11-03T16:05:51Z",
            "published": "2023-11-03T16:05:51Z",
            "summary": "There is a growing interest in model-based deep learning (MBDL) for solving\nimaging inverse problems. MBDL networks can be seen as iterative algorithms\nthat estimate the desired image using a physical measurement model and a\nlearned image prior specified using a convolutional neural net (CNNs). The\niterative nature of MBDL networks increases the test-time computational\ncomplexity, which limits their applicability in certain large-scale\napplications. We address this issue by presenting structured pruning algorithm\nfor model-based deep learning (SPADE) as the first structured pruning algorithm\nfor MBDL networks. SPADE reduces the computational complexity of CNNs used\nwithin MBDL networks by pruning its non-essential weights. We propose three\ndistinct strategies to fine-tune the pruned MBDL networks to minimize the\nperformance loss. Each fine-tuning strategy has a unique benefit that depends\non the presence of a pre-trained model and a high-quality ground truth. We\nvalidate SPADE on two distinct inverse problems, namely compressed sensing MRI\nand image super-resolution. Our results highlight that MBDL models pruned by\nSPADE can achieve substantial speed up in testing time while maintaining\ncompetitive performance.",
            "author": [
                "Chicago Park",
                "Weijie Gan",
                "Zihao Zou",
                "Yuyang Hu",
                "Zhixin Sun",
                "Ulugbek S. Kamilov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02003v1",
                "http://arxiv.org/pdf/2311.02003v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01996v1",
            "title": "Detection of keratoconus Diseases using deep Learning",
            "updated": "2023-11-03T15:49:06Z",
            "published": "2023-11-03T15:49:06Z",
            "summary": "One of the most serious corneal disorders, keratoconus is difficult to\ndiagnose in its early stages and can result in blindness. This illness, which\noften appears in the second decade of life, affects people of all sexes and\nraces. Convolutional neural networks (CNNs), one of the deep learning\napproaches, have recently come to light as particularly promising tools for the\naccurate and timely diagnosis of keratoconus. The purpose of this study was to\nevaluate how well different D-CNN models identified keratoconus-related\ndiseases. To be more precise, we compared five different CNN-based deep\nlearning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19,\nXception). In our comprehensive experimental analysis, the DenseNet201-based\nmodel performed very well in keratoconus disease identification in our\nextensive experimental research. This model outperformed its D-CNN equivalents,\nwith an astounding accuracy rate of 89.14% in three crucial classes:\nKeratoconus, Normal, and Suspect. The results demonstrate not only the\nstability and robustness of the model but also its practical usefulness in\nreal-world applications for accurate and dependable keratoconus identification.\nIn addition, D-CNN DenseNet201 performs extraordinarily well in terms of\nprecision, recall rates, and F1 scores in addition to accuracy. These measures\nvalidate the model's usefulness as an effective diagnostic tool by highlighting\nits capacity to reliably detect instances of keratoconus and to reduce false\npositives and negatives.",
            "author": [
                "AKM Enzam-Ul Haque",
                "Golam Rabbany",
                "Md. Siam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01996v1",
                "http://arxiv.org/pdf/2311.01996v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01994v1",
            "title": "Obtaining Explainable Classification Models using Distributionally\n  Robust Optimization",
            "updated": "2023-11-03T15:45:34Z",
            "published": "2023-11-03T15:45:34Z",
            "summary": "Model explainability is crucial for human users to be able to interpret how a\nproposed classifier assigns labels to data based on its feature values. We\nstudy generalized linear models constructed using sets of feature value rules,\nwhich can capture nonlinear dependencies and interactions. An inherent\ntrade-off exists between rule set sparsity and its prediction accuracy. It is\ncomputationally expensive to find the right choice of sparsity -- e.g., via\ncross-validation -- with existing methods. We propose a new formulation to\nlearn an ensemble of rule sets that simultaneously addresses these competing\nfactors. Good generalization is ensured while keeping computational costs low\nby utilizing distributionally robust optimization. The formulation utilizes\ncolumn generation to efficiently search the space of rule sets and constructs a\nsparse ensemble of rule sets, in contrast with techniques like random forests\nor boosting and their variants. We present theoretical results that motivate\nand justify the use of our distributionally robust formulation. Extensive\nnumerical experiments establish that our method improves over competing methods\n-- on a large set of publicly available binary classification problem instances\n-- with respect to one or more of the following metrics: generalization\nquality, computational cost, and explainability.",
            "author": [
                "Sanjeeb Dash",
                "Soumyadip Ghosh",
                "Joao Goncalves",
                "Mark S. Squillante"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01994v1",
                "http://arxiv.org/pdf/2311.01994v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01989v2",
            "title": "Leveraging Large-Scale Pretrained Vision Foundation Models for\n  Label-Efficient 3D Point Cloud Segmentation",
            "updated": "2023-11-06T08:18:26Z",
            "published": "2023-11-03T15:41:15Z",
            "summary": "Recently, large-scale pre-trained models such as Segment-Anything Model (SAM)\nand Contrastive Language-Image Pre-training (CLIP) have demonstrated remarkable\nsuccess and revolutionized the field of computer vision. These foundation\nvision models effectively capture knowledge from a large-scale broad data with\ntheir vast model parameters, enabling them to perform zero-shot segmentation on\npreviously unseen data without additional training. While they showcase\ncompetence in 2D tasks, their potential for enhancing 3D scene understanding\nremains relatively unexplored. To this end, we present a novel framework that\nadapts various foundational models for the 3D point cloud segmentation task.\nOur approach involves making initial predictions of 2D semantic masks using\ndifferent large vision models. We then project these mask predictions from\nvarious frames of RGB-D video sequences into 3D space. To generate robust 3D\nsemantic pseudo labels, we introduce a semantic label fusion strategy that\neffectively combines all the results via voting. We examine diverse scenarios,\nlike zero-shot learning and limited guidance from sparse 2D point labels, to\nassess the pros and cons of different vision foundation models. Our approach is\nexperimented on ScanNet dataset for 3D indoor scenes, and the results\ndemonstrate the effectiveness of adopting general 2D foundation models on\nsolving 3D point cloud segmentation tasks.",
            "author": [
                "Shichao Dong",
                "Fayao Liu",
                "Guosheng Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01989v2",
                "http://arxiv.org/pdf/2311.01989v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01987v1",
            "title": "Generalization of Graph-Based Active Learning Relaxation Strategies\n  Across Materials",
            "updated": "2023-11-03T15:40:20Z",
            "published": "2023-11-03T15:40:20Z",
            "summary": "Although density functional theory (DFT) has aided in accelerating the\ndiscovery of new materials, such calculations are computationally expensive,\nespecially for high-throughput efforts. This has prompted an explosion in\nexploration of machine learning assisted techniques to improve the\ncomputational efficiency of DFT. In this study, we present a comprehensive\ninvestigation of the broader application of Finetuna, an active learning\nframework to accelerate structural relaxation in DFT with prior information\nfrom Open Catalyst Project pretrained graph neural networks. We explore the\nchallenges associated with out-of-domain systems: alcohol ($C_{>2}$) on metal\nsurfaces as larger adsorbates, metal-oxides with spin polarization, and\nthree-dimensional (3D) structures like zeolites and metal-organic-frameworks.\nBy pre-training machine learning models on large datasets and fine-tuning the\nmodel along the simulation, we demonstrate the framework's ability to conduct\nrelaxations with fewer DFT calculations. Depending on the similarity of the\ntest systems to the training systems, a more conservative querying strategy is\napplied. Our best-performing Finetuna strategy reduces the number of DFT\nsingle-point calculations by 80% for alcohols and 3D structures, and 42% for\noxide systems.",
            "author": [
                "Xiaoxiao Wang",
                "Joseph Musielewicz",
                "Richard Tran",
                "Sudheesh Kumar Ethirajan",
                "Xiaoyan Fu",
                "Hilda Mera",
                "John R. Kitchin",
                "Rachel C. Kurchin",
                "Zachary W. Ulissi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01987v1",
                "http://arxiv.org/pdf/2311.01987v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01986v1",
            "title": "Combining scattering experiments and colloid theory to characterize\n  charge effects in concentrated antibody solutions",
            "updated": "2023-11-03T15:39:44Z",
            "published": "2023-11-03T15:39:44Z",
            "summary": "Charges and their contribution to protein-protein interactions are essential\nfor the key structural and dynamic properties of monoclonal antibody (mAb)\nsolutions. In fact, they influence the apparent molecular weight, the static\nstructure factor, the collective diffusion coefficient or the relative\nviscosity and their concentration dependence. Further, charges play an\nimportant role in the colloidal stability of mAbs. There exist standard\nexperimental tools to characterise mAb net charges such as the measurement of\nthe electrophoretic mobility, the second virial coefficient, or the diffusion\ninteraction parameter. However, the resulting values are difficult to be\ndirectly related to the actual overall net charge of the antibody and to\ntheoretical predictions based on its known molecular structure. Here, we report\nthe results of a systematic investigation of the solution properties of a\ncharged IgG1 mAb as a function of concentration and ionic strength using a\ncombination of electrophoretic measurements, static and dynamic light\nscattering, small-angle x-ray scattering (SAXS), and tracer particle-based\nmicrorheology. We analyse and interpret the experimental results using\nestablished colloid theory and coarse-grained computer simulations. We discuss\nthe potential and limits of colloidal models for the description of interaction\neffects of charged mAbs, in particular pointing out the importance of\nincorporating shape and charge anisotropy when attempting to predict structural\nand dynamic solution properties at high concentrations.",
            "author": [
                "Alessandro Gulotta",
                "Marco Polimeni",
                "Samuel Lenton",
                "Charles G. Starr",
                "Jonathan S. Kingsbury",
                "Anna Stradner",
                "Emanuela Zaccarelli",
                "Peter Schurtenberger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01986v1",
                "http://arxiv.org/pdf/2311.01986v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01985v1",
            "title": "Maximizing Portfolio Predictability with Machine Learning",
            "updated": "2023-11-03T15:38:10Z",
            "published": "2023-11-03T15:38:10Z",
            "summary": "We construct the maximally predictable portfolio (MPP) of stocks using\nmachine learning. Solving for the optimal constrained weights in the\nmulti-asset MPP gives portfolios with a high monthly coefficient of\ndetermination, given the sample covariance matrix of predicted return errors\nfrom a machine learning model. Various models for the covariance matrix are\ntested. The MPPs of S&P 500 index constituents with estimated returns from\nElastic Net, Random Forest, and Support Vector Regression models can outperform\nor underperform the index depending on the time period. Portfolios that take\nadvantage of the high predictability of the MPP's returns and employ a Kelly\ncriterion style strategy consistently outperform the benchmark.",
            "author": [
                "Michael Pinelis",
                "David Ruppert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01985v1",
                "http://arxiv.org/pdf/2311.01985v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01984v1",
            "title": "Optimal Image Transport on Sparse Dictionaries",
            "updated": "2023-11-03T15:37:01Z",
            "published": "2023-11-03T15:37:01Z",
            "summary": "In this paper, we derive a novel optimal image transport algorithm over\nsparse dictionaries by taking advantage of Sparse Representation (SR) and\nOptimal Transport (OT). Concisely, we design a unified optimization framework\nin which the individual image features (color, textures, styles, etc.) are\nencoded using sparse representation compactly, and an optimal transport plan is\nthen inferred between two learned dictionaries in accordance with the encoding\nprocess. This paradigm gives rise to a simple but effective way for\nsimultaneous image representation and transformation, which is also empirically\nsolvable because of the moderate size of sparse coding and optimal transport\nsub-problems. We demonstrate its versatility and many benefits to different\nimage-to-image translation tasks, in particular image color transform and\nartistic style transfer, and show the plausible results for photo-realistic\ntransferred effects.",
            "author": [
                "Junqing Huang",
                "Haihui Wang",
                "Andreas Weiermann",
                "Michael Ruzhansky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01984v1",
                "http://arxiv.org/pdf/2311.01984v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01981v1",
            "title": "ProSG: Using Prompt Synthetic Gradients to Alleviate Prompt Forgetting\n  of RNN-like Language Models",
            "updated": "2023-11-03T15:34:02Z",
            "published": "2023-11-03T15:34:02Z",
            "summary": "RNN-like language models are getting renewed attention from NLP researchers\nin recent years and several models have made significant progress, which\ndemonstrates performance comparable to traditional transformers. However, due\nto the recurrent nature of RNNs, this kind of language model can only store\ninformation in a set of fixed-length state vectors. As a consequence, they\nstill suffer from forgetfulness though after a lot of improvements and\noptimizations, when given complex instructions or prompts. As the prompted\ngeneration is the main and most concerned function of LMs, solving the problem\nof forgetting in the process of generation is no wonder of vital importance. In\nthis paper, focusing on easing the prompt forgetting during generation, we\nproposed an architecture to teach the model memorizing prompt during generation\nby synthetic gradient. To force the model to memorize the prompt, we derive the\nstates that encode the prompt, then transform it into model parameter\nmodification using low-rank gradient approximation, which hard-codes the prompt\ninto model parameters temporarily. We construct a dataset for experiments, and\nthe results have demonstrated the effectiveness of our method in solving the\nproblem of forgetfulness in the process of prompted generation. We will release\nall the code upon acceptance.",
            "author": [
                "Haotian Luo",
                "Kunming Wu",
                "Cheng Dai",
                "Sixian Ding",
                "Xinhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01981v1",
                "http://arxiv.org/pdf/2311.01981v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01976v1",
            "title": "A Corrected Inexact Proximal Augmented Lagrangian Method with a Relative\n  Error Criterion for a Class of Group-quadratic Regularized Optimal Transport\n  Problems",
            "updated": "2023-11-03T15:29:47Z",
            "published": "2023-11-03T15:29:47Z",
            "summary": "The optimal transport (OT) problem and its related problems have attracted\nsignificant attention and have been extensively studied in various\napplications. In this paper, we focus on a class of group-quadratic regularized\nOT problems which aim to find solutions with specialized structures that are\nadvantageous in practical scenarios. To solve this class of problems, we\npropose a corrected inexact proximal augmented Lagrangian method (ciPALM), with\nthe subproblems being solved by the semi-smooth Newton ({\\sc Ssn}) method. We\nestablish that the proposed method exhibits appealing convergence properties\nunder mild conditions. Moreover, our ciPALM distinguishes itself from the\nrecently developed semismooth Newton-based inexact proximal augmented\nLagrangian ({\\sc Snipal}) method for linear programming. Specifically, {\\sc\nSnipal} uses an absolute error criterion for the approximate minimization of\nthe subproblem for which a summable sequence of tolerance parameters needs to\nbe pre-specified for practical implementations. In contrast, our ciPALM adopts\na relative error criterion with a \\textit{single} tolerance parameter, which\nwould be more friendly to tune from computational and implementation\nperspectives. These favorable properties position our ciPALM as a promising\ncandidate for tackling large-scale problems. Various numerical studies validate\nthe effectiveness of employing a relative error criterion for the inexact\nproximal augmented Lagrangian method, and also demonstrate that our ciPALM is\ncompetitive for solving large-scale group-quadratic regularized OT problems.",
            "author": [
                "Lei Yang",
                "Ling Liang",
                "Hong T. M. Chu",
                "Kim-Chuan Toh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01976v1",
                "http://arxiv.org/pdf/2311.01976v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "90C05, 90C06, 90C25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01968v1",
            "title": "Latent Diffusion Model for Conditional Reservoir Facies Generation",
            "updated": "2023-11-03T15:10:05Z",
            "published": "2023-11-03T15:10:05Z",
            "summary": "Creating accurate and geologically realistic reservoir facies based on\nlimited measurements is crucial for field development and reservoir management,\nespecially in the oil and gas sector. Traditional two-point geostatistics,\nwhile foundational, often struggle to capture complex geological patterns.\nMulti-point statistics offers more flexibility, but comes with its own\nchallenges. With the rise of Generative Adversarial Networks (GANs) and their\nsuccess in various fields, there has been a shift towards using them for facies\ngeneration. However, recent advances in the computer vision domain have shown\nthe superiority of diffusion models over GANs. Motivated by this, a novel\nLatent Diffusion Model is proposed, which is specifically designed for\nconditional generation of reservoir facies. The proposed model produces\nhigh-fidelity facies realizations that rigorously preserve conditioning data.\nIt significantly outperforms a GAN-based alternative.",
            "author": [
                "Daesoo Lee",
                "Oscar Ovanger",
                "Jo Eidsvik",
                "Erlend Aune",
                "Jacob Skauvold",
                "Ragnar Hauge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01968v1",
                "http://arxiv.org/pdf/2311.01968v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01967v1",
            "title": "The language of prompting: What linguistic properties make a prompt\n  successful?",
            "updated": "2023-11-03T15:03:36Z",
            "published": "2023-11-03T15:03:36Z",
            "summary": "The latest generation of LLMs can be prompted to achieve impressive zero-shot\nor few-shot performance in many NLP tasks. However, since performance is highly\nsensitive to the choice of prompts, considerable effort has been devoted to\ncrowd-sourcing prompts or designing methods for prompt optimisation. Yet, we\nstill lack a systematic understanding of how linguistic properties of prompts\ncorrelate with task performance. In this work, we investigate how LLMs of\ndifferent sizes, pre-trained and instruction-tuned, perform on prompts that are\nsemantically equivalent, but vary in linguistic structure. We investigate both\ngrammatical properties such as mood, tense, aspect and modality, as well as\nlexico-semantic variation through the use of synonyms. Our findings contradict\nthe common assumption that LLMs achieve optimal performance on lower perplexity\nprompts that reflect language use in pretraining or instruction-tuning data.\nPrompts transfer poorly between datasets or models, and performance cannot\ngenerally be explained by perplexity, word frequency, ambiguity or prompt\nlength. Based on our results, we put forward a proposal for a more robust and\ncomprehensive evaluation standard for prompting research.",
            "author": [
                "Alina Leidinger",
                "Robert van Rooij",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01967v1",
                "http://arxiv.org/pdf/2311.01967v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01966v1",
            "title": "Depth-guided Free-space Segmentation for a Mobile Robot",
            "updated": "2023-11-03T15:02:43Z",
            "published": "2023-11-03T15:02:43Z",
            "summary": "Accurate indoor free-space segmentation is a challenging task due to the\ncomplexity and the dynamic nature that indoor environments exhibit. We propose\nan indoors free-space segmentation method that associates large depth values\nwith navigable regions. Our method leverages an unsupervised masking technique\nthat, using positive instances, generates segmentation labels based on textural\nhomogeneity and depth uniformity. Moreover, we generate superpixels\ncorresponding to areas of higher depth and align them with features extracted\nfrom a Dense Prediction Transformer (DPT). Using the estimated free-space masks\nand the DPT feature representation, a SegFormer model is fine-tuned on our\ncustom-collected indoor dataset. Our experiments demonstrate sufficient\nperformance in intricate scenarios characterized by cluttered obstacles and\nchallenging identification of free space.",
            "author": [
                "Christos Sevastopoulos",
                "Joey Hussain",
                "Stasinos Konstantopoulos",
                "Vangelis Karkaletsis",
                "Fillia Makedon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01966v1",
                "http://arxiv.org/pdf/2311.01966v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01964v1",
            "title": "Don't Make Your LLM an Evaluation Benchmark Cheater",
            "updated": "2023-11-03T14:59:54Z",
            "published": "2023-11-03T14:59:54Z",
            "summary": "Large language models~(LLMs) have greatly advanced the frontiers of\nartificial intelligence, attaining remarkable improvement in model capacity. To\nassess the model performance, a typical approach is to construct evaluation\nbenchmarks for measuring the ability level of LLMs in different aspects.\nDespite that a number of high-quality benchmarks have been released, the\nconcerns about the appropriate use of these benchmarks and the fair comparison\nof different models are increasingly growing. Considering these concerns, in\nthis paper, we discuss the potential risk and impact of inappropriately using\nevaluation benchmarks and misleadingly interpreting the evaluation results.\nSpecially, we focus on a special issue that would lead to inappropriate\nevaluation, \\ie \\emph{benchmark leakage}, referring that the data related to\nevaluation sets is occasionally used for model training. This phenomenon now\nbecomes more common since pre-training data is often prepared ahead of model\ntest. We conduct extensive experiments to study the effect of benchmark\nleverage, and find that it can dramatically boost the evaluation results, which\nwould finally lead to an unreliable assessment of model performance. To improve\nthe use of existing evaluation benchmarks, we finally present several\nguidelines for both LLM developers and benchmark maintainers. We hope this work\ncan draw attention to appropriate training and evaluation of LLMs.",
            "author": [
                "Kun Zhou",
                "Yutao Zhu",
                "Zhipeng Chen",
                "Wentong Chen",
                "Wayne Xin Zhao",
                "Xu Chen",
                "Yankai Lin",
                "Ji-Rong Wen",
                "Jiawei Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01964v1",
                "http://arxiv.org/pdf/2311.01964v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01961v1",
            "title": "Assessing Fidelity in XAI post-hoc techniques: A Comparative Study with\n  Ground Truth Explanations Datasets",
            "updated": "2023-11-03T14:57:24Z",
            "published": "2023-11-03T14:57:24Z",
            "summary": "The evaluation of the fidelity of eXplainable Artificial Intelligence (XAI)\nmethods to their underlying models is a challenging task, primarily due to the\nabsence of a ground truth for explanations. However, assessing fidelity is a\nnecessary step for ensuring a correct XAI methodology. In this study, we\nconduct a fair and objective comparison of the current state-of-the-art XAI\nmethods by introducing three novel image datasets with reliable ground truth\nfor explanations. The primary objective of this comparison is to identify\nmethods with low fidelity and eliminate them from further research, thereby\npromoting the development of more trustworthy and effective XAI techniques. Our\nresults demonstrate that XAI methods based on the backpropagation of output\ninformation to input yield higher accuracy and reliability compared to methods\nrelying on sensitivity analysis or Class Activation Maps (CAM). However, the\nbackpropagation method tends to generate more noisy saliency maps. These\nfindings have significant implications for the advancement of XAI methods,\nenabling the elimination of erroneous explanations and fostering the\ndevelopment of more robust and reliable XAI.",
            "author": [
                "M. Mir\u00f3-Nicolau",
                "A. Jaume-i-Cap\u00f3",
                "G. Moy\u00e0-Alcover"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01961v1",
                "http://arxiv.org/pdf/2311.01961v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01960v1",
            "title": "Hardness of Low Rank Approximation of Entrywise Transformed Matrix\n  Products",
            "updated": "2023-11-03T14:56:24Z",
            "published": "2023-11-03T14:56:24Z",
            "summary": "Inspired by fast algorithms in natural language processing, we study low rank\napproximation in the entrywise transformed setting where we want to find a good\nrank $k$ approximation to $f(U \\cdot V)$, where $U, V^\\top \\in \\mathbb{R}^{n\n\\times r}$ are given, $r = O(\\log(n))$, and $f(x)$ is a general scalar\nfunction. Previous work in sublinear low rank approximation has shown that if\nboth (1) $U = V^\\top$ and (2) $f(x)$ is a PSD kernel function, then there is an\n$O(nk^{\\omega-1})$ time constant relative error approximation algorithm, where\n$\\omega \\approx 2.376$ is the exponent of matrix multiplication. We give the\nfirst conditional time hardness results for this problem, demonstrating that\nboth conditions (1) and (2) are in fact necessary for getting better than\n$n^{2-o(1)}$ time for a relative error low rank approximation for a wide class\nof functions. We give novel reductions from the Strong Exponential Time\nHypothesis (SETH) that rely on lower bounding the leverage scores of flat\nsparse vectors and hold even when the rank of the transformed matrix $f(UV)$\nand the target rank are $n^{o(1)}$, and when $U = V^\\top$. Furthermore, even\nwhen $f(x) = x^p$ is a simple polynomial, we give runtime lower bounds in the\ncase when $U \\neq V^\\top$ of the form $\\Omega(\\min(n^{2-o(1)}, \\Omega(2^p)))$.\nLastly, we demonstrate that our lower bounds are tight by giving an $O(n \\cdot\n\\text{poly}(k, 2^p, 1/\\epsilon))$ time relative error approximation algorithm\nand a fast $O(n \\cdot \\text{poly}(k, p, 1/\\epsilon))$ additive error\napproximation using fast tensor-based sketching. Additionally, since our low\nrank algorithms rely on matrix-vector product subroutines, our lower bounds\nextend to show that computing $f(UV)W$, for even a small matrix $W$, requires\n$\\Omega(n^{2-o(1)})$ time.",
            "author": [
                "Tamas Sarlos",
                "Xingyou Song",
                "David Woodruff",
                "Qiuyi",
                "Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01960v1",
                "http://arxiv.org/pdf/2311.01960v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01955v1",
            "title": "Too Much Information: Keeping Training Simple for BabyLMs",
            "updated": "2023-11-03T14:50:00Z",
            "published": "2023-11-03T14:50:00Z",
            "summary": "This paper details the work of the University of Groningen for the BabyLM\nChallenge. We follow the idea that, like babies, language models should be\nintroduced to simpler concepts first and build off of that knowledge to\nunderstand more complex concepts. We examine this strategy of\nsimple-then-complex through a variety of lenses, namely context size,\nvocabulary, and overall linguistic complexity of the data. We find that only\none, context size, is truly beneficial to training a language model. However\nthis simple change to context size gives us improvements of 2 points on average\non (Super)GLUE tasks, 1 point on MSGS tasks, and 12\\% on average on BLiMP\ntasks. Our context-limited model outperforms the baseline that was trained on\n10$\\times$ the amount of data.",
            "author": [
                "Lukas Edman",
                "Lisa Bylinina"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01955v1",
                "http://arxiv.org/pdf/2311.01955v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04926v1",
            "title": "More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve\n  Visually Diverse Images of Parsons Problems",
            "updated": "2023-11-03T14:47:17Z",
            "published": "2023-11-03T14:47:17Z",
            "summary": "The advent of large language models is reshaping computing education. Recent\nresearch has demonstrated that these models can produce better explanations\nthan students, answer multiple-choice questions at or above the class average,\nand generate code that can pass automated tests in introductory courses. These\ncapabilities have prompted instructors to rapidly adapt their courses and\nassessment methods to accommodate changes in learning objectives and the\npotential for academic integrity violations. While some scholars have advocated\nfor the integration of visual problems as a safeguard against the capabilities\nof language models, new multimodal language models now have vision and language\ncapabilities that may allow them to analyze and solve visual problems. In this\npaper, we evaluate the performance of two large multimodal models on visual\nassignments, with a specific focus on Parsons problems presented across diverse\nvisual representations. Our results show that GPT-4V solved 96.7\\% of these\nvisual problems, struggling minimally with a single Parsons problem.\nConversely, Bard performed poorly by only solving 69.2\\% of problems,\nstruggling with common issues like hallucinations and refusals. These findings\nsuggest that merely transitioning to visual programming problems might not be a\npanacea to issues of academic integrity in the generative AI era.",
            "author": [
                "Irene Hou",
                "Owen Man",
                "Sophie Mettille",
                "Sebastian Gutierrez",
                "Kenneth Angelikas",
                "Stephen MacNeil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04926v1",
                "http://arxiv.org/pdf/2311.04926v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01949v1",
            "title": "Hint-enhanced In-Context Learning wakes Large Language Models up for\n  knowledge-intensive tasks",
            "updated": "2023-11-03T14:39:20Z",
            "published": "2023-11-03T14:39:20Z",
            "summary": "In-context learning (ICL) ability has emerged with the increasing scale of\nlarge language models (LLMs), enabling them to learn input-label mappings from\ndemonstrations and perform well on downstream tasks. However, under the\nstandard ICL setting, LLMs may sometimes neglect query-related information in\ndemonstrations, leading to incorrect predictions. To address this limitation,\nwe propose a new paradigm called Hint-enhanced In-Context Learning (HICL) to\nexplore the power of ICL in open-domain question answering, an important form\nin knowledge-intensive tasks. HICL leverages LLMs' reasoning ability to extract\nquery-related knowledge from demonstrations, then concatenates the knowledge to\nprompt LLMs in a more explicit way. Furthermore, we track the source of this\nknowledge to identify specific examples, and introduce a Hint-related Example\nRetriever (HER) to select informative examples for enhanced demonstrations. We\nevaluate HICL with HER on 3 open-domain QA benchmarks, and observe average\nperformance gains of 2.89 EM score and 2.52 F1 score on gpt-3.5-turbo, 7.62 EM\nscore and 7.27 F1 score on LLaMA-2-Chat-7B compared with standard setting.",
            "author": [
                "Yifan Wang",
                "Qingyan Guo",
                "Xinzhe Ni",
                "Chufan Shi",
                "Lemao Liu",
                "Haiyun Jiang",
                "Yujiu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01949v1",
                "http://arxiv.org/pdf/2311.01949v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14685v1",
            "title": "Comprehensive Assessment of Toxicity in ChatGPT",
            "updated": "2023-11-03T14:37:53Z",
            "published": "2023-11-03T14:37:53Z",
            "summary": "Moderating offensive, hateful, and toxic language has always been an\nimportant but challenging topic in the domain of safe use in NLP. The emerging\nlarge language models (LLMs), such as ChatGPT, can potentially further\naccentuate this threat. Previous works have discovered that ChatGPT can\ngenerate toxic responses using carefully crafted inputs. However, limited\nresearch has been done to systematically examine when ChatGPT generates toxic\nresponses. In this paper, we comprehensively evaluate the toxicity in ChatGPT\nby utilizing instruction-tuning datasets that closely align with real-world\nscenarios. Our results show that ChatGPT's toxicity varies based on different\nproperties and settings of the prompts, including tasks, domains, length, and\nlanguages. Notably, prompts in creative writing tasks can be 2x more likely\nthan others to elicit toxic responses. Prompting in German and Portuguese can\nalso double the response toxicity. Additionally, we discover that certain\ndeliberately toxic prompts, designed in earlier studies, no longer yield\nharmful responses. We hope our discoveries can guide model developers to better\nregulate these AI systems and the users to avoid undesirable outputs.",
            "author": [
                "Boyang Zhang",
                "Xinyue Shen",
                "Wai Man Si",
                "Zeyang Sha",
                "Zeyuan Chen",
                "Ahmed Salem",
                "Yun Shen",
                "Michael Backes",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14685v1",
                "http://arxiv.org/pdf/2311.14685v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02133v1",
            "title": "Safe Online Dynamics Learning with Initially Unknown Models and\n  Infeasible Safety Certificates",
            "updated": "2023-11-03T14:23:57Z",
            "published": "2023-11-03T14:23:57Z",
            "summary": "Safety-critical control tasks with high levels of uncertainty are becoming\nincreasingly common. Typically, techniques that guarantee safety during\nlearning and control utilize constraint-based safety certificates, which can be\nleveraged to compute safe control inputs. However, excessive model uncertainty\ncan render robust safety certification methods or infeasible, meaning no\ncontrol input satisfies the constraints imposed by the safety certificate. This\npaper considers a learning-based setting with a robust safety certificate based\non a control barrier function (CBF) second-order cone program. If the control\nbarrier function certificate is feasible, our approach leverages it to\nguarantee safety. Otherwise, our method explores the system dynamics to collect\ndata and recover the feasibility of the control barrier function constraint. To\nthis end, we employ a method inspired by well-established tools from Bayesian\noptimization. We show that if the sampling frequency is high enough, we recover\nthe feasibility of the robust CBF certificate, guaranteeing safety. Our\napproach requires no prior model and corresponds, to the best of our knowledge,\nto the first algorithm that guarantees safety in settings with occasionally\ninfeasible safety certificates without requiring a backup non-learning-based\ncontroller.",
            "author": [
                "Alexandre Capone",
                "Ryan Cosner",
                "Aaron Ames",
                "Sandra Hirche"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02133v1",
                "http://arxiv.org/pdf/2311.02133v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01938v1",
            "title": "Computer-assisted proofs of existence of KAM tori in planetary dynamical\n  models of $\\upsilon$-And $\\mathbf{b}$",
            "updated": "2023-11-03T14:22:56Z",
            "published": "2023-11-03T14:22:56Z",
            "summary": "We reconsider the problem of the orbital dynamics of the innermost exoplanet\nof the $\\upsilon$-Andromedae system (i.e., $\\upsilon$-And $\\mathbf{b}$) into\nthe framework of a Secular Quasi-Periodic Restricted Hamiltonian model. This\nmeans that we preassign the orbits of the planets that are expected to be the\nbiggest ones in that extrasolar system (namely, $\\upsilon$-And $\\mathbf{c}$ and\n$\\upsilon$-And $\\mathbf{d}$). The Fourier decompositions of their secular\nmotions are injected in the equations describing the orbital dynamics of\n$\\upsilon$-And $\\mathbf{b}$ under the gravitational effects exerted by those\ntwo exoplanets. By a computer-assisted procedure, we prove the existence of KAM\ntori corresponding to orbital motions that we consider to be very robust\nconfigurations, according to the analysis and the numerical explorations made\nin our previous article. The computer-assisted assisted proofs are successfully\nperformed for two variants of the Secular Quasi-Periodic Restricted Hamiltonian\nmodel, which differs for what concerns the effects of the relativistic\ncorrections on the orbital motion of $\\upsilon$-And $\\mathbf{b}$, depending on\nwhether they are considered or not.",
            "author": [
                "Rita Mastroianni",
                "Ugo Locatelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01938v1",
                "http://arxiv.org/pdf/2311.01938v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01937v1",
            "title": "Supermind Ideator: Exploring generative AI to support creative\n  problem-solving",
            "updated": "2023-11-03T14:21:39Z",
            "published": "2023-11-03T14:21:39Z",
            "summary": "Previous efforts to support creative problem-solving have included (a)\ntechniques (such as brainstorming and design thinking) to stimulate creative\nideas, and (b) software tools to record and share these ideas. Now, generative\nAI technologies can suggest new ideas that might never have occurred to the\nusers, and users can then select from these ideas or use them to stimulate even\nmore ideas. Here, we describe such a system, Supermind Ideator. The system uses\na large language model (GPT 3.5) and adds prompting, fine tuning, and a user\ninterface specifically designed to help people use creative problem-solving\ntechniques. Some of these techniques can be applied to any problem; others are\nspecifically intended to help generate innovative ideas about how to design\ngroups of people and/or computers (\"superminds\"). We also describe our early\nexperiences with using this system and suggest ways it could be extended to\nsupport additional techniques for other specific problem-solving domains.",
            "author": [
                "Steven R. Rick",
                "Gianni Giacomelli",
                "Haoran Wen",
                "Robert J. Laubacher",
                "Nancy Taubenslag",
                "Jennifer L. Heyman",
                "Max Sina Knicker",
                "Younes Jeddi",
                "Hendrik Maier",
                "Stephen Dwyer",
                "Pranav Ragupathy",
                "Thomas W. Malone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01937v1",
                "http://arxiv.org/pdf/2311.01937v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01934v1",
            "title": "Does Difficulty even Matter? Investigating Difficulty Adjustment and\n  Practice Behavior in an Open-Ended Learning Task",
            "updated": "2023-11-03T14:18:52Z",
            "published": "2023-11-03T14:18:52Z",
            "summary": "Difficulty adjustment in practice exercises has been shown to be beneficial\nfor learning. However, previous research has mostly investigated close-ended\ntasks, which do not offer the students multiple ways to reach a valid solution.\nContrary to this, in order to learn in an open-ended learning task, students\nneed to effectively explore the solution space as there are multiple ways to\nreach a solution. For this reason, the effects of difficulty adjustment could\nbe different for open-ended tasks. To investigate this, as our first\ncontribution, we compare different methods of difficulty adjustment in a user\nstudy conducted with 86 participants. Furthermore, as the practice behavior of\nthe students is expected to influence how well the students learn, we\nadditionally look at their practice behavior as a post-hoc analysis. Therefore,\nas a second contribution, we identify different types of practice behavior and\nhow they link to students' learning outcomes and subjective evaluation measures\nas well as explore the influence the difficulty adjustment methods have on the\npractice behaviors. Our results suggest the usefulness of taking into account\nthe practice behavior in addition to only using the practice performance to\ninform adaptive intervention and difficulty adjustment methods.",
            "author": [
                "Anan Sch\u00fctt",
                "Tobias Huber",
                "Jauwairia Nasir",
                "Cristina Conati",
                "Elisabeth Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01934v1",
                "http://arxiv.org/pdf/2311.01934v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02132v1",
            "title": "Resource savings from fault-tolerant circuit design",
            "updated": "2023-11-03T14:18:09Z",
            "published": "2023-11-03T14:18:09Z",
            "summary": "Using fault-tolerant constructions, computations performed with unreliable\ncomponents can simulate their noiseless counterparts though the introduction of\na modest amount of redundancy. Given the modest overhead required to achieve\nfault-tolerance, and the fact that increasing the reliability of basic\ncomponents often comes at a cost, are there situations where fault-tolerance\nmay be more economical? We present a general framework to account for this\noverhead cost in order to effectively compare fault-tolerant to\nnon-fault-tolerant approaches for computation, in the limit of small logical\nerror rates. Using this detailed accounting, we determine explicit boundaries\nat which fault-tolerant designs become more efficient than designs that achieve\ncomparable reliability through direct consumption of resources. We find that\nthe fault-tolerant construction is always preferred in the limit of high\nreliability in cases where the resources required to construct a basic unit\ngrows faster than $\\log(1 / \\epsilon)$ asymptotically for small $\\epsilon$.",
            "author": [
                "Andrew K. Tan",
                "Isaac L. Chuang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02132v1",
                "http://arxiv.org/pdf/2311.02132v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01929v2",
            "title": "ProS: Facial Omni-Representation Learning via Prototype-based\n  Self-Distillation",
            "updated": "2023-11-07T15:34:42Z",
            "published": "2023-11-03T14:10:06Z",
            "summary": "This paper presents a novel approach, called Prototype-based\nSelf-Distillation (ProS), for unsupervised face representation learning. The\nexisting supervised methods heavily rely on a large amount of annotated\ntraining facial data, which poses challenges in terms of data collection and\nprivacy concerns. To address these issues, we propose ProS, which leverages a\nvast collection of unlabeled face images to learn a comprehensive facial\nomni-representation. In particular, ProS consists of two vision-transformers\n(teacher and student models) that are trained with different augmented images\n(cropping, blurring, coloring, etc.). Besides, we build a face-aware retrieval\nsystem along with augmentations to obtain the curated images comprising\npredominantly facial areas. To enhance the discrimination of learned features,\nwe introduce a prototype-based matching loss that aligns the similarity\ndistributions between features (teacher or student) and a set of learnable\nprototypes. After pre-training, the teacher vision transformer serves as a\nbackbone for downstream tasks, including attribute estimation, expression\nrecognition, and landmark alignment, achieved through simple fine-tuning with\nadditional layers. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance on various tasks, both in full and few-shot\nsettings. Furthermore, we investigate pre-training with synthetic face images,\nand ProS exhibits promising performance in this scenario as well.",
            "author": [
                "Xing Di",
                "Yiyu Zheng",
                "Xiaoming Liu",
                "Yu Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01929v2",
                "http://arxiv.org/pdf/2311.01929v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01928v1",
            "title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive\n  Text-based Games",
            "updated": "2023-11-03T14:09:31Z",
            "published": "2023-11-03T14:09:31Z",
            "summary": "In natural language processing, interactive text-based games serve as a test\nbed for interactive AI systems. Prior work has proposed to play text-based\ngames by acting based on discrete knowledge graphs constructed by the Discrete\nGraph Updater (DGU) to represent the game state from the natural language\ndescription. While DGU has shown promising results with high interpretability,\nit suffers from lower knowledge graph accuracy due to its lack of temporality\nand limited generalizability to complex environments with objects with the same\nlabel. In order to address DGU's weaknesses while preserving its high\ninterpretability, we propose the Temporal Discrete Graph Updater (TDGU), a\nnovel neural network model that represents dynamic knowledge graphs as a\nsequence of timestamped graph events and models them using a temporal point\nbased graph neural network. Through experiments on the dataset collected from a\ntext-based game TextWorld, we show that TDGU outperforms the baseline DGU. We\nfurther show the importance of temporal information for TDGU's performance\nthrough an ablation study and demonstrate that TDGU has the ability to\ngeneralize to more complex environments with objects with the same label. All\nthe relevant code can be found at\n\\url{https://github.com/yukw777/temporal-discrete-graph-updater}.",
            "author": [
                "Keunwoo Peter Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01928v1",
                "http://arxiv.org/pdf/2311.01928v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01927v1",
            "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling",
            "updated": "2023-11-03T14:08:39Z",
            "published": "2023-11-03T14:08:39Z",
            "summary": "Linear Recurrence has proven to be a powerful tool for modeling long\nsequences efficiently. In this work, we show that existing models fail to take\nfull advantage of its potential. Motivated by this finding, we develop\nGateLoop, a foundational sequence model that generalizes linear recurrent\nmodels such as S4, S5, LRU and RetNet, by employing data-controlled state\ntransitions. Utilizing this theoretical advance, GateLoop empirically\noutperforms existing models for auto-regressive language modeling. Our method\ncomes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \\log_{2} l)$\nparallel mode making use of highly optimized associative scan implementations.\nFurthermore, we derive an $O(l^2)$ surrogate attention mode, revealing\nremarkable implications for Transformer and recently proposed architectures.\nSpecifically, we prove that our approach can be interpreted as providing\ndata-controlled relative-positional information to Attention. While many\nexisting models solely rely on data-controlled cumulative sums for context\naggregation, our findings suggest that incorporating data-controlled complex\ncumulative products may be a crucial step towards more powerful sequence\nmodels.",
            "author": [
                "Tobias Katsch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01927v1",
                "http://arxiv.org/pdf/2311.01927v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08417v1",
            "title": "Image complexity based fMRI-BOLD visual network categorization across\n  visual datasets using topological descriptors and deep-hybrid learning",
            "updated": "2023-11-03T14:05:57Z",
            "published": "2023-11-03T14:05:57Z",
            "summary": "This study proposes a new approach that investigates differences in\ntopological characteristics of visual networks, which are constructed using\nfMRI BOLD time-series corresponding to visual datasets of COCO, ImageNet, and\nSUN. A publicly available BOLD5000 dataset is utilized that contains fMRI scans\nwhile viewing 5254 images of diverse complexities. The objective of this study\nis to examine how network topology differs in response to distinct visual\nstimuli from these visual datasets. To achieve this, 0- and 1-dimensional\npersistence diagrams are computed for each visual network representing COCO,\nImageNet, and SUN. For extracting suitable features from topological\npersistence diagrams, K-means clustering is executed. The extracted K-means\ncluster features are fed to a novel deep-hybrid model that yields accuracy in\nthe range of 90%-95% in classifying these visual networks. To understand\nvision, this type of visual network categorization across visual datasets is\nimportant as it captures differences in BOLD signals while perceiving images\nwith different contexts and complexities. Furthermore, distinctive topological\npatterns of visual network associated with each dataset, as revealed from this\nstudy, could potentially lead to the development of future neuroimaging\nbiomarkers for diagnosing visual processing disorders like visual agnosia or\nprosopagnosia, and tracking changes in visual cognition over time.",
            "author": [
                "Debanjali Bhattacharya",
                "Neelam Sinha",
                "Yashwanth R.",
                "Amit Chattopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08417v1",
                "http://arxiv.org/pdf/2311.08417v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "eess.SP",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01924v1",
            "title": "Cascadic Tensor Multigrid Method and Economic Cascadic Tensor Multigrid\n  Method for Image Restoration Problems",
            "updated": "2023-11-03T14:02:25Z",
            "published": "2023-11-03T14:02:25Z",
            "summary": "A cascadic tensor multigrid method and an economic cascadic tensor multigrid\nmethod is presented for solving the image restoration models. The methods use\nquadratic interpolation as prolongation operator to provide more accurate\ninitial values for the next fine grid level, and constructs a\npreserving-edge-denoising operator to obtain better edges and remove noise. The\nexperimental results show that the new methods not only improves computational\nefficiency but also achieve better restoration quality.",
            "author": [
                "Ziqi Yan",
                "Chenliang Li",
                "Yuhan Chen"
            ],
            "link": [
                "http://dx.doi.org/10.12691/ajna-7-1-1",
                "http://arxiv.org/abs/2311.01924v1",
                "http://arxiv.org/pdf/2311.01924v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "15A69, 65F22, 68U10, 65M55"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04925v1",
            "title": "Investigating Deep-Learning NLP for Automating the Extraction of\n  Oncology Efficacy Endpoints from Scientific Literature",
            "updated": "2023-11-03T14:01:54Z",
            "published": "2023-11-03T14:01:54Z",
            "summary": "Benchmarking drug efficacy is a critical step in clinical trial design and\nplanning. The challenge is that much of the data on efficacy endpoints is\nstored in scientific papers in free text form, so extraction of such data is\ncurrently a largely manual task. Our objective is to automate this task as much\nas possible. In this study we have developed and optimised a framework to\nextract efficacy endpoints from text in scientific papers, using a machine\nlearning approach. Our machine learning model predicts 25 classes associated\nwith efficacy endpoints and leads to high F1 scores (harmonic mean of precision\nand recall) of 96.4% on the test set, and 93.9% and 93.7% on two case studies.\nThese methods were evaluated against - and showed strong agreement with -\nsubject matter experts and show significant promise in the future of automating\nthe extraction of clinical endpoints from free text. Clinical information\nextraction from text data is currently a laborious manual task which scales\npoorly and is prone to human error. Demonstrating the ability to extract\nefficacy endpoints automatically shows great promise for accelerating clinical\ntrial design moving forwards.",
            "author": [
                "Aline Gendrin-Brokmann",
                "Eden Harrison",
                "Julianne Noveras",
                "Leonidas Souliotis",
                "Harris Vince",
                "Ines Smit",
                "Francisco Costa",
                "David Milward",
                "Sashka Dimitrievska",
                "Paul Metcalfe",
                "Emilie Louvet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04925v1",
                "http://arxiv.org/pdf/2311.04925v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01923v1",
            "title": "A Proof of the Kashaev Signature Conjecture",
            "updated": "2023-11-03T14:01:38Z",
            "published": "2023-11-03T14:01:38Z",
            "summary": "In 2018 Kashaev introduced a diagrammatic link invariant conjectured to be\ntwice the Levine-Tristram signature. If true, the conjecture would provide a\nsimple way of computing the Levine-Tristram signature of a link by taking the\nsignature of a real symmetric matrix associated with a corresponding link\ndiagram. This paper establishes the conjecture using the Seifert surface\ndefinition of the Levine-Tristram signature on the disjoint union of an\noriented link and its reverse. The proof also reveals yet another formula for\nthe Alexander polynomial.",
            "author": [
                "Jessica Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01923v1",
                "http://arxiv.org/pdf/2311.01923v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "57K10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01918v1",
            "title": "Large Language Models Illuminate a Progressive Pathway to Artificial\n  Healthcare Assistant: A Review",
            "updated": "2023-11-03T13:51:36Z",
            "published": "2023-11-03T13:51:36Z",
            "summary": "With the rapid development of artificial intelligence, large language models\n(LLMs) have shown promising capabilities in mimicking human-level language\ncomprehension and reasoning. This has sparked significant interest in applying\nLLMs to enhance various aspects of healthcare, ranging from medical education\nto clinical decision support. However, medicine involves multifaceted data\nmodalities and nuanced reasoning skills, presenting challenges for integrating\nLLMs. This paper provides a comprehensive review on the applications and\nimplications of LLMs in medicine. It begins by examining the fundamental\napplications of general-purpose and specialized LLMs, demonstrating their\nutilities in knowledge retrieval, research support, clinical workflow\nautomation, and diagnostic assistance. Recognizing the inherent multimodality\nof medicine, the review then focuses on multimodal LLMs, investigating their\nability to process diverse data types like medical imaging and EHRs to augment\ndiagnostic accuracy. To address LLMs' limitations regarding personalization and\ncomplex clinical reasoning, the paper explores the emerging development of\nLLM-powered autonomous agents for healthcare. Furthermore, it summarizes the\nevaluation methodologies for assessing LLMs' reliability and safety in medical\ncontexts. Overall, this review offers an extensive analysis on the\ntransformative potential of LLMs in modern medicine. It also highlights the\npivotal need for continuous optimizations and ethical oversight before these\nmodels can be effectively integrated into clinical practice. Visit\nhttps://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying\nGitHub repository containing latest papers.",
            "author": [
                "Mingze Yuan",
                "Peng Bao",
                "Jiajia Yuan",
                "Yunhao Shen",
                "Zifan Chen",
                "Yi Xie",
                "Jie Zhao",
                "Yang Chen",
                "Li Zhang",
                "Lin Shen",
                "Bin Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01918v1",
                "http://arxiv.org/pdf/2311.01918v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01916v1",
            "title": "Contrast-Agnostic Groupwise Registration by Robust PCA for Quantitative\n  Cardiac MRI",
            "updated": "2023-11-03T13:48:13Z",
            "published": "2023-11-03T13:48:13Z",
            "summary": "Quantitative cardiac magnetic resonance imaging (MRI) is an increasingly\nimportant diagnostic tool for cardiovascular diseases. Yet, co-registration of\nall baseline images within the quantitative MRI sequence is essential for the\naccuracy and precision of quantitative maps. However, co-registering all\nbaseline images from a quantitative cardiac MRI sequence remains a nontrivial\ntask because of the simultaneous changes in intensity and contrast, in\ncombination with cardiac and respiratory motion. To address the challenge, we\npropose a novel motion correction framework based on robust principle component\nanalysis (rPCA) that decomposes quantitative cardiac MRI into low-rank and\nsparse components, and we integrate the groupwise CNN-based registration\nbackbone within the rPCA framework. The low-rank component of rPCA corresponds\nto the quantitative mapping (i.e. limited degree of freedom in variation),\nwhile the sparse component corresponds to the residual motion, making it easier\nto formulate and solve the groupwise registration problem. We evaluated our\nproposed method on cardiac T1 mapping by the modified Look-Locker inversion\nrecovery (MOLLI) sequence, both before and after the Gadolinium contrast agent\nadministration. Our experiments showed that our method effectively improved\nregistration performance over baseline methods without introducing rPCA, and\nreduced quantitative mapping error in both in-domain (pre-contrast MOLLI) and\nout-of-domain (post-contrast MOLLI) inference. The proposed rPCA framework is\ngeneric and can be integrated with other registration backbones.",
            "author": [
                "Xinqi Li",
                "Yi Zhang",
                "Yidong Zhao",
                "Jan van Gemert",
                "Qian Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01916v1",
                "http://arxiv.org/pdf/2311.01916v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01914v1",
            "title": "Dynamic Redundancy-aware Blockchain-based Partial Computation Offloading\n  for the Metaverse in In-network Computing",
            "updated": "2023-11-03T13:44:48Z",
            "published": "2023-11-03T13:44:48Z",
            "summary": "The computing in the network (COIN) paradigm has emerged as a potential\nsolution for computation-intensive applications like the metaverse by utilizing\nunused network resources. The blockchain (BC) guarantees task-offloading\nprivacy, but cost reduction, queueing delays, and redundancy elimination remain\nopen problems. This paper presents a redundancy-aware BC-based approach for the\nmetaverse's partial computation offloading (PCO). Specifically, we formulate a\njoint BC redundancy factor (BRF) and PCO problem to minimize computation costs,\nmaximize incentives, and meet delay and BC offloading constraints. We proved\nthis problem is NP-hard and transformed it into two subproblems based on their\ntemporal correlation: real-time PCO and Markov decision process-based BRF. We\nformulated the PCO problem as a multiuser game, proposed a decentralized\nalgorithm for Nash equilibrium under any BC redundancy state, and designed a\ndouble deep Q-network-based algorithm for the optimal BRF policy. The BRF\nstrategy is updated periodically based on user computation demand and network\nstatus to assist the PCO algorithm. The experimental results suggest that the\nproposed approach outperforms existing schemes, resulting in a remarkable 47%\nreduction in cost overhead, delivering approximately 64% higher rewards, and\nachieving convergence in just a few training episodes.",
            "author": [
                "Ibrahim Aliyu",
                "Cho-Rong Yu",
                "Tai-Won Um",
                "Jinsul Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01914v1",
                "http://arxiv.org/pdf/2311.01914v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01912v1",
            "title": "End-to-End assessment of AR-assisted neurosurgery systems",
            "updated": "2023-11-03T13:41:44Z",
            "published": "2023-11-03T13:41:44Z",
            "summary": "Augmented Reality (AR) has emerged as a significant advancement in surgical\nprocedures, offering a solution to the challenges posed by traditional\nneuronavigation methods. These conventional techniques often necessitate\nsurgeons to split their focus between the surgical site and a separate monitor\nthat displays guiding images. Over the years, many systems have been developed\nto register and track the hologram at the targeted locations, each employed its\nown evaluation technique. On the other hand, hologram displacement measurement\nis not a straightforward task because of various factors such as occlusion,\nVengence-Accomodation Conflict, and unstable holograms in space. In this study,\nwe explore and classify different techniques for assessing an AR-assisted\nneurosurgery system and propose a new technique to systematize the assessment\nprocedure. Moreover, we conduct a deeper investigation to assess surgeon error\nin the pre- and intra-operative phases of the surgery based on the respective\nfeedback given. We found that although the system can undergo registration and\ntracking errors, physical feedback can significantly reduce the error caused by\nhologram displacement. However, the lack of visual feedback on the hologram\ndoes not have a significant effect on the user 3D perception.",
            "author": [
                "Mahdi Bagheri",
                "Farhad Piri",
                "Hadi Digale",
                "Saem Sattarzadeh",
                "Mohammad Reza Mohammadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01912v1",
                "http://arxiv.org/pdf/2311.01912v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV",
                "92C50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01911v1",
            "title": "Astrophysical black holes: theory and observations",
            "updated": "2023-11-03T13:40:35Z",
            "published": "2023-11-03T13:40:35Z",
            "summary": "These notes cover part of the lectures presented by Andrea Maselli for the\n59th Winter School of Theoretical Physics and third COST Action CA18108\nTraining School 'Gravity -- Classical, Quantum and Phenomenology'. The school\ntook place at Palac Wojan\\'ow, Poland, from February 12th to 21st, 2023. The\nlectures focused on some key aspects of black hole physics, and in particular\non the dynamics of particles and on the scattering of waves in the\nSchwarzschild spacetime. The goal of the course was to introduce the students\nto the concept of black hole quasi normal modes, to discuss their properties,\ntheir connection with the geodesic motion of massless particles, and to provide\nnumerical approaches to compute their actual values.",
            "author": [
                "Martina Adamo",
                "Andrea Maselli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01911v1",
                "http://arxiv.org/pdf/2311.01911v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01908v2",
            "title": "LLM-driven Multimodal Target Volume Contouring in Radiation Oncology",
            "updated": "2023-11-27T15:23:27Z",
            "published": "2023-11-03T13:38:42Z",
            "summary": "Target volume contouring for radiation therapy is considered significantly\nmore challenging than the normal organ segmentation tasks as it necessitates\nthe utilization of both image and text-based clinical information. Inspired by\nthe recent advancement of large language models (LLMs) that can facilitate the\nintegration of the textural information and images, here we present a novel\nLLM-driven multi-modal AI that utilizes the clinical text information and is\napplicable to the challenging task of target volume contouring for radiation\ntherapy, and validate it within the context of breast cancer radiation therapy\ntarget volume contouring. Using external validation and data-insufficient\nenvironments, which attributes highly conducive to real-world applications, we\ndemonstrate that the proposed model exhibits markedly improved performance\ncompared to conventional vision-only AI models, particularly exhibiting robust\ngeneralization performance and data-efficiency. To our best knowledge, this is\nthe first LLM-driven multimodal AI model that integrates the clinical text\ninformation into target volume delineation for radiation oncology.",
            "author": [
                "Yujin Oh",
                "Sangjoon Park",
                "Hwa Kyung Byun",
                "Jin Sung Kim",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01908v2",
                "http://arxiv.org/pdf/2311.01908v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01907v2",
            "title": "BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural\n  Sentence Simplification",
            "updated": "2023-12-06T08:49:40Z",
            "published": "2023-11-03T13:34:08Z",
            "summary": "Automatic simplification can help laypeople to comprehend complex scientific\ntext. Language models are frequently applied to this task by translating from\ncomplex to simple language. In this paper, we describe our system based on\nLlama 2, which ranked first in the PLABA shared task addressing the\nsimplification of biomedical text. We find that the large portion of shared\ntokens between input and output leads to weak training signals and\nconservatively editing models. To mitigate these issues, we propose\nsentence-level and token-level loss weights. They give higher weight to\nmodified tokens, indicated by edit distance and edit operations, respectively.\nWe conduct an empirical evaluation on the PLABA dataset and find that both\napproaches lead to simplifications closer to those created by human annotators\n(+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x /\n1.8x edit distance) compared to the same model fine-tuned with standard cross\nentropy. We furthermore show that the hyperparameter $\\lambda$ in token-level\nloss weights can be used to control the edit distance and the simplicity level\n(FKGL).",
            "author": [
                "Valentin Knappich",
                "Simon Razniewski",
                "Annemarie Friedrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01907v2",
                "http://arxiv.org/pdf/2311.01907v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01905v1",
            "title": "From Chaos to Calibration: A Geometric Mutual Information Approach to\n  Target-Free Camera LiDAR Extrinsic Calibration",
            "updated": "2023-11-03T13:30:31Z",
            "published": "2023-11-03T13:30:31Z",
            "summary": "Sensor fusion is vital for the safe and robust operation of autonomous\nvehicles. Accurate extrinsic sensor to sensor calibration is necessary to\naccurately fuse multiple sensor's data in a common spatial reference frame. In\nthis paper, we propose a target free extrinsic calibration algorithm that\nrequires no ground truth training data, artificially constrained motion\ntrajectories, hand engineered features or offline optimization and that is\naccurate, precise and extremely robust to initialization error.\n  Most current research on online camera-LiDAR extrinsic calibration requires\nground truth training data which is impossible to capture at scale. We revisit\nanalytical mutual information based methods first proposed in 2012 and\ndemonstrate that geometric features provide a robust information metric for\ncamera-LiDAR extrinsic calibration. We demonstrate our proposed improvement\nusing the KITTI and KITTI-360 fisheye data set.",
            "author": [
                "Jack Borer",
                "Jeremy Tschirner",
                "Florian \u00d6lsner",
                "Stefan Milz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01905v1",
                "http://arxiv.org/pdf/2311.01905v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01894v1",
            "title": "Simulation of acquisition shifts in T2 Flair MR images to stress test AI\n  segmentation networks",
            "updated": "2023-11-03T13:10:55Z",
            "published": "2023-11-03T13:10:55Z",
            "summary": "Purpose: To provide a simulation framework for routine neuroimaging test\ndata, which allows for \"stress testing\" of deep segmentation networks against\nacquisition shifts that commonly occur in clinical practice for T2 weighted\n(T2w) fluid attenuated inversion recovery (FLAIR) Magnetic Resonance Imaging\n(MRI) protocols.\n  Approach: The approach simulates \"acquisition shift derivatives\" of MR images\nbased on MR signal equations. Experiments comprise the validation of the\nsimulated images by real MR scans and example stress tests on state-of-the-art\nMS lesion segmentation networks to explore a generic model function to describe\nthe F1 score in dependence of the contrast-affecting sequence parameters echo\ntime (TE) and inversion time (TI).\n  Results: The differences between real and simulated images range up to 19 %\nin gray and white matter for extreme parameter settings. For the segmentation\nnetworks under test the F1 score dependency on TE and TI can be well described\nby quadratic model functions (R^2 > 0.9). The coefficients of the model\nfunctions indicate that changes of TE have more influence on the model\nperformance than TI.\n  Conclusions: We show that these deviations are in the range of values as may\nbe caused by erroneous or individual differences of relaxation times as\ndescribed by literature. The coefficients of the F1 model function allow for\nquantitative comparison of the influences of TE and TI. Limitations arise\nmainly from tissues with the low baseline signal (like CSF) and when the\nprotocol contains contrast-affecting measures that cannot be modelled due to\nmissing information in the DICOM header.",
            "author": [
                "Christiane Posselt",
                "Mehmet Yigit Avci",
                "Mehmet Yigitsoy",
                "Patrick Sch\u00fcnke",
                "Christoph Kolbitsch",
                "Tobias Sch\u00e4ffter",
                "Stefanie Remmele"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01894v1",
                "http://arxiv.org/pdf/2311.01894v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01886v1",
            "title": "Bridging the Gap between Multi-focus and Multi-modal: A Focused\n  Integration Framework for Multi-modal Image Fusion",
            "updated": "2023-11-03T12:58:39Z",
            "published": "2023-11-03T12:58:39Z",
            "summary": "Multi-modal image fusion (MMIF) integrates valuable information from\ndifferent modality images into a fused one. However, the fusion of multiple\nvisible images with different focal regions and infrared images is a\nunprecedented challenge in real MMIF applications. This is because of the\nlimited depth of the focus of visible optical lenses, which impedes the\nsimultaneous capture of the focal information within the same scene. To address\nthis issue, in this paper, we propose a MMIF framework for joint focused\nintegration and modalities information extraction. Specifically, a\nsemi-sparsity-based smoothing filter is introduced to decompose the images into\nstructure and texture components. Subsequently, a novel multi-scale operator is\nproposed to fuse the texture components, capable of detecting significant\ninformation by considering the pixel focus attributes and relevant data from\nvarious modal images. Additionally, to achieve an effective capture of scene\nluminance and reasonable contrast maintenance, we consider the distribution of\nenergy information in the structural components in terms of multi-directional\nfrequency variance and information entropy. Extensive experiments on existing\nMMIF datasets, as well as the object detection and depth estimation tasks,\nconsistently demonstrate that the proposed algorithm can surpass the\nstate-of-the-art methods in visual perception and quantitative evaluation. The\ncode is available at https://github.com/ixilai/MFIF-MMIF.",
            "author": [
                "Xilai Li",
                "Xiaosong Li",
                "Tao Ye",
                "Xiaoqi Cheng",
                "Wuyang Liu",
                "Haishu Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01886v1",
                "http://arxiv.org/pdf/2311.01886v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14684v1",
            "title": "The risks of risk-based AI regulation: taking liability seriously",
            "updated": "2023-11-03T12:51:37Z",
            "published": "2023-11-03T12:51:37Z",
            "summary": "The development and regulation of multi-purpose, large \"foundation models\" of\nAI seems to have reached a critical stage, with major investments and new\napplications announced every other day. Some experts are calling for a\nmoratorium on the training of AI systems more powerful than GPT-4. Legislators\nglobally compete to set the blueprint for a new regulatory regime. This paper\nanalyses the most advanced legal proposal, the European Union's AI Act\ncurrently in the stage of final \"trilogue\" negotiations between the EU\ninstitutions. This legislation will likely have extra-territorial implications,\nsometimes called \"the Brussels effect\". It also constitutes a radical departure\nfrom conventional information and communications technology policy by\nregulating AI ex-ante through a risk-based approach that seeks to prevent\ncertain harmful outcomes based on product safety principles. We offer a review\nand critique, specifically discussing the AI Act's problematic obligations\nregarding data quality and human oversight. Our proposal is to take liability\nseriously as the key regulatory mechanism. This signals to industry that if a\nbreach of law occurs, firms are required to know in particular what their\ninputs were and how to retrain the system to remedy the breach. Moreover, we\nsuggest differentiating between endogenous and exogenous sources of potential\nharm, which can be mitigated by carefully allocating liability between\ndevelopers and deployers of AI technology.",
            "author": [
                "Martin Kretschmer",
                "Tobias Kretschmer",
                "Alexander Peukert",
                "Christian Peukert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14684v1",
                "http://arxiv.org/pdf/2311.14684v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01882v1",
            "title": "Indicative Summarization of Long Discussions",
            "updated": "2023-11-03T12:44:59Z",
            "published": "2023-11-03T12:44:59Z",
            "summary": "Online forums encourage the exchange and discussion of different stances on\nmany topics. Not only do they provide an opportunity to present one's own\narguments, but may also gather a broad cross-section of others' arguments.\nHowever, the resulting long discussions are difficult to overview. This paper\npresents a novel unsupervised approach using large language models (LLMs) to\ngenerating indicative summaries for long discussions that basically serve as\ntables of contents. Our approach first clusters argument sentences, generates\ncluster labels as abstractive summaries, and classifies the generated cluster\nlabels into argumentation frames resulting in a two-level summary. Based on an\nextensively optimized prompt engineering approach, we evaluate 19~LLMs for\ngenerative cluster labeling and frame classification. To evaluate the\nusefulness of our indicative summaries, we conduct a purpose-driven user study\nvia a new visual interface called Discussion Explorer: It shows that our\nproposed indicative summaries serve as a convenient navigation tool to explore\nlong discussions.",
            "author": [
                "Shahbaz Syed",
                "Dominik Schwabe",
                "Khalid Al-Khatib",
                "Martin Potthast"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01882v1",
                "http://arxiv.org/pdf/2311.01882v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01881v1",
            "title": "Quantitative Evaluation of a Multi-Modal Camera Setup for Fusing Event\n  Data with RGB Images",
            "updated": "2023-11-03T12:39:47Z",
            "published": "2023-11-03T12:39:47Z",
            "summary": "Event-based cameras, also called silicon retinas, potentially revolutionize\ncomputer vision by detecting and reporting significant changes in intensity\nasynchronous events, offering extended dynamic range, low latency, and low\npower consumption, enabling a wide range of applications from autonomous\ndriving to longtime surveillance. As an emerging technology, there is a notable\nscarcity of publicly available datasets for event-based systems that also\nfeature frame-based cameras, in order to exploit the benefits of both\ntechnologies. This work quantitatively evaluates a multi-modal camera setup for\nfusing high-resolution DVS data with RGB image data by static camera alignment.\nThe proposed setup, which is intended for semi-automatic DVS data labeling,\ncombines two recently released Prophesee EVK4 DVS cameras and one global\nshutter XIMEA MQ022CG-CM RGB camera. After alignment, state-of-the-art object\ndetection or segmentation networks label the image data by mapping boundary\nboxes or labeled pixels directly to the aligned events. To facilitate this\nprocess, various time-based synchronization methods for DVS data are analyzed,\nand calibration accuracy, camera alignment, and lens impact are evaluated.\nExperimental results demonstrate the benefits of the proposed system: the best\nsynchronization method yields an image calibration error of less than 0.90px\nand a pixel cross-correlation deviation of1.6px, while a lens with 8mm focal\nlength enables detection of objects with size 30cm at a distance of 350m\nagainst homogeneous background.",
            "author": [
                "Julian Moosmann",
                "Jakub Mandula",
                "Philipp Mayer",
                "Luca Benini",
                "Michele Magno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01881v1",
                "http://arxiv.org/pdf/2311.01881v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01876v1",
            "title": "Sentiment Analysis through LLM Negotiations",
            "updated": "2023-11-03T12:35:29Z",
            "published": "2023-11-03T12:35:29Z",
            "summary": "A standard paradigm for sentiment analysis is to rely on a singular LLM and\nmakes the decision in a single round under the framework of in-context\nlearning. This framework suffers the key disadvantage that the single-turn\noutput generated by a single LLM might not deliver the perfect decision, just\nas humans sometimes need multiple attempts to get things right. This is\nespecially true for the task of sentiment analysis where deep reasoning is\nrequired to address the complex linguistic phenomenon (e.g., clause\ncomposition, irony, etc) in the input.\n  To address this issue, this paper introduces a multi-LLM negotiation\nframework for sentiment analysis. The framework consists of a reasoning-infused\ngenerator to provide decision along with rationale, a explanation-deriving\ndiscriminator to evaluate the credibility of the generator. The generator and\nthe discriminator iterate until a consensus is reached. The proposed framework\nnaturally addressed the aforementioned challenge, as we are able to take the\ncomplementary abilities of two LLMs, have them use rationale to persuade each\nother for correction.\n  Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie\nReview, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed\napproach: it consistently yields better performances than the ICL baseline\nacross all benchmarks, and even superior performances to supervised baselines\non the Twitter and movie review datasets.",
            "author": [
                "Xiaofei Sun",
                "Xiaoya Li",
                "Shengyu Zhang",
                "Shuhe Wang",
                "Fei Wu",
                "Jiwei Li",
                "Tianwei Zhang",
                "Guoyin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01876v1",
                "http://arxiv.org/pdf/2311.01876v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01873v1",
            "title": "Efficient Black-Box Adversarial Attacks on Neural Text Detectors",
            "updated": "2023-11-03T12:29:32Z",
            "published": "2023-11-03T12:29:32Z",
            "summary": "Neural text detectors are models trained to detect whether a given text was\ngenerated by a language model or written by a human. In this paper, we\ninvestigate three simple and resource-efficient strategies (parameter tweaking,\nprompt engineering, and character-level mutations) to alter texts generated by\nGPT-3.5 that are unsuspicious or unnoticeable for humans but cause\nmisclassification by neural text detectors. The results show that especially\nparameter tweaking and character-level mutations are effective strategies.",
            "author": [
                "Vitalii Fishchuk",
                "Daniel Braun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01873v1",
                "http://arxiv.org/pdf/2311.01873v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01870v1",
            "title": "Multi-EuP: The Multilingual European Parliament Dataset for Analysis of\n  Bias in Information Retrieval",
            "updated": "2023-11-03T12:29:11Z",
            "published": "2023-11-03T12:29:11Z",
            "summary": "We present Multi-EuP, a new multilingual benchmark dataset, comprising 22K\nmulti-lingual documents collected from the European Parliament, spanning 24\nlanguages. This dataset is designed to investigate fairness in a multilingual\ninformation retrieval (IR) context to analyze both language and demographic\nbias in a ranking context. It boasts an authentic multilingual corpus,\nfeaturing topics translated into all 24 languages, as well as cross-lingual\nrelevance judgments. Furthermore, it offers rich demographic information\nassociated with its documents, facilitating the study of demographic bias. We\nreport the effectiveness of Multi-EuP for benchmarking both monolingual and\nmultilingual IR. We also conduct a preliminary experiment on language bias\ncaused by the choice of tokenization strategy.",
            "author": [
                "Jinrui Yang",
                "Timothy Baldwin",
                "Trevor Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01870v1",
                "http://arxiv.org/pdf/2311.01870v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16136v1",
            "title": "ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware\n  Approach",
            "updated": "2023-11-03T12:20:13Z",
            "published": "2023-11-03T12:20:13Z",
            "summary": "Over the past few years, Machine Learning-as-a-Service (MLaaS) has received a\nsurging demand for supporting Machine Learning-driven services to offer\nrevolutionized user experience across diverse application areas. MLaaS provides\ninference service with low inference latency to application users based on an\nML model trained using a dataset collected from numerous individual data\nowners. Recently, for the sake of data owners' privacy and to comply with the\n\"right to be forgotten (RTBF)\" as enacted by data protection legislation, many\nmachine unlearning methods have been proposed to remove data owners' data from\ntrained models upon their unlearning requests. However, despite their promising\nefficiency, almost all existing machine unlearning methods handle unlearning\nrequests in a manner that is independent of inference requests, which\nunfortunately introduces new security and privacy vulnerabilities for machine\nunlearning in MLaaS. In this paper, we propose the ERASER framework for machinE\nunleaRning in MLaAS via an inferencE seRving-aware approach. ERASER proposes a\nnovel certified inference consistency mechanism that reduces inference latency\nby selectively postponing unlearning execution incurred by unlearning requests\nfrom data owners, while strictly adhering to the RTBF principle. ERASER offers\nthree groups of design choices to allow for tailor-made variants that best suit\nthe specific environments and preferences of different MLaaS systems. Extensive\nempirical evaluations across various settings confirm ERASER's effectiveness,\ne.g., it can effectively save up to 99% of inference latency and 31% of\ncomputation overhead over the inference-oblivion baseline.",
            "author": [
                "Yuke Hu",
                "Jian Lou",
                "Jiaqi Liu",
                "Feng Lin",
                "Zhan Qin",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16136v1",
                "http://arxiv.org/pdf/2311.16136v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01866v1",
            "title": "Towards Concept-Aware Large Language Models",
            "updated": "2023-11-03T12:19:22Z",
            "published": "2023-11-03T12:19:22Z",
            "summary": "Concepts play a pivotal role in various human cognitive functions, including\nlearning, reasoning and communication. However, there is very little work on\nendowing machines with the ability to form and reason with concepts. In\nparticular, state-of-the-art large language models (LLMs) work at the level of\ntokens, not concepts.\n  In this work, we analyze how well contemporary LLMs capture human concepts\nand their structure. We then discuss ways to develop concept-aware LLMs, taking\nplace at different stages of the pipeline. We sketch a method for pretraining\nLLMs using concepts, and also explore the simpler approach that uses the output\nof existing LLMs. Despite its simplicity, our proof-of-concept is shown to\nbetter match human intuition, as well as improve the robustness of predictions.\nThese preliminary results underscore the promise of concept-aware LLMs.",
            "author": [
                "Chen Shani",
                "Jilles Vreeken",
                "Dafna Shahaf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01866v1",
                "http://arxiv.org/pdf/2311.01866v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01864v1",
            "title": "SortNet: Learning To Rank By a Neural-Based Sorting Algorithm",
            "updated": "2023-11-03T12:14:26Z",
            "published": "2023-11-03T12:14:26Z",
            "summary": "The problem of relevance ranking consists of sorting a set of objects with\nrespect to a given criterion. Since users may prefer different relevance\ncriteria, the ranking algorithms should be adaptable to the user needs. Two\nmain approaches exist in literature for the task of learning to rank: 1) a\nscore function, learned by examples, which evaluates the properties of each\nobject yielding an absolute relevance value that can be used to order the\nobjects or 2) a pairwise approach, where a \"preference function\" is learned\nusing pairs of objects to define which one has to be ranked first. In this\npaper, we present SortNet, an adaptive ranking algorithm which orders objects\nusing a neural network as a comparator. The neural network training set\nprovides examples of the desired ordering between pairs of items and it is\nconstructed by an iterative procedure which, at each iteration, adds the most\ninformative training examples. Moreover, the comparator adopts a connectionist\narchitecture that is particularly suited for implementing a preference\nfunction. We also prove that such an architecture has the universal\napproximation property and can implement a wide class of functions. Finally,\nthe proposed algorithm is evaluated on the LETOR dataset showing promising\nperformances in comparison with other state of the art algorithms.",
            "author": [
                "Leonardo Rigutini",
                "Tiziano Papini",
                "Marco Maggini",
                "Franco Scarselli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01864v1",
                "http://arxiv.org/pdf/2311.01864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01862v1",
            "title": "$R^3$-NL2GQL: A Hybrid Models Approach for for Accuracy Enhancing and\n  Hallucinations Mitigation",
            "updated": "2023-11-03T12:11:12Z",
            "published": "2023-11-03T12:11:12Z",
            "summary": "While current NL2SQL tasks constructed using Foundation Models have achieved\ncommendable results, their direct application to Natural Language to Graph\nQuery Language (NL2GQL) tasks poses challenges due to the significant\ndifferences between GQL and SQL expressions, as well as the numerous types of\nGQL. Our extensive experiments reveal that in NL2GQL tasks, larger Foundation\nModels demonstrate superior cross-schema generalization abilities, while\nsmaller Foundation Models struggle to improve their GQL generation capabilities\nthrough fine-tuning. However, after fine-tuning, smaller models exhibit better\nintent comprehension and higher grammatical accuracy. Diverging from rule-based\nand slot-filling techniques, we introduce R3-NL2GQL, which employs both smaller\nand larger Foundation Models as reranker, rewriter and refiner. The approach\nharnesses the comprehension ability of smaller models for information reranker\nand rewriter, and the exceptional generalization and generation capabilities of\nlarger models to transform input natural language queries and code structure\nschema into any form of GQLs. Recognizing the lack of established datasets in\nthis nascent domain, we have created a bilingual dataset derived from graph\ndatabase documentation and some open-source Knowledge Graphs (KGs). We tested\nour approach on this dataset and the experimental results showed that delivers\npromising performance and robustness.Our code and dataset is available at\nhttps://github.com/zhiqix/NL2GQL",
            "author": [
                "Yuhang Zhou",
                "He Yu",
                "Siyu Tian",
                "Dan Chen",
                "Liuzhi Zhou",
                "Xinlin Yu",
                "Chuanjun Ji",
                "Sen Liu",
                "Guangnan Ye",
                "Hongfeng Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01862v1",
                "http://arxiv.org/pdf/2311.01862v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01860v1",
            "title": "FAME: Flexible, Scalable Analogy Mappings Engine",
            "updated": "2023-11-03T12:08:02Z",
            "published": "2023-11-03T12:08:02Z",
            "summary": "Analogy is one of the core capacities of human cognition; when faced with new\nsituations, we often transfer prior experience from other domains. Most work on\ncomputational analogy relies heavily on complex, manually crafted input. In\nthis work, we relax the input requirements, requiring only names of entities to\nbe mapped. We automatically extract commonsense representations and use them to\nidentify a mapping between the entities. Unlike previous works, our framework\ncan handle partial analogies and suggest new entities to be added. Moreover,\nour method's output is easily interpretable, allowing for users to understand\nwhy a specific mapping was chosen.\n  Experiments show that our model correctly maps 81.2% of classical 2x2 analogy\nproblems (guess level=50%). On larger problems, it achieves 77.8% accuracy\n(mean guess level=13.1%). In another experiment, we show our algorithm\noutperforms human performance, and the automatic suggestions of new entities\nresemble those suggested by humans. We hope this work will advance\ncomputational analogy by paving the way to more flexible, realistic input\nrequirements, with broader applicability.",
            "author": [
                "Shahar Jacob",
                "Chen Shani",
                "Dafna Shahaf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01860v1",
                "http://arxiv.org/pdf/2311.01860v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01854v1",
            "title": "An Ensemble Machine Learning Approach for Screening Covid-19 based on\n  Urine Parameters",
            "updated": "2023-11-03T11:45:10Z",
            "published": "2023-11-03T11:45:10Z",
            "summary": "The rapid spread of COVID-19 and the emergence of new variants underscore the\nimportance of effective screening measures. Rapid diagnosis and subsequent\nquarantine of infected individuals can prevent further spread of the virus in\nsociety. While PCR tests are the gold standard for COVID-19 diagnosis, they are\ncostly and time-consuming. In contrast, urine test strips are an inexpensive,\nnon-invasive, and rapidly obtainable screening method that can provide\nimportant information about a patient's health status. In this study, we\ncollected a new dataset and used the RGB (Red Green Blue) color space of urine\ntest strips parameters to detect the health status of individuals. To improve\nthe accuracy of our model, we converted the RGB space to 10 additional color\nspaces. After evaluating four different machine learning models, we proposed a\nnew ensemble model based on a multi-layer perceptron neural network. Although\nthe initial results were not strong, we were able to improve the model's\nscreening performance for COVID-19 by removing uncertain regions of the model\nspace. Ultimately, our model achieved a screening accuracy of 80% based on\nurine parameters. Our results suggest that urine test strips can be a useful\ntool for COVID-19 screening, particularly in resource-constrained settings\nwhere PCR testing may not be feasible. Further research is needed to validate\nour findings and explore the potential role of urine test strips in COVID-19\ndiagnosis and management.",
            "author": [
                "Behzad Moayedi",
                "Abdalsamad Keramatfar",
                "Mohammad Hadi Goldani",
                "Mohammad Javad Fallahi",
                "Alborz Jahangirisisakht",
                "Mohammad Saboori",
                "Leyla badiei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01854v1",
                "http://arxiv.org/pdf/2311.01854v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01852v1",
            "title": "Optimisation of Active Space Debris Removal Missions With Multiple\n  Targets Using Quantum Annealing",
            "updated": "2023-11-03T11:35:55Z",
            "published": "2023-11-03T11:35:55Z",
            "summary": "A strategy for the analysis of active debris removal missions targeting\nmultiple objects from a set of objects in near-circular orbit with similar\ninclination is presented. Algebraic techniques successfully reduce the orbital\nmechanics regarding specific inter-debris transfer and disposal methods to\nsimple computations, which can be used as the coefficients of a quadratic\nunconstrained binary optimisation (QUBO) problem formulation which minimises\nthe total propellant used in the mission whilst allowing for servicing time and\nmeeting the mission deadline. The QUBO is validated by solving artificial small\nproblems (from 2 to 11 debris) using classical computational methods and the\nweaknesses in using these methods are examined prior to solution using quantum\nannealing hardware. The quantum processing unit (QPU) and quantum-classical\nhybrid solvers provided by D-Wave are then used to solve the same small\nproblems, with attention paid to evident strengths and weaknesses of each\napproach. Hybrid solvers are found to be significantly more effective at\nsolving larger problems. Finally, the hybrid method is used to solve a large\nproblem using a real dataset. From a set of 79 debris objects resulting from\nthe destruction of the Kosmos-1408 satellite, an active debris removal mission\nstarting on 30 September 2023 targeting 5 debris objects for disposal within a\nyear with 20 days servicing time per object is successfully planned. This plan\ncalculates the total propellant cost of transfer and disposal to be 0.87km/s\nand would be complete well within the deadline at 241 days from the start date.\nThis problem uses 6,478 binary variables in total and is solved using around\n25s of QPU access time.",
            "author": [
                "Thomas Swain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01852v1",
                "http://arxiv.org/pdf/2311.01852v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01851v1",
            "title": "Holistic Representation Learning for Multitask Trajectory Anomaly\n  Detection",
            "updated": "2023-11-03T11:32:53Z",
            "published": "2023-11-03T11:32:53Z",
            "summary": "Video anomaly detection deals with the recognition of abnormal events in\nvideos. Apart from the visual signal, video anomaly detection has also been\naddressed with the use of skeleton sequences. We propose a holistic\nrepresentation of skeleton trajectories to learn expected motions across\nsegments at different times. Our approach uses multitask learning to\nreconstruct any continuous unobserved temporal segment of the trajectory\nallowing the extrapolation of past or future segments and the interpolation of\nin-between segments. We use an end-to-end attention-based encoder-decoder. We\nencode temporally occluded trajectories, jointly learn latent representations\nof the occluded segments, and reconstruct trajectories based on expected\nmotions across different temporal segments. Extensive experiments on three\ntrajectory-based video anomaly detection datasets show the advantages and\neffectiveness of our approach with state-of-the-art results on anomaly\ndetection in skeleton trajectories.",
            "author": [
                "Alexandros Stergiou",
                "Brent De Weerdt",
                "Nikos Deligiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01851v1",
                "http://arxiv.org/pdf/2311.01851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01850v1",
            "title": "Leveraging Mobile Learning Platforms for Flexible Education Delivery:\n  Bridging Educational Gaps in Afghanistan",
            "updated": "2023-11-03T11:26:55Z",
            "published": "2023-11-03T11:26:55Z",
            "summary": "The educational landscape of Afghanistan, besieged by infrastructural\ninadequacies and socio-political tribulations, presents a compelling case for\nthe integration of mobile learning platforms. This article embarks on an\nexploratory voyage into the realms of mobile learning as a potential harbinger\nof educational transformation in Afghanistan. It delineates the pervasive\neducational challenges, underscores the technological innovations powering\nmobile learning platforms, and illuminates the pathways through which mobile\nlearning can transcend the extant barriers to education. Enriched by real-world\ncase studies, the narrative unravels the pragmatic lessons that can be\nharnessed to tailor mobile learning solutions to Afghanistan's unique context.\nThe discussion further traverses the collaborative horizon, elucidating the\nsynergistic interplay among academia, government, the private sector, and\ninternational bodies essential for the successful implementation of mobile\nlearning platforms. The article also furnishes pragmatic recommendations,\nemphasizing the triad of policy formulation, infrastructure enhancement, and\ncapacity building as cornerstone imperatives. The envisioned integration of\nmobile learning platforms augurs a paradigmatic shift towards a more\naccessible, inclusive, and resilient educational framework in Afghanistan, with\nfar-reaching implications for socio-economic development. Through a meticulous\namalgamation of technology, policy, and collaborative endeavors, this article\nposits that Afghanistan stands on the cusp of an educational renaissance, with\nmobile learning platforms serving as a pivotal conduit toward this envisioned\nhorizon.",
            "author": [
                "Mursal Dawodi",
                "Jawid Ahmad Baktash",
                "Sayed Mohammad Reza Dawodi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01850v1",
                "http://arxiv.org/pdf/2311.01850v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01840v1",
            "title": "Spectral Clustering of Attributed Multi-relational Graphs",
            "updated": "2023-11-03T11:05:29Z",
            "published": "2023-11-03T11:05:29Z",
            "summary": "Graph clustering aims at discovering a natural grouping of the nodes such\nthat similar nodes are assigned to a common cluster. Many different algorithms\nhave been proposed in the literature: for simple graphs, for graphs with\nattributes associated to nodes, and for graphs where edges represent different\ntypes of relations among nodes. However, complex data in many domains can be\nrepresented as both attributed and multi-relational networks.\n  In this paper, we propose SpectralMix, a joint dimensionality reduction\ntechnique for multi-relational graphs with categorical node attributes.\nSpectralMix integrates all information available from the attributes, the\ndifferent types of relations, and the graph structure to enable a sound\ninterpretation of the clustering results. Moreover, it generalizes existing\ntechniques: it reduces to spectral embedding and clustering when only applied\nto a single graph and to homogeneity analysis when applied to categorical data.\nExperiments conducted on several real-world datasets enable us to detect\ndependencies between graph structure and categorical attributes, moreover, they\nexhibit the superiority of SpectralMix over existing methods.",
            "author": [
                "Ylli Sadikaj",
                "Yllka Velaj",
                "Sahar Behzadi",
                "Claudia Plant"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3447548.3467381",
                "http://arxiv.org/abs/2311.01840v1",
                "http://arxiv.org/pdf/2311.01840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01838v1",
            "title": "When fairness is an abstraction: Equity and AI in Swedish compulsory\n  education",
            "updated": "2023-11-03T10:52:16Z",
            "published": "2023-11-03T10:52:16Z",
            "summary": "Artificial intelligence experts often question whether AI is fair. They view\nfairness as a property of AI systems rather than of sociopolitical and economic\nsystems. This paper emphasizes the need to be fair in the social, political,\nand economic contexts within which an educational system operates and uses AI.\nTaking Swedish decentralized compulsory education as the context, this paper\nexamines whether and how the use of AI envisaged by national authorities and\nedtech companies exacerbates unfairness. A qualitative content analysis of\nselected Swedish policy documents and edtech reports was conducted using the\nconcept of relevant social groups to understand how different groups view the\nrisks and benefits of AI for fairness. Three groups that view efficiency as a\nkey value of AI are identified, and interpreted as economical, pedagogical and\naccessibility-related. By separating fairness from social justice, this paper\nchallenges the notion of fairness as the formal equality of opportunities.",
            "author": [
                "Marie Utterberg Mod\u00e9n",
                "Marisa Ponti",
                "Johan Lundin",
                "Martin Tallvid"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01838v1",
                "http://arxiv.org/pdf/2311.01838v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "K.3; K.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01830v1",
            "title": "Automated ab initio-accurate atomistic simulations of dissociated\n  dislocations",
            "updated": "2023-11-03T10:37:39Z",
            "published": "2023-11-03T10:37:39Z",
            "summary": "In (M Hodapp and A Shapeev 2020 Mach. Learn.: Sci. Technol. 1 045005), we\nhave proposed an algorithm that fully automatically trains machine-learning\ninteratomic potentials (MLIPs) during large-scale simulations, and successfully\napplied it to simulate screw dislocation motion in body-centered cubic\ntungsten. The algorithm identifies local subregions of the large-scale\nsimulation region where the potential extrapolates, and then constructs\nperiodic configurations of 100--200 atoms out of these non-periodic subregions\nthat can be efficiently computed with plane-wave Density Functional Theory\n(DFT) codes.\n  In this work, we extend this algorithm to dissociated dislocations with\narbitrary character angles and apply it to partial dislocations in\nface-centered cubic aluminum. Given the excellent agreement with available DFT\nreference results, we argue that our algorithm has the potential to become a\nuniversal way of simulating dissociated dislocations in face-centered cubic and\npossibly also other materials, such as hexagonal closed-packed magnesium, and\ntheir alloys. Moreover, it can be used to construct reliable training sets for\nMLIPs to be used in large-scale simulations of curved dislocations.",
            "author": [
                "Laura Mismetti",
                "Max Hodapp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01830v1",
                "http://arxiv.org/pdf/2311.01830v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01829v1",
            "title": "Mix-ME: Quality-Diversity for Multi-Agent Learning",
            "updated": "2023-11-03T10:36:54Z",
            "published": "2023-11-03T10:36:54Z",
            "summary": "In many real-world systems, such as adaptive robotics, achieving a single,\noptimised solution may be insufficient. Instead, a diverse set of\nhigh-performing solutions is often required to adapt to varying contexts and\nrequirements. This is the realm of Quality-Diversity (QD), which aims to\ndiscover a collection of high-performing solutions, each with their own unique\ncharacteristics. QD methods have recently seen success in many domains,\nincluding robotics, where they have been used to discover damage-adaptive\nlocomotion controllers. However, most existing work has focused on single-agent\nsettings, despite many tasks of interest being multi-agent. To this end, we\nintroduce Mix-ME, a novel multi-agent variant of the popular MAP-Elites\nalgorithm that forms new solutions using a crossover-like operator by mixing\ntogether agents from different teams. We evaluate the proposed methods on a\nvariety of partially observable continuous control tasks. Our evaluation shows\nthat these multi-agent variants obtained by Mix-ME not only compete with\nsingle-agent baselines but also often outperform them in multi-agent settings\nunder partial observability.",
            "author": [
                "Gar\u00f0ar Ingvarsson",
                "Mikayel Samvelyan",
                "Bryan Lim",
                "Manon Flageat",
                "Antoine Cully",
                "Tim Rockt\u00e4schel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01829v1",
                "http://arxiv.org/pdf/2311.01829v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01826v1",
            "title": "Ensemble Principal Component Analysis",
            "updated": "2023-11-03T10:29:27Z",
            "published": "2023-11-03T10:29:27Z",
            "summary": "Efficient representations of data are essential for processing, exploration,\nand human understanding, and Principal Component Analysis (PCA) is one of the\nmost common dimensionality reduction techniques used for the analysis of large,\nmultivariate datasets today. Two well-known limitations of the method include\nsensitivity to outliers and noise and no clear methodology for the uncertainty\nquantification of the principle components or their associated explained\nvariances. Whereas previous work has focused on each of these problems\nindividually, we propose a scalable method called Ensemble PCA (EPCA) that\naddresses them simultaneously for data which has an inherently low-rank\nstructure. EPCA combines boostrapped PCA with k-means cluster analysis to\nhandle challenges associated with sign-ambiguity and the re-ordering of\ncomponents in the PCA subsamples. EPCA provides a noise-resistant extension of\nPCA that lends itself naturally to uncertainty quantification. We test EPCA on\ndata corrupted with white noise, sparse noise, and outliers against both\nclassical PCA and Robust PCA (RPCA) and show that EPCA performs competitively\nacross different noise scenarios, with a clear advantage on datasets containing\noutliers and orders of magnitude reduction in computational cost compared to\nRPCA.",
            "author": [
                "Olga Dorabiala",
                "Aleksandr Aravkin",
                "J. Nathan Kutz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01826v1",
                "http://arxiv.org/pdf/2311.01826v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "62F40, 62H30",
                "I.5.3; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01825v2",
            "title": "Large Language Models to the Rescue: Reducing the Complexity in\n  Scientific Workflow Development Using ChatGPT",
            "updated": "2023-11-06T11:43:33Z",
            "published": "2023-11-03T10:28:53Z",
            "summary": "Scientific workflow systems are increasingly popular for expressing and\nexecuting complex data analysis pipelines over large datasets, as they offer\nreproducibility, dependability, and scalability of analyses by automatic\nparallelization on large compute clusters. However, implementing workflows is\ndifficult due to the involvement of many black-box tools and the deep\ninfrastructure stack necessary for their execution. Simultaneously,\nuser-supporting tools are rare, and the number of available examples is much\nlower than in classical programming languages. To address these challenges, we\ninvestigate the efficiency of Large Language Models (LLMs), specifically\nChatGPT, to support users when dealing with scientific workflows. We performed\nthree user studies in two scientific domains to evaluate ChatGPT for\ncomprehending, adapting, and extending workflows. Our results indicate that\nLLMs efficiently interpret workflows but achieve lower performance for\nexchanging components or purposeful workflow extensions. We characterize their\nlimitations in these challenging scenarios and suggest future research\ndirections.",
            "author": [
                "Mario S\u00e4nger",
                "Ninon De Mecquenem",
                "Katarzyna Ewa Lewi\u0144ska",
                "Vasilis Bountris",
                "Fabian Lehmann",
                "Ulf Leser",
                "Thomas Kosch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01825v2",
                "http://arxiv.org/pdf/2311.01825v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01823v1",
            "title": "Multi-LiDAR Localization and Mapping Pipeline for Urban Autonomous\n  Driving",
            "updated": "2023-11-03T10:24:20Z",
            "published": "2023-11-03T10:24:20Z",
            "summary": "Autonomous vehicles require accurate and robust localization and mapping\nalgorithms to navigate safely and reliably in urban environments. We present a\nnovel sensor fusion-based pipeline for offline mapping and online localization\nbased on LiDAR sensors. The proposed approach leverages four LiDAR sensors.\nMapping and localization algorithms are based on the KISS-ICP, enabling\nreal-time performance and high accuracy. We introduce an approach to generate\nsemantic maps for driving tasks such as path planning. The presented pipeline\nis integrated into the ROS 2 based Autoware software stack, providing a robust\nand flexible environment for autonomous driving applications. We show that our\npipeline outperforms state-of-the-art approaches for a given research vehicle\nand real-world autonomous driving application.",
            "author": [
                "Florian Sauerbeck",
                "Dominik Kulmer",
                "Markus Pielmeier",
                "Maximilian Leitenstern",
                "Christoph Wei\u00df",
                "Johannes Betz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01823v1",
                "http://arxiv.org/pdf/2311.01823v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01820v1",
            "title": "Minimalist Grammar: Construction without Overgeneration",
            "updated": "2023-11-03T10:02:00Z",
            "published": "2023-11-03T10:02:00Z",
            "summary": "In this paper we give instructions on how to write a minimalist grammar (MG).\nIn order to present the instructions as an algorithm, we use a variant of\ncontext free grammars (CFG) as an input format. We can exclude overgeneration,\nif the CFG has no recursion, i.e. no non-terminal can (indirectly) derive to a\nright-hand side containing itself. The constructed MGs utilize licensors/-ees\nas a special way of exception handling. A CFG format for a derivation\n$A\\_eats\\_B\\mapsto^* peter\\_eats\\_apples$, where $A$ and $B$ generate noun\nphrases, normally leads to overgeneration, e.\\,g., $i\\_eats\\_apples$. In order\nto avoid overgeneration, a CFG would need many non-terminal symbols and rules,\nthat mainly produce the same word, just to handle exceptions. In our MGs\nhowever, we can summarize CFG rules that produce the same word in one item and\nhandle exceptions by a proper distribution of licensees/-ors. The difficulty\nwith this technique is that in most generations the majority of licensees/-ors\nis not needed, but still has to be triggered somehow. We solve this problem\nwith $\\epsilon$-items called \\emph{adapters}.",
            "author": [
                "Isidor Konrad Maier",
                "Johannes Kuhn",
                "Jesse Beisegel",
                "Markus Huber-Liebl",
                "Matthias Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01820v1",
                "http://arxiv.org/pdf/2311.01820v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01817v1",
            "title": "Mitigating Framing Bias with Polarity Minimization Loss",
            "updated": "2023-11-03T09:50:23Z",
            "published": "2023-11-03T09:50:23Z",
            "summary": "Framing bias plays a significant role in exacerbating political polarization\nby distorting the perception of actual events. Media outlets with divergent\npolitical stances often use polarized language in their reporting of the same\nevent. We propose a new loss function that encourages the model to minimize the\npolarity difference between the polarized input articles to reduce framing\nbias. Specifically, our loss is designed to jointly optimize the model to map\npolarity ends bidirectionally. Our experimental results demonstrate that\nincorporating the proposed polarity minimization loss leads to a substantial\nreduction in framing bias when compared to a BART-based multi-document\nsummarization model. Notably, we find that the effectiveness of this approach\nis most pronounced when the model is trained to minimize the polarity loss\nassociated with informational framing bias (i.e., skewed selection of\ninformation to report).",
            "author": [
                "Yejin Bang",
                "Nayeon Lee",
                "Pascale Fung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01817v1",
                "http://arxiv.org/pdf/2311.01817v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01815v2",
            "title": "Estimating 3D Uncertainty Field: Quantifying Uncertainty for Neural\n  Radiance Fields",
            "updated": "2023-11-26T03:44:36Z",
            "published": "2023-11-03T09:47:53Z",
            "summary": "Current methods based on Neural Radiance Fields (NeRF) significantly lack the\ncapacity to quantify uncertainty in their predictions, particularly on the\nunseen space including the occluded and outside scene content. This limitation\nhinders their extensive applications in robotics, where the reliability of\nmodel predictions has to be considered for tasks such as robotic exploration\nand planning in unknown environments. To address this, we propose a novel\napproach to estimate a 3D Uncertainty Field based on the learned incomplete\nscene geometry, which explicitly identifies these unseen regions. By\nconsidering the accumulated transmittance along each camera ray, our\nUncertainty Field infers 2D pixel-wise uncertainty, exhibiting high values for\nrays directly casting towards occluded or outside the scene content. To\nquantify the uncertainty on the learned surface, we model a stochastic radiance\nfield. Our experiments demonstrate that our approach is the only one that can\nexplicitly reason about high uncertainty both on 3D unseen regions and its\ninvolved 2D rendered pixels, compared with recent methods. Furthermore, we\nillustrate that our designed uncertainty field is ideally suited for real-world\nrobotics tasks, such as next-best-view selection.",
            "author": [
                "Jianxiong Shen",
                "Ruijie Ren",
                "Adria Ruiz",
                "Francesc Moreno-Noguer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01815v2",
                "http://arxiv.org/pdf/2311.01815v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01813v2",
            "title": "FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain\n  Text-to-Video Generation",
            "updated": "2023-11-08T11:53:01Z",
            "published": "2023-11-03T09:46:05Z",
            "summary": "Recently, open-domain text-to-video (T2V) generation models have made\nremarkable progress. However, the promising results are mainly shown by the\nqualitative cases of generated videos, while the quantitative evaluation of T2V\nmodels still faces two critical problems. Firstly, existing studies lack\nfine-grained evaluation of T2V models on different categories of text prompts.\nAlthough some benchmarks have categorized the prompts, their categorization\neither only focuses on a single aspect or fails to consider the temporal\ninformation in video generation. Secondly, it is unclear whether the automatic\nevaluation metrics are consistent with human standards. To address these\nproblems, we propose FETV, a benchmark for Fine-grained Evaluation of\nText-to-Video generation. FETV is multi-aspect, categorizing the prompts based\non three orthogonal aspects: the major content, the attributes to control and\nthe prompt complexity. FETV is also temporal-aware, which introduces several\ntemporal categories tailored for video generation. Based on FETV, we conduct\ncomprehensive manual evaluations of four representative T2V models, revealing\ntheir pros and cons on different categories of prompts from different aspects.\nWe also extend FETV as a testbed to evaluate the reliability of automatic T2V\nmetrics. The multi-aspect categorization of FETV enables fine-grained analysis\nof the metrics' reliability in different scenarios. We find that existing\nautomatic metrics (e.g., CLIPScore and FVD) correlate poorly with human\nevaluation. To address this problem, we explore several solutions to improve\nCLIPScore and FVD, and develop two automatic metrics that exhibit significant\nhigher correlation with humans than existing metrics. Benchmark page:\nhttps://github.com/llyx97/FETV.",
            "author": [
                "Yuanxin Liu",
                "Lei Li",
                "Shuhuai Ren",
                "Rundong Gao",
                "Shicheng Li",
                "Sishuo Chen",
                "Xu Sun",
                "Lu Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01813v2",
                "http://arxiv.org/pdf/2311.01813v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01811v1",
            "title": "DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with\n  Diffusion Auto-encoder",
            "updated": "2023-11-03T09:41:51Z",
            "published": "2023-11-03T09:41:51Z",
            "summary": "Generating high-quality and person-generic visual dubbing remains a\nchallenge. Recent innovation has seen the advent of a two-stage paradigm,\ndecoupling the rendering and lip synchronization process facilitated by\nintermediate representation as a conduit. Still, previous methodologies rely on\nrough landmarks or are confined to a single speaker, thus limiting their\nperformance. In this paper, we propose DiffDub: Diffusion-based dubbing. We\nfirst craft the Diffusion auto-encoder by an inpainting renderer incorporating\na mask to delineate editable zones and unaltered regions. This allows for\nseamless filling of the lower-face region while preserving the remaining parts.\nThroughout our experiments, we encountered several challenges. Primarily, the\nsemantic encoder lacks robustness, constricting its ability to capture\nhigh-level features. Besides, the modeling ignored facial positioning, causing\nmouth or nose jitters across frames. To tackle these issues, we employ\nversatile strategies, including data augmentation and supplementary eye\nguidance. Moreover, we encapsulated a conformer-based reference encoder and\nmotion generator fortified by a cross-attention mechanism. This enables our\nmodel to learn person-specific textures with varying references and reduces\nreliance on paired audio-visual data. Our rigorous experiments comprehensively\nhighlight that our ground-breaking approach outpaces existing methods with\nconsiderable margins and delivers seamless, intelligible videos in\nperson-generic and multilingual scenarios.",
            "author": [
                "Tao Liu",
                "Chenpeng Du",
                "Shuai Fan",
                "Feilong Chen",
                "Kai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01811v1",
                "http://arxiv.org/pdf/2311.01811v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01804v2",
            "title": "inkn'hue: Enhancing Manga Colorization from Multiple Priors with\n  Alignment Multi-Encoder VAE",
            "updated": "2023-11-07T15:06:50Z",
            "published": "2023-11-03T09:33:32Z",
            "summary": "Manga, a form of Japanese comics and distinct visual storytelling, has\ncaptivated readers worldwide. Traditionally presented in black and white,\nmanga's appeal lies in its ability to convey complex narratives and emotions\nthrough intricate line art and shading. Yet, the desire to experience manga in\nvibrant colors has sparked the pursuit of manga colorization, a task of\nparamount significance for artists. However, existing methods, originally\ndesigned for line art and sketches, face challenges when applied to manga.\nThese methods often fall short in achieving the desired results, leading to the\nneed for specialized manga-specific solutions. Existing approaches frequently\nrely on a single training step or extensive manual artist intervention, which\ncan yield less satisfactory outcomes. To address these challenges, we propose a\nspecialized framework for manga colorization. Leveraging established models for\nshading and vibrant coloring, our approach aligns both using a multi-encoder\nVAE. This structured workflow ensures clear and colorful results, with the\noption to incorporate reference images and manual hints.",
            "author": [
                "Tawin Jiramahapokee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01804v2",
                "http://arxiv.org/pdf/2311.01804v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02126v1",
            "title": "PILL: Plug Into LLM with Adapter Expert and Attention Gate",
            "updated": "2023-11-03T09:31:10Z",
            "published": "2023-11-03T09:31:10Z",
            "summary": "Due to the remarkable capabilities of powerful Large Language Models (LLMs)\nin effectively following instructions, there has been a growing number of\nassistants in the community to assist humans. Recently, significant progress\nhas been made in the development of Vision Language Models (VLMs), expanding\nthe capabilities of LLMs and enabling them to execute more diverse\ninstructions. However, it is foreseeable that models will likely need to handle\ntasks involving additional modalities such as speech, video, and others. This\nposes a particularly prominent challenge of dealing with the complexity of\nmixed modalities. To address this, we introduce a novel architecture called\nPILL: Plug Into LLM with adapter expert and attention gate to better decouple\nthese complex modalities and leverage efficient fine-tuning. We introduce two\nmodules: Firstly, utilizing Mixture-of-Modality-Adapter-Expert to independently\nhandle different modalities, enabling better adaptation to downstream tasks\nwhile preserving the expressive capability of the original model. Secondly, by\nintroducing Modality-Attention-Gating, which enables adaptive control of the\ncontribution of modality tokens to the overall representation. In addition, we\nhave made improvements to the Adapter to enhance its learning and expressive\ncapabilities. Experimental results demonstrate that our approach exhibits\ncompetitive performance compared to other mainstream methods for modality\nfusion. For researchers interested in our work, we provide free access to the\ncode and models at https://github.com/DsaltYfish/PILL.",
            "author": [
                "Fangyuan Zhang",
                "Tingting Liang",
                "Zhengyuan Wu",
                "Yuyu Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02126v1",
                "http://arxiv.org/pdf/2311.02126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01798v1",
            "title": "Passive elasticity properties of $\\textit{Octopus rubescens}$ arm",
            "updated": "2023-11-03T09:22:45Z",
            "published": "2023-11-03T09:22:45Z",
            "summary": "In this report, passive elasticity properties of $\\textit{Octopus rubescens}$\narm tissue are investigated using a multidisciplinary approach encompassing\nbiomechanical experiments, computational modeling, and analyses. Tensile tests\nare conducted to obtain stress-strain relationships of the arm under axial\nstretch. Rheological tests are also performed to probe into dynamic shear\nresponse of the arm tissue. Based on these tests, comparisons against three\ndifferent viscoelasticity models are reported.",
            "author": [
                "Udit Halder",
                "Ekaterina Gribkova",
                "Rhanor Gillette",
                "Prashant G. Mehta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01798v1",
                "http://arxiv.org/pdf/2311.01798v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03384v1",
            "title": "Serious Games in Digital Gaming: A Comprehensive Review of Applications,\n  Game Engines and Advancements",
            "updated": "2023-11-03T09:17:09Z",
            "published": "2023-11-03T09:17:09Z",
            "summary": "Serious games are defined as applied games that focus on the gamification of\nan experience (e.g., learning and training activities) and are not strictly for\nentertainment purposes. In recent years, serious games have become increasingly\npopular due to their ability to simultaneously educate and entertain users. In\nthis review, we provide a comprehensive overview of the different types of\ndigital games and expand on the serious games genre while focusing on its\nvarious applications. Furthermore, we present the most widely used game engines\nused in the game development industry and extend the Unity game machine\nadvantages. Lastly, we conclude our research with a detailed comparison of the\ntwo most popular choices (Unreal and Unity engines) and their respective\nadvantages and disadvantages while providing future suggestions for serious\ndigital game development.",
            "author": [
                "Alexandros Gazis",
                "Eleftheria Katsiri"
            ],
            "link": [
                "http://dx.doi.org/10.37394/232018.2023.11.2",
                "http://arxiv.org/abs/2311.03384v1",
                "http://arxiv.org/pdf/2311.03384v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04924v1",
            "title": "Tuning-less Object Naming with a Foundation Model",
            "updated": "2023-11-03T09:11:49Z",
            "published": "2023-11-03T09:11:49Z",
            "summary": "We implement a real-time object naming system that enables learning a set of\nnamed entities never seen. Our approach employs an existing foundation model\nthat we consider ready to see anything before starting. It turns seen images\ninto relatively small feature vectors that we associate with index to a\ngradually built vocabulary without any training of fine-tuning of the model.\nOur contribution is using the association mechanism known from transformers as\nattention. It has features that support generalization from irrelevant\ninformation for distinguishing the entities and potentially enable associating\nwith much more than indices to vocabulary. As a result, the system can work in\na one-shot manner and correctly name objects named in different contents. We\nalso outline implementation details of the system modules integrated by a\nblackboard architecture. Finally, we investigate the system's quality, mainly\nhow many objects it can handle in this way.",
            "author": [
                "Andrej Lucny",
                "Pavel Petrovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04924v1",
                "http://arxiv.org/pdf/2311.04924v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01793v1",
            "title": "Near-Optimal Quantum Algorithms for Bounded Edit Distance and Lempel-Ziv\n  Factorization",
            "updated": "2023-11-03T09:09:23Z",
            "published": "2023-11-03T09:09:23Z",
            "summary": "Classically, the edit distance of two length-$n$ strings can be computed in\n$O(n^2)$ time, whereas an $O(n^{2-\\epsilon})$-time procedure would falsify the\nOrthogonal Vectors Hypothesis. If the edit distance does not exceed $k$, the\nrunning time can be improved to $O(n+k^2)$, which is near-optimal (conditioned\non OVH) as a function of $n$ and $k$. Our first main contribution is a quantum\n$\\tilde{O}(\\sqrt{nk}+k^2)$-time algorithm that uses $\\tilde{O}(\\sqrt{nk})$\nqueries, where $\\tilde{O}(\\cdot)$ hides polylogarithmic factors. This query\ncomplexity is unconditionally optimal, and any significant improvement in the\ntime complexity would resolve a long-standing open question of whether edit\ndistance admits an $O(n^{2-\\epsilon})$-time quantum algorithm. Our\ndivide-and-conquer quantum algorithm reduces the edit distance problem to a\ncase where the strings have small Lempel-Ziv factorizations. Then, it combines\na quantum LZ compression algorithm with a classical edit-distance subroutine\nfor compressed strings.\n  The LZ factorization problem can be classically solved in $O(n)$ time, which\nis unconditionally optimal in the quantum setting. We can, however, hope for a\nquantum speedup if we parameterize the complexity in terms of the factorization\nsize $z$. Already a generic oracle identification algorithm yields the optimal\nquery complexity of $\\tilde{O}(\\sqrt{nz})$ at the price of exponential running\ntime. Our second main contribution is a quantum algorithm that achieves the\noptimal time complexity of $\\tilde{O}(\\sqrt{nz})$. The key tool is a novel\nLZ-like factorization of size $O(z\\log^2n)$ whose subsequent factors can be\nefficiently computed through a combination of classical and quantum techniques.\nWe can then obtain the string's run-length encoded Burrows-Wheeler Transform\n(BWT), construct the $r$-index, and solve many fundamental string processing\nproblems in time $\\tilde{O}(\\sqrt{nz})$.",
            "author": [
                "Daniel Gibney",
                "Ce Jin",
                "Tomasz Kociumaka",
                "Sharma V. Thankachan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01793v1",
                "http://arxiv.org/pdf/2311.01793v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01792v1",
            "title": "AFPQ: Asymmetric Floating Point Quantization for LLMs",
            "updated": "2023-11-03T09:07:09Z",
            "published": "2023-11-03T09:07:09Z",
            "summary": "Large language models (LLMs) show great performance in various tasks, but\nface deployment challenges from limited memory capacity and bandwidth. Low-bit\nweight quantization can save memory and accelerate inference. Although\nfloating-point (FP) formats show good performance in LLM quantization, they\ntend to perform poorly with small group sizes or sub-4 bits. We find the reason\nis that the absence of asymmetry in previous FP quantization makes it\nunsuitable for handling asymmetric value distribution of LLM weight tensors. In\nthis work, we propose asymmetric FP quantization (AFPQ), which sets separate\nscales for positive and negative values. Our method leads to large accuracy\nimprovements and can be easily plugged into other quantization methods,\nincluding GPTQ and AWQ, for better performance. Besides, no additional storage\nis needed compared with asymmetric integer (INT) quantization. The code is\navailable at https://github.com/zhangsichengsjtu/AFPQ.",
            "author": [
                "Yijia Zhang",
                "Sicheng Zhang",
                "Shijie Cao",
                "Dayou Du",
                "Jianyu Wei",
                "Ting Cao",
                "Ningyi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01792v1",
                "http://arxiv.org/pdf/2311.01792v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01791v1",
            "title": "Stable twisted cohomology of the mapping class groups in the exterior\n  powers of the unit tangent bundle homology",
            "updated": "2023-11-03T09:05:46Z",
            "published": "2023-11-03T09:05:46Z",
            "summary": "We study the stable cohomology groups of the mapping class groups of surfaces\nwith twisted coefficients given by the $d^{th}$ exterior powers of the first\nrational homology of the unit tangent bundles of the surfaces\n$\\tilde{H}_{\\mathbb{Q}}$. These coefficients are outside of the traditional\nframework of cohomological stability. They form a module\n$H_{\\mathrm{st}}^{*}(\\Lambda^{d}\\tilde{H}_{\\mathbb{Q}})$ over the stable\ncohomology algebra of the mapping class groups with trivial coefficients\ndenoted by $\\mathrm{Sym}_{\\mathbb{Q}}(\\mathcal{E})$. If $d\\neq 2$, the\n$\\mathrm{Tor}$-group in each degree of\n$H_{\\mathrm{st}}^{*}(\\Lambda^{d}\\tilde{H}_{\\mathbb{Q}})$ does not vanish, and\nwe compute all these $\\mathrm{Tor}$-groups explicitly for $d \\leq 5$. In\nparticular, for each $d\\neq 2$, the module\n$H_{\\mathrm{st}}^{*}(\\Lambda^{d}\\tilde{H}_{\\mathbb{Q}})$ is not free over\n$\\mathrm{Sym}_{\\mathbb{Q}}(\\mathcal{E})$, while it is free for $d=2$.For\ncomparison, we also compute the stable cohomology group with coefficients in\nthe $d^{th}$ exterior powers of the first rational cohomology of the unit\ntangent bundle of the surface, which fit into the classical framework of\ncohomological stability.",
            "author": [
                "Nariya Kawazumi",
                "Arthur Souli\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01791v1",
                "http://arxiv.org/pdf/2311.01791v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.AT",
                "math.GR",
                "math.RA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01790v2",
            "title": "A First Order Theory of Diagram Chasing",
            "updated": "2023-11-28T13:08:02Z",
            "published": "2023-11-03T09:04:19Z",
            "summary": "This paper discusses the formalization of proofs \"by diagram chasing\", a\nstandard technique for proving properties in abelian categories. We discuss how\nthe essence of diagram chases can be captured by a simple many-sorted\nfirst-order theory, and we study the models and decidability of this theory.\nThe longer-term motivation of this work is the design of a computer-aided\ninstrument for writing reliable proofs in homological algebra, based on\ninteractive theorem provers.",
            "author": [
                "Assia Mahboubi",
                "Matthieu Piquerez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01790v2",
                "http://arxiv.org/pdf/2311.01790v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01788v1",
            "title": "Fast ellipsoidal conformal and quasi-conformal parameterization of\n  genus-0 closed surfaces",
            "updated": "2023-11-03T09:01:37Z",
            "published": "2023-11-03T09:01:37Z",
            "summary": "Surface parameterization plays a fundamental role in many science and\nengineering problems. In particular, as genus-0 closed surfaces are\ntopologically equivalent to a sphere, many spherical parameterization methods\nhave been developed over the past few decades. However, in practice, mapping a\ngenus-0 closed surface onto a sphere may result in a large distortion due to\ntheir geometric difference. In this work, we propose a new framework for\ncomputing ellipsoidal conformal and quasi-conformal parameterizations of\ngenus-0 closed surfaces, in which the target parameter domain is an ellipsoid\ninstead of a sphere. By combining simple conformal transformations with\ndifferent types of quasi-conformal mappings, we can easily achieve a large\nvariety of ellipsoidal parameterizations with their bijectivity guaranteed by\nquasi-conformal theory. Numerical experiments are presented to demonstrate the\neffectiveness of the proposed framework.",
            "author": [
                "Gary P. T. Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01788v1",
                "http://arxiv.org/pdf/2311.01788v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.GR",
                "math.CV",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04923v2",
            "title": "Is one brick enough to break the wall of spoken dialogue state tracking?",
            "updated": "2023-12-05T08:44:12Z",
            "published": "2023-11-03T08:59:51Z",
            "summary": "In Task-Oriented Dialogue (TOD) systems, correctly updating the system's\nunderstanding of the user's needs (a.k.a dialogue state tracking) is key to a\nsmooth interaction. Traditionally, TOD systems perform this update in three\nsteps: transcription of the user's utterance, semantic extraction of the key\nconcepts, and contextualization with the previously identified concepts. Such\ncascade approaches suffer from cascading errors and separate optimization.\nEnd-to-End approaches have been proved helpful up to the semantic extraction\nstep. This paper goes one step further paving the path towards completely\nneural spoken dialogue state tracking by comparing three approaches: (1) a\nstate of the art cascade approach, (2) a locally E2E approach with rule-based\ncontextualization and (3) a completely neural approach.",
            "author": [
                "Lucas Druart",
                "Valentin Vielzeuf",
                "Yannick Est\u00e8ve"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04923v2",
                "http://arxiv.org/pdf/2311.04923v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01787v1",
            "title": "Labour Absorption In Manufacturing Industry In Indonesia: Anomalous And\n  Regressive Phenomena",
            "updated": "2023-11-03T08:58:00Z",
            "published": "2023-11-03T08:58:00Z",
            "summary": "The manufacturing industry sector was expected to generate new employment\nopportunities and take on labour. Gradually, however, it emerged as a menace to\nthe sustenance of its workers. According to the findings of this study, 24\nmanufacturing subsectors with ISIC 2 digits in Indonesia exhibited regressive\nand abnormal patterns in the period 2012-2020. This suggests that, to a great\nextent, labour absorption has been limited and, in some cases, even shown a\ndecline. Anomalous occurrences were observed in three subsectors: ISIC 12\n(tobacco products), ISIC 26 (computer, electronic and optical products), and\nISIC 31 (furniture). In contrast, regressive phenomena were present in the\nremaining 21 ISIC subsectors. Furthermore, the manufacturing industry displayed\na negative correlation between employment and efficiency index, demonstrating\nthis anomalous and regressive phenomenon. This implies that as the efficiency\nindex of the manufacturing industry increases, the index of labour absorption\ndecreases",
            "author": [
                "Tongam Sihol Nababan",
                "Elvis Fresly Purba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01787v1",
                "http://arxiv.org/pdf/2311.01787v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01786v1",
            "title": "TCM-GPT: Efficient Pre-training of Large Language Models for Domain\n  Adaptation in Traditional Chinese Medicine",
            "updated": "2023-11-03T08:54:50Z",
            "published": "2023-11-03T08:54:50Z",
            "summary": "Pre-training and fine-tuning have emerged as a promising paradigm across\nvarious natural language processing (NLP) tasks. The effectiveness of\npretrained large language models (LLM) has witnessed further enhancement,\nholding potential for applications in the field of medicine, particularly in\nthe context of Traditional Chinese Medicine (TCM). However, the application of\nthese general models to specific domains often yields suboptimal results,\nprimarily due to challenges like lack of domain knowledge, unique objectives,\nand computational efficiency. Furthermore, their effectiveness in specialized\ndomains, such as Traditional Chinese Medicine, requires comprehensive\nevaluation. To address the above issues, we propose a novel domain specific\nTCMDA (TCM Domain Adaptation) approach, efficient pre-training with\ndomain-specific corpus. Specifically, we first construct a large TCM-specific\ncorpus, TCM-Corpus-1B, by identifying domain keywords and retreving from\ngeneral corpus. Then, our TCMDA leverages the LoRA which freezes the pretrained\nmodel's weights and uses rank decomposition matrices to efficiently train\nspecific dense layers for pre-training and fine-tuning, efficiently aligning\nthe model with TCM-related tasks, namely TCM-GPT-7B. We further conducted\nextensive experiments on two TCM tasks, including TCM examination and TCM\ndiagnosis. TCM-GPT-7B archived the best performance across both datasets,\noutperforming other models by relative increments of 17% and 12% in accuracy,\nrespectively. To the best of our knowledge, our study represents the pioneering\nvalidation of domain adaptation of a large language model with 7 billion\nparameters in TCM domain. We will release both TCMCorpus-1B and TCM-GPT-7B\nmodel once accepted to facilitate interdisciplinary development in TCM and NLP,\nserving as the foundation for further study.",
            "author": [
                "Guoxing Yang",
                "Jianyu Shi",
                "Zan Wang",
                "Xiaohong Liu",
                "Guangyu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01786v1",
                "http://arxiv.org/pdf/2311.01786v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04922v1",
            "title": "Are cascade dialogue state tracking models speaking out of turn in\n  spoken dialogues?",
            "updated": "2023-11-03T08:45:22Z",
            "published": "2023-11-03T08:45:22Z",
            "summary": "In Task-Oriented Dialogue (TOD) systems, correctly updating the system's\nunderstanding of the user's needs is key to a smooth interaction. Traditionally\nTOD systems are composed of several modules that interact with one another.\nWhile each of these components is the focus of active research communities,\ntheir behavior in interaction can be overlooked. This paper proposes a\ncomprehensive analysis of the errors of state of the art systems in complex\nsettings such as Dialogue State Tracking which highly depends on the dialogue\ncontext. Based on spoken MultiWoz, we identify that errors on non-categorical\nslots' values are essential to address in order to bridge the gap between\nspoken and chat-based dialogue systems. We explore potential solutions to\nimprove transcriptions and help dialogue state tracking generative models\ncorrect such errors.",
            "author": [
                "Lucas Druart",
                "L\u00e9o Jacqmin",
                "Beno\u00eet Favre",
                "Lina Maria Rojas-Barahona",
                "Valentin Vielzeuf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04922v1",
                "http://arxiv.org/pdf/2311.04922v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01782v1",
            "title": "Generating Unbiased Pseudo-labels via a Theoretically Guaranteed\n  Chebyshev Constraint to Unify Semi-supervised Classification and Regression",
            "updated": "2023-11-03T08:39:35Z",
            "published": "2023-11-03T08:39:35Z",
            "summary": "Both semi-supervised classification and regression are practically\nchallenging tasks for computer vision. However, semi-supervised classification\nmethods are barely applied to regression tasks. Because the threshold-to-pseudo\nlabel process (T2L) in classification uses confidence to determine the quality\nof label. It is successful for classification tasks but inefficient for\nregression tasks. In nature, regression also requires unbiased methods to\ngenerate high-quality labels. On the other hand, T2L for classification often\nfails if the confidence is generated by a biased method. To address this issue,\nin this paper, we propose a theoretically guaranteed constraint for generating\nunbiased labels based on Chebyshev's inequality, combining multiple predictions\nto generate superior quality labels from several inferior ones. In terms of\nhigh-quality labels, the unbiased method naturally avoids the drawback of T2L.\nSpecially, we propose an Unbiased Pseudo-labels network (UBPL network) with\nmultiple branches to combine multiple predictions as pseudo-labels, where a\nFeature Decorrelation loss (FD loss) is proposed based on Chebyshev constraint.\nIn principle, our method can be used for both classification and regression and\ncan be easily extended to any semi-supervised framework, e.g. Mean Teacher,\nFixMatch, DualPose. Our approach achieves superior performance over SOTAs on\nthe pose estimation datasets Mouse, FLIC and LSP, as well as the classification\ndatasets CIFAR10/100 and SVHN.",
            "author": [
                "Jiaqi Wu",
                "Junbiao Pang",
                "Qingming Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01782v1",
                "http://arxiv.org/pdf/2311.01782v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02125v1",
            "title": "Using General Value Functions to Learn Domain-Backed Inventory\n  Management Policies",
            "updated": "2023-11-03T08:35:54Z",
            "published": "2023-11-03T08:35:54Z",
            "summary": "We consider the inventory management problem, where the goal is to balance\nconflicting objectives such as availability and wastage of a large range of\nproducts in a store. We propose a reinforcement learning (RL) approach that\nutilises General Value Functions (GVFs) to derive domain-backed inventory\nreplenishment policies. The inventory replenishment decisions are modelled as a\nsequential decision making problem, which is challenging due to uncertain\ndemand and the existence of aggregate (cross-product) constraints. In existing\nliterature, GVFs have primarily been used for auxiliary task learning. We use\nthis capability to train GVFs on domain-critical characteristics such as\nprediction of stock-out probability and wastage quantity. Using this domain\nexpertise for more effective exploration, we train an RL agent to compute the\ninventory replenishment quantities for a large range of products (up to 6000 in\nthe reported experiments), which share aggregate constraints such as the total\nweight/volume per delivery. Additionally, we show that the GVF predictions can\nbe used to provide additional domain-backed insights into the decisions\nproposed by the RL agent. Finally, since the environment dynamics are fully\ntransferred, the trained GVFs can be used for faster adaptation to vastly\ndifferent business objectives (for example, due to the start of a promotional\nperiod or due to deployment in a new customer environment).",
            "author": [
                "Durgesh Kalwar",
                "Omkar Shelke",
                "Harshad Khadilkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02125v1",
                "http://arxiv.org/pdf/2311.02125v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01779v1",
            "title": "Majorana qubit codes that also correct odd-weight errors",
            "updated": "2023-11-03T08:29:38Z",
            "published": "2023-11-03T08:29:38Z",
            "summary": "The tetron architecture is a promising candidate for topological quantum\ncomputation. Each tetron Majorana island has four Majorana zero modes, and\npossible measurements are constrained to span zero or two Majoranas per tetron.\nSuch measurements are known to be sufficient for correcting so-called \"bosonic\nerrors,\" which affect an even number of Majoranas per tetron. We demonstrate\nthat such measurements are also sufficient for correcting \"fermionic errors,\"\nwhich affect an odd number of Majoranas per tetron. In contrast, previous\nproposals for \"fermionic error correction\" on tetrons introduce more\nexperimental challenges. We show that \"fermionic codes\" can be derived from\ntraditional \"bosonic codes\" by inclusion of tetrons in the stabilizer group.",
            "author": [
                "Sourav Kundu",
                "Ben W. Reichardt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01779v1",
                "http://arxiv.org/pdf/2311.01779v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01777v1",
            "title": "CheX-Nomaly: Segmenting Lung Abnormalities from Chest Radiographs using\n  Machine Learning",
            "updated": "2023-11-03T08:27:57Z",
            "published": "2023-11-03T08:27:57Z",
            "summary": "The global challenge in chest radiograph X-ray (CXR) abnormalities often\nbeing misdiagnosed is primarily associated with perceptual errors, where\nhealthcare providers struggle to accurately identify the location of\nabnormalities, rather than misclassification errors. We currently address this\nproblem through disease-specific segmentation models. Unfortunately, these\nmodels cannot be released in the field due to their lack of generalizability\nacross all thoracic diseases. A binary model tends to perform poorly when it\nencounters a disease that isn't represented in the dataset. We present\nCheX-nomaly: a binary localization U-net model that leverages transfer learning\ntechniques with the incorporation of an innovative contrastive learning\napproach. Trained on the VinDr-CXR dataset, which encompasses 14 distinct\ndiseases in addition to 'no finding' cases, my model achieves generalizability\nacross these 14 diseases and others it has not seen before. We show that we can\nsignificantly improve the generalizability of an abnormality localization model\nby incorporating a contrastive learning method and dissociating the bounding\nboxes with its disease class. We also introduce a new loss technique to apply\nto enhance the U-nets performance on bounding box segmentation. By introducing\nCheX-nomaly, we offer a promising solution to enhance the precision of chest\ndisease diagnosis, with a specific focus on reducing the significant number of\nperceptual errors in healthcare.",
            "author": [
                "Sanskriti Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01777v1",
                "http://arxiv.org/pdf/2311.01777v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01775v1",
            "title": "UP4LS: User Profile Constructed by Multiple Attributes for Enhancing\n  Linguistic Steganalysis",
            "updated": "2023-11-03T08:20:48Z",
            "published": "2023-11-03T08:20:48Z",
            "summary": "Linguistic steganalysis (LS) tasks aim to effectively detect stegos generated\nby linguistic steganography. Existing LS methods overlook the distinctive user\ncharacteristics, leading to weak performance in social networks. The limited\noccurrence of stegos further complicates detection. In this paper, we propose\nthe UP4LS, a novel framework with the User Profile for enhancing LS\nperformance. Specifically, by delving into post content, we explore user\nattributes like writing habits, psychological states, and focal areas, thereby\nbuilding the user profile for LS. For each attribute, we design the identified\nfeature extraction module. The extracted features are mapped to\nhigh-dimensional user features via deep-learning networks from existing\nmethods. Then the language model is employed to extract content features. The\nuser and content features are integrated to optimize feature representation.\nDuring the training phase, we prioritize the distribution of stegos.\nExperiments demonstrate that UP4LS can significantly enhance the performance of\nexisting methods, and an overall accuracy improvement of nearly 25%. In\nparticular, the improvement is especially pronounced with fewer stego samples.\nAdditionally, UP4LS also sets the stage for studies on related tasks,\nencouraging extensive applications on LS tasks.",
            "author": [
                "Yihao Wang",
                "Ruiqi Song",
                "Ru Zhang",
                "Jianyi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01775v1",
                "http://arxiv.org/pdf/2311.01775v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01773v1",
            "title": "PDF: Point Diffusion Implicit Function for Large-scale Scene Neural\n  Representation",
            "updated": "2023-11-03T08:19:47Z",
            "published": "2023-11-03T08:19:47Z",
            "summary": "Recent advances in implicit neural representations have achieved impressive\nresults by sampling and fusing individual points along sampling rays in the\nsampling space. However, due to the explosively growing sampling space, finely\nrepresenting and synthesizing detailed textures remains a challenge for\nunbounded large-scale outdoor scenes. To alleviate the dilemma of using\nindividual points to perceive the entire colossal space, we explore learning\nthe surface distribution of the scene to provide structural priors and reduce\nthe samplable space and propose a Point Diffusion implicit Function, PDF, for\nlarge-scale scene neural representation. The core of our method is a\nlarge-scale point cloud super-resolution diffusion module that enhances the\nsparse point cloud reconstructed from several training images into a dense\npoint cloud as an explicit prior. Then in the rendering stage, only sampling\npoints with prior points within the sampling radius are retained. That is, the\nsampling space is reduced from the unbounded space to the scene surface.\nMeanwhile, to fill in the background of the scene that cannot be provided by\npoint clouds, the region sampling based on Mip-NeRF 360 is employed to model\nthe background representation. Expensive experiments have demonstrated the\neffectiveness of our method for large-scale scene novel view synthesis, which\noutperforms relevant state-of-the-art baselines.",
            "author": [
                "Yuhan Ding",
                "Fukun Yin",
                "Jiayuan Fan",
                "Hui Li",
                "Xin Chen",
                "Wen Liu",
                "Chongshan Lu",
                "Gang YU",
                "Tao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01773v1",
                "http://arxiv.org/pdf/2311.01773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01770v1",
            "title": "Modeling the Uncertainty with Maximum Discrepant Students for\n  Semi-supervised 2D Pose Estimation",
            "updated": "2023-11-03T08:11:06Z",
            "published": "2023-11-03T08:11:06Z",
            "summary": "Semi-supervised pose estimation is a practically challenging task for\ncomputer vision. Although numerous excellent semi-supervised classification\nmethods have emerged, these methods typically use confidence to evaluate the\nquality of pseudo-labels, which is difficult to achieve in pose estimation\ntasks. For example, in pose estimation, confidence represents only the\npossibility that a position of the heatmap is a keypoint, not the quality of\nthat prediction. In this paper, we propose a simple yet efficient framework to\nestimate the quality of pseudo-labels in semi-supervised pose estimation tasks\nfrom the perspective of modeling the uncertainty of the pseudo-labels.\nConcretely, under the dual mean-teacher framework, we construct the two maximum\ndiscrepant students (MDSs) to effectively push two teachers to generate\ndifferent decision boundaries for the same sample. Moreover, we create multiple\nuncertainties to assess the quality of the pseudo-labels. Experimental results\ndemonstrate that our method improves the performance of semi-supervised pose\nestimation on three datasets.",
            "author": [
                "Jiaqi Wu",
                "Junbiao Pang",
                "Qingming Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01770v1",
                "http://arxiv.org/pdf/2311.01770v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01767v2",
            "title": "PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task\n  Completion",
            "updated": "2023-11-07T10:13:34Z",
            "published": "2023-11-03T08:06:35Z",
            "summary": "Recent evaluations of Large Language Models (LLMs) have centered around\ntesting their zero-shot/few-shot capabilities for basic natural language tasks\nand their ability to translate instructions into tool APIs. However, the\nevaluation of LLMs utilizing complex tools to finish multi-turn, multi-modal\ninstructions in a complex multi-modal environment has not been investigated. To\naddress this gap, we introduce the PowerPoint Task Completion (PPTC) benchmark\nto assess LLMs' ability to create and edit PPT files based on user\ninstructions. It contains 279 multi-turn sessions covering diverse topics and\nhundreds of instructions involving multi-modal operations. We also propose the\nPPTX-Match Evaluation System that evaluates if LLMs finish the instruction\nbased on the prediction file rather than the label API sequence, thus it\nsupports various LLM-generated API sequences. We measure 3 closed LLMs and 6\nopen-source LLMs. The results show that GPT-4 outperforms other LLMs with\n75.1\\% accuracy in single-turn dialogue testing but faces challenges in\ncompleting entire sessions, achieving just 6\\% session accuracy. We find three\nmain error causes in our benchmark: error accumulation in the multi-turn\nsession, long PPT template processing, and multi-modality perception. These\npose great challenges for future LLM and agent systems. We release the data,\ncode, and evaluation system of PPTC at \\url{https://github.com/gydpku/PPTC}.",
            "author": [
                "Yiduo Guo",
                "Zekai Zhang",
                "Yaobo Liang",
                "Dongyan Zhao",
                "Nan Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01767v2",
                "http://arxiv.org/pdf/2311.01767v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01766v3",
            "title": "Support or Refute: Analyzing the Stance of Evidence to Detect\n  Out-of-Context Mis- and Disinformation",
            "updated": "2023-11-16T07:21:10Z",
            "published": "2023-11-03T08:05:54Z",
            "summary": "Mis- and disinformation online have become a major societal problem as major\nsources of online harms of different kinds. One common form of mis- and\ndisinformation is out-of-context (OOC) information, where different pieces of\ninformation are falsely associated, e.g., a real image combined with a false\ntextual caption or a misleading textual description. Although some past studies\nhave attempted to defend against OOC mis- and disinformation through external\nevidence, they tend to disregard the role of different pieces of evidence with\ndifferent stances. Motivated by the intuition that the stance of evidence\nrepresents a bias towards different detection results, we propose a stance\nextraction network (SEN) that can extract the stances of different pieces of\nmulti-modal evidence in a unified framework. Moreover, we introduce a\nsupport-refutation score calculated based on the co-occurrence relations of\nnamed entities into the textual SEN. Extensive experiments on a public\nlarge-scale dataset demonstrated that our proposed method outperformed the\nstate-of-the-art baselines, with the best model achieving a performance gain of\n3.2% in accuracy.",
            "author": [
                "Xin Yuan",
                "Jie Guo",
                "Weidong Qiu",
                "Zheng Huang",
                "Shujun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01766v3",
                "http://arxiv.org/pdf/2311.01766v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05640v1",
            "title": "FinGPT: Large Generative Models for a Small Language",
            "updated": "2023-11-03T08:05:04Z",
            "published": "2023-11-03T08:05:04Z",
            "summary": "Large language models (LLMs) excel in many tasks in NLP and beyond, but most\nopen models have very limited coverage of smaller languages and LLM work tends\nto focus on languages where nearly unlimited data is available for pretraining.\nIn this work, we study the challenges of creating LLMs for Finnish, a language\nspoken by less than 0.1% of the world population. We compile an extensive\ndataset of Finnish combining web crawls, news, social media and eBooks. We\npursue two approaches to pretrain models: 1) we train seven monolingual models\nfrom scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the\npretraining of the multilingual BLOOM model on a mix of its original training\ndata and Finnish, resulting in a 176 billion parameter model we call BLUUMI.\nFor model evaluation, we introduce FIN-bench, a version of BIG-bench with\nFinnish tasks. We also assess other model qualities such as toxicity and bias.\nOur models and tools are openly available at https://turkunlp.org/gpt3-finnish.",
            "author": [
                "Risto Luukkonen",
                "Ville Komulainen",
                "Jouni Luoma",
                "Anni Eskelinen",
                "Jenna Kanerva",
                "Hanna-Mari Kupari",
                "Filip Ginter",
                "Veronika Laippala",
                "Niklas Muennighoff",
                "Aleksandra Piktus",
                "Thomas Wang",
                "Nouamane Tazi",
                "Teven Le Scao",
                "Thomas Wolf",
                "Osma Suominen",
                "Samuli Sairanen",
                "Mikko Merioksa",
                "Jyrki Heinonen",
                "Aija Vahtola",
                "Samuel Antao",
                "Sampo Pyysalo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05640v1",
                "http://arxiv.org/pdf/2311.05640v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02173v1",
            "title": "TailorMe: Self-Supervised Learning of an Anatomically Constrained\n  Volumetric Human Shape Model",
            "updated": "2023-11-03T07:42:19Z",
            "published": "2023-11-03T07:42:19Z",
            "summary": "Human shape spaces have been extensively studied, as they are a core element\nof human shape and pose inference tasks. Classic methods for creating a human\nshape model register a surface template mesh to a database of 3D scans and use\ndimensionality reduction techniques, such as Principal Component Analysis, to\nlearn a compact representation. While these shape models enable global shape\nmodifications by correlating anthropometric measurements with the learned\nsubspace, they only provide limited localized shape control. We instead\nregister a volumetric anatomical template, consisting of skeleton bones and\nsoft tissue, to the surface scans of the CAESAR database. We further enlarge\nour training data to the full Cartesian product of all skeletons and all soft\ntissues using physically plausible volumetric deformation transfer. This data\nis then used to learn an anatomically constrained volumetric human shape model\nin a self-supervised fashion. The resulting TailorMe model enables shape\nsampling, localized shape manipulation, and fast inference from given surface\nscans.",
            "author": [
                "Stephan Wenninger",
                "Fabian Kemper",
                "Ulrich Schwanecke",
                "Mario Botsch"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02173v1",
                "http://arxiv.org/pdf/2312.02173v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "I.3.0; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01757v1",
            "title": "Indo LEGO-ABSA: A Multitask Generative Aspect Based Sentiment Analysis\n  for Indonesian Language",
            "updated": "2023-11-03T07:28:12Z",
            "published": "2023-11-03T07:28:12Z",
            "summary": "Aspect-based sentiment analysis is a method in natural language processing\naimed at identifying and understanding sentiments related to specific aspects\nof an entity. Aspects are words or phrases that represent an aspect or\nattribute of a particular entity. Previous research has utilized generative\npre-trained language models to perform aspect-based sentiment analysis.\nLEGO-ABSA is one framework that has successfully employed generative\npre-trained language models in aspect-based sentiment analysis, particularly in\nEnglish. LEGO-ABSA uses a multitask learning and prompting approach to enhance\nmodel performance. However, the application of this approach has not been done\nin the context of Bahasa Indonesia. Therefore, this research aims to implement\nthe multitask learning and prompting approach in aspect-based sentiment\nanalysis for Bahasa Indonesia using generative pre-trained language models. In\nthis study, the Indo LEGO-ABSA model is developed, which is an aspect-based\nsentiment analysis model utilizing generative pre-trained language models and\ntrained with multitask learning and prompting. Indo LEGO-ABSA is trained with a\nhotel domain dataset in the Indonesian language. The obtained results include\nan f1-score of 79.55% for the Aspect Sentiment Triplet Extraction task, 86.09%\nfor Unified Aspect-based Sentiment Analysis, 79.85% for Aspect Opinion Pair\nExtraction, 87.45% for Aspect Term Extraction, and 88.09% for Opinion Term\nExtraction. Indo LEGO-ABSA adopts the LEGO-ABSA framework that employs the T5\nmodel, specifically mT5, by applying multitask learning to train all tasks\nwithin aspect-based sentiment analysis.",
            "author": [
                "Randy Zakya Suchrady",
                "Ayu Purwarianti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01757v1",
                "http://arxiv.org/pdf/2311.01757v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01755v1",
            "title": "Towards a Unified Transformer-based Framework for Scene Graph Generation\n  and Human-object Interaction Detection",
            "updated": "2023-11-03T07:25:57Z",
            "published": "2023-11-03T07:25:57Z",
            "summary": "Scene graph generation (SGG) and human-object interaction (HOI) detection are\ntwo important visual tasks aiming at localising and recognising relationships\nbetween objects, and interactions between humans and objects, respectively.\n  Prevailing works treat these tasks as distinct tasks, leading to the\ndevelopment of task-specific models tailored to individual datasets. However,\nwe posit that the presence of visual relationships can furnish crucial\ncontextual and intricate relational cues that significantly augment the\ninference of human-object interactions. This motivates us to think if there is\na natural intrinsic relationship between the two tasks, where scene graphs can\nserve as a source for inferring human-object interactions. In light of this, we\nintroduce SG2HOI+, a unified one-step model based on the Transformer\narchitecture. Our approach employs two interactive hierarchical Transformers to\nseamlessly unify the tasks of SGG and HOI detection. Concretely, we initiate a\nrelation Transformer tasked with generating relation triples from a suite of\nvisual features. Subsequently, we employ another transformer-based decoder to\npredict human-object interactions based on the generated relation triples. A\ncomprehensive series of experiments conducted across established benchmark\ndatasets including Visual Genome, V-COCO, and HICO-DET demonstrates the\ncompelling performance of our SG2HOI+ model in comparison to prevalent\none-stage SGG models. Remarkably, our approach achieves competitive performance\nwhen compared to state-of-the-art HOI methods. Additionally, we observe that\nour SG2HOI+ jointly trained on both SGG and HOI tasks in an end-to-end manner\nyields substantial improvements for both tasks compared to individualized\ntraining paradigms.",
            "author": [
                "Tao He",
                "Lianli Gao",
                "Jingkuan Song",
                "Yuan-Fang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01755v1",
                "http://arxiv.org/pdf/2311.01755v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02122v1",
            "title": "Lost Your Style? Navigating with Semantic-Level Approach for\n  Text-to-Outfit Retrieval",
            "updated": "2023-11-03T07:23:21Z",
            "published": "2023-11-03T07:23:21Z",
            "summary": "Fashion stylists have historically bridged the gap between consumers' desires\nand perfect outfits, which involve intricate combinations of colors, patterns,\nand materials. Although recent advancements in fashion recommendation systems\nhave made strides in outfit compatibility prediction and complementary item\nretrieval, these systems rely heavily on pre-selected customer choices.\nTherefore, we introduce a groundbreaking approach to fashion recommendations:\ntext-to-outfit retrieval task that generates a complete outfit set based solely\non textual descriptions given by users. Our model is devised at three semantic\nlevels-item, style, and outfit-where each level progressively aggregates data\nto form a coherent outfit recommendation based on textual input. Here, we\nleverage strategies similar to those in the contrastive language-image\npretraining model to address the intricate-style matrix within the outfit sets.\nUsing the Maryland Polyvore and Polyvore Outfit datasets, our approach\nsignificantly outperformed state-of-the-art models in text-video retrieval\ntasks, solidifying its effectiveness in the fashion recommendation domain. This\nresearch not only pioneers a new facet of fashion recommendation systems, but\nalso introduces a method that captures the essence of individual style\npreferences through textual descriptions.",
            "author": [
                "Junkyu Jang",
                "Eugene Hwang",
                "Sung-Hyuk Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02122v1",
                "http://arxiv.org/pdf/2311.02122v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01754v1",
            "title": "Fibered toric varieties",
            "updated": "2023-11-03T07:21:58Z",
            "published": "2023-11-03T07:21:58Z",
            "summary": "A toric variety is called fibered if it can be represented as a total space\nof fibre bundle over toric base and with toric fiber. Fibered toric varieties\nform a special case of toric variety bundles. In this note we first give an\nintroduction to the class of fibered toric varieties. Then we use them to\nillustrate some known and conjectural results on topology and intersection\ntheory of general toric variety bundles. Finally, using the language of fibered\ntoric varieties, we compute the equivariant cohomology rings of smooth complete\ntoric varieties.",
            "author": [
                "Askold Khovanskii",
                "Leonid Monin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01754v1",
                "http://arxiv.org/pdf/2311.01754v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01751v1",
            "title": "EmojiLM: Modeling the New Emoji Language",
            "updated": "2023-11-03T07:06:51Z",
            "published": "2023-11-03T07:06:51Z",
            "summary": "With the rapid development of the internet, online social media welcomes\npeople with different backgrounds through its diverse content. The increasing\nusage of emoji becomes a noticeable trend thanks to emoji's rich information\nbeyond cultural or linguistic borders. However, the current study on emojis is\nlimited to single emoji prediction and there are limited data resources\navailable for further study of the interesting linguistic phenomenon. To this\nend, we synthesize a large text-emoji parallel corpus, Text2Emoji, from a large\nlanguage model. Based on the parallel corpus, we distill a sequence-to-sequence\nmodel, EmojiLM, which is specialized in the text-emoji bidirectional\ntranslation. Extensive experiments on public benchmarks and human evaluation\ndemonstrate that our proposed model outperforms strong baselines and the\nparallel corpus benefits emoji-related downstream tasks.",
            "author": [
                "Letian Peng",
                "Zilong Wang",
                "Hang Liu",
                "Zihan Wang",
                "Jingbo Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01751v1",
                "http://arxiv.org/pdf/2311.01751v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02121v1",
            "title": "Enhancing Monocular Height Estimation from Aerial Images with\n  Street-view Images",
            "updated": "2023-11-03T06:43:32Z",
            "published": "2023-11-03T06:43:32Z",
            "summary": "Accurate height estimation from monocular aerial imagery presents a\nsignificant challenge due to its inherently ill-posed nature. This limitation\nis rooted in the absence of adequate geometric constraints available to the\nmodel when training with monocular imagery. Without additional geometric\ninformation to supplement the monocular image data, the model's ability to\nprovide reliable estimations is compromised.\n  In this paper, we propose a method that enhances monocular height estimation\nby incorporating street-view images. Our insight is that street-view images\nprovide a distinct viewing perspective and rich structural details of the\nscene, serving as geometric constraints to enhance the performance of monocular\nheight estimation. Specifically, we aim to optimize an implicit 3D scene\nrepresentation, density field, with geometry constraints from street-view\nimages, thereby improving the accuracy and robustness of height estimation. Our\nexperimental results demonstrate the effectiveness of our proposed method,\noutperforming the baseline and offering significant improvements in terms of\naccuracy and structural consistency.",
            "author": [
                "Xiaomou Hou",
                "Wanshui Gan",
                "Naoto Yokoya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02121v1",
                "http://arxiv.org/pdf/2311.02121v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01744v1",
            "title": "Data-Centric Long-Tailed Image Recognition",
            "updated": "2023-11-03T06:34:37Z",
            "published": "2023-11-03T06:34:37Z",
            "summary": "In the context of the long-tail scenario, models exhibit a strong demand for\nhigh-quality data. Data-centric approaches aim to enhance both the quantity and\nquality of data to improve model performance. Among these approaches,\ninformation augmentation has been progressively introduced as a crucial\ncategory. It achieves a balance in model performance by augmenting the richness\nand quantity of samples in the tail classes. However, there is currently a lack\nof research into the underlying mechanisms explaining the effectiveness of\ninformation augmentation methods. Consequently, the utilization of information\naugmentation in long-tail recognition tasks relies heavily on empirical and\nintricate fine-tuning. This work makes two primary contributions. Firstly, we\napproach the problem from the perspectives of feature diversity and\ndistribution shift, introducing the concept of Feature Diversity Gain (FDG) to\nelucidate why information augmentation is effective. We find that the\nperformance of information augmentation can be explained by FDG, and its\nperformance peaks when FDG achieves an appropriate balance. Experimental\nresults demonstrate that by using FDG to select augmented data, we can further\nenhance model performance without the need for any modifications to the model's\narchitecture. Thus, data-centric approaches hold significant potential in the\nfield of long-tail recognition, beyond the development of new model structures.\nFurthermore, we systematically introduce the core components and fundamental\ntasks of a data-centric long-tail learning framework for the first time. These\ncore components guide the implementation and deployment of the system, while\nthe corresponding fundamental tasks refine and expand the research area.",
            "author": [
                "Yanbiao Ma",
                "Licheng Jiao",
                "Fang Liu",
                "Shuyuan Yang",
                "Xu Liu",
                "Puhua Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01744v1",
                "http://arxiv.org/pdf/2311.01744v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01740v1",
            "title": "SAC$^3$: Reliable Hallucination Detection in Black-Box Language Models\n  via Semantic-aware Cross-check Consistency",
            "updated": "2023-11-03T06:32:43Z",
            "published": "2023-11-03T06:32:43Z",
            "summary": "Hallucination detection is a critical step toward understanding the\ntrustworthiness of modern language models (LMs). To achieve this goal, we\nre-examine existing detection approaches based on the self-consistency of LMs\nand uncover two types of hallucinations resulting from 1) question-level and 2)\nmodel-level, which cannot be effectively identified through self-consistency\ncheck alone. Building upon this discovery, we propose a novel sampling-based\nmethod, i.e., semantic-aware cross-check consistency (SAC$^3$) that expands on\nthe principle of self-consistency checking. Our SAC$^3$ approach incorporates\nadditional mechanisms to detect both question-level and model-level\nhallucinations by leveraging advances including semantically equivalent\nquestion perturbation and cross-model response consistency checking. Through\nextensive and systematic empirical analysis, we demonstrate that SAC$^3$\noutperforms the state of the art in detecting both non-factual and factual\nstatements across multiple question-answering and open-domain generation\nbenchmarks.",
            "author": [
                "Jiaxin Zhang",
                "Zhuohang Li",
                "Kamalika Das",
                "Bradley A. Malin",
                "Sricharan Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01740v1",
                "http://arxiv.org/pdf/2311.01740v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01739v2",
            "title": "Efficient Algorithms for Monte Carlo Particle Transport on AI\n  Accelerator Hardware",
            "updated": "2023-11-07T03:22:56Z",
            "published": "2023-11-03T06:27:36Z",
            "summary": "The recent trend toward deep learning has led to the development of a variety\nof highly innovative AI accelerator architectures. One such architecture, the\nCerebras Wafer-Scale Engine 2 (WSE-2), features 40 GB of on-chip SRAM, making\nit a potentially attractive platform for latency- or bandwidth-bound HPC\nsimulation workloads. In this study, we examine the feasibility of performing\ncontinuous energy Monte Carlo (MC) particle transport on the WSE-2 by porting a\nkey kernel from the MC transport algorithm to Cerebras's CSL programming model.\nNew algorithms for minimizing communication costs and for handling load\nbalancing are developed and tested. The WSE-2 is found to run 130 times faster\nthan a highly optimized CUDA version of the kernel run on an NVIDIA A100 GPU --\nsignificantly outpacing the expected performance increase given the difference\nin transistor counts between the architectures.",
            "author": [
                "John Tramm",
                "Bryce Allen",
                "Kazutomo Yoshii",
                "Andrew Siegel",
                "Leighton Wilson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01739v2",
                "http://arxiv.org/pdf/2311.01739v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.PF",
                "D.1.3; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01737v1",
            "title": "CoPriv: Network/Protocol Co-Optimization for Communication-Efficient\n  Private Inference",
            "updated": "2023-11-03T06:19:48Z",
            "published": "2023-11-03T06:19:48Z",
            "summary": "Deep neural network (DNN) inference based on secure 2-party computation (2PC)\ncan offer cryptographically-secure privacy protection but suffers from orders\nof magnitude latency overhead due to enormous communication. Previous works\nheavily rely on a proxy metric of ReLU counts to approximate the communication\noverhead and focus on reducing the ReLUs to improve the communication\nefficiency. However, we observe these works achieve limited communication\nreduction for state-of-the-art (SOTA) 2PC protocols due to the ignorance of\nother linear and non-linear operations, which now contribute to the majority of\ncommunication. In this work, we present CoPriv, a framework that jointly\noptimizes the 2PC inference protocol and the DNN architecture. CoPriv features\na new 2PC protocol for convolution based on Winograd transformation and\ndevelops DNN-aware optimization to significantly reduce the inference\ncommunication. CoPriv further develops a 2PC-aware network optimization\nalgorithm that is compatible with the proposed protocol and simultaneously\nreduces the communication for all the linear and non-linear operations. We\ncompare CoPriv with the SOTA 2PC protocol, CrypTFlow2, and demonstrate 2.1x\ncommunication reduction for both ResNet-18 and ResNet-32 on CIFAR-100. We also\ncompare CoPriv with SOTA network optimization methods, including SNL,\nMetaPruning, etc. CoPriv achieves 9.98x and 3.88x online and total\ncommunication reduction with a higher accuracy compare to SNL, respectively.\nCoPriv also achieves 3.87x online communication reduction with more than 3%\nhigher accuracy compared to MetaPruning.",
            "author": [
                "Wenxuan Zeng",
                "Meng Li",
                "Haichuan Yang",
                "Wen-jie Lu",
                "Runsheng Wang",
                "Ru Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01737v1",
                "http://arxiv.org/pdf/2311.01737v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01734v1",
            "title": "MixCon3D: Synergizing Multi-View and Cross-Modal Contrastive Learning\n  for Enhancing 3D Representation",
            "updated": "2023-11-03T06:05:36Z",
            "published": "2023-11-03T06:05:36Z",
            "summary": "Contrastive learning has emerged as a promising paradigm for 3D open-world\nunderstanding, jointly with text, image, and point cloud. In this paper, we\nintroduce MixCon3D, which combines the complementary information between 2D\nimages and 3D point clouds to enhance contrastive learning. With the further\nintegration of multi-view 2D images, MixCon3D enhances the traditional\ntri-modal representation by offering a more accurate and comprehensive\ndepiction of real-world 3D objects and bolstering text alignment. Additionally,\nwe pioneer the first thorough investigation of various training recipes for the\n3D contrastive learning paradigm, building a solid baseline with improved\nperformance. Extensive experiments conducted on three representative benchmarks\nreveal that our method renders significant improvement over the baseline,\nsurpassing the previous state-of-the-art performance on the challenging\n1,156-category Objaverse-LVIS dataset by 5.7%. We further showcase the\neffectiveness of our approach in more applications, including text-to-3D\nretrieval and point cloud captioning. The code is available at\nhttps://github.com/UCSC-VLAA/MixCon3D.",
            "author": [
                "Yipeng Gao",
                "Zeyu Wang",
                "Wei-Shi Zheng",
                "Cihang Xie",
                "Yuyin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01734v1",
                "http://arxiv.org/pdf/2311.01734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01732v2",
            "title": "Proto-lm: A Prototypical Network-Based Framework for Built-in\n  Interpretability in Large Language Models",
            "updated": "2023-11-12T04:28:43Z",
            "published": "2023-11-03T05:55:32Z",
            "summary": "Large Language Models (LLMs) have significantly advanced the field of Natural\nLanguage Processing (NLP), but their lack of interpretability has been a major\nconcern. Current methods for interpreting LLMs are post hoc, applied after\ninference time, and have limitations such as their focus on low-level features\nand lack of explainability at higher level text units. In this work, we\nintroduce proto-lm, a prototypical network-based white-box framework that\nallows LLMs to learn immediately interpretable embeddings during the\nfine-tuning stage while maintaining competitive performance. Our method's\napplicability and interpretability are demonstrated through experiments on a\nwide range of NLP tasks, and our results indicate a new possibility of creating\ninterpretable models without sacrificing performance. This novel approach to\ninterpretability in LLMs can pave the way for more interpretable models without\nthe need to sacrifice performance.",
            "author": [
                "Sean Xie",
                "Soroush Vosoughi",
                "Saeed Hassanpour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01732v2",
                "http://arxiv.org/pdf/2311.01732v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01731v1",
            "title": "Capturing Local and Global Features in Medical Images by Using Ensemble\n  CNN-Transformer",
            "updated": "2023-11-03T05:55:28Z",
            "published": "2023-11-03T05:55:28Z",
            "summary": "This paper introduces a groundbreaking classification model called the\nControllable Ensemble Transformer and CNN (CETC) for the analysis of medical\nimages. The CETC model combines the powerful capabilities of convolutional\nneural networks (CNNs) and transformers to effectively capture both local and\nglobal features present in medical images. The model architecture comprises\nthree main components: a convolutional encoder block (CEB), a\ntransposed-convolutional decoder block (TDB), and a transformer classification\nblock (TCB). The CEB is responsible for capturing multi-local features at\ndifferent scales and draws upon components from VGGNet, ResNet, and MobileNet\nas backbones. By leveraging this combination, the CEB is able to effectively\ndetect and encode local features. The TDB, on the other hand, consists of\nsub-decoders that decode and sum the captured features using ensemble\ncoefficients. This enables the model to efficiently integrate the information\nfrom multiple scales. Finally, the TCB utilizes the SwT backbone and a\nspecially designed prediction head to capture global features, ensuring a\ncomprehensive understanding of the entire image. The paper provides detailed\ninformation on the experimental setup and implementation, including the use of\ntransfer learning, data preprocessing techniques, and training settings. The\nCETC model is trained and evaluated using two publicly available COVID-19\ndatasets. Remarkably, the model outperforms existing state-of-the-art models\nacross various evaluation metrics. The experimental results clearly demonstrate\nthe superiority of the CETC model, emphasizing its potential for accurately and\nefficiently analyzing medical images.",
            "author": [
                "Javad Mirzapour Kaleybar",
                "Hooman Saadat",
                "Hooman Khaloo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01731v1",
                "http://arxiv.org/pdf/2311.01731v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01730v1",
            "title": "Disorder effects on the Topological Superconductor with Hubbard\n  Interactions",
            "updated": "2023-11-03T05:55:24Z",
            "published": "2023-11-03T05:55:24Z",
            "summary": "We study the two-dimensional disordered topological superconductor with\nHubbard interactions. When the magnitude of the pairing potential is tuned to\nspecial values, this interacting model is exactly solvable even when disorders\nare imposed on the potential term or coupling constants. The topology of this\nmodel is investigated in detail by the real space Chern number formula, which\ncomputes the topological index of disordered systems to high precisions. It is\nfound that the disorders can drive the system from topological trivial phase to\na non-trivial phase, which generalizes the topological Anderson phenomena to\ninteracting models. The self-consistent Born approximation is also employed to\nunderstand the influence of the disorders on the parameters of the interacting\ntopological superconductor. It provide an alternative way to understand the\ntopological transitions at weak disordered region.",
            "author": [
                "Yiting Deng",
                "Yan He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01730v1",
                "http://arxiv.org/pdf/2311.01730v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01727v1",
            "title": "Flexible Error Mitigation of Quantum Processes with Data Augmentation\n  Empowered Neural Model",
            "updated": "2023-11-03T05:52:14Z",
            "published": "2023-11-03T05:52:14Z",
            "summary": "Neural networks have shown their effectiveness in various tasks in the realm\nof quantum computing. However, their application in quantum error mitigation, a\ncrucial step towards realizing practical quantum advancements, has been\nrestricted by reliance on noise-free statistics. To tackle this critical\nchallenge, we propose a data augmentation empowered neural model for error\nmitigation (DAEM). Our model does not require any prior knowledge about the\nspecific noise type and measurement settings and can estimate noise-free\nstatistics solely from the noisy measurement results of the target quantum\nprocess, rendering it highly suitable for practical implementation. In\nnumerical experiments, we show the model's superior performance in mitigating\nvarious types of noise, including Markovian noise and Non-Markovian noise,\ncompared with previous error mitigation methods. We further demonstrate its\nversatility by employing the model to mitigate errors in diverse types of\nquantum processes, including those involving large-scale quantum systems and\ncontinuous-variable quantum states. This powerful data augmentation-empowered\nneural model for error mitigation establishes a solid foundation for realizing\nmore reliable and robust quantum technologies in practical applications.",
            "author": [
                "Manwen Liao",
                "Yan Zhu",
                "Giulio Chiribella",
                "Yuxiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01727v1",
                "http://arxiv.org/pdf/2311.01727v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02120v1",
            "title": "Static Virus Spread Algorithm for DNA Sequence Design",
            "updated": "2023-11-03T05:47:00Z",
            "published": "2023-11-03T05:47:00Z",
            "summary": "DNA is not only the genetic material of life, but also a favorable material\nfor a new computing model. Various research works based on DNA computing have\nbeen carried out in recent years. DNA sequence design is the foundation of such\nresearch. The sequence quality directly affects the universality, robustness,\nand stability of DNA computing. How to design DNA sequences depends on the\nbiological properties and target requirements, which is a typical combinatorial\noptimization problem. In this paper, in order to design DNA sequences with\nhigh-quality, we propose a novel meta-heuristic evolutionary algorithm, termed\nthe static virus spread algorithm (SVS). Through this algorithm, we focus on\nthe constraints of universal DNA sequence design and produce a large number of\nDNA sequences with non-complementarity and small difference in melting\ntemperature as the objectives, and fully considering the balanced proportion of\nthe four bases. The computer simulation and polyacrylamide gel electrophoresis\nexperiments show that the high-quality DNA sequences designed by this algorithm\nare effective, which is expected to provide a convenient tool for sequence\npreparation before DNA biochemical operations.",
            "author": [
                "Yao Yao",
                "Xun Zhang",
                "Xin Liu",
                "Yuan Liu",
                "Xiaokang Zhang",
                "Qiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02120v1",
                "http://arxiv.org/pdf/2311.02120v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01725v1",
            "title": "Quantum Recursive Programming with Quantum Case Statements",
            "updated": "2023-11-03T05:44:52Z",
            "published": "2023-11-03T05:44:52Z",
            "summary": "We introduce a novel scheme of quantum recursive programming, in which large\nunitary transformations, i.e. quantum gates, can be recursively defined using\nquantum case statements, which are quantum counterparts of conditionals and\ncase statements extensively used in classical programming. A simple programming\nlanguage for supporting this kind of quantum recursion is defined, and its\nsemantics is formally described. A series of examples are presented to show\nthat some quantum algorithms can be elegantly written as quantum recursive\nprograms.",
            "author": [
                "Mingsheng Ying",
                "Zhicheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01725v1",
                "http://arxiv.org/pdf/2311.01725v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LO",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01724v2",
            "title": "Holography Transformer",
            "updated": "2023-11-10T02:57:37Z",
            "published": "2023-11-03T05:41:49Z",
            "summary": "We have constructed a generative artificial intelligence model to predict\ndual gravity solutions when provided with the input of holographic entanglement\nentropy. The model utilized in our study is based on the transformer algorithm,\nwidely used for various natural language tasks including text generation,\nsummarization, and translation. This algorithm possesses the ability to\nunderstand the meanings of input and output sequences by utilizing multi-head\nattention layers. In the training procedure, we generated pairs of examples\nconsisting of holographic entanglement entropy data and their corresponding\nmetric solutions. Once the model has completed the training process, it\ndemonstrates the ability to generate predictions regarding a dual geometry that\ncorresponds to the given holographic entanglement entropy. Subsequently, we\nproceed to validate the dual geometry to confirm its correspondence with the\nholographic entanglement entropy data.",
            "author": [
                "Chanyong Park",
                "Sejin Kim",
                "Jung Hun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01724v2",
                "http://arxiv.org/pdf/2311.01724v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01723v3",
            "title": "Towards Calibrated Robust Fine-Tuning of Vision-Language Models",
            "updated": "2023-11-30T00:07:54Z",
            "published": "2023-11-03T05:41:25Z",
            "summary": "While fine-tuning unlocks the potential of a pre-trained model for a specific\ntask, it compromises the model's ability to generalize to out-of-distribution\n(OOD) datasets. To mitigate this, robust fine-tuning aims to ensure performance\non OOD datasets as well as on an in-distribution (ID) dataset for which the\nmodel is being tuned. However, another criterion for reliable machine learning\n(ML), confidence calibration, has been overlooked despite its increasing demand\nfor real-world high-stakes ML applications (e.g., autonomous driving and\nmedical diagnosis). For the first time, we raise concerns about the calibration\nof fine-tuned vision-language models (VLMs) under distribution shift by showing\nthat naive fine-tuning and even state-of-the-art robust fine-tuning methods\nhurt the calibration of pre-trained VLMs, especially on OOD datasets. To\naddress this issue, we provide a simple approach, called calibrated robust\nfine-tuning (CaRot), that incentivizes calibration and robustness on both ID\nand OOD datasets. Empirical results on ImageNet-1K distribution shift\nevaluation verify the effectiveness of our method.",
            "author": [
                "Changdae Oh",
                "Mijoo Kim",
                "Hyesu Lim",
                "Junhyeok Park",
                "Euiseog Jeong",
                "Zhi-Qi Cheng",
                "Kyungwoo Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01723v3",
                "http://arxiv.org/pdf/2311.01723v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10099v1",
            "title": "Smart Traffic Management of Vehicles using Faster R-CNN based Deep\n  Learning Method",
            "updated": "2023-11-03T05:30:13Z",
            "published": "2023-11-03T05:30:13Z",
            "summary": "With constant growth of civilization and modernization of cities all across\nthe world since past few centuries smart traffic management of vehicles is one\nof the most sorted after problem by research community. It is a challenging\nproblem in computer vision and artificial intelligence domain. Smart traffic\nmanagement basically involves segmentation of vehicles, estimation of traffic\ndensity and tracking of vehicles. The vehicle segmentation from traffic videos\nhelps realization of niche applications such as monitoring of speed and\nestimation of traffic. When occlusions, background with clutters and traffic\nwith density variations are present, this problem becomes more intractable in\nnature. Keeping this motivation in this research work, we investigate Faster\nR-CNN based deep learning method towards segmentation of vehicles. This problem\nis addressed in four steps viz minimization with adaptive background model,\nFaster R-CNN based subnet operation, Faster R-CNN initial refinement and result\noptimization with extended topological active nets. The computational framework\nuses ideas of adaptive background modeling. It also addresses shadow and\nillumination related issues. Higher segmentation accuracy is achieved through\ntopological active net deformable models. The topological and extended\ntopological active nets help to achieve stated deformations. Mesh deformation\nis achieved with minimization of energy. The segmentation accuracy is improved\nwith modified version of extended topological active net. The experimental\nresults demonstrate superiority of this computational framework",
            "author": [
                "Arindam Chaudhuri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10099v1",
                "http://arxiv.org/pdf/2311.10099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01720v1",
            "title": "Learning Reduced-Order Soft Robot Controller",
            "updated": "2023-11-03T05:24:19Z",
            "published": "2023-11-03T05:24:19Z",
            "summary": "Deformable robots are notoriously difficult to model or control due to its\nhigh-dimensional configuration spaces. Direct trajectory optimization suffers\nfrom the curse-of-dimensionality and incurs a high computational cost, while\nlearning-based controller optimization methods are sensitive to hyper-parameter\ntuning. To overcome these limitations, we hypothesize that high fidelity soft\nrobots can be both simulated and controlled by restricting to low-dimensional\nspaces. Under such assumption, we propose a two-stage algorithm to identify\nsuch simulation- and control-spaces. Our method first identifies the so-called\nsimulation-space that captures the salient deformation modes, to which the\nrobot's governing equation is restricted. We then identify the control-space,\nto which control signals are restricted. We propose a multi-fidelity Riemannian\nBayesian bilevel optimization to identify task-specific control spaces. We show\nthat the dimension of control-space can be less than $10$ for a high-DOF soft\nrobot to accomplish walking and swimming tasks, allowing low-dimensional MPC\ncontrollers to be applied to soft robots with tractable computational\ncomplexity.",
            "author": [
                "Chen Liang",
                "Xifeng Gao",
                "Kui Wu",
                "Zherong Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01720v1",
                "http://arxiv.org/pdf/2311.01720v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01714v2",
            "title": "EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape\n  Generation",
            "updated": "2023-11-30T15:02:57Z",
            "published": "2023-11-03T05:01:51Z",
            "summary": "This paper presents a new text-guided technique for generating 3D shapes. The\ntechnique leverages a hybrid 3D shape representation, namely EXIM, combining\nthe strengths of explicit and implicit representations. Specifically, the\nexplicit stage controls the topology of the generated 3D shapes and enables\nlocal modifications, whereas the implicit stage refines the shape and paints it\nwith plausible colors. Also, the hybrid approach separates the shape and color\nand generates color conditioned on shape to ensure shape-color consistency.\nUnlike the existing state-of-the-art methods, we achieve high-fidelity shape\ngeneration from natural-language descriptions without the need for\ntime-consuming per-shape optimization or reliance on human-annotated texts\nduring training or test-time optimization. Further, we demonstrate the\napplicability of our approach to generate indoor scenes with consistent styles\nusing text-induced 3D shapes. Through extensive experiments, we demonstrate the\ncompelling quality of our results and the high coherency of our generated\nshapes with the input texts, surpassing the performance of existing methods by\na significant margin. Codes and models are released at\nhttps://github.com/liuzhengzhe/EXIM.",
            "author": [
                "Zhengzhe Liu",
                "Jingyu Hu",
                "Ka-Hei Hui",
                "Xiaojuan Qi",
                "Daniel Cohen-Or",
                "Chi-Wing Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01714v2",
                "http://arxiv.org/pdf/2311.01714v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01713v1",
            "title": "An Empirical Study of Benchmarking Chinese Aspect Sentiment Quad\n  Prediction",
            "updated": "2023-11-03T05:00:44Z",
            "published": "2023-11-03T05:00:44Z",
            "summary": "Aspect sentiment quad prediction (ASQP) is a critical subtask of aspect-level\nsentiment analysis. Current ASQP datasets are characterized by their small size\nand low quadruple density, which hinders technical development. To expand\ncapacity, we construct two large Chinese ASQP datasets crawled from multiple\nonline platforms. The datasets hold several significant characteristics: larger\nsize (each with 10,000+ samples) and rich aspect categories, more words per\nsentence, and higher density than existing ASQP datasets. Moreover, we are the\nfirst to evaluate the performance of Generative Pre-trained Transformer (GPT)\nseries models on ASQP and exhibit potential issues. The experiments with\nstate-of-the-art ASQP baselines underscore the need to explore additional\ntechniques to address ASQP, as well as the importance of further investigation\ninto methods to improve the performance of GPTs.",
            "author": [
                "Junxian Zhou",
                "Haiqin Yang",
                "Ye Junpeng",
                "Yuxuan He",
                "Hao Mou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01713v1",
                "http://arxiv.org/pdf/2311.01713v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01712v1",
            "title": "A New Korean Text Classification Benchmark for Recognizing the Political\n  Intents in Online Newspapers",
            "updated": "2023-11-03T04:59:55Z",
            "published": "2023-11-03T04:59:55Z",
            "summary": "Many users reading online articles in various magazines may suffer\nconsiderable difficulty in distinguishing the implicit intents in texts. In\nthis work, we focus on automatically recognizing the political intents of a\ngiven online newspaper by understanding the context of the text. To solve this\ntask, we present a novel Korean text classification dataset that contains\nvarious articles. We also provide deep-learning-based text classification\nbaseline models trained on the proposed dataset. Our dataset contains 12,000\nnews articles that may contain political intentions, from the politics section\nof six of the most representative newspaper organizations in South Korea. All\nthe text samples are labeled simultaneously in two aspects (1) the level of\npolitical orientation and (2) the level of pro-government. To the best of our\nknowledge, our paper is the most large-scale Korean news dataset that contains\nlong text and addresses multi-task classification problems. We also train\nrecent state-of-the-art (SOTA) language models that are based on transformer\narchitectures and demonstrate that the trained models show decent text\nclassification performance. All the codes, datasets, and trained models are\navailable at https://github.com/Kdavid2355/KoPolitic-Benchmark-Dataset.",
            "author": [
                "Beomjune Kim",
                "Eunsun Lee",
                "Dongbin Na"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01712v1",
                "http://arxiv.org/pdf/2311.01712v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01707v1",
            "title": "Distributed Multi-Robot Multi-Target Tracking Using Heterogeneous\n  Limited-Range Sensors",
            "updated": "2023-11-03T04:29:43Z",
            "published": "2023-11-03T04:29:43Z",
            "summary": "This paper presents a cooperative multi-robot multi-target tracking framework\naimed at enhancing the efficiency of the heterogeneous sensor network and,\nconsequently, improving overall target tracking accuracy. The concept of\nnormalized unused sensing capacity is introduced to quantify the information a\nsensor is currently gathering relative to its theoretical maximum. This\nmeasurement can be computed using entirely local information and is applicable\nto various sensor models, distinguishing it from previous literature on the\nsubject. It is then utilized to develop a distributed coverage control strategy\nfor a heterogeneous sensor network, adaptively balancing the workload based on\neach sensor's current unused capacity. The algorithm is validated through a\nseries of ROS and MATLAB simulations, demonstrating superior results compared\nto standard approaches that do not account for heterogeneity or current usage\nrates.",
            "author": [
                "Jun Chen",
                "Mohammed Abugurain",
                "Philip Dames",
                "Shinkyu Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01707v1",
                "http://arxiv.org/pdf/2311.01707v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01703v2",
            "title": "Taking a PEEK into YOLOv5 for Satellite Component Recognition via\n  Entropy-based Visual Explanations",
            "updated": "2023-11-25T20:22:24Z",
            "published": "2023-11-03T04:21:27Z",
            "summary": "The escalating risk of collisions and the accumulation of space debris in Low\nEarth Orbit (LEO) has reached critical concern due to the ever increasing\nnumber of spacecraft. Addressing this crisis, especially in dealing with\nnon-cooperative and unidentified space debris, is of paramount importance. This\npaper contributes to efforts in enabling autonomous swarms of small chaser\nsatellites for target geometry determination and safe flight trajectory\nplanning for proximity operations in LEO. Our research explores on-orbit use of\nthe You Only Look Once v5 (YOLOv5) object detection model trained to detect\nsatellite components. While this model has shown promise, its inherent lack of\ninterpretability hinders human understanding, a critical aspect of validating\nalgorithms for use in safety-critical missions. To analyze the decision\nprocesses, we introduce Probabilistic Explanations for Entropic Knowledge\nextraction (PEEK), a method that utilizes information theoretic analysis of the\nlatent representations within the hidden layers of the model. Through both\nsynthetic in hardware-in-the-loop experiments, PEEK illuminates the\ndecision-making processes of the model, helping identify its strengths,\nlimitations and biases.",
            "author": [
                "Mackenzie J. Meni",
                "Trupti Mahendrakar",
                "Olivia D. M. Raney",
                "Ryan T. White",
                "Michael L. Mayo",
                "Kevin Pilkiewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01703v2",
                "http://arxiv.org/pdf/2311.01703v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01702v1",
            "title": "Medical Image Segmentation with Domain Adaptation: A Survey",
            "updated": "2023-11-03T04:17:06Z",
            "published": "2023-11-03T04:17:06Z",
            "summary": "Deep learning (DL) has shown remarkable success in various medical imaging\ndata analysis applications. However, it remains challenging for DL models to\nachieve good generalization, especially when the training and testing datasets\nare collected at sites with different scanners, due to domain shift caused by\ndifferences in data distributions. Domain adaptation has emerged as an\neffective means to address this challenge by mitigating domain gaps in medical\nimaging applications. In this review, we specifically focus on domain\nadaptation approaches for DL-based medical image segmentation. We first present\nthe motivation and background knowledge underlying domain adaptations, then\nprovide a comprehensive review of domain adaptation applications in medical\nimage segmentations, and finally discuss the challenges, limitations, and\nfuture research trends in the field to promote the methodology development of\ndomain adaptation in the context of medical image segmentation. Our goal was to\nprovide researchers with up-to-date references on the applications of domain\nadaptation in medical image segmentation studies.",
            "author": [
                "Yuemeng Li",
                "Yong Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01702v1",
                "http://arxiv.org/pdf/2311.01702v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01696v1",
            "title": "Universal Perturbation-based Secret Key-Controlled Data Hiding",
            "updated": "2023-11-03T03:57:01Z",
            "published": "2023-11-03T03:57:01Z",
            "summary": "Deep neural networks (DNNs) are demonstrated to be vulnerable to universal\nperturbation, a single quasi-perceptible perturbation that can deceive the DNN\non most images. However, the previous works are focused on using universal\nperturbation to perform adversarial attacks, while the potential usability of\nuniversal perturbation as data carriers in data hiding is less explored,\nespecially for the key-controlled data hiding method. In this paper, we propose\na novel universal perturbation-based secret key-controlled data-hiding method,\nrealizing data hiding with a single universal perturbation and data decoding\nwith the secret key-controlled decoder. Specifically, we optimize a single\nuniversal perturbation, which serves as a data carrier that can hide multiple\nsecret images and be added to most cover images. Then, we devise a secret\nkey-controlled decoder to extract different secret images from the single\ncontainer image constructed by the universal perturbation by using different\nsecret keys. Moreover, a suppress loss function is proposed to prevent the\nsecret image from leakage. Furthermore, we adopt a robust module to boost the\ndecoder's capability against corruption. Finally, A co-joint optimization\nstrategy is proposed to find the optimal universal perturbation and decoder.\nExtensive experiments are conducted on different datasets to demonstrate the\neffectiveness of the proposed method. Additionally, the physical test performed\non platforms (e.g., WeChat and Twitter) verifies the usability of the proposed\nmethod in practice.",
            "author": [
                "Donghua Wang",
                "Wen Yao",
                "Tingsong Jiang",
                "Xiaoqian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01696v1",
                "http://arxiv.org/pdf/2311.01696v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01695v1",
            "title": "Communication-Efficient Federated Non-Linear Bandit Optimization",
            "updated": "2023-11-03T03:50:31Z",
            "published": "2023-11-03T03:50:31Z",
            "summary": "Federated optimization studies the problem of collaborative function\noptimization among multiple clients (e.g. mobile devices or organizations)\nunder the coordination of a central server. Since the data is collected\nseparately by each client and always remains decentralized, federated\noptimization preserves data privacy and allows for large-scale computing, which\nmakes it a promising decentralized machine learning paradigm. Though it is\noften deployed for tasks that are online in nature, e.g., next-word prediction\non keyboard apps, most works formulate it as an offline problem. The few\nexceptions that consider federated bandit optimization are limited to very\nsimplistic function classes, e.g., linear, generalized linear, or\nnon-parametric function class with bounded RKHS norm, which severely hinders\nits practical usage. In this paper, we propose a new algorithm, named\nFed-GO-UCB, for federated bandit optimization with generic non-linear objective\nfunction. Under some mild conditions, we rigorously prove that Fed-GO-UCB is\nable to achieve sub-linear rate for both cumulative regret and communication\ncost. At the heart of our theoretical analysis are distributed regression\noracle and individual confidence set construction, which can be of independent\ninterests. Empirical evaluations also demonstrate the effectiveness of the\nproposed algorithm.",
            "author": [
                "Chuanhao Li",
                "Chong Liu",
                "Yu-Xiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01695v1",
                "http://arxiv.org/pdf/2311.01695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01693v1",
            "title": "Enhancing Computer Science Education with Pair Programming and Problem\n  Solving Studios",
            "updated": "2023-11-03T03:40:55Z",
            "published": "2023-11-03T03:40:55Z",
            "summary": "This study examines the adaptation of the problem-solving studio to computer\nscience education by combining it with pair programming. Pair programming is a\nsoftware engineering practice in industry, but has seen mixed results in the\nclassroom. Recent research suggests that pair programming has promise and\npotential to be an effective pedagogical tool, however what constitutes good\ninstructional design and implementation for pair programming in the classroom\nis not clear. We developed a framework for instructional design for pair\nprogramming by adapting the problem-solving studio (PSS), a pedagogy originally\nfrom biomedical engineering. PSS involves teams of students solving open-ended\nproblems with real-time feedback given by the instructor. Notably, PSS uses\nproblems of adjustable difficulty to keep students of all levels engaged and\nfunctioning within the zone of proximal development. The course structure has\nthree stages, first starting with demonstration, followed by a PSS session,\nthen finishing with a debrief. We studied the combination of PSS and pair\nprogramming in a CS1 class over three years. Surveys of the students report a\nhigh level of engagement, learning, and motivation.",
            "author": [
                "J. Walker Orr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01693v1",
                "http://arxiv.org/pdf/2311.01693v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01690v1",
            "title": "Discrete unified gas kinetic scheme for the solution of electron\n  Boltzmann transport equation with Callaway approximation",
            "updated": "2023-11-03T03:31:50Z",
            "published": "2023-11-03T03:31:50Z",
            "summary": "Electrons are the carriers of heat and electricity in materials, and exhibit\nabundant transport phenomena such as ballistic, diffusive, and hydrodynamic\nbehaviors in systems with different sizes. The electron Boltzmann transport\nequation (eBTE) is a reliable model for describing electron transport, but it\nis a challenging problem to efficiently obtain the numerical solutions of eBTE\nwithin one unified scheme involving ballistic, hydrodynamics and/or diffusive\nregimes. In this work, a discrete unified gas kinetic scheme (DUGKS) in\nfinite-volume framework is developed based on the eBTE with the Callaway\nrelaxation model for electron transport. By reconstructing the distribution\nfunction at the cell interface, the processes of electron drift and scattering\nare coupled together within a single time step. Numerical tests demonstrate\nthat the DUGKS can be adaptively applied to multiscale electron transport,\nacross different regimes.",
            "author": [
                "Meng Lian",
                "Chuang Zhang",
                "Zhaoli Guo",
                "Jing-Tao L\u00fc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01690v1",
                "http://arxiv.org/pdf/2311.01690v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01689v1",
            "title": "Data-Free Distillation of Language Model by Text-to-Text Transfer",
            "updated": "2023-11-03T03:31:47Z",
            "published": "2023-11-03T03:31:47Z",
            "summary": "Data-Free Knowledge Distillation (DFKD) plays a vital role in compressing the\nmodel when original training data is unavailable. Previous works for DFKD in\nNLP mainly focus on distilling encoder-only structures like BERT on\nclassification tasks, which overlook the notable progress of generative\nlanguage modeling. In this work, we propose a novel DFKD framework, namely\nDFKD-T$^{3}$, where the pretrained generative language model can also serve as\na controllable data generator for model compression. This novel framework\nDFKD-T$^{3}$ leads to an end-to-end learnable text-to-text framework to\ntransform the general domain corpus to compression-friendly task data,\ntargeting to improve both the \\textit{specificity} and \\textit{diversity}.\nExtensive experiments show that our method can boost the distillation\nperformance in various downstream tasks such as sentiment analysis, linguistic\nacceptability, and information extraction. Furthermore, we show that the\ngenerated texts can be directly used for distilling other language models and\noutperform the SOTA methods, making our method more appealing in a general DFKD\nsetting. Our code is available at\nhttps://gitee.com/mindspore/models/tree/master/research/nlp/DFKD\\_T3.",
            "author": [
                "Zheyuan Bai",
                "Xinduo Liu",
                "Hailin Hu",
                "Tianyu Guo",
                "Qinghua Zhang",
                "Yunhe Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01689v1",
                "http://arxiv.org/pdf/2311.01689v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01687v1",
            "title": "A Computational Study and Parameterisation of Phosphatidylinositol\n  Phosphates for Lipid Simulations with AMBER",
            "updated": "2023-11-03T03:30:21Z",
            "published": "2023-11-03T03:30:21Z",
            "summary": "Phosphatidylinositol phosphates (PIPs) are membrane phospholipids that play\ncrucial roles in a wide range of cellular functions. However, there is a dearth\nof experimental data in the literature on PIPs because their investigations are\nnot always feasible and often prohibitively expensive. Hence, there is great\ninterest in using computational simulations to study the structures,\ntransitions, and interactions of PIP-containing membranes. Assisted Model\nBuilding with Energy Refinement (AMBER) is a molecular dynamics program with\nvalidated force fields parameterized for a range of lipid types. The\ndevelopment of AMBER's Lipid force fields is a continuous process with ongoing\nwork in both improving the accuracy of the simulated result and extending the\nforce field with diverse lipid types. The research conducted for this work\nrepresents the first attempt to parameterize PIPs using the protocols of the\nlatest Lipid21 force field.",
            "author": [
                "Clare Yijia Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01687v1",
                "http://arxiv.org/pdf/2311.01687v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01686v1",
            "title": "Disentangled Representation Learning with Transmitted Information\n  Bottleneck",
            "updated": "2023-11-03T03:18:40Z",
            "published": "2023-11-03T03:18:40Z",
            "summary": "Encoding only the task-related information from the raw data, \\ie,\ndisentangled representation learning, can greatly contribute to the robustness\nand generalizability of models. Although significant advances have been made by\nregularizing the information in representations with information theory, two\nmajor challenges remain: 1) the representation compression inevitably leads to\nperformance drop; 2) the disentanglement constraints on representations are in\ncomplicated optimization. To these issues, we introduce Bayesian networks with\ntransmitted information to formulate the interaction among input and\nrepresentations during disentanglement. Building upon this framework, we\npropose \\textbf{DisTIB} (\\textbf{T}ransmitted \\textbf{I}nformation\n\\textbf{B}ottleneck for \\textbf{Dis}entangled representation learning), a novel\nobjective that navigates the balance between information compression and\npreservation. We employ variational inference to derive a tractable estimation\nfor DisTIB. This estimation can be simply optimized via standard gradient\ndescent with a reparameterization trick. Moreover, we theoretically prove that\nDisTIB can achieve optimal disentanglement, underscoring its superior efficacy.\nTo solidify our claims, we conduct extensive experiments on various downstream\ntasks to demonstrate the appealing efficacy of DisTIB and validate our\ntheoretical analyses.",
            "author": [
                "Zhuohang Dang",
                "Minnan Luo",
                "Chengyou Jia",
                "Guang Dai",
                "Jihong Wang",
                "Xiaojun Chang",
                "Jingdong Wang",
                "Qinghua Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01686v1",
                "http://arxiv.org/pdf/2311.01686v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01684v1",
            "title": "CASE: Commonsense-Augmented Score with an Expanded Answer Space",
            "updated": "2023-11-03T03:15:26Z",
            "published": "2023-11-03T03:15:26Z",
            "summary": "LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks\nto the knowledge they acquired in their training. In multiple-choice QA tasks,\nthe LM probabilities are used as an imperfect measure of the plausibility of\neach answer choice. One of the major limitations of the basic score is that it\ntreats all words as equally important. We propose CASE, a Commonsense-Augmented\nScore with an Expanded Answer Space. CASE addresses this limitation by\nassigning importance weights for individual words based on their semantic\nrelations to other words in the input. The dynamic weighting approach\noutperforms basic LM scores, not only because it reduces noise from unimportant\nwords, but also because it informs the model of implicit commonsense knowledge\nthat may be useful for answering the question. We then also follow prior work\nin expanding the answer space by generating lexically-divergent answers that\nare conceptually-similar to the choices. When combined with answer space\nexpansion, our method outperforms strong baselines on 5 commonsense benchmarks.\nWe further show these two approaches are complementary and may be especially\nbeneficial when using smaller LMs.",
            "author": [
                "Wenkai Chen",
                "Sahithya Ravi",
                "Vered Shwartz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01684v1",
                "http://arxiv.org/pdf/2311.01684v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01682v1",
            "title": "Flow-Based Feature Fusion for Vehicle-Infrastructure Cooperative 3D\n  Object Detection",
            "updated": "2023-11-03T03:10:09Z",
            "published": "2023-11-03T03:10:09Z",
            "summary": "Cooperatively utilizing both ego-vehicle and infrastructure sensor data can\nsignificantly enhance autonomous driving perception abilities. However, the\nuncertain temporal asynchrony and limited communication conditions can lead to\nfusion misalignment and constrain the exploitation of infrastructure data. To\naddress these issues in vehicle-infrastructure cooperative 3D (VIC3D) object\ndetection, we propose the Feature Flow Net (FFNet), a novel cooperative\ndetection framework. FFNet is a flow-based feature fusion framework that uses a\nfeature flow prediction module to predict future features and compensate for\nasynchrony. Instead of transmitting feature maps extracted from still-images,\nFFNet transmits feature flow, leveraging the temporal coherence of sequential\ninfrastructure frames. Furthermore, we introduce a self-supervised training\napproach that enables FFNet to generate feature flow with feature prediction\nability from raw infrastructure sequences. Experimental results demonstrate\nthat our proposed method outperforms existing cooperative detection methods\nwhile only requiring about 1/100 of the transmission cost of raw data and\ncovers all latency in one model on the DAIR-V2X dataset. The code is available\nat\n\\href{https://github.com/haibao-yu/FFNet-VIC3D}{https://github.com/haibao-yu/FFNet-VIC3D}.",
            "author": [
                "Haibao Yu",
                "Yingjuan Tang",
                "Enze Xie",
                "Jilei Mao",
                "Ping Luo",
                "Zaiqing Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01682v1",
                "http://arxiv.org/pdf/2311.01682v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01677v1",
            "title": "DialogBench: Evaluating LLMs as Human-like Dialogue Systems",
            "updated": "2023-11-03T02:59:56Z",
            "published": "2023-11-03T02:59:56Z",
            "summary": "Large language models (LLMs) have achieved remarkable breakthroughs in new\ndialogue capabilities, refreshing human's impressions on dialogue systems. The\nlong-standing goal of dialogue systems is to be human-like enough to establish\nlong-term connections with users by satisfying the need for communication,\naffection and social belonging. Therefore, there has been an urgent need to\nevaluate LLMs as human-like dialogue systems. In this paper, we propose\nDialogBench, a dialogue evaluation benchmark that currently contains $12$\ndialogue tasks to assess the capabilities of LLMs as human-like dialogue\nsystems should have. Specifically, we prompt GPT-4 to generate evaluation\ninstances for each task. We first design the basic prompt based on widely-used\ndesign principles and further mitigate the existing biases to generate\nhigher-quality evaluation instances. Our extensive test over $28$ LLMs\n(including pre-trained and supervised instruction-tuning) shows that\ninstruction fine-tuning benefits improve the human likeness of LLMs to a\ncertain extent, but there is still much room to improve those capabilities for\nmost LLMs as human-like dialogue systems. In addition, experimental results\nalso indicate that LLMs perform differently in various abilities that\nhuman-like dialogue systems should have. We will publicly release DialogBench,\nalong with the associated evaluation code for the broader research community.",
            "author": [
                "Jiao Ou",
                "Junda Lu",
                "Che Liu",
                "Yihong Tang",
                "Fuzheng Zhang",
                "Di Zhang",
                "Zhongyuan Wang",
                "Kun Gai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01677v1",
                "http://arxiv.org/pdf/2311.01677v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02117v2",
            "title": "Cooperative Network Learning for Large-Scale and Decentralized Graphs",
            "updated": "2023-11-07T08:50:24Z",
            "published": "2023-11-03T02:56:01Z",
            "summary": "Graph research, the systematic study of interconnected data points\nrepresented as graphs, plays a vital role in capturing intricate relationships\nwithin networked systems. However, in the real world, as graphs scale up,\nconcerns about data security among different data-owning agencies arise,\nhindering information sharing and, ultimately, the utilization of graph data.\nTherefore, establishing a mutual trust mechanism among graph agencies is\ncrucial for unlocking the full potential of graphs. Here, we introduce a\nCooperative Network Learning (CNL) framework to ensure secure graph computing\nfor various graph tasks. Essentially, this CNL framework unifies the local and\nglobal perspectives of GNN computing with distributed data for an agency by\nvirtually connecting all participating agencies as a global graph without a\nfixed central coordinator. Inter-agency computing is protected by various\ntechnologies inherent in our framework, including homomorphic encryption and\nsecure transmission. Moreover, each agency has a fair right to design or employ\nvarious graph learning models from its local or global perspective. Thus, CNL\ncan collaboratively train GNN models based on decentralized graphs inferred\nfrom local and global graphs. Experiments on contagion dynamics prediction and\ntraditional graph tasks (i.e., node classification and link prediction)\ndemonstrate that our CNL architecture outperforms state-of-the-art GNNs\ndeveloped at individual sites, revealing that CNL can provide a reliable, fair,\nsecure, privacy-preserving, and global perspective to build effective and\npersonalized models for network applications. We hope this framework will\naddress privacy concerns in graph-related research and integrate decentralized\ngraph data structures to benefit the network research community in cooperation\nand innovation.",
            "author": [
                "Qiang Wu",
                "Yiming Huang",
                "Yujie Zeng",
                "Yijie Teng",
                "Fang Zhou",
                "Linyuan L\u00fc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02117v2",
                "http://arxiv.org/pdf/2311.02117v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01676v1",
            "title": "MineSegSAT: An automated system to evaluate mining disturbed area\n  extents from Sentinel-2 imagery",
            "updated": "2023-11-03T02:52:01Z",
            "published": "2023-11-03T02:52:01Z",
            "summary": "Assessing the environmental impact of the mineral extraction industry plays a\ncritical role in understanding and mitigating the ecological consequences of\nextractive activities. This paper presents MineSegSAT, a model that presents a\nnovel approach to predicting environmentally impacted areas of mineral\nextraction sites using the SegFormer deep learning segmentation architecture\ntrained on Sentinel-2 data. The data was collected from non-overlapping regions\nover Western Canada in 2021 containing areas of land that have been\nenvironmentally impacted by mining activities that were identified from\nhigh-resolution satellite imagery in 2021. The SegFormer architecture, a\nstate-of-the-art semantic segmentation framework, is employed to leverage its\nadvanced spatial understanding capabilities for accurate land cover\nclassification. We investigate the efficacy of loss functions including Dice,\nTversky, and Lovasz loss respectively. The trained model was utilized for\ninference over the test region in the ensuing year to identify potential areas\nof expansion or contraction over these same periods. The Sentinel-2 data is\nmade available on Amazon Web Services through a collaboration with Earth Daily\nAnalytics which provides corrected and tiled analytics-ready data on the AWS\nplatform. The model and ongoing API to access the data on AWS allow the\ncreation of an automated tool to monitor the extent of disturbed areas\nsurrounding known mining sites to ensure compliance with their environmental\nimpact goals.",
            "author": [
                "Ezra MacDonald",
                "Derek Jacoby",
                "Yvonne Coady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01676v1",
                "http://arxiv.org/pdf/2311.01676v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01673v1",
            "title": "Content Significance Distribution of Sub-Text Blocks in Articles and Its\n  Application to Article-Organization Assessment",
            "updated": "2023-11-03T02:43:51Z",
            "published": "2023-11-03T02:43:51Z",
            "summary": "We explore how to capture the significance of a sub-text block in an article\nand how it may be used for text mining tasks. A sub-text block is a\nsub-sequence of sentences in the article. We formulate the notion of content\nsignificance distribution (CSD) of sub-text blocks, referred to as CSD of the\nfirst kind and denoted by CSD-1. In particular, we leverage Hugging Face's\nSentenceTransformer to generate contextual sentence embeddings, and use\nMoverScore over text embeddings to measure how similar a sub-text block is to\nthe entire text. To overcome the exponential blowup on the number of sub-text\nblocks, we present an approximation algorithm and show that the approximated\nCSD-1 is almost identical to the exact CSD-1. Under this approximation, we show\nthat the average and median CSD-1's for news, scholarly research, argument, and\nnarrative articles share the same pattern. We also show that under a certain\nlinear transformation, the complement of the cumulative distribution function\nof the beta distribution with certain values of $\\alpha$ and $\\beta$ resembles\na CSD-1 curve. We then use CSD-1's to extract linguistic features to train an\nSVC classifier for assessing how well an article is organized. Through\nexperiments, we show that this method achieves high accuracy for assessing\nstudent essays. Moreover, we study CSD of sentence locations, referred to as\nCSD of the second kind and denoted by CSD-2, and show that average CSD-2's for\ndifferent types of articles possess distinctive patterns, which either conform\ncommon perceptions of article structures or provide rectification with minor\ndeviation.",
            "author": [
                "You Zhou",
                "Jie Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01673v1",
                "http://arxiv.org/pdf/2311.01673v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01666v1",
            "title": "Plot Retrieval as an Assessment of Abstract Semantic Association",
            "updated": "2023-11-03T02:02:43Z",
            "published": "2023-11-03T02:02:43Z",
            "summary": "Retrieving relevant plots from the book for a query is a critical task, which\ncan improve the reading experience and efficiency of readers. Readers usually\nonly give an abstract and vague description as the query based on their own\nunderstanding, summaries, or speculations of the plot, which requires the\nretrieval model to have a strong ability to estimate the abstract semantic\nassociations between the query and candidate plots. However, existing\ninformation retrieval (IR) datasets cannot reflect this ability well. In this\npaper, we propose Plot Retrieval, a labeled dataset to train and evaluate the\nperformance of IR models on the novel task Plot Retrieval. Text pairs in Plot\nRetrieval have less word overlap and more abstract semantic association, which\ncan reflect the ability of the IR models to estimate the abstract semantic\nassociation, rather than just traditional lexical or semantic matching.\nExtensive experiments across various lexical retrieval, sparse retrieval, dense\nretrieval, and cross-encoder methods compared with human studies on Plot\nRetrieval show current IR models still struggle in capturing abstract semantic\nassociation between texts. Plot Retrieval can be the benchmark for further\nresearch on the semantic association modeling ability of IR models.",
            "author": [
                "Shicheng Xu",
                "Liang Pang",
                "Jiangnan Li",
                "Mo Yu",
                "Fandong Meng",
                "Huawei Shen",
                "Xueqi Cheng",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01666v1",
                "http://arxiv.org/pdf/2311.01666v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01664v1",
            "title": "A Theoretical Case Study of the Generalisation of Machine-learned\n  Potentials",
            "updated": "2023-11-03T01:55:14Z",
            "published": "2023-11-03T01:55:14Z",
            "summary": "Machine-learned interatomic potentials (MLIPs) are typically trained on\ndatasets that encompass a restricted subset of possible input structures, which\npresents a potential challenge for their generalization to a broader range of\nsystems outside the training set. Nevertheless, MLIPs have demonstrated\nimpressive accuracy in predicting forces and energies in simulations involving\nintricate and complex structures. In this paper we aim to take steps towards\nrigorously explaining the excellent observed generalisation properties of\nMLIPs. Specifically, we offer a comprehensive theoretical and numerical\ninvestigation of the generalization of MLIPs in the context of dislocation\nsimulations. We quantify precisely how the accuracy of such simulations is\ndirectly determined by a few key factors: the size of the training structures,\nthe choice of training observations (e.g., energies, forces, virials), and the\nlevel of accuracy achieved in the fitting process. Notably, our study reveals\nthe crucial role of fitting virials in ensuring the consistency of MLIPs for\ndislocation simulations. Our series of careful numerical experiments\nencompassing screw, edge, and mixed dislocations, supports existing best\npractices in the MLIPs literature but also provides new insights into the\ndesign of data sets and loss functions.",
            "author": [
                "Yangshuai Wang",
                "Shashwat Patel",
                "Christoph Ortner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01664v1",
                "http://arxiv.org/pdf/2311.01664v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01661v1",
            "title": "Deep Learning-driven Community Resilience Rating based on Intertwined\n  Socio-Technical Systems Features",
            "updated": "2023-11-03T01:50:36Z",
            "published": "2023-11-03T01:50:36Z",
            "summary": "Community resilience is a complex and muti-faceted phenomenon that emerges\nfrom complex and nonlinear interactions among different socio-technical systems\nand their resilience properties. However, present studies on community\nresilience focus primarily on vulnerability assessment and utilize index-based\napproaches, with limited ability to capture heterogeneous features within\ncommunity socio-technical systems and their nonlinear interactions in shaping\nrobustness, redundancy, and resourcefulness components of resilience. To\naddress this gap, this paper presents an integrated three-layer deep learning\nmodel for community resilience rating (called Resili-Net). Twelve measurable\nresilience features are specified and computed within community socio-technical\nsystems (i.e., facilities, infrastructures, and society) related to three\nresilience components of robustness, redundancy, and resourcefulness. Using\npublicly accessible data from multiple metropolitan statistical areas in the\nUnited States, Resili-Net characterizes the resilience levels of spatial areas\ninto five distinct levels. The interpretability of the model outcomes enables\nfeature analysis for specifying the determinants of resilience in areas within\neach resilience level, allowing for the identification of specific resilience\nenhancement strategies. Changes in community resilience profiles under urban\ndevelopment patterns are further examined by changing the value of related\nsocio-technical systems features. Accordingly, the outcomes provide novel\nperspectives for community resilience assessment by harnessing machine\nintelligence and heterogeneous urban big data.",
            "author": [
                "Kai Yin",
                "Ali Mostafavi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01661v1",
                "http://arxiv.org/pdf/2311.01661v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01659v1",
            "title": "Efficient Cloud Pipelines for Neural Radiance Fields",
            "updated": "2023-11-03T01:39:56Z",
            "published": "2023-11-03T01:39:56Z",
            "summary": "Since their introduction in 2020, Neural Radiance Fields (NeRFs) have taken\nthe computer vision community by storm. They provide a multi-view\nrepresentation of a scene or object that is ideal for eXtended Reality (XR)\napplications and for creative endeavors such as virtual production, as well as\nchange detection operations in geospatial analytics. The computational cost of\nthese generative AI models is quite high, however, and the construction of\ncloud pipelines to generate NeRFs is neccesary to realize their potential in\nclient applications. In this paper, we present pipelines on a high performance\nacademic computing cluster and compare it with a pipeline implemented on\nMicrosoft Azure. Along the way, we describe some uses of NeRFs in enabling\nnovel user interaction scenarios.",
            "author": [
                "Derek Jacoby",
                "Donglin Xu",
                "Weder Ribas",
                "Minyi Xu",
                "Ting Liu",
                "Vishwanath Jayaraman",
                "Mengdi Wei",
                "Emma De Blois",
                "Yvonne Coady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01659v1",
                "http://arxiv.org/pdf/2311.01659v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02115v1",
            "title": "Towards objective and systematic evaluation of bias in medical imaging\n  AI",
            "updated": "2023-11-03T01:37:28Z",
            "published": "2023-11-03T01:37:28Z",
            "summary": "Artificial intelligence (AI) models trained using medical images for clinical\ntasks often exhibit bias in the form of disparities in performance between\nsubgroups. Since not all sources of biases in real-world medical imaging data\nare easily identifiable, it is challenging to comprehensively assess how those\nbiases are encoded in models, and how capable bias mitigation methods are at\nameliorating performance disparities. In this article, we introduce a novel\nanalysis framework for systematically and objectively investigating the impact\nof biases in medical images on AI models. We developed and tested this\nframework for conducting controlled in silico trials to assess bias in medical\nimaging AI using a tool for generating synthetic magnetic resonance images with\nknown disease effects and sources of bias. The feasibility is showcased by\nusing three counterfactual bias scenarios to measure the impact of simulated\nbias effects on a convolutional neural network (CNN) classifier and the\nefficacy of three bias mitigation strategies. The analysis revealed that the\nsimulated biases resulted in expected subgroup performance disparities when the\nCNN was trained on the synthetic datasets. Moreover, reweighing was identified\nas the most successful bias mitigation strategy for this setup, and we\ndemonstrated how explainable AI methods can aid in investigating the\nmanifestation of bias in the model using this framework. Developing fair AI\nmodels is a considerable challenge given that many and often unknown sources of\nbiases can be present in medical imaging datasets. In this work, we present a\nnovel methodology to objectively study the impact of biases and mitigation\nstrategies on deep learning pipelines, which can support the development of\nclinical AI that is robust and responsible.",
            "author": [
                "Emma A. M. Stanley",
                "Raissa Souza",
                "Anthony Winder",
                "Vedant Gulve",
                "Kimberly Amador",
                "Matthias Wilms",
                "Nils D. Forkert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02115v1",
                "http://arxiv.org/pdf/2311.02115v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01657v1",
            "title": "Simulating Heavy-Hex Transverse Field Ising Model Magnetization Dynamics\n  Using Programmable Quantum Annealers",
            "updated": "2023-11-03T01:33:24Z",
            "published": "2023-11-03T01:33:24Z",
            "summary": "Recently, a Hamiltonian dynamics simulation was performed on a kicked\nferromagnetic 2D transverse field Ising model with a connectivity graph native\nto the 127 qubit heavy-hex IBM Quantum architecture using ZNE quantum error\nmitigation. We demonstrate that one of the observables in this Trotterized\nHamiltonian dynamics simulation, namely magnetization, can be efficiently\nsimulated on current superconducting qubit-based programmable quantum annealing\ncomputers. We show this using two distinct methods: reverse quantum annealing\nand h-gain state encoding. This simulation is possible because the 127 qubit\nheavy-hex connectivity graph can be natively embedded onto the D-Wave Pegasus\nquantum annealer hardware graph and because there exists a direct equivalence\nbetween the energy scales of the two types of quantum computers. We derive\nequivalent anneal pauses in order to simulate the Trotterized quantum circuit\ndynamics for varying Rx rotations $\\theta_h \\in (0, \\frac{\\pi}{2}]$, using\nquantum annealing processors. Multiple disjoint instances of the Ising model of\ninterest can be embedded onto the D-Wave Pegasus hardware graph, allowing for\nparallel quantum annealing. We report equivalent magnetization dynamics using\nquantum annealing for time steps of 20, 50 up to 10,000, which we find are\nconsistent with exact classical 27 qubit heavy-hex Trotterized circuit\nmagnetization dynamics, and we observe reasonable, albeit noisy, agreement with\nthe existing simulations for single site magnetization at 20 Trotter steps. The\nquantum annealers are able to simulate equivalent magnetization dynamics for\nthousands of time steps, significantly out of the computational reach of the\ndigital quantum computers on which the original Hamiltonian dynamics\nsimulations were performed.",
            "author": [
                "Elijah Pelofske",
                "Andreas B\u00e4rtschi",
                "Stephan Eidenbenz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01657v1",
                "http://arxiv.org/pdf/2311.01657v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01656v1",
            "title": "Hydride Units Filled B--C Clathrate: A New Pathway for High-Temperature\n  Superconductivity at Ambient Pressure",
            "updated": "2023-11-03T01:26:31Z",
            "published": "2023-11-03T01:26:31Z",
            "summary": "The pursuit of room-temperature superconductors has recently advanced with\nthe discovery of high-temperature superconductivity in compressed hydrides,\nalthough sustaining the superconductivity of hydrides at ambient pressure\nremains challenging. In parallel, $sp^3$-bonded frameworks comprising\nlightweight elements (\\textit{e.g.}, boron and carbon) have emerged as another\navenue for developing ambient-pressure superconductors. However, despite their\nstability at low pressures, the critical temperature ($T_\\text{c}$) values\nobserved in these materials have not yet reached the impressive benchmarks set\nby hydride-based superconductors. Here we propose a novel design strategy for\nachieving high-temperature superconductivity at ambient pressure by integrating\nhydride units into B-C clathrate structures. This approach exploits the\nbeneficial properties of hydrogen, the lightest element, to enhance the\nsuperconductivity beyond that of the parent compounds. For instance, our\ncomputational predictions indicate that doping SrB$_3$C$_3$ with ammonium\n(NH$_4$) yields a SrNH$_4$B$_6$C$_6$ compound with an estimated $T_\\text{c}$ of\n73 K at ambient pressure -- more than double that of its precursor (31 K).\nExtensive substitution across the periodic table results in a family of\nMNHNH$_4$B$_6$C$_6$ superconductors that are predicted to be superconducting at\nambient pressure. These compounds can potentially be synthesized using\nhigh-pressure techniques and then quenched to ambient conditions, with the\nhighest predicted ambient-pressure $T_\\text{c}$ of 86 K in PbNH$_4$B$_6$C$_6$.\nOur findings present a promising strategy for discovering high-$T_\\text{c}$\nsuperconductors at ambient pressure, potentially revolutionizing technologies\nreliant on superconducting materials.",
            "author": [
                "Ying Sun",
                "Li Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01656v1",
                "http://arxiv.org/pdf/2311.01656v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01655v2",
            "title": "Detecting Spurious Correlations via Robust Visual Concepts in Real and\n  AI-Generated Image Classification",
            "updated": "2023-11-16T00:22:27Z",
            "published": "2023-11-03T01:12:35Z",
            "summary": "Often machine learning models tend to automatically learn associations\npresent in the training data without questioning their validity or\nappropriateness. This undesirable property is the root cause of the\nmanifestation of spurious correlations, which render models unreliable and\nprone to failure in the presence of distribution shifts. Research shows that\nmost methods attempting to remedy spurious correlations are only effective for\na model's known spurious associations. Current spurious correlation detection\nalgorithms either rely on extensive human annotations or are too restrictive in\ntheir formulation. Moreover, they rely on strict definitions of visual\nartifacts that may not apply to data produced by generative models, as they are\nknown to hallucinate contents that do not conform to standard specifications.\nIn this work, we introduce a general-purpose method that efficiently detects\npotential spurious correlations, and requires significantly less human\ninterference in comparison to the prior art. Additionally, the proposed method\nprovides intuitive explanations while eliminating the need for pixel-level\nannotations. We demonstrate the proposed method's tolerance to the peculiarity\nof AI-generated images, which is a considerably challenging task, one where\nmost of the existing methods fall short. Consequently, our method is also\nsuitable for detecting spurious correlations that may propagate to downstream\napplications originating from generative models.",
            "author": [
                "Preetam Prabhu Srikar Dammu",
                "Chirag Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01655v2",
                "http://arxiv.org/pdf/2311.01655v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01653v1",
            "title": "INeAT: Iterative Neural Adaptive Tomography",
            "updated": "2023-11-03T01:00:36Z",
            "published": "2023-11-03T01:00:36Z",
            "summary": "Computed Tomography (CT) with its remarkable capability for three-dimensional\nimaging from multiple projections, enjoys a broad range of applications in\nclinical diagnosis, scientific observation, and industrial detection. Neural\nAdaptive Tomography (NeAT) is a recently proposed 3D rendering method based on\nneural radiance field for CT, and it demonstrates superior performance compared\nto traditional methods. However, it still faces challenges when dealing with\nthe substantial perturbations and pose shifts encountered in CT scanning\nprocesses. Here, we propose a neural rendering method for CT reconstruction,\nnamed Iterative Neural Adaptive Tomography (INeAT), which incorporates\niterative posture optimization to effectively counteract the influence of\nposture perturbations in data, particularly in cases involving significant\nposture variations. Through the implementation of a posture feedback\noptimization strategy, INeAT iteratively refines the posture corresponding to\nthe input images based on the reconstructed 3D volume. We demonstrate that\nINeAT achieves artifact-suppressed and resolution-enhanced reconstruction in\nscenarios with significant pose disturbances. Furthermore, we show that our\nINeAT maintains comparable reconstruction performance to stable-state\nacquisitions even using data from unstable-state acquisitions, which\nsignificantly reduces the time required for CT scanning and relaxes the\nstringent requirements on imaging hardware systems, underscoring its immense\npotential for applications in short-time and low-cost CT technology.",
            "author": [
                "Bo Xiong",
                "Changqing Su",
                "Zihan Lin",
                "You Zhou",
                "Zhaofei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01653v1",
                "http://arxiv.org/pdf/2311.01653v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01651v1",
            "title": "Keypoint Description by Symmetry Assessment -- Applications in\n  Biometrics",
            "updated": "2023-11-03T00:49:25Z",
            "published": "2023-11-03T00:49:25Z",
            "summary": "We present a model-based feature extractor to describe neighborhoods around\nkeypoints by finite expansion, estimating the spatially varying orientation by\nharmonic functions. The iso-curves of such functions are highly symmetric\nw.r.t. the origin (a keypoint) and the estimated parameters have well defined\ngeometric interpretations. The origin is also a unique singularity of all\nharmonic functions, helping to determine the location of a keypoint precisely,\nwhereas the functions describe the object shape of the neighborhood. This is\nnovel and complementary to traditional texture features which describe\ntexture-shape properties i.e. they are purposively invariant to translation\n(within a texture). We report on experiments of verification and identification\nof keypoints in forensic fingerprints by using publicly available data (NIST\nSD27) and discuss the results in comparison to other studies. These support our\nconclusions that the novel features can equip single cores or single minutia\nwith a significant verification power at 19% EER, and an identification power\nof 24-78% for ranks of 1-20. Additionally, we report verification results of\nperiocular biometrics using near-infrared images, reaching an EER performance\nof 13%, which is comparable to the state of the art. More importantly, fusion\nof two systems, our and texture features (Gabor), result in a measurable\nperformance improvement. We report reduction of the EER to 9%, supporting the\nview that the novel features capture relevant visual information, which\ntraditional texture features do not.",
            "author": [
                "Anna Mikaelyan",
                "Fernando Alonso-Fernandez",
                "Josef Bigun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01651v1",
                "http://arxiv.org/pdf/2311.01651v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01650v1",
            "title": "MARRS: Multimodal Reference Resolution System",
            "updated": "2023-11-03T00:48:42Z",
            "published": "2023-11-03T00:48:42Z",
            "summary": "Successfully handling context is essential for any dialog understanding task.\nThis context maybe be conversational (relying on previous user queries or\nsystem responses), visual (relying on what the user sees, for example, on their\nscreen), or background (based on signals such as a ringing alarm or playing\nmusic). In this work, we present an overview of MARRS, or Multimodal Reference\nResolution System, an on-device framework within a Natural Language\nUnderstanding system, responsible for handling conversational, visual and\nbackground context. In particular, we present different machine learning models\nto enable handing contextual queries; specifically, one to enable reference\nresolution, and one to handle context via query rewriting. We also describe how\nthese models complement each other to form a unified, coherent, lightweight\nsystem that can understand context while preserving user privacy.",
            "author": [
                "Halim Cagri Ates",
                "Shruti Bhargava",
                "Site Li",
                "Jiarui Lu",
                "Siddhardha Maddula",
                "Joel Ruben Antony Moniz",
                "Anil Kumar Nalamalapu",
                "Roman Hoang Nguyen",
                "Melis Ozyildirim",
                "Alkesh Patel",
                "Dhivya Piraviperumal",
                "Vincent Renkens",
                "Ankit Samal",
                "Thy Tran",
                "Bo-Hsiang Tseng",
                "Hong Yu",
                "Yuan Zhang",
                "Rong Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01650v1",
                "http://arxiv.org/pdf/2311.01650v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01647v1",
            "title": "Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational\n  and Temporal Graphs",
            "updated": "2023-11-03T00:33:24Z",
            "published": "2023-11-03T00:33:24Z",
            "summary": "As a powerful framework for graph representation learning, Graph Neural\nNetworks (GNNs) have garnered significant attention in recent years. However,\nto the best of our knowledge, there has been no formal analysis of the logical\nexpressiveness of GNNs as Boolean node classifiers over multi-relational\ngraphs, where each edge carries a specific relation type. In this paper, we\ninvestigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two\nvariables and counting quantifiers. On the negative side, we demonstrate that\nthe R$^2$-GNN architecture, which extends the local message passing GNN by\nincorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in\nthe general case. Nevertheless, on the positive side, we establish that\nR$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain\nrestricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs\nregarding expressiveness, we propose a simple graph transformation technique,\nakin to a preprocessing step, which can be executed in linear time. This\ntransformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$\nclassifiers when applied to the \"transformed\" input graph. Moreover, we extend\nour analysis of expressiveness and graph transformation to temporal graphs,\nexploring several temporal GNN architectures and providing an expressiveness\nhierarchy for them. To validate our findings, we implement R$^2$-GNNs and the\ngraph transformation technique and conduct empirical tests in node\nclassification tasks against various well-known GNN architectures that support\nmulti-relational or temporal graphs. Our experimental results consistently\ndemonstrate that R$^2$-GNN with the graph transformation outperforms the\nbaseline methods on both synthetic and real-world datasets",
            "author": [
                "Yeyuan Chen",
                "Dingmin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01647v1",
                "http://arxiv.org/pdf/2311.01647v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01646v1",
            "title": "SemiGPC: Distribution-Aware Label Refinement for Imbalanced\n  Semi-Supervised Learning Using Gaussian Processes",
            "updated": "2023-11-03T00:25:58Z",
            "published": "2023-11-03T00:25:58Z",
            "summary": "In this paper we introduce SemiGPC, a distribution-aware label refinement\nstrategy based on Gaussian Processes where the predictions of the model are\nderived from the labels posterior distribution. Differently from other\nbuffer-based semi-supervised methods such as CoMatch and SimMatch, our SemiGPC\nincludes a normalization term that addresses imbalances in the global data\ndistribution while maintaining local sensitivity. This explicit control allows\nSemiGPC to be more robust to confirmation bias especially under class\nimbalance. We show that SemiGPC improves performance when paired with different\nSemi-Supervised methods such as FixMatch, ReMixMatch, SimMatch and FreeMatch\nand different pre-training strategies including MSN and Dino. We also show that\nSemiGPC achieves state of the art results under different degrees of class\nimbalance on standard CIFAR10-LT/CIFAR100-LT especially in the low data-regime.\nUsing SemiGPC also results in about 2% avg.accuracy increase compared to a new\ncompetitive baseline on the more challenging benchmarks SemiAves, SemiCUB,\nSemiFungi and Semi-iNat.",
            "author": [
                "Abdelhak Lemkhenter",
                "Manchen Wang",
                "Luca Zancato",
                "Gurumurthy Swaminathan",
                "Paolo Favaro",
                "Davide Modolo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01646v1",
                "http://arxiv.org/pdf/2311.01646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01644v1",
            "title": "Should Under-parameterized Student Networks Copy or Average Teacher\n  Weights?",
            "updated": "2023-11-03T00:21:36Z",
            "published": "2023-11-03T00:21:36Z",
            "summary": "Any continuous function $f^*$ can be approximated arbitrarily well by a\nneural network with sufficiently many neurons $k$. We consider the case when\n$f^*$ itself is a neural network with one hidden layer and $k$ neurons.\nApproximating $f^*$ with a neural network with $n< k$ neurons can thus be seen\nas fitting an under-parameterized \"student\" network with $n$ neurons to a\n\"teacher\" network with $k$ neurons. As the student has fewer neurons than the\nteacher, it is unclear, whether each of the $n$ student neurons should copy one\nof the teacher neurons or rather average a group of teacher neurons. For\nshallow neural networks with erf activation function and for the standard\nGaussian input distribution, we prove that \"copy-average\" configurations are\ncritical points if the teacher's incoming vectors are orthonormal and its\noutgoing weights are unitary. Moreover, the optimum among such configurations\nis reached when $n-1$ student neurons each copy one teacher neuron and the\n$n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the\nstudent network with $n=1$ neuron, we provide additionally a closed-form\nsolution of the non-trivial critical point(s) for commonly used activation\nfunctions through solving an equivalent constrained optimization problem.\nEmpirically, we find for the erf activation function that gradient flow\nconverges either to the optimal copy-average critical point or to another point\nwhere each student neuron approximately copies a different teacher neuron.\nFinally, we find similar results for the ReLU activation function, suggesting\nthat the optimal solution of underparameterized networks has a universal\nstructure.",
            "author": [
                "Berfin \u015eim\u015fek",
                "Amire Bendjeddou",
                "Wulfram Gerstner",
                "Johanni Brea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01644v1",
                "http://arxiv.org/pdf/2311.01644v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04921v1",
            "title": "Successor Features for Efficient Multisubject Controlled Text Generation",
            "updated": "2023-11-03T00:17:08Z",
            "published": "2023-11-03T00:17:08Z",
            "summary": "While large language models (LLMs) have achieved impressive performance in\ngenerating fluent and realistic text, controlling the generated text so that it\nexhibits properties such as safety, factuality, and non-toxicity remains\nchallenging. % such as DExperts, GeDi, and rectification Existing\ndecoding-based methods are static in terms of the dimension of control; if the\ntarget subject is changed, they require new training. Moreover, it can quickly\nbecome prohibitive to concurrently control multiple subjects. In this work, we\nintroduce SF-GEN, which is grounded in two primary concepts: successor features\n(SFs) to decouple the LLM's dynamics from task-specific rewards, and language\nmodel rectification to proportionally adjust the probability of selecting a\ntoken based on the likelihood that the finished text becomes undesired. SF-GEN\nseamlessly integrates the two to enable dynamic steering of text generation\nwith no need to alter the LLM's parameters. Thanks to the decoupling effect\ninduced by successor features, our method proves to be memory-wise and\ncomputationally efficient for training as well as decoding, especially when\ndealing with multiple target subjects. To the best of our knowledge, our\nresearch represents the first application of successor features in text\ngeneration. In addition to its computational efficiency, the resultant language\nproduced by our method is comparable to the SOTA (and outperforms baselines) in\nboth control measures as well as language quality, which we demonstrate through\na series of experiments in various controllable text generation tasks.",
            "author": [
                "Meng Cao",
                "Mehdi Fatemi",
                "Jackie Chi Kit Cheung",
                "Samira Shabanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04921v1",
                "http://arxiv.org/pdf/2311.04921v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01641v1",
            "title": "Joint Queue-Length Distribution for the Non-Preemptive Multi-Server\n  Multi-Level Markovian Priority Queue",
            "updated": "2023-11-02T23:57:47Z",
            "published": "2023-11-02T23:57:47Z",
            "summary": "Explicit results are obtained using simple and exact methods for the joint\nqueue-length distribution of the M/M/c queue with an arbitrary number of\nnon-preemptive priority levels. This work is the first to provide explicit\nresults for the joint probability generating function and joint probability\nmass function for a general number of priority levels. A fixed-point iteration\nis developed for the stationary balance equations, which enables direct\ncomputation of the joint queue-length distribution. A multi-variate probability\ngenerating function is also derived, from which the joint probability mass\nfunction can be computed by means of a multi-dimensional fast Fourier transform\nmethod.",
            "author": [
                "Josef Zuk",
                "David Kirszenblat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01641v1",
                "http://arxiv.org/pdf/2311.01641v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "90B22 (Primary) 60K25, 60J74 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01635v1",
            "title": "RTP: Rethinking Tensor Parallelism with Memory Deduplication",
            "updated": "2023-11-02T23:12:42Z",
            "published": "2023-11-02T23:12:42Z",
            "summary": "In the evolving landscape of neural network models, one prominent challenge\nstand out: the significant memory overheads associated with training expansive\nmodels. Addressing this challenge, this study delves deep into the Rotated\nTensor Parallelism (RTP). RTP is an innovative approach that strategically\nfocuses on memory deduplication in distributed training environments. It boasts\nof unique features like a customized communication primitive and the Flyweight\nPattern initialization. Furthermore, RTP ensures a seamless overlap between\npartition computation and partition weight communication, optimizing the\ntraining process. Our empirical evaluations underscore RTP's efficiency,\nrevealing that its memory consumption during distributed system training is\nremarkably close to the optimal - distributing the memory overhead of a single\nmachine equitably among multiple machines. The experimental results demonstrate\nthat RTP is capable of achieving comparable performance to Distributed Data\nParallel while providing support for significantly larger models with\nnear-linear scalability in terms of memory. Code of RTP is available at\nhttps://github.com/wdlctc/rtp.",
            "author": [
                "Cheng Luo",
                "Tianle Zhong",
                "Geoffrey Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01635v1",
                "http://arxiv.org/pdf/2311.01635v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01634v1",
            "title": "\"Close...but not as good as an educator.\" -- Using ChatGPT to provide\n  formative feedback in large-class collaborative learning",
            "updated": "2023-11-02T23:00:38Z",
            "published": "2023-11-02T23:00:38Z",
            "summary": "Delivering personalised, formative feedback to multiple problem-based\nlearning groups in a short time period can be almost impossible. We employed\nChatGPT to provide personalised formative feedback in a one-hour Zoom break-out\nroom activity that taught practicing health professionals how to formulate\nevaluation plans for digital health initiatives. Learners completed an\nevaluation survey that included Likert scales and open-ended questions that\nwere analysed. Half of the 44 survey respondents had never used ChatGPT before.\nOverall, respondents found the feedback favourable, described a wide range of\ngroup dynamics, and had adaptive responses to the feedback, yet only three\ngroups used the feedback loop to improve their evaluation plans. Future\neducators can learn from our experience including engineering prompts,\nproviding instructions on how to use ChatGPT, and scaffolding optimal group\ninteractions with ChatGPT. Future researchers should explore the influence of\nChatGPT on group dynamics and derive design principles for the use of ChatGPT\nin collaborative learning.",
            "author": [
                "Cory Dal Ponte",
                "Sathana Dushyanthen",
                "Kayley Lyons"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01634v1",
                "http://arxiv.org/pdf/2311.01634v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01630v1",
            "title": "Generalizations of Matrix Multiplication can solve the Light Bulb\n  Problem",
            "updated": "2023-11-02T22:49:41Z",
            "published": "2023-11-02T22:49:41Z",
            "summary": "In the light bulb problem, one is given uniformly random vectors $x_1,\n\\ldots, x_n, y_1, \\ldots, y_n \\in \\{-1,1\\}^d$. They are all chosen\nindependently except a planted pair $(x_{i^*}, y_{j^*})$ is chosen with\ncorrelation $\\rho>0$. The goal is to find the planted pair. This problem was\nintroduced over 30 years ago by L.~Valiant, and is known to have many\napplications in data analysis, statistics, and learning theory.\n  The naive algorithm runs in $\\Omega(n^2)$ time, and algorithms based on\nLocality-Sensitive Hashing approach quadratic time as $\\rho \\to 0$. In 2012,\nG.~Valiant gave a breakthrough algorithm using fast matrix multiplication that\nruns in time $O(n^{(5-\\omega)/(4-\\omega)}) < O(n^{1.615})$, no matter how small\n$\\rho>0$ is. This was subsequently refined by Karppa, Kaski, and Kohonen in\n2016 to $O(n^{2 \\omega / 3}) < O(n^{1.582})$.\n  In this paper, we propose a new approach which can replace matrix\nmultiplication tensor with other tensors. Those tensors can omit some terms one\nis supposed to compute, and include additional error terms. Our new approach\ncan make use of any tensors which previously had no known algorithmic\napplications, including tensors which arise naturally as intermediate steps in\nborder rank methods and in the Laser method.\n  We further show that our approach can be combined with locality-sensitive\nhashing to design an algorithm whose running time improves as $\\rho$ gets\nlarger. To our knowledge, this is the first algorithm which combines fast\nmatrix multiplication with hashing for the light bulb problem or any closest\npair problem, and it leads to faster algorithms for small $\\rho>0$.\n  We also introduce a new tensor $T_{2112}$, which has the same size of $2\n\\times 2$ matrix multiplication tensor, but runs faster than the Strassen's\nalgorithm for light bulb problem.",
            "author": [
                "Josh Alman",
                "Hengjie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01630v1",
                "http://arxiv.org/pdf/2311.01630v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01629v1",
            "title": "On semidefinite programming characterizations of the numerical radius\n  and its dual norm for quaternionic matrices",
            "updated": "2023-11-02T22:45:45Z",
            "published": "2023-11-02T22:45:45Z",
            "summary": "We give a semidefinite programming characterizations of the numerical radius\nand its dual norm for quaternionic matrices. We show that the computation of\nthe numerical radius and its dual norm within $\\varepsilon$ precision are\npolynomially time computable in the data and $|\\log \\varepsilon |$ using the\nshort step, primal interior point method.",
            "author": [
                "Shmuel Friedland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01629v1",
                "http://arxiv.org/pdf/2311.01629v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "15A60, 15A69, 15B33, 68Q25, 68W25, 90C22, 90C51"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01624v1",
            "title": "Attention based Dual-Branch Complex Feature Fusion Network for\n  Hyperspectral Image Classification",
            "updated": "2023-11-02T22:31:24Z",
            "published": "2023-11-02T22:31:24Z",
            "summary": "This research work presents a novel dual-branch model for hyperspectral image\nclassification that combines two streams: one for processing standard\nhyperspectral patches using Real-Valued Neural Network (RVNN) and the other for\nprocessing their corresponding Fourier transforms using Complex-Valued Neural\nNetwork (CVNN). The proposed model is evaluated on the Pavia University and\nSalinas datasets. Results show that the proposed model outperforms\nstate-of-the-art methods in terms of overall accuracy, average accuracy, and\nKappa. Through the incorporation of Fourier transforms in the second stream,\nthe model is able to extract frequency information, which complements the\nspatial information extracted by the first stream. The combination of these two\nstreams improves the overall performance of the model. Furthermore, to enhance\nthe model performance, the Squeeze and Excitation (SE) mechanism has been\nutilized. Experimental evidence show that SE block improves the models overall\naccuracy by almost 1\\%.",
            "author": [
                "Mohammed Q. Alkhatib",
                "Mina Al-Saad",
                "Nour Aburaed",
                "M. Sami Zitouni",
                "Hussain Al Ahmad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01624v1",
                "http://arxiv.org/pdf/2311.01624v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01620v1",
            "title": "ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life\n  Videos",
            "updated": "2023-11-02T22:17:03Z",
            "published": "2023-11-02T22:17:03Z",
            "summary": "Multimodal counterfactual reasoning is a vital yet challenging ability for AI\nsystems. It involves predicting the outcomes of hypothetical circumstances\nbased on vision and language inputs, which enables AI models to learn from\nfailures and explore hypothetical scenarios. Despite its importance, there are\nonly a few datasets targeting the counterfactual reasoning abilities of\nmultimodal models. Among them, they only cover reasoning over synthetic\nenvironments or specific types of events (e.g. traffic collisions), making them\nhard to reliably benchmark the model generalization ability in diverse\nreal-world scenarios and reasoning dimensions. To overcome these limitations,\nwe develop a video question answering dataset, ACQUIRED: it consists of 3.9K\nannotated videos, encompassing a wide range of event types and incorporating\nboth first and third-person viewpoints, which ensures a focus on real-world\ndiversity. In addition, each video is annotated with questions that span three\ndistinct dimensions of reasoning, including physical, social, and temporal,\nwhich can comprehensively evaluate the model counterfactual abilities along\nmultiple aspects. We benchmark our dataset against several state-of-the-art\nlanguage-only and multimodal models and experimental results demonstrate a\nsignificant performance gap (>13%) between models and humans. The findings\nsuggest that multimodal counterfactual reasoning remains an open challenge and\nACQUIRED is a comprehensive and reliable benchmark for inspiring future\nresearch in this direction.",
            "author": [
                "Te-Lin Wu",
                "Zi-Yi Dou",
                "Qingyuan Hu",
                "Yu Hou",
                "Nischal Reddy Chandra",
                "Marjorie Freedman",
                "Ralph M. Weischedel",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01620v1",
                "http://arxiv.org/pdf/2311.01620v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01619v2",
            "title": "InsPLAD: A Dataset and Benchmark for Power Line Asset Inspection in UAV\n  Images",
            "updated": "2023-12-04T01:08:34Z",
            "published": "2023-11-02T22:06:23Z",
            "summary": "Power line maintenance and inspection are essential to avoid power supply\ninterruptions, reducing its high social and financial impacts yearly.\nAutomating power line visual inspections remains a relevant open problem for\nthe industry due to the lack of public real-world datasets of power line\ncomponents and their various defects to foster new research. This paper\nintroduces InsPLAD, a Power Line Asset Inspection Dataset and Benchmark\ncontaining 10,607 high-resolution Unmanned Aerial Vehicles colour images. The\ndataset contains seventeen unique power line assets captured from real-world\noperating power lines. Additionally, five of those assets present six defects:\nfour of which are corrosion, one is a broken component, and one is a bird's\nnest presence. All assets were labelled according to their condition, whether\nnormal or the defect name found on an image level. We thoroughly evaluate\nstate-of-the-art and popular methods for three image-level computer vision\ntasks covered by InsPLAD: object detection, through the AP metric; defect\nclassification, through Balanced Accuracy; and anomaly detection, through the\nAUROC metric. InsPLAD offers various vision challenges from uncontrolled\nenvironments, such as multi-scale objects, multi-size class instances, multiple\nobjects per image, intra-class variation, cluttered background, distinct\npoint-of-views, perspective distortion, occlusion, and varied lighting\nconditions. To the best of our knowledge, InsPLAD is the first large real-world\ndataset and benchmark for power line asset inspection with multiple components\nand defects for various computer vision tasks, with a potential impact to\nimprove state-of-the-art methods in the field. It will be publicly available in\nits integrity on a repository with a thorough description. It can be found at\nhttps://github.com/andreluizbvs/InsPLAD.",
            "author": [
                "Andr\u00e9 Luiz Buarque Vieira e Silva",
                "Heitor de Castro Felix",
                "Franscisco Paulo Magalh\u00e3es Sim\u00f5es",
                "Veronica Teichrieb",
                "Michel Mozinho dos Santos",
                "Hemir Santiago",
                "Virginia Sgotti",
                "Henrique Lott Neto"
            ],
            "link": [
                "http://dx.doi.org/10.1080/01431161.2023.2283900",
                "http://arxiv.org/abs/2311.01619v2",
                "http://arxiv.org/pdf/2311.01619v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01617v1",
            "title": "Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks",
            "updated": "2023-11-02T22:00:23Z",
            "published": "2023-11-02T22:00:23Z",
            "summary": "Contrastive representation learning has emerged as a promising technique for\ncontinual learning as it can learn representations that are robust to\ncatastrophic forgetting and generalize well to unseen future tasks. Previous\nwork in continual learning has addressed forgetting by using previous task data\nand trained models. Inspired by event models created and updated in the brain,\nwe propose a new mechanism that takes place during task boundaries, i.e., when\none task finishes and another starts. By observing the redundancy-inducing\nability of contrastive loss on the output of a neural network, our method\nleverages the first few samples of the new task to identify and retain\nparameters contributing most to the transfer ability of the neural network,\nfreeing up the remaining parts of the network to learn new features. We\nevaluate the proposed methods on benchmark computer vision datasets including\nCIFAR10 and TinyImagenet and demonstrate state-of-the-art performance in the\ntask-incremental, class-incremental, and domain-incremental continual learning\nscenarios.",
            "author": [
                "Rouzbeh Meshkinnejad",
                "Jie Mei",
                "Daniel Lizotte",
                "Yalda Mohsenzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01617v1",
                "http://arxiv.org/pdf/2311.01617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01615v1",
            "title": "FLAP: Fast Language-Audio Pre-training",
            "updated": "2023-11-02T21:58:50Z",
            "published": "2023-11-02T21:58:50Z",
            "summary": "We propose Fast Language-Audio Pre-training (FLAP), a self-supervised\napproach that efficiently and effectively learns aligned audio and language\nrepresentations through masking, contrastive learning and reconstruction. For\nefficiency, FLAP randomly drops audio spectrogram tokens, focusing solely on\nthe remaining ones for self-supervision. Through inter-modal contrastive\nlearning, FLAP learns to align paired audio and text representations in a\nshared latent space. Notably, FLAP leverages multiple augmented views via\nmasking for inter-modal contrast and learns to reconstruct the masked portion\nof audio tokens. Moreover, FLAP leverages large language models (LLMs) to\naugment the text inputs, contributing to improved performance. These approaches\nlead to more robust and informative audio-text representations, enabling FLAP\nto achieve state-of-the-art (SoTA) performance on audio-text retrieval tasks on\nAudioCaps (achieving 53.0% R@1) and Clotho (achieving 25.5% R@1).",
            "author": [
                "Ching-Feng Yeh",
                "Po-Yao Huang",
                "Vasu Sharma",
                "Shang-Wen Li",
                "Gargi Gosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01615v1",
                "http://arxiv.org/pdf/2311.01615v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01614v1",
            "title": "Alleviating the Curse of Dimensionality in Minkowski Sum Approximations\n  of Storage Flexibility",
            "updated": "2023-11-02T21:57:28Z",
            "published": "2023-11-02T21:57:28Z",
            "summary": "Many real-world applications require the joint optimization of a large number\nof flexible devices over some time horizon. The flexibility of multiple\nbatteries, thermostatically controlled loads, or electric vehicles, e.g., can\nbe used to support grid operations and to reduce operation costs. Using\npiecewise constant power values, the flexibility of each device over $d$ time\nperiods can be described as a polytopic subset in power space. The aggregated\nflexibility is given by the Minkowski sum of these polytopes. As the\ncomputation of Minkowski sums is in general demanding, several approximations\nhave been proposed in the literature. Yet, their application potential is often\nobjective-dependent and limited by the curse of dimensionality. In this paper,\nwe show that up to $2^d$ vertices of each polytope can be computed efficiently\nand that the convex hull of their sums provides a computationally efficient\ninner approximation of the Minkowski sum. Via an extensive simulation study, we\nillustrate that our approach outperforms ten state-of-the-art inner\napproximations in terms of computational complexity and accuracy for different\nobjectives. Moreover, we propose an efficient disaggregation method applicable\nto any vertex-based approximation. The proposed methods provide an efficient\nmeans to aggregate and to disaggregate typical battery storages in\nquarter-hourly periods over an entire day with reasonable accuracy for\naggregated cost and for peak power optimization.",
            "author": [
                "Emrah \u00d6zt\u00fcrk",
                "Timm Faulwasser",
                "Karl Worthmann",
                "Markus Prei\u00dfinger",
                "Klaus Rheinberger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01614v1",
                "http://arxiv.org/pdf/2311.01614v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01610v1",
            "title": "Stabilization of codimension of persistence barcodes",
            "updated": "2023-11-02T21:42:01Z",
            "published": "2023-11-02T21:42:01Z",
            "summary": "Persistent homology has become a ubiquitous tool in topological data\nanalysis. Throughout this paper, we consider persistent homology of a fixed\ndataset which is assumed to be a point cloud in a Euclidean space. Further, we\nuse the Rips construction for computation of persistent homology which, in our\nsetup, takes as a parameter a step size $h$. For a fixed $h$, one important\ndata visualization for the persistent homology is the persistence barcode. From\nanother point of view, each persistence barcode corresponds to a specific\nisomorphism class of quiver representations of an equioriented A-type Dynkin\nquiver. Using algebro-geometric facts regarding type-A quiver representations,\nwe define the codimension of a persistence barcode as the codimension of the\ncorresponding isomorphism class in the space of all quiver representations.\nFurther, we prove a new formula for the codimension and, as an application we\nprove that for a fixed dataset, the value of the codimension of the persistence\nbarcode stabilizes as the step size parameter tends to zero. As a consequence,\nwe define a new topological statistic for a dataset which we call the quiver\ncodimension of the dataset, and which is equal to the stabilized value of the\nbarcode codimensions.",
            "author": [
                "Justin Allman",
                "Anran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01610v1",
                "http://arxiv.org/pdf/2311.01610v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02110v1",
            "title": "Feature Attribution Explanations for Spiking Neural Networks",
            "updated": "2023-11-02T21:30:56Z",
            "published": "2023-11-02T21:30:56Z",
            "summary": "Third-generation artificial neural networks, Spiking Neural Networks (SNNs),\ncan be efficiently implemented on hardware. Their implementation on\nneuromorphic chips opens a broad range of applications, such as machine\nlearning-based autonomous control and intelligent biomedical devices. In\ncritical applications, however, insight into the reasoning of SNNs is\nimportant, thus SNNs need to be equipped with the ability to explain how\ndecisions are reached. We present \\textit{Temporal Spike Attribution} (TSA), a\nlocal explanation method for SNNs. To compute the explanation, we aggregate all\ninformation available in model-internal variables: spike times and model\nweights. We evaluate TSA on artificial and real-world time series data and\nmeasure explanation quality w.r.t. multiple quantitative criteria. We find that\nTSA correctly identifies a small subset of input features relevant to the\ndecision (i.e., is output-complete and compact) and generates similar\nexplanations for similar inputs (i.e., is continuous). Further, our experiments\nshow that incorporating the notion of \\emph{absent} spikes improves explanation\nquality. Our work can serve as a starting point for explainable SNNs, with\nfuture implementations on hardware yielding not only predictions but also\nexplanations in a broad range of application scenarios. Source code is\navailable at https://github.com/ElisaNguyen/tsa-explanations.",
            "author": [
                "Elisa Nguyen",
                "Meike Nauta",
                "Gwenn Englebienne",
                "Christin Seifert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02110v1",
                "http://arxiv.org/pdf/2311.02110v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01598v1",
            "title": "CiFlow: Dataflow Analysis and Optimization of Key Switching for\n  Homomorphic Encryption",
            "updated": "2023-11-02T21:08:56Z",
            "published": "2023-11-02T21:08:56Z",
            "summary": "Homomorphic encryption (HE) is a privacy-preserving computation technique\nthat enables computation on encrypted data. Today, the potential of HE remains\nlargely unrealized as it is impractically slow, preventing it from being used\nin real applications. A major computational bottleneck in HE is the\nkey-switching operation, accounting for approximately 70% of the overall HE\nexecution time and involving a large amount of data for inputs, intermediates,\nand keys. Prior research has focused on hardware accelerators to improve HE\nperformance, typically featuring large on-chip SRAMs and high off-chip\nbandwidth to deal with large scale data. In this paper, we present a novel\napproach to improve key-switching performance by rigorously analyzing its\ndataflow. Our primary goal is to optimize data reuse with limited on-chip\nmemory to minimize off-chip data movement. We introduce three distinct\ndataflows: Max-Parallel (MP), Digit-Centric (DC), and Output-Centric (OC), each\nwith unique scheduling approaches for key-switching computations. Through our\nanalysis, we show how our proposed Output-Centric technique can effectively\nreuse data by significantly lowering the intermediate key-switching working set\nand alleviating the need for massive off-chip bandwidth. We thoroughly evaluate\nthe three dataflows using the RPU, a recently published vector processor\ntailored for ring processing algorithms, which includes HE. This evaluation\nconsiders sweeps of bandwidth and computational throughput, and whether keys\nare buffered on-chip or streamed. With OC, we demonstrate up to 4.16x speedup\nover the MP dataflow and show how OC can save 16x on-chip SRAM by streaming\nkeys for minimal performance penalty.",
            "author": [
                "Negar Neda",
                "Austin Ebel",
                "Benedict Reynwar",
                "Brandon Reagen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01598v1",
                "http://arxiv.org/pdf/2311.01598v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01597v1",
            "title": "Vertical Decomposition in 3D and 4D with Applications to Line\n  Nearest-Neighbor Searching in 3D",
            "updated": "2023-11-02T21:07:07Z",
            "published": "2023-11-02T21:07:07Z",
            "summary": "Vertical decomposition is a widely used general technique for decomposing the\ncells of arrangements of semi-algebraic sets in $d$-space into\nconstant-complexity subcells. In this paper, we settle in the affirmative a few\nlong-standing open problems involving the vertical decomposition of\nsubstructures of arrangements for $d=3,4$: (i) Let $\\mathcal{S}$ be a\ncollection of $n$ semi-algebraic sets of constant complexity in 3D, and let\n$U(m)$ be an upper bound on the complexity of the union\n$\\mathcal{U}(\\mathcal{S}')$ of any subset $\\mathcal{S}'\\subseteq \\mathcal{S}$\nof size at most $m$. We prove that the complexity of the vertical decomposition\nof the complement of $\\mathcal{U}(\\mathcal{S})$ is $O^*(n^2+U(n))$ (where the\n$O^*(\\cdot)$ notation hides subpolynomial factors). We also show that the\ncomplexity of the vertical decomposition of the entire arrangement\n$\\mathcal{A}(\\mathcal{S})$ is $O^*(n^2+X)$, where $X$ is the number of vertices\nin $\\mathcal{A}(\\mathcal{S})$. (ii) Let $\\mathcal{F}$ be a collection of $n$\ntrivariate functions whose graphs are semi-algebraic sets of constant\ncomplexity. We show that the complexity of the vertical decomposition of the\nportion of the arrangement $\\mathcal{A}(\\mathcal{F})$ in 4D lying below the\nlower envelope of $\\mathcal{F}$ is $O^*(n^3)$.\n  These results lead to efficient algorithms for a variety of problems\ninvolving these decompositions, including algorithms for constructing the\ndecompositions themselves, and for constructing $(1/r)$-cuttings of\nsubstructures of arrangements of the kinds considered above. One additional\nalgorithm of interest is for output-sensitive point enclosure queries amid\nsemi-algebraic sets in three or four dimensions. In addition, as a main domain\nof applications, we study various proximity problems involving points and lines\nin 3D.",
            "author": [
                "Pankaj K. Agarwal",
                "Esther Ezra",
                "Micha Sharir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01597v1",
                "http://arxiv.org/pdf/2311.01597v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01596v1",
            "title": "Local Bayesian Dirichlet mixing of imperfect models",
            "updated": "2023-11-02T21:02:40Z",
            "published": "2023-11-02T21:02:40Z",
            "summary": "To improve the predictability of complex computational models in the\nexperimentally-unknown domains, we propose a Bayesian statistical machine\nlearning framework utilizing the Dirichlet distribution that combines results\nof several imperfect models. This framework can be viewed as an extension of\nBayesian stacking. To illustrate the method, we study the ability of Bayesian\nmodel averaging and mixing techniques to mine nuclear masses. We show that the\nglobal and local mixtures of models reach excellent performance on both\nprediction accuracy and uncertainty quantification and are preferable to\nclassical Bayesian model averaging. Additionally, our statistical analysis\nindicates that improving model predictions through mixing rather than mixing of\ncorrected models leads to more robust extrapolations.",
            "author": [
                "Vojtech Kejzlar",
                "L\u00e9o Neufcourt",
                "Witold Nazarewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01596v1",
                "http://arxiv.org/pdf/2311.01596v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "nucl-th",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01586v1",
            "title": "Dimension reduction for Nonlinear Schr\u00f6dinger equations",
            "updated": "2023-11-02T20:32:39Z",
            "published": "2023-11-02T20:32:39Z",
            "summary": "We discuss mathematical methods to derive Nonlinear Schr\\\"odinger equations\n(NLS) in \"low dimensional\" settings, i.e. the 3-dimensional physical space e.g.\nto 2 or 1 space dimensions. Beside from the case the system exhibits an\ninternal symmetry we consider the approaches of dimension reduction via\nconfinement limits and the method of variation. We deal with 2 types of NLS:\nnonlocal nonlinearities like the Hartree equation, including the\nSchr\\\"odinger--Poisson system (SPS), and local nonlinearities like the\nGross--Pitaevskii equation (GPE). Our theoretical considerations of dimension\nreduction get finally illustrated by numerical examples in a \"quasi 1-d\"\nsetting.",
            "author": [
                "Peter Allmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01586v1",
                "http://arxiv.org/pdf/2311.01586v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04229v1",
            "title": "Exploring Best Practices for ECG Signal Processing in Machine Learning",
            "updated": "2023-11-02T20:29:15Z",
            "published": "2023-11-02T20:29:15Z",
            "summary": "In this work we search for best practices in pre-processing of\nElectrocardiogram (ECG) signals in order to train better classifiers for the\ndiagnosis of heart conditions. State of the art machine learning algorithms\nhave achieved remarkable results in classification of some heart conditions\nusing ECG data, yet there appears to be no consensus on pre-processing best\npractices. Is this lack of consensus due to different conditions and\narchitectures requiring different processing steps for optimal performance? Is\nit possible that state of the art deep-learning models have rendered\npre-processing unnecessary? In this work we apply down-sampling, normalization,\nand filtering functions to 3 different multi-label ECG datasets and measure\ntheir effects on 3 different high-performing time-series classifiers. We find\nthat sampling rates as low as 50Hz can yield comparable results to the commonly\nused 500Hz. This is significant as smaller sampling rates will result in\nsmaller datasets and models, which require less time and resources to train.\nAdditionally, despite their common usage, we found min-max normalization to be\nslightly detrimental overall, and band-passing to make no measurable\ndifference. We found the blind approach to pre-processing of ECGs for\nmulti-label classification to be ineffective, with the exception of sample rate\nreduction which reliably reduces computational resources, but does not increase\naccuracy.",
            "author": [
                "Amir Salimi",
                "Sunil Vasu Kalmady",
                "Abram Hindle",
                "Osmar Zaiane",
                "Padma Kaul"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04229v1",
                "http://arxiv.org/pdf/2311.04229v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01583v1",
            "title": "A time splitting spectral method for the Klein-Gordon-Maxwell system",
            "updated": "2023-11-02T20:28:06Z",
            "published": "2023-11-02T20:28:06Z",
            "summary": "We discuss a time-splitting spectral method for the solution of the\nKlein--Gordon--Maxwell system in quantum electrodynamics. The convergence in\nHilbert space is proven theoretically and charge conservation is established.\nThe theoretical order two for the Strang splitting is illustrated by numerical\nexamples in 1D and 3D.",
            "author": [
                "Peter Allmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01583v1",
                "http://arxiv.org/pdf/2311.01583v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01581v1",
            "title": "Fast Many-to-Many Routing for Dynamic Taxi Sharing with Meeting Points",
            "updated": "2023-11-02T20:21:23Z",
            "published": "2023-11-02T20:21:23Z",
            "summary": "We introduce an improved algorithm for the dynamic taxi sharing problem, i.e.\na dispatcher that schedules a fleet of shared taxis as it is used by services\nlike UberXShare and Lyft Shared. We speed up the basic online algorithm that\nlooks for all possible insertions of a new customer into a set of existing\nroutes, we generalize the objective function, and we efficiently support a\nlarge number of possible pick-up and drop-off locations. This lays an\nalgorithmic foundation for taxi sharing systems with higher vehicle occupancy -\nenabling greatly reduced cost and ecological impact at comparable service\nquality. We find that our algorithm computes assignments between vehicles and\nriders several times faster than a previous state-of-the-art approach. Further,\nwe observe that allowing meeting points for vehicles and riders can reduce the\noperating cost of vehicle fleets by up to 15% while also reducing rider wait\nand trip times.",
            "author": [
                "Moritz Laupichler",
                "Peter Sanders"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01581v1",
                "http://arxiv.org/pdf/2311.01581v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01580v1",
            "title": "MetaReVision: Meta-Learning with Retrieval for Visually Grounded\n  Compositional Concept Acquisition",
            "updated": "2023-11-02T20:19:58Z",
            "published": "2023-11-02T20:19:58Z",
            "summary": "Humans have the ability to learn novel compositional concepts by recalling\nand generalizing primitive concepts acquired from past experiences. Inspired by\nthis observation, in this paper, we propose MetaReVision, a retrieval-enhanced\nmeta-learning model to address the visually grounded compositional concept\nlearning problem. The proposed MetaReVision consists of a retrieval module and\na meta-learning module which are designed to incorporate retrieved primitive\nconcepts as a supporting set to meta-train vision-anguage models for grounded\ncompositional concept recognition. Through meta-learning from episodes\nconstructed by the retriever, MetaReVision learns a generic compositional\nrepresentation that can be fast updated to recognize novel compositional\nconcepts. We create CompCOCO and CompFlickr to benchmark the grounded\ncompositional concept learning. Our experimental results show that MetaReVision\noutperforms other competitive baselines and the retrieval module plays an\nimportant role in this compositional learning process.",
            "author": [
                "Guangyue Xu",
                "Parisa Kordjamshidi",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01580v1",
                "http://arxiv.org/pdf/2311.01580v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01576v1",
            "title": "Numerical Solution of the Non-polynomial Schr\u00f6dinger Equation",
            "updated": "2023-11-02T20:15:15Z",
            "published": "2023-11-02T20:15:15Z",
            "summary": "Starting from the 3D Gross-Pitaevskii equation we revisit the dimensional\nreduction to an effective one-dimensional wave-equation that describes the\nlongitudinal dynamics of a Bose condensate in an axially-symmetric external\npotential. Using a variational approach, Salasnich et al. introduced the\nnon-polynomial Schr\\\"odinger equation (NPSE) which takes into account radial\nbroadening of the wave function due to particle interactions. A closed form was\nderived by neglecting slow variation of the radial wave function along the\nlongitudinal direction. We show that the full equation can efficiently be\nimplemented using a time splitting spectral scheme coupled to a constraint\nequation. We confirm the validity of the approximation for experimentally\nrelevant parameters. The corrections are found to be localized to regions of\nstrong density gradients for which we highlight the differences through a\nnumber of numerical examples comparing the different 1D models.",
            "author": [
                "Peter Allmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01576v1",
                "http://arxiv.org/pdf/2311.01576v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01574v1",
            "title": "Improving Lesion Segmentation in FDG-18 Whole-Body PET/CT scans using\n  Multilabel approach: AutoPET II challenge",
            "updated": "2023-11-02T19:51:54Z",
            "published": "2023-11-02T19:51:54Z",
            "summary": "Automatic segmentation of lesions in FDG-18 Whole Body (WB) PET/CT scans\nusing deep learning models is instrumental for determining treatment response,\noptimizing dosimetry, and advancing theranostic applications in oncology.\nHowever, the presence of organs with elevated radiotracer uptake, such as the\nliver, spleen, brain, and bladder, often leads to challenges, as these regions\nare often misidentified as lesions by deep learning models. To address this\nissue, we propose a novel approach of segmenting both organs and lesions,\naiming to enhance the performance of automatic lesion segmentation methods. In\nthis study, we assessed the effectiveness of our proposed method using the\nAutoPET II challenge dataset, which comprises 1014 subjects. We evaluated the\nimpact of inclusion of additional labels and data in the segmentation\nperformance of the model. In addition to the expert-annotated lesion labels, we\nintroduced eight additional labels for organs, including the liver, kidneys,\nurinary bladder, spleen, lung, brain, heart, and stomach. These labels were\nintegrated into the dataset, and a 3D UNET model was trained within the nnUNet\nframework. Our results demonstrate that our method achieved the top ranking in\nthe held-out test dataset, underscoring the potential of this approach to\nsignificantly improve lesion segmentation accuracy in FDG-18 Whole-Body PET/CT\nscans, ultimately benefiting cancer patients and advancing clinical practice.",
            "author": [
                "Gowtham Krishnan Murugesan",
                "Diana McCrumb",
                "Eric Brunner",
                "Jithendra Kumar",
                "Rahul Soni",
                "Vasily Grigorash",
                "Stephen Moore",
                "Jeff Van Oss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01574v1",
                "http://arxiv.org/pdf/2311.01574v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01573v1",
            "title": "Improving Fairness using Vision-Language Driven Image Augmentation",
            "updated": "2023-11-02T19:51:10Z",
            "published": "2023-11-02T19:51:10Z",
            "summary": "Fairness is crucial when training a deep-learning discriminative model,\nespecially in the facial domain. Models tend to correlate specific\ncharacteristics (such as age and skin color) with unrelated attributes\n(downstream tasks), resulting in biases which do not correspond to reality. It\nis common knowledge that these correlations are present in the data and are\nthen transferred to the models during training. This paper proposes a method to\nmitigate these correlations to improve fairness. To do so, we learn\ninterpretable and meaningful paths lying in the semantic space of a pre-trained\ndiffusion model (DiffAE) -- such paths being supervised by contrastive text\ndipoles. That is, we learn to edit protected characteristics (age and skin\ncolor). These paths are then applied to augment images to improve the fairness\nof a given dataset. We test the proposed method on CelebA-HQ and UTKFace on\nseveral downstream tasks with age and skin color as protected characteristics.\nAs a proxy for fairness, we compute the difference in accuracy with respect to\nthe protected characteristics. Quantitative results show how the augmented\nimages help the model improve the overall accuracy, the aforementioned metric,\nand the disparity of equal opportunity. Code is available at:\nhttps://github.com/Moreno98/Vision-Language-Bias-Control.",
            "author": [
                "Moreno D'Inc\u00e0",
                "Christos Tzelepis",
                "Ioannis Patras",
                "Nicu Sebe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01573v1",
                "http://arxiv.org/pdf/2311.01573v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01571v1",
            "title": "Preserving the knowledge of long clinical texts using aggregated\n  ensembles of large language models",
            "updated": "2023-11-02T19:50:02Z",
            "published": "2023-11-02T19:50:02Z",
            "summary": "Clinical texts, such as admission notes, discharge summaries, and progress\nnotes, contain rich and valuable information that can be used for various\nclinical outcome prediction tasks. However, applying large language models,\nsuch as BERT-based models, to clinical texts poses two major challenges: the\nlimitation of input length and the diversity of data sources. This paper\nproposes a novel method to preserve the knowledge of long clinical texts using\naggregated ensembles of large language models. Unlike previous studies which\nuse model ensembling or text aggregation methods separately, we combine\nensemble learning with text aggregation and train multiple large language\nmodels on two clinical outcome tasks: mortality prediction and length of stay\nprediction. We show that our method can achieve better results than baselines,\nensembling, and aggregation individually, and can improve the performance of\nlarge language models while handling long inputs and diverse datasets. We\nconduct extensive experiments on the admission notes from the MIMIC-III\nclinical database by combining multiple unstructured and high-dimensional\ndatasets, demonstrating our method's effectiveness and superiority over\nexisting approaches. We also provide a comprehensive analysis and discussion of\nour results, highlighting our method's applications and limitations for future\nresearch in the domain of clinical healthcare. The results and analysis of this\nstudy is supportive of our method assisting in clinical healthcare systems by\nenabling clinical decision-making with robust performance overcoming the\nchallenges of long text inputs and varied datasets.",
            "author": [
                "Mohammad Junayed Hasan",
                "Suhra Noor",
                "Mohammad Ashrafuzzaman Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01571v1",
                "http://arxiv.org/pdf/2311.01571v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01570v1",
            "title": "Sequential Subset Matching for Dataset Distillation",
            "updated": "2023-11-02T19:49:11Z",
            "published": "2023-11-02T19:49:11Z",
            "summary": "Dataset distillation is a newly emerging task that synthesizes a small-size\ndataset used in training deep neural networks (DNNs) for reducing data storage\nand model training costs. The synthetic datasets are expected to capture the\nessence of the knowledge contained in real-world datasets such that the former\nyields a similar performance as the latter. Recent advancements in distillation\nmethods have produced notable improvements in generating synthetic datasets.\nHowever, current state-of-the-art methods treat the entire synthetic dataset as\na unified entity and optimize each synthetic instance equally. This static\noptimization approach may lead to performance degradation in dataset\ndistillation. Specifically, we argue that static optimization can give rise to\na coupling issue within the synthetic data, particularly when a larger amount\nof synthetic data is being optimized. This coupling issue, in turn, leads to\nthe failure of the distilled dataset to extract the high-level features learned\nby the deep neural network (DNN) in the latter epochs.\n  In this study, we propose a new dataset distillation strategy called\nSequential Subset Matching (SeqMatch), which tackles this problem by adaptively\noptimizing the synthetic data to encourage sequential acquisition of knowledge\nduring dataset distillation. Our analysis indicates that SeqMatch effectively\naddresses the coupling issue by sequentially generating the synthetic\ninstances, thereby enhancing its performance significantly. Our proposed\nSeqMatch outperforms state-of-the-art methods in various datasets, including\nSVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet. Our code is available at\nhttps://github.com/shqii1j/seqmatch.",
            "author": [
                "Jiawei Du",
                "Qin Shi",
                "Joey Tianyi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01570v1",
                "http://arxiv.org/pdf/2311.01570v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01568v2",
            "title": "Anytime-Competitive Reinforcement Learning with Policy Prior",
            "updated": "2023-11-13T08:15:37Z",
            "published": "2023-11-02T19:44:59Z",
            "summary": "This paper studies the problem of Anytime-Competitive Markov Decision Process\n(A-CMDP). Existing works on Constrained Markov Decision Processes (CMDPs) aim\nto optimize the expected reward while constraining the expected cost over\nrandom dynamics, but the cost in a specific episode can still be\nunsatisfactorily high. In contrast, the goal of A-CMDP is to optimize the\nexpected reward while guaranteeing a bounded cost in each round of any episode\nagainst a policy prior. We propose a new algorithm, called Anytime-Competitive\nReinforcement Learning (ACRL), which provably guarantees the anytime cost\nconstraints. The regret analysis shows the policy asymptotically matches the\noptimal reward achievable under the anytime competitive constraints.\nExperiments on the application of carbon-intelligent computing verify the\nreward performance and cost constraint guarantee of ACRL.",
            "author": [
                "Jianyi Yang",
                "Pengfei Li",
                "Tongxin Li",
                "Adam Wierman",
                "Shaolei Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01568v2",
                "http://arxiv.org/pdf/2311.01568v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01567v1",
            "title": "Exploring the Hyperparameter Space of Image Diffusion Models for\n  Echocardiogram Generation",
            "updated": "2023-11-02T19:43:08Z",
            "published": "2023-11-02T19:43:08Z",
            "summary": "This work presents an extensive hyperparameter search on Image Diffusion\nModels for Echocardiogram generation. The objective is to establish\nfoundational benchmarks and provide guidelines within the realm of ultrasound\nimage and video generation. This study builds over the latest advancements,\nincluding cutting-edge model architectures and training methodologies. We also\nexamine the distribution shift between real and generated samples and consider\npotential solutions, crucial to train efficient models on generated data. We\ndetermine an Optimal FID score of $0.88$ for our research problem and achieve\nan FID of $2.60$. This work is aimed at contributing valuable insights and\nserving as a reference for further developments in the specialized field of\nultrasound image and video generation.",
            "author": [
                "Hadrien Reynaud",
                "Bernhard Kainz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01567v1",
                "http://arxiv.org/pdf/2311.01567v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01563v1",
            "title": "Assist Is Just as Important as the Goal: Image Resurfacing to Aid\n  Model's Robust Prediction",
            "updated": "2023-11-02T19:33:32Z",
            "published": "2023-11-02T19:33:32Z",
            "summary": "Adversarial patches threaten visual AI models in the real world. The number\nof patches in a patch attack is variable and determines the attack's potency in\na specific environment. Most existing defenses assume a single patch in the\nscene, and the multiple patch scenarios are shown to overcome them. This paper\npresents a model-agnostic defense against patch attacks based on total\nvariation for image resurfacing (TVR). The TVR is an image-cleansing method\nthat processes images to remove probable adversarial regions. TVR can be\nutilized solely or augmented with a defended model, providing multi-level\nsecurity for robust prediction. TVR nullifies the influence of patches in a\nsingle image scan with no prior assumption on the number of patches in the\nscene. We validate TVR on the ImageNet-Patch benchmark dataset and with\nreal-world physical objects, demonstrating its ability to mitigate patch\nattack.",
            "author": [
                "Abhijith Sharma",
                "Phil Munz",
                "Apurva Narayan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01563v1",
                "http://arxiv.org/pdf/2311.01563v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01556v1",
            "title": "MemorySeg: Online LiDAR Semantic Segmentation with a Latent Memory",
            "updated": "2023-11-02T19:18:34Z",
            "published": "2023-11-02T19:18:34Z",
            "summary": "Semantic segmentation of LiDAR point clouds has been widely studied in recent\nyears, with most existing methods focusing on tackling this task using a single\nscan of the environment. However, leveraging the temporal stream of\nobservations can provide very rich contextual information on regions of the\nscene with poor visibility (e.g., occlusions) or sparse observations (e.g., at\nlong range), and can help reduce redundant computation frame after frame. In\nthis paper, we tackle the challenge of exploiting the information from the past\nframes to improve the predictions of the current frame in an online fashion. To\naddress this challenge, we propose a novel framework for semantic segmentation\nof a temporal sequence of LiDAR point clouds that utilizes a memory network to\nstore, update and retrieve past information. Our framework also includes a\nregularizer that penalizes prediction variations in the neighborhood of the\npoint cloud. Prior works have attempted to incorporate memory in range view\nrepresentations for semantic segmentation, but these methods fail to handle\nocclusions and the range view representation of the scene changes drastically\nas agents nearby move. Our proposed framework overcomes these limitations by\nbuilding a sparse 3D latent representation of the surroundings. We evaluate our\nmethod on SemanticKITTI, nuScenes, and PandaSet. Our experiments demonstrate\nthe effectiveness of the proposed framework compared to the state-of-the-art.",
            "author": [
                "Enxu Li",
                "Sergio Casas",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01556v1",
                "http://arxiv.org/pdf/2311.01556v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01555v1",
            "title": "Instruction Distillation Makes Large Language Models Efficient Zero-shot\n  Rankers",
            "updated": "2023-11-02T19:16:21Z",
            "published": "2023-11-02T19:16:21Z",
            "summary": "Recent studies have demonstrated the great potential of Large Language Models\n(LLMs) serving as zero-shot relevance rankers. The typical approach involves\nmaking comparisons between pairs or lists of documents. Although effective,\nthese listwise and pairwise methods are not efficient and also heavily rely on\nintricate prompt engineering. To tackle this problem, we introduce a novel\ninstruction distillation method. The key idea is to distill the pairwise\nranking ability of open-sourced LLMs to a simpler but more efficient pointwise\nranking. Specifically, given the same LLM, we first rank documents using the\neffective pairwise approach with complex instructions, and then distill the\nteacher predictions to the pointwise approach with simpler instructions.\nEvaluation results on the BEIR, TREC, and ReDial datasets demonstrate that\ninstruction distillation can improve efficiency by 10 to 100x and also enhance\nthe ranking performance of LLMs. Furthermore, our approach surpasses the\nperformance of existing supervised methods like monoT5 and is on par with the\nstate-of-the-art zero-shot methods. The code to reproduce our results is\navailable at www.github.com/sunnweiwei/RankGPT.",
            "author": [
                "Weiwei Sun",
                "Zheng Chen",
                "Xinyu Ma",
                "Lingyong Yan",
                "Shuaiqiang Wang",
                "Pengjie Ren",
                "Zhumin Chen",
                "Dawei Yin",
                "Zhaochun Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01555v1",
                "http://arxiv.org/pdf/2311.01555v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01553v1",
            "title": "Total Variation Meets Differential Privacy",
            "updated": "2023-11-02T19:13:17Z",
            "published": "2023-11-02T19:13:17Z",
            "summary": "The framework of approximate differential privacy is considered, and\naugmented by introducing the notion of \"the total variation of a\n(privacy-preserving) mechanism\" (denoted by $\\eta$-TV). With this refinement,\nan exact composition result is derived, and shown to be significantly tighter\nthan the optimal bounds for differential privacy (which do not consider the\ntotal variation). Furthermore, it is shown that $(\\varepsilon,\\delta)$-DP with\n$\\eta$-TV is closed under subsampling. The induced total variation of commonly\nused mechanisms are computed. Moreover, the notion of total variation of a\nmechanism is extended to the local privacy setting and privacy-utility\ntradeoffs are investigated. In particular, total variation distance and KL\ndivergence are considered as utility functions and upper bounds are derived.\nFinally, the results are compared and connected to the (purely) locally\ndifferentially private setting.",
            "author": [
                "Elena Ghazi",
                "Ibrahim Issa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01553v1",
                "http://arxiv.org/pdf/2311.01553v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01548v2",
            "title": "The MadNIS Reloaded",
            "updated": "2023-11-16T09:33:11Z",
            "published": "2023-11-02T19:00:01Z",
            "summary": "In pursuit of precise and fast theory predictions for the LHC, we present an\nimplementation of the MadNIS method in the MadGraph event generator. A series\nof improvements in MadNIS further enhance its efficiency and speed. We validate\nthis implementation for realistic partonic processes and find significant gains\nfrom using modern machine learning in event generators.",
            "author": [
                "Theo Heimel",
                "Nathan Huetsch",
                "Fabio Maltoni",
                "Olivier Mattelaer",
                "Tilman Plehn",
                "Ramon Winterhalder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01548v2",
                "http://arxiv.org/pdf/2311.01548v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01544v2",
            "title": "Divergent Token Metrics: Measuring degradation to prune away LLM\n  components -- and optimize quantization",
            "updated": "2023-11-13T15:33:35Z",
            "published": "2023-11-02T18:55:53Z",
            "summary": "Large Language Models (LLMs) have reshaped natural language processing with\ntheir impressive capabilities. Their ever-increasing size, however, raised\nconcerns about their effective deployment and the need for LLM compressions.\nThis study introduces the Divergent Token metrics (DTMs), a novel approach for\nassessing compressed LLMs, addressing the limitations of traditional perplexity\nor accuracy measures that fail to accurately reflect text generation quality.\nDTMs focus on token divergence, that allow deeper insights into the subtleties\nof model compression, i.p. when evaluating component's impacts individually.\nUtilizing the First Divergent Token metric (FDTM) in model sparsification\nreveals that a quarter of all attention components can be pruned beyond 90% on\nthe Llama-2 model family, still keeping SOTA performance. For quantization FDTM\nsuggests that over 80% of parameters can naively be transformed to int8 without\nspecial outlier management. These evaluations indicate the necessity of\nchoosing appropriate compressions for parameters individually-and that FDTM can\nidentify those-while standard metrics result in deteriorated outcomes.",
            "author": [
                "Bj\u00f6rn Deiseroth",
                "Max Meuer",
                "Nikolas Gritsch",
                "Constantin Eichenberg",
                "Patrick Schramowski",
                "Matthias A\u00dfenmacher",
                "Kristian Kersting"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01544v2",
                "http://arxiv.org/pdf/2311.01544v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01539v1",
            "title": "Influence of ion-to-electron temperature ratio on tearing instability\n  and resulting subion-scale turbulence in a low-$\u03b2_e$ collisionless plasma",
            "updated": "2023-11-02T18:46:41Z",
            "published": "2023-11-02T18:46:41Z",
            "summary": "A two-field gyrofluid model including ion finite Larmor radius (FLR)\ncorrections, magnetic fluctuations along the ambient field and electron inertia\nis used to study two-dimensional reconnection in a low $\\beta_e$ collisionless\nplasma, in a plane perpendicular to the ambient field. Both moderate and large\nvalues of the ion-to-electron temperature ratio $\\tau$ are considered. The\nlinear growth rate of the tearing instability is computed for various values of\n$\\tau$, confirming the convergence to reduced electron magnetodynamics (REMHD)\npredictions in the large $\\tau$ limit. Comparisons with analytical estimates in\nseveral limit cases are also presented. The nonlinear dynamics leads to a\nfully-developed turbulent regime that appears to be sensitive to the value of\nthe parameter $\\tau$. For $\\tau = 100$, strong large-scale velocity shears\ntrigger Kelvin-Helmholtz instability, leading to the propagation of the\nturbulence through the separatrices, together with the formation of eddies of\nsize of the order of the electron skin depth. In the $\\tau = 1$ regime, the\nvortices are significantly smaller and their accurate description requires that\nelectron FLR effects be taken into account.",
            "author": [
                "C. Granier",
                "E. Tassi",
                "D. Laveder",
                "T. Passot",
                "P. L. Sulem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01539v1",
                "http://arxiv.org/pdf/2311.01539v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01535v1",
            "title": "Nonequilibrium statistical mechanics of money/energy exchange models",
            "updated": "2023-11-02T18:33:36Z",
            "published": "2023-11-02T18:33:36Z",
            "summary": "Many-body dynamical models in which Boltzmann statistics can be derived\ndirectly from the underlying dynamical laws without invoking the fundamental\npostulates of statistical mechanics are scarce. Interestingly, one such model\nis found in econophysics and in chemistry classrooms: the money game, in which\nplayers exchange money randomly in a process that resembles elastic\nintermolecular collisions in a gas, giving rise to the Boltzmann distribution\nof money owned by each player. Although this model offers a pedagogical example\nthat demonstrates the origins of Boltzmann statistics, such demonstrations\nusually rely on computer simulations - a proof of the exponential steady-state\ndistribution in this model has only become available in recent years. Here, we\nstudy this random money/energy exchange model, and its extensions, using a\nsimple mean-field-type approach that examines the properties of the\none-dimensional random walk performed by one of its participants. We give a\nsimple derivation of the Boltzmann steady-state distribution in this model.\nBreaking the time-reversal symmetry of the game by modifying its rules results\nin non-Boltzmann steady-state statistics. In particular, introducing \"unfair\"\nexchange rules in which a poorer player is more likely to give money to a\nricher player than to receive money from that richer player, results in an\nanalytically provable Pareto-type power-law distribution of the money in the\nlimit where the number of players is infinite, with a finite fraction of\nplayers in the \"ground state\" (i.e., with zero money). For a finite number of\nplayers, however, the game may give rise to a bimodal distribution of money and\nto bistable dynamics, in which a participant's wealth jumps between poor and\nrich states. The latter corresponds to a scenario where the player accumulates\nnearly all the available money in the game.",
            "author": [
                "Maggie Miao",
                "Kristian Blom",
                "Dmitrii E. Makarov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01535v1",
                "http://arxiv.org/pdf/2311.01535v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01534v1",
            "title": "Approximate Multiagent Reinforcement Learning for On-Demand Urban\n  Mobility Problem on a Large Map (extended version)",
            "updated": "2023-11-02T18:33:32Z",
            "published": "2023-11-02T18:33:32Z",
            "summary": "In this paper, we focus on the autonomous multiagent taxi routing problem for\na large urban environment where the location and number of future ride requests\nare unknown a-priori, but follow an estimated empirical distribution. Recent\ntheory has shown that if a base policy is stable then a rollout-based algorithm\nwith such a base policy produces a near-optimal stable policy. Although,\nrollout-based approaches are well-suited for learning cooperative multiagent\npolicies with considerations for future demand, applying such methods to a\nlarge urban environment can be computationally expensive. Large environments\ntend to have a large volume of requests, and hence require a large fleet of\ntaxis to guarantee stability. In this paper, we aim to address the\ncomputational bottleneck of multiagent (one-at-a-time) rollout, where the\ncomputational complexity grows linearly in the number of agents. We propose an\napproximate one-at-a-time rollout-based two-phase algorithm that reduces the\ncomputational cost, while still achieving a stable near-optimal policy. Our\napproach partitions the graph into sectors based on the predicted demand and an\nuser-defined maximum number of agents that can be planned for using the\none-at-a-time rollout approach. The algorithm then applies instantaneous\nassignment (IA) for re-balancing taxis across sectors and a sector-wide\none-at-a-time rollout algorithm that is executed in parallel for each sector.\nWe characterize the number of taxis $m$ that is sufficient for IA base policy\nto be stable, and derive a necessary condition on $m$ as time goes to infinity.\nOur numerical results show that our approach achieves stability for an $m$ that\nsatisfies the theoretical conditions. We also empirically demonstrate that our\nproposed two-phase algorithm has comparable performance to the one-at-a-time\nrollout over the entire map, but with significantly lower runtimes.",
            "author": [
                "Daniel Garces",
                "Sushmita Bhattacharya",
                "Dimitri Bertsekas",
                "Stephanie Gil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01534v1",
                "http://arxiv.org/pdf/2311.01534v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01531v1",
            "title": "Quantum Variational Solving of Nonlinear and Multi-Dimensional Partial\n  Differential Equations",
            "updated": "2023-11-02T18:29:31Z",
            "published": "2023-11-02T18:29:31Z",
            "summary": "A variational quantum algorithm for numerically solving partial differential\nequations (PDEs) on a quantum computer was proposed by Lubasch et al. In this\npaper, we generalize the method introduced by Lubasch et al. to cover a broader\nclass of nonlinear PDEs as well as multidimensional PDEs, and study the\nperformance of the variational quantum algorithm on several example equations.\nSpecifically, we show via numerical simulations that the algorithm can solve\ninstances of the Single-Asset Black-Scholes equation with a nontrivial\nnonlinear volatility model, the Double-Asset Black-Scholes equation, the\nBuckmaster equation, and the deterministic Kardar-Parisi-Zhang equation. Our\nsimulations used up to $n=12$ ansatz qubits, computing PDE solutions with $2^n$\ngrid points. We also performed proof-of-concept experiments with a trapped-ion\nquantum processor from IonQ, showing accurate computation of two representative\nexpectation values needed for the calculation of a single timestep of the\nnonlinear Black--Scholes equation. Through our classical simulations and\nexperiments on quantum hardware, we have identified -- and we discuss --\nseveral open challenges for using quantum variational methods to solve PDEs in\na regime with a large number ($\\gg 2^{20}$) of grid points, but also a\npractical number of gates per circuit and circuit shots.",
            "author": [
                "Abhijat Sarma",
                "Thomas W. Watts",
                "Mudassir Moosa",
                "Yilian Liu",
                "Peter L. McMahon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01531v1",
                "http://arxiv.org/pdf/2311.01531v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01523v1",
            "title": "Linear interference and systematic soliton shape modulation by\n  engineering plane wave background and soliton parameters",
            "updated": "2023-11-02T18:10:34Z",
            "published": "2023-11-02T18:10:34Z",
            "summary": "We investigate linear interference of a plane wave with different localised\nwaves using coupled Fokas-Lenells equation(FLE) with four wave mixing (FWM)\nterm. We obtain localised wave solution of the coupled FLE by linear\nsuperposition of two distinctly independent wave solutions namely plane wave\nand one soliton solution & plane wave and two soliton solution. We obtain\nseveral nonlinear profiles depending on the relative phase induced by soliton\nparameters. We analyse the linear interference profile under four different\nconditions on the spatial and temporal phase coefficients of interfering waves.\nWe further investigate the interaction of two soliton solution and a plane\nwave. In this case we notice that asymptotically, two solitons profile may be\nsimilar or different from each other depending on the choices of soliton\nparameters in the two cases. The results obtained by us might be useful for\napplications in soliton control, a fiber amplifier, all optical switching, and\noptical computing. Further we believe that the present investigation would be\nuseful to study the linear interference pattern of other localised waves of\nFLE.",
            "author": [
                "Sagardeep Talukdar",
                "Riki Dutta",
                "Gautam Kumar Saharia",
                "Sudipta Nandy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01523v1",
                "http://arxiv.org/pdf/2311.01523v1"
            ],
            "primary_category": "nlin.PS",
            "category": [
                "nlin.PS",
                "nlin.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01522v2",
            "title": "An Efficient Detection and Control System for Underwater Docking using\n  Machine Learning and Realistic Simulation: A Comprehensive Approach",
            "updated": "2023-11-06T19:34:05Z",
            "published": "2023-11-02T18:10:20Z",
            "summary": "Underwater docking is critical to enable the persistent operation of\nAutonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of\ndetecting and localizing the docking station, which is complex due to the\nhighly dynamic undersea environment. Image-based solutions offer a high\nacquisition rate and versatile alternative to adapt to this environment;\nhowever, the underwater environment presents challenges such as low visibility,\nhigh turbidity, and distortion. In addition to this, field experiments to\nvalidate underwater docking capabilities can be costly and dangerous due to the\nspecialized equipment and safety considerations required to conduct the\nexperiments. This work compares different deep-learning architectures to\nperform underwater docking detection and classification. The architecture with\nthe best performance is then compressed using knowledge distillation under the\nteacher-student paradigm to reduce the network's memory footprint, allowing\nreal-time implementation. To reduce the simulation-to-reality gap, a Generative\nAdversarial Network (GAN) is used to do image-to-image translation, converting\nthe Gazebo simulation image into a realistic underwater-looking image. The\nobtained image is then processed using an underwater image formation model to\nsimulate image attenuation over distance under different water types. The\nproposed method is finally evaluated according to the AUV docking success rate\nand compared with classical vision methods. The simulation results show an\nimprovement of 20% in the high turbidity scenarios regardless of the underwater\ncurrents. Furthermore, we show the performance of the proposed approach by\nshowing experimental results on the off-the-shelf AUV Iver3.",
            "author": [
                "Jalil Chavez-Galaviz",
                "Jianwen Li",
                "Matthew Bergman",
                "Miras Mengdibayev",
                "Nina Mahmoudian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01522v2",
                "http://arxiv.org/pdf/2311.01522v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01520v2",
            "title": "4D-Former: Multimodal 4D Panoptic Segmentation",
            "updated": "2023-11-17T21:58:35Z",
            "published": "2023-11-02T18:09:35Z",
            "summary": "4D panoptic segmentation is a challenging but practically useful task that\nrequires every point in a LiDAR point-cloud sequence to be assigned a semantic\nclass label, and individual objects to be segmented and tracked over time.\nExisting approaches utilize only LiDAR inputs which convey limited information\nin regions with point sparsity. This problem can, however, be mitigated by\nutilizing RGB camera images which offer appearance-based information that can\nreinforce the geometry-based LiDAR features. Motivated by this, we propose\n4D-Former: a novel method for 4D panoptic segmentation which leverages both\nLiDAR and image modalities, and predicts semantic masks as well as temporally\nconsistent object masks for the input point-cloud sequence. We encode semantic\nclasses and objects using a set of concise queries which absorb feature\ninformation from both data modalities. Additionally, we propose a learned\nmechanism to associate object tracks over time which reasons over both\nappearance and spatial location. We apply 4D-Former to the nuScenes and\nSemanticKITTI datasets where it achieves state-of-the-art results.",
            "author": [
                "Ali Athar",
                "Enxu Li",
                "Sergio Casas",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01520v2",
                "http://arxiv.org/pdf/2311.01520v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01512v1",
            "title": "Distributed Simulation of Statevectors and Density Matrices",
            "updated": "2023-11-02T18:00:36Z",
            "published": "2023-11-02T18:00:36Z",
            "summary": "Classical simulation of quantum computers is an irreplaceable step in the\ndesign of quantum algorithms. Exponential simulation costs demand the use of\nhigh-performance computing techniques, and in particular distribution, whereby\nthe quantum state description is partitioned between a network of cooperating\ncomputers - necessary for the exact simulation of more than approximately 30\nqubits. Distributed computing is notoriously difficult, requiring bespoke\nalgorithms dissimilar to their serial counterparts with different resource\nconsiderations, and which appear to restrict the utilities of a quantum\nsimulator. This manuscript presents a plethora of novel algorithms for\ndistributed full-state simulation of gates, operators, noise channels and other\ncalculations in digital quantum computers. We show how a simple, common but\nseemingly restrictive distribution model actually permits a rich set of\nadvanced facilities including Pauli gadgets, many-controlled many-target\ngeneral unitaries, density matrices, general decoherence channels, and partial\ntraces. These algorithms include asymptotically, polynomially improved\nsimulations of exotic gates, and thorough motivations for high-performance\ncomputing techniques which will be useful for even non-distributed simulators.\nOur results are derived in language familiar to a quantum information theory\naudience, and our algorithms formalised for the scientific simulation\ncommunity. We have implemented all algorithms herein presented into an\nisolated, minimalist C++ project, hosted open-source on Github with a\npermissive MIT license, and extensive testing. This manuscript aims both to\nsignificantly improve the high-performance quantum simulation tools available,\nand offer a thorough introduction to, and derivation of, full-state simulation\ntechniques.",
            "author": [
                "Tyson Jones",
                "B\u00e1lint Koczor",
                "Simon C. Benjamin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01512v1",
                "http://arxiv.org/pdf/2311.01512v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01511v1",
            "title": "Dispersion, Capacitated Nodes, and the Power of a Trusted Shepherd",
            "updated": "2023-11-02T18:00:23Z",
            "published": "2023-11-02T18:00:23Z",
            "summary": "In this paper, we look at and expand the problems of dispersion and Byzantine\ndispersion of mobile robots on a graph, introduced by Augustine and\nMoses~Jr.~[ICDCN~2018] and by Molla, Mondal, and Moses~Jr.~[ALGOSENSORS~2020],\nrespectively, to graphs where nodes have variable capacities. We use the idea\nof a single shepherd, a more powerful robot that will never act in a Byzantine\nmanner, to achieve fast Byzantine dispersion, even when other robots may be\nstrong Byzantine in nature. We also show the benefit of a shepherd for\ndispersion on capacitated graphs when no Byzantine robots are present.",
            "author": [
                "William K. Moses Jr.",
                "Amanda Redlich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01511v1",
                "http://arxiv.org/pdf/2311.01511v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "F.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01508v1",
            "title": "$\\texttt{slick}$: Modeling a Universe of Molecular Line Luminosities in\n  Hydrodynamical Simulations",
            "updated": "2023-11-02T18:00:08Z",
            "published": "2023-11-02T18:00:08Z",
            "summary": "We present {\\sc slick} (the Scalable Line Intensity Computation Kit), a\nsoftware package that calculates realistic CO, [\\ion{C}{1}], and [\\ion{C}{2}]\nluminosities for clouds and galaxies formed in hydrodynamic simulations. Built\non the radiative transfer code {\\sc despotic}, {\\sc slick} computes the\nthermal, radiative, and statistical equilibrium in concentric zones of model\nclouds, based on their physical properties and individual environments. We\nvalidate our results applying {\\sc slick} to the high-resolution run of the\n{\\sc Simba} simulations, testing the derived luminosities against empirical and\ntheoretical/analytic relations. To simulate the line emission from a universe\nof emitting clouds, we have incorporated random forest machine learning (ML)\nmethods into our approach, allowing us to predict cosmologically evolving\nproperties of CO, [\\ion{C}{1}] and [\\ion{C}{2}] emission from galaxies such as\nluminosity functions. We tested this model in 100,000 gas particles, and 2,500\ngalaxies, reaching an average accuracy of $\\sim$99.8\\% for all lines. Finally,\nwe present the first model light cones created with realistic and ML-predicted\nCO, [\\ion{C}{1}], and [\\ion{C}{2}] luminosities in cosmological hydrodynamical\nsimulations, from $z=0$ to $z=10$.",
            "author": [
                "Karolina Garcia",
                "Desika Narayanan",
                "Gerg\u00f6 Popping",
                "R. Anirudh",
                "Sagan Sutherland",
                "Melanie Kaasinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01508v1",
                "http://arxiv.org/pdf/2311.01508v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO",
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01496v1",
            "title": "Noncoplanar and chiral spin states on the way towards N\u00e9el ordering in\n  fullerene Heisenberg models",
            "updated": "2023-11-02T18:00:01Z",
            "published": "2023-11-02T18:00:01Z",
            "summary": "Using high-accuracy variational Monte Carlo based on group-convolutional\nneural networks (GCNNs), we obtain the symmetry-resolved low-energy spectrum of\nthe spin-1/2 Heisenberg model on several highly symmetric fullerene geometries,\nincluding the famous C$_{60}$ buckminsterfullerene. We argue that as the degree\nof frustration is lowered in large fullerenes, they display characteristic\nfeatures of incipient magnetic ordering: correlation functions show\nhigh-intensity Bragg peaks consistent with N\\'eel-like ordering, while the\nlow-energy spectrum is organised into a tower of states. Competition with\nfrustration, however, turns the simple N\\'eel order into a noncoplanar one.\nRemarkably, we find and predict chiral incipient ordering in a large number of\nfullerene structures.",
            "author": [
                "Attila Szab\u00f3",
                "Sylvain Capponi",
                "Fabien Alet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01496v1",
                "http://arxiv.org/pdf/2311.01496v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01498v1",
            "title": "Tetraquarks made of sufficiently heavy quarks are bound in QCD",
            "updated": "2023-11-02T18:00:01Z",
            "published": "2023-11-02T18:00:01Z",
            "summary": "Tetraquarks, bound states composed of two quarks and two antiquarks, have\nbeen the subject of intense study but have yet to be understood from first\nprinciples. Previous studies of fully-heavy tetraquarks in nonrelativistic\neffective field theories of quantum chromodynamics (QCD) suggest different\nconclusions for their existence. We apply variational and Green's function\nMonte Carlo methods to compute tetraquarks' ground- and excited-state energies\nin potential nonrelativistic QCD. We robustly demonstrate that fully-heavy\ntetraquarks are bound in QCD for sufficiently heavy quark masses. We also\npredict the masses of tetraquark bound states comprised of $b$ and $c$ quarks,\nwhich are experimentally accessible, and suggest possible resolutions for\nprevious theoretical discrepancies.",
            "author": [
                "Beno\u00eet Assi",
                "Michael L. Wagman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01498v1",
                "http://arxiv.org/pdf/2311.01498v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01492v1",
            "title": "pyC$^2$Ray: A flexible and GPU-accelerated Radiative Transfer Framework\n  for Simulating the Cosmic Epoch of Reionization",
            "updated": "2023-11-02T18:00:00Z",
            "published": "2023-11-02T18:00:00Z",
            "summary": "Detailed modelling of the evolution of neutral hydrogen in the intergalactic\nmedium during the Epoch of Reionization, $5 \\leq z \\leq 20$, is critical in\ninterpreting the cosmological signals from current and upcoming 21-cm\nexperiments such as Low-Frequency Array (LOFAR) and the Square Kilometre Array\n(SKA). Numerical radiative transfer codes offer the most physically motivated\napproach for simulating the reionization process. However, they are\ncomputationally expensive as they must encompass enormous cosmological volumes\nwhile accurately capturing astrophysical processes occurring at small scales\n($\\lesssim\\rm Mpc$). Here, we present pyC$^2$Ray, an updated version of the\nmassively parallel ray-tracing and chemistry code, C$^2$Ray, which has been\nextensively employed in reionization simulations. The most time-consuming part\nof the code is calculating the hydrogen column density along the path of the\nionizing photons. Here, we present the Accelerated Short-characteristics\nOcthaedral RAytracing (ASORA) method, a ray-tracing algorithm specifically\ndesigned to run on graphical processing units (GPUs). We include a modern\nPython interface, allowing easy and customized use of the code without\ncompromising computational efficiency. We test pyC$^2$Ray on a series of\nstandard ray-tracing tests and a complete cosmological simulation with volume\nsize $(349\\,\\rm Mpc)^3$, mesh size of $250^3$ and approximately $10^6$ sources.\nCompared to the original code, pyC$^2$Ray achieves the same results with\nnegligible fractional differences, $\\sim 10^{-5}$, and a speedup factor of two\norders of magnitude. Benchmark analysis shows that ASORA takes a few\nnanoseconds per source per voxel and scales linearly for an increasing number\nof sources and voxels within the ray-tracing radii.",
            "author": [
                "Patrick Hirling",
                "Michele Bianco",
                "Sambit K. Giri",
                "Ilian T. Iliev",
                "Garrelt Mellema",
                "Jean-Paul Kneib"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01492v1",
                "http://arxiv.org/pdf/2311.01492v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01462v1",
            "title": "Idempotent Generative Network",
            "updated": "2023-11-02T17:59:55Z",
            "published": "2023-11-02T17:59:55Z",
            "summary": "We propose a new approach for generative modeling based on training a neural\nnetwork to be idempotent. An idempotent operator is one that can be applied\nsequentially without changing the result beyond the initial application, namely\n$f(f(z))=f(z)$. The proposed model $f$ is trained to map a source distribution\n(e.g, Gaussian noise) to a target distribution (e.g. realistic images) using\nthe following objectives: (1) Instances from the target distribution should map\nto themselves, namely $f(x)=x$. We define the target manifold as the set of all\ninstances that $f$ maps to themselves. (2) Instances that form the source\ndistribution should map onto the defined target manifold. This is achieved by\noptimizing the idempotence term, $f(f(z))=f(z)$ which encourages the range of\n$f(z)$ to be on the target manifold. Under ideal assumptions such a process\nprovably converges to the target distribution. This strategy results in a model\ncapable of generating an output in one step, maintaining a consistent latent\nspace, while also allowing sequential applications for refinement.\nAdditionally, we find that by processing inputs from both target and source\ndistributions, the model adeptly projects corrupted or modified data back to\nthe target manifold. This work is a first step towards a ``global projector''\nthat enables projecting any input into a target data distribution.",
            "author": [
                "Assaf Shocher",
                "Amil Dravid",
                "Yossi Gandelsman",
                "Inbar Mosseri",
                "Michael Rubinstein",
                "Alexei A. Efros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01462v1",
                "http://arxiv.org/pdf/2311.01462v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01461v1",
            "title": "The Property Law of Crypto Tokens",
            "updated": "2023-11-02T17:59:51Z",
            "published": "2023-11-02T17:59:51Z",
            "summary": "This article addresses the lack of comprehensive studies on Web3\ntechnologies, primarily due to lawyers' reluctance to explore technical\nintricacies. Understanding the underlying technological foundations is crucial\nto enhance the credibility of legal opinions. This article aims to illuminate\nthese foundations, debunk myths, and concentrate on determining the legal\nstatus of crypto-assets in the context of property rights within the\ndistributed economy. In addition, this article notes that the intangible nature\nof crypto-assets that derive value from distributed registries, and their\nresistance to deletion, makes crypto-assets more akin to the autonomy of\nintellectual property than physical media. The article presents illustrative\nexamples from common law (United States, United Kingdom, New Zealand) and civil\nlaw (Germany, Austria, Poland) systems. Proposing a universal solution, it\nadvocates a comprehensive framework safeguarding digital property - data\nownership - extending beyond the confines of Web3.\n  This article presents a comprehensive, multi-layered approach to the analysis\nof tokens as digital content and virtual goods. The approach, universally\napplicable to various of such goods, scrutinizes property on three distinct\nlayers: first, the rights to the virtual good itself; second, the rights to the\nassets linked to the virtual good; and third, the rights to the intellectual\nproperty intricately associated with the token. Additionally, the paper\nprovides concise analysis of the conflict of laws rules applicable to virtual\ngoods. It also delves into issues concerning formal requirements for the\ntransfer of intellectual property rights, licensing, the first sale\n(exhaustion) doctrine, the concept of the lawful acquirer, and other crucial\naspects of intellectual property in the realm of virtual goods, particularly\nwithin the emerging metaverse.",
            "author": [
                "Jakub Wyczik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01461v1",
                "http://arxiv.org/pdf/2311.01461v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01460v1",
            "title": "Implicit Chain of Thought Reasoning via Knowledge Distillation",
            "updated": "2023-11-02T17:59:49Z",
            "published": "2023-11-02T17:59:49Z",
            "summary": "To augment language models with the ability to reason, researchers usually\nprompt or finetune them to produce chain of thought reasoning steps before\nproducing the final answer. However, although people use natural language to\nreason effectively, it may be that LMs could reason more effectively with some\nintermediate computation that is not in natural language. In this work, we\nexplore an alternative reasoning approach: instead of explicitly producing the\nchain of thought reasoning steps, we use the language model's internal hidden\nstates to perform implicit reasoning. The implicit reasoning steps are\ndistilled from a teacher model trained on explicit chain-of-thought reasoning,\nand instead of doing reasoning \"horizontally\" by producing intermediate words\none-by-one, we distill it such that the reasoning happens \"vertically\" among\nthe hidden states in different layers. We conduct experiments on a multi-digit\nmultiplication task and a grade school math problem dataset and find that this\napproach enables solving tasks previously not solvable without explicit\nchain-of-thought, at a speed comparable to no chain-of-thought.",
            "author": [
                "Yuntian Deng",
                "Kiran Prasad",
                "Roland Fernandez",
                "Paul Smolensky",
                "Vishrav Chaudhary",
                "Stuart Shieber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01460v1",
                "http://arxiv.org/pdf/2311.01460v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01459v1",
            "title": "Align Your Prompts: Test-Time Prompting with Distribution Alignment for\n  Zero-Shot Generalization",
            "updated": "2023-11-02T17:59:32Z",
            "published": "2023-11-02T17:59:32Z",
            "summary": "The promising zero-shot generalization of vision-language models such as CLIP\nhas led to their adoption using prompt learning for numerous downstream tasks.\nPrevious works have shown test-time prompt tuning using entropy minimization to\nadapt text prompts for unseen domains. While effective, this overlooks the key\ncause for performance degradation to unseen domains -- distribution shift. In\nthis work, we explicitly handle this problem by aligning the\nout-of-distribution (OOD) test sample statistics to those of the source data\nusing prompt tuning. We use a single test sample to adapt multi-modal prompts\nat test time by minimizing the feature distribution shift to bridge the gap in\nthe test domain. Evaluating against the domain generalization benchmark, our\nmethod improves zero-shot top- 1 accuracy beyond existing prompt-learning\ntechniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset\ngeneralization with unseen categories across 10 datasets, our method improves\nconsistently across all datasets compared to the existing state-of-the-art. Our\nsource code and models are available at\nhttps://jameelhassan.github.io/promptalign.",
            "author": [
                "Jameel Hassan",
                "Hanan Gani",
                "Noor Hussein",
                "Muhammad Uzair Khattak",
                "Muzammal Naseer",
                "Fahad Shahbaz Khan",
                "Salman Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01459v1",
                "http://arxiv.org/pdf/2311.01459v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01458v1",
            "title": "Detecting Deepfakes Without Seeing Any",
            "updated": "2023-11-02T17:59:31Z",
            "published": "2023-11-02T17:59:31Z",
            "summary": "Deepfake attacks, malicious manipulation of media containing people, are a\nserious concern for society. Conventional deepfake detection methods train\nsupervised classifiers to distinguish real media from previously encountered\ndeepfakes. Such techniques can only detect deepfakes similar to those\npreviously seen, but not zero-day (previously unseen) attack types. As current\ndeepfake generation techniques are changing at a breathtaking pace, new attack\ntypes are proposed frequently, making this a major issue. Our main observations\nare that: i) in many effective deepfake attacks, the fake media must be\naccompanied by false facts i.e. claims about the identity, speech, motion, or\nappearance of the person. For instance, when impersonating Obama, the attacker\nexplicitly or implicitly claims that the fake media show Obama; ii) current\ngenerative techniques cannot perfectly synthesize the false facts claimed by\nthe attacker. We therefore introduce the concept of \"fact checking\", adapted\nfrom fake news detection, for detecting zero-day deepfake attacks. Fact\nchecking verifies that the claimed facts (e.g. identity is Obama), agree with\nthe observed media (e.g. is the face really Obama's?), and thus can\ndifferentiate between real and fake media. Consequently, we introduce FACTOR, a\npractical recipe for deepfake fact checking and demonstrate its power in\ncritical attack settings: face swapping and audio-visual synthesis. Although it\nis training-free, relies exclusively on off-the-shelf features, is very easy to\nimplement, and does not see any deepfakes, it achieves better than\nstate-of-the-art accuracy.",
            "author": [
                "Tal Reiss",
                "Bar Cavia",
                "Yedid Hoshen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01458v1",
                "http://arxiv.org/pdf/2311.01458v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01455v2",
            "title": "RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning\n  via Generative Simulation",
            "updated": "2023-11-13T18:40:10Z",
            "published": "2023-11-02T17:59:21Z",
            "summary": "We present RoboGen, a generative robotic agent that automatically learns\ndiverse robotic skills at scale via generative simulation. RoboGen leverages\nthe latest advancements in foundation and generative models. Instead of\ndirectly using or adapting these models to produce policies or low-level\nactions, we advocate for a generative scheme, which uses these models to\nautomatically generate diversified tasks, scenes, and training supervisions,\nthereby scaling up robotic skill learning with minimal human supervision. Our\napproach equips a robotic agent with a self-guided propose-generate-learn\ncycle: the agent first proposes interesting tasks and skills to develop, and\nthen generates corresponding simulation environments by populating pertinent\nobjects and assets with proper spatial configurations. Afterwards, the agent\ndecomposes the proposed high-level task into sub-tasks, selects the optimal\nlearning approach (reinforcement learning, motion planning, or trajectory\noptimization), generates required training supervision, and then learns\npolicies to acquire the proposed skill. Our work attempts to extract the\nextensive and versatile knowledge embedded in large-scale models and transfer\nthem to the field of robotics. Our fully generative pipeline can be queried\nrepeatedly, producing an endless stream of skill demonstrations associated with\ndiverse tasks and environments.",
            "author": [
                "Yufei Wang",
                "Zhou Xian",
                "Feng Chen",
                "Tsun-Hsuan Wang",
                "Yian Wang",
                "Zackory Erickson",
                "David Held",
                "Chuang Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01455v2",
                "http://arxiv.org/pdf/2311.01455v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01453v1",
            "title": "PPI++: Efficient Prediction-Powered Inference",
            "updated": "2023-11-02T17:59:04Z",
            "published": "2023-11-02T17:59:04Z",
            "summary": "We present PPI++: a computationally lightweight methodology for estimation\nand inference based on a small labeled dataset and a typically much larger\ndataset of machine-learning predictions. The methods automatically adapt to the\nquality of available predictions, yielding easy-to-compute confidence sets --\nfor parameters of any dimensionality -- that always improve on classical\nintervals using only the labeled data. PPI++ builds on prediction-powered\ninference (PPI), which targets the same problem setting, improving its\ncomputational and statistical efficiency. Real and synthetic experiments\ndemonstrate the benefits of the proposed adaptations.",
            "author": [
                "Anastasios N. Angelopoulos",
                "John C. Duchi",
                "Tijana Zrnic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01453v1",
                "http://arxiv.org/pdf/2311.01453v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01491v1",
            "title": "Investigating the Behavior of Diffusion Models for Accelerating\n  Electronic Structure Calculations",
            "updated": "2023-11-02T17:58:37Z",
            "published": "2023-11-02T17:58:37Z",
            "summary": "We present an investigation into diffusion models for molecular generation,\nwith the aim of better understanding how their predictions compare to the\nresults of physics-based calculations. The investigation into these models is\ndriven by their potential to significantly accelerate electronic structure\ncalculations using machine learning, without requiring expensive\nfirst-principles datasets for training interatomic potentials. We find that the\ninference process of a popular diffusion model for de novo molecular generation\nis divided into an exploration phase, where the model chooses the atomic\nspecies, and a relaxation phase, where it adjusts the atomic coordinates to\nfind a low-energy geometry. As training proceeds, we show that the model\ninitially learns about the first-order structure of the potential energy\nsurface, and then later learns about higher-order structure. We also find that\nthe relaxation phase of the diffusion model can be re-purposed to sample the\nBoltzmann distribution over conformations and to carry out structure\nrelaxations. For structure relaxations, the model finds geometries with ~10x\nlower energy than those produced by a classical force field for small organic\nmolecules. Initializing a density functional theory (DFT) relaxation at the\ndiffusion-produced structures yields a >2x speedup to the DFT relaxation when\ncompared to initializing at structures relaxed with a classical force field.",
            "author": [
                "Daniel Rothchild",
                "Andrew S. Rosen",
                "Eric Taw",
                "Connie Robinson",
                "Joseph E. Gonzalez",
                "Aditi S. Krishnapriyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01491v1",
                "http://arxiv.org/pdf/2311.01491v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.mtrl-sci",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01452v1",
            "title": "Time Series Anomaly Detection using Diffusion-based Models",
            "updated": "2023-11-02T17:58:09Z",
            "published": "2023-11-02T17:58:09Z",
            "summary": "Diffusion models have been recently used for anomaly detection (AD) in\nimages. In this paper we investigate whether they can also be leveraged for AD\non multivariate time series (MTS). We test two diffusion-based models and\ncompare them to several strong neural baselines. We also extend the PA%K\nprotocol, by computing a ROCK-AUC metric, which is agnostic to both the\ndetection threshold and the ratio K of correctly detected points. Our models\noutperform the baselines on synthetic datasets and are competitive on\nreal-world datasets, illustrating the potential of diffusion-based methods for\nAD in multivariate time series.",
            "author": [
                "Ioana Pintilie",
                "Andrei Manolache",
                "Florin Brad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01452v1",
                "http://arxiv.org/pdf/2311.01452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01449v1",
            "title": "TopicGPT: A Prompt-based Topic Modeling Framework",
            "updated": "2023-11-02T17:57:10Z",
            "published": "2023-11-02T17:57:10Z",
            "summary": "Topic modeling is a well-established technique for exploring text corpora.\nConventional topic models (e.g., LDA) represent topics as bags of words that\noften require \"reading the tea leaves\" to interpret; additionally, they offer\nusers minimal semantic control over topics. To tackle these issues, we\nintroduce TopicGPT, a prompt-based framework that uses large language models\n(LLMs) to uncover latent topics within a provided text collection. TopicGPT\nproduces topics that align better with human categorizations compared to\ncompeting methods: for example, it achieves a harmonic mean purity of 0.74\nagainst human-annotated Wikipedia topics compared to 0.64 for the strongest\nbaseline. Its topics are also more interpretable, dispensing with ambiguous\nbags of words in favor of topics with natural language labels and associated\nfree-form descriptions. Moreover, the framework is highly adaptable, allowing\nusers to specify constraints and modify topics without the need for model\nretraining. TopicGPT can be further extended to hierarchical topical modeling,\nenabling users to explore topics at various levels of granularity. By\nstreamlining access to high-quality and interpretable topics, TopicGPT\nrepresents a compelling, human-centered approach to topic modeling.",
            "author": [
                "Chau Minh Pham",
                "Alexander Hoyle",
                "Simeng Sun",
                "Mohit Iyyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01449v1",
                "http://arxiv.org/pdf/2311.01449v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01448v1",
            "title": "UltraLiDAR: Learning Compact Representations for LiDAR Completion and\n  Generation",
            "updated": "2023-11-02T17:57:03Z",
            "published": "2023-11-02T17:57:03Z",
            "summary": "LiDAR provides accurate geometric measurements of the 3D world.\nUnfortunately, dense LiDARs are very expensive and the point clouds captured by\nlow-beam LiDAR are often sparse. To address these issues, we present\nUltraLiDAR, a data-driven framework for scene-level LiDAR completion, LiDAR\ngeneration, and LiDAR manipulation. The crux of UltraLiDAR is a compact,\ndiscrete representation that encodes the point cloud's geometric structure, is\nrobust to noise, and is easy to manipulate. We show that by aligning the\nrepresentation of a sparse point cloud to that of a dense point cloud, we can\ndensify the sparse point clouds as if they were captured by a real high-density\nLiDAR, drastically reducing the cost. Furthermore, by learning a prior over the\ndiscrete codebook, we can generate diverse, realistic LiDAR point clouds for\nself-driving. We evaluate the effectiveness of UltraLiDAR on sparse-to-dense\nLiDAR completion and LiDAR generation. Experiments show that densifying\nreal-world point clouds with our approach can significantly improve the\nperformance of downstream perception systems. Compared to prior art on LiDAR\ngeneration, our approach generates much more realistic point clouds. According\nto A/B test, over 98.5\\% of the time human participants prefer our results over\nthose of previous methods.",
            "author": [
                "Yuwen Xiong",
                "Wei-Chiu Ma",
                "Jingkang Wang",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01448v1",
                "http://arxiv.org/pdf/2311.01448v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01447v1",
            "title": "CADSim: Robust and Scalable in-the-wild 3D Reconstruction for\n  Controllable Sensor Simulation",
            "updated": "2023-11-02T17:56:59Z",
            "published": "2023-11-02T17:56:59Z",
            "summary": "Realistic simulation is key to enabling safe and scalable development of %\nself-driving vehicles. A core component is simulating the sensors so that the\nentire autonomy system can be tested in simulation. Sensor simulation involves\nmodeling traffic participants, such as vehicles, with high quality appearance\nand articulated geometry, and rendering them in real time. The self-driving\nindustry has typically employed artists to build these assets. However, this is\nexpensive, slow, and may not reflect reality. Instead, reconstructing assets\nautomatically from sensor data collected in the wild would provide a better\npath to generating a diverse and large set with good real-world coverage.\nNevertheless, current reconstruction approaches struggle on in-the-wild sensor\ndata, due to its sparsity and noise. To tackle these issues, we present CADSim,\nwhich combines part-aware object-class priors via a small set of CAD models\nwith differentiable rendering to automatically reconstruct vehicle geometry,\nincluding articulated wheels, with high-quality appearance. Our experiments\nshow our method recovers more accurate shapes from sparse data compared to\nexisting approaches. Importantly, it also trains and renders efficiently. We\ndemonstrate our reconstructed vehicles in several applications, including\naccurate testing of autonomy perception systems.",
            "author": [
                "Jingkang Wang",
                "Sivabalan Manivasagam",
                "Yun Chen",
                "Ze Yang",
                "Ioan Andrei B\u00e2rsan",
                "Anqi Joyce Yang",
                "Wei-Chiu Ma",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01447v1",
                "http://arxiv.org/pdf/2311.01447v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01446v1",
            "title": "Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop\n  Simulation",
            "updated": "2023-11-02T17:56:44Z",
            "published": "2023-11-02T17:56:44Z",
            "summary": "Self-driving vehicles (SDVs) must be rigorously tested on a wide range of\nscenarios to ensure safe deployment. The industry typically relies on\nclosed-loop simulation to evaluate how the SDV interacts on a corpus of\nsynthetic and real scenarios and verify it performs properly. However, they\nprimarily only test the system's motion planning module, and only consider\nbehavior variations. It is key to evaluate the full autonomy system in\nclosed-loop, and to understand how variations in sensor data based on scene\nappearance, such as the shape of actors, affect system performance. In this\npaper, we propose a framework, Adv3D, that takes real world scenarios and\nperforms closed-loop sensor simulation to evaluate autonomy performance, and\nfinds vehicle shapes that make the scenario more challenging, resulting in\nautonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add\ncontrived adversarial shapes to vehicle roof-tops or roadside to harm\nperception only, we optimize a low-dimensional shape representation to modify\nthe vehicle shape itself in a realistic manner to degrade autonomy performance\n(e.g., perception, prediction, and motion planning). Moreover, we find that the\nshape variations found with Adv3D optimized in closed-loop are much more\neffective than those in open-loop, demonstrating the importance of finding\nscene appearance variations that affect autonomy in the interactive setting.",
            "author": [
                "Jay Sarva",
                "Jingkang Wang",
                "James Tu",
                "Yuwen Xiong",
                "Sivabalan Manivasagam",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01446v1",
                "http://arxiv.org/pdf/2311.01446v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01444v1",
            "title": "LabelFormer: Object Trajectory Refinement for Offboard Perception from\n  LiDAR Point Clouds",
            "updated": "2023-11-02T17:56:06Z",
            "published": "2023-11-02T17:56:06Z",
            "summary": "A major bottleneck to scaling-up training of self-driving perception systems\nare the human annotations required for supervision. A promising alternative is\nto leverage \"auto-labelling\" offboard perception models that are trained to\nautomatically generate annotations from raw LiDAR point clouds at a fraction of\nthe cost. Auto-labels are most commonly generated via a two-stage approach --\nfirst objects are detected and tracked over time, and then each object\ntrajectory is passed to a learned refinement model to improve accuracy. Since\nexisting refinement models are overly complex and lack advanced temporal\nreasoning capabilities, in this work we propose LabelFormer, a simple,\nefficient, and effective trajectory-level refinement approach. Our approach\nfirst encodes each frame's observations separately, then exploits\nself-attention to reason about the trajectory with full temporal context, and\nfinally decodes the refined object size and per-frame poses. Evaluation on both\nurban and highway datasets demonstrates that LabelFormer outperforms existing\nworks by a large margin. Finally, we show that training on a dataset augmented\nwith auto-labels generated by our method leads to improved downstream detection\nperformance compared to existing methods. Please visit the project website for\ndetails https://waabi.ai/labelformer",
            "author": [
                "Anqi Joyce Yang",
                "Sergio Casas",
                "Nikita Dvornik",
                "Sean Segal",
                "Yuwen Xiong",
                "Jordan Sir Kwang Hu",
                "Carter Fang",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01444v1",
                "http://arxiv.org/pdf/2311.01444v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01442v3",
            "title": "Deep Double Descent for Time Series Forecasting: Avoiding Undertrained\n  Models",
            "updated": "2023-11-30T06:51:26Z",
            "published": "2023-11-02T17:55:41Z",
            "summary": "Deep learning models, particularly Transformers, have achieved impressive\nresults in various domains, including time series forecasting. While existing\ntime series literature primarily focuses on model architecture modifications\nand data augmentation techniques, this paper explores the training schema of\ndeep learning models for time series; how models are trained regardless of\ntheir architecture. We perform extensive experiments to investigate the\noccurrence of deep double descent in several Transformer models trained on\npublic time series data sets. We demonstrate epoch-wise deep double descent and\nthat overfitting can be reverted using more epochs. Leveraging these findings,\nwe achieve state-of-the-art results for long sequence time series forecasting\nin nearly 70% of the 72 benchmarks tested. This suggests that many models in\nthe literature may possess untapped potential. Additionally, we introduce a\ntaxonomy for classifying training schema modifications, covering data\naugmentation, model inputs, model targets, time series per model, and\ncomputational budget.",
            "author": [
                "Valentino Assandri",
                "Sam Heshmati",
                "Burhaneddin Yaman",
                "Anton Iakovlev",
                "Ariel Emiliano Repetur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01442v3",
                "http://arxiv.org/pdf/2311.01442v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01441v1",
            "title": "Distilling Out-of-Distribution Robustness from Vision-Language\n  Foundation Models",
            "updated": "2023-11-02T17:55:13Z",
            "published": "2023-11-02T17:55:13Z",
            "summary": "We propose a conceptually simple and lightweight framework for improving the\nrobustness of vision models through the combination of knowledge distillation\nand data augmentation. We address the conjecture that larger models do not make\nfor better teachers by showing strong gains in out-of-distribution robustness\nwhen distilling from pretrained foundation models. Following this finding, we\npropose Discrete Adversarial Distillation (DAD), which leverages a robust\nteacher to generate adversarial examples and a VQGAN to discretize them,\ncreating more informative samples than standard data augmentation techniques.\nWe provide a theoretical framework for the use of a robust teacher in the\nknowledge distillation with data augmentation setting and demonstrate strong\ngains in out-of-distribution robustness and clean accuracy across different\nstudent architectures. Notably, our method adds minor computational overhead\ncompared to similar techniques and can be easily combined with other data\naugmentations for further improvements.",
            "author": [
                "Andy Zhou",
                "Jindong Wang",
                "Yu-Xiong Wang",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01441v1",
                "http://arxiv.org/pdf/2311.01441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01437v1",
            "title": "Checkerboard CFT",
            "updated": "2023-11-02T17:52:12Z",
            "published": "2023-11-02T17:52:12Z",
            "summary": "The Checkerboard conformal field theory is an interesting representative of a\nlarge class of non-unitary, logarithmic Fishnet CFTs (FCFT) in arbitrary\ndimension which have been intensively studied in the last years. Its planar\nFeynman graphs have the structure of a regular square lattice with checkerboard\ncolouring. Such graphs are integrable since each coloured cell of the lattice\nis equal to an R-matrix in the principal series representations of the\nconformal group. We compute perturbatively and numerically the anomalous\ndimension of the shortest single-trace operator in two reductions of the\nCheckerboard CFT: the first one corresponds to the fishnet limit of the twisted\nABJM theory in 3D, whereas the spectrum in the second, 2D reduction contains\nthe energy of the BFKL Pomeron. We derive an analytic expression for the\nCheckerboard analogues of Basso--Dixon 4-point functions, as well as for the\nclass of Diamond-type 4-point graphs with disc topology. The properties of the\nlatter are studied in terms of OPE for operators with open indices. We prove\nthat the spectrum of the theory receives corrections only at even orders in the\nloop expansion and we conjecture such a modification of Checkerboard CFT where\nquantum corrections occur only with a given periodicity in the loop order.",
            "author": [
                "Mikhail Alfimov",
                "Gwena\u00ebl Ferrando",
                "Vladimir Kazakov",
                "Enrico Olivucci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01437v1",
                "http://arxiv.org/pdf/2311.01437v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01432v1",
            "title": "Transformation Decoupling Strategy based on Screw Theory for\n  Deterministic Point Cloud Registration with Gravity Prior",
            "updated": "2023-11-02T17:46:25Z",
            "published": "2023-11-02T17:46:25Z",
            "summary": "Point cloud registration is challenging in the presence of heavy outlier\ncorrespondences. This paper focuses on addressing the robust\ncorrespondence-based registration problem with gravity prior that often arises\nin practice. The gravity directions are typically obtained by inertial\nmeasurement units (IMUs) and can reduce the degree of freedom (DOF) of rotation\nfrom 3 to 1. We propose a novel transformation decoupling strategy by\nleveraging screw theory. This strategy decomposes the original 4-DOF problem\ninto three sub-problems with 1-DOF, 2-DOF, and 1-DOF, respectively, thereby\nenhancing the computation efficiency. Specifically, the first 1-DOF represents\nthe translation along the rotation axis and we propose an interval\nstabbing-based method to solve it. The second 2-DOF represents the pole which\nis an auxiliary variable in screw theory and we utilize a branch-and-bound\nmethod to solve it. The last 1-DOF represents the rotation angle and we propose\na global voting method for its estimation. The proposed method sequentially\nsolves three consensus maximization sub-problems, leading to efficient and\ndeterministic registration. In particular, it can even handle the\ncorrespondence-free registration problem due to its significant robustness.\nExtensive experiments on both synthetic and real-world datasets demonstrate\nthat our method is more efficient and robust than state-of-the-art methods,\neven when dealing with outlier rates exceeding 99%.",
            "author": [
                "Xinyi Li",
                "Zijian Ma",
                "Yinlong Liu",
                "Walter Zimmer",
                "Hu Cao",
                "Feihu Zhang",
                "Alois Knoll"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01432v1",
                "http://arxiv.org/pdf/2311.01432v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01430v2",
            "title": "Scattering of spinning compact objects from a worldline EFT",
            "updated": "2023-11-07T15:45:33Z",
            "published": "2023-11-02T17:44:59Z",
            "summary": "We study the EFT of a spinning compact object and show that with appropriate\ngauge fixing, computations become amenable to worldline quantum field theory\ntechniques. We use the resulting action to compute Compton and one-loop\nscattering amplitudes at fourth order in spin. By matching these amplitdes to\nsolutions of the Teukolsky equations, we fix the values of Wilson coefficients\nappearing in the EFT such that it reproduces Kerr black hole scattering. We\nkeep track of the spin supplementary condition throughout our computations and\ndiscuss alternative ways to ensure its preservation.",
            "author": [
                "Maor Ben-Shahar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01430v2",
                "http://arxiv.org/pdf/2311.01430v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01429v1",
            "title": "Efficient Vision Transformer for Accurate Traffic Sign Detection",
            "updated": "2023-11-02T17:44:32Z",
            "published": "2023-11-02T17:44:32Z",
            "summary": "This research paper addresses the challenges associated with traffic sign\ndetection in self-driving vehicles and driver assistance systems. The\ndevelopment of reliable and highly accurate algorithms is crucial for the\nwidespread adoption of traffic sign recognition and detection (TSRD) in diverse\nreal-life scenarios. However, this task is complicated by suboptimal traffic\nimages affected by factors such as camera movement, adverse weather conditions,\nand inadequate lighting. This study specifically focuses on traffic sign\ndetection methods and introduces the application of the Transformer model,\nparticularly the Vision Transformer variants, to tackle this task. The\nTransformer's attention mechanism, originally designed for natural language\nprocessing, offers improved parallel efficiency. Vision Transformers have\ndemonstrated success in various domains, including autonomous driving, object\ndetection, healthcare, and defense-related applications. To enhance the\nefficiency of the Transformer model, the research proposes a novel strategy\nthat integrates a locality inductive bias and a transformer module. This\nincludes the introduction of the Efficient Convolution Block and the Local\nTransformer Block, which effectively capture short-term and long-term\ndependency information, thereby improving both detection speed and accuracy.\nExperimental evaluations demonstrate the significant advancements achieved by\nthis approach, particularly when applied to the GTSDB dataset.",
            "author": [
                "Javad Mirzapour Kaleybar",
                "Hooman Khaloo",
                "Avaz Naghipour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01429v1",
                "http://arxiv.org/pdf/2311.01429v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01427v1",
            "title": "Developing a Drift Rate Distribution for Technosignature Searches of\n  Exoplanets",
            "updated": "2023-11-02T17:42:33Z",
            "published": "2023-11-02T17:42:33Z",
            "summary": "A stable-frequency transmitter with relative radial acceleration to a\nreceiver will show a change in received frequency over time, known as a \"drift\nrate''. For a transmission from an exoplanet, we must account for multiple\ncomponents of drift rate: the exoplanet's orbit and rotation, the Earth's orbit\nand rotation, and other contributions. Understanding the drift rate\ndistribution produced by exoplanets relative to Earth, can a) help us constrain\nthe range of drift rates to check in a Search for Extraterrestrial Intelligence\n(SETI) project to detect radio technosignatures and b) help us decide validity\nof signals-of-interest, as we can compare drifting signals with expected drift\nrates from the target star. In this paper, we modeled the drift rate\ndistribution for $\\sim$5300 confirmed exoplanets, using parameters from the\nNASA Exoplanet Archive (NEA). We find that confirmed exoplanets have drift\nrates such that 99\\% of them fall within the $\\pm$53 nHz range. This implies a\ndistribution-informed maximum drift rate $\\sim$4 times lower than previous\nwork. To mitigate the observational biases inherent in the NEA, we also\nsimulated an exoplanet population built to reduce these biases. The results\nsuggest that, for a Kepler-like target star without known exoplanets, $\\pm$0.44\nnHz would be sufficient to account for 99\\% of signals. This reduction in\nrecommended maximum drift rate is partially due to inclination effects and bias\ntowards short orbital periods in the NEA. These narrowed drift rate maxima will\nincrease the efficiency of searches and save significant computational effort\nin future radio technosignature searches.",
            "author": [
                "Megan G. Li",
                "Sofia Z. Sheikh",
                "Christian Gilbertson",
                "Matthias Y. He",
                "Howard Isaacson",
                "Steve Croft",
                "Evan L. Sneed"
            ],
            "link": [
                "http://dx.doi.org/10.3847/1538-3881/acf83d",
                "http://arxiv.org/abs/2311.01427v1",
                "http://arxiv.org/pdf/2311.01427v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01425v1",
            "title": "Exploring Deep Learning Techniques for Glaucoma Detection: A\n  Comprehensive Review",
            "updated": "2023-11-02T17:39:40Z",
            "published": "2023-11-02T17:39:40Z",
            "summary": "Glaucoma is one of the primary causes of vision loss around the world,\nnecessitating accurate and efficient detection methods. Traditional manual\ndetection approaches have limitations in terms of cost, time, and subjectivity.\nRecent developments in deep learning approaches demonstrate potential in\nautomating glaucoma detection by detecting relevant features from retinal\nfundus images. This article provides a comprehensive overview of cutting-edge\ndeep learning methods used for the segmentation, classification, and detection\nof glaucoma. By analyzing recent studies, the effectiveness and limitations of\nthese techniques are evaluated, key findings are highlighted, and potential\nareas for further research are identified. The use of deep learning algorithms\nmay significantly improve the efficacy, usefulness, and accuracy of glaucoma\ndetection. The findings from this research contribute to the ongoing\nadvancements in automated glaucoma detection and have implications for\nimproving patient outcomes and reducing the global burden of glaucoma.",
            "author": [
                "Aized Amin Soofi",
                "Fazal-e-Amin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01425v1",
                "http://arxiv.org/pdf/2311.01425v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01423v2",
            "title": "CenterRadarNet: Joint 3D Object Detection and Tracking Framework using\n  4D FMCW Radar",
            "updated": "2023-11-04T21:30:42Z",
            "published": "2023-11-02T17:36:40Z",
            "summary": "Robust perception is a vital component for ensuring safe autonomous and\nassisted driving. Automotive radar (77 to 81 GHz), which offers\nweather-resilient sensing, provides a complementary capability to the vision-\nor LiDAR-based autonomous driving systems. Raw radio-frequency (RF) radar\ntensors contain rich spatiotemporal semantics besides 3D location information.\nThe majority of previous methods take in 3D (Doppler-range-azimuth) RF radar\ntensors, allowing prediction of an object's location, heading angle, and size\nin bird's-eye-view (BEV). However, they lack the ability to at the same time\ninfer objects' size, orientation, and identity in the 3D space. To overcome\nthis limitation, we propose an efficient joint architecture called\nCenterRadarNet, designed to facilitate high-resolution representation learning\nfrom 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection\nand re-identification (re-ID) tasks. As a single-stage 3D object detector,\nCenterRadarNet directly infers the BEV object distribution confidence maps,\ncorresponding 3D bounding box attributes, and appearance embedding for each\npixel. Moreover, we build an online tracker utilizing the learned appearance\nembedding for re-ID. CenterRadarNet achieves the state-of-the-art result on the\nK-Radar 3D object detection benchmark. In addition, we present the first 3D\nobject-tracking result using radar on the K-Radar dataset V2. In diverse\ndriving scenarios, CenterRadarNet shows consistent, robust performance,\nemphasizing its wide applicability.",
            "author": [
                "Jen-Hao Cheng",
                "Sheng-Yao Kuan",
                "Hugo Latapie",
                "Gaowen Liu",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01423v2",
                "http://arxiv.org/pdf/2311.01423v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01417v1",
            "title": "Multi-axis fields boost SABRE hyperpolarization via new strategies",
            "updated": "2023-11-02T17:32:45Z",
            "published": "2023-11-02T17:32:45Z",
            "summary": "The inherently low signal-to-noise ratio of NMR and MRI is now being\naddressed by hyperpolarization methods. For example, iridium-based catalysts\nthat reversibly bind both parahydrogen and ligands in solution can\nhyperpolarize protons (SABRE) or heteronuclei (X-SABRE) on a wide variety of\nligands, using a complex interplay of spin dynamics and chemical exchange\nprocesses, with common signal enhancements between $10^3-10^4$. This does not\napproach obvious theoretical limits, and further enhancement would be valuable\nin many applications (such as imaging mM concentration species in vivo). Most\nSABRE/X-SABRE implementations require far lower fields (${\\mu}T-mT$) than\nstandard magnetic resonance (>1T), and this gives an additional degree of\nfreedom: the ability to fully modulate fields in three dimensions. However,\nthis has been underexplored because the standard simplifying theoretical\nassumptions in magnetic resonance need to be revisited. Here we take a\ndifferent approach, an evolutionary strategy algorithm for numerical\noptimization, Multi-Axis Computer-aided HEteronuclear Transfer Enhancement for\nSABRE (MACHETE-SABRE). We find nonintuitive but highly efficient multi-axial\npulse sequences which experimentally can produce a 10-fold improvement in\npolarization over continuous excitation. This approach optimizes polarization\ndifferently than traditional methods, thus gaining extra efficiency.",
            "author": [
                "Jacob R. Lindale",
                "Loren L. Smith",
                "Mathew W. Mammen",
                "Shannon L. Eriksson",
                "Lucas Everhart",
                "Warren S. Warren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01417v1",
                "http://arxiv.org/pdf/2311.01417v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01414v3",
            "title": "A Dynamic Temporal Logic for Quality of Service in Choreographic Models",
            "updated": "2023-11-06T16:54:34Z",
            "published": "2023-11-02T17:30:51Z",
            "summary": "We propose a framework for expressing and analyzing the Quality of Service\n(QoS) of message-passing systems using a choreographic model that consists of\ng-choreographies and Communicating Finite State machines (CFSMs). The following\nare our three main contributions: (I) an extension of CFSMs with non-functional\ncontracts to specify quantitative constraints of local computations, (II) a\ndynamic temporal logic capable of expressing QoS, properties of systems\nrelative to the g-choreography that specifies the communication protocol, (III)\nthe semi-decidability of our logic which enables a bounded model-checking\napproach to verify QoS property of communicating systems.",
            "author": [
                "Carlos G. Lopez Pombo",
                "Agust\u00edn E. Martinez Su\u00f1\u00e9",
                "Emilio Tuosto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01414v3",
                "http://arxiv.org/pdf/2311.01414v3"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "68U07",
                "D.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01410v1",
            "title": "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based\n  Image Editing",
            "updated": "2023-11-02T17:23:14Z",
            "published": "2023-11-02T17:23:14Z",
            "summary": "We present a unified probabilistic formulation for diffusion-based image\nediting, where a latent variable is edited in a task-specific manner and\ngenerally deviates from the corresponding marginal distribution induced by the\noriginal stochastic or ordinary differential equation (SDE or ODE). Instead, it\ndefines a corresponding SDE or ODE for editing. In the formulation, we prove\nthat the Kullback-Leibler divergence between the marginal distributions of the\ntwo SDEs gradually decreases while that for the ODEs remains as the time\napproaches zero, which shows the promise of SDE in image editing. Inspired by\nit, we provide the SDE counterparts for widely used ODE baselines in various\ntasks including inpainting and image-to-image translation, where SDE shows a\nconsistent and substantial improvement. Moreover, we propose SDE-Drag -- a\nsimple yet effective method built upon the SDE formulation for point-based\ncontent dragging. We build a challenging benchmark (termed DragBench) with\nopen-set natural, art, and AI-generated images for evaluation. A user study on\nDragBench indicates that SDE-Drag significantly outperforms our ODE baseline,\nexisting diffusion-based methods, and the renowned DragGAN. Our results\ndemonstrate the superiority and versatility of SDE in image editing and push\nthe boundary of diffusion-based editing methods.",
            "author": [
                "Shen Nie",
                "Hanzhong Allan Guo",
                "Cheng Lu",
                "Yuhao Zhou",
                "Chenyu Zheng",
                "Chongxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01410v1",
                "http://arxiv.org/pdf/2311.01410v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01405v1",
            "title": "Learning to See Physical Properties with Active Sensing Motor Policies",
            "updated": "2023-11-02T17:19:18Z",
            "published": "2023-11-02T17:19:18Z",
            "summary": "Knowledge of terrain's physical properties inferred from color images can aid\nin making efficient robotic locomotion plans. However, unlike image\nclassification, it is unintuitive for humans to label image patches with\nphysical properties. Without labeled data, building a vision system that takes\nas input the observed terrain and predicts physical properties remains\nchallenging. We present a method that overcomes this challenge by\nself-supervised labeling of images captured by robots during real-world\ntraversal with physical property estimators trained in simulation. To ensure\naccurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are\ntrained to explore locomotion behaviors that increase the accuracy of\nestimating physical parameters. For instance, the quadruped robot learns to\nswipe its foot against the ground to estimate the friction coefficient\naccurately. We show that the visual system trained with a small amount of\nreal-world traversal data accurately predicts physical parameters. The trained\nsystem is robust and works even with overhead images captured by a drone\ndespite being trained on data collected by cameras attached to a quadruped\nrobot walking on the ground.",
            "author": [
                "Gabriel B. Margolis",
                "Xiang Fu",
                "Yandong Ji",
                "Pulkit Agrawal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01405v1",
                "http://arxiv.org/pdf/2311.01405v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01404v2",
            "title": "Normalizing flows as approximations of optimal transport maps via\n  linear-control neural ODEs",
            "updated": "2023-11-17T11:06:52Z",
            "published": "2023-11-02T17:17:03Z",
            "summary": "The term \"Normalizing Flows\" is related to the task of constructing\ninvertible transport maps between probability measures by means of deep neural\nnetworks. In this paper, we consider the problem of recovering the\n$W_2$-optimal transport map $T$ between absolutely continuous measures\n$\\mu,\\nu\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural\nODE. We first show that, under suitable assumptions on $\\mu,\\nu$ and on the\ncontrolled vector fields, the optimal transport map is contained in the\n$C^0_c$-closure of the flows generated by the system. Assuming that discrete\napproximations $\\mu_N,\\nu_N$ of the original measures $\\mu,\\nu$ are available,\nwe use a discrete optimal coupling $\\gamma_N$ to define an optimal control\nproblem. With a $\\Gamma$-convergence argument, we prove that its solutions\ncorrespond to flows that approximate the optimal transport map $T$. Finally,\ntaking advantage of the Pontryagin Maximum Principle, we propose an iterative\nnumerical scheme for the resolution of the optimal control problem, resulting\nin an algorithm for the practical computation of the approximated optimal\ntransport map.",
            "author": [
                "Alessandro Scagliotti",
                "Sara Farinelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01404v2",
                "http://arxiv.org/pdf/2311.01404v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "34H05, 49Q22, 49J45, 49M05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00301v1",
            "title": "A Simple Formula for Binomial Coefficients Revealed Through Polynomial\n  Encoding",
            "updated": "2023-11-02T17:09:34Z",
            "published": "2023-11-02T17:09:34Z",
            "summary": "We provide a detailed derivation of a new formula for binomial coefficients\nby harnessing an underexplored property of polynomial encoding. The formula,\n$\\binom{n}{k} = \\left\\lfloor\\frac{(1 + 2^{n})^{n}}{2^{n k}}\\right\\rfloor\n\\bmod{2^{n}}$, is valid for $n > 0$ and $0 \\leq k \\leq n$. We relate this\nformula to existing mathematical methods via Kronecker substitution. To\nshowcase the versatility of our approach, we also apply it to multinomials. A\nbaseline computational complexity analysis identifies opportunities for\noptimization. We conclude by positing an open problem concerning the efficient\ncomputation of $\\binom{n}{k}$ modulo $n$ using our formula.",
            "author": [
                "Joseph M. Shunia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00301v1",
                "http://arxiv.org/pdf/2312.00301v1"
            ],
            "primary_category": "math.GM",
            "category": [
                "math.GM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01398v1",
            "title": "Server-side Rescoring of Spoken Entity-centric Knowledge Queries for\n  Virtual Assistants",
            "updated": "2023-11-02T17:07:23Z",
            "published": "2023-11-02T17:07:23Z",
            "summary": "On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition\n(ASR) require effective knowledge integration for the challenging entity-rich\nquery recognition. In this paper, we conduct an empirical study of modeling\nstrategies for server-side rescoring of spoken information domain queries using\nvarious categories of Language Models (LMs) (N-gram word LMs, sub-word neural\nLMs). We investigate the combination of on-device and server-side signals, and\ndemonstrate significant WER improvements of 23%-35% on various entity-centric\nquery subpopulations by integrating various server-side LMs compared to\nperforming ASR on-device only. We also perform a comparison between LMs trained\non domain data and a GPT-3 variant offered by OpenAI as a baseline.\nFurthermore, we also show that model fusion of multiple server-side LMs trained\nfrom scratch most effectively combines complementary strengths of each model\nand integrates knowledge learned from domain-specific data to a VA ASR system.",
            "author": [
                "Youyuan Zhang",
                "Sashank Gondala",
                "Thiago Fraga-Silva",
                "Christophe Van Gysel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01398v1",
                "http://arxiv.org/pdf/2311.01398v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01397v1",
            "title": "Schubert matroids, Delannoy paths, and Speyer's invariant",
            "updated": "2023-11-02T17:04:06Z",
            "published": "2023-11-02T17:04:06Z",
            "summary": "We provide a combinatorial way of computing Speyer's $g$-polynomial on\narbitrary Schubert matroids via the enumeration of certain Delannoy paths. We\ndefine a new statistic of a basis in a matroid, and express the $g$-polynomial\nof a Schubert matroid in terms of it and internal and external activities. Some\nsurprising positivity properties of the $g$-polynomial of Schubert matroids are\ndeduced from our expression. Finally, we combine our formulas with a\nfundamental result of Derksen and Fink to provide an algorithm for computing\nthe $g$-polynomial of an arbitrary matroid.",
            "author": [
                "Luis Ferroni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01397v1",
                "http://arxiv.org/pdf/2311.01397v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01395v1",
            "title": "A Cosmological Bootstrap for Resonant Non-Gaussianity",
            "updated": "2023-11-02T16:59:12Z",
            "published": "2023-11-02T16:59:12Z",
            "summary": "Recent progress has revealed a number of constraints that cosmological\ncorrelators and the closely related field-theoretic wavefunction must obey as a\nconsequence of unitarity, locality, causality and the choice of initial state.\nWhen combined with symmetries, namely homogeneity, isotropy and scale\ninvariance, these constraints enable one to compute large classes of simple\nobservables, an approach known as (boostless) cosmological bootstrap. Here we\nshow that it is possible to relax the restriction of scale invariance, if one\nretains a discrete scaling subgroup. We find an infinite class of solutions to\nthe weaker bootstrap constraints and show that they reproduce and extend\nresonant non-Gaussianity, which arises in well-motivated models such as axion\nmonodromy inflation. We find no evidence of the new non-Gaussian shapes in the\nPlanck data. Intriguingly, our results can be re-interpreted as a deformation\nof the scale-invariant case to include a complex order of the total energy\npole, or more evocatively interactions with a complex number of derivatives. We\nalso discuss for the first time IR-divergent resonant contributions and\nhighlight an inconsequential inconsistency in the previous literature.",
            "author": [
                "Carlos Duaso Pueyo",
                "Enrico Pajer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01395v1",
                "http://arxiv.org/pdf/2311.01395v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "astro-ph.CO",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01394v1",
            "title": "Learning Realistic Traffic Agents in Closed-loop",
            "updated": "2023-11-02T16:55:23Z",
            "published": "2023-11-02T16:55:23Z",
            "summary": "Realistic traffic simulation is crucial for developing self-driving software\nin a safe and scalable manner prior to real-world deployment. Typically,\nimitation learning (IL) is used to learn human-like traffic agents directly\nfrom real-world observations collected offline, but without explicit\nspecification of traffic rules, agents trained from IL alone frequently display\nunrealistic infractions like collisions and driving off the road. This problem\nis exacerbated in out-of-distribution and long-tail scenarios. On the other\nhand, reinforcement learning (RL) can train traffic agents to avoid\ninfractions, but using RL alone results in unhuman-like driving behaviors. We\npropose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning\nobjective to match expert demonstrations under a traffic compliance constraint,\nwhich naturally gives rise to a joint IL + RL approach, obtaining the best of\nboth worlds. Our method learns in closed-loop simulations of both nominal\nscenarios from real-world datasets as well as procedurally generated long-tail\nscenarios. Our experiments show that RTR learns more realistic and\ngeneralizable traffic simulation policies, achieving significantly better\ntradeoffs between human-like driving and traffic compliance in both nominal and\nlong-tail scenarios. Moreover, when used as a data generation tool for training\nprediction models, our learned traffic policy leads to considerably improved\ndownstream prediction metrics compared to baseline traffic agents. For more\ninformation, visit the project website: https://waabi.ai/rtr",
            "author": [
                "Chris Zhang",
                "James Tu",
                "Lunjun Zhang",
                "Kelvin Wong",
                "Simon Suo",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01394v1",
                "http://arxiv.org/pdf/2311.01394v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01388v1",
            "title": "Time-series Generation by Contrastive Imitation",
            "updated": "2023-11-02T16:45:25Z",
            "published": "2023-11-02T16:45:25Z",
            "summary": "Consider learning a generative model for time-series data. The sequential\nsetting poses a unique challenge: Not only should the generator capture the\nconditional dynamics of (stepwise) transitions, but its open-loop rollouts\nshould also preserve the joint distribution of (multi-step) trajectories. On\none hand, autoregressive models trained by MLE allow learning and computing\nexplicit transition distributions, but suffer from compounding error during\nrollouts. On the other hand, adversarial models based on GAN training alleviate\nsuch exposure bias, but transitions are implicit and hard to assess. In this\nwork, we study a generative framework that seeks to combine the strengths of\nboth: Motivated by a moment-matching objective to mitigate compounding error,\nwe optimize a local (but forward-looking) transition policy, where the\nreinforcement signal is provided by a global (but stepwise-decomposable) energy\nmodel trained by contrastive estimation. At training, the two components are\nlearned cooperatively, avoiding the instabilities typical of adversarial\nobjectives. At inference, the learned policy serves as the generator for\niterative sampling, and the learned energy serves as a trajectory-level measure\nfor evaluating sample quality. By expressly training a policy to imitate\nsequential behavior of time-series features in a dataset, this approach\nembodies \"generation by imitation\". Theoretically, we illustrate the\ncorrectness of this formulation and the consistency of the algorithm.\nEmpirically, we evaluate its ability to generate predictively useful samples\nfrom real-world datasets, verifying that it performs at the standard of\nexisting benchmarks.",
            "author": [
                "Daniel Jarrett",
                "Ioana Bica",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01388v1",
                "http://arxiv.org/pdf/2311.01388v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01386v1",
            "title": "Can Language Models Be Tricked by Language Illusions? Easier with\n  Syntax, Harder with Semantics",
            "updated": "2023-11-02T16:44:24Z",
            "published": "2023-11-02T16:44:24Z",
            "summary": "Language models (LMs) have been argued to overlap substantially with human\nbeings in grammaticality judgment tasks. But when humans systematically make\nerrors in language processing, should we expect LMs to behave like cognitive\nmodels of language and mimic human behavior? We answer this question by\ninvestigating LMs' more subtle judgments associated with \"language illusions\"\n-- sentences that are vague in meaning, implausible, or ungrammatical but\nreceive unexpectedly high acceptability judgments by humans. We looked at three\nillusions: the comparative illusion (e.g. \"More people have been to Russia than\nI have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be\nignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who\nno villager believed to be trustworthy will ever shoot a bear\"). We found that\nprobabilities represented by LMs were more likely to align with human judgments\nof being \"tricked\" by the NPI illusion which examines a structural dependency,\ncompared to the comparative and the depth-charge illusions which require\nsophisticated semantic understanding. No single LM or metric yielded results\nthat are entirely consistent with human behavior. Ultimately, we show that LMs\nare limited both in their construal as cognitive models of human language\nprocessing and in their capacity to recognize nuanced but critical information\nin complicated language materials.",
            "author": [
                "Yuhan Zhang",
                "Edward Gibson",
                "Forrest Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01386v1",
                "http://arxiv.org/pdf/2311.01386v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01385v1",
            "title": "Ultra-Fast Generation of Air Shower Images for Imaging Air Cherenkov\n  Telescopes using Generative Adversarial Networks",
            "updated": "2023-11-02T16:44:01Z",
            "published": "2023-11-02T16:44:01Z",
            "summary": "For the analysis of data taken by Imaging Air Cherenkov Telescopes (IACTs), a\nlarge number of air shower simulations are needed to derive the instrument\nresponse. The simulations are very complex, involving computational and\nmemory-intensive calculations, and are usually performed repeatedly for\ndifferent observation intervals to take into account the varying optical\nsensitivity of the instrument. The use of generative models based on deep\nneural networks offers the prospect for memory-efficient storing of huge\nsimulation libraries and cost-effective generation of a large number of\nsimulations in an extremely short time. In this work, we use Wasserstein\nGenerative Adversarial Networks to generate photon showers for an IACT equipped\nwith the FlashCam design, which has more than $1{,}500$ pixels. Using\nsimulations of the H.E.S.S. experiment, we demonstrate the successful\ngeneration of high-quality IACT images. The analysis includes a comprehensive\nstudy of the generated image quality based on low-level observables and the\nwell-known Hillas parameters that describe the shower shape. We demonstrate for\nthe first time that the generated images have high fidelity with respect to\nlow-level observables, the Hillas parameters, their physical properties, as\nwell as their correlations. The found increase in generation speed in the order\nof $10^5$ yields promising prospects for fast and memory-efficient simulations\nof air showers for IACTs.",
            "author": [
                "Christian Elflein",
                "Stefan Funk",
                "Jonas Glombitza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01385v1",
                "http://arxiv.org/pdf/2311.01385v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01380v1",
            "title": "Sim2Real Bilevel Adaptation for Object Surface Classification using\n  Vision-Based Tactile Sensors",
            "updated": "2023-11-02T16:37:27Z",
            "published": "2023-11-02T16:37:27Z",
            "summary": "In this paper, we address the Sim2Real gap in the field of vision-based\ntactile sensors for classifying object surfaces. We train a Diffusion Model to\nbridge this gap using a relatively small dataset of real-world images randomly\ncollected from unlabeled everyday objects via the DIGIT sensor. Subsequently,\nwe employ a simulator to generate images by uniformly sampling the surface of\nobjects from the YCB Model Set. These simulated images are then translated into\nthe real domain using the Diffusion Model and automatically labeled to train a\nclassifier. During this training, we further align features of the two domains\nusing an adversarial procedure. Our evaluation is conducted on a dataset of\ntactile images obtained from a set of ten 3D printed YCB objects. The results\nreveal a total accuracy of 81.9%, a significant improvement compared to the\n34.7% achieved by the classifier trained solely on simulated images. This\ndemonstrates the effectiveness of our approach. We further validate our\napproach using the classifier on a 6D object pose estimation task from tactile\ndata.",
            "author": [
                "Gabriele M. Caddeo",
                "Andrea Maracani",
                "Paolo D. Alfano",
                "Nicola A. Piga",
                "Lorenzo Rosasco",
                "Lorenzo Natale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01380v1",
                "http://arxiv.org/pdf/2311.01380v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01379v1",
            "title": "Collaborative Decision-Making and the k-Strong Price of Anarchy in\n  Common Interest Games",
            "updated": "2023-11-02T16:36:40Z",
            "published": "2023-11-02T16:36:40Z",
            "summary": "The control of large-scale, multi-agent systems often entails distributing\ndecision-making across the system components. However, with advances in\ncommunication and computation technologies, we can consider new collaborative\ndecision-making paradigms that exist somewhere between centralized and\ndistributed control. In this work, we seek to understand the benefits and costs\nof increased collaborative communication in multi-agent systems. We\nspecifically study this in the context of common interest games in which groups\nof up to k agents can coordinate their actions in maximizing the common\nobjective function. The equilibria that emerge in these systems are the\nk-strong Nash equilibria of the common interest game; studying the properties\nof these states can provide relevant insights into the efficacy of inter-agent\ncollaboration. Our contributions come threefold: 1) provide bounds on how well\nk-strong Nash equilibria approximate the optimal system welfare, formalized by\nthe k-strong price of anarchy, 2) study the run-time and transient performance\nof collaborative agent-based dynamics, and 3) consider the task of redesigning\nobjectives for groups of agents which improve system performance. We study\nthese three facets generally as well as in the context of resource allocation\nproblems, in which we provide tractable linear programs that give tight bounds\non the k-strong price of anarchy.",
            "author": [
                "Bryce L. Ferguson",
                "Dario Paccagnan",
                "Bary S. R. Pradelski",
                "Jason R. Marden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01379v1",
                "http://arxiv.org/pdf/2311.01379v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01378v2",
            "title": "Vision-Language Foundation Models as Effective Robot Imitators",
            "updated": "2023-11-06T07:40:27Z",
            "published": "2023-11-02T16:34:33Z",
            "summary": "Recent progress in vision language foundation models has shown their ability\nto understand multimodal data and resolve complicated vision language tasks,\nincluding robotics manipulation. We seek a straightforward way of making use of\nexisting vision-language models (VLMs) with simple fine-tuning on robotics\ndata. To this end, we derive a simple and novel vision-language manipulation\nframework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.\nUnlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step\nvision-language comprehension, models sequential history information with an\nexplicit policy head, and is slightly fine-tuned by imitation learning only on\nlanguage-conditioned manipulation datasets. Such a decomposition provides\nRoboFlamingo the flexibility for open-loop control and deployment on\nlow-performance platforms. By exceeding the state-of-the-art performance with a\nlarge margin on the tested benchmark, we show RoboFlamingo can be an effective\nand competitive alternative to adapt VLMs to robot control. Our extensive\nexperimental results also reveal several interesting conclusions regarding the\nbehavior of different pre-trained VLMs on manipulation tasks. We believe\nRoboFlamingo has the potential to be a cost-effective and easy-to-use solution\nfor robotics manipulation, empowering everyone with the ability to fine-tune\ntheir own robotics policy.",
            "author": [
                "Xinghang Li",
                "Minghuan Liu",
                "Hanbo Zhang",
                "Cunjun Yu",
                "Jie Xu",
                "Hongtao Wu",
                "Chilam Cheang",
                "Ya Jing",
                "Weinan Zhang",
                "Huaping Liu",
                "Hang Li",
                "Tao Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01378v2",
                "http://arxiv.org/pdf/2311.01378v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01373v1",
            "title": "Recognize Any Regions",
            "updated": "2023-11-02T16:31:49Z",
            "published": "2023-11-02T16:31:49Z",
            "summary": "Understanding the semantics of individual regions or patches within\nunconstrained images, such as in open-world object detection, represents a\ncritical yet challenging task in computer vision. Building on the success of\npowerful image-level vision-language (ViL) foundation models like CLIP, recent\nefforts have sought to harness their capabilities by either training a\ncontrastive model from scratch with an extensive collection of region-label\npairs or aligning the outputs of a detection model with image-level\nrepresentations of region proposals. Despite notable progress, these approaches\nare plagued by computationally intensive training requirements, susceptibility\nto data noise, and deficiency in contextual information. To address these\nlimitations, we explore the synergistic potential of off-the-shelf foundation\nmodels, leveraging their respective strengths in localization and semantics. We\nintroduce a novel, generic, and efficient region recognition architecture,\nnamed RegionSpot, designed to integrate position-aware localization knowledge\nfrom a localization foundation model (e.g., SAM) with semantic information\nextracted from a ViL model (e.g., CLIP). To fully exploit pretrained knowledge\nwhile minimizing training overhead, we keep both foundation models frozen,\nfocusing optimization efforts solely on a lightweight attention-based knowledge\nintegration module. Through extensive experiments in the context of open-world\nobject recognition, our RegionSpot demonstrates significant performance\nimprovements over prior alternatives, while also providing substantial\ncomputational savings. For instance, training our model with 3 million data in\na single day using 8 V100 GPUs. Our model outperforms GLIP by 6.5 % in mean\naverage precision (mAP), with an even larger margin by 14.8 % for more\nchallenging and rare categories.",
            "author": [
                "Haosen Yang",
                "Chuofan Ma",
                "Bin Wen",
                "Yi Jiang",
                "Zehuan Yuan",
                "Xiatian Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01373v1",
                "http://arxiv.org/pdf/2311.01373v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01372v2",
            "title": "Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese\n  Media Bias Detection",
            "updated": "2023-11-18T09:45:01Z",
            "published": "2023-11-02T16:29:49Z",
            "summary": "With the increasing pursuit of objective reports, automatically understanding\nmedia bias has drawn more attention in recent research. However, most of the\nprevious work examines media bias from Western ideology, such as the left and\nright in the political spectrum, which is not applicable to Chinese outlets.\nBased on the previous lexical bias and informational bias structure, we refine\nit from the Chinese perspective and go one step further to craft data with 7\nfine-grained labels. To be specific, we first construct a dataset with Chinese\nnews reports about COVID-19 which is annotated by our newly designed system,\nand then conduct substantial experiments on it to detect media bias. However,\nthe scale of the annotated data is not enough for the latest deep-learning\ntechnology, and the cost of human annotation in media bias, which needs a lot\nof professional knowledge, is too expensive. Thus, we explore some context\nenrichment methods to automatically improve these problems. In Data-Augmented\nContext Enrichment (DACE), we enlarge the training data; while in\nRetrieval-Augmented Context Enrichment (RACE), we improve information retrieval\nmethods to select valuable information and integrate it into our models to\nbetter understand bias. Extensive experiments are conducted on both our dataset\nand an English dataset BASIL. Our results show that both methods outperform our\nbaselines, while the RACE methods are more efficient and have more potential.",
            "author": [
                "Luyang Lin",
                "Jing Li",
                "Kam-Fai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01372v2",
                "http://arxiv.org/pdf/2311.01372v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01363v1",
            "title": "Variational Methods for Computing Non-Local Quantum Strategies",
            "updated": "2023-11-02T16:17:18Z",
            "published": "2023-11-02T16:17:18Z",
            "summary": "In a nonlocal game, two noncommunicating players cooperate to convince a\nreferee that they possess a strategy that does not violate the rules of the\ngame. Quantum strategies enable players to optimally win some games by\nperforming joint measurements on a shared entangled state, but computing these\nstrategies can be challenging. We develop a variational algorithm for computing\nstrategies of nonlocal games and show that it can yield optimal strategies for\nsmall examples of both convex and non-convex games. We show that our algorithm\nreturns an optimal quantum strategy for a graph coloring game; whereas no\noptimal quantum strategy was previously known for this problem. Moreover, we\ndescribe how this technique can be run on quantum computers to discover\nshallow-depth circuits that yield optimal quantum strategies. We argue that\nsuch circuits will be useful for benchmarking quantum computers because of the\nability to verify the solutions at scale and the experiment's sensitivity to\n2-qubit gate noise. Finally, we demonstrate the use of nonlocal games as a\nbenchmarking strategy experimentally on 11 IBM quantum computers.",
            "author": [
                "Jim Furches",
                "Nathan Wiebe",
                "Carlos Ortiz Marrero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01363v1",
                "http://arxiv.org/pdf/2311.01363v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01362v1",
            "title": "Handbook for Efficiently Quantifying Robustness of Magic",
            "updated": "2023-11-02T16:15:00Z",
            "published": "2023-11-02T16:15:00Z",
            "summary": "The nonstabilizerness, or magic, is an essential quantum resource to perform\nuniversal quantum computation. Robustness of magic (RoM) in particular\ncharacterizes the degree of usefulness of a given quantum state for\nnon-Clifford operation. While the mathematical formalism of RoM can be given in\na concise manner, it is extremely challenging to determine the RoM in practice,\nsince it involves superexponentially many pure stabilizer states. In this work,\nwe present efficient novel algorithms to compute the RoM. The crucial technique\nis a subroutine that achieves the remarkable features in calculation of\noverlaps between pure stabilizer states: (i) the time complexity per each\nstabilizer is reduced exponentially, (ii) the space complexity is reduced\nsuperexponentially. Based on this subroutine, we present algorithms to compute\nthe RoM for arbitrary states up to $n=7$ qubits on a laptop, while brute-force\nmethods require a memory size of 86 TiB. As a byproduct, the proposed\nsubroutine allows us to simulate the stabilizer fidelity up to $n=8$ qubits,\nfor which naive methods require memory size of 86 PiB so that any\nstate-of-the-art classical computer cannot execute the computation. We further\npropose novel algorithms that utilize the preknowledge on the structure of\ntarget quantum state such as the permutation symmetry of disentanglement, and\nnumerically demonstrate our state-of-the-art results for copies of magic states\nand partially disentangled quantum states. The series of algorithms constitute\na comprehensive ``handbook'' to scale up the computation of the RoM, and we\nenvision that the proposed technique applies to the computation of other\nquantum resource measures as well.",
            "author": [
                "Hiroki Hamaguchi",
                "Kou Hamada",
                "Nobuyuki Yoshioka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01362v1",
                "http://arxiv.org/pdf/2311.01362v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04228v1",
            "title": "Graph Neural Networks for Topological Feature Extraction in ECG\n  Classification",
            "updated": "2023-11-02T16:14:34Z",
            "published": "2023-11-02T16:14:34Z",
            "summary": "The electrocardiogram (ECG) is a dependable instrument for assessing the\nfunction of the cardiovascular system. There has recently been much emphasis on\nprecisely classifying ECGs. While ECG situations have numerous similarities,\nlittle attention has been paid to categorizing ECGs using graph neural\nnetworks. In this study, we offer three distinct techniques for classifying\nheartbeats using deep graph neural networks to classify the ECG signals\naccurately. We suggest using different methods to extract topological features\nfrom the ECG signal and then using a branch of the graph neural network named\ngraph isomorphism network for classifying the ECGs. On the PTB Diagnostics data\nset, we tested the three proposed techniques. According to the findings, the\nthree proposed techniques are capable of making arrhythmia classification\npredictions with the accuracy of 99.38, 98.76, and 91.93 percent, respectively.",
            "author": [
                "Kamyar Zeinalipour",
                "Marco Gori"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-3592-5_2",
                "http://arxiv.org/abs/2311.04228v1",
                "http://arxiv.org/pdf/2311.04228v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01361v1",
            "title": "GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks",
            "updated": "2023-11-02T16:11:09Z",
            "published": "2023-11-02T16:11:09Z",
            "summary": "Automatically evaluating vision-language tasks is challenging, especially\nwhen it comes to reflecting human judgments due to limitations in accounting\nfor fine-grained details. Although GPT-4V has shown promising results in\nvarious multi-modal tasks, leveraging GPT-4V as a generalist evaluator for\nthese tasks has not yet been systematically explored. We comprehensively\nvalidate GPT-4V's capabilities for evaluation purposes, addressing tasks\nranging from foundational image-to-text and text-to-image synthesis to\nhigh-level image-to-image translations and multi-images to text alignment. We\nemploy two evaluation methods, single-answer grading and pairwise comparison,\nusing GPT-4V. Notably, GPT-4V shows promising agreement with humans across\nvarious tasks and evaluation methods, demonstrating immense potential for\nmulti-modal LLMs as evaluators. Despite limitations like restricted visual\nclarity grading and real-world complex reasoning, its ability to provide\nhuman-aligned scores enriched with detailed explanations is promising for\nuniversal automatic evaluator.",
            "author": [
                "Xinlu Zhang",
                "Yujie Lu",
                "Weizhi Wang",
                "An Yan",
                "Jun Yan",
                "Lianke Qin",
                "Heng Wang",
                "Xifeng Yan",
                "William Yang Wang",
                "Linda Ruth Petzold"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01361v1",
                "http://arxiv.org/pdf/2311.01361v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01360v1",
            "title": "Minimum-dissipation model for large-eddy simulation using\n  symmetry-preserving discretization in OpenFOAM",
            "updated": "2023-11-02T16:10:18Z",
            "published": "2023-11-02T16:10:18Z",
            "summary": "The minimum-dissipation model is applied to channel flow up to $Re_\\tau =\n2000$, flow past a circular cylinder at $Re=3900$, and flow over periodic hills\nat $Re=10595$. Numerical simulations were performed in OpenFOAM which is based\non the finite volume methods. We used both symmetry-preserving and standard\nsecond-order accurate discretization methods in OpenFOAM on structured meshes.\nThe results are compared to DNS and experimental data.\n  The results of channel flow demonstrate a static QR model performs equally\nwell as the dynamic models while reducing the computational cost. The model\nconstant of $C=0.024$ gives the most accurate prediction, and the contribution\nof the sub-grid model decreases with the increase of the mesh resolution and\nbecomes very small (less than 0.2 molecular viscosity) if a fine mesh is used.\nFurthermore, the QR model is able to predict the mean and rms velocity\naccurately up to $Re_\\tau = 2000$ without a wall damping function. The\nsymmetry-preserving discretization outperforms the standard OpenFOAM\ndiscretization at $Re_\\tau=1000$. The results for the flow over a cylinder show\nthat the mean velocity, drag coefficient, and lift coefficient are in good\nagreement with the experimental data and the central difference schemes\nconjugated with the QR model predict better results. The various comparisons\ncarried out for flows over periodic hills demonstrate the need to use central\ndifference schemes in OpenFOAM in combination with the minimum dissipation\nmodel. The best model constant is again $C=0.024$. The single wind turbine\nsimulation shows that the QR model is capable of predicting accurate results in\ncomplex rotating scenarios.",
            "author": [
                "J Sun",
                "R. W. C. P Verstappen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01360v1",
                "http://arxiv.org/pdf/2311.01360v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01357v1",
            "title": "Robust Identity Perceptual Watermark Against Deepfake Face Swapping",
            "updated": "2023-11-02T16:04:32Z",
            "published": "2023-11-02T16:04:32Z",
            "summary": "Notwithstanding offering convenience and entertainment to society, Deepfake\nface swapping has caused critical privacy issues with the rapid development of\ndeep generative models. Due to imperceptible artifacts in high-quality\nsynthetic images, passive detection models against face swapping in recent\nyears usually suffer performance damping regarding the generalizability issue.\nTherefore, several studies have been attempted to proactively protect the\noriginal images against malicious manipulations by inserting invisible signals\nin advance. However, the existing proactive defense approaches demonstrate\nunsatisfactory results with respect to visual quality, detection accuracy, and\nsource tracing ability. In this study, we propose the first robust identity\nperceptual watermarking framework that concurrently performs detection and\nsource tracing against Deepfake face swapping proactively. We assign identity\nsemantics regarding the image contents to the watermarks and devise an\nunpredictable and unreversible chaotic encryption system to ensure watermark\nconfidentiality. The watermarks are encoded and recovered by jointly training\nan encoder-decoder framework along with adversarial image manipulations.\nExtensive experiments demonstrate state-of-the-art performance against Deepfake\nface swapping under both cross-dataset and cross-manipulation settings.",
            "author": [
                "Tianyi Wang",
                "Mengxiao Huang",
                "Harry Cheng",
                "Bin Ma",
                "Yinglong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01357v1",
                "http://arxiv.org/pdf/2311.01357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01355v1",
            "title": "Physically constrained eigenspace perturbation for turbulence model\n  uncertainty estimation",
            "updated": "2023-11-02T16:02:42Z",
            "published": "2023-11-02T16:02:42Z",
            "summary": "Aerospace design is increasingly incorporating Design Under Uncertainty based\napproaches to lead to more robust and reliable optimal designs. These\napproaches require dependable estimates of uncertainty in simulations for their\nsuccess. The key contributor of predictive uncertainty in Computational Fluid\nDynamics (CFD) simulations of turbulent flows are the structural limitations of\nReynolds-averaged Navier-Stokes models, termed model-form uncertainty.\nCurrently, the common procedure to estimate turbulence model-form uncertainty\nis the Eigenspace Perturbation Framework (EPF), involving perturbations to the\nmodeled Reynolds Stress tensor within physical limits. The EPF has been applied\nwith success in design and analysis tasks in numerous prior works from the\nindustry and academia. Owing to its rapid success and adoption in several\ncommercial and open-source CFD solvers, in depth Verification and Validation of\nthe EPF is critical. In this work, we show that under certain conditions, the\nperturbations in the EPF can lead to Reynolds stress dynamics that are not\nphysically realizable. This analysis enables us to propose a set of necessary\nphysics-based constraints, leading to a realizable EPF. We apply this\nconstrained procedure to the illustrative test case of a converging-diverging\nchannel, and we demonstrate that these constraints limit physically implausible\ndynamics of the Reynolds stress tensor, while enhancing the accuracy and\nstability of the uncertainty estimation procedure.",
            "author": [
                "Marcel Matha",
                "Christian Morsbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01355v1",
                "http://arxiv.org/pdf/2311.01355v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01353v1",
            "title": "libepa -- a C++/Python library for calculations of cross sections of\n  ultraperipheral collisions",
            "updated": "2023-11-02T16:01:15Z",
            "published": "2023-11-02T16:01:15Z",
            "summary": "The library provides a set of C++/Python functions for computing cross\nsections of ultraperipheral collisions of high energy particles under the\nequivalent photons approximation. Cross sections are represented through\nmultiple integrals over the phase space. The integrals are calculated through\nrecurrent application of algorithms for one dimensional integration. The paper\ncontains an introduction to the theory of ultraperipheral collisions, discusses\nthe library approach and provides a few examples of calculations.",
            "author": [
                "E. V. Zhemchugov",
                "S. I. Godunov",
                "E. K. Karkaryan",
                "V. A. Novikov",
                "A. N. Rozanov",
                "M. I. Vysotsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01353v1",
                "http://arxiv.org/pdf/2311.01353v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01352v1",
            "title": "Deep learning based Image Compression for Microscopy Images: An\n  Empirical Study",
            "updated": "2023-11-02T16:00:32Z",
            "published": "2023-11-02T16:00:32Z",
            "summary": "With the fast development of modern microscopes and bioimaging techniques, an\nunprecedentedly large amount of imaging data are being generated, stored,\nanalyzed, and even shared through networks. The size of the data poses great\nchallenges for current data infrastructure. One common way to reduce the data\nsize is by image compression. This present study analyzes classic and deep\nlearning based image compression methods, and their impact on deep learning\nbased image processing models. Deep learning based label-free prediction models\n(i.e., predicting fluorescent images from bright field images) are used as an\nexample application for comparison and analysis. Effective image compression\nmethods could help reduce the data size significantly without losing necessary\ninformation, and therefore reduce the burden on data management infrastructure\nand permit fast transmission through the network for data sharing or cloud\ncomputing. To compress images in such a wanted way, multiple classical lossy\nimage compression techniques are compared to several AI-based compression\nmodels provided by and trained with the CompressAI toolbox using python. These\ndifferent compression techniques are compared in compression ratio, multiple\nimage similarity measures and, most importantly, the prediction accuracy from\nlabel-free models on compressed images. We found that AI-based compression\ntechniques largely outperform the classic ones and will minimally affect the\ndownstream label-free task in 2D cases. In the end, we hope the present study\ncould shed light on the potential of deep learning based image compression and\nthe impact of image compression on downstream deep learning based image\nanalysis models.",
            "author": [
                "Yu Zhou",
                "Jan Sollman",
                "Jianxu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01352v1",
                "http://arxiv.org/pdf/2311.01352v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01351v3",
            "title": "Simplicial Models for the Epistemic Logic of Faulty Agents",
            "updated": "2023-11-14T11:23:59Z",
            "published": "2023-11-02T16:00:28Z",
            "summary": "In recent years, several authors have been investigating simplicial models, a\nmodel of epistemic logic based on higher-dimensional structures called\nsimplicial complexes. In the original formulation, simplicial models were\nalways assumed to be pure, meaning that all worlds have the same dimension.\nThis is equivalent to the standard S5n semantics of epistemic logic, based on\nKripke models. By removing the assumption that models must be pure, we can go\nbeyond the usual Kripke semantics and study epistemic logics where the number\nof agents participating in a world can vary. This approach has been developed\nin a number of papers, with applications in fault-tolerant distributed\ncomputing where processes may crash during the execution of a system. A\ndifficulty that arises is that subtle design choices in the definition of\nimpure simplicial models can result in different axioms of the resulting logic.\nIn this paper, we classify those design choices systematically, and axiomatize\nthe corresponding logics. We illustrate them via distributed computing examples\nof synchronous systems where processes may crash.",
            "author": [
                "Eric Goubault",
                "Roman Kniazev",
                "Jeremy Ledent",
                "Sergio Rajsbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01351v3",
                "http://arxiv.org/pdf/2311.01351v3"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.DC",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01349v1",
            "title": "Unreading Race: Purging Protected Features from Chest X-ray Embeddings",
            "updated": "2023-11-02T15:59:00Z",
            "published": "2023-11-02T15:59:00Z",
            "summary": "Purpose: To analyze and remove protected feature effects in chest radiograph\nembeddings of deep learning models.\n  Materials and Methods: An orthogonalization is utilized to remove the\ninfluence of protected features (e.g., age, sex, race) in chest radiograph\nembeddings, ensuring feature-independent results. To validate the efficacy of\nthe approach, we retrospectively study the MIMIC and CheXpert datasets using\nthree pre-trained models, namely a supervised contrastive, a self-supervised\ncontrastive, and a baseline classifier model. Our statistical analysis involves\ncomparing the original versus the orthogonalized embeddings by estimating\nprotected feature influences and evaluating the ability to predict race, age,\nor sex using the two types of embeddings.\n  Results: Our experiments reveal a significant influence of protected features\non predictions of pathologies. Applying orthogonalization removes these feature\neffects. Apart from removing any influence on pathology classification, while\nmaintaining competitive predictive performance, orthogonalized embeddings\nfurther make it infeasible to directly predict protected attributes and\nmitigate subgroup disparities.\n  Conclusion: The presented work demonstrates the successful application and\nevaluation of the orthogonalization technique in the domain of chest X-ray\nclassification.",
            "author": [
                "Tobias Weber",
                "Michael Ingrisch",
                "Bernd Bischl",
                "David R\u00fcgamer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01349v1",
                "http://arxiv.org/pdf/2311.01349v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01346v1",
            "title": "On the Proportion of Coprime Fractions in Number Fields",
            "updated": "2023-11-02T15:56:44Z",
            "published": "2023-11-02T15:56:44Z",
            "summary": "In this paper we determine the asymptotic density of coprime fractions in\nthose of the reduced fractions of number fields. When ordered by norms of\ndenominators, we count a fraction as soon as it ``appears'' for the first time\nand no later. The natural density of coprime fractions in the set of reduced\nfractions may then be computed using well-known facts about Hecke\n$L$-functions. Furthermore, we draw some connections to the modular group and\nHeegner points.",
            "author": [
                "Walter Bridges",
                "Johann Franke",
                "Johann Christian Stumpenhusen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01346v1",
                "http://arxiv.org/pdf/2311.01346v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "11R45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01344v1",
            "title": "Like an Open Book? Read Neural Network Architecture with Simple Power\n  Analysis on 32-bit Microcontrollers",
            "updated": "2023-11-02T15:55:20Z",
            "published": "2023-11-02T15:55:20Z",
            "summary": "Model extraction is a growing concern for the security of AI systems. For\ndeep neural network models, the architecture is the most important information\nan adversary aims to recover. Being a sequence of repeated computation blocks,\nneural network models deployed on edge-devices will generate distinctive\nside-channel leakages. The latter can be exploited to extract critical\ninformation when targeted platforms are physically accessible. By combining\ntheoretical knowledge about deep learning practices and analysis of a\nwidespread implementation library (ARM CMSIS-NN), our purpose is to answer this\ncritical question: how far can we extract architecture information by simply\nexamining an EM side-channel trace? For the first time, we propose an\nextraction methodology for traditional MLP and CNN models running on a high-end\n32-bit microcontroller (Cortex-M7) that relies only on simple pattern\nrecognition analysis. Despite few challenging cases, we claim that, contrary to\nparameters extraction, the complexity of the attack is relatively low and we\nhighlight the urgent need for practicable protections that could fit the strong\nmemory and latency requirements of such platforms.",
            "author": [
                "Raphael Joud",
                "Pierre-Alain Moellic",
                "Simon Pontie",
                "Jean-Baptiste Rigaud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01344v1",
                "http://arxiv.org/pdf/2311.01344v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01338v1",
            "title": "Securing Wireless Communication in Critical Infrastructure: Challenges\n  and Opportunities",
            "updated": "2023-11-02T15:48:05Z",
            "published": "2023-11-02T15:48:05Z",
            "summary": "Critical infrastructure constitutes the foundation of every society. While\ntraditionally solely relying on dedicated cable-based communication, this\ninfrastructure rapidly transforms to highly digitized and interconnected\nsystems which increasingly rely on wireless communication. Besides providing\ntremendous benefits, especially affording the easy, cheap, and flexible\ninterconnection of a large number of assets spread over larger geographic\nareas, wireless communication in critical infrastructure also raises unique\nsecurity challenges. Most importantly, the shift from dedicated private wired\nnetworks to heterogeneous wireless communication over public and shared\nnetworks requires significantly more involved security measures. In this paper,\nwe identify the most relevant challenges resulting from the use of wireless\ncommunication in critical infrastructure and use those to identify a\ncomprehensive set of promising opportunities to preserve the high security\nstandards of critical infrastructure even when switching from wired to wireless\ncommunication.",
            "author": [
                "J\u00f6rn Bodenhausen",
                "Christian Sorgatz",
                "Thomas Vogt",
                "Kolja Grafflage",
                "Sebastian R\u00f6tzel",
                "Michael Rademacher",
                "Martin Henze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01338v1",
                "http://arxiv.org/pdf/2311.01338v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01335v2",
            "title": "Automatic Robot Hand-Eye Calibration Enabled by Learning-Based 3D Vision",
            "updated": "2023-11-27T14:19:34Z",
            "published": "2023-11-02T15:45:09Z",
            "summary": "Hand-eye calibration, as a fundamental task in vision-based robotic systems,\naims to estimate the transformation matrix between the coordinate frame of the\ncamera and the robot flange. Most approaches to hand-eye calibration rely on\nexternal markers or human assistance. We proposed Look at Robot Base Once\n(LRBO), a novel methodology that addresses the hand-eye calibration problem\nwithout external calibration objects or human support, but with the robot base.\nUsing point clouds of the robot base, a transformation matrix from the\ncoordinate frame of the camera to the robot base is established as I=AXB. To\nthis end, we exploit learning-based 3D detection and registration algorithms to\nestimate the location and orientation of the robot base. The robustness and\naccuracy of the method are quantified by ground-truth-based evaluation, and the\naccuracy result is compared with other 3D vision-based calibration methods. To\nassess the feasibility of our methodology, we carried out experiments utilizing\na low-cost structured light scanner across varying joint configurations and\ngroups of experiments. The proposed hand-eye calibration method achieved a\ntranslation deviation of 0.930 mm and a rotation deviation of 0.265 degrees\naccording to the experimental results. Additionally, the 3D reconstruction\nexperiments demonstrated a rotation error of 0.994 degrees and a position error\nof 1.697 mm. Moreover, our method offers the potential to be completed in 1\nsecond, which is the fastest compared to other 3D hand-eye calibration methods.\nCode is released at github.com/leihui6/LRBO.",
            "author": [
                "Leihui Li",
                "Xingyu Yang",
                "Riwei Wang",
                "Xuping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01335v2",
                "http://arxiv.org/pdf/2311.01335v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01332v1",
            "title": "Fast ZZ-Free Entangling Gates for Superconducting Qubits Assisted by a\n  Driven Resonator",
            "updated": "2023-11-02T15:42:02Z",
            "published": "2023-11-02T15:42:02Z",
            "summary": "Engineering high-fidelity two-qubit gates is an indispensable step toward\npractical quantum computing. For superconducting quantum platforms, one\nimportant setback is the stray interaction between qubits, which causes\nsignificant coherent errors. For transmon qubits, protocols for mitigating such\nerrors usually involve fine-tuning the hardware parameters or introducing\nusually noisy flux-tunable couplers. In this work, we propose a simple scheme\nto cancel these stray interactions. The coupler used for such cancellation is a\ndriven high-coherence resonator, where the amplitude and frequency of the drive\nserve as control knobs. Through the resonator-induced-phase (RIP) interaction,\nthe static ZZ coupling can be entirely neutralized. We numerically show that\nsuch a scheme can enable short and high-fidelity entangling gates, including\ncross-resonance CNOT gates within 40 ns and adiabatic CZ gates within 140 ns.\nOur architecture is not only ZZ free but also contains no extra noisy\ncomponents, such that it preserves the coherence times of fixed-frequency\ntransmon qubits. With the state-of-the-art coherence times, the error of our\ncross-resonance CNOT gate can be reduced to below 1e-4.",
            "author": [
                "Ziwen Huang",
                "Taeyoon Kim",
                "Tanay Roy",
                "Yao Lu",
                "Alexander Romanenko",
                "Shaojiang Zhu",
                "Anna Grassellino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01332v1",
                "http://arxiv.org/pdf/2311.01332v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01328v1",
            "title": "Analog information decoding of bosonic quantum LDPC codes",
            "updated": "2023-11-02T15:41:03Z",
            "published": "2023-11-02T15:41:03Z",
            "summary": "Quantum error correction is crucial for scalable quantum information\nprocessing applications. Traditional discrete-variable quantum codes that use\nmultiple two-level systems to encode logical information can be\nhardware-intensive. An alternative approach is provided by bosonic codes, which\nuse the infinite-dimensional Hilbert space of harmonic oscillators to encode\nquantum information. Two promising features of bosonic codes are that syndrome\nmeasurements are natively analog and that they can be concatenated with\ndiscrete-variable codes. In this work, we propose novel decoding methods that\nexplicitly exploit the analog syndrome information obtained from the bosonic\nqubit readout in a concatenated architecture. Our methods are versatile and can\nbe generally applied to any bosonic code concatenated with a quantum\nlow-density parity-check (QLDPC) code. Furthermore, we introduce the concept of\nquasi-single-shot protocols as a novel approach that significantly reduces the\nnumber of repeated syndrome measurements required when decoding under\nphenomenological noise. To realize the protocol, we present a first\nimplementation of time-domain decoding with the overlapping window method for\ngeneral QLDPC codes, and a novel analog single-shot decoding method. Our\nresults lay the foundation for general decoding algorithms using analog\ninformation and demonstrate promising results in the direction of\nfault-tolerant quantum computation with concatenated bosonic-QLDPC codes.",
            "author": [
                "Lucas Berent",
                "Timo Hillmann",
                "Jens Eisert",
                "Robert Wille",
                "Joschka Roffe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01328v1",
                "http://arxiv.org/pdf/2311.01328v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14683v1",
            "title": "Data Science for Social Good",
            "updated": "2023-11-02T15:40:20Z",
            "published": "2023-11-02T15:40:20Z",
            "summary": "Data science has been described as the fourth paradigm for scientific\ndiscovery. The latest wave of data science research, pertaining to machine\nlearning and artificial intelligence (AI), is growing exponentially and\ngarnering millions of annual citations. However, this growth has been\naccompanied by a diminishing emphasis on social good challenges - our analysis\nreveals that the proportion of data science research focusing on social good is\nless than it has ever been. At the same time, the proliferation of machine\nlearning and generative AI have sparked debates about the socio-technical\nprospects and challenges associated with data science for human flourishing,\norganizations, and society. Against this backdrop, we present a framework for\n\"data science for social good\" (DSSG) research that considers the interplay\nbetween relevant data science research genres, social good challenges, and\ndifferent levels of socio-technical abstraction. We perform an analysis of the\nliterature to empirically demonstrate the paucity of work on DSSG in\ninformation systems (and other related disciplines) and highlight current\nimpediments. We then use our proposed framework to introduce the articles\nappearing in the special issue. We hope that this article and the special issue\nwill spur future DSSG research and help reverse the alarming trend across data\nscience research over the past 30-plus years in which social good challenges\nare garnering proportionately less attention with each passing day.",
            "author": [
                "Ahmed Abbasi",
                "Roger H. L. Chiang",
                "Jennifer J. Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14683v1",
                "http://arxiv.org/pdf/2311.14683v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01326v1",
            "title": "Better Together: Enhancing Generative Knowledge Graph Completion with\n  Language Models and Neighborhood Information",
            "updated": "2023-11-02T15:38:39Z",
            "published": "2023-11-02T15:38:39Z",
            "summary": "Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which\nlimits their potential performance. Knowledge Graph Completion (KGC) techniques\naim to address this issue. However, traditional KGC methods are computationally\nintensive and impractical for large-scale KGs, necessitating the learning of\ndense node embeddings and computing pairwise distances. Generative\ntransformer-based language models (e.g., T5 and recent KGT5) offer a promising\nsolution as they can predict the tail nodes directly. In this study, we propose\nto include node neighborhoods as additional information to improve KGC methods\nbased on language models. We examine the effects of this imputation and show\nthat, on both inductive and transductive Wikidata subsets, our method\noutperforms KGT5 and conventional KGC approaches. We also provide an extensive\nanalysis of the impact of neighborhood on model prediction and show its\nimportance. Furthermore, we point the way to significantly improve KGC through\nmore effective neighborhood selection.",
            "author": [
                "Alla Chepurova",
                "Aydar Bulatov",
                "Yuri Kuratov",
                "Mikhail Burtsev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01326v1",
                "http://arxiv.org/pdf/2311.01326v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01325v1",
            "title": "Pushdown Normal-Form Bisimulation: A Nominal Context-Free Approach to\n  Program Equivalence",
            "updated": "2023-11-02T15:37:07Z",
            "published": "2023-11-02T15:37:07Z",
            "summary": "We propose Pushdown Normal Form (PDNF) Bisimulation to verify contextual\nequivalence in higher-order functional programming languages with local state.\nSimilar to previous work on Normal Form (NF) bisimulation, PDNF Bisimulation is\nsound and complete with respect to contextual equivalence. However, unlike\ntraditional NF Bisimulation, PDNF Bisimulation is also decidable for a class of\nprogram terms that reach bounded configurations but can potentially have\nunbounded call stacks and input an unbounded number of unknown functions from\ntheir context. Our approach relies on the principle that, in model-checking for\nreachability, pushdown systems can be simulated by finite-state automata\ndesigned to accept their initial/final stack content. We embody this in a\nstackless Labelled Transition System (LTS), together with an on-the-fly\nsaturation procedure for call stacks, upon which bisimulation is defined. To\nenhance the effectiveness of our bisimulation, we develop up-to techniques and\nconfirm their soundness for PDNF Bisimulation. We develop a prototype\nimplementation of our technique which is able to verify equivalence in examples\nfrom practice and the literature that were out of reach for previous work.",
            "author": [
                "Vasileios Koutavas",
                "Yu-Yang Lin",
                "Nikos Tzevelekos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01325v1",
                "http://arxiv.org/pdf/2311.01325v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LO",
                "ACM-class: F.3.1, F.3.2, D.3.1, D.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01487v1",
            "title": "What Makes for Good Visual Instructions? Synthesizing Complex Visual\n  Reasoning Instructions for Visual Instruction Tuning",
            "updated": "2023-11-02T15:36:12Z",
            "published": "2023-11-02T15:36:12Z",
            "summary": "Visual instruction tuning is an essential approach to improving the zero-shot\ngeneralization capability of Multi-modal Large Language Models (MLLMs). A surge\nof visual instruction datasets with various focuses and characteristics have\nbeen proposed recently, enabling MLLMs to achieve surprising results on\nevaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to\ninvestigate a more fundamental question: ``what makes for good visual\ninstructions?''. By conducting a comprehensive empirical study, we find that\ninstructions focused on complex visual reasoning tasks are particularly\neffective in improving the performance of MLLMs on evaluation benchmarks.\nBuilding upon this finding, we design a systematic approach to automatically\ncreating high-quality complex visual reasoning instructions. Our approach\nemploys a synthesis-complication-reformulation paradigm, leveraging multiple\nstages to gradually increase the complexity of the instructions while\nguaranteeing quality. Based on this approach, we create the synthetic visual\nreasoning instruction dataset consisting of 32K examples, namely ComVint, and\nfine-tune four MLLMs on it. Experimental results demonstrate that our dataset\nconsistently enhances the performance of all the compared MLLMs, e.g.,\nimproving the performance of MiniGPT-4 and BLIP-2 on MME-Cognition by 32.6% and\n28.8%, respectively. Our code and data are publicly available at the link:\nhttps://github.com/RUCAIBox/ComVint.",
            "author": [
                "Yifan Du",
                "Hangyu Guo",
                "Kun Zhou",
                "Wayne Xin Zhao",
                "Jinpeng Wang",
                "Chuyuan Wang",
                "Mingchen Cai",
                "Ruihua Song",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01487v1",
                "http://arxiv.org/pdf/2311.01487v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01323v1",
            "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically,\n  and Fairly",
            "updated": "2023-11-02T15:35:58Z",
            "published": "2023-11-02T15:35:58Z",
            "summary": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great\nattention due to the security risk of applying these models in real-world\napplications. Based on transferability of adversarial examples, an increasing\nnumber of transfer-based methods have been developed to fool black-box DNN\nmodels whose architecture and parameters are inaccessible. Although tremendous\neffort has been exerted, there still lacks a standardized benchmark that could\nbe taken advantage of to compare these methods systematically, fairly, and\npractically. Our investigation shows that the evaluation of some methods needs\nto be more reasonable and more thorough to verify their effectiveness, to\navoid, for example, unfair comparison and insufficient consideration of\npossible substitute/victim models. Therefore, we establish a transfer-based\nattack benchmark (TA-Bench) which implements 30+ methods. In this paper, we\nevaluate and compare them comprehensively on 25 popular substitute/victim\nmodels on ImageNet. New insights about the effectiveness of these methods are\ngained and guidelines for future evaluations are provided. Code at:\nhttps://github.com/qizhangli/TA-Bench.",
            "author": [
                "Qizhang Li",
                "Yiwen Guo",
                "Wangmeng Zuo",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01323v1",
                "http://arxiv.org/pdf/2311.01323v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01315v2",
            "title": "Generic Model Checking for Modal Fixpoint Logics in COOL-MC",
            "updated": "2023-11-03T13:22:22Z",
            "published": "2023-11-02T15:32:24Z",
            "summary": "We report on COOL-MC, a model checking tool for fixpoint logics that is\nparametric in the branching type of models (nondeterministic, game-based,\nprobabilistic etc.) and in the next-step modalities used in formulae. The tool\nimplements generic model checking algorithms developed in coalgebraic logic\nthat are easily adapted to concrete instance logics. Apart from the standard\nmodal $\\mu$-calculus, COOL-MC currently supports alternating-time, graded,\nprobabilistic and monotone variants of the $\\mu$-calculus, but is also\neffortlessly extensible with new instance logics. The model checking process is\nrealized by polynomial reductions to parity game solving, or, alternatively, by\na local model checking algorithm that directly computes the extensions of\nformulae in a lazy fashion, thereby potentially avoiding the construction of\nthe full parity game. We evaluate COOL-MC on informative benchmark sets.",
            "author": [
                "Daniel Hausmann",
                "Merlin Humml",
                "Simon Prucker",
                "Lutz Schr\u00f6der",
                "Aaron Strahlberger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01315v2",
                "http://arxiv.org/pdf/2311.01315v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01312v1",
            "title": "Statistical Results of Multivariate Fox-H Function for Exact Performance\n  Analysis of RIS-Assisted Wireless Communication",
            "updated": "2023-11-02T15:27:37Z",
            "published": "2023-11-02T15:27:37Z",
            "summary": "Existing research provides statistical results on the sum of single-variate\nFox-H functions to analyze the performance of diversity receivers and\nreconfigurable intelligent surfaces (RIS) based wireless systems. There is a\nresearch gap in exact performance analysis when more than a single-variate\nFox-H function represents the statistical characterization of wireless systems.\nIn this paper, we propose a novel approach to obtain the distribution of the\nsum of independent and non-identically distributed (i.ni.d) random variables\ncharacterized by the multivariate Fox-H function. Further, we develop a general\nframework for an exact analysis of the ergodic capacity when the multivariate\nFox-H function characterizes the statistics of signal-to-noise ratio (SNR). We\napply the derived results to conduct an exact performance analysis of outage\nprobability and ergodic capacity, taking an example of RIS-assisted\ncommunication over Rician fading channels with phase errors. We conduct\ncomputer simulations to validate the exact analysis and demonstrate performance\nof the RIS-assisted system under various practically relevant scenarios for a\nbetter performance assessment.",
            "author": [
                "vinay kumar chapala",
                "S. M. Zafaruddin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01312v1",
                "http://arxiv.org/pdf/2311.01312v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01310v2",
            "title": "Scattering Vision Transformer: Spectral Mixing Matters",
            "updated": "2023-11-20T13:08:27Z",
            "published": "2023-11-02T15:24:23Z",
            "summary": "Vision transformers have gained significant attention and achieved\nstate-of-the-art performance in various computer vision tasks, including image\nclassification, instance segmentation, and object detection. However,\nchallenges remain in addressing attention complexity and effectively capturing\nfine-grained information within images. Existing solutions often resort to\ndown-sampling operations, such as pooling, to reduce computational cost.\nUnfortunately, such operations are non-invertible and can result in information\nloss. In this paper, we present a novel approach called Scattering Vision\nTransformer (SVT) to tackle these challenges. SVT incorporates a spectrally\nscattering network that enables the capture of intricate image details. SVT\novercomes the invertibility issue associated with down-sampling operations by\nseparating low-frequency and high-frequency components. Furthermore, SVT\nintroduces a unique spectral gating network utilizing Einstein multiplication\nfor token and channel mixing, effectively reducing complexity. We show that SVT\nachieves state-of-the-art performance on the ImageNet dataset with a\nsignificant reduction in a number of parameters and FLOPS. SVT shows 2\\%\nimprovement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy,\nwhile SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L\nreaches 85.7\\% (again state-of-art for large versions). SVT also shows\ncomparable results in other vision tasks such as instance segmentation. SVT\nalso outperforms other transformers in transfer learning on standard datasets\nsuch as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The\nproject page is available on this\nwebpage.\\url{https://badripatro.github.io/svt/}.",
            "author": [
                "Badri N. Patro",
                "Vijay Srinivas Agneeswaran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01310v2",
                "http://arxiv.org/pdf/2311.01310v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01308v1",
            "title": "Hybrid-Fusion Transformer for Multisequence MRI",
            "updated": "2023-11-02T15:22:49Z",
            "published": "2023-11-02T15:22:49Z",
            "summary": "Medical segmentation has grown exponentially through the advent of a fully\nconvolutional network (FCN), and we have now reached a turning point through\nthe success of Transformer. However, the different characteristics of the\nmodality have not been fully integrated into Transformer for medical\nsegmentation. In this work, we propose the novel hybrid fusion Transformer\n(HFTrans) for multisequence MRI image segmentation. We take advantage of the\ndifferences among multimodal MRI sequences and utilize the Transformer layers\nto integrate the features extracted from each modality as well as the features\nof the early fused modalities. We validate the effectiveness of our\nhybrid-fusion method in three-dimensional (3D) medical segmentation.\nExperiments on two public datasets, BraTS2020 and MRBrainS18, show that the\nproposed method outperforms previous state-of-the-art methods on the task of\nbrain tumor segmentation and brain structure segmentation.",
            "author": [
                "Jihoon Cho",
                "Jinah Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01308v1",
                "http://arxiv.org/pdf/2311.01308v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01307v1",
            "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual\n  Consistency of Language Models",
            "updated": "2023-11-02T15:20:11Z",
            "published": "2023-11-02T15:20:11Z",
            "summary": "Large Language Models (LLMs) make natural interfaces to factual knowledge,\nbut their usefulness is limited by their tendency to deliver inconsistent\nanswers to semantically equivalent questions. For example, a model might\npredict both \"Anne Redpath passed away in Edinburgh.\" and \"Anne Redpath's life\nended in London.\" In this work, we identify potential causes of inconsistency\nand evaluate the effectiveness of two mitigation strategies: up-scaling and\naugmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas\nmodels show that both strategies reduce inconsistency while retrieval\naugmentation is considerably more efficient. We further consider and\ndisentangle the consistency contributions of different components of Atlas. For\nall LMs evaluated we find that syntactical form and other evaluation task\nartifacts impact consistency. Taken together, our results provide a better\nunderstanding of the factors affecting the factual consistency of language\nmodels.",
            "author": [
                "Lovisa Hagstr\u00f6m",
                "Denitsa Saynova",
                "Tobias Norlund",
                "Moa Johansson",
                "Richard Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01307v1",
                "http://arxiv.org/pdf/2311.01307v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01306v1",
            "title": "Quantum error mitigation in quantum annealing",
            "updated": "2023-11-02T15:19:07Z",
            "published": "2023-11-02T15:19:07Z",
            "summary": "Quantum Error Mitigation (QEM) presents a promising near-term approach to\nreduce error when estimating expectation values in quantum computing. Here, we\nintroduce QEM techniques tailored for quantum annealing, using Zero-Noise\nExtrapolation (ZNE). We implement ZNE through zero-temperature extrapolation as\nwell as energy-time rescaling. We conduct experimental investigations into the\nquantum critical dynamics of a transverse-field Ising spin chain, demonstrating\nthe successful mitigation of thermal noise through both of these techniques.\nMoreover, we show that energy-time rescaling effectively mitigates control\nerrors in the coherent regime where the effect of thermal noise is minimal. Our\nZNE results agree with exact calculations of the coherent evolution over a\nrange of annealing times that exceeds the coherent annealing range by almost an\norder of magnitude.",
            "author": [
                "Mohammad H. Amin",
                "Andrew D. King",
                "Jack Raymond",
                "Richard Harris",
                "William Bernoudy",
                "Andrew J. Berkley",
                "Kelly Boothby",
                "Anatoly Smirnov",
                "Fabio Altomare",
                "Michael Babcock",
                "Catia Baron",
                "Jake Connor",
                "Martin Dehn",
                "Colin Enderud",
                "Emile Hoskinson",
                "Shuiyuan Huang",
                "Mark W. Johnson",
                "Eric Ladizinsky",
                "Trevor Lanting",
                "Allison J. R. MacDonald",
                "Gaelen Marsden",
                "Reza Molavi",
                "Travis Oh",
                "Gabriel Poulin-Lamarre",
                "Hugh Ramp",
                "Chris Rich",
                "Berta Trullas Clavera",
                "Nicholas Tsai",
                "Mark Volkmann",
                "Jed D. Whittaker",
                "Jason Yao",
                "Niclas Heinsdorf",
                "Nitin Kaushal",
                "Alberto Nocera",
                "Marcel Franz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01306v1",
                "http://arxiv.org/pdf/2311.01306v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01305v3",
            "title": "AWEQ: Post-Training Quantization with Activation-Weight Equalization for\n  Large Language Models",
            "updated": "2023-11-12T07:54:09Z",
            "published": "2023-11-02T15:18:22Z",
            "summary": "Large language models(LLMs) exhibit excellent performance across a variety of\ntasks, but they come with significant computational and storage costs.\nQuantizing these models is an effective way to alleviate this issue. However,\nexisting methods struggle to strike a balance between model accuracy and\nhardware efficiency. This is where we introduce AWEQ, a post-training method\nthat requires no additional training overhead. AWEQ excels in both\nultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.\nThere is an observation that weight quantization is less challenging than\nactivation quantization. AWEQ transfers the difficulty of activation\nquantization to weights using channel equalization, achieving a balance between\nthe quantization difficulties of both, and thereby maximizing performance. We\nhave further refined the equalization method to mitigate quantization bias\nerror, ensuring the robustness of the model. Extensive experiments on popular\nmodels such as LLaMA and OPT demonstrate that AWEQ outperforms all existing\npost-training quantization methods for large models.",
            "author": [
                "Baisong Li",
                "Xingwang Wang",
                "Haixiao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01305v3",
                "http://arxiv.org/pdf/2311.01305v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01304v1",
            "title": "VM-Rec: A Variational Mapping Approach for Cold-start User\n  Recommendation",
            "updated": "2023-11-02T15:18:00Z",
            "published": "2023-11-02T15:18:00Z",
            "summary": "The cold-start problem is a common challenge for most recommender systems.\nWith extremely limited interactions of cold-start users, conventional\nrecommender models often struggle to generate embeddings with sufficient\nexpressivity. Moreover, the absence of auxiliary content information of users\nexacerbates the presence of challenges, rendering most cold-start methods\ndifficult to apply. To address this issue, our motivation is based on the\nobservation that if a model can generate expressive embeddings for existing\nusers with relatively more interactions, who were also initially cold-start\nusers, then we can establish a mapping from few initial interactions to\nexpressive embeddings, simulating the process of generating embeddings for\ncold-start users. Based on this motivation, we propose a Variational Mapping\napproach for cold-start user Recommendation (VM-Rec). Firstly, we generate a\npersonalized mapping function for cold-start users based on their initial\ninteractions, and parameters of the function are generated from a variational\ndistribution. For the sake of interpretability and computational efficiency, we\nmodel the personalized mapping function as a sparse linear model, where each\nparameter indicates the association to a specific existing user. Consequently,\nwe use this mapping function to map the embeddings of existing users to an\nembedding of the cold-start user in the same space. The resulting embedding has\nsimilar expressivity to that of existing users and can be directly integrated\ninto a pre-trained recommender model to predict click through rates or ranking\nscores. We evaluate our method based on three widely used recommender models as\npre-trained base recommender models, outperforming four popular cold-start\nmethods on two datasets under the same base model.",
            "author": [
                "Linan Zheng",
                "Jiale Chen",
                "Pengsheng Liu",
                "Guangfa Zhang",
                "Jinyun Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01304v1",
                "http://arxiv.org/pdf/2311.01304v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01295v1",
            "title": "DP-Mix: Mixup-based Data Augmentation for Differentially Private\n  Learning",
            "updated": "2023-11-02T15:12:12Z",
            "published": "2023-11-02T15:12:12Z",
            "summary": "Data augmentation techniques, such as simple image transformations and\ncombinations, are highly effective at improving the generalization of computer\nvision models, especially when training data is limited. However, such\ntechniques are fundamentally incompatible with differentially private learning\napproaches, due to the latter's built-in assumption that each training image's\ncontribution to the learned model is bounded. In this paper, we investigate why\nnaive applications of multi-sample data augmentation techniques, such as mixup,\nfail to achieve good performance and propose two novel data augmentation\ntechniques specifically designed for the constraints of differentially private\nlearning. Our first technique, DP-Mix_Self, achieves SoTA classification\nperformance across a range of datasets and settings by performing mixup on\nself-augmented data. Our second technique, DP-Mix_Diff, further improves\nperformance by incorporating synthetic data from a pre-trained diffusion model\ninto the mixup process. We open-source the code at\nhttps://github.com/wenxuan-Bao/DP-Mix.",
            "author": [
                "Wenxuan Bao",
                "Francesco Pittaluga",
                "Vijay Kumar B G",
                "Vincent Bindschaedler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01295v1",
                "http://arxiv.org/pdf/2311.01295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01292v1",
            "title": "Joint 3D Shape and Motion Estimation from Rolling Shutter Light-Field\n  Images",
            "updated": "2023-11-02T15:08:18Z",
            "published": "2023-11-02T15:08:18Z",
            "summary": "In this paper, we propose an approach to address the problem of 3D\nreconstruction of scenes from a single image captured by a light-field camera\nequipped with a rolling shutter sensor. Our method leverages the 3D information\ncues present in the light-field and the motion information provided by the\nrolling shutter effect. We present a generic model for the imaging process of\nthis sensor and a two-stage algorithm that minimizes the re-projection error\nwhile considering the position and motion of the camera in a motion-shape\nbundle adjustment estimation strategy. Thereby, we provide an instantaneous 3D\nshape-and-pose-and-velocity sensing paradigm. To the best of our knowledge,\nthis is the first study to leverage this type of sensor for this purpose. We\nalso present a new benchmark dataset composed of different light-fields showing\nrolling shutter effects, which can be used as a common base to improve the\nevaluation and tracking the progress in the field. We demonstrate the\neffectiveness and advantages of our approach through several experiments\nconducted for different scenes and types of motions. The source code and\ndataset are publicly available at: https://github.com/ICB-Vision-AI/RSLF",
            "author": [
                "Hermes McGriff",
                "Renato Martins",
                "Nicolas Andreff",
                "C\u00e9dric Demonceaux"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01292v1",
                "http://arxiv.org/pdf/2311.01292v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01288v1",
            "title": "Unraveling Diffusion in Fusion Plasma: A Case Study of In Situ\n  Processing and Particle Sorting",
            "updated": "2023-11-02T15:02:19Z",
            "published": "2023-11-02T15:02:19Z",
            "summary": "This work starts an in situ processing capability to study a certain\ndiffusion process in magnetic confinement fusion. This diffusion process\ninvolves plasma particles that are likely to escape confinement. Such particles\ncarry a significant amount of energy from the burning plasma inside the tokamak\nto the diverter and damaging the diverter plate. This study requires in situ\nprocessing because of the fast changing nature of the particle diffusion\nprocess. However, the in situ processing approach is challenging because the\namount of data to be retained for the diffusion calculations increases over\ntime, unlike in other in situ processing cases where the amount of data to be\nprocessed is constant over time. Here we report our preliminary efforts to\ncontrol the memory usage while ensuring the necessary analysis tasks are\ncompleted in a timely manner. Compared with an earlier naive attempt to\ndirectly computing the same diffusion displacements in the simulation code,\nthis in situ version reduces the memory usage from particle information by\nnearly 60% and computation time by about 20%.",
            "author": [
                "Junmin Gu",
                "Paul Lin",
                "Kesheng Wu",
                "Seung-Hoe Ku",
                "C. S. Chang",
                "R. Michael Churchill",
                "Jong Choi",
                "Norbert Podhorszki",
                "Scott Klasky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01288v1",
                "http://arxiv.org/pdf/2311.01288v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01284v1",
            "title": "Binary Black Holes and Quantum Off-Shell Recursion",
            "updated": "2023-11-02T14:59:46Z",
            "published": "2023-11-02T14:59:46Z",
            "summary": "The quantum off-shell recursion provides an efficient and universal\ncomputational tool for loop-level scattering amplitudes. In this work, we\npresent a new comprehensive computational framework based on the quantum\noff-shell recursion for binary black hole systems. Using the quantum\nperturbiner method, we derive the recursions and solve them explicitly up to\ntwo-loop order. We develop a power-counting prescription that enables the\nstraightforward separation of classical diagrams. We also devise a\nclassification scheme that optimizes the integration by parts (IBP) reduction\nprocess, which makes higher-loop calculations more tractable. By employing the\nsoft expansion technique, we remove irrelevant terms from the loop integrands\nand express them in terms of master integrals. We classify the one-loop and the\ntwo-loop classical diagrams, and their loop integrands are represented by\nlinear combinations of the master integrals. Finally, we explicitly calculate\nthe classical scalar 2 to 2 amplitudes in the potential region up to the 3PM\norder and reproduce the known results.",
            "author": [
                "Kyoungho Cho",
                "Kwangeon Kim",
                "Kanghoon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01284v1",
                "http://arxiv.org/pdf/2311.01284v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01283v1",
            "title": "Distilling Knowledge from CNN-Transformer Models for Enhanced Human\n  Action Recognition",
            "updated": "2023-11-02T14:57:58Z",
            "published": "2023-11-02T14:57:58Z",
            "summary": "This paper presents a study on improving human action recognition through the\nutilization of knowledge distillation, and the combination of CNN and ViT\nmodels. The research aims to enhance the performance and efficiency of smaller\nstudent models by transferring knowledge from larger teacher models. The\nproposed method employs a Transformer vision network as the student model,\nwhile a convolutional network serves as the teacher model. The teacher model\nextracts local image features, whereas the student model focuses on global\nfeatures using an attention mechanism. The Vision Transformer (ViT)\narchitecture is introduced as a robust framework for capturing global\ndependencies in images. Additionally, advanced variants of ViT, namely PVT,\nConvit, MVIT, Swin Transformer, and Twins, are discussed, highlighting their\ncontributions to computer vision tasks. The ConvNeXt model is introduced as a\nteacher model, known for its efficiency and effectiveness in computer vision.\nThe paper presents performance results for human action recognition on the\nStanford 40 dataset, comparing the accuracy and mAP of student models trained\nwith and without knowledge distillation. The findings illustrate that the\nsuggested approach significantly improves the accuracy and mAP when compared to\ntraining networks under regular settings. These findings emphasize the\npotential of combining local and global features in action recognition tasks.",
            "author": [
                "Hamid Ahmadabadi",
                "Omid Nejati Manzari",
                "Ahmad Ayatollahi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01283v1",
                "http://arxiv.org/pdf/2311.01283v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01282v3",
            "title": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
            "updated": "2023-11-10T01:43:51Z",
            "published": "2023-11-02T14:57:03Z",
            "summary": "As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.",
            "author": [
                "Ke Hong",
                "Guohao Dai",
                "Jiaming Xu",
                "Qiuli Mao",
                "Xiuhong Li",
                "Jun Liu",
                "Kangdi Chen",
                "Yuhan Dong",
                "Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01282v3",
                "http://arxiv.org/pdf/2311.01282v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01279v1",
            "title": "ExPECA: An Experimental Platform for Trustworthy Edge Computing\n  Applications",
            "updated": "2023-11-02T14:50:01Z",
            "published": "2023-11-02T14:50:01Z",
            "summary": "This paper presents ExPECA, an edge computing and wireless communication\nresearch testbed designed to tackle two pressing challenges: comprehensive\nend-to-end experimentation and high levels of experimental reproducibility.\nLeveraging OpenStack-based Chameleon Infrastructure (CHI) framework for its\nproven flexibility and ease of operation, ExPECA is located in a unique,\nisolated underground facility, providing a highly controlled setting for\nwireless experiments. The testbed is engineered to facilitate integrated\nstudies of both communication and computation, offering a diverse array of\nSoftware-Defined Radios (SDR) and Commercial Off-The-Shelf (COTS) wireless and\nwired links, as well as containerized computational environments. We exemplify\nthe experimental possibilities of the testbed using OpenRTiST, a\nlatency-sensitive, bandwidth-intensive application, and analyze its\nperformance. Lastly, we highlight an array of research domains and experimental\nsetups that stand to gain from ExPECA's features, including closed-loop\napplications and time-sensitive networking.",
            "author": [
                "Samie Mostafavi",
                "Vishnu Narayanan Moothedath",
                "Stefan R\u00f6nngren",
                "Neelabhro Roy",
                "Gourav Prateek Sharma",
                "Sangwon Seo",
                "Manuel Olgu\u00edn Mu\u00f1oz",
                "James Gross"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583740.3626819",
                "http://arxiv.org/abs/2311.01279v1",
                "http://arxiv.org/pdf/2311.01279v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01483v2",
            "title": "FedSN: A General Federated Learning Framework over LEO Satellite\n  Networks",
            "updated": "2023-11-22T08:55:37Z",
            "published": "2023-11-02T14:47:06Z",
            "summary": "Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.",
            "author": [
                "Zheng Lin",
                "Zhe Chen",
                "Zihan Fang",
                "Xianhao Chen",
                "Xiong Wang",
                "Yue Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01483v2",
                "http://arxiv.org/pdf/2311.01483v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01274v1",
            "title": "Layer-adapted meshes for singularly perturbed problems via mesh partial\n  differential equations and a posteriori information",
            "updated": "2023-11-02T14:37:56Z",
            "published": "2023-11-02T14:37:56Z",
            "summary": "We propose a new method for the construction of layer-adapted meshes for\nsingularly perturbed differential equations (SPDEs), based on mesh partial\ndifferential equations (MPDEs) that incorporate \\emph{a posteriori} solution\ninformation. There are numerous studies on the development of parameter robust\nnumerical methods for SPDEs that depend on the layer-adapted mesh of Bakhvalov.\nIn~\\citep{HiMa2021}, a novel MPDE-based approach for constructing a\ngeneralisation of these meshes was proposed. Like with most layer-adapted mesh\nmethods, the algorithms in that article depended on detailed derivations of\n\\emph{a priori} bounds on the SPDE's solution and its derivatives. In this work\nwe extend that approach so that it instead uses \\emph{a posteriori} computed\nestimates of the solution. We present detailed algorithms for the efficient\nimplementation of the method, and numerical results for the robust solution of\ntwo-parameter reaction-convection-diffusion problems, in one and two\ndimensions. We also provide full FEniCS code for a one-dimensional example.",
            "author": [
                "R\u00f3is\u00edn Hill",
                "Niall Madden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01274v1",
                "http://arxiv.org/pdf/2311.01274v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N50, 65N30, 65-04"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01273v1",
            "title": "Finding Common Ground: Annotating and Predicting Common Ground in Spoken\n  Conversations",
            "updated": "2023-11-02T14:37:28Z",
            "published": "2023-11-02T14:37:28Z",
            "summary": "When we communicate with other humans, we do not simply generate a sequence\nof words. Rather, we use our cognitive state (beliefs, desires, intentions) and\nour model of the audience's cognitive state to create utterances that affect\nthe audience's cognitive state in the intended manner. An important part of\ncognitive state is the common ground, which is the content the speaker\nbelieves, and the speaker believes the audience believes, and so on. While much\nattention has been paid to common ground in cognitive science, there has not\nbeen much work in natural language processing. In this paper, we introduce a\nnew annotation and corpus to capture common ground. We then describe some\ninitial experiments extracting propositions from dialog and tracking their\nstatus in the common ground from the perspective of each speaker.",
            "author": [
                "Magdalena Markowska",
                "Mohammad Taghizadeh",
                "Adil Soubki",
                "Seyed Abolghasem Mirroshandel",
                "Owen Rambow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01273v1",
                "http://arxiv.org/pdf/2311.01273v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10751v2",
            "title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
            "updated": "2023-11-23T12:14:08Z",
            "published": "2023-11-02T14:32:16Z",
            "summary": "From ancient water wheels to robotic process automation (RPA), automation\ntechnology has evolved throughout history to liberate human beings from arduous\ntasks. Yet, RPA struggles with tasks needing human-like intelligence,\nespecially in elaborate design of workflow construction and dynamic\ndecision-making in workflow execution. As Large Language Models (LLMs) have\nemerged human-like intelligence, this paper introduces Agentic Process\nAutomation (APA), a groundbreaking automation paradigm using LLM-based agents\nfor advanced automation by offloading the human labor to agents associated with\nconstruction and execution. We then instantiate ProAgent, an LLM-based agent\ndesigned to craft workflows from human instructions and make intricate\ndecisions by coordinating specialized agents. Empirical experiments are\nconducted to detail its construction and execution procedure of workflow,\nshowcasing the feasibility of APA, unveiling the possibility of a new paradigm\nof automation driven by agents. Our code is public at\nhttps://github.com/OpenBMB/ProAgent.",
            "author": [
                "Yining Ye",
                "Xin Cong",
                "Shizuo Tian",
                "Jiannan Cao",
                "Hao Wang",
                "Yujia Qin",
                "Yaxi Lu",
                "Heyang Yu",
                "Huadong Wang",
                "Yankai Lin",
                "Zhiyuan Liu",
                "Maosong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10751v2",
                "http://arxiv.org/pdf/2311.10751v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01270v2",
            "title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated\n  Counterfactually Augmented Data for Harmful Language Detection",
            "updated": "2023-11-28T18:23:48Z",
            "published": "2023-11-02T14:31:25Z",
            "summary": "NLP models are used in a variety of critical social computing tasks, such as\ndetecting sexist, racist, or otherwise hateful content. Therefore, it is\nimperative that these models are robust to spurious features. Past work has\nattempted to tackle such spurious features using training data augmentation,\nincluding Counterfactually Augmented Data (CADs). CADs introduce minimal\nchanges to existing training data points and flip their labels; training on\nthem may reduce model dependency on spurious features. However, manually\ngenerating CADs can be time-consuming and expensive. Hence in this work, we\nassess if this task can be automated using generative NLP models. We\nautomatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate\ntheir usefulness in improving model robustness compared to manually-generated\nCADs. By testing both model performance on multiple out-of-domain test sets and\nindividual data point efficacy, our results show that while manual CADs are\nstill the most effective, CADs generated by ChatGPT come a close second. One\nkey reason for the lower performance of automated methods is that the changes\nthey introduce are often insufficient to flip the original label.",
            "author": [
                "Indira Sen",
                "Dennis Assenmacher",
                "Mattia Samory",
                "Isabelle Augenstein",
                "Wil van der Aalst",
                "Claudia Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01270v2",
                "http://arxiv.org/pdf/2311.01270v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01267v1",
            "title": "UniFolding: Towards Sample-efficient, Scalable, and Generalizable\n  Robotic Garment Folding",
            "updated": "2023-11-02T14:25:10Z",
            "published": "2023-11-02T14:25:10Z",
            "summary": "This paper explores the development of UniFolding, a sample-efficient,\nscalable, and generalizable robotic system for unfolding and folding various\ngarments. UniFolding employs the proposed UFONet neural network to integrate\nunfolding and folding decisions into a single policy model that is adaptable to\ndifferent garment types and states. The design of UniFolding is based on a\ngarment's partial point cloud, which aids in generalization and reduces\nsensitivity to variations in texture and shape. The training pipeline\nprioritizes low-cost, sample-efficient data collection. Training data is\ncollected via a human-centric process with offline and online stages. The\noffline stage involves human unfolding and folding actions via Virtual Reality,\nwhile the online stage utilizes human-in-the-loop learning to fine-tune the\nmodel in a real-world setting. The system is tested on two garment types:\nlong-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with\nsignificant variations in textures, shapes, and materials. More experiments and\nvideos can be found in the supplementary materials and on the website:\nhttps://unifolding.robotflow.ai",
            "author": [
                "Han Xue",
                "Yutong Li",
                "Wenqiang Xu",
                "Huanyu Li",
                "Dongzhe Zheng",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01267v1",
                "http://arxiv.org/pdf/2311.01267v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01263v1",
            "title": "Efficient Neural Ranking using Forward Indexes and Lightweight Encoders",
            "updated": "2023-11-02T14:23:45Z",
            "published": "2023-11-02T14:23:45Z",
            "summary": "Dual-encoder-based dense retrieval models have become the standard in IR.\nThey employ large Transformer-based language models, which are notoriously\ninefficient in terms of resources and latency. We propose Fast-Forward indexes\n-- vector forward indexes which exploit the semantic matching capabilities of\ndual-encoder models for efficient and effective re-ranking. Our framework\nenables re-ranking at very high retrieval depths and combines the merits of\nboth lexical and semantic matching via score interpolation. Furthermore, in\norder to mitigate the limitations of dual-encoders, we tackle two main\nchallenges: Firstly, we improve computational efficiency by either\npre-computing representations, avoiding unnecessary computations altogether, or\nreducing the complexity of encoders. This allows us to considerably improve\nranking efficiency and latency. Secondly, we optimize the memory footprint and\nmaintenance cost of indexes; we propose two complementary techniques to reduce\nthe index size and show that, by dynamically dropping irrelevant document\ntokens, the index maintenance efficiency can be improved substantially. We\nperform evaluation to show the effectiveness and efficiency of Fast-Forward\nindexes -- our method has low latency and achieves competitive results without\nthe need for hardware acceleration, such as GPUs.",
            "author": [
                "Jurek Leonhardt",
                "Henrik M\u00fcller",
                "Koustav Rudra",
                "Megha Khosla",
                "Abhijit Anand",
                "Avishek Anand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01263v1",
                "http://arxiv.org/pdf/2311.01263v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12866v1",
            "title": "Modular Blended Attention Network for Video Question Answering",
            "updated": "2023-11-02T14:22:17Z",
            "published": "2023-11-02T14:22:17Z",
            "summary": "In multimodal machine learning tasks, it is due to the complexity of the\nassignments that the network structure, in most cases, is assembled in a\nsophisticated way. The holistic architecture can be separated into several\nlogical parts according to the respective ends that the modules are devised to\nachieve. As the number of modalities of information representation increases,\nconstructing ad hoc subnetworks for processing the data from divergent\nmodalities while mediating the fusion of different information types has become\na cumbersome and expensive problem. In this paper, we present an approach to\nfacilitate the question with a reusable and composable neural unit; by\nconnecting the units in series or parallel, the arduous network constructing of\nmultimodal machine learning tasks will be accomplished in a much\nstraightforward way. Additionally, through parameter sharing (weights\nreplication) among the units, the space complexity will be significantly\nreduced. We have conducted experiments on three commonly used datasets; our\nmethod achieves impressive performance compared to several video QA baselines.",
            "author": [
                "Mingjie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12866v1",
                "http://arxiv.org/pdf/2311.12866v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01258v1",
            "title": "Formal Methods for Autonomous Systems",
            "updated": "2023-11-02T14:18:43Z",
            "published": "2023-11-02T14:18:43Z",
            "summary": "Formal methods refer to rigorous, mathematical approaches to system\ndevelopment and have played a key role in establishing the correctness of\nsafety-critical systems. The main building blocks of formal methods are models\nand specifications, which are analogous to behaviors and requirements in system\ndesign and give us the means to verify and synthesize system behaviors with\nformal guarantees.\n  This monograph provides a survey of the current state of the art on\napplications of formal methods in the autonomous systems domain. We consider\ncorrect-by-construction synthesis under various formulations, including closed\nsystems, reactive, and probabilistic settings. Beyond synthesizing systems in\nknown environments, we address the concept of uncertainty and bound the\nbehavior of systems that employ learning using formal methods. Further, we\nexamine the synthesis of systems with monitoring, a mitigation technique for\nensuring that once a system deviates from expected behavior, it knows a way of\nreturning to normalcy. We also show how to overcome some limitations of formal\nmethods themselves with learning. We conclude with future directions for formal\nmethods in reinforcement learning, uncertainty, privacy, explainability of\nformal methods, and regulation and certification.",
            "author": [
                "Tichakorn Wongpiromsarn",
                "Mahsa Ghasemi",
                "Murat Cubuktepe",
                "Georgios Bakirtzis",
                "Steven Carr",
                "Mustafa O. Karabag",
                "Cyrus Neary",
                "Parham Gohari",
                "Ufuk Topcu"
            ],
            "link": [
                "http://dx.doi.org/10.1561/2600000029",
                "http://arxiv.org/abs/2311.01258v1",
                "http://arxiv.org/pdf/2311.01258v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01257v1",
            "title": "New mass-loss rates of Magellanic Cloud B supergiants from global wind\n  models",
            "updated": "2023-11-02T14:17:05Z",
            "published": "2023-11-02T14:17:05Z",
            "summary": "We provide global models of line-driven winds of B supergiants for\nmetallicities corresponding to the Large and Small Magellanic Clouds. The\nvelocity and density structure of the models is determined consistently from\nhydrodynamical equations with radiative force derived in the comoving frame and\nlevel populations computed from kinetic equilibrium equations. We provide a\nformula expressing the predicted mass-loss rates in terms of stellar\nluminosity, effective temperature, and metallicity. Predicted wind mass-loss\nrates decrease with decreasing metallicity as $\\dot M\\sim Z^{0.60}$ and are\nproportional to the stellar luminosity. The mass-loss rates increase below the\nregion of the bistability jump at about 20\\,kK because of iron recombination.\nIn agreement with previous theoretical and observational studies, we find a\nsmooth change of wind properties in the region of the bistability jump. With\ndecreasing metallicity, the bistability jump becomes weaker and shifts to lower\neffective temperatures. At lower metallicities above the bistability jump, our\npredictions provide similar rates to those used in current evolutionary models,\nbut our rates are significantly lower than older predictions below the\nbistability jump. Our predicted mass-loss rates agree with observational\nestimates derived from H$\\alpha$ line assuming that observations of stellar\nwinds from Galaxy and the Magellanic Clouds are uniformly affected by clumping.\nThe models nicely reproduce the dependence of terminal velocities on\ntemperature derived from ultraviolet spectroscopy.",
            "author": [
                "J. Krticka",
                "J. Kubat",
                "I. Krtickova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01257v1",
                "http://arxiv.org/pdf/2311.01257v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01256v1",
            "title": "An energy-based comparative analysis of common approaches to text\n  classification in the Legal domain",
            "updated": "2023-11-02T14:16:48Z",
            "published": "2023-11-02T14:16:48Z",
            "summary": "Most Machine Learning research evaluates the best solutions in terms of\nperformance. However, in the race for the best performing model, many important\naspects are often overlooked when, on the contrary, they should be carefully\nconsidered. In fact, sometimes the gaps in performance between different\napproaches are neglectable, whereas factors such as production costs, energy\nconsumption, and carbon footprint must take into consideration. Large Language\nModels (LLMs) are extensively adopted to address NLP problems in academia and\nindustry. In this work, we present a detailed quantitative comparison of LLM\nand traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes\ninto account both performance (standard indices) and alternative metrics such\nas timing, power consumption and cost, in a word: the carbon-footprint. In our\nanalysis, we considered the prototyping phase (model selection by\ntraining-validation-test iterations) and in-production phases separately, since\nthey follow different implementation procedures and also require different\nresources. The results indicate that very often, the simplest algorithms\nachieve performance very close to that of large LLMs but with very low power\nconsumption and lower resource demands. The results obtained could suggest\ncompanies to include additional evaluations in the choice of Machine Learning\n(ML) solutions.",
            "author": [
                "Sinan Gultekin",
                "Achille Globo",
                "Andrea Zugarini",
                "Marco Ernandes",
                "Leonardo Rigutini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01256v1",
                "http://arxiv.org/pdf/2311.01256v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01254v1",
            "title": "Human participants in AI research: Ethics and transparency in practice",
            "updated": "2023-11-02T14:12:21Z",
            "published": "2023-11-02T14:12:21Z",
            "summary": "In recent years, research involving human participants has been critical to\nadvances in artificial intelligence (AI) and machine learning (ML),\nparticularly in the areas of conversational, human-compatible, and cooperative\nAI. For example, around 12% and 6% of publications at recent AAAI and NeurIPS\nconferences indicate the collection of original human data, respectively. Yet\nAI and ML researchers lack guidelines for ethical, transparent research\npractices with human participants. Fewer than one out of every four of these\nAAAI and NeurIPS papers provide details of ethical review, the collection of\ninformed consent, or participant compensation. This paper aims to bridge this\ngap by exploring normative similarities and differences between AI research and\nrelated fields that involve human participants. Though psychology,\nhuman-computer interaction, and other adjacent fields offer historic lessons\nand helpful insights, AI research raises several specific\nconcerns$\\unicode{x2014}$namely, participatory design, crowdsourced dataset\ndevelopment, and an expansive role of corporations$\\unicode{x2014}$that\nnecessitate a contextual ethics framework. To address these concerns, this\npaper outlines a set of guidelines for ethical and transparent practice with\nhuman participants in AI and ML research. These guidelines can be found in\nSection 4 on pp. 4$\\unicode{x2013}$7.",
            "author": [
                "Kevin R. McKee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01254v1",
                "http://arxiv.org/pdf/2311.01254v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01245v1",
            "title": "Robustness for Free: Quality-Diversity Driven Discovery of Agile Soft\n  Robotic Gaits",
            "updated": "2023-11-02T14:00:11Z",
            "published": "2023-11-02T14:00:11Z",
            "summary": "Soft robotics aims to develop robots able to adapt their behavior across a\nwide range of unstructured and unknown environments. A critical challenge of\nsoft robotic control is that nonlinear dynamics often result in complex\nbehaviors hard to model and predict. Typically behaviors for mobile soft robots\nare discovered through empirical trial and error and hand-tuning. More\nrecently, optimization algorithms such as Genetic Algorithms (GA) have been\nused to discover gaits, but these behaviors are often optimized for a single\nenvironment or terrain, and can be brittle to unplanned changes to terrain. In\nthis paper we demonstrate how Quality Diversity Algorithms, which search of a\nrange of high-performing behaviors, can produce repertoires of gaits that are\nrobust to changing terrains. This robustness significantly out-performs that of\ngaits produced by a single objective optimization algorithm.",
            "author": [
                "John Daly",
                "Daniel Casper",
                "Muhammad Farooq",
                "Andrew James",
                "Ali Khan",
                "Phoenix Mulgrew",
                "Daniel Tyebkhan",
                "Bao Vo",
                "John Rieffel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01245v1",
                "http://arxiv.org/pdf/2311.01245v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01242v1",
            "title": "Pushing the Limits of Quantum Computing for Simulating PFAS Chemistry",
            "updated": "2023-11-02T13:58:02Z",
            "published": "2023-11-02T13:58:02Z",
            "summary": "Accurate and scalable methods for computational quantum chemistry can\naccelerate research and development in many fields, ranging from drug discovery\nto advanced material design. Solving the electronic Schrodinger equation is the\ncore problem of computational chemistry. However, the combinatorial complexity\nof this problem makes it intractable to find exact solutions, except for very\nsmall systems. The idea of quantum computing originated from this computational\nchallenge in simulating quantum-mechanics. We propose an end-to-end quantum\nchemistry pipeline based on the variational quantum eigensolver (VQE) algorithm\nand integrated with both HPC-based simulators and a trapped-ion quantum\ncomputer. Our platform orchestrates hundreds of simulation jobs on compute\nresources to efficiently complete a set of ab initio chemistry experiments with\na wide range of parameterization. Per- and poly-fluoroalkyl substances (PFAS)\nare a large family of human-made chemicals that pose a major environmental and\nhealth issue globally. Our simulations includes breaking a Carbon-Fluorine bond\nin trifluoroacetic acid (TFA), a common PFAS chemical. This is a common pathway\ntowards destruction and removal of PFAS. Molecules are modeled on both a\nquantum simulator and a trapped-ion quantum computer, specifically IonQ Aria.\nUsing basic error mitigation techniques, the 11-qubit TFA model (56 entangling\ngates) on IonQ Aria yields near-quantitative results with milli-Hartree\naccuracy. Our novel results show the current state and future projections for\nquantum computing in solving the electronic structure problem, push the\nboundaries for the VQE algorithm and quantum computers, and facilitates\ndevelopment of quantum chemistry workflows.",
            "author": [
                "Emil Dimitrov",
                "Goar Sanchez-Sanz",
                "James Nelson",
                "Lee O'Riordan",
                "Myles Doyle",
                "Sean Courtney",
                "Venkatesh Kannan",
                "Hassan Naseri",
                "Alberto Garcia Garcia",
                "James Tricker",
                "Marisa Faraggi",
                "Joshua Goings",
                "Luning Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01242v1",
                "http://arxiv.org/pdf/2311.01242v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01241v1",
            "title": "Exploring Deep Learning Image Super-Resolution for Iris Recognition",
            "updated": "2023-11-02T13:57:48Z",
            "published": "2023-11-02T13:57:48Z",
            "summary": "In this work we test the ability of deep learning methods to provide an\nend-to-end mapping between low and high resolution images applying it to the\niris recognition problem. Here, we propose the use of two deep learning\nsingle-image super-resolution approaches: Stacked Auto-Encoders (SAE) and\nConvolutional Neural Networks (CNN) with the most possible lightweight\nstructure to achieve fast speed, preserve local information and reduce\nartifacts at the same time. We validate the methods with a database of 1.872\nnear-infrared iris images with quality assessment and recognition experiments\nshowing the superiority of deep learning approaches over the compared\nalgorithms.",
            "author": [
                "Eduardo Ribeiro",
                "Andreas Uhl",
                "Fernando Alonso-Fernandez",
                "Reuben A. Farrugia"
            ],
            "link": [
                "http://dx.doi.org/10.23919/EUSIPCO.2017.8081595",
                "http://arxiv.org/abs/2311.01241v1",
                "http://arxiv.org/pdf/2311.01241v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01240v2",
            "title": "FacadeNet: Conditional Facade Synthesis via Selective Editing",
            "updated": "2023-11-03T11:08:03Z",
            "published": "2023-11-02T13:57:43Z",
            "summary": "We introduce FacadeNet, a deep learning approach for synthesizing building\nfacade images from diverse viewpoints. Our method employs a conditional GAN,\ntaking a single view of a facade along with the desired viewpoint information\nand generates an image of the facade from the distinct viewpoint. To precisely\nmodify view-dependent elements like windows and doors while preserving the\nstructure of view-independent components such as walls, we introduce a\nselective editing module. This module leverages image embeddings extracted from\na pre-trained vision transformer. Our experiments demonstrated state-of-the-art\nperformance on building facade generation, surpassing alternative methods.",
            "author": [
                "Yiangos Georgiou",
                "Marios Loizou",
                "Tom Kelly",
                "Melinos Averkiou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01240v2",
                "http://arxiv.org/pdf/2311.01240v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16469v1",
            "title": "Reconciling the theoretical and experimental electronic structure of\n  NbO2",
            "updated": "2023-11-02T13:56:24Z",
            "published": "2023-11-02T13:56:24Z",
            "summary": "Metal-insulator transition materials such as NbO2 have generated much\nexcitement in recent years for their potential applications in computing and\nsensing. NbO2 has generated considerable debate over the nature of the phase\ntransition, and the values for the band gap/band widths in the insulating\nphase. We present a combined theoretical and experimental study of the band gap\nand electronic structure of the insulating phase of NbO2. We carry out\nab-initio density functional theory plus U calculations, directly determining U\nand J parameters for both the Nb 4d and O 2p subspaces through the recently\nintroduced minimum-tracking linear response method. We find a fundamental bulk\nband gap of 0.80 eV for the full DFT+U+J theory. We also perform calculations\nand measurements for a (100) oriented thin film. Scanning tunnelling\nspectroscopy measurements show that the surface band gap varies from 0.75 eV to\n1.35 eV due to an excess of oxygen in and near the surface region of the film.\nSlab calculations indicate metallicity localised at the surface region caused\nby an energy level shift consistent with a reduction in Coulomb repulsion. We\ndemonstrate that this effect in combination with the simple, low cost DFT+U+J\nmethod can account for the band widths and p-d gap observed in X-ray\nphotoelectron spectroscopy experiments. Overall, our results indicate the\npossible presence of a 2D anisotropic metallic layer at the (100) surface of\nNbO2.",
            "author": [
                "Samuel Berman",
                "Ainur Zhussupbekova",
                "Jos E. Boschker",
                "Jutta Schwarzkopf",
                "David D. O'Regan",
                "Igor V. Shvets",
                "Kuanysh Zhussupbekov"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevB.108.155141",
                "http://arxiv.org/abs/2311.16469v1",
                "http://arxiv.org/pdf/2311.16469v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01237v1",
            "title": "Log-Likelihood Score Level Fusion for Improved Cross-Sensor Smartphone\n  Periocular Recognition",
            "updated": "2023-11-02T13:43:44Z",
            "published": "2023-11-02T13:43:44Z",
            "summary": "The proliferation of cameras and personal devices results in a wide\nvariability of imaging conditions, producing large intra-class variations and a\nsignificant performance drop when images from heterogeneous environments are\ncompared. However, many applications require to deal with data from different\nsources regularly, thus needing to overcome these interoperability problems.\nHere, we employ fusion of several comparators to improve periocular performance\nwhen images from different smartphones are compared. We use a probabilistic\nfusion framework based on linear logistic regression, in which fused scores\ntend to be log-likelihood ratios, obtaining a reduction in cross-sensor EER of\nup to 40% due to the fusion. Our framework also provides an elegant and simple\nsolution to handle signals from different devices, since same-sensor and\ncross-sensor score distributions are aligned and mapped to a common\nprobabilistic domain. This allows the use of Bayes thresholds for optimal\ndecision-making, eliminating the need of sensor-specific thresholds, which is\nessential in operational conditions because the threshold setting critically\ndetermines the accuracy of the authentication process in many applications.",
            "author": [
                "Fernando Alonso-Fernandez",
                "Kiran B. Raja",
                "Christoph Busch",
                "Josef Bigun"
            ],
            "link": [
                "http://dx.doi.org/10.23919/EUSIPCO.2017.8081211",
                "http://arxiv.org/abs/2311.01237v1",
                "http://arxiv.org/pdf/2311.01237v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01233v1",
            "title": "Long Story Short: a Summarize-then-Search Method for Long Video Question\n  Answering",
            "updated": "2023-11-02T13:36:11Z",
            "published": "2023-11-02T13:36:11Z",
            "summary": "Large language models such as GPT-3 have demonstrated an impressive\ncapability to adapt to new tasks without requiring task-specific training data.\nThis capability has been particularly effective in settings such as narrative\nquestion answering, where the diversity of tasks is immense, but the available\nsupervision data is small. In this work, we investigate if such language models\ncan extend their zero-shot reasoning abilities to long multimodal narratives in\nmultimedia content such as drama, movies, and animation, where the story plays\nan essential role. We propose Long Story Short, a framework for narrative video\nQA that first summarizes the narrative of the video to a short plot and then\nsearches parts of the video relevant to the question. We also propose to\nenhance visual matching with CLIPCheck. Our model outperforms state-of-the-art\nsupervised models by a large margin, highlighting the potential of zero-shot QA\nfor long videos.",
            "author": [
                "Jiwan Chung",
                "Youngjae Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01233v1",
                "http://arxiv.org/pdf/2311.01233v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01230v1",
            "title": "Multi-Operational Mathematical Derivations in Latent Space",
            "updated": "2023-11-02T13:33:07Z",
            "published": "2023-11-02T13:33:07Z",
            "summary": "This paper investigates the possibility of approximating multiple\nmathematical operations in latent space for expression derivation. To this end,\nwe introduce different multi-operational representation paradigms, modelling\nmathematical operations as explicit geometric transformations. By leveraging a\nsymbolic engine, we construct a large-scale dataset comprising 1.7M derivation\nsteps stemming from 61K premises and 6 operators, analysing the properties of\neach paradigm when instantiated with state-of-the-art neural encoders.\nSpecifically, we investigate how different encoding mechanisms can approximate\nequational reasoning in latent space, exploring the trade-off between learning\ndifferent operators and specialising within single operations, as well as the\nability to support multi-step derivations and out-of-distribution\ngeneralisation. Our empirical analysis reveals that the multi-operational\nparadigm is crucial for disentangling different operators, while discriminating\nthe conclusions for a single operation is achievable in the original expression\nencoder. Moreover, we show that architectural choices can heavily affect the\ntraining dynamics, structural organisation, and generalisation of the latent\nspace, resulting in significant variations across paradigms and classes of\nencoders.",
            "author": [
                "Marco Valentino",
                "Jordan Meadows",
                "Lan Zhang",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01230v1",
                "http://arxiv.org/pdf/2311.01230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01229v1",
            "title": "Theoretical Analysis of Impact of Delayed Updates on Decentralized\n  Federated Learning",
            "updated": "2023-11-02T13:29:23Z",
            "published": "2023-11-02T13:29:23Z",
            "summary": "Decentralized Federated learning is a distributed edge intelligence framework\nby exchanging parameter updates instead of training data among participators,\nin order to retrain or fine-tune deep learning models for mobile intelligent\napplications. Considering the various topologies of edge networks in mobile\ninternet, the impact of transmission delay of updates during model training is\nnon-negligible for data-intensive intelligent applications on mobile devices,\ne.g., intelligent medical services, automated driving vehicles, etc.. To\naddress this problem, we analyze the impact of delayed updates for\ndecentralized federated learning, and provide a theoretical bound for these\nupdates to achieve model convergence. Within the theoretical bound of updating\nperiod, the latest versions for the delayed updates are reused to continue\naggregation, in case the model parameters from a specific neighbor are not\ncollected or updated in time.",
            "author": [
                "Yong Zeng",
                "Siyuan Liu",
                "Zhiwei Xu",
                "Jie Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01229v1",
                "http://arxiv.org/pdf/2311.01229v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01227v1",
            "title": "Robust Feature Learning and Global Variance-Driven Classifier Alignment\n  for Long-Tail Class Incremental Learning",
            "updated": "2023-11-02T13:28:53Z",
            "published": "2023-11-02T13:28:53Z",
            "summary": "This paper introduces a two-stage framework designed to enhance long-tail\nclass incremental learning, enabling the model to progressively learn new\nclasses, while mitigating catastrophic forgetting in the context of long-tailed\ndata distributions. Addressing the challenge posed by the under-representation\nof tail classes in long-tail class incremental learning, our approach achieves\nclassifier alignment by leveraging global variance as an informative measure\nand class prototypes in the second stage. This process effectively captures\nclass properties and eliminates the need for data balancing or additional layer\ntuning. Alongside traditional class incremental learning losses in the first\nstage, the proposed approach incorporates mixup classes to learn robust feature\nrepresentations, ensuring smoother boundaries. The proposed framework can\nseamlessly integrate as a module with any class incremental learning method to\neffectively handle long-tail class incremental learning scenarios. Extensive\nexperimentation on the CIFAR-100 and ImageNet-Subset datasets validates the\napproach's efficacy, showcasing its superiority over state-of-the-art\ntechniques across various long-tail CIL settings.",
            "author": [
                "Jayateja Kalla",
                "Soma Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01227v1",
                "http://arxiv.org/pdf/2311.01227v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01226v1",
            "title": "Optimal Transport-Guided Conditional Score-Based Diffusion Models",
            "updated": "2023-11-02T13:28:44Z",
            "published": "2023-11-02T13:28:44Z",
            "summary": "Conditional score-based diffusion model (SBDM) is for conditional generation\nof target data with paired data as condition, and has achieved great success in\nimage translation. However, it requires the paired data as condition, and there\nwould be insufficient paired data provided in real-world applications. To\ntackle the applications with partially paired or even unpaired dataset, we\npropose a novel Optimal Transport-guided Conditional Score-based diffusion\nmodel (OTCS) in this paper. We build the coupling relationship for the unpaired\nor partially paired dataset based on $L_2$-regularized unsupervised or\nsemi-supervised optimal transport, respectively. Based on the coupling\nrelationship, we develop the objective for training the conditional score-based\nmodel for unpaired or partially paired settings, which is based on a\nreformulation and generalization of the conditional SBDM for paired setting.\nWith the estimated coupling relationship, we effectively train the conditional\nscore-based model by designing a ``resampling-by-compatibility'' strategy to\nchoose the sampled data with high compatibility as guidance. Extensive\nexperiments on unpaired super-resolution and semi-paired image-to-image\ntranslation demonstrated the effectiveness of the proposed OTCS model. From the\nviewpoint of optimal transport, OTCS provides an approach to transport data\nacross distributions, which is a challenge for OT on large-scale datasets. We\ntheoretically prove that OTCS realizes the data transport in OT with a\ntheoretical bound. Code is available at \\url{https://github.com/XJTU-XGU/OTCS}.",
            "author": [
                "Xiang Gu",
                "Liwei Yang",
                "Jian Sun",
                "Zongben Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01226v1",
                "http://arxiv.org/pdf/2311.01226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14682v1",
            "title": "Data-Driven Models for studying the Dynamics of the COVID-19 Pandemics",
            "updated": "2023-11-02T13:28:21Z",
            "published": "2023-11-02T13:28:21Z",
            "summary": "This paper seeks to study the evolution of the COVID-19 pandemic based on\ndaily published data from Worldometer website, using a time-dependent SIR\nmodel. Our findings indicate that this model fits well such data, for different\nchosen periods and different regions. This well-known model, consisting of\nthree disjoint compartments, susceptible , infected , and removed , depends in\nour case on two time dependent parameters, the infection rate $\\beta(t)$ and\nthe removal rate $\\rho(t)$. After deriving the model, we prove the local\nexponential behavior of the number of infected people, be it growth or decay.\nFurthermore, we extract a time dependent replacement factor $\\sigma_s(t)\n={\\beta(t)}s(t)/{\\rho(t) }$, where $s(t)$ is the ratio of susceptible people at\ntime $t$. In addition, $i(t)$ and $r(t)$ are respectively the ratios of\ninfected and removed people, based on a population of size $N$, usually assumed\nto be constant. Besides these theoretical results, the report provides\nsimulations on the daily data obtained for Germany, Italy, and the entire\nWorld, as collected from Worldometer over the period stretching from April 2020\nto June 2022. The computational model consists of the estimation of $\\beta(t)$,\n$\\rho(t)$ and $s(t)$ based on the time-dependent SIR model. The validation of\nour approach is demonstrated by comparing the profiles of the collected $i(t),\nr(t)$ data and those obtained from the SIR model with the approximated\nparameters. We also consider matching the data with a constant-coefficient SIR\nmodel, which seems to be working only for short periods. Thus, such model helps\nunderstanding and predicting the evolution of the pandemics for short periods\nof time where no radical change occurs.",
            "author": [
                "Rawan H. Madi",
                "Sophie M. Moufawad",
                "Nabil R. Nassif"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14682v1",
                "http://arxiv.org/pdf/2311.14682v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01224v1",
            "title": "EISim: A Platform for Simulating Intelligent Edge Orchestration\n  Solutions",
            "updated": "2023-11-02T13:24:04Z",
            "published": "2023-11-02T13:24:04Z",
            "summary": "To support the stringent requirements of the future intelligent and\ninteractive applications, intelligence needs to become an essential part of the\nresource management in the edge environment. Developing intelligent\norchestration solutions is a challenging and arduous task, where the evaluation\nand comparison of the proposed solution is a focal point. Simulation is\ncommonly used to evaluate and compare proposed solutions. However, the\ncurrently existing, openly available simulators are lacking in terms of\nsupporting the research on intelligent edge orchestration methods. To address\nthis need, this article presents a simulation platform called Edge Intelligence\nSimulator (EISim), the purpose of which is to facilitate the research on\nintelligent edge orchestration solutions. EISim is extended from an existing\nfog simulator called PureEdgeSim. In its current form, EISim supports\nsimulating deep reinforcement learning based solutions and different\norchestration control topologies in scenarios related to task offloading and\nresource pricing on edge. The platform also includes additional tools for\ncreating simulation environments, running simulations for agent training and\nevaluation, and plotting results.",
            "author": [
                "Henna Kokkonen",
                "Susanna Pirttikangas",
                "Lauri Lov\u00e9n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01224v1",
                "http://arxiv.org/pdf/2311.01224v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01222v1",
            "title": "Image Reflection on LLEE Charts -- Another Proof for the Completeness of\n  an Axiomatization of 1-Free Regular Expressions Modulo Bisimilarity",
            "updated": "2023-11-02T13:22:05Z",
            "published": "2023-11-02T13:22:05Z",
            "summary": "We analyze a phenomenon called \"image reflection\" on a type of\ncharacterization graphs -- LLEE charts -- of 1-free regular expressions modulo\nbisimulation equivalence. Due to the correspondence between 1-free regular\nexpressions and the provable solutions of LEE/LLEE charts, this observation\nnaturally leads to a new proof for the completeness of the proof system\n\\MilIfree\\ for 1-free regular expressions modulo bisimulation equivalence. The\ncritical part of the previous proof is to show that bisimulation collapse,\nwhich plays the role in linking the provable solutions of two LLEE charts, is\nstill an LLEE chart. The difference of our proof, compared to the previous one,\nis that we do not rely on the graph transformations from LLEE charts into their\nbisimulation collapses by merging two bisimular nodes in each transformation\nstep. Instead, we directly show that the bisimulation collapse of an LLEE chart\npossesses an LEE/LLEE structure based on its set of images mapped through the\nbisimulation function from the LLEE chart, and the constrained relation between\nthe images and their so-called \"well-structured\" looping-back charts pre-images\non the LLEE chart. Our approach provides a novel angle to look at this problem\nand related problems, and might introduce a different way for proving the\ncompleteness problem of \\Mil\\ for regular expressions modulo bisimulation\nequivalence, which had remained open until very recently.",
            "author": [
                "Yuanrui Zhang",
                "Xinxin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01222v1",
                "http://arxiv.org/pdf/2311.01222v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04919v1",
            "title": "The Impact of Preference Agreement in Reinforcement Learning from Human\n  Feedback: A Case Study in Summarization",
            "updated": "2023-11-02T13:21:23Z",
            "published": "2023-11-02T13:21:23Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) can be used to capture\ncomplex and nuanced properties of text generation quality. As a result, the\ntask of text summarization has been identified as a good candidate for this\nprocess. In this paper, we explore how preference agreement impacts the\nefficacy of RLHF for summarization. We show that sampling human preferences to\ninclude a range of annotator agreement results in (1) higher accuracy reward\nmodels and (2) alters the characteristics of quality captured. We additionally\nshow improvements in downstream generation when using a reward model trained\nwith a range of preference agreements. Our contributions have implications for\nthe design of synthetic datasets as well as the importance of considering\nquality differentials in comparison-based data.",
            "author": [
                "Sian Gooding",
                "Hassan Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04919v1",
                "http://arxiv.org/pdf/2311.04919v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01217v1",
            "title": "The learning effects of subsidies to bundled goods: a semiparametric\n  approach",
            "updated": "2023-11-02T13:18:57Z",
            "published": "2023-11-02T13:18:57Z",
            "summary": "Can temporary subsidies to bundles induce long-run changes in demand due to\nlearning about the relative quality of one of its constituent goods? This paper\nprovides theoretical and experimental evidence on the role of this mechanism.\nTheoretically, we introduce a model where an agent learns about the quality of\nan innovation on an essential good through consumption. Our results show that\nthe contemporaneous effect of a one-off subsidy to a bundle that contains the\ninnovation may be decomposed into a direct price effect, and an indirect\nlearning motive, whereby an agent leverages the discount to increase the\ninformational bequest left to her future selves. We then assess the predictions\nof our theory in a randomised experiment in a ridesharing platform. The\nexperiment provided two-week discounts for car trips integrating with a train\nor metro station (a bundle). Given the heavy-tailed nature of our data, we\nfollow \\cite{Athey2023} and, motivated by our theory, propose a semiparametric\nmodel for treatment effects that enables the construction of more efficient\nestimators. We introduce a statistically efficient estimator for our model by\nrelying on L-moments, a robust alternative to standard moments. Our estimator\nimmediately yields a specification test for the semiparametric model; moreover,\nin our adopted parametrisation, it can be easily computed through generalized\nleast squares. Our empirical results indicate that a two-week 50\\% discount on\ncar trips integrating with train/metro leads to a contemporaneous increase in\nthe demand for integrated rides, and, consistent with our learning model,\npersistent changes in the mean and dispersion of nonintegrated rides. These\neffects persist for over four months after the discount. A simple calibration\nof our model shows that around 40\\% to 50\\% of the estimated contemporaneous\nincrease in integrated rides may be attributed to a learning motive.",
            "author": [
                "Luis Alvarez",
                "Ciro Biderman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01217v1",
                "http://arxiv.org/pdf/2311.01217v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01216v1",
            "title": "Convergent plug-and-play with proximal denoiser and unconstrained\n  regularization parameter",
            "updated": "2023-11-02T13:18:39Z",
            "published": "2023-11-02T13:18:39Z",
            "summary": "In this work, we present new proofs of convergence for Plug-and-Play (PnP)\nalgorithms. PnP methods are efficient iterative algorithms for solving image\ninverse problems where regularization is performed by plugging a pre-trained\ndenoiser in a proximal algorithm, such as Proximal Gradient Descent (PGD) or\nDouglas-Rachford Splitting (DRS). Recent research has explored convergence by\nincorporating a denoiser that writes exactly as a proximal operator. However,\nthe corresponding PnP algorithm has then to be run with stepsize equal to $1$.\nThe stepsize condition for nonconvex convergence of the proximal algorithm in\nuse then translates to restrictive conditions on the regularization parameter\nof the inverse problem. This can severely degrade the restoration capacity of\nthe algorithm. In this paper, we present two remedies for this limitation.\nFirst, we provide a novel convergence proof for PnP-DRS that does not impose\nany restrictions on the regularization parameter. Second, we examine a relaxed\nversion of the PGD algorithm that converges across a broader range of\nregularization parameters. Our experimental study, conducted on deblurring and\nsuper-resolution experiments, demonstrate that both of these solutions enhance\nthe accuracy of image restoration.",
            "author": [
                "Samuel Hurault",
                "Antonin Chambolle",
                "Arthur Leclaire",
                "Nicolas Papadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01216v1",
                "http://arxiv.org/pdf/2311.01216v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01214v1",
            "title": "High-Quality Animatable Dynamic Garment Reconstruction from Monocular\n  Videos",
            "updated": "2023-11-02T13:16:27Z",
            "published": "2023-11-02T13:16:27Z",
            "summary": "Much progress has been made in reconstructing garments from an image or a\nvideo. However, none of existing works meet the expectations of digitizing\nhigh-quality animatable dynamic garments that can be adjusted to various unseen\nposes. In this paper, we propose the first method to recover high-quality\nanimatable dynamic garments from monocular videos without depending on scanned\ndata. To generate reasonable deformations for various unseen poses, we propose\na learnable garment deformation network that formulates the garment\nreconstruction task as a pose-driven deformation problem. To alleviate the\nambiguity estimating 3D garments from monocular videos, we design a\nmulti-hypothesis deformation module that learns spatial representations of\nmultiple plausible deformations. Experimental results on several public\ndatasets demonstrate that our method can reconstruct high-quality dynamic\ngarments with coherent surface details, which can be easily animated under\nunseen poses. The code will be provided for research purposes.",
            "author": [
                "Xiongzheng Li",
                "Jinsong Zhang",
                "Yu-Kun Lai",
                "Jingyu Yang",
                "Kun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01214v1",
                "http://arxiv.org/pdf/2311.01214v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16133v2",
            "title": "Effective Quantization for Diffusion Models on CPUs",
            "updated": "2023-11-29T08:24:57Z",
            "published": "2023-11-02T13:14:01Z",
            "summary": "Diffusion models have gained popularity for generating images from textual\ndescriptions. Nonetheless, the substantial need for computational resources\ncontinues to present a noteworthy challenge, contributing to time-consuming\nprocesses. Quantization, a technique employed to compress deep learning models\nfor enhanced efficiency, presents challenges when applied to diffusion models.\nThese models are notably more sensitive to quantization compared to other model\ntypes, potentially resulting in a degradation of image quality. In this paper,\nwe introduce a novel approach to quantize the diffusion models by leveraging\nboth quantization-aware training and distillation. Our results show the\nquantized models can maintain the high image quality while demonstrating the\ninference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.",
            "author": [
                "Hanwen Chang",
                "Haihao Shen",
                "Yiyang Cai",
                "Xinyu Ye",
                "Zhenzhong Xu",
                "Wenhua Cheng",
                "Kaokao Lv",
                "Weiwei Zhang",
                "Yintong Lu",
                "Heng Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16133v2",
                "http://arxiv.org/pdf/2311.16133v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01212v1",
            "title": "Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral\n  Image Classification",
            "updated": "2023-11-02T13:06:03Z",
            "published": "2023-11-02T13:06:03Z",
            "summary": "Cross-domain few-shot hyperspectral image classification focuses on learning\nprior knowledge from a large number of labeled samples from source domain and\nthen transferring the knowledge to the tasks which contain only few labeled\nsamples in target domains. Following the metric-based manner, many current\nmethods first extract the features of the query and support samples, and then\ndirectly predict the classes of query samples according to their distance to\nthe support samples or prototypes. The relations between samples have not been\nfully explored and utilized. Different from current works, this paper proposes\nto learn sample relations from different views and take them into the model\nlearning process, to improve the cross-domain few-shot hyperspectral image\nclassification. Building on current DCFSL method which adopts a domain\ndiscriminator to deal with domain-level distribution difference, the proposed\nmethod applys contrastive learning to learn the class-level sample relations to\nobtain more discriminable sample features. In addition, it adopts a transformer\nbased cross-attention learning module to learn the set-level sample relations\nand acquire the attentions from query samples to support samples. Our\nexperimental results have demonstrated the contribution of the multi-view\nrelation learning mechanism for few-shot hyperspectral image classification\nwhen compared with the state of the art methods.",
            "author": [
                "Chun Liu",
                "Longwei Yang",
                "Zheng Li",
                "Wei Yang",
                "Zhigang Han",
                "Jianzhong Guo",
                "Junyong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01212v1",
                "http://arxiv.org/pdf/2311.01212v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01205v1",
            "title": "Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go\n  Indifferent",
            "updated": "2023-11-02T12:59:32Z",
            "published": "2023-11-02T12:59:32Z",
            "summary": "Prior attacks on graph neural networks have mostly focused on graph poisoning\nand evasion, neglecting the network's weights and biases. Traditional\nweight-based fault injection attacks, such as bit flip attacks used for\nconvolutional neural networks, do not consider the unique properties of graph\nneural networks. We propose the Injectivity Bit Flip Attack, the first bit flip\nattack designed specifically for graph neural networks. Our attack targets the\nlearnable neighborhood aggregation functions in quantized message passing\nneural networks, degrading their ability to distinguish graph structures and\nlosing the expressivity of the Weisfeiler-Lehman test. Our findings suggest\nthat exploiting mathematical properties specific to certain graph neural\nnetwork architectures can significantly increase their vulnerability to bit\nflip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive\nGraph Isomorphism Networks trained on various graph property prediction\ndatasets to random output by flipping only a small fraction of the network's\nbits, demonstrating its higher destructive power compared to a bit flip attack\ntransferred from convolutional neural networks. Our attack is transparent and\nmotivated by theoretical insights which are confirmed by extensive empirical\nresults.",
            "author": [
                "Lorenz Kummer",
                "Samir Moustafa",
                "Nils N. Kriege",
                "Wilfried N. Gansterer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01205v1",
                "http://arxiv.org/pdf/2311.01205v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01202v1",
            "title": "Cross-Modal Information-Guided Network using Contrastive Learning for\n  Point Cloud Registration",
            "updated": "2023-11-02T12:56:47Z",
            "published": "2023-11-02T12:56:47Z",
            "summary": "The majority of point cloud registration methods currently rely on extracting\nfeatures from points. However, these methods are limited by their dependence on\ninformation obtained from a single modality of points, which can result in\ndeficiencies such as inadequate perception of global features and a lack of\ntexture information. Actually, humans can employ visual information learned\nfrom 2D images to comprehend the 3D world. Based on this fact, we present a\nnovel Cross-Modal Information-Guided Network (CMIGNet), which obtains global\nshape perception through cross-modal information to achieve precise and robust\npoint cloud registration. Specifically, we first incorporate the projected\nimages from the point clouds and fuse the cross-modal features using the\nattention mechanism. Furthermore, we employ two contrastive learning\nstrategies, namely overlapping contrastive learning and cross-modal contrastive\nlearning. The former focuses on features in overlapping regions, while the\nlatter emphasizes the correspondences between 2D and 3D features. Finally, we\npropose a mask prediction module to identify keypoints in the point clouds.\nExtensive experiments on several benchmark datasets demonstrate that our\nnetwork achieves superior registration performance.",
            "author": [
                "Yifan Xie",
                "Jihua Zhu",
                "Shiqi Li",
                "Pengcheng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01202v1",
                "http://arxiv.org/pdf/2311.01202v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01200v1",
            "title": "A Study of Continual Learning Under Language Shift",
            "updated": "2023-11-02T12:54:50Z",
            "published": "2023-11-02T12:54:50Z",
            "summary": "The recent increase in data and model scale for language model pre-training\nhas led to huge training costs. In scenarios where new data become available\nover time, updating a model instead of fully retraining it would therefore\nprovide significant gains. In this paper, we study the benefits and downsides\nof updating a language model when new data comes from new languages - the case\nof continual learning under language shift. Starting from a monolingual English\nlanguage model, we incrementally add data from Norwegian and Icelandic to\ninvestigate how forward and backward transfer effects depend on the\npre-training order and characteristics of languages, for different model sizes\nand learning rate schedulers. Our results show that, while forward transfer is\nlargely positive and independent of language order, backward transfer can be\neither positive or negative depending on the order and characteristics of new\nlanguages. To explain these patterns we explore several language similarity\nmetrics and find that syntactic similarity appears to have the best correlation\nwith our results.",
            "author": [
                "Evangelia Gogoulou",
                "Timoth\u00e9e Lesort",
                "Magnus Boman",
                "Joakim Nivre"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01200v1",
                "http://arxiv.org/pdf/2311.01200v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01197v1",
            "title": "AiluRus: A Scalable ViT Framework for Dense Prediction",
            "updated": "2023-11-02T12:48:43Z",
            "published": "2023-11-02T12:48:43Z",
            "summary": "Vision transformers (ViTs) have emerged as a prevalent architecture for\nvision tasks owing to their impressive performance. However, when it comes to\nhandling long token sequences, especially in dense prediction tasks that\nrequire high-resolution input, the complexity of ViTs increases significantly.\nNotably, dense prediction tasks, such as semantic segmentation or object\ndetection, emphasize more on the contours or shapes of objects, while the\ntexture inside objects is less informative. Motivated by this observation, we\npropose to apply adaptive resolution for different regions in the image\naccording to their importance. Specifically, at the intermediate layer of the\nViT, we utilize a spatial-aware density-based clustering algorithm to select\nrepresentative tokens from the token sequence. Once the representative tokens\nare determined, we proceed to merge other tokens into their closest\nrepresentative token. Consequently, semantic similar tokens are merged together\nto form low-resolution regions, while semantic irrelevant tokens are preserved\nindependently as high-resolution regions. This strategy effectively reduces the\nnumber of tokens, allowing subsequent layers to handle a reduced token sequence\nand achieve acceleration. We evaluate our proposed method on three different\ndatasets and observe promising performance. For example, the \"Segmenter ViT-L\"\nmodel can be accelerated by 48% FPS without fine-tuning, while maintaining the\nperformance. Additionally, our method can be applied to accelerate fine-tuning\nas well. Experimental results demonstrate that we can save 52% training time\nwhile accelerating 2.46 times FPS with only a 0.09% performance drop. The code\nis available at https://github.com/caddyless/ailurus/tree/main.",
            "author": [
                "Jin Li",
                "Yaoming Wang",
                "Xiaopeng Zhang",
                "Bowen Shi",
                "Dongsheng Jiang",
                "Chenglin Li",
                "Wenrui Dai",
                "Hongkai Xiong",
                "Qi Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01197v1",
                "http://arxiv.org/pdf/2311.01197v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01192v1",
            "title": "Semantic Scene Graph Generation Based on an Edge Dual Scene Graph and\n  Message Passing Neural Network",
            "updated": "2023-11-02T12:36:52Z",
            "published": "2023-11-02T12:36:52Z",
            "summary": "Along with generative AI, interest in scene graph generation (SGG), which\ncomprehensively captures the relationships and interactions between objects in\nan image and creates a structured graph-based representation, has significantly\nincreased in recent years. However, relying on object-centric and dichotomous\nrelationships, existing SGG methods have a limited ability to accurately\npredict detailed relationships. To solve these problems, a new approach to the\nmodeling multiobject relationships, called edge dual scene graph generation\n(EdgeSGG), is proposed herein. EdgeSGG is based on a edge dual scene graph and\nDual Message Passing Neural Network (DualMPNN), which can capture rich\ncontextual interactions between unconstrained objects. To facilitate the\nlearning of edge dual scene graphs with a symmetric graph structure, the\nproposed DualMPNN learns both object- and relation-centric features for more\naccurately predicting relation-aware contexts and allows fine-grained\nrelational updates between objects. A comparative experiment with\nstate-of-the-art (SoTA) methods was conducted using two public datasets for SGG\noperations and six metrics for three subtasks. Compared with SoTA approaches,\nthe proposed model exhibited substantial performance improvements across all\nSGG subtasks. Furthermore, experiment on long-tail distributions revealed that\nincorporating the relationships between objects effectively mitigates existing\nlong-tail problems.",
            "author": [
                "Hyeongjin Kim",
                "Sangwon Kim",
                "Jong Taek Lee",
                "Byoung Chul Ko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01192v1",
                "http://arxiv.org/pdf/2311.01192v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01188v1",
            "title": "Terrain-Informed Self-Supervised Learning: Enhancing Building Footprint\n  Extraction from LiDAR Data with Limited Annotations",
            "updated": "2023-11-02T12:34:23Z",
            "published": "2023-11-02T12:34:23Z",
            "summary": "Estimating building footprint maps from geospatial data is of paramount\nimportance in urban planning, development, disaster management, and various\nother applications. Deep learning methodologies have gained prominence in\nbuilding segmentation maps, offering the promise of precise footprint\nextraction without extensive post-processing. However, these methods face\nchallenges in generalization and label efficiency, particularly in remote\nsensing, where obtaining accurate labels can be both expensive and\ntime-consuming. To address these challenges, we propose terrain-aware\nself-supervised learning, tailored to remote sensing, using digital elevation\nmodels from LiDAR data. We propose to learn a model to differentiate between\nbare Earth and superimposed structures enabling the network to implicitly learn\ndomain-relevant features without the need for extensive pixel-level\nannotations. We test the effectiveness of our approach by evaluating building\nsegmentation performance on test datasets with varying label fractions.\nRemarkably, with only 1% of the labels (equivalent to 25 labeled examples), our\nmethod improves over ImageNet pre-training, showing the advantage of leveraging\nunlabeled data for feature extraction in the domain of remote sensing. The\nperformance improvement is more pronounced in few-shot scenarios and gradually\ncloses the gap with ImageNet pre-training as the label fraction increases. We\ntest on a dataset characterized by substantial distribution shifts and labeling\nerrors to demonstrate the generalizability of our approach. When compared to\nother baselines, including ImageNet pretraining and more complex architectures,\nour approach consistently performs better, demonstrating the efficiency and\neffectiveness of self-supervised terrain-aware feature learning.",
            "author": [
                "Anuja Vats",
                "David V\u00f6lgyes",
                "Martijn Vermeer",
                "Marius Pedersen",
                "Kiran Raja",
                "Daniele S. M. Fantin",
                "Jacob Alexander Hay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01188v1",
                "http://arxiv.org/pdf/2311.01188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01185v1",
            "title": "Revolutionizing Healthcare Image Analysis in Pandemic-Based Fog-Cloud\n  Computing Architectures",
            "updated": "2023-11-02T12:32:25Z",
            "published": "2023-11-02T12:32:25Z",
            "summary": "The emergence of pandemics has significantly emphasized the need for\neffective solutions in healthcare data analysis. One particular challenge in\nthis domain is the manual examination of medical images, such as X-rays and CT\nscans. This process is time-consuming and involves the logistical complexities\nof transferring these images to centralized cloud computing servers.\nAdditionally, the speed and accuracy of image analysis are vital for efficient\nhealthcare image management. This research paper introduces an innovative\nhealthcare architecture that tackles the challenges of analysis efficiency and\naccuracy by harnessing the capabilities of Artificial Intelligence (AI).\nSpecifically, the proposed architecture utilizes fog computing and presents a\nmodified Convolutional Neural Network (CNN) designed specifically for image\nanalysis. Different architectures of CNN layers are thoroughly explored and\nevaluated to optimize overall performance. To demonstrate the effectiveness of\nthe proposed approach, a dataset of X-ray images is utilized for analysis and\nevaluation. Comparative assessments are conducted against recent models such as\nVGG16, VGG19, MobileNet, and related research papers. Notably, the proposed\napproach achieves an exceptional accuracy rate of 99.88% in classifying normal\ncases, accompanied by a validation rate of 96.5%, precision and recall rates of\n100%, and an F1 score of 100%. These results highlight the immense potential of\nfog computing and modified CNNs in revolutionizing healthcare image analysis\nand diagnosis, not only during pandemics but also in the future. By leveraging\nthese technologies, healthcare professionals can enhance the efficiency and\naccuracy of medical image analysis, leading to improved patient care and\noutcomes.",
            "author": [
                "Al Zahraa Elsayed",
                "Khalil Mohamed",
                "Hany Harb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01185v1",
                "http://arxiv.org/pdf/2311.01185v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01184v1",
            "title": "A correspondence between the time and space complexity",
            "updated": "2023-11-02T12:31:27Z",
            "published": "2023-11-02T12:31:27Z",
            "summary": "We investigate the correspondence between the time and space recognition\ncomplexity of languages; for this purpose, we will code the long-continued\ncomputations of deterministic two-tape Turing machines by the relatively\nshort-length quantified Boolean formulae. The modified Stockmeyer and Meyer\nmethod will appreciably be used for this simulation. It will be proved using\nthis modeling that the complexity classes $\\mathbf{EXP}$ and $\\mathbf{PSPACE}$\ncoincide; and more generally, the class $(k\\!+\\!1)$-fold Deterministic\nExponential Time equals to the class $k$-fold Deterministic Exponential Space\nfor each $k\\geqslant1$; the space complexity of the languages of the class\n$\\mathbf{P}$ will also be studied. Furthermore, this allows us to slightly\nimprove the early founded lower complexity bound of decidable theories that are\nnontrivial relative to some equivalence relation (this relation may be\nequality) -- each of these theories is consistent with the formula, which\nasserts that there are two non-equivalent elements.\n  Keywords: computational complexity, the coding of computations through\nformulae, exponential time, polynomial space, lower complexity bound of the\nlanguage recognition",
            "author": [
                "Ivan V. Latkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01184v1",
                "http://arxiv.org/pdf/2311.01184v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.LO",
                "math.LO",
                "68Q15 (Primary), 68Q17, 03D15, 03B70 (Secondary)",
                "F.1.1; F.1.3; F.2.3; F.4.1; F.4.2; F.4.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01181v1",
            "title": "Enhanced Traffic Congestion Management with Fog Computing: A\n  Simulation-based Investigation using iFog-Simulator",
            "updated": "2023-11-02T12:23:26Z",
            "published": "2023-11-02T12:23:26Z",
            "summary": "Accurate latency computation is essential for the Internet of Things (IoT)\nsince the connected devices generate a vast amount of data that is processed on\ncloud infrastructure. However, the cloud is not an optimal solution. To\novercome this issue, fog computing is used to enable processing at the edge\nwhile still allowing communication with the cloud. Many applications rely on\nfog computing, including traffic management. In this paper, an Intelligent\nTraffic Congestion Mitigation System (ITCMS) is proposed to address traffic\ncongestion in heavily populated smart cities. The proposed system is\nimplemented using fog computing and tested in a crowded city. Its performance\nis evaluated based on multiple metrics, such as traffic efficiency, energy\nsavings, reduced latency, average traffic flow rate, and waiting time. The\nobtained results are compared with similar techniques that tackle the same\nissue. The results obtained indicate that the execution time of the simulation\nis 4,538 seconds, and the delay in the application loop is 49.67 seconds. The\npaper addresses various issues, including CPU usage, heap memory usage,\nthroughput, and the total average delay, which are essential for evaluating the\nperformance of the ITCMS. Our system model is also compared with other models\nto assess its performance. A comparison is made using two parameters, namely\nthroughput and the total average delay, between the ITCMS, IOV (Internet of\nVehicle), and STL (Seasonal-Trend Decomposition Procedure based on LOESS).\nConsequently, the results confirm that the proposed system outperforms the\nothers in terms of higher accuracy, lower latency, and improved traffic\nefficiency.",
            "author": [
                "Alzahraa Elsayed",
                "Khalil Mohamed",
                "Hany Harb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01181v1",
                "http://arxiv.org/pdf/2311.01181v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01180v1",
            "title": "Automatic Configuration of Multi-Agent Model Predictive Controllers\n  based on Semantic Graph World Models",
            "updated": "2023-11-02T12:23:08Z",
            "published": "2023-11-02T12:23:08Z",
            "summary": "We propose a shared semantic map architecture to construct and configure\nModel Predictive Controllers (MPC) dynamically, that solve navigation problems\nfor multiple robotic agents sharing parts of the same environment. The\nnavigation task is represented as a sequence of semantically labeled areas in\nthe map, that must be traversed sequentially, i.e. a route. Each semantic label\nrepresents one or more constraints on the robots' motion behaviour in that\narea. The advantages of this approach are: (i) an MPC-based motion controller\nin each individual robot can be (re-)configured, at runtime, with the locally\nand temporally relevant parameters; (ii) the application can influence, also at\nruntime, the navigation behaviour of the robots, just by adapting the semantic\nlabels; and (iii) the robots can reason about their need for coordination,\nthrough analyzing over which horizon in time and space their routes overlap.\nThe paper provides simulations of various representative situations, showing\nthat the approach of runtime configuration of the MPC drastically decreases\ncomputation time, while retaining task execution performance similar to an\napproach in which each robot always includes all other robots in its MPC\ncomputations.",
            "author": [
                "K. de Vos",
                "E. Torta",
                "H. Bruyninckx",
                "C. A. Lopez Martinez",
                "M. J. G. van de Molengraft"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01180v1",
                "http://arxiv.org/pdf/2311.01180v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01179v1",
            "title": "An Optimal Medium for Haptics",
            "updated": "2023-11-02T12:22:26Z",
            "published": "2023-11-02T12:22:26Z",
            "summary": "Humans rely on multimodal perception to form representations of the world.\nThis implies that environmental stimuli must remain consistent and predictable\nthroughout their journey to our sensory organs. When it comes to vision,\nelectromagnetic waves are minimally affected when passing through air or glass\ntreated for chromatic aberrations. Similar conclusions can be drawn for hearing\nand acoustic waves. However, tools that propagate elastic waves to our\ncutaneous afferents tend to color tactual perception due to parasitic\nmechanical attributes such as resonances and inertia. These issues are often\noverlooked, despite their critical importance for haptic devices that aim to\nfaithfully render or record tactile interactions. Here, we investigate how to\noptimize this mechanical transmission with sandwich structures made from rigid,\nlightweight carbon fiber sheets arranged around a 3D-printed lattice core.\nThrough a comprehensive parametric evaluation, we demonstrate that this design\nparadigm provides superior haptic transparency. Drawing an analogy with\ntopology optimization, our solution approaches a foreseeable technological\nlimit. This novel medium offers a practical way to create high-fidelity haptic\ninterfaces, opening new avenues for research on tool-mediated interactions.",
            "author": [
                "Thomas Daunizeau",
                "Sinan Haliyo",
                "Vincent Hayward"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01179v1",
                "http://arxiv.org/pdf/2311.01179v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01178v1",
            "title": "A Probabilistic Distance-Based Stability Quantifier for Complex\n  Dynamical Systems",
            "updated": "2023-11-02T12:21:40Z",
            "published": "2023-11-02T12:21:40Z",
            "summary": "For a dynamical system, an attractor of the system may represent the\n`desirable' state. Perturbations acting on the system may push the system out\nof the basin of attraction of the desirable attractor. Hence, it is important\nto study the stability of such systems against reasonably large perturbations.\nWe introduce a distance-based measure of stability, called `stability bound',\nto characterize the stability of dynamical systems against finite\nperturbations. This stability measure depends on the size and shape of the\nbasin of attraction of the desirable attractor. A probabilistic sampling-based\napproach is used to estimate stability bound and quantify the associated\nestimation error. An important feature of stability bound is that it is\nnumerically computable for any basin of attraction, including fractal basins.\nWe demonstrate the merit of this stability measure using an ecological model of\nthe Amazon rainforest, a ship capsize model, and a power grid model.",
            "author": [
                "Calvin Alvares",
                "Soumitro Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01178v1",
                "http://arxiv.org/pdf/2311.01178v1"
            ],
            "primary_category": "nlin.CD",
            "category": [
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01175v1",
            "title": "Synthesis of urea on the surface of interstellar water ice clusters. A\n  quantum chemical study",
            "updated": "2023-11-02T12:15:02Z",
            "published": "2023-11-02T12:15:02Z",
            "summary": "Urea is a prebiotic molecule that has been detected in few sources of the\ninterstellar medium (ISM) and in Murchison meteorite. Being stable against\nultraviolet radiation and high-energy electron bombardment, urea is expected to\nbe present in interstellar ices. Theoretical and experimental studies suggest\nthat isocyanic acid (HNCO) and formamide (NH$_2$CHO) are possible precursors of\nurea. However, uncertainties still exist regarding its formation routes.\nPrevious computational works characterised urea formation in the gas phase or\nin presence of few water molecules by reaction of formamide with\nnitrogen-bearing species. In this work, we investigated the reaction of HNCO +\nNH$_3$ on an 18 water molecules ice cluster model mimicking interstellar ice\nmantles by means of quantum chemical computations. We characterised different\nmechanisms involving both closed-shell and open-shell species at\nB3LYP-D3(BJ)/ma-def2-TZVP level of theory, in which the radical-radical\nH$_2$NCO + NH$_2$ coupling has been found to be the most favourable one due to\nbeing almost barrierless. In this path, the presence of the icy surfaces is\ncrucial for acting as reactant concentrators/suppliers, as well as third bodies\nable to dissipate the energy liberated during the urea formation.",
            "author": [
                "J. Perrero",
                "A. Rimola"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.icarus.2023.115848",
                "http://arxiv.org/abs/2311.01175v1",
                "http://arxiv.org/pdf/2311.01175v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01174v1",
            "title": "Online Multivariate Changepoint Detection: Leveraging Links With\n  Computational Geometry",
            "updated": "2023-11-02T12:13:59Z",
            "published": "2023-11-02T12:13:59Z",
            "summary": "The increasing volume of data streams poses significant computational\nchallenges for detecting changepoints online. Likelihood-based methods are\neffective, but their straightforward implementation becomes impractical online.\nWe develop two online algorithms that exactly calculate the likelihood ratio\ntest for a single changepoint in p-dimensional data streams by leveraging\nfascinating connections with computational geometry. Our first algorithm is\nstraightforward and empirically quasi-linear. The second is more complex but\nprovably quasi-linear: $\\mathcal{O}(n\\log(n)^{p+1})$ for $n$ data points.\nThrough simulations, we illustrate, that they are fast and allow us to process\nmillions of points within a matter of minutes up to $p=5$.",
            "author": [
                "Liudmila Pishchagina",
                "Gaetano Romano",
                "Paul Fearnhead",
                "Vincent Runge",
                "Guillem Rigaill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01174v1",
                "http://arxiv.org/pdf/2311.01174v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01173v1",
            "title": "CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL",
            "updated": "2023-11-02T12:13:52Z",
            "published": "2023-11-02T12:13:52Z",
            "summary": "Existing Text-to-SQL generators require the entire schema to be encoded with\nthe user text. This is expensive or impractical for large databases with tens\nof thousands of columns. Standard dense retrieval techniques are inadequate for\nschema subsetting of a large structured database, where the correct semantics\nof retrieval demands that we rank sets of schema elements rather than\nindividual elements. In response, we propose a two-stage process for effective\ncoverage during retrieval. First, we instruct an LLM to hallucinate a minimal\nDB schema deemed adequate to answer the query. We use the hallucinated schema\nto retrieve a subset of the actual schema, by composing the results from\nmultiple dense retrievals. Remarkably, hallucination $\\unicode{x2013}$\ngenerally considered a nuisance $\\unicode{x2013}$ turns out to be actually\nuseful as a bridging mechanism. Since no existing benchmarks exist for schema\nsubsetting on large databases, we introduce three benchmarks. Two\nsemi-synthetic datasets are derived from the union of schemas in two well-known\ndatasets, SPIDER and BIRD, resulting in 4502 and 798 schema elements\nrespectively. A real-life benchmark called SocialDB is sourced from an actual\nlarge data warehouse comprising 17844 schema elements. We show that our method1\nleads to significantly higher recall than SOTA retrieval-based augmentation\nmethods.",
            "author": [
                "Mayank Kothyari",
                "Dhruva Dhingra",
                "Sunita Sarawagi",
                "Soumen Chakrabarti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01173v1",
                "http://arxiv.org/pdf/2311.01173v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01171v1",
            "title": "Memristor-based hardware and algorithms for higher-order Hopfield\n  optimization solver outperforming quadratic Ising machines",
            "updated": "2023-11-02T12:09:20Z",
            "published": "2023-11-02T12:09:20Z",
            "summary": "Ising solvers offer a promising physics-based approach to tackle the\nchallenging class of combinatorial optimization problems. However, typical\nsolvers operate in a quadratic energy space, having only pair-wise coupling\nelements which already dominate area and energy. We show that such\nquadratization can cause severe problems: increased dimensionality, a rugged\nsearch landscape, and misalignment with the original objective function. Here,\nwe design and quantify a higher-order Hopfield optimization solver, with 28nm\nCMOS technology and memristive couplings for lower area and energy\ncomputations. We combine algorithmic and circuit analysis to show quantitative\nadvantages over quadratic Ising Machines (IM)s, yielding 48x and 72x reduction\nin time-to-solution (TTS) and energy-to-solution (ETS) respectively for Boolean\nsatisfiability problems of 150 variables, with favorable scaling.",
            "author": [
                "Mohammad Hizzani",
                "Arne Heittmann",
                "George Hutchinson",
                "Dmitrii Dobrynin",
                "Thomas Van Vaerenbergh",
                "Tinish Bhattacharya",
                "Adrien Renaudineau",
                "Dmitri Strukov",
                "John Paul Strachan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01171v1",
                "http://arxiv.org/pdf/2311.01171v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01169v1",
            "title": "Resource-aware Research on Universe and Matter: Call-to-Action in\n  Digital Transformation",
            "updated": "2023-11-02T12:07:35Z",
            "published": "2023-11-02T12:07:35Z",
            "summary": "Given the urgency to reduce fossil fuel energy production to make climate\ntipping points less likely, we call for resource-aware knowledge gain in the\nresearch areas on Universe and Matter with emphasis on the digital\ntransformation. A portfolio of measures is described in detail and then\nsummarized according to the timescales required for their implementation. The\nmeasures will both contribute to sustainable research and accelerate scientific\nprogress through increased awareness of resource usage. This work is based on a\nthree-days workshop on sustainability in digital transformation held in May\n2023.",
            "author": [
                "Ben Bruers",
                "Marilyn Cruces",
                "Markus Demleitner",
                "Guenter Duckeck",
                "Michael D\u00fcren",
                "Niclas Eich",
                "Torsten En\u00dflin",
                "Johannes Erdmann",
                "Martin Erdmann",
                "Peter Fackeldey",
                "Christian Felder",
                "Benjamin Fischer",
                "Stefan Fr\u00f6se",
                "Stefan Funk",
                "Martin Gasthuber",
                "Andrew Grimshaw",
                "Daniela Hadasch",
                "Moritz Hannemann",
                "Alexander Kappes",
                "Raphael Kleinem\u00fchl",
                "Oleksiy M. Kozlov",
                "Thomas Kuhr",
                "Michael Lupberger",
                "Simon Neuhaus",
                "Pardis Niknejadi",
                "Judith Reindl",
                "Daniel Schindler",
                "Astrid Schneidewind",
                "Frank Schreiber",
                "Markus Schumacher",
                "Kilian Schwarz",
                "Achim Streit",
                "R. Florian von Cube",
                "Rod Walker",
                "Cyrus Walther",
                "Sebastian Wozniewski",
                "Kai Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01169v1",
                "http://arxiv.org/pdf/2311.01169v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "astro-ph.IM",
                "cond-mat.mtrl-sci",
                "hep-ex",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01168v1",
            "title": "Scalable architecture for trapped-ion quantum computing using RF traps\n  and dynamic optical potentials",
            "updated": "2023-11-02T12:06:49Z",
            "published": "2023-11-02T12:06:49Z",
            "summary": "Qubits based on ions trapped in linear radio-frequency traps form a\nsuccessful platform for quantum computing, due to their high-fidelity of\noperations, all-to-all connectivity and degree of local control. In principle\nthere is no fundamental limit to the number of ion-based qubits that can be\nconfined in a single 1d register. However, in practice there are two main\nissues associated with long trapped ion-crystals, that stem from the\n'softening' of their modes of motion, upon scaling up: high heating rates of\nthe ions' motion, and a dense motional spectrum; both impede the performance of\nhigh-fidelity qubit operations. Here we propose a holistic, scalable\narchitecture for quantum computing with large ion-crystals that overcomes these\nissues. Our method relies on dynamically-operated optical potentials, that\ninstantaneously segment the ion-crystal into cells of a manageable size. We\nshow that these cells behave as nearly independent quantum registers, allowing\nfor parallel entangling gates on all cells. The ability to reconfigure the\noptical potentials guarantees connectivity across the full ion-crystal, and\nalso enables efficient mid-circuit measurements. We study the implementation of\nlarge-scale parallel multi-qubit entangling gates that operate simultaneously\non all cells, and present a protocol to compensate for crosstalk errors,\nenabling full-scale usage of an extensively large register. We illustrate that\nthis architecture is advantageous both for fault-tolerant digital quantum\ncomputation and for analog quantum simulations.",
            "author": [
                "David Schwerdt",
                "Lee Peleg",
                "Yotam Shapira",
                "Nadav Priel",
                "Yanay Florshaim",
                "Avram Gross",
                "Ayelet Zalic",
                "Gadi Afek",
                "Nitzan Akerman",
                "Ady Stern",
                "Amit Ben Kish",
                "Roee Ozeri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01168v1",
                "http://arxiv.org/pdf/2311.01168v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01166v1",
            "title": "Generative Input: Towards Next-Generation Input Methods Paradigm",
            "updated": "2023-11-02T12:01:29Z",
            "published": "2023-11-02T12:01:29Z",
            "summary": "Since the release of ChatGPT, generative models have achieved tremendous\nsuccess and become the de facto approach for various NLP tasks. However, its\napplication in the field of input methods remains under-explored. Many neural\nnetwork approaches have been applied to the construction of Chinese input\nmethod engines(IMEs).Previous research often assumed that the input pinyin was\ncorrect and focused on Pinyin-to-character(P2C) task, which significantly falls\nshort of meeting users' demands. Moreover, previous research could not leverage\nuser feedback to optimize the model and provide personalized results. In this\nstudy, we propose a novel Generative Input paradigm named GeneInput. It uses\nprompts to handle all input scenarios and other intelligent auxiliary input\nfunctions, optimizing the model with user feedback to deliver personalized\nresults. The results demonstrate that we have achieved state-of-the-art\nperformance for the first time in the Full-mode Key-sequence to\nCharacters(FK2C) task. We propose a novel reward model training method that\neliminates the need for additional manual annotations and the performance\nsurpasses GPT-4 in tasks involving intelligent association and conversational\nassistance. Compared to traditional paradigms, GeneInput not only demonstrates\nsuperior performance but also exhibits enhanced robustness, scalability, and\nonline learning capabilities.",
            "author": [
                "Keyu Ding",
                "Yongcan Wang",
                "Zihang Xu",
                "Zhenzhen Jia",
                "Shijin Wang",
                "Cong Liu",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01166v1",
                "http://arxiv.org/pdf/2311.01166v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01482v1",
            "title": "Quantum theory of a harmonic oscillator in a time dependent\n  noncommutative background",
            "updated": "2023-11-02T11:56:57Z",
            "published": "2023-11-02T11:56:57Z",
            "summary": "This work explores the behaviour of a noncommutative harmonic oscillator in a\ntime-dependent background, as previously investigated by Dey {\\it et\nal.}\\,\\cite{Dey}. Specifically, we examine the system when expressed in terms\nof commutative variables, utilizing a generalized form of the standard\nBopp-shift relations recently introduced by \\cite{spb}. We solved the time\ndependent system and obtained the analytical form of the eigenfunction using\nLewis' method of invariants, which is associated with the Ermakov-Pinney\nequation, a non-linear differential equation. We then explicitly provided the\nexact analytical solution set for the Ermakov-Pinney equation. Then, we\ncomputed the dynamics of the energy expectation value analytically and explored\ntheir graphical representations for various solution sets of the Ermakov-Pinney\nequation, associated with a particular choice of quantum number. Finally, we\ndetermined the generalized form of the uncertainty equality relations among the\noperators for both commutative and noncommutative cases. Expectedly, our study\nis consistent with the findings in \\cite{Dey}, specifically in a particular\nlimit where the coordinate mapping relations reduce to the standard Bopp-shift\nrelations.",
            "author": [
                "Manjari Dutta",
                "Shreemoyee Ganguly",
                "Sunandan Gangopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01482v1",
                "http://arxiv.org/pdf/2311.01482v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01165v1",
            "title": "Chandrasekhar-based maximum correntropy Kalman filtering with the\n  adaptive kernel size selection",
            "updated": "2023-11-02T11:55:35Z",
            "published": "2023-11-02T11:55:35Z",
            "summary": "This technical note is aimed to derive the Chandrasekhar-type recursion for\nthe maximum correntropy criterion (MCC) Kalman filtering (KF). For the\nclassical KF, the first Chandrasekhar difference equation was proposed at the\nbeginning of 1970s. This is the alternative to the traditionally used Riccati\nrecursion and it yields the so-called fast implementations known as the\nMorf-Sidhu-Kailath-Sayed KF algorithms. They are proved to be computationally\ncheap because of propagating the matrices of a smaller size than $n \\times n$\nerror covariance matrix in the Riccati recursion. The problem of deriving the\nChandrasekhar-type recursion within the MCC estimation methodology has never\nbeen raised yet in engineering literature. In this technical note, we do the\nfirst step and derive the Chandrasekhar MCC-KF estimators for the case of\nadaptive kernel size selection strategy, which implies a constant scalar\nadjusting weight. Numerical examples substantiate a practical feasibility of\nthe newly suggested MCC-KF implementations and correctness of the presented\ntheoretical derivations.",
            "author": [
                "Maria Kulikova"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TAC.2019.2919341",
                "http://arxiv.org/abs/2311.01165v1",
                "http://arxiv.org/pdf/2311.01165v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02107v1",
            "title": "Generative Artificial Intelligence in Healthcare: Ethical Considerations\n  and Assessment Checklist",
            "updated": "2023-11-02T11:55:07Z",
            "published": "2023-11-02T11:55:07Z",
            "summary": "The widespread use of ChatGPT and other emerging technology powered by\ngenerative artificial intelligence (AI) has drawn much attention to potential\nethical issues, especially in high-stakes applications such as healthcare.\nHowever, less clear is how to resolve such issues beyond following guidelines\nand regulations that are still under discussion and development. On the other\nhand, other types of generative AI have been used to synthesize images and\nother types of data for research and practical purposes, which have resolved\nsome ethical issues and exposed other ethical issues, but such technology is\nless often the focus of ongoing ethical discussions. Here we highlight gaps in\ncurrent ethical discussions of generative AI via a systematic scoping review of\nrelevant existing research in healthcare, and reduce the gaps by proposing an\nethics checklist for comprehensive assessment and transparent documentation of\nethical discussions in generative AI development. While the checklist can be\nreadily integrated into the current peer review and publication system to\nenhance generative AI research, it may also be used in broader settings to\ndisclose ethics-related considerations in generative AI-powered products (or\nreal-life applications of such products) to help users establish reasonable\ntrust in their capabilities.",
            "author": [
                "Yilin Ning",
                "Salinelat Teixayavong",
                "Yuqing Shang",
                "Julian Savulescu",
                "Vaishaanth Nagaraj",
                "Di Miao",
                "Mayli Mertens",
                "Daniel Shu Wei Ting",
                "Jasmine Chiat Ling Ong",
                "Mingxuan Liu",
                "Jiuwen Cao",
                "Michael Dunn",
                "Roger Vaughan",
                "Marcus Eng Hock Ong",
                "Joseph Jao-Yiu Sung",
                "Eric J Topol",
                "Nan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02107v1",
                "http://arxiv.org/pdf/2311.02107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01161v1",
            "title": "Weakly Supervised Semantic Parsing with Execution-based Spurious Program\n  Filtering",
            "updated": "2023-11-02T11:45:40Z",
            "published": "2023-11-02T11:45:40Z",
            "summary": "The problem of spurious programs is a longstanding challenge when training a\nsemantic parser from weak supervision. To eliminate such programs that have\nwrong semantics but correct denotation, existing methods focus on exploiting\nsimilarities between examples based on domain-specific knowledge. In this\npaper, we propose a domain-agnostic filtering mechanism based on program\nexecution results. Specifically, for each program obtained through the search\nprocess, we first construct a representation that captures the program's\nsemantics as execution results under various inputs. Then, we run a majority\nvote on these representations to identify and filter out programs with\nsignificantly different semantics from the other programs. In particular, our\nmethod is orthogonal to the program search process so that it can easily\naugment any of the existing weakly supervised semantic parsing frameworks.\nEmpirical evaluations on the Natural Language Visual Reasoning and\nWikiTableQuestions demonstrate that applying our method to the existing\nsemantic parsers induces significantly improved performances.",
            "author": [
                "Kang-il Lee",
                "Segwang Kim",
                "Kyomin Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01161v1",
                "http://arxiv.org/pdf/2311.01161v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01157v1",
            "title": "The Repeating Flaring Activity of Blazar AO 0235+164",
            "updated": "2023-11-02T11:36:26Z",
            "published": "2023-11-02T11:36:26Z",
            "summary": "Context. Blazar AO 0235+164, located at redshift z = 0.94, has undergone\nseveral sharp multi-spectral-range flaring episodes during the last decades. In\nparticular, the episodes peaking in 2008 and 2015, that received extensive\nmulti-wavelength coverage, exhibited interesting behavior.\n  Aims. We study the actual origin of these two observed flares by constraining\nthe properties of the observed photo-polarimetric variability, those of the\nbroad-band spectral energy-distribution and the observed time-evolution\nbehavior of the source as seen by ultra-high resolution total-flux and\npolarimetric Very-long-baseline interferometry (VLBI) imaging.\n  Methods. The analysis of VLBI images allows us to constrain kinematic and\ngeometrical parameters of the 7 mm jet. We use the Discrete Correlation\nFunction to compute the statistical correlation and the delays between emission\nat different spectral ranges. Multi-epoch modeling of the spectral energy\ndistributions allows us to propose specific models of emission; in particular\nfor the unusual spectral features observed in this source in the X-ray region\nof the spectrum during strong multi spectral-range flares.\n  Results. We find that these X-ray spectral features can be explained by an\nemission component originating in a separate particle distribution than the one\nresponsible for the two standard blazar bumps. This is in agreement with the\nresults of our correlation analysis that do not find a strong correlation\nbetween the X-rays and the remaining spectral ranges. We find that both\nexternal Compton dominated and synchrotron self-Compton dominated models can\nexplain the observed spectral energy distributions. However, synchrotron\nself-Compton models are strongly favored by the delays and geometrical\nparameters inferred from the observations.",
            "author": [
                "Juan Escudero Pedrosa",
                "Iv\u00e1n Agudo",
                "Andrea Tramacere",
                "Alan P. Marscher",
                "Svetlana Jorstad",
                "Z. R. Weaver",
                "Carolina Casadio",
                "Clemens Thum",
                "Ioannis Myserlis",
                "Antonio Fuentes",
                "Efthalia Traianou",
                "Jae-Young Kim",
                "Joana Kramer",
                "Rub\u00e9n L\u00f3pez-Coto",
                "Filippo D'Ammando",
                "M. Bernardos",
                "Giacomo Bonnoli",
                "Dmitriy A. Blinov",
                "G. A. Borman",
                "T. S. Grishina",
                "V. A. Hagen-Thorn",
                "E. N. Kopatskaya",
                "E. G. Larionova",
                "V. M. Larionov",
                "L. V. Larionova",
                "D. A. Morozova",
                "S. S. Savchenko",
                "I. S. Troitskiy",
                "Y. V. Troitskaya",
                "A. A. Vasilyev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01157v1",
                "http://arxiv.org/pdf/2311.01157v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01156v1",
            "title": "Several Consequences of Optimality",
            "updated": "2023-11-02T11:33:51Z",
            "published": "2023-11-02T11:33:51Z",
            "summary": "Rationality is frequently associated with making the best possible decisions.\nIt's widely acknowledged that humans, as rational beings, have limitations in\ntheir decision-making capabilities. Nevertheless, recent advancements in\nfields, such as, computing, science and technology, combined with the\navailability of vast amounts of data, have sparked optimism that these\ndevelopments could potentially expand the boundaries of human bounded\nrationality through the augmentation of machine intelligence. In this paper,\nfindings from a computational model demonstrated that when an increasing number\nof agents independently strive to achieve global optimality, facilitated by\nimproved computing power, etc., they indirectly accelerated the occurrence of\nthe \"tragedy of the commons\" by depleting shared resources at a faster rate.\nFurther, as agents achieve optimality, there is a drop in information entropy\namong the solutions of the agents. Also, clear economic divide emerges among\nagents. Considering, two groups, one as producer and the other (the group\nagents searching for optimality) as consumer of the highest consumed resource,\nthe consumers seem to gain more than the producers. Thus, bounded rationality\ncould be seen as boon to sustainability.",
            "author": [
                "Dibakar Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01156v1",
                "http://arxiv.org/pdf/2311.01156v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01155v1",
            "title": "Learning Intra and Inter-Camera Invariance for Isolated Camera\n  Supervised Person Re-identification",
            "updated": "2023-11-02T11:32:40Z",
            "published": "2023-11-02T11:32:40Z",
            "summary": "Supervised person re-identification assumes that a person has images captured\nunder multiple cameras. However when cameras are placed in distance, a person\nrarely appears in more than one camera. This paper thus studies person re-ID\nunder such isolated camera supervised (ISCS) setting. Instead of trying to\ngenerate fake cross-camera features like previous methods, we explore a novel\nperspective by making efficient use of the variation in training data. Under\nISCS setting, a person only has limited images from a single camera, so the\ncamera bias becomes a critical issue confounding ID discrimination.\nCross-camera images are prone to being recognized as different IDs simply by\ncamera style. To eliminate the confounding effect of camera bias, we propose to\nlearn both intra- and inter-camera invariance under a unified framework. First,\nwe construct style-consistent environments via clustering, and perform\nprototypical contrastive learning within each environment. Meanwhile, strongly\naugmented images are contrasted with original prototypes to enforce\nintra-camera augmentation invariance. For inter-camera invariance, we further\ndesign a much improved variant of multi-camera negative loss that optimizes the\ndistance of multi-level negatives. The resulting model learns to be invariant\nto both subtle and severe style variation within and cross-camera. On multiple\nbenchmarks, we conduct extensive experiments and validate the effectiveness and\nsuperiority of the proposed method. Code will be available at\nhttps://github.com/Terminator8758/IICI.",
            "author": [
                "Menglin Wang",
                "Xiaojin Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01155v1",
                "http://arxiv.org/pdf/2311.01155v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01153v1",
            "title": "ACES: Translation Accuracy Challenge Sets at WMT 2023",
            "updated": "2023-11-02T11:29:09Z",
            "published": "2023-11-02T11:29:09Z",
            "summary": "We benchmark the performance of segmentlevel metrics submitted to WMT 2023\nusing the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists\nof 36K examples representing challenges from 68 phenomena and covering 146\nlanguage pairs. The phenomena range from simple perturbations at the\nword/character level to more complex errors based on discourse and real-world\nknowledge. For each metric, we provide a detailed profile of performance over a\nrange of error categories as well as an overall ACES-Score for quick\ncomparison. We also measure the incremental performance of the metrics\nsubmitted to both WMT 2023 and 2022. We find that 1) there is no clear winner\namong the metrics submitted to WMT 2023, and 2) performance change between the\n2023 and 2022 versions of the metrics is highly variable. Our recommendations\nare similar to those from WMT 2022. Metric developers should focus on: building\nensembles of metrics from different design families, developing metrics that\npay more attention to the source and rely less on surface-level overlap, and\ncarefully determining the influence of multilingual embeddings on MT\nevaluation.",
            "author": [
                "Chantal Amrhein",
                "Nikita Moghe",
                "Liane Guillou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01153v1",
                "http://arxiv.org/pdf/2311.01153v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01152v1",
            "title": "Predicting Question-Answering Performance of Large Language Models\n  through Semantic Consistency",
            "updated": "2023-11-02T11:27:21Z",
            "published": "2023-11-02T11:27:21Z",
            "summary": "Semantic consistency of a language model is broadly defined as the model's\nability to produce semantically-equivalent outputs, given\nsemantically-equivalent inputs. We address the task of assessing\nquestion-answering (QA) semantic consistency of contemporary large language\nmodels (LLMs) by manually creating a benchmark dataset with high-quality\nparaphrases for factual questions, and release the dataset to the community.\n  We further combine the semantic consistency metric with additional\nmeasurements suggested in prior work as correlating with LLM QA accuracy, for\nbuilding and evaluating a framework for factual QA reference-less performance\nprediction -- predicting the likelihood of a language model to accurately\nanswer a question. Evaluating the framework on five contemporary LLMs, we\ndemonstrate encouraging, significantly outperforming baselines, results.",
            "author": [
                "Ella Rabinovich",
                "Samuel Ackerman",
                "Orna Raz",
                "Eitan Farchi",
                "Ateret Anaby-Tavor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01152v1",
                "http://arxiv.org/pdf/2311.01152v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01150v1",
            "title": "Revisiting the Knowledge Injection Frameworks",
            "updated": "2023-11-02T11:18:16Z",
            "published": "2023-11-02T11:18:16Z",
            "summary": "In recent years, large language models (LLMs), such as GPTs, have attained\ngreat impact worldwide. However, how to adapt these LLMs to better suit the\nvertical domain-specific tasks by utilizing external knowledge remains not\ncompletely solved. Indeed, there have emerged a few works on this line where\nmost of them rely on an alignment heuristic that is built to inject the\ncorresponding knowledge tuple into the associated text sample.\n  However, despite the promise, we identify a pivotal problem in this work\nubiquitously. Simply put, we find that injecting unaligned (i.e., random)\nknowledge tuple into the LLMs achieves comparable (and sometimes better)\nresults than the aligned knowledge being injected. We therefore take a thorough\ninvestigation of this frustrating finding on a variety of related prior work\nand further provide a chain of potential interpretations for the phenomenon.\nBased on all that, we offer a simple remediated technique. Briefly, the core of\nthis technique is rooted in an ideological emphasis on the pruning and\npurification of the external knowledge base to be injected into LLMs. At last,\nwe show that by integrating this technique into most (if not all) knowledge\ninjection frameworks and recent LLMs, it manages to overcome the aforementioned\nsanity problem and further pushes the boundary of the performance of the\ndomain-adaptive LLMs.",
            "author": [
                "Peng Fu",
                "Yiming Zhang",
                "Haobo Wang",
                "Weikang Qiu",
                "Junbo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01150v1",
                "http://arxiv.org/pdf/2311.01150v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01149v2",
            "title": "ChineseWebText: Large-scale High-quality Chinese Web Text Extracted with\n  Effective Evaluation Model",
            "updated": "2023-11-10T06:28:48Z",
            "published": "2023-11-02T11:13:51Z",
            "summary": "During the development of large language models (LLMs), the scale and quality\nof the pre-training data play a crucial role in shaping LLMs' capabilities. To\naccelerate the research of LLMs, several large-scale datasets, such as C4 [1],\nPile [2], RefinedWeb [3] and WanJuan [4], have been released to the public.\nHowever, most of the released corpus focus mainly on English, and there is\nstill lack of complete tool-chain for extracting clean texts from web data.\nFurthermore, fine-grained information of the corpus, e.g. the quality of each\ntext, is missing. To address these challenges, we propose in this paper a new\ncomplete tool-chain EvalWeb to extract Chinese clean texts from noisy web data.\nFirst, similar to previous work, manually crafted rules are employed to discard\nexplicit noisy texts from the raw crawled web contents. Second, a well-designed\nevaluation model is leveraged to assess the remaining relatively clean data,\nand each text is assigned a specific quality score. Finally, we can easily\nutilize an appropriate threshold to select the high-quality pre-training data\nfor Chinese. Using our proposed approach, we release the largest and latest\nlarge-scale high-quality Chinese web text ChineseWebText, which consists of\n1.42 TB and each text is associated with a quality score, facilitating the LLM\nresearchers to choose the data according to the desired quality thresholds. We\nalso release a much cleaner subset of 600 GB Chinese data with the quality\nexceeding 90%.",
            "author": [
                "Jianghao Chen",
                "Pu Jian",
                "Tengxiao Xi",
                "Dongyi Yi",
                "Qianlong Du",
                "Chenglin Ding",
                "Guibo Zhu",
                "Chengqing Zong",
                "Jinqiao Wang",
                "Jiajun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01149v2",
                "http://arxiv.org/pdf/2311.01149v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01147v1",
            "title": "Variational Inference for Sparse Poisson Regression",
            "updated": "2023-11-02T11:04:02Z",
            "published": "2023-11-02T11:04:02Z",
            "summary": "We have utilized the non-conjugate VB method for the problem of the sparse\nPoisson regression model. To provide an approximated conjugacy in the model,\nthe likelihood is approximated by a quadratic function, which provides the\nconjugacy of the approximation component with the Gaussian prior to the\nregression coefficient. Three sparsity-enforcing priors are used for this\nproblem. The proposed models are compared with each other and two frequentist\nsparse Poisson methods (LASSO and SCAD) to evaluate the prediction performance,\nas well as, the sparsing performance of the proposed methods. Throughout a\nsimulated data example, the accuracy of the VB methods is computed compared to\nthe corresponding benchmark MCMC methods. It can be observed that the proposed\nVB methods have provided a good approximation to the posterior distribution of\nthe parameters, while the VB methods are much faster than the MCMC ones. Using\nseveral benchmark count response data sets, the prediction performance of the\nproposed methods is evaluated in real-world applications.",
            "author": [
                "Mitra Kharabati",
                "Morteza Amini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01147v1",
                "http://arxiv.org/pdf/2311.01147v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01138v1",
            "title": "AeroPath: An airway segmentation benchmark dataset with challenging\n  pathology",
            "updated": "2023-11-02T10:41:42Z",
            "published": "2023-11-02T10:41:42Z",
            "summary": "To improve the prognosis of patients suffering from pulmonary diseases, such\nas lung cancer, early diagnosis and treatment are crucial. The analysis of CT\nimages is invaluable for diagnosis, whereas high quality segmentation of the\nairway tree are required for intervention planning and live guidance during\nbronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATM'22)\nchallenge released a large dataset, both enabling training of deep-learning\nbased models and bringing substantial improvement of the state-of-the-art for\nthe airway segmentation task. However, the ATM'22 dataset includes few patients\nwith severe pathologies affecting the airway tree anatomy. In this study, we\nintroduce a new public benchmark dataset (AeroPath), consisting of 27 CT images\nfrom patients with pathologies ranging from emphysema to large tumors, with\ncorresponding trachea and bronchi annotations. Second, we present a multiscale\nfusion design for automatic airway segmentation. Models were trained on the\nATM'22 dataset, tested on the AeroPath dataset, and further evaluated against\ncompetitive open-source methods. The same performance metrics as used in the\nATM'22 challenge were used to benchmark the different considered approaches.\nLastly, an open web application is developed, to easily test the proposed model\non new data. The results demonstrated that our proposed architecture predicted\ntopologically correct segmentations for all the patients included in the\nAeroPath dataset. The proposed method is robust and able to handle various\nanomalies, down to at least the fifth airway generation. In addition, the\nAeroPath dataset, featuring patients with challenging pathologies, will\ncontribute to development of new state-of-the-art methods. The AeroPath dataset\nand the web application are made openly available.",
            "author": [
                "Karen-Helene St\u00f8verud",
                "David Bouget",
                "Andre Pedersen",
                "H\u00e5kon Olav Leira",
                "Thomas Lang\u00f8",
                "Erlend Fagertun Hofstad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01138v1",
                "http://arxiv.org/pdf/2311.01138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01135v1",
            "title": "Generating QM1B with PySCF$_{\\text{IPU}}$",
            "updated": "2023-11-02T10:31:20Z",
            "published": "2023-11-02T10:31:20Z",
            "summary": "The emergence of foundation models in Computer Vision and Natural Language\nProcessing have resulted in immense progress on downstream tasks. This progress\nwas enabled by datasets with billions of training examples. Similar benefits\nare yet to be unlocked for quantum chemistry, where the potential of deep\nlearning is constrained by comparatively small datasets with 100k to 20M\ntraining examples. These datasets are limited in size because the labels are\ncomputed using the accurate (but computationally demanding) predictions of\nDensity Functional Theory (DFT). Notably, prior DFT datasets were created using\nCPU supercomputers without leveraging hardware acceleration. In this paper, we\ntake a first step towards utilising hardware accelerators by introducing the\ndata generator PySCF$_{\\text{IPU}}$ using Intelligence Processing Units (IPUs).\nThis allowed us to create the dataset QM1B with one billion training examples\ncontaining 9-11 heavy atoms. We demonstrate that a simple baseline neural\nnetwork (SchNet 9M) improves its performance by simply increasing the amount of\ntraining data without additional inductive biases. To encourage future\nresearchers to use QM1B responsibly, we highlight several limitations of QM1B\nand emphasise the low-resolution of our DFT options, which also serves as\nmotivation for even larger, more accurate datasets. Code and dataset are\navailable on Github: http://github.com/graphcore-research/pyscf-ipu",
            "author": [
                "Alexander Mathiasen",
                "Hatem Helal",
                "Kerstin Klaser",
                "Paul Balanca",
                "Josef Dean",
                "Carlo Luschi",
                "Dominique Beaini",
                "Andrew Fitzgibbon",
                "Dominic Masters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01135v1",
                "http://arxiv.org/pdf/2311.01135v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "I.2.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01134v1",
            "title": "Precise predictions for the trilinear Higgs self-coupling in the\n  Standard Model and beyond",
            "updated": "2023-11-02T10:30:05Z",
            "published": "2023-11-02T10:30:05Z",
            "summary": "Deviations in the trilinear self-coupling of the Higgs boson at 125 GeV from\nthe Standard Model (SM) prediction are a sensitive test of physics Beyond the\nSM (BSM). The LHC experiments searching for the simultaneous production of two\nHiggs bosons start to become sensitive to such deviations. Therefore, precise\npredictions for the trilinear Higgs self-coupling in different BSM models are\nrequired in order to be able to test them against current and future bounds. We\npresent the new framework $\\texttt{anyH3}$, which is a $\\texttt{Python}$\nlibrary that can be utilized to obtain predictions for trilinear scalar\ncouplings up to the one-loop level in any renormalisable theory. The program\nmakes use of the $\\texttt{UFO}$ format as input and is able to automatically\napply a wide variety of renormalisation schemes involving minimal and\nnon-minimal subtraction conditions. External-leg corrections are also computed\nautomatically, and finite external momenta can be optionally taken into\naccount. The $\\texttt{Python}$ library comes with convenient command-line as\nwell as $\\texttt{Mathematica}$ user interfaces. We perform cross-checks using\nconsistency conditions such as UV-finiteness and decoupling, and also by\ncomparing against results know in the literature. As example applications, we\nobtain results for the trilinear self-coupling of the SM-like Higgs boson in\nvarious concrete BSM models, study the effect of external momenta as well as of\ndifferent renormalisation schemes.",
            "author": [
                "Henning Bahl",
                "Johannes Braathen",
                "Martin Gabelmann",
                "Georg Weiglein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01134v1",
                "http://arxiv.org/pdf/2311.01134v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01130v1",
            "title": "A deep learning experiment for semantic segmentation of overlapping\n  characters in palimpsests",
            "updated": "2023-11-02T10:25:47Z",
            "published": "2023-11-02T10:25:47Z",
            "summary": "Palimpsests refer to historical manuscripts where erased writings have been\npartially covered by the superimposition of a second writing. By employing\nimaging techniques, e.g., multispectral imaging, it becomes possible to\nidentify features that are imperceptible to the naked eye, including faded and\nerased inks. When dealing with overlapping inks, Artificial Intelligence\ntechniques can be utilized to disentangle complex nodes of overlapping letters.\nIn this work, we propose deep learning-based semantic segmentation as a method\nfor identifying and segmenting individual letters in overlapping characters.\nThe experiment was conceived as a proof of concept, focusing on the palimpsests\nof the Ars Grammatica by Prisciano as a case study. Furthermore, caveats and\nprospects of our approach combined with multispectral imaging are also\ndiscussed.",
            "author": [
                "Michela Perino",
                "Michele Ginolfi",
                "Anna Candida Felici",
                "Michela Rosellini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01130v1",
                "http://arxiv.org/pdf/2311.01130v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01129v1",
            "title": "Constrained Submodular Maximization via New Bounds for DR-Submodular\n  Functions",
            "updated": "2023-11-02T10:22:08Z",
            "published": "2023-11-02T10:22:08Z",
            "summary": "Submodular maximization under various constraints is a fundamental problem\nstudied continuously, in both computer science and operations research, since\nthe late $1970$'s. A central technique in this field is to approximately\noptimize the multilinear extension of the submodular objective, and then round\nthe solution. The use of this technique requires a solver able to approximately\nmaximize multilinear extensions. Following a long line of work, Buchbinder and\nFeldman (2019) described such a solver guaranteeing $0.385$-approximation for\ndown-closed constraints, while Oveis Gharan and Vondr\\'ak (2011) showed that no\nsolver can guarantee better than $0.478$-approximation. In this paper, we\npresent a solver guaranteeing $0.401$-approximation, which significantly\nreduces the gap between the best known solver and the inapproximability result.\nThe design and analysis of our solver are based on a novel bound that we prove\nfor DR-submodular functions. This bound improves over a previous bound due to\nFeldman et al. (2011) that is used by essentially all state-of-the-art results\nfor constrained maximization of general submodular/DR-submodular functions.\nHence, we believe that our new bound is likely to find many additional\napplications in related problems, and to be a key component for further\nimprovement.",
            "author": [
                "Niv Buchbinder",
                "Moran Feldman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01129v1",
                "http://arxiv.org/pdf/2311.01129v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "90C27 (Primary) 90C26, 68W25 (Secondary)",
                "G.2.1; F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04918v1",
            "title": "Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization\n  Help?",
            "updated": "2023-11-02T10:14:52Z",
            "published": "2023-11-02T10:14:52Z",
            "summary": "Named entity recognition (NER), a task that identifies and categorizes named\nentities such as persons or organizations from text, is traditionally framed as\na multi-class classification problem. However, this approach often overlooks\nthe issues of imbalanced label distributions, particularly in low-resource\nsettings, which is common in certain NER contexts, like biomedical NER\n(bioNER). To address these issues, we propose an innovative reformulation of\nthe multi-class problem as a one-vs-all (OVA) learning problem and introduce a\nloss function based on the area under the receiver operating characteristic\ncurve (AUC). To enhance the efficiency of our OVA-based approach, we propose\ntwo training strategies: one groups labels with similar linguistic\ncharacteristics, and another employs meta-learning. The superiority of our\napproach is confirmed by its performance, which surpasses traditional NER\nlearning in varying NER settings.",
            "author": [
                "Ngoc Dang Nguyen",
                "Wei Tan",
                "Lan Du",
                "Wray Buntine",
                "Richard Beare",
                "Changyou Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04918v1",
                "http://arxiv.org/pdf/2311.04918v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01121v1",
            "title": "Higher order terms of Mather's $\u03b2$-function for symplectic and outer\n  billiards",
            "updated": "2023-11-02T09:58:53Z",
            "published": "2023-11-02T09:58:53Z",
            "summary": "We compute explicitly the higher order terms of the formal Taylor expansion\nof Mather's $\\beta$-function for symplectic and outer billiards in a\nstrictly-convex planar domain $C$. In particular, we specify the third terms of\nthe asymptotic expansions of the distance (in the sense of the symmetric\ndifference metric) between $C$ and its best approximating inscribed or\ncircumscribed polygons with at most $n$ vertices. We use tools from affine\ndifferential geometry.",
            "author": [
                "Luca Baracco",
                "Olga Bernardi",
                "Alessandra Nardi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01121v1",
                "http://arxiv.org/pdf/2311.01121v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01120v1",
            "title": "EHA: Entanglement-variational Hardware-efficient Ansatz for Eigensolvers",
            "updated": "2023-11-02T09:58:02Z",
            "published": "2023-11-02T09:58:02Z",
            "summary": "Variational quantum eigensolvers (VQEs) are one of the most important and\neffective applications of quantum computing, especially in the current noisy\nintermediate-scale quantum (NISQ) era. There are mainly two ways for VQEs:\nproblem-agnostic and problem-specific. For problem-agnostic methods, they often\nsuffer from trainability issues. For problem-specific methods, their\nperformance usually relies upon choices of initial reference states which are\noften hard to determine. In this paper, we propose an Entanglement-variational\nHardware-efficient Ansatz (EHA), and numerically compare it with some widely\nused ansatzes by solving benchmark problems in quantum many-body systems and\nquantum chemistry. Our EHA is problem-agnostic and hardware-efficient,\nespecially suitable for NISQ devices and having potential for wide\napplications. EHA can achieve a higher level of accuracy in finding ground\nstates and their energies in most cases even compared with problem-specific\nmethods. The performance of EHA is robust to choices of initial states and\nparameters initialization and it has the ability to quickly adjust the\nentanglement to the required amount, which is also the fundamental reason for\nits superiority.",
            "author": [
                "Xin Wang",
                "Bo Qi",
                "Yabo Wang",
                "Daoyi Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01120v1",
                "http://arxiv.org/pdf/2311.01120v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01119v1",
            "title": "Pattern formation in vector-valued phase fields under convex constraints",
            "updated": "2023-11-02T09:48:58Z",
            "published": "2023-11-02T09:48:58Z",
            "summary": "In this work, a new class of vector-valued phase field models is presented,\nwhere the values of the phase parameters are constrained by a convex set. The\ngenerated phase fields feature the partition of the domain into patches of\ndistinct phases, separated by thin interfaces. The configuration and dynamics\nof the phases are directly dependent on the geometry and topology of the convex\nconstraint set, which makes it possible to engineer models of this type that\nexhibit desired interactions and patterns. An efficient proximal gradient\nsolver is introduced to study numerically their L2-gradient flow, i.e.~the\nassociated Allen-Cahn-type equation. Applying the solver together with various\nchoices for the convex constraint set, yields numerical results that feature a\nnumber of patterns observed in nature and engineering, such as multiphase\ngrains in metal alloys, traveling waves in reaction-diffusion systems, and\nvortices in magnetic materials.",
            "author": [
                "Orestis Vantzos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01119v1",
                "http://arxiv.org/pdf/2311.01119v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "cs.GR",
                "cs.NA",
                "math-ph",
                "math.MP",
                "math.NA",
                "00-01, 99-00"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01117v1",
            "title": "Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth\n  Simulation",
            "updated": "2023-11-02T09:44:21Z",
            "published": "2023-11-02T09:44:21Z",
            "summary": "RGB-based surface anomaly detection methods have advanced significantly.\nHowever, certain surface anomalies remain practically invisible in RGB alone,\nnecessitating the incorporation of 3D information. Existing approaches that\nemploy point-cloud backbones suffer from suboptimal representations and reduced\napplicability due to slow processing. Re-training RGB backbones, designed for\nfaster dense input processing, on industrial depth datasets is hindered by the\nlimited availability of sufficiently large datasets. We make several\ncontributions to address these challenges. (i) We propose a novel Depth-Aware\nDiscrete Autoencoder (DADA) architecture, that enables learning a general\ndiscrete latent space that jointly models RGB and 3D data for 3D surface\nanomaly detection. (ii) We tackle the lack of diverse industrial depth datasets\nby introducing a simulation process for learning informative depth features in\nthe depth encoder. (iii) We propose a new surface anomaly detection method\n3DSR, which outperforms all existing state-of-the-art on the challenging\nMVTec3D anomaly detection benchmark, both in terms of accuracy and processing\nspeed. The experimental results validate the effectiveness and efficiency of\nour approach, highlighting the potential of utilizing depth information for\nimproved surface anomaly detection.",
            "author": [
                "Vitjan Zavrtanik",
                "Matej Kristan",
                "Danijel Sko\u010daj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01117v1",
                "http://arxiv.org/pdf/2311.01117v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01115v1",
            "title": "Dynamically Maintaining the Persistent Homology of Time Series",
            "updated": "2023-11-02T09:41:49Z",
            "published": "2023-11-02T09:41:49Z",
            "summary": "We present a dynamic data structure for maintaining the persistent homology\nof a time series of real numbers. The data structure supports local operations,\nincluding the insertion and deletion of an item and the cutting and\nconcatenating of lists, each in time $O(\\log n + k)$, in which $n$ counts the\ncritical items and $k$ the changes in the augmented persistence diagram. To\nachieve this, we design a tailor-made tree structure with an unconventional\nrepresentation, referred to as banana tree, which may be useful in its own\nright.",
            "author": [
                "Sebastiano Cultrera di Montesano",
                "Herbert Edelsbrunner",
                "Monika Henzinger",
                "Lara Ost"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01115v1",
                "http://arxiv.org/pdf/2311.01115v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01114v1",
            "title": "On the indecomposable involutive solutions of the Yang-Baxter equation\n  of finite primitive level",
            "updated": "2023-11-02T09:41:35Z",
            "published": "2023-11-02T09:41:35Z",
            "summary": "In this paper, we study the class of indecomposable involutive solutions of\nthe Yang-Baxter equation of finite primitive level, recently introduced by\nCed\\'o and Okni\\'nski in \\cite{cedo2021constructing}. We give a group-theoretic\ncharacterization of these solutions by means of displacements groups and we\napply this result to compute and enumerate the ones having small size. For some\nclasses of indecomposable involutive solutions recently studied in literature,\nwe compute the exact value of the primitive level. Some relationships with\nother families of solutions also are discussed. Finally, following\n\\cite[Question 3.2]{cedo2021constructing}, we completely describe the ones\nhaving primitive level $2$ by left braces.",
            "author": [
                "Marco Castelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01114v1",
                "http://arxiv.org/pdf/2311.01114v1"
            ],
            "primary_category": "math.QA",
            "category": [
                "math.QA",
                "math.GR",
                "16T25, 81R50, 20E22, 20N02"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01111v1",
            "title": "H-NeXt: The next step towards roto-translation invariant networks",
            "updated": "2023-11-02T09:36:20Z",
            "published": "2023-11-02T09:36:20Z",
            "summary": "The widespread popularity of equivariant networks underscores the\nsignificance of parameter efficient models and effective use of training data.\nAt a time when robustness to unseen deformations is becoming increasingly\nimportant, we present H-NeXt, which bridges the gap between equivariance and\ninvariance. H-NeXt is a parameter-efficient roto-translation invariant network\nthat is trained without a single augmented image in the training set. Our\nnetwork comprises three components: an equivariant backbone for learning\nroto-translation independent features, an invariant pooling layer for\ndiscarding roto-translation information, and a classification layer. H-NeXt\noutperforms the state of the art in classification on unaugmented training sets\nand augmented test sets of MNIST and CIFAR-10.",
            "author": [
                "Tomas Karella",
                "Filip Sroubek",
                "Jan Flusser",
                "Jan Blazek",
                "Vasek Kosik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01111v1",
                "http://arxiv.org/pdf/2311.01111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01108v1",
            "title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External\n  Guidance",
            "updated": "2023-11-02T09:20:38Z",
            "published": "2023-11-02T09:20:38Z",
            "summary": "Adopting a two-stage paradigm of pretraining followed by fine-tuning,\nPretrained Language Models (PLMs) have achieved substantial advancements in the\nfield of natural language processing. However, in real-world scenarios, data\nlabels are often noisy due to the complex annotation process, making it\nessential to develop strategies for fine-tuning PLMs with such noisy labels. To\nthis end, we introduce an innovative approach for fine-tuning PLMs using noisy\nlabels, which incorporates the guidance of Large Language Models (LLMs) like\nChatGPT. This guidance assists in accurately distinguishing between clean and\nnoisy samples and provides supplementary information beyond the noisy labels,\nthereby boosting the learning process during fine-tuning PLMs. Extensive\nexperiments on synthetic and real-world noisy datasets further demonstrate the\nsuperior advantages of our framework over the state-of-the-art baselines.",
            "author": [
                "Song Wang",
                "Zhen Tan",
                "Ruocheng Guo",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01108v1",
                "http://arxiv.org/pdf/2311.01108v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02105v1",
            "title": "Making Harmful Behaviors Unlearnable for Large Language Models",
            "updated": "2023-11-02T09:18:21Z",
            "published": "2023-11-02T09:18:21Z",
            "summary": "Large language models (LLMs) have shown great potential as general-purpose AI\nassistants in various domains. To meet the requirements of different\napplications, LLMs are often customized by further fine-tuning. However, the\npowerful learning ability of LLMs not only enables them to acquire new tasks\nbut also makes them susceptible to learning undesired behaviors. For example,\neven safety-aligned LLMs can be easily fine-tuned into harmful assistants as\nthe fine-tuning data often contains implicit or explicit harmful content. Can\nwe train LLMs on harmful data without learning harmful behaviors? This paper\nproposes a controllable training framework that makes harmful behaviors\nunlearnable during the fine-tuning process. Specifically, we introduce\n``security vectors'', a few new parameters that can be separated from the LLM,\nto ensure LLM's responses are consistent with the harmful behavior. Security\nvectors are activated during fine-tuning, the consistent behavior makes LLM\nbelieve that such behavior has already been learned, there is no need to\nfurther optimize for harmful data. During inference, we can deactivate security\nvectors to restore the LLM's normal behavior. The experimental results show\nthat the security vectors generated by 100 harmful samples are enough to\nprevent LLM from learning 1000 harmful samples, while preserving the ability to\nlearn other useful information.",
            "author": [
                "Xin Zhou",
                "Yi Lu",
                "Ruotian Ma",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02105v1",
                "http://arxiv.org/pdf/2311.02105v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01105v1",
            "title": "ADAPT-QSCI: Adaptive Construction of Input State for Quantum-Selected\n  Configuration Interaction",
            "updated": "2023-11-02T09:15:50Z",
            "published": "2023-11-02T09:15:50Z",
            "summary": "We present a quantum-classical hybrid algorithm for calculating the ground\nstate and its energy of the quantum many-body Hamiltonian by proposing an\nadaptive construction of a quantum state for the quantum-selected configuration\ninteraction (QSCI) method. QSCI allows us to select important electronic\nconfigurations in the system to perform CI calculation (subspace\ndiagonalization of the Hamiltonian) by sampling measurement for a proper input\nquantum state on a quantum computer, but how we prepare a desirable input state\nhas remained a challenge. We propose an adaptive construction of the input\nstate for QSCI in which we run QSCI repeatedly to grow the input state\niteratively. We numerically illustrate that our method, dubbed\n\\textit{ADAPT-QSCI}, can yield accurate ground-state energies for small\nmolecules, including a noisy situation for eight qubits where error rates of\ntwo-qubit gates and the measurement are both as large as 1\\%. ADAPT-QSCI serves\nas a promising method to take advantage of current noisy quantum devices and\npushes forward its application to quantum chemistry.",
            "author": [
                "Yuya O. Nakagawa",
                "Masahiko Kamoshita",
                "Wataru Mizukami",
                "Shotaro Sudo",
                "Yu-ya Ohnishi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01105v1",
                "http://arxiv.org/pdf/2311.01105v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09238v1",
            "title": "Toward Ultra-Low-Power Remote Health Monitoring: An Optimal and Adaptive\n  Compressed Sensing Framework for Activity Recognition",
            "updated": "2023-11-02T09:07:47Z",
            "published": "2023-11-02T09:07:47Z",
            "summary": "Activity recognition, as an important component of behavioral monitoring and\nintervention, has attracted enormous attention, especially in Mobile Cloud\nComputing (MCC) and Remote Health Monitoring (RHM) paradigms. While recently\nresource constrained wearable devices have been gaining popularity, their\nbattery life is limited and constrained by the frequent wireless transmission\nof data to more computationally powerful back-ends. This paper proposes an\nultra-low power activity recognition system using a novel adaptive compressed\nsensing technique that aims to minimize transmission costs. Coarse-grained\non-body sensor localization and unsupervised clustering modules are devised to\nautonomously reconfigure the compressed sensing module for further power\nsaving. We perform a thorough heuristic optimization using Grammatical\nEvolution (GE) to ensure minimal computation overhead of the proposed\nmethodology. Our evaluation on a real-world dataset and a low power wearable\nsensing node demonstrates that our approach can reduce the energy consumption\nof the wireless data transmission up to $81.2\\%$ and $61.5\\%$, with up to\n$60.6\\%$ and $35.0\\%$ overall power savings in comparison with baseline and a\nnaive state-of-the-art approaches, respectively. These solutions lead to an\naverage activity recognition accuracy of $89.0\\%$ -- only $4.8\\%$ less than the\nbaseline accuracy -- while having a negligible energy overhead of on-node\ncomputation.",
            "author": [
                "J. Pagan",
                "R. Fallahzadeh",
                "M. Pedram",
                "Jos\u00e9 L. Risco-Mart\u00edn",
                "J. M. Moya",
                "J. L. Ayala",
                "H. Ghasemzadeh"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TMC.2018.2843373",
                "http://arxiv.org/abs/2311.09238v1",
                "http://arxiv.org/pdf/2311.09238v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01100v1",
            "title": "The Operator Product Expansion for Radial Lattice Quantization of 3D\n  $\u03c6^4$ Theory",
            "updated": "2023-11-02T09:07:36Z",
            "published": "2023-11-02T09:07:36Z",
            "summary": "At its critical point, the three-dimensional lattice Ising model is described\nby a conformal field theory (CFT), the 3d Ising CFT. Instead of carrying out\nsimulations on Euclidean lattices, we use the Quantum Finite Elements method to\nimplement radially quantized critical $\\phi^4$ theory on simplicial lattices\napproaching $\\mathbb{R} \\times S^2$. Computing the four-point function of\nidentical scalars, we demonstrate the power of radial quantization by the\naccurate determination of the scaling dimensions $\\Delta_{\\epsilon}$ and\n$\\Delta_{T}$ as well as ratios of the operator product expansion (OPE)\ncoefficients $f_{\\sigma \\sigma \\epsilon}$ and $f_{\\sigma \\sigma T}$ of the\nfirst spin-0 and spin-2 primary operators $\\epsilon$ and $T$ of the 3d Ising\nCFT.",
            "author": [
                "Venkitesh Ayyar",
                "Richard C. Brower",
                "George T. Fleming",
                "Anna-Maria E. Gl\u00fcck",
                "Evan K. Owen",
                "Timothy G. Raben",
                "Chung-I Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01100v1",
                "http://arxiv.org/pdf/2311.01100v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "cond-mat.stat-mech",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02172v1",
            "title": "Mercury: A modeling, simulation, and optimization framework for data\n  stream-oriented IoT applications",
            "updated": "2023-11-02T09:06:02Z",
            "published": "2023-11-02T09:06:02Z",
            "summary": "The Internet of Things is transforming our society by monitoring users and\ninfrastructures' behavior to enable new services that will improve life quality\nand resource management. These applications require a vast amount of localized\ninformation to be processed in real-time so, the deployment of new fog\ncomputing infrastructures that bring computing closer to the data sources is a\nmajor concern. In this context, we present Mercury, a Modeling, Simulation, and\nOptimization (M&S&O) framework to analyze the dimensioning and the dynamic\noperation of real-time fog computing scenarios. Our research proposes a\nlocation-aware solution that supports data stream analytics applications\nincluding FaaS-based computation offloading. Mercury implements a detailed\nstructural and behavioral simulation model, providing fine-grained simulation\noutputs, and is described using the Discrete Event System Specification (DEVS)\nmathematical formalism, helping to validate the model's implementation.\nFinally, we present a case study using real traces from a driver assistance\nscenario, offering a detailed comparison with other state-of-the-art\nsimulators.",
            "author": [
                "Rom\u00e1n C\u00e1rdenas",
                "Patricia Arroba",
                "Roberto Blanco",
                "Pedro Malag\u00f3n",
                "Jos\u00e9 L. Risco-Mart\u00edn",
                "Jos\u00e9 M. Moya"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.simpat.2019.102037",
                "http://arxiv.org/abs/2312.02172v1",
                "http://arxiv.org/pdf/2312.02172v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01096v1",
            "title": "Gapped boundaries of fermionic topological orders and higher central\n  charges",
            "updated": "2023-11-02T08:59:27Z",
            "published": "2023-11-02T08:59:27Z",
            "summary": "We develop a test for the vanishing of higher central charges of a fermionic\ntopological order, which is a necessary condition for the existence of a gapped\nboundary, purely in terms of the modular data of the super-modular tensor\ncategory. More precisely, we test whether a given super-MTC has $c = 0$ mod\n$\\frac{1}{2}$, and, if so, whether the modular extension with $c =0$ mod $8$\nhas vanishing higher central charges. The test itself does not require an\nexplicit computation of the modular extensions and is easily carried out. We\napply this test to known examples of super-modular tensor categories. Since our\ntest allows us to obtain information about the chiral central charge of a\nsuper-modular tensor category in terms of its modular data without direct\nknowledge of its modular extensions, this can also be thought of as the first\nstep towards a fermionic analogue of the Gauss-Milgram formula.",
            "author": [
                "Minyoung You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01096v1",
                "http://arxiv.org/pdf/2311.01096v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01092v1",
            "title": "Learning A Multi-Task Transformer Via Unified And Customized Instruction\n  Tuning For Chest Radiograph Interpretation",
            "updated": "2023-11-02T08:55:48Z",
            "published": "2023-11-02T08:55:48Z",
            "summary": "The emergence of multi-modal deep learning models has made significant\nimpacts on clinical applications in the last decade. However, the majority of\nmodels are limited to single-tasking, without considering disease diagnosis is\nindeed a multi-task procedure. Here, we demonstrate a unified transformer model\nspecifically designed for multi-modal clinical tasks by incorporating\ncustomized instruction tuning. We first compose a multi-task training dataset\ncomprising 13.4 million instruction and ground-truth pairs (with approximately\none million radiographs) for the customized tuning, involving both image- and\npixel-level tasks. Thus, we can unify the various vision-intensive tasks in a\nsingle training framework with homogeneous model inputs and outputs to increase\nclinical interpretability in one reading. Finally, we demonstrate the overall\nsuperior performance of our model compared to prior arts on various chest X-ray\nbenchmarks across multi-tasks in both direct inference and finetuning settings.\nThree radiologists further evaluate the generated reports against the recorded\nones, which also exhibit the enhanced explainability of our multi-task model.",
            "author": [
                "Lijian Xu",
                "Ziyu Ni",
                "Xinglong Liu",
                "Xiaosong Wang",
                "Hongsheng Li",
                "Shaoting Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01092v1",
                "http://arxiv.org/pdf/2311.01092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01091v1",
            "title": "Enriching Phrases with Coupled Pixel and Object Contexts for Panoptic\n  Narrative Grounding",
            "updated": "2023-11-02T08:55:28Z",
            "published": "2023-11-02T08:55:28Z",
            "summary": "Panoptic narrative grounding (PNG) aims to segment things and stuff objects\nin an image described by noun phrases of a narrative caption. As a multimodal\ntask, an essential aspect of PNG is the visual-linguistic interaction between\nimage and caption. The previous two-stage method aggregates visual contexts\nfrom offline-generated mask proposals to phrase features, which tend to be\nnoisy and fragmentary. The recent one-stage method aggregates only pixel\ncontexts from image features to phrase features, which may incur semantic\nmisalignment due to lacking object priors. To realize more comprehensive\nvisual-linguistic interaction, we propose to enrich phrases with coupled pixel\nand object contexts by designing a Phrase-Pixel-Object Transformer Decoder\n(PPO-TD), where both fine-grained part details and coarse-grained entity clues\nare aggregated to phrase features. In addition, we also propose a PhraseObject\nContrastive Loss (POCL) to pull closer the matched phrase-object pairs and push\naway unmatched ones for aggregating more precise object contexts from more\nphrase-relevant object tokens. Extensive experiments on the PNG benchmark show\nour method achieves new state-of-the-art performance with large margins.",
            "author": [
                "Tianrui Hui",
                "Zihan Ding",
                "Junshi Huang",
                "Xiaoming Wei",
                "Xiaolin Wei",
                "Jiao Dai",
                "Jizhong Han",
                "Si Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01091v1",
                "http://arxiv.org/pdf/2311.01091v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01090v1",
            "title": "Infusion: Internal Diffusion for Video Inpainting",
            "updated": "2023-11-02T08:55:11Z",
            "published": "2023-11-02T08:55:11Z",
            "summary": "Video inpainting is the task of filling a desired region in a video in a\nvisually convincing manner. It is a very challenging task due to the high\ndimensionality of the signal and the temporal consistency required for\nobtaining convincing results. Recently, diffusion models have shown impressive\nresults in modeling complex data distributions, including images and videos.\nDiffusion models remain nonetheless very expensive to train and perform\ninference with, which strongly restrict their application to video. We show\nthat in the case of video inpainting, thanks to the highly auto-similar nature\nof videos, the training of a diffusion model can be restricted to the video to\ninpaint and still produce very satisfying results. This leads us to adopt an\ninternal learning approch, which also allows for a greatly reduced network\nsize. We call our approach \"Infusion\": an internal learning algorithm for video\ninpainting through diffusion. Due to our frugal network, we are able to propose\nthe first video inpainting approach based purely on diffusion. Other methods\nrequire supporting elements such as optical flow estimation, which limits their\nperformance in the case of dynamic textures for example. We introduce a new\nmethod for efficient training and inference of diffusion models in the context\nof internal learning. We split the diffusion process into different learning\nintervals which greatly simplifies the learning steps. We show qualititative\nand quantitative results, demonstrating that our method reaches\nstate-of-the-art performance, in particular in the case of dynamic backgrounds\nand textures.",
            "author": [
                "Nicolas Cherel",
                "Andr\u00e9s Almansa",
                "Yann Gousseau",
                "Alasdair Newson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01090v1",
                "http://arxiv.org/pdf/2311.01090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01086v1",
            "title": "Non-linear non-zero-sum Dynkin games with Bermudan strategies",
            "updated": "2023-11-02T08:53:03Z",
            "published": "2023-11-02T08:53:03Z",
            "summary": "In this paper, we study a non-zero-sum game with two players, where each of\nthe players plays what we call Bermudan strategies and optimizes a general\nnon-linear assessment functional of the pay-off. By using a recursive\nconstruction, we show that the game has a Nash equilibrium point.",
            "author": [
                "Miryana Grigorova",
                "Marie-Claire Quenez",
                "Yuan Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01086v1",
                "http://arxiv.org/pdf/2311.01086v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01085v1",
            "title": "Blending Bathymetry: Combination of image-derived parametric\n  approximations and celerity data sets for nearshore bathymetry estimation",
            "updated": "2023-11-02T08:52:38Z",
            "published": "2023-11-02T08:52:38Z",
            "summary": "Estimation of nearshore bathymetry is important for accurate prediction of\nnearshore wave conditions. However, direct data collection is expensive and\ntime-consuming while accurate airborne lidar-based survey is limited by\nbreaking waves and decreased light penetration affected by water turbidity.\nInstead, tower-based platforms or Unmanned Aircraft System (UAS) can provide\nindirect video-based observations. The video-based time-series imagery provides\nwave celerity information and time-averaged (timex) or variance enhanced (var)\nimages identify persistent regions of wave breaking.\n  In this work, we propose a rapid and improved bathymetry estimation method\nthat takes advantage of image-derived wave celerity and a first-order\nbathymetry estimate from Parameter Beach Tool (PBT), software that fits\nparameterized sandbar and slope forms to the timex or var images. Two different\nsources of the data, PBT and wave celerity, are combined or blended optimally\nbased on their assumed accuracy in a statistical framework. The PBT-derived\nbathymetry serves as \"prior\" coarse-scale background information and then is\nupdated and corrected with the imagery-derived wave data through the dispersion\nrelationship, which results in a better bathymetry estimate that is consistent\nwith imagery-based wave data. To illustrate the accuracy of our proposed\nmethod, imagery data sets collected in 2017 at the US Army EDRC's Field\nResearch Facility in Duck, NC under different weather and wave height\nconditions are tested. Estimated bathymetry profiles are remarkably close to\nthe direct survey data. The computational time for the estimation from\nPBT-based bathymetry and imagery-derived wave celerity is only about five\nminutes on a free Google Cloud node with one CPU core. These promising results\nindicate the feasibility of reliable real-time bathymetry imaging during a\nsingle flight of UAS.",
            "author": [
                "Jonghyun Lee",
                "Katherine DeVore",
                "Tyler Hesser",
                "A. Spicer Bak",
                "Katherine Brodie",
                "Brittany Bruder",
                "Matthew Farthing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01085v1",
                "http://arxiv.org/pdf/2311.01085v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.data-an",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01073v2",
            "title": "Fourier Analysis of Signals on Directed Acyclic Graphs (DAG) Using Graph\n  Zero-Padding",
            "updated": "2023-11-13T09:33:24Z",
            "published": "2023-11-02T08:40:21Z",
            "summary": "Directed acyclic graphs (DAGs) are used for modeling causal relationships,\ndependencies, and flows in various systems. However, spectral analysis becomes\nimpractical in this setting because the eigen-decomposition of the adjacency\nmatrix yields all eigenvalues equal to zero. This inherent property of DAGs\nresults in an inability to differentiate between frequency components of\nsignals on such graphs. This problem can be addressed by alternating the\nFourier basis or adding edges in a DAG. However, these approaches change the\nphysics of the considered problem. To address this limitation, we propose a\ngraph zero-padding approach. This approach involves augmenting the original DAG\nwith additional vertices that are connected to the existing structure. The\nadded vertices are characterized by signal values set to zero. The proposed\ntechnique enables the spectral evaluation of system outputs on DAGs (in almost\nall cases), that is the computation of vertex-domain convolution without the\nadverse effects of aliasing due to changes in a graph structure, with the\nultimate goal of preserving the output of the system on a graph as if the\nchanges in the graph structure were not done.",
            "author": [
                "Ljubisa Stankovic",
                "Milos Dakovic",
                "Ali Bagheri Bardi",
                "Milos Brajovic",
                "Isidora Stankovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01073v2",
                "http://arxiv.org/pdf/2311.01073v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04917v1",
            "title": "Adapting Fake News Detection to the Era of Large Language Models",
            "updated": "2023-11-02T08:39:45Z",
            "published": "2023-11-02T08:39:45Z",
            "summary": "In the age of large language models (LLMs) and the widespread adoption of\nAI-driven content creation, the landscape of information dissemination has\nwitnessed a paradigm shift. With the proliferation of both human-written and\nmachine-generated real and fake news, robustly and effectively discerning the\nveracity of news articles has become an intricate challenge. While substantial\nresearch has been dedicated to fake news detection, this either assumes that\nall news articles are human-written or abruptly assumes that all\nmachine-generated news are fake. Thus, a significant gap exists in\nunderstanding the interplay between machine-(paraphrased) real news,\nmachine-generated fake news, human-written fake news, and human-written real\nnews. In this paper, we study this gap by conducting a comprehensive evaluation\nof fake news detectors trained in various scenarios. Our primary objectives\nrevolve around the following pivotal question: How to adapt fake news detectors\nto the era of LLMs? Our experiments reveal an interesting pattern that\ndetectors trained exclusively on human-written articles can indeed perform well\nat detecting machine-generated fake news, but not vice versa. Moreover, due to\nthe bias of detectors against machine-generated texts \\cite{su2023fake}, they\nshould be trained on datasets with a lower machine-generated news ratio than\nthe test set. Building on our findings, we provide a practical strategy for the\ndevelopment of robust fake news detectors.",
            "author": [
                "Jinyan Su",
                "Claire Cardie",
                "Preslav Nakov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04917v1",
                "http://arxiv.org/pdf/2311.04917v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01070v1",
            "title": "DistilWhisper: Efficient Distillation of Multi-task Speech Models via\n  Language-Specific Experts",
            "updated": "2023-11-02T08:37:30Z",
            "published": "2023-11-02T08:37:30Z",
            "summary": "Whisper is a multitask and multilingual speech model covering 99 languages.\nIt yields commendable automatic speech recognition (ASR) results in a subset of\nits covered languages, but the model still under-performs on a non-negligible\nnumber of under-represented languages, a problem exacerbated in smaller model\nversions. In this work, we propose DistilWhisper, an approach able to bridge\nthe performance gap in ASR for these languages while retaining the advantages\nof multitask and multilingual capabilities. Our approach involves two key\nstrategies: lightweight modular ASR fine-tuning of whisper-small using\nlanguage-specific experts, and knowledge distillation from whisper-large-v2.\nThis dual approach allows us to effectively boost ASR performance while keeping\nthe robustness inherited from the multitask and multilingual pre-training.\nResults demonstrate that our approach is more effective than standard\nfine-tuning or LoRA adapters, boosting performance in the targeted languages\nfor both in- and out-of-domain test sets, while introducing only a negligible\nparameter overhead at inference.",
            "author": [
                "Thomas Palmeira Ferraz",
                "Marcely Zanon Boito",
                "Caroline Brun",
                "Vassilina Nikoulina"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01070v1",
                "http://arxiv.org/pdf/2311.01070v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01066v3",
            "title": "Dynamic Multimodal Information Bottleneck for Multimodality\n  Classification",
            "updated": "2023-11-25T08:20:33Z",
            "published": "2023-11-02T08:34:08Z",
            "summary": "Effectively leveraging multimodal data such as various images, laboratory\ntests and clinical information is gaining traction in a variety of AI-based\nmedical diagnosis and prognosis tasks. Most existing multi-modal techniques\nonly focus on enhancing their performance by leveraging the differences or\nshared features from various modalities and fusing feature across different\nmodalities. These approaches are generally not optimal for clinical settings,\nwhich pose the additional challenges of limited training data, as well as being\nrife with redundant data or noisy modality channels, leading to subpar\nperformance. To address this gap, we study the robustness of existing methods\nto data redundancy and noise and propose a generalized dynamic multimodal\ninformation bottleneck framework for attaining a robust fused feature\nrepresentation. Specifically, our information bottleneck module serves to\nfilter out the task-irrelevant information and noises in the fused feature, and\nwe further introduce a sufficiency loss to prevent dropping of task-relevant\ninformation, thus explicitly preserving the sufficiency of prediction\ninformation in the distilled feature. We validate our model on an in-house and\na public COVID19 dataset for mortality prediction as well as two public\nbiomedical datasets for diagnostic tasks. Extensive experiments show that our\nmethod surpasses the state-of-the-art and is significantly more robust, being\nthe only method to remain performance when large-scale noisy channels exist.\nOur code is publicly available at https://github.com/ayanglab/DMIB.",
            "author": [
                "Yingying Fang",
                "Shuang Wu",
                "Sheng Zhang",
                "Chaoyan Huang",
                "Tieyong Zeng",
                "Xiaodan Xing",
                "Simon Walsh",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01066v3",
                "http://arxiv.org/pdf/2311.01066v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01065v1",
            "title": "Novel View Synthesis from a Single RGBD Image for Indoor Scenes",
            "updated": "2023-11-02T08:34:07Z",
            "published": "2023-11-02T08:34:07Z",
            "summary": "In this paper, we propose an approach for synthesizing novel view images from\na single RGBD (Red Green Blue-Depth) input. Novel view synthesis (NVS) is an\ninteresting computer vision task with extensive applications. Methods using\nmultiple images has been well-studied, exemplary ones include training\nscene-specific Neural Radiance Fields (NeRF), or leveraging multi-view stereo\n(MVS) and 3D rendering pipelines. However, both are either computationally\nintensive or non-generalizable across different scenes, limiting their\npractical value. Conversely, the depth information embedded in RGBD images\nunlocks 3D potential from a singular view, simplifying NVS. The widespread\navailability of compact, affordable stereo cameras, and even LiDARs in\ncontemporary devices like smartphones, makes capturing RGBD images more\naccessible than ever. In our method, we convert an RGBD image into a point\ncloud and render it from a different viewpoint, then formulate the NVS task\ninto an image translation problem. We leveraged generative adversarial networks\nto style-transfer the rendered image, achieving a result similar to a\nphotograph taken from the new perspective. We explore both unsupervised\nlearning using CycleGAN and supervised learning with Pix2Pix, and demonstrate\nthe qualitative results. Our method circumvents the limitations of traditional\nmulti-image techniques, holding significant promise for practical, real-time\napplications in NVS.",
            "author": [
                "Congrui Hetang",
                "Yuping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01065v1",
                "http://arxiv.org/pdf/2311.01065v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01064v1",
            "title": "Multimodal Foundation Models for Zero-shot Animal Species Recognition in\n  Camera Trap Images",
            "updated": "2023-11-02T08:32:00Z",
            "published": "2023-11-02T08:32:00Z",
            "summary": "Due to deteriorating environmental conditions and increasing human activity,\nconservation efforts directed towards wildlife is crucial. Motion-activated\ncamera traps constitute an efficient tool for tracking and monitoring wildlife\npopulations across the globe. Supervised learning techniques have been\nsuccessfully deployed to analyze such imagery, however training such techniques\nrequires annotations from experts. Reducing the reliance on costly labelled\ndata therefore has immense potential in developing large-scale wildlife\ntracking solutions with markedly less human labor. In this work we propose\nWildMatch, a novel zero-shot species classification framework that leverages\nmultimodal foundation models. In particular, we instruction tune\nvision-language models to generate detailed visual descriptions of camera trap\nimages using similar terminology to experts. Then, we match the generated\ncaption to an external knowledge base of descriptions in order to determine the\nspecies in a zero-shot manner. We investigate techniques to build instruction\ntuning datasets for detailed animal description generation and propose a novel\nknowledge augmentation technique to enhance caption quality. We demonstrate the\nperformance of WildMatch on a new camera trap dataset collected in the\nMagdalena Medio region of Colombia.",
            "author": [
                "Zalan Fabian",
                "Zhongqi Miao",
                "Chunyuan Li",
                "Yuanhan Zhang",
                "Ziwei Liu",
                "Andr\u00e9s Hern\u00e1ndez",
                "Andr\u00e9s Montes-Rojas",
                "Rafael Escucha",
                "Laura Siabatto",
                "Andr\u00e9s Link",
                "Pablo Arbel\u00e1ez",
                "Rahul Dodhia",
                "Juan Lavista Ferres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01064v1",
                "http://arxiv.org/pdf/2311.01064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10750v1",
            "title": "A method of estimating the content of crystalline phases in multiphase\n  samples based on X-ray diffraction data",
            "updated": "2023-11-02T08:18:55Z",
            "published": "2023-11-02T08:18:55Z",
            "summary": "A method for estimating the relative content of crystalline phases of a\nmultiphase sample, based on probabilistic analysis of the intensities of the\ndiffraction pattern reflexes, has been developed. The method is based on the\nintroduction of some numerical parameter, which uniquely characterizes the\ndiffraction pattern, and comparison of the diffraction patterns according to\nthis parameter, using methods of computational statistics. In situations where\nthe absorption coefficients of the phases are close, the method works solely on\nthe analysis of the diffraction pattern data from a specific multiphase sample.\n  It is shown on the control measurements that the uncertainty of the estimates\ndoes not exceed $\\pm 8$~\\%.",
            "author": [
                "S. V. Gabielkov",
                "I. V. Zhyganiuk",
                "A. D. Skorbun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10750v1",
                "http://arxiv.org/pdf/2311.10750v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03380v1",
            "title": "An attempt to generate new bridge types from latent space of variational\n  autoencoder",
            "updated": "2023-11-02T08:18:37Z",
            "published": "2023-11-02T08:18:37Z",
            "summary": "Try to generate new bridge types using generative artificial intelligence\ntechnology. The grayscale images of the bridge facade with the change of\ncomponent width was rendered by 3dsMax animation software, and then the OpenCV\nmodule performed an appropriate amount of geometric transformation (rotation,\nhorizontal scale, vertical scale) to obtain the image dataset of three-span\nbeam bridge, arch bridge, cable-stayed bridge and suspension bridge. Based on\nPython programming language, TensorFlow and Keras deep learning platform\nframework, variational autoencoder was constructed and trained, and\nlow-dimensional bridge-type latent space that is convenient for vector\noperations was obtained. Variational autoencoder can combine two bridge types\non the basis of the original of human into one that is a new bridge type.\nGenerative artificial intelligence technology can assist bridge designers in\nbridge-type innovation, and can be used as copilot.",
            "author": [
                "Hongjun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03380v1",
                "http://arxiv.org/pdf/2311.03380v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01057v2",
            "title": "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart\n  Glasses with TinyissimoYOLO",
            "updated": "2023-11-03T15:25:55Z",
            "published": "2023-11-02T08:01:49Z",
            "summary": "Smart glasses are rapidly gaining advanced functionality thanks to\ncutting-edge computing technologies, accelerated hardware architectures, and\ntiny AI algorithms. Integrating AI into smart glasses featuring a small form\nfactor and limited battery capacity is still challenging when targeting\nfull-day usage for a satisfactory user experience. This paper illustrates the\ndesign and implementation of tiny machine-learning algorithms exploiting novel\nlow-power processors to enable prolonged continuous operation in smart glasses.\nWe explore the energy- and latency-efficient of smart glasses in the case of\nreal-time object detection. To this goal, we designed a smart glasses prototype\nas a research platform featuring two microcontrollers, including a novel\nmilliwatt-power RISC-V parallel processor with a hardware accelerator for\nvisual AI, and a Bluetooth low-power module for communication. The smart\nglasses integrate power cycling mechanisms, including image and audio sensing\ninterfaces. Furthermore, we developed a family of novel tiny deep-learning\nmodels based on YOLO with sub-million parameters customized for\nmicrocontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming\nat benchmarking object detection with smart glasses for energy and latency.\nEvaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's\n17ms inference latency and 1.59mJ energy consumption per inference while\nensuring acceptable detection accuracy. Further evaluation reveals an\nend-to-end latency from image capturing to the algorithm's prediction of 56ms\nor equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to\na 9.3 hours of continuous run time on a 154mAh battery. These results\noutperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image\nclassification) at just 7.3 fps per second.",
            "author": [
                "Julian Moosmann",
                "Pietro Bonazzi",
                "Yawei Li",
                "Sizhen Bian",
                "Philipp Mayer",
                "Luca Benini",
                "Michele Magno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01057v2",
                "http://arxiv.org/pdf/2311.01057v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01054v2",
            "title": "A feasible and unitary programming language with quantum control",
            "updated": "2023-11-21T09:17:36Z",
            "published": "2023-11-02T07:57:56Z",
            "summary": "We introduce PUNQ, a novel quantum programming language with quantum control,\nwhich features higher-order programs that can be superposed, enabling quantum\ncontrol via quantum conditionals. Our language boasts a type system\nguaranteeing both unitarity and polynomial-time normalization. Unitarity is\nachieved by using a special modality for superpositions while requiring\northogonality among superposed terms. Polynomial-time normalization is achieved\nusing a linear-logic-based type discipline employing Barber and Plotkin duality\nalong with a specific modality to account for potential duplications. This type\ndiscipline also guarantees that derived values have polynomial size. PUNQ\nseamlessly combines the two modalities: quantum circuit programs uphold\nunitarity, and all programs are evaluated in polynomial time, ensuring their\nfeasibility.",
            "author": [
                "Alejandro D\u00edaz-Caro",
                "Emmanuel Hainry",
                "Romain P\u00e9choux",
                "M\u00e1rio Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01054v2",
                "http://arxiv.org/pdf/2311.01054v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01049v1",
            "title": "Multi-dimensional data refining strategy for effective fine-tuning LLMs",
            "updated": "2023-11-02T07:50:43Z",
            "published": "2023-11-02T07:50:43Z",
            "summary": "Data is a cornerstone for fine-tuning large language models, yet acquiring\nsuitable data remains challenging. Challenges encompassed data scarcity,\nlinguistic diversity, and domain-specific content. This paper presents lessons\nlearned while crawling and refining data tailored for fine-tuning Vietnamese\nlanguage models. Crafting such a dataset, while accounting for linguistic\nintricacies and striking a balance between inclusivity and accuracy, demands\nmeticulous planning. Our paper presents a multidimensional strategy including\nleveraging existing datasets in the English language and developing customized\ndata-crawling scripts with the assistance of generative AI tools. A fine-tuned\nLLM model for the Vietnamese language, which was produced using resultant\ndatasets, demonstrated good performance while generating Vietnamese news\narticles from prompts. The study offers practical solutions and guidance for\nfuture fine-tuning models in languages like Vietnamese.",
            "author": [
                "Thanh Nguyen Ngoc",
                "Quang Nhat Tran",
                "Arthur Tang",
                "Bao Nguyen",
                "Thuy Nguyen",
                "Thanh Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01049v1",
                "http://arxiv.org/pdf/2311.01049v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01048v1",
            "title": "AI-assisted Learning for Electronic Engineering Courses in High\n  Education",
            "updated": "2023-11-02T07:48:10Z",
            "published": "2023-11-02T07:48:10Z",
            "summary": "This study evaluates the efficacy of ChatGPT as an AI teaching and learning\nsupport tool in an integrated circuit systems course at a higher education\ninstitution in an Asian country. Various question types were completed, and\nChatGPT responses were assessed to gain valuable insights for further\ninvestigation. The objective is to assess ChatGPT's ability to provide\ninsights, personalized support, and interactive learning experiences in\nengineering education. The study includes the evaluation and reflection of\ndifferent stakeholders: students, lecturers, and engineers. The findings of\nthis study shed light on the benefits and limitations of ChatGPT as an AI tool,\npaving the way for innovative learning approaches in technical disciplines.\nFurthermore, the study contributes to our understanding of how digital\ntransformation is likely to unfold in the education sector.",
            "author": [
                "Thanh Nguyen Ngoc",
                "Quang Nhat Tran",
                "Arthur Tang",
                "Bao Nguyen",
                "Thuy Nguyen",
                "Thanh Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01048v1",
                "http://arxiv.org/pdf/2311.01048v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01047v1",
            "title": "Improving Robustness via Tilted Exponential Layer: A\n  Communication-Theoretic Perspective",
            "updated": "2023-11-02T07:47:42Z",
            "published": "2023-11-02T07:47:42Z",
            "summary": "State-of-the-art techniques for enhancing robustness of deep networks mostly\nrely on empirical risk minimization with suitable data augmentation. In this\npaper, we propose a complementary approach motivated by communication theory,\naimed at enhancing the signal-to-noise ratio at the output of a neural network\nlayer via neural competition during learning and inference. In addition to\nminimization of a standard end-to-end cost, neurons compete to sparsely\nrepresent layer inputs by maximization of a tilted exponential (TEXP) objective\nfunction for the layer. TEXP learning can be interpreted as maximum likelihood\nestimation of matched filters under a Gaussian model for data noise. Inference\nin a TEXP layer is accomplished by replacing batch norm by a tilted softmax,\nwhich can be interpreted as computation of posterior probabilities for the\ncompeting signaling hypotheses represented by each neuron. After providing\ninsights via simplified models, we show, by experimentation on standard image\ndatasets, that TEXP learning and inference enhances robustness against noise\nand other common corruptions, without requiring data augmentation. Further\ncumulative gains in robustness against this array of distortions can be\nobtained by appropriately combining TEXP with data augmentation techniques.",
            "author": [
                "Bhagyashree Puranik",
                "Ahmad Beirami",
                "Yao Qin",
                "Upamanyu Madhow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01047v1",
                "http://arxiv.org/pdf/2311.01047v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01044v1",
            "title": "Hidden-charm pentaquarks with strangeness in a chiral quark model",
            "updated": "2023-11-02T07:32:34Z",
            "published": "2023-11-02T07:32:34Z",
            "summary": "The LHCb collaboration has recently announced the discovery of two\nhidden-charm pentaquark states with also strange quark content, $P_{cs}(4338)$\nand $P_{cs}(4459)$; its analysis points towards having both hadrons isospin\nequal to zero and spin-parity quantum numbers $\\frac12^-$ and $\\frac32^-$,\nrespectively. We perform herein a systematical investigation of the\n$qqsc\\bar{c}$ $(q=u,\\,d)$ system by means of a chiral quark model, along with a\nhighly accurate computational method, the Gaussian expansion approach combined\nwith the complex-scaling technique. Baryon-meson configurations in both\nsinglet- and hidden-color channels are considered. The $P_{cs}(4338)$ and\n$P_{cs}(4459)$ signals can be well identified as molecular bound states with\ndominant components $\\Lambda J/\\psi$ $(60\\%)$ and $\\Xi_c D$ $(23\\%)$ for the\nlowest-energy case and $\\Xi_c D^*$ $(72\\%)$ for the highest-energy one.\nBesides, it seems that some narrow resonances can be also found in each allowed\n$I(J^P)$-channel in the energy region of $4.6-5.5$ GeV, except for the\n$1(\\frac12^-)$ where a shallow bound state with dominant $\\Xi^*_c D^*$\nstructure is obtained at $4673$ MeV with binding energy $E_B=-3$ MeV. These\nexotic states are expected to be confirmed in future high energy experiments.",
            "author": [
                "Gang Yang",
                "Jialun Ping",
                "Jorge Segovia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01044v1",
                "http://arxiv.org/pdf/2311.01044v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "hep-lat",
                "nucl-ex",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01043v2",
            "title": "LLM4Drive: A Survey of Large Language Models for Autonomous Driving",
            "updated": "2023-11-27T05:43:45Z",
            "published": "2023-11-02T07:23:33Z",
            "summary": "Autonomous driving technology, a catalyst for revolutionizing transportation\nand urban mobility, has the tend to transition from rule-based systems to\ndata-driven strategies. Traditional module-based systems are constrained by\ncumulative errors among cascaded modules and inflexible pre-set rules. In\ncontrast, end-to-end autonomous driving systems have the potential to avoid\nerror accumulation due to their fully data-driven training process, although\nthey often lack transparency due to their \"black box\" nature, complicating the\nvalidation and traceability of decisions. Recently, large language models\n(LLMs) have demonstrated abilities including understanding context, logical\nreasoning, and generating answers. A natural thought is to utilize these\nabilities to empower autonomous driving. By combining LLM with foundation\nvision models, it could open the door to open-world understanding, reasoning,\nand few-shot learning, which current autonomous driving systems are lacking. In\nthis paper, we systematically review a research line about \\textit{Large\nLanguage Models for Autonomous Driving (LLM4AD)}. This study evaluates the\ncurrent state of technological advancements, distinctly outlining the principal\nchallenges and prospective directions for the field. For the convenience of\nresearchers in academia and industry, we provide real-time updates on the\nlatest advances in the field as well as relevant open-source resources via the\ndesignated link: https://github.com/Thinklab-SJTU/Awesome-LLM4AD.",
            "author": [
                "Zhenjie Yang",
                "Xiaosong Jia",
                "Hongyang Li",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01043v2",
                "http://arxiv.org/pdf/2311.01043v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01041v1",
            "title": "Learn to Refuse: Making Large Language Models More Controllable and\n  Reliable through Knowledge Scope Limitation and Refusal Mechanism",
            "updated": "2023-11-02T07:20:49Z",
            "published": "2023-11-02T07:20:49Z",
            "summary": "Large language models (LLMs) have demonstrated impressive language\nunderstanding and generation capabilities, enabling them to answer a wide range\nof questions across various domains. However, these models are not flawless and\noften produce responses that contain errors or misinformation. These\ninaccuracies, commonly referred to as hallucinations, render LLMs unreliable\nand even unusable in many scenarios. In this paper, our focus is on mitigating\nthe issue of hallucination in LLMs, particularly in the context of\nquestion-answering. Instead of attempting to answer all questions, we explore a\nrefusal mechanism that instructs LLMs to refuse to answer challenging questions\nin order to avoid errors. We then propose a simple yet effective solution\ncalled Learn to Refuse (L2R), which incorporates the refusal mechanism to\nenable LLMs to recognize and refuse to answer questions that they find\ndifficult to address. To achieve this, we utilize a structured knowledge base\nto represent all the LLM's understanding of the world, enabling it to provide\ntraceable gold knowledge. This knowledge base is separate from the LLM and\ninitially empty, and it is progressively expanded with validated knowledge.\nWhen an LLM encounters questions outside its domain, the system recognizes its\nknowledge scope and determines whether it can answer the question\nindependently. Additionally, we introduce a method for automatically and\nefficiently expanding the knowledge base of LLMs. Through qualitative and\nquantitative analysis, we demonstrate that our approach enhances the\ncontrollability and reliability of LLMs.",
            "author": [
                "Lang Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01041v1",
                "http://arxiv.org/pdf/2311.01041v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01036v1",
            "title": "ATHENA: Mathematical Reasoning with Thought Expansion",
            "updated": "2023-11-02T07:03:25Z",
            "published": "2023-11-02T07:03:25Z",
            "summary": "Solving math word problems depends on how to articulate the problems, the\nlens through which models view human linguistic expressions. Real-world\nsettings count on such a method even more due to the diverse practices of the\nsame mathematical operations. Earlier works constrain available thinking\nprocesses by limited prediction strategies without considering their\nsignificance in acquiring mathematical knowledge. We introduce Attention-based\nTHought Expansion Network Architecture (ATHENA) to tackle the challenges of\nreal-world practices by mimicking human thought expansion mechanisms in the\nform of neural network propagation. A thought expansion recurrently generates\nthe candidates carrying the thoughts of possible math expressions driven from\nthe previous step and yields reasonable thoughts by selecting the valid\npathways to the goal. Our experiments show that ATHENA achieves a new\nstate-of-the-art stage toward the ideal model that is compelling in variant\nquestions even when the informativeness in training examples is restricted.",
            "author": [
                "JB. Kim",
                "Hazel Kim",
                "Joonghyuk Hahn",
                "Yo-Sub Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01036v1",
                "http://arxiv.org/pdf/2311.01036v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7; I.2.3; F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01035v1",
            "title": "Mathematical Properties of the Zadoff-Chu Sequences",
            "updated": "2023-11-02T06:59:47Z",
            "published": "2023-11-02T06:59:47Z",
            "summary": "This paper is a compilation of well-known results about Zadoff-Chu sequences,\nincluding all proofs with a consistent mathematical notation, for easy\nreference. Moreover, for a Zadoff-Chu sequence $x_u[n]$ of prime length\n$N_{\\text{ZC}}$ and root index $u$, a formula is derived that allows computing\nthe first term (frequency zero) of its discrete Fourier transform, $X_u[0]$,\nwith constant complexity independent of the sequence length, as opposed to\naccumulating all its $N_{\\text{ZC}}$ terms. The formula stems from a famous\nresult in analytic number theory and is an interesting complement to the fact\nthat the discrete Fourier transform of a Zadoff-Chu sequence is itself a\nZadoff-Chu sequence whose terms are scaled by $X_u[0]$. Finally, the paper\nconcludes with a brief analysis of time-continuous signals derived from\nZadoff-Chu sequences, especially those obtained by OFDM-modulating a Zadoff-Chu\nsequence.",
            "author": [
                "David Gregoratti",
                "Xavier Arteaga",
                "Joaquim Broquetas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01035v1",
                "http://arxiv.org/pdf/2311.01035v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01034v1",
            "title": "Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation",
            "updated": "2023-11-02T06:56:50Z",
            "published": "2023-11-02T06:56:50Z",
            "summary": "Pre-trained Vision-Language Models (VLMs), such as CLIP, have shown enhanced\nperformance across a range of tasks that involve the integration of visual and\nlinguistic modalities. When CLIP is used for depth estimation tasks, the\npatches, divided from the input images, can be combined with a series of\nsemantic descriptions of the depth information to obtain similarity results.\nThe coarse estimation of depth is then achieved by weighting and summing the\ndepth values, called depth bins, corresponding to the predefined semantic\ndescriptions. The zero-shot approach circumvents the computational and\ntime-intensive nature of traditional fully-supervised depth estimation methods.\nHowever, this method, utilizing fixed depth bins, may not effectively\ngeneralize as images from different scenes may exhibit distinct depth\ndistributions. To address this challenge, we propose a few-shot-based method\nwhich learns to adapt the VLMs for monocular depth estimation to balance\ntraining costs and generalization capabilities. Specifically, it assigns\ndifferent depth bins for different scenes, which can be selected by the model\nduring inference. Additionally, we incorporate learnable prompts to preprocess\nthe input text to convert the easily human-understood text into easily\nmodel-understood vectors and further enhance the performance. With only one\nimage per scene for training, our extensive experiment results on the NYU V2\nand KITTI dataset demonstrate that our method outperforms the previous\nstate-of-the-art method by up to 10.6\\% in terms of MARE.",
            "author": [
                "Xueting Hu",
                "Ce Zhang",
                "Yi Zhang",
                "Bowen Hai",
                "Ke Yu",
                "Zhihai He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01034v1",
                "http://arxiv.org/pdf/2311.01034v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01030v1",
            "title": "Joint Learning of Local and Global Features for Aspect-based Sentiment\n  Classification",
            "updated": "2023-11-02T06:43:50Z",
            "published": "2023-11-02T06:43:50Z",
            "summary": "Aspect-based sentiment classification (ASC) aims to judge the sentiment\npolarity conveyed by the given aspect term in a sentence. The sentiment\npolarity is not only determined by the local context but also related to the\nwords far away from the given aspect term. Most recent efforts related to the\nattention-based models can not sufficiently distinguish which words they should\npay more attention to in some cases. Meanwhile, graph-based models are coming\ninto ASC to encode syntactic dependency tree information. But these models do\nnot fully leverage syntactic dependency trees as they neglect to incorporate\ndependency relation tag information into representation learning effectively.\nIn this paper, we address these problems by effectively modeling the local and\nglobal features. Firstly, we design a local encoder containing: a Gaussian mask\nlayer and a covariance self-attention layer. The Gaussian mask layer tends to\nadjust the receptive field around aspect terms adaptively to deemphasize the\neffects of unrelated words and pay more attention to local information. The\ncovariance self-attention layer can distinguish the attention weights of\ndifferent words more obviously. Furthermore, we propose a dual-level graph\nattention network as a global encoder by fully employing dependency tag\ninformation to capture long-distance information effectively. Our model\nachieves state-of-the-art performance on both SemEval 2014 and Twitter\ndatasets.",
            "author": [
                "Hao Niu",
                "Yun Xiong",
                "Xiaosu Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01030v1",
                "http://arxiv.org/pdf/2311.01030v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01028v1",
            "title": "Nonnegative/Binary Matrix Factorization for Image Classification using\n  Quantum Annealing",
            "updated": "2023-11-02T06:41:27Z",
            "published": "2023-11-02T06:41:27Z",
            "summary": "Classical computing has borne witness to the development of machine learning.\nThe integration of quantum technology into this mix will lead to unimaginable\nbenefits and be regarded as a giant leap forward in mankind's ability to\ncompute. Demonstrating the benefits of this integration now becomes essential.\nWith the advance of quantum computing, several machine-learning techniques have\nbeen proposed that use quantum annealing. In this study, we implement a matrix\nfactorization method using quantum annealing for image classification and\ncompare the performance with traditional machine-learning methods.\nNonnegative/binary matrix factorization (NBMF) was originally introduced as a\ngenerative model, and we propose a multiclass classification model as an\napplication. We extract the features of handwritten digit images using NBMF and\napply them to solve the classification problem. Our findings show that when the\namount of data, features, and epochs is small, the accuracy of models trained\nby NBMF is superior to classical machine-learning methods, such as neural\nnetworks. Moreover, we found that training models using a quantum annealing\nsolver significantly reduces computation time. Under certain conditions, there\nis a benefit to using quantum annealing technology with machine learning.",
            "author": [
                "Hinako Asaoka",
                "Kazue Kudo"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-43729-z",
                "http://arxiv.org/abs/2311.01028v1",
                "http://arxiv.org/pdf/2311.01028v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01025v1",
            "title": "Incorporating Language-Driven Appearance Knowledge Units with Visual\n  Cues in Pedestrian Detection",
            "updated": "2023-11-02T06:38:19Z",
            "published": "2023-11-02T06:38:19Z",
            "summary": "Large language models (LLMs) have shown their capability in understanding\ncontextual and semantic information regarding appearance knowledge of\ninstances. In this paper, we introduce a novel approach to utilize the strength\nof an LLM in understanding contextual appearance variations and to leverage its\nknowledge into a vision model (here, pedestrian detection). While pedestrian\ndetection is considered one of crucial tasks directly related with our safety\n(e.g., intelligent driving system), it is challenging because of varying\nappearances and poses in diverse scenes. Therefore, we propose to formulate\nlanguage-driven appearance knowledge units and incorporate them with visual\ncues in pedestrian detection. To this end, we establish description corpus\nwhich includes numerous narratives describing various appearances of\npedestrians and others. By feeding them through an LLM, we extract appearance\nknowledge sets that contain the representations of appearance variations. After\nthat, we perform a task-prompting process to obtain appearance knowledge units\nwhich are representative appearance knowledge guided to be relevant to a\ndownstream pedestrian detection task. Finally, we provide plentiful appearance\ninformation by integrating the language-driven knowledge units with visual\ncues. Through comprehensive experiments with various pedestrian detectors, we\nverify the effectiveness of our method showing noticeable performance gains and\nachieving state-of-the-art detection performance.",
            "author": [
                "Sungjune Park",
                "Hyunjun Kim",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01025v1",
                "http://arxiv.org/pdf/2311.01025v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01023v1",
            "title": "Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview\n  Learning for Medical Image Segmentation",
            "updated": "2023-11-02T06:31:08Z",
            "published": "2023-11-02T06:31:08Z",
            "summary": "The utilisation of deep learning segmentation algorithms that learn complex\norgans and tissue patterns and extract essential regions of interest from the\nnoisy background to improve the visual ability for medical image diagnosis has\nachieved impressive results in Medical Image Computing (MIC). This thesis\nfocuses on retinal blood vessel segmentation tasks, providing an extensive\nliterature review of deep learning-based medical image segmentation approaches\nwhile comparing the methodologies and empirical performances. The work also\nexamines the limitations of current state-of-the-art methods by pointing out\nthe two significant existing limitations: data size constraints and the\ndependency on high computational resources. To address such problems, this work\nproposes a novel efficient, simple multiview learning framework that\ncontrastively learns invariant vessel feature representation by comparing with\nmultiple augmented views by various transformations to overcome data shortage\nand improve generalisation ability. Moreover, the hybrid network architecture\nintegrates the attention mechanism into a Convolutional Neural Network to\nfurther capture complex continuous curvilinear vessel structures. The result\ndemonstrates the proposed method validated on the CHASE-DB1 dataset, attaining\nthe highest F1 score of 83.46% and the highest Intersection over Union (IOU)\nscore of 71.62% with UNet structure, surpassing existing benchmark UNet-based\nmethods by 1.95% and 2.8%, respectively. The combination of the metrics\nindicates the model detects the vessel object accurately with a highly\ncoincidental location with the ground truth. Moreover, the proposed approach\ncould be trained within 30 minutes by consuming less than 3 GB GPU RAM, and\nsuch characteristics support the efficient implementation for real-world\napplications and deployments.",
            "author": [
                "Yanming Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01023v1",
                "http://arxiv.org/pdf/2311.01023v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01022v1",
            "title": "NeuroWrite: Predictive Handwritten Digit Classification using Deep\n  Neural Networks",
            "updated": "2023-11-02T06:29:53Z",
            "published": "2023-11-02T06:29:53Z",
            "summary": "The rapid evolution of deep neural networks has revolutionized the field of\nmachine learning, enabling remarkable advancements in various domains. In this\narticle, we introduce NeuroWrite, a unique method for predicting the\ncategorization of handwritten digits using deep neural networks. Our model\nexhibits outstanding accuracy in identifying and categorising handwritten\ndigits by utilising the strength of convolutional neural networks (CNNs) and\nrecurrent neural networks (RNNs).In this article, we give a thorough\nexamination of the data preparation methods, network design, and training\nmethods used in NeuroWrite. By implementing state-of-the-art techniques, we\nshowcase how NeuroWrite can achieve high classification accuracy and robust\ngeneralization on handwritten digit datasets, such as MNIST. Furthermore, we\nexplore the model's potential for real-world applications, including digit\nrecognition in digitized documents, signature verification, and automated\npostal code recognition. NeuroWrite is a useful tool for computer vision and\npattern recognition because of its performance and adaptability.The\narchitecture, training procedure, and evaluation metrics of NeuroWrite are\ncovered in detail in this study, illustrating how it can improve a number of\napplications that call for handwritten digit classification. The outcomes show\nthat NeuroWrite is a promising method for raising the bar for deep neural\nnetwork-based handwritten digit recognition.",
            "author": [
                "Kottakota Asish",
                "P. Sarath Teja",
                "R. Kishan Chander",
                "Dr. D. Deva Hema"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01022v1",
                "http://arxiv.org/pdf/2311.01022v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "68T10, 68T45, 68T60",
                "I.4.8; I.5.2; J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01021v1",
            "title": "ABC-based Forecasting in State Space Models",
            "updated": "2023-11-02T06:27:46Z",
            "published": "2023-11-02T06:27:46Z",
            "summary": "Approximate Bayesian Computation (ABC) has gained popularity as a method for\nconducting inference and forecasting in complex models, most notably those\nwhich are intractable in some sense. In this paper we use ABC to produce\nprobabilistic forecasts in state space models (SSMs). Whilst ABC-based\nforecasting in correctly-specified SSMs has been studied, the misspecified case\nhas not been investigated, and it is that case which we emphasize. We invoke\nrecent principles of 'focused' Bayesian prediction, whereby Bayesian updates\nare driven by a scoring rule that rewards predictive accuracy; the aim being to\nproduce predictives that perform well in that rule, despite misspecification.\nTwo methods are investigated for producing the focused predictions. In a\nsimulation setting, 'coherent' predictions are in evidence for both methods:\nthe predictive constructed via the use of a particular scoring rule predicts\nbest according to that rule. Importantly, both focused methods typically\nproduce more accurate forecasts than an exact, but misspecified, predictive. An\nempirical application to a truly intractable SSM completes the paper.",
            "author": [
                "Chaya Weerasinghe",
                "Ruben Loaiza-Maya",
                "Gael M. Martin",
                "David T. Frazier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01021v1",
                "http://arxiv.org/pdf/2311.01021v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01018v1",
            "title": "Expanding Expressiveness of Diffusion Models with Limited Data via\n  Self-Distillation based Fine-Tuning",
            "updated": "2023-11-02T06:24:06Z",
            "published": "2023-11-02T06:24:06Z",
            "summary": "Training diffusion models on limited datasets poses challenges in terms of\nlimited generation capacity and expressiveness, leading to unsatisfactory\nresults in various downstream tasks utilizing pretrained diffusion models, such\nas domain translation and text-guided image manipulation. In this paper, we\npropose Self-Distillation for Fine-Tuning diffusion models (SDFT), a\nmethodology to address these challenges by leveraging diverse features from\ndiffusion models pretrained on large source datasets. SDFT distills more\ngeneral features (shape, colors, etc.) and less domain-specific features\n(texture, fine details, etc) from the source model, allowing successful\nknowledge transfer without disturbing the training process on target datasets.\nThe proposed method is not constrained by the specific architecture of the\nmodel and thus can be generally adopted to existing frameworks. Experimental\nresults demonstrate that SDFT enhances the expressiveness of the diffusion\nmodel with limited datasets, resulting in improved generation capabilities\nacross various downstream tasks.",
            "author": [
                "Jiwan Hur",
                "Jaehyun Choi",
                "Gyojin Han",
                "Dong-Jae Lee",
                "Junmo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01018v1",
                "http://arxiv.org/pdf/2311.01018v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01017v2",
            "title": "Learning Unsupervised World Models for Autonomous Driving via Discrete\n  Diffusion",
            "updated": "2023-11-24T00:24:06Z",
            "published": "2023-11-02T06:21:56Z",
            "summary": "Learning world models can teach an agent how the world works in an\nunsupervised manner. Even though it can be viewed as a special case of sequence\nmodeling, progress for scaling world models on robotic applications such as\nautonomous driving has been somewhat less rapid than scaling language models\nwith Generative Pre-trained Transformers (GPT). We identify two reasons as\nmajor bottlenecks: dealing with complex and unstructured observation space, and\nhaving a scalable generative model. Consequently, we propose a novel world\nmodeling approach that first tokenizes sensor observations with VQVAE, then\npredicts the future via discrete diffusion. To efficiently decode and denoise\ntokens in parallel, we recast Masked Generative Image Transformer into the\ndiscrete diffusion framework with a few simple changes, resulting in notable\nimprovement. When applied to learning world models on point cloud observations,\nour model reduces prior SOTA Chamfer distance by more than 65% for 1s\nprediction, and more than 50% for 3s prediction, across NuScenes, KITTI\nOdometry, and Argoverse2 datasets. Our results demonstrate that discrete\ndiffusion on tokenized agent experience can unlock the power of GPT-like\nunsupervised learning for robotic agents.",
            "author": [
                "Lunjun Zhang",
                "Yuwen Xiong",
                "Ze Yang",
                "Sergio Casas",
                "Rui Hu",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01017v2",
                "http://arxiv.org/pdf/2311.01017v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01016v1",
            "title": "Visual Analytics for Efficient Image Exploration and User-Guided Image\n  Captioning",
            "updated": "2023-11-02T06:21:35Z",
            "published": "2023-11-02T06:21:35Z",
            "summary": "Recent advancements in pre-trained large-scale language-image models have\nushered in a new era of visual comprehension, offering a significant leap\nforward. These breakthroughs have proven particularly instrumental in\naddressing long-standing challenges that were previously daunting. Leveraging\nthese innovative techniques, this paper tackles two well-known issues within\nthe realm of visual analytics: (1) the efficient exploration of large-scale\nimage datasets and identification of potential data biases within them; (2) the\nevaluation of image captions and steering of their generation process. On the\none hand, by visually examining the captions automatically generated from\nlanguage-image models for an image dataset, we gain deeper insights into the\nsemantic underpinnings of the visual contents, unearthing data biases that may\nbe entrenched within the dataset. On the other hand, by depicting the\nassociation between visual contents and textual captions, we expose the\nweaknesses of pre-trained language-image models in their captioning capability\nand propose an interactive interface to steer caption generation. The two parts\nhave been coalesced into a coordinated visual analytics system, fostering\nmutual enrichment of visual and textual elements. We validate the effectiveness\nof the system with domain practitioners through concrete case studies with\nlarge-scale image datasets.",
            "author": [
                "Yiran Li",
                "Junpeng Wang",
                "Prince Aboagye",
                "Michael Yeh",
                "Yan Zheng",
                "Liang Wang",
                "Wei Zhang",
                "Kwan-Liu Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01016v1",
                "http://arxiv.org/pdf/2311.01016v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01015v1",
            "title": "Act As You Wish: Fine-Grained Control of Motion Diffusion Model with\n  Hierarchical Semantic Graphs",
            "updated": "2023-11-02T06:20:23Z",
            "published": "2023-11-02T06:20:23Z",
            "summary": "Most text-driven human motion generation methods employ sequential modeling\napproaches, e.g., transformer, to extract sentence-level text representations\nautomatically and implicitly for human motion synthesis. However, these compact\ntext representations may overemphasize the action names at the expense of other\nimportant properties and lack fine-grained details to guide the synthesis of\nsubtly distinct motion. In this paper, we propose hierarchical semantic graphs\nfor fine-grained control over motion generation. Specifically, we disentangle\nmotion descriptions into hierarchical semantic graphs including three levels of\nmotions, actions, and specifics. Such global-to-local structures facilitate a\ncomprehensive understanding of motion description and fine-grained control of\nmotion generation. Correspondingly, to leverage the coarse-to-fine topology of\nhierarchical semantic graphs, we decompose the text-to-motion diffusion process\ninto three semantic levels, which correspond to capturing the overall motion,\nlocal actions, and action specifics. Extensive experiments on two benchmark\nhuman motion datasets, including HumanML3D and KIT, with superior performances,\njustify the efficacy of our method. More encouragingly, by modifying the edge\nweights of hierarchical semantic graphs, our method can continuously refine the\ngenerated motion, which may have a far-reaching impact on the community. Code\nand pre-training weights are available at\nhttps://github.com/jpthu17/GraphMotion.",
            "author": [
                "Peng Jin",
                "Yang Wu",
                "Yanbo Fan",
                "Zhongqian Sun",
                "Yang Wei",
                "Li Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01015v1",
                "http://arxiv.org/pdf/2311.01015v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01013v1",
            "title": "Evaluation Measures of Individual Item Fairness for Recommender Systems:\n  A Critical Study",
            "updated": "2023-11-02T06:15:49Z",
            "published": "2023-11-02T06:15:49Z",
            "summary": "Fairness is an emerging and challenging topic in recommender systems. In\nrecent years, various ways of evaluating and therefore improving fairness have\nemerged. In this study, we examine existing evaluation measures of fairness in\nrecommender systems. Specifically, we focus solely on exposure-based fairness\nmeasures of individual items that aim to quantify the disparity in how\nindividual items are recommended to users, separate from item relevance to\nusers. We gather all such measures and we critically analyse their theoretical\nproperties. We identify a series of limitations in each of them, which\ncollectively may render the affected measures hard or impossible to interpret,\nto compute, or to use for comparing recommendations. We resolve these\nlimitations by redefining or correcting the affected measures, or we argue why\ncertain limitations cannot be resolved. We further perform a comprehensive\nempirical analysis of both the original and our corrected versions of these\nfairness measures, using real-world and synthetic datasets. Our analysis\nprovides novel insights into the relationship between measures based on\ndifferent fairness concepts, and different levels of measure sensitivity and\nstrictness. We conclude with practical suggestions of which fairness measures\nshould be used and when. Our code is publicly available. To our knowledge, this\nis the first critical comparison of individual item fairness measures in\nrecommender systems.",
            "author": [
                "Theresia Veronika Rampisela",
                "Maria Maistro",
                "Tuukka Ruotsalo",
                "Christina Lioma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01013v1",
                "http://arxiv.org/pdf/2311.01013v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01012v2",
            "title": "COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances",
            "updated": "2023-11-13T18:19:44Z",
            "published": "2023-11-02T06:14:41Z",
            "summary": "We present publicly available COPAL-ID, a novel Indonesian language common\nsense reasoning dataset. Unlike the previous Indonesian COPA dataset\n(XCOPA-ID), COPAL-ID incorporates Indonesian local and cultural nuances, and\ntherefore, provides a more natural portrayal of day-to-day causal reasoning\nwithin the Indonesian cultural sphere. Professionally written by natives from\nscratch, COPAL-ID is more fluent and free from awkward phrases, unlike the\ntranslated XCOPA-ID. In addition, we present COPAL-ID in both standard\nIndonesian and in Jakartan Indonesian--a dialect commonly used in daily\nconversation. COPAL-ID poses a greater challenge for existing open-sourced and\nclosed state-of-the-art multilingual language models, yet is trivially easy for\nhumans. Our findings suggest that even the current best open-source,\nmultilingual model struggles to perform well, achieving 65.47% accuracy on\nCOPAL-ID, significantly lower than on the culturally-devoid XCOPA-ID (79.40%).\nDespite GPT-4's impressive score, it suffers the same performance degradation\ncompared to its XCOPA-ID score, and it still falls short of human performance.\nThis shows that these language models are still way behind in comprehending the\nlocal nuances of Indonesian.",
            "author": [
                "Haryo Akbarianto Wibowo",
                "Erland Hilman Fuadi",
                "Made Nindyatama Nityasya",
                "Radityo Eko Prasojo",
                "Alham Fikri Aji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01012v2",
                "http://arxiv.org/pdf/2311.01012v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01010v1",
            "title": "Exploring Unified Perspective For Fast Shapley Value Estimation",
            "updated": "2023-11-02T06:09:24Z",
            "published": "2023-11-02T06:09:24Z",
            "summary": "Shapley values have emerged as a widely accepted and trustworthy tool,\ngrounded in theoretical axioms, for addressing challenges posed by black-box\nmodels like deep neural networks. However, computing Shapley values encounters\nexponential complexity in the number of features. Various approaches, including\nApproSemivalue, KernelSHAP, and FastSHAP, have been explored to expedite the\ncomputation. We analyze the consistency of existing works and conclude that\nstochastic estimators can be unified as the linear transformation of importance\nsampling of feature subsets. Based on this, we investigate the possibility of\ndesigning simple amortized estimators and propose a straightforward and\nefficient one, SimSHAP, by eliminating redundant techniques. Extensive\nexperiments conducted on tabular and image datasets validate the effectiveness\nof our SimSHAP, which significantly accelerates the computation of accurate\nShapley values.",
            "author": [
                "Borui Zhang",
                "Baotong Tian",
                "Wenzhao Zheng",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01010v1",
                "http://arxiv.org/pdf/2311.01010v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01009v1",
            "title": "Revamping AI Models in Dermatology: Overcoming Critical Challenges for\n  Enhanced Skin Lesion Diagnosis",
            "updated": "2023-11-02T06:08:49Z",
            "published": "2023-11-02T06:08:49Z",
            "summary": "The surge in developing deep learning models for diagnosing skin lesions\nthrough image analysis is notable, yet their clinical black faces challenges.\nCurrent dermatology AI models have limitations: limited number of possible\ndiagnostic outputs, lack of real-world testing on uncommon skin lesions,\ninability to detect out-of-distribution images, and over-reliance on\ndermoscopic images. To address these, we present an All-In-One\n\\textbf{H}ierarchical-\\textbf{O}ut of Distribution-\\textbf{C}linical Triage\n(HOT) model. For a clinical image, our model generates three outputs: a\nhierarchical prediction, an alert for out-of-distribution images, and a\nrecommendation for dermoscopy if clinical image alone is insufficient for\ndiagnosis. When the recommendation is pursued, it integrates both clinical and\ndermoscopic images to deliver final diagnosis. Extensive experiments on a\nrepresentative cutaneous lesion dataset demonstrate the effectiveness and\nsynergy of each component within our framework. Our versatile model provides\nvaluable decision support for lesion diagnosis and sets a promising precedent\nfor medical AI applications.",
            "author": [
                "Deval Mehta",
                "Brigid Betz-Stablein",
                "Toan D Nguyen",
                "Yaniv Gal",
                "Adrian Bowling",
                "Martin Haskett",
                "Maithili Sashindranath",
                "Paul Bonnington",
                "Victoria Mar",
                "H Peter Soyer",
                "Zongyuan Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01009v1",
                "http://arxiv.org/pdf/2311.01009v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01004v1",
            "title": "Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning\n  for Medical Image Captioning",
            "updated": "2023-11-02T05:44:13Z",
            "published": "2023-11-02T05:44:13Z",
            "summary": "With the development of multimodality and large language models, the deep\nlearning-based technique for medical image captioning holds the potential to\noffer valuable diagnostic recommendations. However, current generic text and\nimage pre-trained models do not yield satisfactory results when it comes to\ndescribing intricate details within medical images. In this paper, we present a\nnovel medical image captioning method guided by the segment anything model\n(SAM) to enable enhanced encoding with both general and detailed feature\nextraction. In addition, our approach employs a distinctive pre-training\nstrategy with mixed semantic learning to simultaneously capture both the\noverall information and finer details within medical images. We demonstrate the\neffectiveness of this approach, as it outperforms the pre-trained BLIP2 model\non various evaluation metrics for generating descriptions of medical images.",
            "author": [
                "Gaoang Wang",
                "Zhenyu Zhang",
                "Benlu Wang",
                "Weijie Liang",
                "Yizhi Li",
                "Xuechen Guo",
                "Guanhong Wang",
                "Shiyan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01004v1",
                "http://arxiv.org/pdf/2311.01004v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01002v1",
            "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling\n  Accuracy",
            "updated": "2023-11-02T05:40:26Z",
            "published": "2023-11-02T05:40:26Z",
            "summary": "Data pruning, which aims to downsize a large training set into a small\ninformative subset, is crucial for reducing the enormous computational costs of\nmodern deep learning. Though large-scale data collections invariably contain\nannotation noise and numerous robust learning methods have been developed, data\npruning for the noise-robust learning scenario has received little attention.\nWith state-of-the-art Re-labeling methods that self-correct erroneous labels\nwhile training, it is challenging to identify which subset induces the most\naccurate re-labeling of erroneous labels in the entire training set. In this\npaper, we formalize the problem of data pruning with re-labeling. We first show\nthat the likelihood of a training example being correctly re-labeled is\nproportional to the prediction confidence of its neighborhood in the subset.\nTherefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a\nsubset maximizing the total neighborhood confidence of all training examples,\nthereby maximizing the re-labeling accuracy and generalization performance.\nExtensive experiments on four real and one synthetic noisy datasets show that\n\\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as\nwell as those with a standard model by up to 21.6%.",
            "author": [
                "Dongmin Park",
                "Seola Choi",
                "Doyoung Kim",
                "Hwanjun Song",
                "Jae-Gil Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01002v1",
                "http://arxiv.org/pdf/2311.01002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01001v1",
            "title": "Fully Quantized Always-on Face Detector Considering Mobile Image Sensors",
            "updated": "2023-11-02T05:35:49Z",
            "published": "2023-11-02T05:35:49Z",
            "summary": "Despite significant research on lightweight deep neural networks (DNNs)\ndesigned for edge devices, the current face detectors do not fully meet the\nrequirements for \"intelligent\" CMOS image sensors (iCISs) integrated with\nembedded DNNs. These sensors are essential in various practical applications,\nsuch as energy-efficient mobile phones and surveillance systems with always-on\ncapabilities. One noteworthy limitation is the absence of suitable face\ndetectors for the always-on scenario, a crucial aspect of image sensor-level\napplications. These detectors must operate directly with sensor RAW data before\nthe image signal processor (ISP) takes over. This gap poses a significant\nchallenge in achieving optimal performance in such scenarios. Further research\nand development are necessary to bridge this gap and fully leverage the\npotential of iCIS applications. In this study, we aim to bridge the gap by\nexploring extremely low-bit lightweight face detectors, focusing on the\nalways-on face detection scenario for mobile image sensor applications. To\nachieve this, our proposed model utilizes sensor-aware synthetic RAW inputs,\nsimulating always-on face detection processed \"before\" the ISP chain. Our\napproach employs ternary (-1, 0, 1) weights for potential implementations in\nimage sensors, resulting in a relatively simple network architecture with\nshallow layers and extremely low-bitwidth. Our method demonstrates reasonable\nface detection performance and excellent efficiency in simulation studies,\noffering promising possibilities for practical always-on face detectors in\nreal-world applications.",
            "author": [
                "Haechang Lee",
                "Wongi Jeong",
                "Dongil Ryu",
                "Hyunwoo Je",
                "Albert No",
                "Kijeong Kim",
                "Se Young Chun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01001v1",
                "http://arxiv.org/pdf/2311.01001v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00998v1",
            "title": "Replicable Benchmarking of Neural Machine Translation (NMT) on\n  Low-Resource Local Languages in Indonesia",
            "updated": "2023-11-02T05:27:48Z",
            "published": "2023-11-02T05:27:48Z",
            "summary": "Neural machine translation (NMT) for low-resource local languages in\nIndonesia faces significant challenges, including the need for a representative\nbenchmark and limited data availability. This work addresses these challenges\nby comprehensively analyzing training NMT systems for four low-resource local\nlanguages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our\nstudy encompasses various training approaches, paradigms, data sizes, and a\npreliminary study into using large language models for synthetic low-resource\nlanguages parallel data generation. We reveal specific trends and insights into\npractical strategies for low-resource language translation. Our research\ndemonstrates that despite limited computational resources and textual data,\nseveral of our NMT systems achieve competitive performances, rivaling the\ntranslation quality of zero-shot gpt-3.5-turbo. These findings significantly\nadvance NMT for low-resource languages, offering valuable guidance for\nresearchers in similar contexts.",
            "author": [
                "Lucky Susanto",
                "Ryandito Diandaru",
                "Adila Krisnadhi",
                "Ayu Purwarianti",
                "Derry Wijaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00998v1",
                "http://arxiv.org/pdf/2311.00998v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00996v2",
            "title": "VCISR: Blind Single Image Super-Resolution with Video Compression\n  Synthetic Data",
            "updated": "2023-11-23T03:58:04Z",
            "published": "2023-11-02T05:24:19Z",
            "summary": "In the blind single image super-resolution (SISR) task, existing works have\nbeen successful in restoring image-level unknown degradations. However, when a\nsingle video frame becomes the input, these works usually fail to address\ndegradations caused by video compression, such as mosquito noise, ringing,\nblockiness, and staircase noise. In this work, we for the first time, present a\nvideo compression-based degradation model to synthesize low-resolution image\ndata in the blind SISR task. Our proposed image synthesizing method is widely\napplicable to existing image datasets, so that a single degraded image can\ncontain distortions caused by the lossy video compression algorithms. This\novercomes the leak of feature diversity in video data and thus retains the\ntraining efficiency. By introducing video coding artifacts to SISR degradation\nmodels, neural networks can super-resolve images with the ability to restore\nvideo compression degradations, and achieve better results on restoring generic\ndistortions caused by image compression as well. Our proposed approach achieves\nsuperior performance in SOTA no-reference Image Quality Assessment, and shows\nbetter visual quality on various datasets. In addition, we evaluate the SISR\nneural network trained with our degradation model on video super-resolution\n(VSR) datasets. Compared to architectures specifically designed for the VSR\npurpose, our method exhibits similar or better performance, evidencing that the\npresented strategy on infusing video-based degradation is generalizable to\naddress more complicated compression artifacts even without temporal cues.",
            "author": [
                "Boyang Wang",
                "Bowen Liu",
                "Shiyu Liu",
                "Fengyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00996v2",
                "http://arxiv.org/pdf/2311.00996v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00995v1",
            "title": "A Chronological Survey of Theoretical Advancements in Generative\n  Adversarial Networks for Computer Vision",
            "updated": "2023-11-02T05:11:47Z",
            "published": "2023-11-02T05:11:47Z",
            "summary": "Generative Adversarial Networks (GANs) have been workhorse generative models\nfor last many years, especially in the research field of computer vision.\nAccordingly, there have been many significant advancements in the theory and\napplication of GAN models, which are notoriously hard to train, but produce\ngood results if trained well. There have been many a surveys on GANs,\norganizing the vast GAN literature from various focus and perspectives.\nHowever, none of the surveys brings out the important chronological aspect: how\nthe multiple challenges of employing GAN models were solved one-by-one over\ntime, across multiple landmark research works. This survey intends to bridge\nthat gap and present some of the landmark research works on the theory and\napplication of GANs, in chronological order.",
            "author": [
                "Hrishikesh Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00995v1",
                "http://arxiv.org/pdf/2311.00995v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00994v1",
            "title": "LaughTalk: Expressive 3D Talking Head Generation with Laughter",
            "updated": "2023-11-02T05:04:33Z",
            "published": "2023-11-02T05:04:33Z",
            "summary": "Laughter is a unique expression, essential to affirmative social interactions\nof humans. Although current 3D talking head generation methods produce\nconvincing verbal articulations, they often fail to capture the vitality and\nsubtleties of laughter and smiles despite their importance in social context.\nIn this paper, we introduce a novel task to generate 3D talking heads capable\nof both articulate speech and authentic laughter. Our newly curated dataset\ncomprises 2D laughing videos paired with pseudo-annotated and human-validated\n3D FLAME parameters and vertices. Given our proposed dataset, we present a\nstrong baseline with a two-stage training scheme: the model first learns to\ntalk and then acquires the ability to express laughter. Extensive experiments\ndemonstrate that our method performs favorably compared to existing approaches\nin both talking head generation and expressing laughter signals. We further\nexplore potential applications on top of our proposed method for rigging\nrealistic avatars.",
            "author": [
                "Kim Sung-Bin",
                "Lee Hyun",
                "Da Hye Hong",
                "Suekyeong Nam",
                "Janghoon Ju",
                "Tae-Hyun Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00994v1",
                "http://arxiv.org/pdf/2311.00994v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00993v1",
            "title": "Scalable Probabilistic Forecasting in Retail with Gradient Boosted\n  Trees: A Practitioner's Approach",
            "updated": "2023-11-02T04:46:32Z",
            "published": "2023-11-02T04:46:32Z",
            "summary": "The recent M5 competition has advanced the state-of-the-art in retail\nforecasting. However, we notice important differences between the competition\nchallenge and the challenges we face in a large e-commerce company. The\ndatasets in our scenario are larger (hundreds of thousands of time series), and\ne-commerce can afford to have a larger assortment than brick-and-mortar\nretailers, leading to more intermittent data. To scale to larger dataset sizes\nwith feasible computational effort, firstly, we investigate a two-layer\nhierarchy and propose a top-down approach to forecasting at an aggregated level\nwith less amount of series and intermittency, and then disaggregating to obtain\nthe decision-level forecasts. Probabilistic forecasts are generated under\ndistributional assumptions. Secondly, direct training at the lower level with\nsubsamples can also be an alternative way of scaling. Performance of modelling\nwith subsets is evaluated with the main dataset. Apart from a proprietary\ndataset, the proposed scalable methods are evaluated using the Favorita dataset\nand the M5 dataset. We are able to show the differences in characteristics of\nthe e-commerce and brick-and-mortar retail datasets. Notably, our top-down\nforecasting framework enters the top 50 of the original M5 competition, even\nwith models trained at a higher level under a much simpler setting.",
            "author": [
                "Xueying Long",
                "Quang Bui",
                "Grady Oktavian",
                "Daniel F. Schmidt",
                "Christoph Bergmeir",
                "Rakshitha Godahewa",
                "Seong Per Lee",
                "Kaifeng Zhao",
                "Paul Condylis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00993v1",
                "http://arxiv.org/pdf/2311.00993v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00992v2",
            "title": "Computing random $r$-orthogonal Latin squares",
            "updated": "2023-11-09T20:38:35Z",
            "published": "2023-11-02T04:46:23Z",
            "summary": "Two Latin squares of order $n$ are $r$-orthogonal if, when superimposed,\nthere are exactly $r$ distinct ordered pairs. The spectrum of all values of $r$\nfor Latin squares of order $n$ is known. A Latin square $A$ of order $n$ is\n$r$-self-orthogonal if $A$ and its transpose are $r$-orthogonal. The spectrum\nof all values of $r$ is known for all orders $n\\ne 14$. We develop randomized\nalgorithms for computing pairs of $r$-orthogonal Latin squares of order $n$ and\nalgorithms for computing $r$-self-orthogonal Latin squares of order $n$.",
            "author": [
                "Sergey Bereg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00992v2",
                "http://arxiv.org/pdf/2311.00992v2"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00991v1",
            "title": "IR-UWB Radar-based Situational Awareness System for\n  Smartphone-Distracted Pedestrians",
            "updated": "2023-11-02T04:45:04Z",
            "published": "2023-11-02T04:45:04Z",
            "summary": "With the widespread adoption of smartphones, ensuring pedestrian safety on\nroads has become a critical concern due to smartphone distraction. This paper\nproposes a novel and real-time assistance system called UWB-assisted Safe Walk\n(UASW) for obstacle detection and warns users about real-time situations. The\nproposed method leverages Impulse Radio Ultra-Wideband (IR-UWB) radar embedded\nin the smartphone, which provides excellent range resolution and high noise\nresilience using short pulses. We implemented UASW specifically for Android\nsmartphones with IR-UWB connectivity. The framework uses complex Channel\nImpulse Response (CIR) data to integrate rule-based obstacle detection with\nartificial neural network (ANN) based obstacle classification. The performance\nof the proposed UASW system is analyzed using real-time collected data. The\nresults show that the proposed system achieves an obstacle detection accuracy\nof up to 97% and obstacle classification accuracy of up to 95% with an\ninference delay of 26.8 ms. The results highlight the effectiveness of UASW in\nassisting smartphone-distracted pedestrians and improving their situational\nawareness.",
            "author": [
                "Jamsheed Manja Ppallan",
                "Ruchi Pandey",
                "Yellappa Damam",
                "Vijay Narayan Tiwari",
                "Karthikeyan Arunachalam",
                "Antariksha Ray"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00991v1",
                "http://arxiv.org/pdf/2311.00991v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00990v1",
            "title": "VideoDreamer: Customized Multi-Subject Text-to-Video Generation with\n  Disen-Mix Finetuning",
            "updated": "2023-11-02T04:38:50Z",
            "published": "2023-11-02T04:38:50Z",
            "summary": "Customized text-to-video generation aims to generate text-guided videos with\ncustomized user-given subjects, which has gained increasing attention recently.\nHowever, existing works are primarily limited to generating videos for a single\nsubject, leaving the more challenging problem of customized multi-subject\ntext-to-video generation largely unexplored. In this paper, we fill this gap\nand propose a novel VideoDreamer framework. VideoDreamer can generate\ntemporally consistent text-guided videos that faithfully preserve the visual\nfeatures of the given multiple subjects. Specifically, VideoDreamer leverages\nthe pretrained Stable Diffusion with latent-code motion dynamics and temporal\ncross-frame attention as the base video generator. The video generator is\nfurther customized for the given multiple subjects by the proposed Disen-Mix\nFinetuning and Human-in-the-Loop Re-finetuning strategy, which can tackle the\nattribute binding problem of multi-subject generation. We also introduce\nMultiStudioBench, a benchmark for evaluating customized multi-subject\ntext-to-video generation models. Extensive experiments demonstrate the\nremarkable ability of VideoDreamer to generate videos with new content such as\nnew events and backgrounds, tailored to the customized multiple subjects. Our\nproject page is available at https://videodreamer23.github.io/.",
            "author": [
                "Hong Chen",
                "Xin Wang",
                "Guanning Zeng",
                "Yipeng Zhang",
                "Yuwei Zhou",
                "Feilin Han",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00990v1",
                "http://arxiv.org/pdf/2311.00990v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00987v1",
            "title": "CML-MOTS: Collaborative Multi-task Learning for Multi-Object Tracking\n  and Segmentation",
            "updated": "2023-11-02T04:32:24Z",
            "published": "2023-11-02T04:32:24Z",
            "summary": "The advancement of computer vision has pushed visual analysis tasks from\nstill images to the video domain. In recent years, video instance segmentation,\nwhich aims to track and segment multiple objects in video frames, has drawn\nmuch attention for its potential applications in various emerging areas such as\nautonomous driving, intelligent transportation, and smart retail. In this\npaper, we propose an effective framework for instance-level visual analysis on\nvideo frames, which can simultaneously conduct object detection, instance\nsegmentation, and multi-object tracking. The core idea of our method is\ncollaborative multi-task learning which is achieved by a novel structure, named\nassociative connections among detection, segmentation, and tracking task heads\nin an end-to-end learnable CNN. These additional connections allow information\npropagation across multiple related tasks, so as to benefit these tasks\nsimultaneously. We evaluate the proposed method extensively on KITTI MOTS and\nMOTS Challenge datasets and obtain quite encouraging results.",
            "author": [
                "Yiming Cui",
                "Cheng Han",
                "Dongfang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00987v1",
                "http://arxiv.org/pdf/2311.00987v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00986v1",
            "title": "M&M3D: Multi-Dataset Training and Efficient Network for Multi-view 3D\n  Object Detection",
            "updated": "2023-11-02T04:28:51Z",
            "published": "2023-11-02T04:28:51Z",
            "summary": "In this research, I proposed a network structure for multi-view 3D object\ndetection using camera-only data and a Bird's-Eye-View map. My work is based on\na current key challenge domain adaptation and visual data transfer. Although\nmany excellent camera-only 3D object detection has been continuously proposed,\nmany research work risk dramatic performance drop when the networks are trained\non the source domain but tested on a different target domain. Then I found it\nis very surprising that predictions on bounding boxes and classes are still\nreplied to on 2D networks. Based on the domain gap assumption on various 3D\ndatasets, I found they still shared a similar data extraction on the same BEV\nmap size and camera data transfer. Therefore, to analyze the domain gap\ninfluence on the current method and to make good use of 3D space information\namong the dataset and the real world, I proposed a transfer learning method and\nTransformer construction to study the 3D object detection on NuScenes-mini and\nLyft. Through multi-dataset training and a detection head from the Transformer,\nthe network demonstrated good data migration performance and efficient\ndetection performance by using 3D anchor query and 3D positional information.\nRelying on only a small amount of source data and the existing large model\npre-training weights, the efficient network manages to achieve competitive\nresults on the new target domain. Moreover, my study utilizes 3D information as\navailable semantic information and 2D multi-view image features blending into\nthe visual-language transfer design. In the final 3D anchor box prediction and\nobject classification, my network achieved good results on standard metrics of\n3D object detection, which differs from dataset-specific models on each\ntraining domain without any fine-tuning.",
            "author": [
                "Hang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00986v1",
                "http://arxiv.org/pdf/2311.00986v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01478v1",
            "title": "Adversary ML Resilience in Autonomous Driving Through Human Centered\n  Perception Mechanisms",
            "updated": "2023-11-02T04:11:45Z",
            "published": "2023-11-02T04:11:45Z",
            "summary": "Physical adversarial attacks on road signs are continuously exploiting\nvulnerabilities in modern day autonomous vehicles (AVs) and impeding their\nability to correctly classify what type of road sign they encounter. Current\nmodels cannot generalize input data well, resulting in overfitting or\nunderfitting. In overfitting, the model memorizes the input data but cannot\ngeneralize to new scenarios. In underfitting, the model does not learn enough\nof the input data to accurately classify these road signs. This paper explores\nthe resilience of autonomous driving systems against three main physical\nadversarial attacks (tape, graffiti, illumination), specifically targeting\nobject classifiers. Several machine learning models were developed and\nevaluated on two distinct datasets: road signs (stop signs, speed limit signs,\ntraffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons,\ncircles, squares, and triangles). The study compared algorithm performance\nunder different conditions, including clean and adversarial training and\ntesting on these datasets. To build robustness against attacks, defense\ntechniques like adversarial training and transfer learning were implemented.\nResults demonstrated transfer learning models played a crucial role in\nperformance by allowing knowledge gained from shape training to improve\ngeneralizability of road sign classification, despite the datasets being\ncompletely different. The paper suggests future research directions, including\nhuman-in-the-loop validation, security analysis, real-world testing, and\nexplainable AI for transparency. This study aims to contribute to improving\nsecurity and robustness of object classifiers in autonomous vehicles and\nmitigating adversarial example impacts on driving systems.",
            "author": [
                "Aakriti Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01478v1",
                "http://arxiv.org/pdf/2311.01478v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "68",
                "I.4.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04916v1",
            "title": "Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks",
            "updated": "2023-11-02T04:01:04Z",
            "published": "2023-11-02T04:01:04Z",
            "summary": "Islamophobic language is a prevalent challenge on online social interaction\nplatforms. Identifying and eliminating such hatred is a crucial step towards a\nfuture of harmony and peace. This study presents a novel paradigm for\nidentifying and explaining hate speech towards Islam using graph neural\nnetworks. Utilizing the intrinsic ability of graph neural networks to find,\nextract, and use relationships across disparate data points, our model\nconsistently achieves outstanding performance while offering explanations for\nthe underlying correlations and causation.",
            "author": [
                "Azmine Toushik Wasi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04916v1",
                "http://arxiv.org/pdf/2311.04916v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00982v1",
            "title": "The c-differential properties of a class of power functions",
            "updated": "2023-11-02T03:59:24Z",
            "published": "2023-11-02T03:59:24Z",
            "summary": "Power functions with low $c$-differential uniformity have been widely studied\nnot only because of their strong resistance to multiplicative differential\nattacks, but also low implementation cost in hardware. Furthermore, the\n$c$-differential spectrum of a function gives a more precise characterization\nof its $c$-differential properties. Let $f(x)=x^{\\frac{p^n+3}{2}}$ be a power\nfunction over the finite field $\\mathbb{F}_{p^{n}}$, where $p\\neq3$ is an odd\nprime and $n$ is a positive integer. In this paper, for all primes $p\\neq3$, by\ninvestigating certain character sums with regard to elliptic curves and\ncomputing the number of solutions of a system of equations over\n$\\mathbb{F}_{p^{n}}$, we determine explicitly the $(-1)$-differential spectrum\nof $f$ with a unified approach. We show that if $p^n \\equiv 3 \\pmod 4$, then\n$f$ is a differentially $(-1,3)$-uniform function except for\n$p^n\\in\\{7,19,23\\}$ where $f$ is an APcN function, and if $p^n \\equiv 1 \\pmod\n4$, the $(-1)$-differential uniformity of $f$ is equal to $4$. In addition, an\nupper bound of the $c$-differential uniformity of $f$ is also given.",
            "author": [
                "Huan Zhou",
                "Xiaoni Du",
                "Wenping Yuan",
                "Xingbin Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00982v1",
                "http://arxiv.org/pdf/2311.00982v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00981v1",
            "title": "Fast generation of mock galaxy catalogues with COLA",
            "updated": "2023-11-02T03:57:39Z",
            "published": "2023-11-02T03:57:39Z",
            "summary": "We investigate the feasibility of using COmoving Lagrangian Acceleration\n(COLA) technique to efficiently generate galaxy mock catalogues that can\naccurately reproduce the statistical properties of observed galaxies. Our\nproposed scheme combines the subhalo abundance matching (SHAM) procedure with\nCOLA simulations, utilizing only three free parameters: the scatter magnitude\n($\\sigma_{\\rm scat}$) in SHAM, the initial redshift ($z_{\\rm init}$) of the\nCOLA simulation, and the time stride ($da$) used by COLA. In this\nproof-of-concept study, we focus on a subset of BOSS CMASS NGC galaxies within\nthe redshift range $z\\in [0.45, 0.55]$. We perform $\\mathtt{GADGET}$ simulation\nand low-resolution COLA simulations with various combinations of $(z_{\\rm\ninit}, da)$, each using $1024^{3}$ particles in an $800~h^{-1}{\\rm Mpc}$ box.\nBy minimizing the difference between COLA mock and CMASS NGC galaxies for the\nmonopole of the two-point correlation function (2PCF), we obtain the optimal\n$\\sigma_{\\rm scat}$. We have found that by setting $z_{\\rm init}=29$ and\n$da=1/30$, we achieve a good agreement between COLA mock and CMASS NGC galaxies\nwithin the range of 4 to $20~h^{-1}{\\rm Mpc}$, with a computational cost two\norders of magnitude lower than that of the N-body code. Moreover, a detailed\nverification is performed by comparing various statistical properties, such as\nanisotropic 2PCF, three-point clustering, and power spectrum multipoles, which\nshows similar performance between GADGET mock and COLA mock catalogues with the\nCMASS NGC galaxies. Furthermore, we assess the robustness of the COLA mock\ncatalogues across different cosmological models, demonstrating consistent\nresults in the resulting 2PCFs. Our findings suggest that COLA simulations are\na promising tool for efficiently generating mock catalogues for emulators and\nmachine learning analyses in exploring the large-scale structure of the\nUniverse.",
            "author": [
                "Jiacheng Ding",
                "Shaohong Li",
                "Yi Zheng",
                "Xiaolin Luo",
                "Le Zhang",
                "Xiao-Dong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00981v1",
                "http://arxiv.org/pdf/2311.00981v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00980v1",
            "title": "MAAIG: Motion Analysis And Instruction Generation",
            "updated": "2023-11-02T03:53:25Z",
            "published": "2023-11-02T03:53:25Z",
            "summary": "Many people engage in self-directed sports training at home but lack the\nreal-time guidance of professional coaches, making them susceptible to injuries\nor the development of incorrect habits. In this paper, we propose a novel\napplication framework called MAAIG(Motion Analysis And Instruction Generation).\nIt can generate embedding vectors for each frame based on user-provided sports\naction videos. These embedding vectors are associated with the 3D skeleton of\neach frame and are further input into a pretrained T5 model. Ultimately, our\nmodel utilizes this information to generate specific sports instructions. It\nhas the capability to identify potential issues and provide real-time guidance\nin a manner akin to professional coaches, helping users improve their sports\nskills and avoid injuries.",
            "author": [
                "Wei-Hsin Yeh",
                "Pei Hsin Lin",
                "Yu-An Su",
                "Wen Hsiang Cheng",
                "Lun-Wei Ku"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3611380.3630165",
                "http://arxiv.org/abs/2311.00980v1",
                "http://arxiv.org/pdf/2311.00980v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.2.10; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00979v2",
            "title": "Overhead Line Defect Recognition Based on Unsupervised Semantic\n  Segmentation",
            "updated": "2023-12-06T23:51:11Z",
            "published": "2023-11-02T03:52:59Z",
            "summary": "Overhead line inspection greatly benefits from defect recognition using\nvisible light imagery. Addressing the limitations of existing feature\nextraction techniques and the heavy data dependency of deep learning\napproaches, this paper introduces a novel defect recognition framework. This is\nbuilt on the Faster RCNN network and complemented by unsupervised semantic\nsegmentation. The approach involves identifying the type and location of the\ntarget equipment, utilizing semantic segmentation to differentiate between the\ndevice and its backdrop, and finally employing similarity measures and logical\nrules to categorize the type of defect. Experimental results indicate that this\nmethodology focuses more on the equipment rather than the defects when\nidentifying issues in overhead lines. This leads to a notable enhancement in\naccuracy and exhibits impressive adaptability. Thus, offering a fresh\nperspective for automating the inspection of distribution network equipment.",
            "author": [
                "Weixi Wang",
                "Xichen Zhong",
                "Xin Li",
                "Sizhe Li",
                "Xun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00979v2",
                "http://arxiv.org/pdf/2311.00979v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00975v2",
            "title": "Autonomous Learning of Generative Models with Chemical Reaction Network\n  Ensembles",
            "updated": "2023-11-06T19:07:59Z",
            "published": "2023-11-02T03:46:23Z",
            "summary": "Can a micron sized sack of interacting molecules autonomously learn an\ninternal model of a complex and fluctuating environment? We draw insights from\ncontrol theory, machine learning theory, chemical reaction network theory, and\nstatistical physics to develop a general architecture whereby a broad class of\nchemical systems can autonomously learn complex distributions. Our construction\ntakes the form of a chemical implementation of machine learning's optimization\nworkhorse: gradient descent on the relative entropy cost function. We show how\nthis method can be applied to optimize any detailed balanced chemical reaction\nnetwork and that the construction is capable of using hidden units to learn\ncomplex distributions. This result is then recast as a form of integral\nfeedback control. Finally, due to our use of an explicit physical model of\nlearning, we are able to derive thermodynamic costs and trade-offs associated\nto this process.",
            "author": [
                "William Poole",
                "Thomas E. Ouldridge",
                "Manoj Gopalkrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00975v2",
                "http://arxiv.org/pdf/2311.00975v2"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.ET",
                "cs.LG",
                "cs.NE",
                "cs.SY",
                "eess.SY",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00974v2",
            "title": "CloudSim Express: A Novel Framework for Rapid Low Code Simulation of\n  Cloud Computing Environments",
            "updated": "2023-11-11T01:56:09Z",
            "published": "2023-11-02T03:44:21Z",
            "summary": "Cloud computing environment simulators enable cost-effective experimentation\nof novel infrastructure designs and management approaches by avoiding\nsignificant costs incurred from repetitive deployments in real Cloud platforms.\nHowever, widely used Cloud environment simulators compromise on usability due\nto complexities in design and configuration, along with the added overhead of\nprogramming language expertise. Existing approaches attempting to reduce this\noverhead, such as script-based simulators and Graphical User Interface (GUI)\nbased simulators, often compromise on the extensibility of the simulator.\nSimulator extensibility allows for customization at a fine-grained level, thus\nreducing it significantly affects flexibility in creating simulations. To\naddress these challenges, we propose an architectural framework to enable\nhuman-readable script-based simulations in existing Cloud environment\nsimulators while minimizing the impact on simulator extensibility. We implement\nthe proposed framework for the widely used Cloud environment simulator, the\nCloudSim toolkit, and compare it against state-of-the-art baselines using a\npractical use case. The resulting framework, called CloudSim Express, achieves\nextensible simulations while surpassing baselines with over a 71.43% reduction\nin code complexity and an 89.42% reduction in lines of code.",
            "author": [
                "Tharindu B. Hewage",
                "Shashikant Ilager",
                "Maria A. Rodriguez",
                "Rajkumar Buyya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00974v2",
                "http://arxiv.org/pdf/2311.00974v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00971v1",
            "title": "An Integrated Framework Integrating Monte Carlo Tree Search and\n  Supervised Learning for Train Timetabling Problem",
            "updated": "2023-11-02T03:39:14Z",
            "published": "2023-11-02T03:39:14Z",
            "summary": "The single-track railway train timetabling problem (TTP) is an important and\ncomplex problem. This article proposes an integrated Monte Carlo Tree Search\n(MCTS) computing framework that combines heuristic methods, unsupervised\nlearning methods, and supervised learning methods for solving TTP in discrete\naction spaces. This article first describes the mathematical model and\nsimulation system dynamics of TTP, analyzes the characteristics of the solution\nfrom the perspective of MCTS, and proposes some heuristic methods to improve\nMCTS. This article considers these methods as planners in the proposed\nframework. Secondly, this article utilizes deep convolutional neural networks\nto approximate the value of nodes and further applies them to the MCTS search\nprocess, referred to as learners. The experiment shows that the proposed\nheuristic MCTS method is beneficial for solving TTP; The algorithm framework\nthat integrates planners and learners can improve the data efficiency of\nsolving TTP; The proposed method provides a new paradigm for solving TTP.",
            "author": [
                "Feiyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00971v1",
                "http://arxiv.org/pdf/2311.00971v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00970v1",
            "title": "Lightweight super resolution network for point cloud geometry\n  compression",
            "updated": "2023-11-02T03:34:51Z",
            "published": "2023-11-02T03:34:51Z",
            "summary": "This paper presents an approach for compressing point cloud geometry by\nleveraging a lightweight super-resolution network. The proposed method involves\ndecomposing a point cloud into a base point cloud and the interpolation\npatterns for reconstructing the original point cloud. While the base point\ncloud can be efficiently compressed using any lossless codec, such as\nGeometry-based Point Cloud Compression, a distinct strategy is employed for\nhandling the interpolation patterns. Rather than directly compressing the\ninterpolation patterns, a lightweight super-resolution network is utilized to\nlearn this information through overfitting. Subsequently, the network parameter\nis transmitted to assist in point cloud reconstruction at the decoder side.\nNotably, our approach differentiates itself from lookup table-based methods,\nallowing us to obtain more accurate interpolation patterns by accessing a\nbroader range of neighboring voxels at an acceptable computational cost.\nExperiments on MPEG Cat1 (Solid) and Cat2 datasets demonstrate the remarkable\ncompression performance achieved by our method.",
            "author": [
                "Wei Zhang",
                "Dingquan Li",
                "Ge Li",
                "Wen Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00970v1",
                "http://arxiv.org/pdf/2311.00970v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00967v1",
            "title": "Vision-Language Interpreter for Robot Task Planning",
            "updated": "2023-11-02T03:32:30Z",
            "published": "2023-11-02T03:32:30Z",
            "summary": "Large language models (LLMs) are accelerating the development of\nlanguage-guided robot planners. Meanwhile, symbolic planners offer the\nadvantage of interpretability. This paper proposes a new task that bridges\nthese two trends, namely, multimodal planning problem specification. The aim is\nto generate a problem description (PD), a machine-readable file used by the\nplanners to find a plan. By generating PDs from language instruction and scene\nobservation, we can drive symbolic planners in a language-guided framework. We\npropose a Vision-Language Interpreter (ViLaIn), a new framework that generates\nPDs using state-of-the-art LLM and vision-language models. ViLaIn can refine\ngenerated PDs via error message feedback from the symbolic planner. Our aim is\nto answer the question: How accurately can ViLaIn and the symbolic planner\ngenerate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset\ncalled the problem description generation (ProDG) dataset. The framework is\nevaluated with four new evaluation metrics. Experimental results show that\nViLaIn can generate syntactically correct problems with more than 99% accuracy\nand valid plans with more than 58% accuracy.",
            "author": [
                "Keisuke Shirai",
                "Cristian C. Beltran-Hernandez",
                "Masashi Hamaya",
                "Atsushi Hashimoto",
                "Shohei Tanaka",
                "Kento Kawaharazuka",
                "Kazutoshi Tanaka",
                "Yoshitaka Ushiku",
                "Shinsuke Mori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00967v1",
                "http://arxiv.org/pdf/2311.00967v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02104v1",
            "title": "Efficient Symbolic Policy Learning with Differentiable Symbolic\n  Expression",
            "updated": "2023-11-02T03:27:51Z",
            "published": "2023-11-02T03:27:51Z",
            "summary": "Deep reinforcement learning (DRL) has led to a wide range of advances in\nsequential decision-making tasks. However, the complexity of neural network\npolicies makes it difficult to understand and deploy with limited computational\nresources. Currently, employing compact symbolic expressions as symbolic\npolicies is a promising strategy to obtain simple and interpretable policies.\nPrevious symbolic policy methods usually involve complex training processes and\npre-trained neural network policies, which are inefficient and limit the\napplication of symbolic policies. In this paper, we propose an efficient\ngradient-based learning method named Efficient Symbolic Policy Learning (ESPL)\nthat learns the symbolic policy from scratch in an end-to-end way. We introduce\na symbolic network as the search space and employ a path selector to find the\ncompact symbolic policy. By doing so we represent the policy with a\ndifferentiable symbolic expression and train it in an off-policy manner which\nfurther improves the efficiency. In addition, in contrast with previous\nsymbolic policies which only work in single-task RL because of complexity, we\nexpand ESPL on meta-RL to generate symbolic policies for unseen tasks.\nExperimentally, we show that our approach generates symbolic policies with\nhigher performance and greatly improves data efficiency for single-task RL. In\nmeta-RL, we demonstrate that compared with neural network policies the proposed\nsymbolic policy achieves higher performance and efficiency and shows the\npotential to be interpretable.",
            "author": [
                "Jiaming Guo",
                "Rui Zhang",
                "Shaohui Peng",
                "Qi Yi",
                "Xing Hu",
                "Ruizhi Chen",
                "Zidong Du",
                "Xishan Zhang",
                "Ling Li",
                "Qi Guo",
                "Yunji Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02104v1",
                "http://arxiv.org/pdf/2311.02104v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00963v1",
            "title": "Log canonical thresholds of high multiplicity reduced plane curves",
            "updated": "2023-11-02T03:11:56Z",
            "published": "2023-11-02T03:11:56Z",
            "summary": "We compute log canonical thresholds of reduced plane curves of degree $d$ at\npoints of multiplicity $d-1$. As a consequence, we describe all possible values\nof log canonical threshold that are less than $2/(d-1)$ for reduced plane\ncurves of degree $d$. In addition, we compute log canonical thresholds for all\nreduced plane curves of degree less than 6.",
            "author": [
                "Erik Paemurru",
                "Nivedita Viswanathan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00963v1",
                "http://arxiv.org/pdf/2311.00963v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "14B05, 14E15, 14H20, 14H50, 32S25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00962v1",
            "title": "Detecting Generated Images by Real Images Only",
            "updated": "2023-11-02T03:09:37Z",
            "published": "2023-11-02T03:09:37Z",
            "summary": "As deep learning technology continues to evolve, the images yielded by\ngenerative models are becoming more and more realistic, triggering people to\nquestion the authenticity of images. Existing generated image detection methods\ndetect visual artifacts in generated images or learn discriminative features\nfrom both real and generated images by massive training. This learning paradigm\nwill result in efficiency and generalization issues, making detection methods\nalways lag behind generation methods. This paper approaches the generated image\ndetection problem from a new perspective: Start from real images. By finding\nthe commonality of real images and mapping them to a dense subspace in feature\nspace, the goal is that generated images, regardless of their generative model,\nare then projected outside the subspace. As a result, images from different\ngenerative models can be detected, solving some long-existing problems in the\nfield. Experimental results show that although our method was trained only by\nreal images and uses 99.9\\% less training data than other deep learning-based\nmethods, it can compete with state-of-the-art methods and shows excellent\nperformance in detecting emerging generative models with high inference\nefficiency. Moreover, the proposed method shows robustness against various\npost-processing. These advantages allow the method to be used in real-world\nscenarios.",
            "author": [
                "Xiuli Bi",
                "Bo Liu",
                "Fan Yang",
                "Bin Xiao",
                "Weisheng Li",
                "Gao Huang",
                "Pamela C. Cosman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00962v1",
                "http://arxiv.org/pdf/2311.00962v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00961v1",
            "title": "Concatenated Masked Autoencoders as Spatial-Temporal Learner",
            "updated": "2023-11-02T03:08:26Z",
            "published": "2023-11-02T03:08:26Z",
            "summary": "Learning representations from videos requires understanding continuous motion\nand visual correspondences between frames. In this paper, we introduce the\nConcatenated Masked Autoencoders (CatMAE) as a spatial-temporal learner for\nself-supervised video representation learning. For the input sequence of video\nframes, CatMAE keeps the initial frame unchanged while applying substantial\nmasking (95%) to subsequent frames. The encoder in CatMAE is responsible for\nencoding visible patches for each frame individually; subsequently, for each\nmasked frame, the decoder leverages visible patches from both previous and\ncurrent frames to reconstruct the original image. Our proposed method enables\nthe model to estimate the motion information between visible patches, match the\ncorrespondences between preceding and succeeding frames, and ultimately learn\nthe evolution of scenes. Furthermore, we propose a new data augmentation\nstrategy, Video-Reverse (ViRe), which uses reversed video frames as the model's\nreconstruction targets. This further encourages the model to utilize continuous\nmotion details and correspondences to complete the reconstruction, thereby\nenhancing the model's capabilities. Compared to the most advanced pre-training\nmethods, CatMAE achieves a leading level in video segmentation tasks and action\nrecognition tasks.",
            "author": [
                "Zhouqiang Jiang",
                "Bowen Wang",
                "Tong Xiang",
                "Zhaofeng Niu",
                "Hong Tang",
                "Guangshun Li",
                "Liangzhi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00961v1",
                "http://arxiv.org/pdf/2311.00961v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00960v1",
            "title": "Trajectory Similarity Measurement: An Efficiency Perspective",
            "updated": "2023-11-02T03:07:26Z",
            "published": "2023-11-02T03:07:26Z",
            "summary": "Trajectories that capture object movement have numerous applications, in\nwhich similarity computation between trajectories often plays a key role.\nTraditionally, the similarity between two trajectories is quantified by means\nof heuristic measures, e.g., Hausdorff or ERP, that operate directly on the\ntrajectories. In contrast, recent studies exploit deep learning to map\ntrajectories to d-dimensional vectors, called embeddings. Then, some distance\nmeasure, e.g., Manhattan or Euclidean, is applied to the embeddings to quantify\ntrajectory similarity. The resulting similarities are inaccurate: they only\napproximate the similarities obtained using the heuristic measures. As distance\ncomputation on embeddings is efficient, focus has been on achieving embeddings\nyielding high accuracy.\n  Adopting an efficiency perspective, we analyze the time complexities of both\nthe heuristic and the learning-based approaches, finding that the time\ncomplexities of the former approaches are not necessarily higher. Through\nextensive experiments on open datasets, we find that, on both CPUs and GPUs,\nonly a few learning-based approaches can deliver the promised higher\nefficiency, when the embeddings can be pre-computed, while heuristic approaches\nare more efficient for one-off computations. Among the learning-based\napproaches, the self-attention-based ones are the fastest to learn embeddings\nthat also yield the highest accuracy for similarity queries. These results have\nimplications for the use of trajectory similarity approaches given different\napplication requirements.",
            "author": [
                "Yanchuan Chang",
                "Egemen Tanin",
                "Gao Cong",
                "Christian S. Jensen",
                "Jianzhong Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00960v1",
                "http://arxiv.org/pdf/2311.00960v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00959v1",
            "title": "Dynamic Fair Federated Learning Based on Reinforcement Learning",
            "updated": "2023-11-02T03:05:40Z",
            "published": "2023-11-02T03:05:40Z",
            "summary": "Federated learning enables a collaborative training and optimization of\nglobal models among a group of devices without sharing local data samples.\nHowever, the heterogeneity of data in federated learning can lead to unfair\nrepresentation of the global model across different devices. To address the\nfairness issue in federated learning, we propose a dynamic q fairness federated\nlearning algorithm with reinforcement learning, called DQFFL. DQFFL aims to\nmitigate the discrepancies in device aggregation and enhance the fairness of\ntreatment for all groups involved in federated learning. To quantify fairness,\nDQFFL leverages the performance of the global federated model on each device\nand incorporates {\\alpha}-fairness to transform the preservation of fairness\nduring federated aggregation into the distribution of client weights in the\naggregation process. Considering the sensitivity of parameters in measuring\nfairness, we propose to utilize reinforcement learning for dynamic parameters\nduring aggregation. Experimental results demonstrate that our DQFFL outperforms\nthe state-of-the-art methods in terms of overall performance, fairness and\nconvergence speed.",
            "author": [
                "Weikang Chen",
                "Junping Du",
                "Yingxia Shao",
                "Jia Wang",
                "Yangxi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00959v1",
                "http://arxiv.org/pdf/2311.00959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10749v1",
            "title": "Measuring Five Accountable Talk Moves to Improve Instruction at Scale",
            "updated": "2023-11-02T03:04:50Z",
            "published": "2023-11-02T03:04:50Z",
            "summary": "Providing consistent, individualized feedback to teachers on their\ninstruction can improve student learning outcomes. Such feedback can especially\nbenefit novice instructors who teach on online platforms and have limited\naccess to instructional training. To build scalable measures of instruction, we\nfine-tune RoBERTa and GPT models to identify five instructional talk moves\ninspired by accountable talk theory: adding on, connecting, eliciting, probing\nand revoicing students' ideas. We fine-tune these models on a newly annotated\ndataset of 2500 instructor utterances derived from transcripts of small group\ninstruction in an online computer science course, Code in Place. Although we\nfind that GPT-3 consistently outperforms RoBERTa in terms of precision, its\nrecall varies significantly. We correlate the instructors' use of each talk\nmove with indicators of student engagement and satisfaction, including\nstudents' section attendance, section ratings, and assignment completion rates.\nWe find that using talk moves generally correlates positively with student\noutcomes, and connecting student ideas has the largest positive impact. These\nresults corroborate previous research on the effectiveness of accountable talk\nmoves and provide exciting avenues for using these models to provide\ninstructors with useful, scalable feedback.",
            "author": [
                "Ashlee Kupor",
                "Candice Morgan",
                "Dorottya Demszky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10749v1",
                "http://arxiv.org/pdf/2311.10749v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00958v1",
            "title": "IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End\n  Task-Oriented Dialogue Systems",
            "updated": "2023-11-02T03:01:53Z",
            "published": "2023-11-02T03:01:53Z",
            "summary": "Task-oriented dialogue (ToD) systems have been mostly created for\nhigh-resource languages, such as English and Chinese. However, there is a need\nto develop ToD systems for other regional or local languages to broaden their\nability to comprehend the dialogue contexts in various languages. This paper\nintroduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We\nextend two English ToD datasets to Indonesian, comprising four different\ndomains by delexicalization to efficiently reduce the size of annotations. To\nensure a high-quality data collection, we hire native speakers to manually\ntranslate the dialogues. Along with the original English datasets, these new\nIndonesian datasets serve as an effective benchmark for evaluating Indonesian\nand English ToD systems as well as exploring the potential benefits of\ncross-lingual and bilingual transfer learning approaches.",
            "author": [
                "Muhammad Dehan Al Kautsar",
                "Rahmah Khoirussyifa' Nurdini",
                "Samuel Cahyawijaya",
                "Genta Indra Winata",
                "Ayu Purwarianti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00958v1",
                "http://arxiv.org/pdf/2311.00958v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00957v1",
            "title": "An equivalent reformulation and multi-proximity gradient algorithms for\n  a class of nonsmooth fractional programming",
            "updated": "2023-11-02T03:00:34Z",
            "published": "2023-11-02T03:00:34Z",
            "summary": "In this paper, we consider a class of structured fractional programs, where\nthe numerator part is the sum of a block-separable (possibly nonsmooth\nnonconvex) function and a locally Lipschitz differentiable (possibly nonconvex)\nfunction, while the denominator is a convex (possibly nonsmooth) function. We\nfirst present a novel reformulation for the original problem and show the\nrelationship between optimal solutions, critical points and KL exponents of\nthese two problems. Inspired by the reformulation, we propose a flexible\nframework of multi-proximity gradient algorithms (MPGA), which computes the\nproximity operator with respect to the Fenchel conjugate associated with the\nconvex denominator of the original problem rather than evaluating its\nsubgradient as in the existing methods. Also, MPGA employs a nonmonotone\nlinear-search scheme in its gradient descent step, since the smooth part in the\nnumerator of the original problem is not globally Lipschitz differentiable.\nBased on the framework of MPGA, we develop two specific algorithms, namely,\ncyclic MPGA and randomized MPGA, and establish their subsequential convergence\nunder mild conditions. Moreover, the sequential convergence of cyclic MPGA with\nthe monotone line-search (CMPGA_ML) is guaranteed if the extended objective\nassociated with the reformulated problem satisfies the Kurdyka-{\\L}ojasiewicz\n(KL) property and some other mild assumptions. In particular, we prove that the\ncorresponding KL exponents are 1/2 for several special cases of the fractional\nprograms, and so, CMPGA_ML exhibits a linear convergence rate. Finally, some\npreliminary numerical experiments are performed to demonstrate the efficiency\nof our proposed algorithms.",
            "author": [
                "Junpeng Zhou",
                "Na Zhang",
                "Qia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00957v1",
                "http://arxiv.org/pdf/2311.00957v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00953v1",
            "title": "Blending Reward Functions via Few Expert Demonstrations for Faithful and\n  Accurate Knowledge-Grounded Dialogue Generation",
            "updated": "2023-11-02T02:42:41Z",
            "published": "2023-11-02T02:42:41Z",
            "summary": "The development of trustworthy conversational information-seeking systems\nrelies on dialogue models that can generate faithful and accurate responses\nbased on relevant knowledge texts. However, two main challenges hinder this\ntask. Firstly, language models may generate hallucinations due to data biases\npresent in their pretraining corpus. Secondly, knowledge texts often contain\nredundant and irrelevant information that distracts the model's attention from\nthe relevant text span. Previous works use additional data annotations on the\nknowledge texts to learn a knowledge identification module in order to bypass\nirrelevant information, but collecting such high-quality span annotations can\nbe costly. In this work, we leverage reinforcement learning algorithms to\novercome the above challenges by introducing a novel reward function. Our\nreward function combines an accuracy metric and a faithfulness metric to\nprovide a balanced quality judgment of generated responses, which can be used\nas a cost-effective approximation to a human preference reward model when only\na few preference annotations are available. Empirical experiments on two\nconversational information-seeking datasets demonstrate that our method can\ncompete with other strong supervised learning baselines.",
            "author": [
                "Wanyu Du",
                "Yangfeng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00953v1",
                "http://arxiv.org/pdf/2311.00953v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00949v1",
            "title": "Optimal Noise pursuit for Augmenting Text-to-Video Generation",
            "updated": "2023-11-02T02:33:09Z",
            "published": "2023-11-02T02:33:09Z",
            "summary": "Despite the remarkable progress in text-to-video generation, existing\ndiffusion-based models often exhibit instability in terms of noise during\ninference. Specifically, when different noises are fed for the given text,\nthese models produce videos that differ significantly in terms of both frame\nquality and temporal consistency. With this observation, we posit that there\nexists an optimal noise matched to each textual input; however, the widely\nadopted strategies of random noise sampling often fail to capture it. In this\npaper, we argue that the optimal noise can be approached through inverting the\ngroundtruth video using the established noise-video mapping derived from the\ndiffusion model. Nevertheless, the groundtruth video for the text prompt is not\navailable during inference. To address this challenge, we propose to\napproximate the optimal noise via a search and inversion pipeline. Given a text\nprompt, we initially search for a video from a predefined candidate pool that\nclosely relates to the text prompt. Subsequently, we invert the searched video\ninto the noise space, which serves as an improved noise prompt for the textual\ninput. In addition to addressing noise, we also observe that the text prompt\nwith richer details often leads to higher-quality videos. Motivated by this, we\nfurther design a semantic-preserving rewriter to enrich the text prompt, where\na reference-guided rewriting is devised for reasonable details compensation,\nand a denoising with a hybrid semantics strategy is proposed to preserve the\nsemantic consistency. Extensive experiments on the WebVid-10M benchmark show\nthat our proposed method can improve the text-to-video models with a clear\nmargin, while introducing no optimization burden.",
            "author": [
                "Shijie Ma",
                "Huayi Xu",
                "Mengjian Li",
                "Weidong Geng",
                "Meng Wang",
                "Yaxiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00949v1",
                "http://arxiv.org/pdf/2311.00949v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00945v1",
            "title": "E3 TTS: Easy End-to-End Diffusion-based Text to Speech",
            "updated": "2023-11-02T02:22:21Z",
            "published": "2023-11-02T02:22:21Z",
            "summary": "We propose Easy End-to-End Diffusion-based Text to Speech, a simple and\nefficient end-to-end text-to-speech model based on diffusion. E3 TTS directly\ntakes plain text as input and generates an audio waveform through an iterative\nrefinement process. Unlike many prior work, E3 TTS does not rely on any\nintermediate representations like spectrogram features or alignment\ninformation. Instead, E3 TTS models the temporal structure of the waveform\nthrough the diffusion process. Without relying on additional conditioning\ninformation, E3 TTS could support flexible latent structure within the given\naudio. This enables E3 TTS to be easily adapted for zero-shot tasks such as\nediting without any additional training. Experiments show that E3 TTS can\ngenerate high-fidelity audio, approaching the performance of a state-of-the-art\nneural TTS system. Audio samples are available at https://e3tts.github.io.",
            "author": [
                "Yuan Gao",
                "Nobuyuki Morioka",
                "Yu Zhang",
                "Nanxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00945v1",
                "http://arxiv.org/pdf/2311.00945v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04915v1",
            "title": "Chain of Empathy: Enhancing Empathetic Response of Large Language Models\n  Based on Psychotherapy Models",
            "updated": "2023-11-02T02:21:39Z",
            "published": "2023-11-02T02:21:39Z",
            "summary": "We present a novel method, the Chain of Empathy (CoE) prompting, that\nutilizes insights from psychotherapy to induce Large Language Models (LLMs) to\nreason about human emotional states. This method is inspired by various\npsychotherapy approaches including Cognitive Behavioral Therapy (CBT),\nDialectical Behavior Therapy (DBT), Person Centered Therapy (PCT), and Reality\nTherapy (RT), each leading to different patterns of interpreting clients'\nmental states. LLMs without reasoning generated predominantly exploratory\nresponses. However, when LLMs used CoE reasoning, we found a more comprehensive\nrange of empathetic responses aligned with the different reasoning patterns of\neach psychotherapy model. The CBT based CoE resulted in the most balanced\ngeneration of empathetic responses. The findings underscore the importance of\nunderstanding the emotional context and how it affects human and AI\ncommunication. Our research contributes to understanding how psychotherapeutic\nmodels can be incorporated into LLMs, facilitating the development of\ncontext-specific, safer, and empathetic AI.",
            "author": [
                "Yoon Kyung Lee",
                "Inju Lee",
                "Minjung Shin",
                "Seoyeon Bae",
                "Sowon Hahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04915v1",
                "http://arxiv.org/pdf/2311.04915v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00941v1",
            "title": "Gaussian Mixture Solvers for Diffusion Models",
            "updated": "2023-11-02T02:05:38Z",
            "published": "2023-11-02T02:05:38Z",
            "summary": "Recently, diffusion models have achieved great success in generative tasks.\nSampling from diffusion models is equivalent to solving the reverse diffusion\nstochastic differential equations (SDEs) or the corresponding probability flow\nordinary differential equations (ODEs). In comparison, SDE-based solvers can\ngenerate samples of higher quality and are suited for image translation tasks\nlike stroke-based synthesis. During inference, however, existing SDE-based\nsolvers are severely constrained by the efficiency-effectiveness dilemma. Our\ninvestigation suggests that this is because the Gaussian assumption in the\nreverse transition kernel is frequently violated (even in the case of simple\nmixture data) given a limited number of discretization steps. To overcome this\nlimitation, we introduce a novel class of SDE-based solvers called\n\\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver\nestimates the first three-order moments and optimizes the parameters of a\nGaussian mixture transition kernel using generalized methods of moments in each\nstep during sampling. Empirically, our solver outperforms numerous SDE-based\nsolvers in terms of sample quality in image generation and stroke-based\nsynthesis in various diffusion models, which validates the motivation and\neffectiveness of GMS. Our code is available at\nhttps://github.com/Guohanzhong/GMS.",
            "author": [
                "Hanzhong Guo",
                "Cheng Lu",
                "Fan Bao",
                "Tianyu Pang",
                "Shuicheng Yan",
                "Chao Du",
                "Chongxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00941v1",
                "http://arxiv.org/pdf/2311.00941v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00939v1",
            "title": "Accelerated Data-Driven Discovery and Screening of Two-Dimensional\n  Magnets Using Graph Neural Networks",
            "updated": "2023-11-02T02:03:30Z",
            "published": "2023-11-02T02:03:30Z",
            "summary": "Two-dimensional (2D) magnets have transformative potential in spintronics\napplications. In this study, we use Graph Neural Networks (GNNs) to accelerate\nthe discovery of novel 2D magnetic materials. Using data from the Materials\nProject database and the Computational 2D materials database (C2DB), we train\nthree GNN architectures on a dataset of 1190 magnetic monolayers with energy\nabove the convex hull $E_{\\text{hull}}$ less than 0.3 eV/atom. Our Crystal\nDiffusion Variational Auto Encoder (CDVAE) generates around 11,000 material\ncandidates. Subsequent training on two Atomistic Line Graph Neural Networks\n(ALIGNN) achieves a 93$\\%$ accuracy in predicting magnetic monolayers and a\nmean average error of 0.039 eV/atom for $E_{\\text{hull}}$ predictions. After\nnarrowing down candidates based on magnetic likelihood and predicted energy,\nand constraining the atom count in the monolayer to four or fewer, we\nidentified 158 candidates. These are validated using Density-Functional Theory\n(DFT) to confirm their magnetic and energetic favorability resulting in 150\nmaterials magnetic monolayer with $E_{\\text{hull}} < 0.3$ eV/atom. Our\nmethodology offers a way to accelerate exploring and predicting potential 2D\nmagnetic materials, contributing to the ongoing computational and experimental\nefforts aimed at the discovery of new 2D magnets.",
            "author": [
                "Ahmed Elrashidy",
                "James Della-Giustina",
                "Jia-An Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00939v1",
                "http://arxiv.org/pdf/2311.00939v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00938v1",
            "title": "Bridging the Gap: Addressing Discrepancies in Diffusion Model Training\n  for Classifier-Free Guidance",
            "updated": "2023-11-02T02:03:12Z",
            "published": "2023-11-02T02:03:12Z",
            "summary": "Diffusion models have emerged as a pivotal advancement in generative models,\nsetting new standards to the quality of the generated instances. In the current\npaper we aim to underscore a discrepancy between conventional training methods\nand the desired conditional sampling behavior of these models. While the\nprevalent classifier-free guidance technique works well, it's not without\nflaws. At higher values for the guidance scale parameter $w$, we often get out\nof distribution samples and mode collapse, whereas at lower values for $w$ we\nmay not get the desired specificity. To address these challenges, we introduce\nan updated loss function that better aligns training objectives with sampling\nbehaviors. Experimental validation with FID scores on CIFAR-10 elucidates our\nmethod's ability to produce higher quality samples with fewer sampling\ntimesteps, and be more robust to the choice of guidance scale $w$. We also\nexperiment with fine-tuning Stable Diffusion on the proposed loss, to provide\nearly evidence that large diffusion models may also benefit from this refined\nloss function.",
            "author": [
                "Niket Patel",
                "Luis Salamanca",
                "Luis Barba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00938v1",
                "http://arxiv.org/pdf/2311.00938v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00936v1",
            "title": "SatBird: Bird Species Distribution Modeling with Remote Sensing and\n  Citizen Science Data",
            "updated": "2023-11-02T02:00:27Z",
            "published": "2023-11-02T02:00:27Z",
            "summary": "Biodiversity is declining at an unprecedented rate, impacting ecosystem\nservices necessary to ensure food, water, and human health and well-being.\nUnderstanding the distribution of species and their habitats is crucial for\nconservation policy planning. However, traditional methods in ecology for\nspecies distribution models (SDMs) generally focus either on narrow sets of\nspecies or narrow geographical areas and there remain significant knowledge\ngaps about the distribution of species. A major reason for this is the limited\navailability of data traditionally used, due to the prohibitive amount of\neffort and expertise required for traditional field monitoring. The wide\navailability of remote sensing data and the growing adoption of citizen science\ntools to collect species observations data at low cost offer an opportunity for\nimproving biodiversity monitoring and enabling the modelling of complex\necosystems. We introduce a novel task for mapping bird species to their\nhabitats by predicting species encounter rates from satellite images, and\npresent SatBird, a satellite dataset of locations in the USA with labels\nderived from presence-absence observation data from the citizen science\ndatabase eBird, considering summer (breeding) and winter seasons. We also\nprovide a dataset in Kenya representing low-data regimes. We additionally\nprovide environmental data and species range maps for each location. We\nbenchmark a set of baselines on our dataset, including SOTA models for remote\nsensing tasks. SatBird opens up possibilities for scalably modelling properties\nof ecosystems worldwide.",
            "author": [
                "M\u00e9lisande Teng",
                "Amna Elmustafa",
                "Benjamin Akera",
                "Yoshua Bengio",
                "Hager Radi Abdelwahed",
                "Hugo Larochelle",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00936v1",
                "http://arxiv.org/pdf/2311.00936v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00933v1",
            "title": "From O(3) to Cubic CFT: Conformal Perturbation and the Large Charge\n  Sector",
            "updated": "2023-11-02T01:56:03Z",
            "published": "2023-11-02T01:56:03Z",
            "summary": "The Cubic CFT can be understood as the O(3) invariant CFT perturbed by a\nslightly relevant operator. In this paper, we use conformal perturbation theory\ntogether with the conformal data of the O(3) vector model to compute the\nanomalous dimension of scalar bilinear operators of the Cubic CFT. When the\n$Z_2$ symmetry that flips the signs of $\\phi_i$ is gauged, the Cubic model\ndescribes a certain phase transition of a quantum dimer model. The scalar\nbilinear operators are the order parameters of this phase transition. Based on\nthe conformal data of the O(3) CFT, we determine the correction to the critical\nexponent as $\\eta_{*}^{Cubic}-\\eta_{*}^{O(3)}\\approx -0.0215(49)$. The O(3)\ndata is obtained using the numerical conformal bootstrap method to study all\nfour-point correlators involving the four operators: $v=\\phi_i$, $s=\\sum_i\n\\phi_i\\phi_i$ and the leading scalar operators with O(3) isospin $j=2$ and 4.\nAccording to large charge effective theory, the leading operator with charge\n$Q$ has scaling dimension $\\Delta_{Q}=c_{3/2} Q^{3/2}+c_{1/2}Q^{1/2}$. We find\na good match with this prediction up to isospin $j=6$ for spin 0 and 2 and\nmeasured the coefficients $c_{3/2}$ and $c_{1/2}$.",
            "author": [
                "Junchen Rong",
                "Ning Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00933v1",
                "http://arxiv.org/pdf/2311.00933v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00932v1",
            "title": "Towards High-quality HDR Deghosting with Conditional Diffusion Models",
            "updated": "2023-11-02T01:53:55Z",
            "published": "2023-11-02T01:53:55Z",
            "summary": "High Dynamic Range (HDR) images can be recovered from several Low Dynamic\nRange (LDR) images by existing Deep Neural Networks (DNNs) techniques. Despite\nthe remarkable progress, DNN-based methods still generate ghosting artifacts\nwhen LDR images have saturation and large motion, which hinders potential\napplications in real-world scenarios. To address this challenge, we formulate\nthe HDR deghosting problem as an image generation that leverages LDR features\nas the diffusion model's condition, consisting of the feature condition\ngenerator and the noise predictor. Feature condition generator employs\nattention and Domain Feature Alignment (DFA) layer to transform the\nintermediate features to avoid ghosting artifacts. With the learned features as\nconditions, the noise predictor leverages a stochastic iterative denoising\nprocess for diffusion models to generate an HDR image by steering the sampling\nprocess. Furthermore, to mitigate semantic confusion caused by the saturation\nproblem of LDR images, we design a sliding window noise estimator to sample\nsmooth noise in a patch-based manner. In addition, an image space loss is\nproposed to avoid the color distortion of the estimated HDR results. We\nempirically evaluate our model on benchmark datasets for HDR imaging. The\nresults demonstrate that our approach achieves state-of-the-art performances\nand well generalization to real-world images.",
            "author": [
                "Qingsen Yan",
                "Tao Hu",
                "Yuan Sun",
                "Hao Tang",
                "Yu Zhu",
                "Wei Dong",
                "Luc Van Gool",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00932v1",
                "http://arxiv.org/pdf/2311.00932v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00926v1",
            "title": "M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place",
            "updated": "2023-11-02T01:42:52Z",
            "published": "2023-11-02T01:42:52Z",
            "summary": "With the advent of large language models and large-scale robotic datasets,\nthere has been tremendous progress in high-level decision-making for object\nmanipulation. These generic models are able to interpret complex tasks using\nlanguage commands, but they often have difficulties generalizing to\nout-of-distribution objects due to the inability of low-level action\nprimitives. In contrast, existing task-specific models excel in low-level\nmanipulation of unknown objects, but only work for a single type of action. To\nbridge this gap, we present M2T2, a single model that supplies different types\nof low-level actions that work robustly on arbitrary objects in cluttered\nscenes. M2T2 is a transformer model which reasons about contact points and\npredicts valid gripper poses for different action modes given a raw point cloud\nof the scene. Trained on a large-scale synthetic dataset with 128K scenes, M2T2\nachieves zero-shot sim2real transfer on the real robot, outperforming the\nbaseline system with state-of-the-art task-specific models by about 19% in\noverall performance and 37.5% in challenging scenes where the object needs to\nbe re-oriented for collision-free placement. M2T2 also achieves\nstate-of-the-art results on a subset of language conditioned tasks in RLBench.\nVideos of robot experiments on unseen objects in both real world and simulation\nare available on our project website https://m2-t2.github.io.",
            "author": [
                "Wentao Yuan",
                "Adithyavairavan Murali",
                "Arsalan Mousavian",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00926v1",
                "http://arxiv.org/pdf/2311.00926v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00924v1",
            "title": "The Power of the Senses: Generalizable Manipulation from Vision and\n  Touch through Masked Multimodal Learning",
            "updated": "2023-11-02T01:33:00Z",
            "published": "2023-11-02T01:33:00Z",
            "summary": "Humans rely on the synergy of their senses for most essential tasks. For\ntasks requiring object manipulation, we seamlessly and effectively exploit the\ncomplementarity of our senses of vision and touch. This paper draws inspiration\nfrom such capabilities and aims to find a systematic approach to fuse visual\nand tactile information in a reinforcement learning setting. We propose Masked\nMultimodal Learning (M3L), which jointly learns a policy and visual-tactile\nrepresentations based on masked autoencoding. The representations jointly\nlearned from vision and touch improve sample efficiency, and unlock\ngeneralization capabilities beyond those achievable through each of the senses\nseparately. Remarkably, representations learned in a multimodal setting also\nbenefit vision-only policies at test time. We evaluate M3L on three simulated\nenvironments with both visual and tactile observations: robotic insertion, door\nopening, and dexterous in-hand manipulation, demonstrating the benefits of\nlearning a multimodal policy. Code and videos of the experiments are available\nat https://sferrazza.cc/m3l_site.",
            "author": [
                "Carmelo Sferrazza",
                "Younggyo Seo",
                "Hao Liu",
                "Youngwoon Lee",
                "Pieter Abbeel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00924v1",
                "http://arxiv.org/pdf/2311.00924v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01477v1",
            "title": "FAITHSCORE: Evaluating Hallucinations in Large Vision-Language Models",
            "updated": "2023-11-02T01:21:45Z",
            "published": "2023-11-02T01:21:45Z",
            "summary": "We introduce FAITHSCORE (Faithfulness to Atomic Image Facts Score), a\nreference-free and fine-grained evaluation metric that measures the\nfaithfulness of the generated free-form answers from large vision-language\nmodels (LVLMs). The FAITHSCORE evaluation first identifies sub-sentences\ncontaining descriptive statements that need to be verified, then extracts a\ncomprehensive list of atomic facts from these sub-sentences, and finally\nconducts consistency verification between fine-grained atomic facts and the\ninput image. Meta-evaluation demonstrates that our metric highly correlates\nwith human judgments of faithfulness. We collect two benchmark datasets (i.e.\nLLaVA-1k and MSCOCO-Cap) for evaluating LVLMs instruction-following\nhallucinations. We measure hallucinations in state-of-the-art LVLMs with\nFAITHSCORE on the datasets. Results reveal that current systems are prone to\ngenerate hallucinated content unfaithful to the image, which leaves room for\nfuture improvements. Further, we find that current LVLMs despite doing well on\ncolor and counting, still struggle with long answers, relations, and multiple\nobjects.",
            "author": [
                "Liqiang Jing",
                "Ruosen Li",
                "Yunmo Chen",
                "Mengzhao Jia",
                "Xinya Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01477v1",
                "http://arxiv.org/pdf/2311.01477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00917v1",
            "title": "RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection",
            "updated": "2023-11-02T01:21:12Z",
            "published": "2023-11-02T01:21:12Z",
            "summary": "Deep learning (DL) networks have achieved remarkable performance in infrared\nsmall target detection (ISTD). However, these structures exhibit a deficiency\nin interpretability and are widely regarded as black boxes, as they disregard\ndomain knowledge in ISTD. To alleviate this issue, this work proposes an\ninterpretable deep network for detecting infrared dim targets, dubbed RPCANet.\nSpecifically, our approach formulates the ISTD task as sparse target\nextraction, low-rank background estimation, and image reconstruction in a\nrelaxed Robust Principle Component Analysis (RPCA) model. By unfolding the\niterative optimization updating steps into a deep-learning framework,\ntime-consuming and complex matrix calculations are replaced by theory-guided\nneural networks. RPCANet detects targets with clear interpretability and\npreserves the intrinsic image feature, instead of directly transforming the\ndetection task into a matrix decomposition problem. Extensive experiments\nsubstantiate the effectiveness of our deep unfolding framework and demonstrate\nits trustworthy results, surpassing baseline methods in both qualitative and\nquantitative evaluations.",
            "author": [
                "Fengyi Wu",
                "Tianfang Zhang",
                "Lei Li",
                "Yian Huang",
                "Zhenming Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00917v1",
                "http://arxiv.org/pdf/2311.00917v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00915v1",
            "title": "Task-Agnostic Low-Rank Adapters for Unseen English Dialects",
            "updated": "2023-11-02T01:17:29Z",
            "published": "2023-11-02T01:17:29Z",
            "summary": "Large Language Models (LLMs) are trained on corpora disproportionally\nweighted in favor of Standard American English. As a result, speakers of other\ndialects experience significantly more failures when interacting with these\ntechnologies. In practice, these speakers often accommodate their speech to be\nbetter understood. Our work shares the belief that language technologies should\nbe designed to accommodate the diversity in English dialects and not the other\nway around. However, prior works on dialect struggle with generalizing to\nevolving and emerging dialects in a scalable manner. To fill this gap, our\nmethod, HyperLoRA, leverages expert linguistic knowledge to enable\nresource-efficient adaptation via hypernetworks. By disentangling\ndialect-specific and cross-dialectal information, HyperLoRA improves\ngeneralization to unseen dialects in a task-agnostic fashion. Not only is\nHyperLoRA more scalable in the number of parameters, but it also achieves the\nbest or most competitive performance across 5 dialects in a zero-shot setting.\nIn this way, our approach facilitates access to language technology for\nbillions of English dialect speakers who are traditionally underrepresented.",
            "author": [
                "Zedian Xiao",
                "William Held",
                "Yanchen Liu",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00915v1",
                "http://arxiv.org/pdf/2311.00915v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00913v1",
            "title": "Self-Influence Guided Data Reweighting for Language Model Pre-training",
            "updated": "2023-11-02T01:00:46Z",
            "published": "2023-11-02T01:00:46Z",
            "summary": "Language Models (LMs) pre-trained with self-supervision on large text corpora\nhave become the default starting point for developing models for various NLP\ntasks. Once the pre-training corpus has been assembled, all data samples in the\ncorpus are treated with equal importance during LM pre-training. However, due\nto varying levels of relevance and quality of data, equal importance to all the\ndata samples may not be the optimal choice. While data reweighting has been\nexplored in the context of task-specific supervised learning and LM\nfine-tuning, model-driven reweighting for pre-training data has not been\nexplored. We fill this important gap and propose PRESENCE, a method for jointly\nreweighting samples by leveraging self-influence (SI) scores as an indicator of\nsample importance and pre-training. PRESENCE promotes novelty and stability for\nmodel pre-training. Through extensive analysis spanning multiple model sizes,\ndatasets, and tasks, we present PRESENCE as an important first step in the\nresearch direction of sample reweighting for pre-training language models.",
            "author": [
                "Megh Thakkar",
                "Tolga Bolukbasi",
                "Sriram Ganapathy",
                "Shikhar Vashishth",
                "Sarath Chandar",
                "Partha Talukdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00913v1",
                "http://arxiv.org/pdf/2311.00913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00909v1",
            "title": "Planar Aerogel and Superfluid $^3$He, Structure and Transitions",
            "updated": "2023-11-02T00:46:02Z",
            "published": "2023-11-02T00:46:02Z",
            "summary": "Anisotropic aerogel possesses structure which exhibits a strong influence\nover the composition and orientation of the order parameter of imbibed\nsuperfluid $^3$He. Computational studies have identified stretched aerogel with\nplane-like structures and compressed aerogel with nematic-like structures.\nStudies of the B phase of superfluid $^3$He in stretched aerogel display an\nenhanced nuclear magnetic susceptibility likely caused by Andreev bound states\nnear plane-like impurity sites. We report further details on the influence of\nthese planar structures on both magnetic and orbital orientation transitions.\nThe orbital orientation transitions appear in both the B and A phases of\nstretched and compressed aerogels. These transitions result from a crossover of\nthe superfluid coherence length with long and short length scale structure with\nthe coherence length and are consequently magnetic field independent.\nAdditionally, the apparent temperature-independence of the susceptibility of\nthe B phase equal to that of the A phase in stretched aerogel, is in marked\ncontrast with the field dependence of the superfluid A to B phase transition,\nindicating that it is a near-isentropic transition.",
            "author": [
                "J. W. Scott",
                "M. D. Nguyen",
                "D. Park",
                "W. P. Halperin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00909v1",
                "http://arxiv.org/pdf/2311.00909v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00908v1",
            "title": "How Real is Incomputability in Physics?",
            "updated": "2023-11-02T00:44:40Z",
            "published": "2023-11-02T00:44:40Z",
            "summary": "A physical system is determined by a finite set of initial conditions and\nlaws represented by equations. The system is computable if we can solve the\nequations in all instances using a ``finite body of mathematical knowledge\". In\nthis case, if the laws of the system can be coded into a computer program, then\ngiven the system's initial conditions of the system, one can compute the\nsystem's evolution. This scenario is tacitly taken for granted. But is this\nreasonable? The answer is negative, and a straightforward example is when the\ninitial conditions or equations use irrational numbers, like Chaitin's Omega\nNumber: no program can deal with such numbers because of their ``infinity''.\nAre there incomputable physical systems? This question has been theoretically\nstudied in the last 30--40 years. This article presents a class of quantum\nprotocols producing quantum random bits. Theoretically, we prove that every\ninfinite sequence generated by these quantum protocols is strongly incomputable\n-- no algorithm computing any bit of such a sequence can be proved correct.\nThis theoretical result is not only more robust than the ones in the\nliterature: experimental results support and complement it.",
            "author": [
                "Jos\u00e9 Manuel Ag\u00fcero Trejo",
                "Cristian S. Calude",
                "Michael J. Dinneen",
                "Arkady Fedorov",
                "Anatoly Kulikov",
                "Rohit Navarathna",
                "Karl Svozil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00908v1",
                "http://arxiv.org/pdf/2311.00908v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00906v1",
            "title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for\n  Named Entity Recognition",
            "updated": "2023-11-02T00:19:02Z",
            "published": "2023-11-02T00:19:02Z",
            "summary": "Active learning, a widely adopted technique for enhancing machine learning\nmodels in text and image classification tasks with limited annotation\nresources, has received relatively little attention in the domain of Named\nEntity Recognition (NER). The challenge of data imbalance in NER has hindered\nthe effectiveness of active learning, as sequence labellers lack sufficient\nlearning signals. To address these challenges, this paper presents a novel\nreweighting-based active learning strategy that assigns dynamic smoothed\nweights to individual tokens. This adaptable strategy is compatible with\nvarious token-level acquisition functions and contributes to the development of\nrobust active learners. Experimental results on multiple corpora demonstrate\nthe substantial performance improvement achieved by incorporating our\nre-weighting strategy into existing acquisition functions, validating its\npractical efficacy.",
            "author": [
                "Haocheng Luo",
                "Wei Tan",
                "Ngoc Dang Nguyen",
                "Lan Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00906v1",
                "http://arxiv.org/pdf/2311.00906v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00903v1",
            "title": "Artificial Intelligence Ethics Education in Cybersecurity: Challenges\n  and Opportunities: a focus group report",
            "updated": "2023-11-02T00:08:07Z",
            "published": "2023-11-02T00:08:07Z",
            "summary": "The emergence of AI tools in cybersecurity creates many opportunities and\nuncertainties. A focus group with advanced graduate students in cybersecurity\nrevealed the potential depth and breadth of the challenges and opportunities.\nThe salient issues are access to open source or free tools, documentation,\ncurricular diversity, and clear articulation of ethical principles for AI\ncybersecurity education. Confronting the \"black box\" mentality in AI\ncybersecurity work is also of the greatest importance, doubled by deeper and\nprior education in foundational AI work. Systems thinking and effective\ncommunication were considered relevant areas of educational improvement. Future\nAI educators and practitioners need to address these issues by implementing\nrigorous technical training curricula, clear documentation, and frameworks for\nethically monitoring AI combined with critical and system's thinking and\ncommunication skills.",
            "author": [
                "Diane Jackson",
                "Sorin Adam Matei",
                "Elisa Bertino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00903v1",
                "http://arxiv.org/pdf/2311.00903v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00897v1",
            "title": "On The Open Prompt Challenge In Conditional Audio Generation",
            "updated": "2023-11-01T23:33:25Z",
            "published": "2023-11-01T23:33:25Z",
            "summary": "Text-to-audio generation (TTA) produces audio from a text description,\nlearning from pairs of audio samples and hand-annotated text. However,\ncommercializing audio generation is challenging as user-input prompts are often\nunder-specified when compared to text descriptions used to train TTA models. In\nthis work, we treat TTA models as a ``blackbox'' and address the user prompt\nchallenge with two key insights: (1) User prompts are generally\nunder-specified, leading to a large alignment gap between user prompts and\ntraining prompts. (2) There is a distribution of audio descriptions for which\nTTA models are better at generating higher quality audio, which we refer to as\n``audionese''. To this end, we rewrite prompts with instruction-tuned models\nand propose utilizing text-audio alignment as feedback signals via margin\nranking learning for audio improvements. On both objective and subjective human\nevaluations, we observed marked improvements in both text-audio alignment and\nmusic audio quality.",
            "author": [
                "Ernie Chang",
                "Sidd Srinivasan",
                "Mahi Luthra",
                "Pin-Jie Lin",
                "Varun Nagaraja",
                "Forrest Iandola",
                "Zechun Liu",
                "Zhaoheng Ni",
                "Changsheng Zhao",
                "Yangyang Shi",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00897v1",
                "http://arxiv.org/pdf/2311.00897v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00895v1",
            "title": "In-Context Prompt Editing For Conditional Audio Generation",
            "updated": "2023-11-01T23:31:51Z",
            "published": "2023-11-01T23:31:51Z",
            "summary": "Distributional shift is a central challenge in the deployment of machine\nlearning models as they can be ill-equipped for real-world data. This is\nparticularly evident in text-to-audio generation where the encoded\nrepresentations are easily undermined by unseen prompts, which leads to the\ndegradation of generated audio -- the limited set of the text-audio pairs\nremains inadequate for conditional audio generation in the wild as user prompts\nare under-specified. In particular, we observe a consistent audio quality\ndegradation in generated audio samples with user prompts, as opposed to\ntraining set prompts. To this end, we present a retrieval-based in-context\nprompt editing framework that leverages the training captions as demonstrative\nexemplars to revisit the user prompts. We show that the framework enhanced the\naudio quality across the set of collected user prompts, which were edited with\nreference to the training captions as exemplars.",
            "author": [
                "Ernie Chang",
                "Pin-Jie Lin",
                "Yang Li",
                "Sidd Srinivasan",
                "Gael Le Lan",
                "David Kant",
                "Yangyang Shi",
                "Forrest Iandola",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00895v1",
                "http://arxiv.org/pdf/2311.00895v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00894v1",
            "title": "Minimizing Convex Functionals over Space of Probability Measures via KL\n  Divergence Gradient Flow",
            "updated": "2023-11-01T23:29:39Z",
            "published": "2023-11-01T23:29:39Z",
            "summary": "Motivated by the computation of the non-parametric maximum likelihood\nestimator (NPMLE) and the Bayesian posterior in statistics, this paper explores\nthe problem of convex optimization over the space of all probability\ndistributions. We introduce an implicit scheme, called the implicit KL proximal\ndescent (IKLPD) algorithm, for discretizing a continuous-time gradient flow\nrelative to the Kullback-Leibler divergence for minimizing a convex target\nfunctional. We show that IKLPD converges to a global optimum at a polynomial\nrate from any initialization; moreover, if the objective functional is strongly\nconvex relative to the KL divergence, for example, when the target functional\nitself is a KL divergence as in the context of Bayesian posterior computation,\nIKLPD exhibits globally exponential convergence. Computationally, we propose a\nnumerical method based on normalizing flow to realize IKLPD. Conversely, our\nnumerical method can also be viewed as a new approach that sequentially trains\na normalizing flow for minimizing a convex functional with a strong theoretical\nguarantee.",
            "author": [
                "Rentian Yao",
                "Linjun Huang",
                "Yun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00894v1",
                "http://arxiv.org/pdf/2311.00894v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02103v1",
            "title": "Relax: Composable Abstractions for End-to-End Dynamic Machine Learning",
            "updated": "2023-11-01T23:03:59Z",
            "published": "2023-11-01T23:03:59Z",
            "summary": "Dynamic shape computations have become critical in modern machine learning\nworkloads, especially in emerging large language models. The success of these\nmodels has driven demand for deploying them to a diverse set of backend\nenvironments. In this paper, we present Relax, a compiler abstraction for\noptimizing end-to-end dynamic machine learning workloads. Relax introduces\nfirst-class symbolic shape annotations to track dynamic shape computations\nglobally across the program. It also introduces a cross-level abstraction that\nencapsulates computational graphs, loop-level tensor programs, and library\ncalls in a single representation to enable cross-level optimizations. We build\nan end-to-end compilation framework using the proposed approach to optimize\ndynamic shape models. Experimental results on large language models show that\nRelax delivers performance competitive with state-of-the-art hand-optimized\nsystems across platforms and enables deployment of emerging dynamic models to a\nbroader set of environments, including mobile phones, embedded devices, and web\nbrowsers.",
            "author": [
                "Ruihang Lai",
                "Junru Shao",
                "Siyuan Feng",
                "Steven S. Lyubomirsky",
                "Bohan Hou",
                "Wuwei Lin",
                "Zihao Ye",
                "Hongyi Jin",
                "Yuchen Jin",
                "Jiawei Liu",
                "Lesheng Jin",
                "Yaxing Cai",
                "Ziheng Jiang",
                "Yong Wu",
                "Sunghyun Park",
                "Prakalp Srivastava",
                "Jared G. Roesch",
                "Todd C. Mowry",
                "Tianqi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02103v1",
                "http://arxiv.org/pdf/2311.02103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00888v1",
            "title": "Robust inter-patient comparison and analysis of blood vessels through\n  the univocal definition of point coordinates",
            "updated": "2023-11-01T22:44:36Z",
            "published": "2023-11-01T22:44:36Z",
            "summary": "The availability of digital twins for the cardiovascular system will enable\ninsightful computational tools both for research and clinical practice. This,\nhowever, demands robust and well defined methods for the different steps\ninvolved in the process. We present a vessel coordinate system (VCS) that\nenables the unanbiguous definition of locations in a vessel section, by\nadapting the idea of cylindrical coordinates to the vessel geometry. Using the\nVCS, point correspondence can be defined among different samples of a cohort,\nallowing data transfer, quantitative comparison, shape coregistration or\npopulation analysis. We provide the technical details for coordinates\ncomputation and discuss the assumptions taken to guarantee that they are well\ndefined. The VCS is tested in a series of applications. We present a robust,\nlow dimensional, patient specific vascular model and use it to study phenotype\nvariability analysis of the thoracic aorta within a cohort of patients. Point\ncorrespondence is exploited to build an haemodynamics atlas of the aorta for\nthe same cohort. Across the paper, we also show how VCS can be used for\nvisualization of different types of data on the anatomy.",
            "author": [
                "Pau Romero",
                "Abel Pedr\u00f3s",
                "Rafael Sebastian",
                "Miguel Lozano",
                "Ignacio Garc\u00eda-Fern\u00e1ndez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00888v1",
                "http://arxiv.org/pdf/2311.00888v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00883v1",
            "title": "Improving the accuracy and scalability of large-scale physics-based\n  data-driven reduced modeling via domain decomposition",
            "updated": "2023-11-01T22:17:25Z",
            "published": "2023-11-01T22:17:25Z",
            "summary": "This paper focuses on the construction of accurate and predictive data-driven\nreduced models of large-scale numerical simulations with complex dynamics and\nsparse training data sets. In these settings, standard, single-domain\napproaches may be too inaccurate or may overfit and hence generalize poorly.\nMoreover, processing large-scale data sets typically requires significant\nmemory and computing resources which can render single-domain approaches\ncomputationally prohibitive. To address these challenges, we introduce a domain\ndecomposition formulation into the construction of a data-driven reduced model.\nIn doing so, the basis functions used in the reduced model approximation become\nlocalized in space, which can increase the accuracy of the domain-decomposed\napproximation of the complex dynamics. The decomposition furthermore reduces\nthe memory and computing requirements to process the underlying large-scale\ntraining data set. We demonstrate the effectiveness and scalability of our\napproach in a large-scale three-dimensional unsteady rotating detonation rocket\nengine simulation scenario with over $75$ million degrees of freedom and a\nsparse training data set. Our results show that compared to the single-domain\napproach, the domain-decomposed version reduces both the training and\nprediction errors for pressure by up to $13 \\%$ and up to $5\\%$ for other key\nquantities, such as temperature, and fuel and oxidizer mass fractions. Lastly,\nour approach decreases the memory requirements for processing by almost a\nfactor of four, which in turn reduces the computing requirements as well.",
            "author": [
                "Ionut-Gabriel Farcas",
                "Rayomand P. Gundevia",
                "Ramakanth Munipalli",
                "Karen E. Willcox"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00883v1",
                "http://arxiv.org/pdf/2311.00883v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.CE",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00882v2",
            "title": "Semidefinite programming and linear equations vs. homomorphism problems",
            "updated": "2023-11-17T05:02:40Z",
            "published": "2023-11-01T22:15:19Z",
            "summary": "We introduce a relaxation for homomorphism problems that combines\nsemidefinite programming with linear Diophantine equations, and propose a\nframework for the analysis of its power based on the spectral theory of\nassociation schemes. We use this framework to establish an unconditional lower\nbound against the semidefinite programming + linear equations model, by showing\nthat the relaxation does not solve the approximate graph homomorphism problem\nand thus, in particular, the approximate graph colouring problem.",
            "author": [
                "Lorenzo Ciardo",
                "Stanislav \u017divn\u00fd"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00882v2",
                "http://arxiv.org/pdf/2311.00882v2"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DM",
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00878v1",
            "title": "Backward Joint Model for Dynamic Prediction using Multivariate\n  Longitudinal and Competing Risk Data",
            "updated": "2023-11-01T22:08:58Z",
            "published": "2023-11-01T22:08:58Z",
            "summary": "Joint modeling is a useful approach to dynamic prediction of clinical\noutcomes using longitudinally measured predictors. When the outcomes are\ncompeting risk events, fitting the conventional shared random effects joint\nmodel often involves intensive computation, especially when multiple\nlongitudinal biomarkers are be used as predictors, as is often desired in\nprediction problems. Motivated by a longitudinal cohort study of chronic kidney\ndisease, this paper proposes a new joint model for the dynamic prediction of\nend-stage renal disease with the competing risk of death. The model factorizes\nthe likelihood into the distribution of the competing risks data and the\ndistribution of longitudinal data given the competing risks data. The\nestimation with the EM algorithm is efficient, stable and fast, with a\none-dimensional integral in the E-step and convex optimization for most\nparameters in the M-step, regardless of the number of longitudinal predictors.\nThe model also comes with a consistent albeit less efficient estimation method\nthat can be quickly implemented with standard software, ideal for model\nbuilding and diagnotics. This model enables the prediction of future\nlongitudinal data trajectories conditional on being at risk at a future time, a\npractically significant problem that has not been studied in the statistical\nliterature. We study the properties of the proposed method using simulations\nand a real dataset and compare its performance with the shared random effects\njoint model.",
            "author": [
                "Wenhao Li",
                "Liang Li",
                "Brad C. Astor",
                "Wei Yang",
                "Tom H. Greene"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00878v1",
                "http://arxiv.org/pdf/2311.00878v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00876v1",
            "title": "Channel Estimation for Reconfigurable Intelligent Surface MIMO with\n  Tensor Signal Modelling",
            "updated": "2023-11-01T22:03:43Z",
            "published": "2023-11-01T22:03:43Z",
            "summary": "We consider a narrowband MIMO reconfigurable intelligent surface\n(RIS)-assisted wireless communication system and use tensor signal modelling\ntechniques to individually estimate all communication channels including the\nnon-RIS channels (direct path) and decoupled RIS channels. We model the\nreceived signal as a third-order tensor composed of two CANDECOMP/PARAFAC\ndecomposition terms for the non-RIS and the RIS-assisted links, respectively,\nand we propose two channel estimation methods based on an iterative alternating\nleast squares (ALS) algorithm: The two-stage RIS OFF-ON method estimates each\nof the non-RIS and RIS-assisted terms in two pilot training stages, whereas the\nenhanced alternating least squares (E-ALS) method improves upon the ALS\nalgorithm to jointly estimate all channels over the full training duration. A\nkey benefit of both methods compared to the traditional least squares (LS)\nsolution is that they exploit the structure of the tensor model to obtain\ndecoupled estimates of all communication channels. We provide the computational\ncomplexities to obtain each of the channel estimates for our two proposed\nmethods. Numerical simulations are used to evaluate the accuracy and verify the\ncomputational complexities of the proposed two-stage RIS OFF-ON, and E-ALS, and\ncompare them to the traditional LS methods. Results show that E-ALS will obtain\nthe most accurate estimate while only having a slightly higher run-time than\nthe two-stage method.",
            "author": [
                "Alexander James Fernandes",
                "Ioannis Psaromiligkos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00876v1",
                "http://arxiv.org/pdf/2311.00876v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00875v1",
            "title": "Learning Collective Behaviors from Observation",
            "updated": "2023-11-01T22:02:08Z",
            "published": "2023-11-01T22:02:08Z",
            "summary": "We present a review of a series of learning methods used to identify the\nstructure of dynamical systems, aiming to understand emergent behaviors in\ncomplex systems of interacting agents. These methods not only offer theoretical\nguarantees of convergence but also demonstrate computational efficiency in\nhandling high-dimensional observational data. They can manage observation data\nfrom both first- and second-order dynamical systems, accounting for\nobservation/stochastic noise, complex interaction rules, missing interaction\nfeatures, and real-world observations of interacting agent systems. The essence\nof developing such a series of learning methods lies in designing appropriate\nloss functions using the variational inverse problem approach, which inherently\nprovides dimension reduction capabilities to our learning methods.",
            "author": [
                "Jinchao Feng",
                "Ming Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00875v1",
                "http://arxiv.org/pdf/2311.00875v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00871v1",
            "title": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in\n  Transformer Models",
            "updated": "2023-11-01T21:41:08Z",
            "published": "2023-11-01T21:41:08Z",
            "summary": "Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.",
            "author": [
                "Steve Yadlowsky",
                "Lyric Doshi",
                "Nilesh Tripuraneni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00871v1",
                "http://arxiv.org/pdf/2311.00871v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00869v1",
            "title": "Scaling Frustration Index and Corresponding Balanced State Discovery for\n  Real Signed Graphs",
            "updated": "2023-11-01T21:37:46Z",
            "published": "2023-11-01T21:37:46Z",
            "summary": "Structural balance modeling for signed graph networks presents how to model\nthe sources of conflicts. The state-of-the-art has focused on computing the\nfrustration index of a signed graph as a critical step toward solving problems\nin social and sensor networks and for scientific modeling. However, the\nproposed approaches do not scale to modern large, sparse signed networks. Also,\nthey do not address that there is more than one way in some networks to reach a\nconsensus with the minimum number of edge-sign switches needed. We propose an\nefficient balanced state discovery algorithm and a network frustration\ncomputation that will discover the nearest balanced state for the \\emph{any}\nsize of the graph network and compute the frustration of the network. The\nspeedup of the proposed method is around 300 times faster than the\nstate-of-the-art for signed graphs with hundreds of thousands of edges. The\ntechnique successfully scales to find the balanced states and frustration of\nthe networks with millions of nodes and edges in real time where\nstate-of-the-art fails.",
            "author": [
                "Muhieddine Shebaro",
                "Jelena Te\u0161i\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00869v1",
                "http://arxiv.org/pdf/2311.00869v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00867v1",
            "title": "Automatic Disfluency Detection from Untranscribed Speech",
            "updated": "2023-11-01T21:36:39Z",
            "published": "2023-11-01T21:36:39Z",
            "summary": "Speech disfluencies, such as filled pauses or repetitions, are disruptions in\nthe typical flow of speech. Stuttering is a speech disorder characterized by a\nhigh rate of disfluencies, but all individuals speak with some disfluencies and\nthe rates of disfluencies may by increased by factors such as cognitive load.\nClinically, automatic disfluency detection may help in treatment planning for\nindividuals who stutter. Outside of the clinic, automatic disfluency detection\nmay serve as a pre-processing step to improve natural language understanding in\ndownstream applications. With this wide range of applications in mind, we\ninvestigate language, acoustic, and multimodal methods for frame-level\nautomatic disfluency detection and categorization. Each of these methods relies\non audio as an input. First, we evaluate several automatic speech recognition\n(ASR) systems in terms of their ability to transcribe disfluencies, measured\nusing disfluency error rates. We then use these ASR transcripts as input to a\nlanguage-based disfluency detection model. We find that disfluency detection\nperformance is largely limited by the quality of transcripts and alignments. We\nfind that an acoustic-based approach that does not require transcription as an\nintermediate step outperforms the ASR language approach. Finally, we present\nmultimodal architectures which we find improve disfluency detection performance\nover the unimodal approaches. Ultimately, this work introduces novel approaches\nfor automatic frame-level disfluency and categorization. In the long term, this\nwill help researchers incorporate automatic disfluency detection into a range\nof applications.",
            "author": [
                "Amrit Romana",
                "Kazuhito Koishida",
                "Emily Mower Provost"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00867v1",
                "http://arxiv.org/pdf/2311.00867v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00863v1",
            "title": "Training Dynamics of Contextual N-Grams in Language Models",
            "updated": "2023-11-01T21:32:51Z",
            "published": "2023-11-01T21:32:51Z",
            "summary": "Prior work has shown the existence of contextual neurons in language models,\nincluding a neuron that activates on German text. We show that this neuron\nexists within a broader contextual n-gram circuit: we find late layer neurons\nwhich recognize and continue n-grams common in German text, but which only\nactivate if the German neuron is active. We investigate the formation of this\ncircuit throughout training and find that it is an example of what we call a\nsecond-order circuit. In particular, both the constituent n-gram circuits and\nthe German detection circuit which culminates in the German neuron form with\nindependent functions early in training - the German detection circuit\npartially through modeling German unigram statistics, and the n-grams by\nboosting appropriate completions. Only after both circuits have already formed\ndo they fit together into a second-order circuit. Contrary to the hypotheses\npresented in prior work, we find that the contextual n-gram circuit forms\ngradually rather than in a sudden phase transition. We further present a range\nof anomalous observations such as a simultaneous phase transition in many tasks\ncoinciding with the learning rate warm-up, and evidence that many context\nneurons form simultaneously early in training but are later unlearned.",
            "author": [
                "Lucia Quirke",
                "Lovis Heindrich",
                "Wes Gurnee",
                "Neel Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00863v1",
                "http://arxiv.org/pdf/2311.00863v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00860v2",
            "title": "Zero Coordinate Shift: Whetted Automatic Differentiation for\n  Physics-informed Operator Learning",
            "updated": "2023-11-23T19:41:41Z",
            "published": "2023-11-01T21:28:24Z",
            "summary": "Automatic differentiation (AD) is a critical step in physics-informed machine\nlearning, required for computing the high-order derivatives of network output\nw.r.t. coordinates of collocation points. In this paper, we present a novel and\nlightweight algorithm to conduct AD for physics-informed operator learning,\nwhich we call the trick of Zero Coordinate Shift (ZCS). Instead of making all\nsampled coordinates as leaf variables, ZCS introduces only one scalar-valued\nleaf variable for each spatial or temporal dimension, simplifying the wanted\nderivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\" whereby\nreverse-mode AD becomes directly utilisable. It has led to an outstanding\nperformance leap by avoiding the duplication of the computational graph along\nthe dimension of functions (physical parameters). ZCS is easy to implement with\ncurrent deep learning libraries; our own implementation is achieved by\nextending the DeepXDE package. We carry out a comprehensive benchmark analysis\nand several case studies, training physics-informed DeepONets to solve partial\ndifferential equations (PDEs) without data. The results show that ZCS has\npersistently reduced GPU memory consumption and wall time for training by an\norder of magnitude, and such reduction factor scales with the number of\nfunctions. As a low-level optimisation technique, ZCS imposes no restrictions\non data, physics (PDE) or network architecture and does not compromise training\nresults from any aspect.",
            "author": [
                "Kuangdai Leng",
                "Mallikarjun Shankar",
                "Jeyan Thiyagalingam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00860v2",
                "http://arxiv.org/pdf/2311.00860v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00848v1",
            "title": "ABCD: Algorithm for Balanced Component Discovery in Signed Networks",
            "updated": "2023-11-01T20:58:14Z",
            "published": "2023-11-01T20:58:14Z",
            "summary": "The most significant balanced element in signed graphs plays a vital role in\nhelping researchers understand the fundamental structure of the graph, as it\nreveals valuable information about the complex relationships between vertices\nin the network. The challenge is an NP-hard problem; there is no current\nbaseline to evaluate state-of-the-art signed graphs derived from real networks.\nIn this paper, we propose a scalable state-of-the-art approach for the maximum\nbalanced sub-graph detection in the network of \\emph{any} size. However, it is\nstill bounded by computational capability. The proposed approach builds on the\ngraph characteristics and a scalable fundamental cycle discovery method to\nminimize the number of vertices discarded. We evaluate the proposed approach\nagainst state-of-the-art and demonstrate over two times higher graph size\nregarding the number of vertices selected of the discovered subset on an\nextensive signed network with millions of vertices and edges over the\nstate-of-art in the same time frame.",
            "author": [
                "Muhieddine Shebaro",
                "Jelena Te\u0161i\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00848v1",
                "http://arxiv.org/pdf/2311.00848v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00844v2",
            "title": "Electronic excited states from physically-constrained machine learning",
            "updated": "2023-11-08T01:04:12Z",
            "published": "2023-11-01T20:49:59Z",
            "summary": "Data-driven techniques are increasingly used to replace electronic-structure\ncalculations of matter. In this context, a relevant question is whether machine\nlearning (ML) should be applied directly to predict the desired properties or\nbe combined explicitly with physically-grounded operations. We present an\nexample of an integrated modeling approach, in which a symmetry-adapted ML\nmodel of an effective Hamiltonian is trained to reproduce electronic\nexcitations from a quantum-mechanical calculation. The resulting model can make\npredictions for molecules that are much larger and more complex than those that\nit is trained on, and allows for dramatic computational savings by indirectly\ntargeting the outputs of well-converged calculations while using a\nparameterization corresponding to a minimal atom-centered basis. These results\nemphasize the merits of intertwining data-driven techniques with physical\napproximations, improving the transferability and interpretability of ML models\nwithout affecting their accuracy and computational efficiency, and providing a\nblueprint for developing ML-augmented electronic-structure methods.",
            "author": [
                "Edoardo Cignoni",
                "Divya Suman",
                "Jigyasa Nigam",
                "Lorenzo Cupellini",
                "Benedetta Mennucci",
                "Michele Ceriotti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00844v2",
                "http://arxiv.org/pdf/2311.00844v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00843v1",
            "title": "Compiled Properties of Nucleonic Matter and Nuclear and Neutron Star\n  Models from Non-Relativistic and Relativistic Interactions",
            "updated": "2023-11-01T20:47:48Z",
            "published": "2023-11-01T20:47:48Z",
            "summary": "This paper compiles the model parameters and zero-temperature properties of\nan extensive collection of published theoretical nuclear interactions,\nincluding 251 non-relativistic (Skyrme-like), 252 relativistic mean field (RMF)\nand point-coupling (RMF-PC), and 13 Gogny-like forces. This forms the most\nexhaustive tabulation of model parameters to date. The properties of uniform\nsymmetric matter and pure neutron matter at the saturation density are\ndetermined. Symmetry properties found from the second-order term of a Taylor\nexpansion in neutron excess are compared to the energy difference of pure\nneutron and symmetric nuclear matter at the saturation density. Selected\nliquid-droplet model parameters, including the surface tension and surface\nsymmetry energy, are determined for semi-infinite surfaces. Liquid droplet\nmodel neutron skin thicknesses and dipole polarizabilities of the neutron-rich\nclosed-shell nuclei $^{48}$Ca and $^{208}$Pb are compared to published\ntheoretical Hartree-Fock and experimental results. In addition, the radii,\nbinding energies, moments of inertia and tidal deformabilities of 1.2, 1.4 and\n1.6 M$_\\odot$ neutron stars are computed. An extensive correlation analysis of\nbulk matter, nuclear structure, and low-mass neutron star properties is\nperformed and compared to nuclear experiments and astrophysical observations.",
            "author": [
                "Boyang Sun",
                "Saketh Bhattiprolu",
                "James M. Lattimer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00843v1",
                "http://arxiv.org/pdf/2311.00843v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00838v2",
            "title": "Computing local minimizers in polynomial optimization under genericity\n  conditions",
            "updated": "2023-11-13T14:11:05Z",
            "published": "2023-11-01T20:40:24Z",
            "summary": "In this paper, we aim at computing all local minimizers of a polynomial\noptimization problem under genericity conditions. By using a technique in\ncomputer algebra, we provide a univariate representation for the set of local\nminimizers. In particular, for an unconstrained problem, the coordinates of all\nlocal minimizers can be represented by several univariate polynomial equalities\nand one univariate polynomial matrix inequality. We also develop the technique\nfor constrained problems having equality constraints. Based on the above\ntechnique, we design algorithms to enumerate the local minimizers.\n  At the end of the paper, we provide some experimental examples.",
            "author": [
                "Vu Trung Hieu",
                "Akiko Takeda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00838v2",
                "http://arxiv.org/pdf/2311.00838v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00837v1",
            "title": "Constant-time Motion Planning with Anytime Refinement for Manipulation",
            "updated": "2023-11-01T20:40:10Z",
            "published": "2023-11-01T20:40:10Z",
            "summary": "Robotic manipulators are essential for future autonomous systems, yet limited\ntrust in their autonomy has confined them to rigid, task-specific systems. The\nintricate configuration space of manipulators, coupled with the challenges of\nobstacle avoidance and constraint satisfaction, often makes motion planning the\nbottleneck for achieving reliable and adaptable autonomy. Recently, a class of\nconstant-time motion planners (CTMP) was introduced. These planners employ a\npreprocessing phase to compute data structures that enable online planning\nprovably guarantee the ability to generate motion plans, potentially\nsub-optimal, within a user defined time bound. This framework has been\ndemonstrated to be effective in a number of time-critical tasks. However,\nrobotic systems often have more time allotted for planning than the online\nportion of CTMP requires, time that can be used to improve the solution. To\nthis end, we propose an anytime refinement approach that works in combination\nwith CTMP algorithms. Our proposed framework, as it operates as a constant time\nalgorithm, rapidly generates an initial solution within a user-defined time\nthreshold. Furthermore, functioning as an anytime algorithm, it iteratively\nrefines the solution's quality within the allocated time budget. This enables\nour approach to strike a balance between guaranteed fast plan generation and\nthe pursuit of optimization over time. We support our approach by elucidating\nits analytical properties, showing the convergence of the anytime component\ntowards optimal solutions. Additionally, we provide empirical validation\nthrough simulation and real-world demonstrations on a 6 degree-of-freedom robot\nmanipulator, applied to an assembly domain.",
            "author": [
                "Itamar Mishani",
                "Hayden Feddock",
                "Maxim Likhachev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00837v1",
                "http://arxiv.org/pdf/2311.00837v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00836v1",
            "title": "Effective filtering approach for joint parameter-state estimation in\n  SDEs via Rao-Blackwellization and modularization",
            "updated": "2023-11-01T20:39:43Z",
            "published": "2023-11-01T20:39:43Z",
            "summary": "Stochastic filtering is a vibrant area of research in both control theory and\nstatistics, with broad applications in many scientific fields. Despite its\nextensive historical development, there still lacks an effective method for\njoint parameter-state estimation in SDEs. The state-of-the-art particle\nfiltering methods suffer from either sample degeneracy or information loss,\nwith both issues stemming from the dynamics of the particles generated to\nrepresent system parameters.\n  This paper provides a novel and effective approach for joint parameter-state\nestimation in SDEs via Rao-Blackwellization and modularization. Our method\noperates in two layers: the first layer estimates the system states using a\nbootstrap particle filter, and the second layer marginalizes out system\nparameters explicitly. This strategy circumvents the need to generate particles\nrepresenting system parameters, thereby mitigating their associated problems of\nsample degeneracy and information loss. Moreover, our method employs a\nmodularization approach when integrating out the parameters, which\nsignificantly reduces the computational complexity. All these designs ensure\nthe superior performance of our method. Finally, a numerical example is\npresented to illustrate that our method outperforms existing approaches by a\nlarge margin.",
            "author": [
                "Zhou Fang",
                "Ankit Gupta",
                "Mustafa Khammash"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00836v1",
                "http://arxiv.org/pdf/2311.00836v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "eess.SP",
                "math.PR",
                "stat.CO",
                "62M20, 62F15, 65C05, 92-08, 93E11"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00835v1",
            "title": "Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine\n  Entity Typing",
            "updated": "2023-11-01T20:39:12Z",
            "published": "2023-11-01T20:39:12Z",
            "summary": "Ultra-fine entity typing plays a crucial role in information extraction by\npredicting fine-grained semantic types for entity mentions in text. However,\nthis task poses significant challenges due to the massive number of entity\ntypes in the output space. The current state-of-the-art approaches, based on\nstandard multi-label classifiers or cross-encoder models, suffer from poor\ngeneralization performance or inefficient inference. In this paper, we present\nCASENT, a seq2seq model designed for ultra-fine entity typing that predicts\nultra-fine types with calibrated confidence scores. Our model takes an entity\nmention as input and employs constrained beam search to generate multiple types\nautoregressively. The raw sequence probabilities associated with the predicted\ntypes are then transformed into confidence scores using a novel calibration\nmethod. We conduct extensive experiments on the UFET dataset which contains\nover 10k types. Our method outperforms the previous state-of-the-art in terms\nof F1 score and calibration error, while achieving an inference speedup of over\n50 times. Additionally, we demonstrate the generalization capabilities of our\nmodel by evaluating it in zero-shot and few-shot settings on five specialized\ndomain entity typing datasets that are unseen during training. Remarkably, our\nmodel outperforms large language models with 10 times more parameters in the\nzero-shot setting, and when fine-tuned on 50 examples, it significantly\noutperforms ChatGPT on all datasets. Our code, models and demo are available at\nhttps://github.com/yanlinf/CASENT.",
            "author": [
                "Yanlin Feng",
                "Adithya Pratapa",
                "David R Mortensen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00835v1",
                "http://arxiv.org/pdf/2311.00835v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00826v1",
            "title": "Cross-correlation of cosmic voids with thermal Sunyaev-Zel'dovich data",
            "updated": "2023-11-01T20:16:14Z",
            "published": "2023-11-01T20:16:14Z",
            "summary": "We provide a measurement of the deficit in the Sunyaev-Zel'dovich Compton-$y$\nsignal towards cosmic voids, by stacking a catalogue of 97,090 voids\nconstructed with BOSS-DR12 data, on the $y$ maps built on data from the Atacama\nCosmology Telescope (ACT) DR4 and the Planck satellite. We detect the void\nsignal with a significance of $7.3\\,\\sigma$ with ACT and $9.7\\,\\sigma$ with\nPlanck, obtaining agreements in the associated void radial $y$ profiles\nextracted from both maps. The inner-void profile (for angular separations\nwithin the void angular radius) is reconstructed with significances of\n$4.7\\sigma$ and $6.1\\sigma$ with ACT and Planck, respectively; we model such\nprofile using a simple model that assumes uniform gas (under)density and\ntemperature, which enables us to place constraints on the product\n$(-\\delta_{\\rm v}T_{\\rm e})$ of the void density contrast (negative) and the\nelectron temperature. The best-fit values from the two data sets are\n$(-\\delta_{\\rm v}T_{\\rm e})=(6.5\\pm 2.3)\\times 10^{5}\\,\\text{K}$ for ACT and\n$(8.6 \\pm 2.1)\\times 10^{5}\\,\\text{K}$ for Planck ($68\\%$ C.L.), which are in\ngood agreement under uncertainty. The data allow us to place lower limits on\nthe expected void electron temperature at $2.7\\times10^5\\,\\text{K}$ with ACT\nand $5.1\\times10^5\\,\\text{K}$ with Planck ($95\\%$ C.L.); these results can\ntransform into upper limits for the ratio between the void electron density and\nthe cosmic mean as $n^{\\rm v}_{\\rm e}/\\bar{n}_{\\rm e}\\leqslant 0.73$ and $0.49$\n($95\\%$ C.L.), respectively. Our findings prove the feasibility of using tSZ\nobservations to constrain the gas properties inside cosmic voids, and confirm\nthat voids are under-pressured regions compared to their surroundings.",
            "author": [
                "Gang Li",
                "Yin-Zhe Ma",
                "Denis Tramonte",
                "Guo-Liang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00826v1",
                "http://arxiv.org/pdf/2311.00826v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00825v1",
            "title": "Quantum Computational Algorithms for Derivative Pricing and Credit Risk\n  in a Regime Switching Economy",
            "updated": "2023-11-01T20:15:59Z",
            "published": "2023-11-01T20:15:59Z",
            "summary": "Quantum computers are not yet up to the task of providing computational\nadvantages for practical stochastic diffusion models commonly used by financial\nanalysts. In this paper we introduce a class of stochastic processes that are\nboth realistic in terms of mimicking financial market risks as well as more\namenable to potential quantum computational advantages. The type of models we\nstudy are based on a regime switching volatility model driven by a Markov chain\nwith observable states. The basic model features a Geometric Brownian Motion\nwith drift and volatility parameters determined by the finite states of a\nMarkov chain. We study algorithms to estimate credit risk and option pricing on\na gate-based quantum computer. These models bring us closer to realistic market\nsettings, and therefore quantum computing closer the realm of practical\napplications.",
            "author": [
                "Eric Ghysels",
                "Jack Morgan",
                "Hamed Mohammadbagherpoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00825v1",
                "http://arxiv.org/pdf/2311.00825v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00821v1",
            "title": "Silicon Implantation and Annealing in $\u03b2$-Ga$_2$O$_3$: Role of\n  Ambient, Temperature, and Time",
            "updated": "2023-11-01T20:11:54Z",
            "published": "2023-11-01T20:11:54Z",
            "summary": "Optimizing thermal anneals of Si-implanted $\\beta$-Ga$_2$O$_3$ is critical\nfor low resistance contacts and selective area doping. We report the impact of\nannealing ambient, temperature, and time on activation of room temperature\nion-implanted Si in $\\beta$-Ga$_2$O$_3$ at concentrations from 5x10$^{18}$ to\n1x10$^{20}$ cm$^{-3}$, demonstrating full activation (>80% activation,\nmobilities >70 cm$^{2}$/Vs) with contact resistances below 0.29 $\\Omega$-mm.\nHomoepitaxial $\\beta$-Ga$_2$O$_3$ films, grown by plasma assisted MBE on\nFe-doped (010) substrates, were implanted at multiple energies to yield 100 nm\nbox profiles of 5x10$^{18}$, 5x10$^{19}$, and 1x10$^{20}$ cm$^{-3}$. Anneals\nwere performed in a UHV-compatible quartz furnace at 1 bar with well-controlled\ngas composition. To maintain $\\beta$-Ga$_2$O$_3$ stability, $p_{O2}$ must be\ngreater than 10$^{-9}$ bar. Anneals up to $p_{O2}$ = 1 bar achieve full\nactivation at 5x10$^{18}$ cm$^{-3}$, while 5x10$^{19}$ cm$^{-3}$ must be\nannealed with $p_{O2}$ <10$^{-4}$ bar and 1x10$^{20}$ cm$^{-3}$ requires\n$p_{O2}$ <10$^{-6}$ bar. Water vapor prevents activation and must be maintained\nbelow 10$^{-8}$ bar. Activation is achieved for anneal temperatures as low as\n850 {\\deg}C with mobility increasing with anneal temperature up to 1050\n{\\deg}C, though Si diffusion has been reported above 950 {\\deg}C. At 950\n{\\deg}C, activation is maximized between 5 and 20 minutes with longer times\nresulting in decreased carrier activation (over-annealing). This over-annealing\nis significant for concentrations above 5x10$^{19}$ cm$^{-3}$ and occurs\nrapidly at 1x10$^{20}$ cm$^{-3}$. RBS (channeling) suggests damage recovery is\nseeded from remnant aligned $\\beta$-Ga$_2$O$_3$ that remains after\nimplantation; this conclusion is also supported by STEM showing retention of\nthe $\\beta$-phase with inclusions that resemble the $\\gamma$-phase.",
            "author": [
                "K. R. Gann",
                "N. Pieczulewski1",
                "C. A. Gorsak",
                "K. Heinselman",
                "T. J. Asel",
                "B. A. Noesges",
                "K. T. Smith",
                "D. M. Dryden",
                "H. G. Xing",
                "H. P. Nair",
                "D. A. Muller",
                "M. O. Thompson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00821v1",
                "http://arxiv.org/pdf/2311.00821v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00817v1",
            "title": "Using the HOMFLY-PT polynomial to compute knot types",
            "updated": "2023-11-01T20:00:15Z",
            "published": "2023-11-01T20:00:15Z",
            "summary": "The HOMFLY-PT polynomial is a link invariant which is effective in\ndetermining chiral knot and link types with small crossing numbers. In this\nchapter, we concentrate on knots. We provide a guide for computing the knot\ntypes of configurations from 3D coordinates via the HOMFLY-PT polynomial using\npublicly-available Linux freeware. We include data on the efficacy of HOMFLY-PT\nfor knot types through crossing number 16.",
            "author": [
                "Eric J. Rawdon",
                "Robert G. Scharein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00817v1",
                "http://arxiv.org/pdf/2311.00817v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "57K10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00816v1",
            "title": "Faster Peace via Inclusivity: An Efficient Paradigm to Understand\n  Populations in Conflict Zones",
            "updated": "2023-11-01T20:00:12Z",
            "published": "2023-11-01T20:00:12Z",
            "summary": "United Nations practice shows that inclusivity is vital for mediation to be\nsuccessful in helping end violent conflict and establish lasting peace.\nHowever, current methods for understanding the views and needs of populations\nduring dynamic situations create tension between inclusivity and efficiency.\nThis work introduces a novel paradigm to mitigate such tension. In partnership\nwith collaborators at the United Nations we develop a realtime large-scale\nsynchronous dialogue process (RLSDP) to understand stakeholder populations on\nan hour timescale. We demonstrate a machine learning model which enables each\ndialogue cycle to take place on a minute-timescale. We manage a key risk\nrelated to machine learning result trustworthiness by computing result\nconfidence from a fast and reliable estimation of posterior variance. Lastly,\nwe highlight a constellation of risks stemming from this new paradigm and\nsuggest policies to mitigate them.",
            "author": [
                "Jordan Bilich",
                "Michael Varga",
                "Daanish Masood",
                "Andrew Konya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00816v1",
                "http://arxiv.org/pdf/2311.00816v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01475v1",
            "title": "Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts",
            "updated": "2023-11-01T19:59:25Z",
            "published": "2023-11-01T19:59:25Z",
            "summary": "Unsupervised image segmentation aims at grouping different semantic patterns\nin an image without the use of human annotation. Similarly, image clustering\nsearches for groupings of images based on their semantic content without\nsupervision. Classically, both problems have captivated researchers as they\ndrew from sound mathematical concepts to produce concrete applications. With\nthe emergence of deep learning, the scientific community turned its attention\nto complex neural network-based solvers that achieved impressive results in\nthose domains but rarely leveraged the advances made by classical methods. In\nthis work, we propose a patch-based unsupervised image segmentation strategy\nthat bridges advances in unsupervised feature extraction from deep clustering\nmethods with the algorithmic help of classical graph-based methods. We show\nthat a simple convolutional neural network, trained to classify image patches\nand iteratively regularized using graph cuts, naturally leads to a\nstate-of-the-art fully-convolutional unsupervised pixel-level segmenter.\nFurthermore, we demonstrate that this is the ideal setting for leveraging the\npatch-level pairwise features generated by vision transformer models. Our\nresults on real image data demonstrate the effectiveness of our proposed\nmethodology.",
            "author": [
                "Isaac Wasserman",
                "Jeova Farias Sales Rocha Neto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01475v1",
                "http://arxiv.org/pdf/2311.01475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00810v1",
            "title": "A Call to Arms: AI Should be Critical for Social Media Analysis of\n  Conflict Zones",
            "updated": "2023-11-01T19:49:32Z",
            "published": "2023-11-01T19:49:32Z",
            "summary": "The massive proliferation of social media data represents a transformative\nmoment in conflict studies. This data can provide unique insights into the\nspread and use of weaponry, but the scale and types of data are problematic for\ntraditional open-source intelligence. This paper presents preliminary,\ntransdisciplinary work using computer vision to identify specific weapon\nsystems and the insignias of the armed groups using them. There is potential to\nnot only track how weapons are distributed through networks of armed units but\nalso to track which types of weapons are being used by the different types of\nstate and non-state military actors in Ukraine. Such a system could ultimately\nbe used to understand conflicts in real-time, including where humanitarian and\nmedical aid is most needed. We believe that using AI to help automate such\nprocesses should be a high-priority goal for our community, with near-term\nreal-world payoffs.",
            "author": [
                "Afia Abedin",
                "Abdul Bais",
                "Cody Buntain",
                "Laura Courchesne",
                "Brian McQuinn",
                "Matthew E. Taylor",
                "Muhib Ullah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00810v1",
                "http://arxiv.org/pdf/2311.00810v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00807v1",
            "title": "VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization",
            "updated": "2023-11-01T19:43:56Z",
            "published": "2023-11-01T19:43:56Z",
            "summary": "Visual question answering (VQA) models are designed to demonstrate\nvisual-textual reasoning capabilities. However, their real-world applicability\nis hindered by a lack of comprehensive benchmark datasets. Existing domain\ngeneralization datasets for VQA exhibit a unilateral focus on textual shifts\nwhile VQA being a multi-modal task contains shifts across both visual and\ntextual domains. We propose VQA-GEN, the first ever multi-modal benchmark\ndataset for distribution shift generated through a shift induced pipeline.\nExperiments demonstrate VQA-GEN dataset exposes the vulnerability of existing\nmethods to joint multi-modal distribution shifts. validating that comprehensive\nmulti-modal shifts are critical for robust VQA generalization. Models trained\non VQA-GEN exhibit improved cross-domain and in-domain performance, confirming\nthe value of VQA-GEN. Further, we analyze the importance of each shift\ntechnique of our pipeline contributing to the generalization of the model.",
            "author": [
                "Suraj Jyothi Unni",
                "Raha Moraffah",
                "Huan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00807v1",
                "http://arxiv.org/pdf/2311.00807v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00802v1",
            "title": "Neural Field Dynamics Model for Granular Object Piles Manipulation",
            "updated": "2023-11-01T19:36:56Z",
            "published": "2023-11-01T19:36:56Z",
            "summary": "We present a learning-based dynamics model for granular material\nmanipulation. Inspired by the Eulerian approach commonly used in fluid\ndynamics, our method adopts a fully convolutional neural network that operates\non a density field-based representation of object piles and pushers, allowing\nit to exploit the spatial locality of inter-object interactions as well as the\ntranslation equivariance through convolution operations. Furthermore, our\ndifferentiable action rendering module makes the model fully differentiable and\ncan be directly integrated with a gradient-based trajectory optimization\nalgorithm. We evaluate our model with a wide array of piles manipulation tasks\nboth in simulation and real-world experiments and demonstrate that it\nsignificantly exceeds existing latent or particle-based methods in both\naccuracy and computation efficiency, and exhibits zero-shot generalization\ncapabilities across various environments and tasks.",
            "author": [
                "Shangjie Xue",
                "Shuo Cheng",
                "Pujith Kachana",
                "Danfei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00802v1",
                "http://arxiv.org/pdf/2311.00802v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00800v1",
            "title": "Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks",
            "updated": "2023-11-01T19:34:45Z",
            "published": "2023-11-01T19:34:45Z",
            "summary": "A defining characteristic of natural vision is its ability to withstand a\nvariety of input alterations, resulting in the creation of an invariant\nrepresentation of the surroundings. While convolutional neural networks exhibit\nresilience to certain forms of spatial input variation, modifications in the\nspatial and temporal aspects can significantly affect the representations of\nvideo content in deep neural networks. Inspired by the resilience of natural\nvision to input variations, we employ a simple multi-stream model to explore\nits potential to address spatiotemporal changes by including temporal features.\nOur primary goal is to introduce a video-trained model and evaluate its\nrobustness to diverse image and video inputs, with a particular focus on\nexploring the role of temporal features in invariant recognition. Results show\nthat including videos and the temporal stream during training mitigates the\ndecline in accuracy and mAP in image and video understanding tasks by 1.36% and\n3.14%, respectively.",
            "author": [
                "AmirHosein Fadaei",
                "Mohammad-Reza A. Dehaqani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00800v1",
                "http://arxiv.org/pdf/2311.00800v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "I.2.10; I.5.1; I.4.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00798v1",
            "title": "Finer-grained Reductions in Fine-grained Hardness of Approximation",
            "updated": "2023-11-01T19:33:36Z",
            "published": "2023-11-01T19:33:36Z",
            "summary": "We investigate the relation between $\\delta$ and $\\epsilon$ required for\nobtaining a $(1+\\delta)$-approximation in time $N^{2-\\epsilon}$ for closest\npair problems under various distance metrics, and for other related problems in\nfine-grained complexity.\n  Specifically, our main result shows that if it is impossible to (exactly)\nsolve the (bichromatic) inner product (IP) problem for vectors of dimension $c\n\\log N$ in time $N^{2-\\epsilon}$, then there is no $(1+\\delta)$-approximation\nalgorithm for (bichromatic) Euclidean Closest Pair running in time\n$N^{2-2\\epsilon}$, where $\\delta \\approx (\\epsilon/c)^2$ (where $\\approx$ hides\n$\\polylog$ factors). This improves on the prior result due to Chen and Williams\n(SODA 2019) which gave a smaller polynomial dependence of $\\delta$ on\n$\\epsilon$, on the order of $\\delta \\approx (\\epsilon/c)^6$. Our result implies\nin turn that no $(1+\\delta)$-approximation algorithm exists for Euclidean\nclosest pair for $\\delta \\approx \\epsilon^4$, unless an algorithmic improvement\nfor IP is obtained. This in turn is very close to the approximation guarantee\nof $\\delta \\approx \\epsilon^3$ for Euclidean closest pair, given by the best\nknown algorithm of Almam, Chan, and Williams (FOCS 2016). By known reductions,\na similar result follows for a host of other related problems in fine-grained\nhardness of approximation.\n  Our reduction combines the hardness of approximation framework of Chen and\nWilliams, together with an MA communication protocol for IP over a small\nalphabet, that is inspired by the MA protocol of Chen (Theory of Computing,\n2020).",
            "author": [
                "Elie Abboud",
                "Noga Ron-Zewi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00798v1",
                "http://arxiv.org/pdf/2311.00798v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00797v2",
            "title": "Tipping Points of Evolving Epidemiological Networks: Machine\n  Learning-Assisted, Data-Driven Effective Modeling",
            "updated": "2023-11-10T22:49:40Z",
            "published": "2023-11-01T19:33:03Z",
            "summary": "We study the tipping point collective dynamics of an adaptive\nsusceptible-infected-susceptible (SIS) epidemiological network in a\ndata-driven, machine learning-assisted manner. We identify a\nparameter-dependent effective stochastic differential equation (eSDE) in terms\nof physically meaningful coarse mean-field variables through a deep-learning\nResNet architecture inspired by numerical stochastic integrators. We construct\nan approximate effective bifurcation diagram based on the identified drift term\nof the eSDE and contrast it with the mean-field SIS model bifurcation diagram.\nWe observe a subcritical Hopf bifurcation in the evolving network's effective\nSIS dynamics, that causes the tipping point behavior; this takes the form of\nlarge amplitude collective oscillations that spontaneously -- yet rarely --\narise from the neighborhood of a (noisy) stationary state. We study the\nstatistics of these rare events both through repeated brute force simulations\nand by using established mathematical/computational tools exploiting the\nright-hand-side of the identified SDE. We demonstrate that such a collective\nSDE can also be identified (and the rare events computations also performed) in\nterms of data-driven coarse observables, obtained here via manifold learning\ntechniques, in particular Diffusion Maps. The workflow of our study is\nstraightforwardly applicable to other complex dynamics problems exhibiting\ntipping point dynamics.",
            "author": [
                "Nikolaos Evangelou",
                "Tianqi Cui",
                "Juan M. Bello-Rivas",
                "Alexei Makeev",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00797v2",
                "http://arxiv.org/pdf/2311.00797v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.DS",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00796v1",
            "title": "Automatic counting of planting microsites via local visual detection and\n  global count estimation",
            "updated": "2023-11-01T19:31:54Z",
            "published": "2023-11-01T19:31:54Z",
            "summary": "In forest industry, mechanical site preparation by mounding is widely used\nprior to planting operations. One of the main problems when planning planting\noperations is the difficulty in estimating the number of mounds present on a\nplanting block, as their number may greatly vary depending on site\ncharacteristics. This estimation is often carried out through field surveys by\nseveral forestry workers. However, this procedure is prone to error and\nslowness. Motivated by recent advances in UAV imagery and artificial\nintelligence, we propose a fully automated framework to estimate the number of\nmounds on a planting block. Using computer vision and machine learning, we\nformulate the counting task as a supervised learning problem using two\nprediction models. A local detection model is firstly used to detect visible\nmounds based on deep features, while a global prediction function is\nsubsequently applied to provide a final estimation based on block-level\nfeatures. To evaluate the proposed method, we constructed a challenging UAV\ndataset representing several plantation blocks with different characteristics.\nThe performed experiments demonstrated the robustness of the proposed method,\nwhich outperforms manual methods in precision, while significantly reducing\ntime and cost.",
            "author": [
                "Ahmed Zgaren",
                "Wassim Bouachir",
                "Nizar Bouguila"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TETCI.2023.3272004",
                "http://arxiv.org/abs/2311.00796v1",
                "http://arxiv.org/pdf/2311.00796v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00791v1",
            "title": "Where to Deploy an Airborne Relay in Unknown Environments: Feasible\n  Locations for Throughput and LoS Enhancement",
            "updated": "2023-11-01T19:22:33Z",
            "published": "2023-11-01T19:22:33Z",
            "summary": "The deployment of heterogeneous teams of both air and ground mobile assets\ncombines the advantages of mobility, sensing capability, and operational\nduration when performing complex tasks. Air assets in such teams act to relay\ninformation between ground assets but must maintain unblocked paths to enable\nhigh-capacity communication modes. Obstacles in the operational environment may\nblock the line of sight (LoS) between air assets and ground assets depending on\ntheir locations and heights. In this paper, we analyze the probability of\nspanning a two-hop communication between a pair of ground assets deployed in an\nenvironment with obstacles at random locations and with random heights (i.e. a\nPoisson Forest) using an air asset at any location near the ground assets. We\nprovide a closed-form expression of the LoS probability based on the\n3-dimensional locations of the air asset. We then compute a 3-D manifold of the\nair asset locations that satisfy a given LoS probability constraint. We further\nconsider throughput as a measure of communication quality, and use it as an\noptimization objective.",
            "author": [
                "Juan David Pabon",
                "Matthew C. Valenti",
                "Xi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00791v1",
                "http://arxiv.org/pdf/2311.00791v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00790v2",
            "title": "Construction Artifacts in Metaphor Identification Datasets",
            "updated": "2023-11-15T19:11:40Z",
            "published": "2023-11-01T19:21:55Z",
            "summary": "Metaphor identification aims at understanding whether a given expression is\nused figuratively in context. However, in this paper we show how existing\nmetaphor identification datasets can be gamed by fully ignoring the potential\nmetaphorical expression or the context in which it occurs. We test this\nhypothesis in a variety of datasets and settings, and show that metaphor\nidentification systems based on language models without complete information\ncan be competitive with those using the full context. This is due to the\nconstruction procedures to build such datasets, which introduce unwanted biases\nfor positive and negative classes. Finally, we test the same hypothesis on\ndatasets that are carefully sampled from natural corpora and where this bias is\nnot present, making these datasets more challenging and reliable.",
            "author": [
                "Joanne Boisson",
                "Luis Espinosa-Anke",
                "Jose Camacho-Collados"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00790v2",
                "http://arxiv.org/pdf/2311.00790v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00787v1",
            "title": "Accelerating Electronic Stopping Power Predictions by 10 Million Times\n  with a Combination of Time-Dependent Density Functional Theory and Machine\n  Learning",
            "updated": "2023-11-01T19:11:46Z",
            "published": "2023-11-01T19:11:46Z",
            "summary": "Knowing the rate at which particle radiation releases energy in a material,\nthe stopping power, is key to designing nuclear reactors, medical treatments,\nsemiconductor and quantum materials, and many other technologies. While the\nnuclear contribution to stopping power, i.e., elastic scattering between atoms,\nis well understood in the literature, the route for gathering data on the\nelectronic contribution has for decades remained costly and reliant on many\nsimplifying assumptions, including that materials are isotropic. We establish a\nmethod that combines time-dependent density functional theory (TDDFT) and\nmachine learning to reduce the time to assess new materials to mere hours on a\nsupercomputer and provides valuable data on how atomic details influence\nelectronic stopping. Our approach uses TDDFT to compute the electronic stopping\ncontributions to stopping power from first principles in several directions and\nthen machine learning to interpolate to other directions at rates 10 million\ntimes higher. We demonstrate the combined approach in a study of proton\nirradiation in aluminum and employ it to predict how the depth of maximum\nenergy deposition, the \"Bragg Peak,\" varies depending on incident angle -- a\nquantity otherwise inaccessible to modelers. The lack of any experimental\ninformation requirement makes our method applicable to most materials, and its\nspeed makes it a prime candidate for enabling quantum-to-continuum models of\nradiation damage. The prospect of reusing valuable TDDFT data for training the\nmodel make our approach appealing for applications in the age of materials data\nscience.",
            "author": [
                "Logan Ward",
                "Ben Blaiszik",
                "Cheng-Wei Lee",
                "Troy Martin",
                "Ian Foster",
                "Andr\u00e9 Schleife"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00787v1",
                "http://arxiv.org/pdf/2311.00787v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00783v1",
            "title": "Log-Sum Regularized Kaczmarz Algorithms for High-Order Tensor Recovery",
            "updated": "2023-11-01T19:02:15Z",
            "published": "2023-11-01T19:02:15Z",
            "summary": "Sparse and low rank tensor recovery has emerged as a significant area of\nresearch with applications in many fields such as computer vision. However,\nminimizing the $\\ell_0$-norm of a vector or the rank of a matrix is NP-hard.\nInstead, their convex relaxed versions are typically adopted in practice due to\nthe computational efficiency, e.g., log-sum penalty. In this work, we propose\nnovel log-sum regularized Kaczmarz algorithms for recovering high-order tensors\nwith either sparse or low-rank structures. We present block variants along with\nconvergence analysis of the proposed algorithms. Numerical experiments on\nsynthetic and real-world data sets demonstrate the effectiveness of the\nproposed methods.",
            "author": [
                "Katherine Henneberger",
                "Jing Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00783v1",
                "http://arxiv.org/pdf/2311.00783v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00779v2",
            "title": "Shortest paths on polymatroids and hypergraphic polytopes",
            "updated": "2023-11-06T10:42:17Z",
            "published": "2023-11-01T18:46:52Z",
            "summary": "Base polytopes of polymatroids, also known as generalized permutohedra, are\npolytopes whose edges are parallel to a vector of the form $\\mathbf{e}_i -\n\\mathbf{e}_j$. We consider the following computational problem: Given two\nvertices of a generalized permutohedron $P$, find a shortest path between them\non the skeleton of $P$. This captures many known flip distance problems, such\nas computing the minimum number of exchanges between two spanning trees of a\ngraph, the rotation distance between binary search trees, the flip distance\nbetween acyclic orientations of a graph, or rectangulations of a square. We\nprove that this problem is $NP$-hard, even when restricted to very simple\npolymatroids in $\\mathbb{R}^n$ defined by $O(n)$ inequalities. Assuming $P\\not=\nNP$, this rules out the existence of an efficient simplex pivoting rule that\nperforms a minimum number of nondegenerate pivoting steps to an optimal\nsolution of a linear program, even when the latter defines a polymatroid. We\nalso prove that the shortest path problem is inapproximable when the\npolymatroid is specified via an evaluation oracle for a corresponding\nsubmodular function, strengthening a recent result by Ito et al. (ICALP'23).\nMore precisely, we prove the $APX$-hardness of the shortest path problem when\nthe polymatroid is a hypergraphic polytope, whose vertices are in bijection\nwith acyclic orientations of a given hypergraph. The shortest path problem then\namounts to computing the flip distance between two acyclic orientations of a\nhypergraph. On the positive side, we provide a polynomial-time approximation\nalgorithm for the problem of computing the flip distance between two acyclic\norientations of a hypergraph, where the approximation factor is the maximum\ncodegree of the hypergraph. Our result implies an exact polynomial-time\nalgorithm for the flip distance between two acyclic orientations of any linear\nhypergraph.",
            "author": [
                "Jean Cardinal",
                "Raphael Steiner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00779v2",
                "http://arxiv.org/pdf/2311.00779v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "math.CO",
                "math.OC",
                "90C05, 90C08, 90C27, 90C35, 90C49, 90C57, 90C60, 05C50, 05C65,\n  05B35, 52B40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00778v1",
            "title": "Convergence of Heterogeneous Learning Dynamics in Zero-sum Stochastic\n  Games",
            "updated": "2023-11-01T18:46:32Z",
            "published": "2023-11-01T18:46:32Z",
            "summary": "This paper presents new families of algorithms for the repeated play of\ntwo-agent (near) zero-sum games and two-agent zero-sum stochastic games. For\nexample, the family includes fictitious play and its variants as members.\nCommonly, the algorithms in this family are all uncoupled, rational, and\nconvergent even in heterogeneous cases, e.g., where the dynamics may differ in\nterms of learning rates, full, none or temporal access to opponent actions, and\nmodel-based vs model-free learning. The convergence of heterogeneous dynamics\nis of practical interest especially in competitive environments since agents\nmay have no means or interests in following the same dynamic with the same\nparameters. We prove that any mixture of such asymmetries does not impact the\nalgorithms' convergence to equilibrium (or near equilibrium if there is\nexperimentation) in zero-sum games with repeated play and in zero-sum\n(irreducible) stochastic games with sufficiently small discount factors.",
            "author": [
                "Yuksel Arslantas",
                "Ege Yuceel",
                "Yigit Yalin",
                "Muhammed O. Sayin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00778v1",
                "http://arxiv.org/pdf/2311.00778v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04913v2",
            "title": "An Improved Transformer-based Model for Detecting Phishing, Spam, and\n  Ham: A Large Language Model Approach",
            "updated": "2023-11-12T16:32:16Z",
            "published": "2023-11-01T18:41:50Z",
            "summary": "Phishing and spam detection is long standing challenge that has been the\nsubject of much academic research. Large Language Models (LLM) have vast\npotential to transform society and provide new and innovative approaches to\nsolve well-established challenges. Phishing and spam have caused financial\nhardships and lost time and resources to email users all over the world and\nfrequently serve as an entry point for ransomware threat actors. While\ndetection approaches exist, especially heuristic-based approaches, LLMs offer\nthe potential to venture into a new unexplored area for understanding and\nsolving this challenge. LLMs have rapidly altered the landscape from business,\nconsumers, and throughout academia and demonstrate transformational potential\nfor the potential of society. Based on this, applying these new and innovative\napproaches to email detection is a rational next step in academic research. In\nthis work, we present IPSDM, our model based on fine-tuning the BERT family of\nmodels to specifically detect phishing and spam email. We demonstrate our\nfine-tuned version, IPSDM, is able to better classify emails in both unbalanced\nand balanced datasets. This work serves as an important first step towards\nemploying LLMs to improve the security of our information systems.",
            "author": [
                "Suhaima Jamal",
                "Hayden Wimmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04913v2",
                "http://arxiv.org/pdf/2311.04913v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00774v1",
            "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
            "updated": "2023-11-01T18:37:07Z",
            "published": "2023-11-01T18:37:07Z",
            "summary": "Uncertainty estimation is critical in high-stakes machine learning\napplications. One effective way to estimate uncertainty is conformal\nprediction, which can provide predictive inference with statistical coverage\nguarantees. We present a new conformal regression method, Spline Prediction\nIntervals via Conformal Estimation (SPICE), that estimates the conditional\ndensity using neural-network-parameterized splines. We prove universal\napproximation and optimality results for SPICE, which are empirically validated\nby our experiments. SPICE is compatible with two different efficient-to-compute\nconformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the\nother asymptotically optimal for conditional coverage (SPICE-HPD). Results on\nbenchmark datasets demonstrate SPICE-ND models achieve the smallest average\nprediction set sizes, including average size reductions of nearly 50% for some\ndatasets compared to the next best baseline. SPICE-HPD models achieve the best\nconditional coverage compared to baselines. The SPICE implementation is made\navailable.",
            "author": [
                "Nathaniel Diamant",
                "Ehsan Hajiramezanali",
                "Tommaso Biancalani",
                "Gabriele Scalia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00774v1",
                "http://arxiv.org/pdf/2311.00774v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04911v1",
            "title": "From Text to Structure: Using Large Language Models to Support the\n  Development of Legal Expert Systems",
            "updated": "2023-11-01T18:31:02Z",
            "published": "2023-11-01T18:31:02Z",
            "summary": "Encoding legislative text in a formal representation is an important\nprerequisite to different tasks in the field of AI & Law. For example,\nrule-based expert systems focused on legislation can support laypeople in\nunderstanding how legislation applies to them and provide them with helpful\ncontext and information. However, the process of analyzing legislation and\nother sources to encode it in the desired formal representation can be\ntime-consuming and represents a bottleneck in the development of such systems.\nHere, we investigate to what degree large language models (LLMs), such as\nGPT-4, are able to automatically extract structured representations from\nlegislation. We use LLMs to create pathways from legislation, according to the\nJusticeBot methodology for legal decision support systems, evaluate the\npathways and compare them to manually created pathways. The results are\npromising, with 60% of generated pathways being rated as equivalent or better\nthan manually created ones in a blind comparison. The approach suggests a\npromising path to leverage the capabilities of LLMs to ease the costly\ndevelopment of systems based on symbolic approaches that are transparent and\nexplainable.",
            "author": [
                "Samyar Janatian",
                "Hannes Westermann",
                "Jinzhe Tan",
                "Jaromir Savelka",
                "Karim Benyekhlef"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04911v1",
                "http://arxiv.org/pdf/2311.04911v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14680v2",
            "title": "E-polis: A serious game for the gamification of sociological surveys",
            "updated": "2023-11-28T10:03:24Z",
            "published": "2023-11-01T18:25:13Z",
            "summary": "E-polis is a multi-platform serious game that gamifies a sociological survey\nfor studying young people's opinions regarding their ideal society. The\ngameplay is based on a user navigating through a digital city, experiencing the\nchanges inflicted, triggered by responses to social and pedagogical surveys,\nknown as \"dilemmas\". The game integrates elements of adventure, exploration,\nand simulation. Unity was the selected game engine used for the development of\nthe game, while a middleware component was also developed to gather and process\nthe users' data. At the end of each game, users are presented with a blueprint\nof the city they navigated to showcase how their choices influenced its\ndevelopment. This motivates them to reflect on their answers and validate them.\nThe game can be used to collect data on a variety of topics, such as social\njustice, and economic development, or to promote civic engagement and encourage\nyoung people to think critically about the world around them.",
            "author": [
                "Alexandros Gazis",
                "Eleftheria Katsiri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14680v2",
                "http://arxiv.org/pdf/2311.14680v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.GR",
                "cs.MM",
                "eess.IV",
                "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00768v1",
            "title": "Language Model Training Paradigms for Clinical Feature Embeddings",
            "updated": "2023-11-01T18:23:12Z",
            "published": "2023-11-01T18:23:12Z",
            "summary": "In research areas with scarce data, representation learning plays a\nsignificant role. This work aims to enhance representation learning for\nclinical time series by deriving universal embeddings for clinical features,\nsuch as heart rate and blood pressure. We use self-supervised training\nparadigms for language models to learn high-quality clinical feature\nembeddings, achieving a finer granularity than existing time-step and\npatient-level representation learning. We visualize the learnt embeddings via\nunsupervised dimension reduction techniques and observe a high degree of\nconsistency with prior clinical knowledge. We also evaluate the model\nperformance on the MIMIC-III benchmark and demonstrate the effectiveness of\nusing clinical feature embeddings. We publish our code online for replication.",
            "author": [
                "Yurong Hu",
                "Manuel Burger",
                "Gunnar R\u00e4tsch",
                "Rita Kuznetsova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00768v1",
                "http://arxiv.org/pdf/2311.00768v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00766v1",
            "title": "Quantum Pathways for Charged Track Finding in High-Energy Collisions",
            "updated": "2023-11-01T18:13:59Z",
            "published": "2023-11-01T18:13:59Z",
            "summary": "In high-energy particle collisions, charged track finding is a complex yet\ncrucial endeavour. We propose a quantum algorithm, specifically quantum\ntemplate matching, to enhance the accuracy and efficiency of track finding.\nAbstracting the Quantum Amplitude Amplification routine by introducing a data\nregister, and utilising a novel oracle construction, allows data to be parsed\nto the circuit and matched with a hit-pattern template, without prior knowledge\nof the input data. Furthermore, we address the challenges posed by missing hit\ndata, demonstrating the ability of the quantum template matching algorithm to\nsuccessfully identify charged-particle tracks from hit patterns with missing\nhits. Our findings therefore propose quantum methodologies tailored for\nreal-world applications and underline the potential of quantum computing in\ncollider physics.",
            "author": [
                "Christopher Brown",
                "Michael Spannowsky",
                "Alexander Tapper",
                "Simon Williams",
                "Ioannis Xiotidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00766v1",
                "http://arxiv.org/pdf/2311.00766v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00765v1",
            "title": "Coupled spin-lattice dynamics from the tight-binding electronic\n  structure",
            "updated": "2023-11-01T18:11:57Z",
            "published": "2023-11-01T18:11:57Z",
            "summary": "We developed a method which performs the coupled adiabatic spin and lattice\ndynamics based on the tight-binding electronic structure model, where the\nintrinsic magnetic field and ionic forces are calculated from the converged\nself-consistent electronic structure at every time step. By doing so, this\nmethod allows us to explore limits where the physics described by a\nparameterized spin-lattice Hamiltonian is no longer accurate. We demonstrate\nhow the lattice dynamics is strongly influenced by the underlying magnetic\nconfiguration, where disorder is able to induce significant lattice\ndistortions. The presented method requires significantly less computational\nresources than ab initio methods, such as time-dependent density functional\ntheory (TD-DFT). Compared to parameterized Hamiltonian-based methods, it also\ndescribes more accurately the dynamics of the coupled spin and lattice degrees\nof freedom, which becomes important outside of the regime of small lattice and\nspin fluctuations.",
            "author": [
                "Ramon Cardias",
                "Simon Streib",
                "Zhiwei Lu",
                "Manuel Pereiro",
                "Anders Bergman",
                "Erik Sj\u00f6qvist",
                "Cyrille Barreteau",
                "Anna Delin",
                "Olle Eriksson",
                "Danny Thonig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00765v1",
                "http://arxiv.org/pdf/2311.00765v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00762v1",
            "title": "Challenges for Linguistically-Driven Computer-Based Sign Recognition\n  from Continuous Signing for American Sign Language",
            "updated": "2023-11-01T18:08:44Z",
            "published": "2023-11-01T18:08:44Z",
            "summary": "There have been recent advances in computer-based recognition of isolated,\ncitation-form signs from video. There are many challenges for such a task, not\nleast the naturally occurring inter- and intra- signer synchronic variation in\nsign production, including sociolinguistic variation in the realization of\ncertain signs. However, there are several significant factors that make\nrecognition of signs from continuous signing an even more difficult problem.\nThis article presents an overview of such challenges, based in part on findings\nfrom a large corpus of linguistically annotated video data for American Sign\nLanguage (ASL). Some linguistic regularities in the structure of signs that can\nboost handshape and sign recognition are also discussed.",
            "author": [
                "Carol Neidle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00762v1",
                "http://arxiv.org/pdf/2311.00762v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00757v1",
            "title": "Hydrodynamic properties of the perfect hard-sphere crystal: Microscopic\n  computations with Helfand moments",
            "updated": "2023-11-01T18:05:25Z",
            "published": "2023-11-01T18:05:25Z",
            "summary": "Within the framework of the local-equilibrium approach, the equilibrium and\nnonequilibrium properties relevant to the hydrodynamics of the perfect\nhard-sphere crystal are obtained with molecular dynamics simulations using the\nHelfand moments associated with momentum and energy transports. Since this\ncrystal is face-centered cubic, the hydrodynamic properties we consider are the\nhydrostatic pressure, the isothermal bulk modulus, the specific heat capacities\nand their ratio, the three isothermal elastic constants\n$(C_{11}^T,C_{12}^T,C_{44}^T)$, the heat conductivity, and the three\nviscosities $(\\eta_{11},\\eta_{12},\\eta_{44})$ (in Voigt's notations). These\nproperties are computed as a function of the particle density. The pressure and\nthe transport coefficients diverge near the close-packing density, as the\ncollision frequency per particle does.",
            "author": [
                "Joel Mabillard",
                "Pierre Gaspard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00757v1",
                "http://arxiv.org/pdf/2311.00757v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00755v2",
            "title": "Distinct distributions of elliptical and disk galaxies across the Local\n  Supercluster as a $\u039b$CDM prediction",
            "updated": "2023-12-05T11:44:42Z",
            "published": "2023-11-01T18:01:44Z",
            "summary": "Galaxies of different types are not equally distributed in the Local\nUniverse. In particular, the supergalactic plane is prominent among the\nbrightest ellipticals, but inconspicuous among the brightest disk galaxies.\nThis striking difference provides a unique test for our understanding of galaxy\nand structure formation. Here we use the SIBELIUS DARK constrained simulation\nto confront the predictions of the standard Lambda Cold Dark Matter\n($\\Lambda$CDM) model and standard galaxy formation theory with these\nobservations. We find that SIBELIUS DARK reproduces the spatial distributions\nof disks and ellipticals and, in particular, the observed excess of massive\nellipticals near the supergalactic equator. We show that this follows directly\nfrom the local large-scale structure and from the standard galaxy formation\nparadigm, wherein disk galaxies evolve mostly in isolation, while giant\nellipticals congregate in the massive clusters that define the supergalactic\nplane. Rather than being anomalous as earlier works have suggested, the\ndistributions of giant ellipticals and disks in the Local Universe and in\nrelation to the supergalactic plane are key predictions of the $\\Lambda$CDM\nmodel.",
            "author": [
                "Till Sawala",
                "Carlos Frenk",
                "Jens Jasche",
                "Peter H. Johansson",
                "Guilhem Lavaux"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00755v2",
                "http://arxiv.org/pdf/2311.00755v2"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00750v1",
            "title": "Are These the Same Apple? Comparing Images Based on Object Intrinsics",
            "updated": "2023-11-01T18:00:03Z",
            "published": "2023-11-01T18:00:03Z",
            "summary": "The human visual system can effortlessly recognize an object under different\nextrinsic factors such as lighting, object poses, and background, yet current\ncomputer vision systems often struggle with these variations. An important step\nto understanding and improving artificial vision systems is to measure image\nsimilarity purely based on intrinsic object properties that define object\nidentity. This problem has been studied in the computer vision literature as\nre-identification, though mostly restricted to specific object categories such\nas people and cars. We propose to extend it to general object categories,\nexploring an image similarity metric based on object intrinsics. To benchmark\nsuch measurements, we collect the Common paired objects Under differenT\nExtrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different\nextrinsic factors such as lighting, poses, and imaging conditions. While\nexisting methods such as LPIPS and CLIP scores do not measure object intrinsics\nwell, we find that combining deep features learned from contrastive\nself-supervised learning with foreground filtering is a simple yet effective\napproach to approximating the similarity. We conduct an extensive survey of\npre-trained features and foreground extraction methods to arrive at a strong\nbaseline that best measures intrinsic object-centric image similarity among\ncurrent methods. Finally, we demonstrate that our approach can aid in\ndownstream applications such as acting as an analog for human subjects and\nimproving generalizable re-identification. Please see our project website at\nhttps://s-tian.github.io/projects/cute/ for visualizations of the data and\ndemos of our metric.",
            "author": [
                "Klemen Kotar",
                "Stephen Tian",
                "Hong-Xing Yu",
                "Daniel L. K. Yamins",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00750v1",
                "http://arxiv.org/pdf/2311.00750v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00748v2",
            "title": "Variational adiabatic transport of tensor networks",
            "updated": "2023-11-28T19:00:04Z",
            "published": "2023-11-01T18:00:02Z",
            "summary": "We discuss a tensor network method for constructing the adiabatic gauge\npotential -- the generator of adiabatic transformations -- as a matrix product\noperator, which allows us to adiabatically transport matrix product states.\nAdiabatic evolution of tensor networks offers a wide range of applications, of\nwhich two are explored in this paper: improving tensor network optimization and\nscanning phase diagrams. By efficiently transporting eigenstates to quantum\ncriticality and performing intermediary density matrix renormalization group\n(DMRG) optimizations along the way, we demonstrate that we can compute ground\nand low-lying excited states faster and more reliably than a standard DMRG\nmethod at or near quantum criticality. We demonstrate a simple automated step\nsize adjustment and detection of the critical point based on the norm of the\nadiabatic gauge potential. Remarkably, we are able to reliably transport states\nthrough the critical point of the models we study.",
            "author": [
                "Hyeongjin Kim",
                "Matthew T. Fishman",
                "Dries Sels"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00748v2",
                "http://arxiv.org/pdf/2311.00748v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.str-el",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00745v1",
            "title": "Tropological Sigma Models",
            "updated": "2023-11-01T18:00:01Z",
            "published": "2023-11-01T18:00:01Z",
            "summary": "With the use of mathematical techniques of tropical geometry, it was shown by\nMikhalkin some twenty years ago that certain Gromov-Witten invariants\nassociated with topological quantum field theories of pseudoholomorphic maps\ncan be computed by going to the tropical limit of the geometries in question.\nHere we examine this phenomenon from the physics perspective of topological\nquantum field theory in the path integral representation, beginning with the\ncase of the topological sigma model before coupling it to topological gravity.\nWe identify the tropicalization of the localization equations, investigate its\ngeometry and symmetries, and study the theory and its observables using the\nstandard cohomological BRST methods. We find that the worldsheet theory\nexhibits a nonrelativistic structure, similar to theories of the Lifshitz type.\nIts path-integral formulation does not require a worldsheet complex structure;\ninstead, it is based on a worldsheet foliation structure.",
            "author": [
                "Emil Albrychiewicz",
                "Kai-Isaak Ellers",
                "Andr\u00e9s Franco Valiente",
                "Petr Ho\u0159ava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00745v1",
                "http://arxiv.org/pdf/2311.00745v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math-ph",
                "math.AG",
                "math.DG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00741v1",
            "title": "(Multi-field) Natural Inflation and Gravitational Waves",
            "updated": "2023-11-01T18:00:00Z",
            "published": "2023-11-01T18:00:00Z",
            "summary": "We provide a detailed study of natural inflation with a periodic non-minimal\ncoupling, which is a well-motivated inflationary model that admits an explicit\nUV completion. We demonstrate that this construction can satisfy the most\nrecent observational constraints from Planck and the BICEP/Keck collaborations.\nWe also compute the corresponding relic gravitational wave background due to\ntensor perturbations and show that future space-borne interferometers, such as\nDECIGO, BBO and ALIA, may be able to detect it. Next, we extend this analysis\nand establish the validity of these results in a multi-field model featuring an\nadditional $R^2$ term in the action, which allows us to interpolate between\nnatural and scalaron (a.k.a.~Starobinsky) inflation. We investigate the\nconditions under which the aforementioned future interferometers will have the\ncapability to differentiate between pure natural inflation and natural-scalaron\ninflation. The latter analysis could open the door to distinguishing between\nsingle-field and multi-field inflation through gravitational wave observations\nin more general contexts.",
            "author": [
                "Alberto Salvio",
                "Simone Sciusco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00741v1",
                "http://arxiv.org/pdf/2311.00741v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00742v1",
            "title": "Cubic and higher-order supergravity couplings for AdS vacua using\n  Exceptional Field Theory",
            "updated": "2023-11-01T18:00:00Z",
            "published": "2023-11-01T18:00:00Z",
            "summary": "We show how to use Exceptional Field Theory to efficiently compute $n$-point\ncouplings of all Kaluza-Klein modes for vacua that can be uplifted from maximal\ngauged supergravities to 10/11 dimensions via a consistent truncation. Via the\nAdS/CFT correspondence, these couplings encode the $n$-point functions of\nholographic conformal fields theories. Our methods show that these $n$-point\ncouplings are controlled by the $n$-point invariant of scalar harmonics of the\nmaximally symmetric point of the truncation, allowing us to show that\ninfinitely-many $n$-point couplings vanish for any vacua of the truncation,\neven though they may be allowed by the remnant symmetry group of the vacua.\nThis gives new results even for the maximally supersymmetric AdS$_5 \\times\nS^5$, AdS$_4 \\times S^7$ and AdS$_7 \\times S^4$ vacua of string and M-theory,\nwhere we prove old conjectures about the vanishing of $n$-point extremal and\nnear-extremal couplings.\n  Focusing in particular on cubic couplings for vacua of 5-dimensional gauged\nsupergravity, we derive explicit universal formulae encoding these couplings\nfor any vacuum within a consistent truncation. We use this to compute known and\nnew couplings involving spin-0, spin-1, spin-2 for the AdS$_5 \\times S^5$\nvacuum of IIB string theory.",
            "author": [
                "Bastien Duboeuf",
                "Emanuel Malek",
                "Henning Samtleben"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00742v1",
                "http://arxiv.org/pdf/2311.00742v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00702v2",
            "title": "Dark Matter in A Mirror Solution to the Strong CP Problem",
            "updated": "2023-11-30T07:16:23Z",
            "published": "2023-11-01T17:59:56Z",
            "summary": "We study thermal production of dark matter (DM) in a realization of the\nminimal models of Ref.\\cite{Bonnefoy:2023afx}, where parity is used to solve\nthe strong CP problem by transforming the entire Standard Model (SM) into a\nmirror copy. Although the mirror electron $e^{\\prime}$ is a good DM candidate,\nits viability is mired by the presence of the mirror up-quark $u^{\\prime}$,\nwhose abundance is intimately related to the $e^{\\prime}$ abundance and must be\nsuppressed. This can be achieved through a sequential freeze-in mechanism,\nwhere mirror photons are first produced from SM gluons, and then the mirror\nphotons produce $e'$. After computing the details of this double freeze-in, we\ndiscuss the allowed parameter space of the model, which lies at the threshold\nof experimental observations. We find that this origin of $e'$ DM requires a\nlow reheating temperature after inflation and is consistent with the baryon\nasymmetry arising from leptogenesis, providing mirror neutrinos have a\nsignificant degeneracy. Finally, we show that this $e'$ DM is not compatible\nwith Higgs Parity, the simplest scheme with exact parity, unless SM parameters\ndeviate significantly from their central values or the minimal model is\nextended.",
            "author": [
                "Quentin Bonnefoy",
                "Lawrence Hall",
                "Claudio Andrea Manzari",
                "Amara McCune",
                "Christiane Scherb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00702v2",
                "http://arxiv.org/pdf/2311.00702v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00701v1",
            "title": "The Moving Discontinuous Galerkin Method with Interface Condition\n  Enforcement for Robust Simulations of High-Speed Viscous Flows",
            "updated": "2023-11-01T17:59:25Z",
            "published": "2023-11-01T17:59:25Z",
            "summary": "The moving discontinuous Galerkin method with interface condition enforcement\n(MDG-ICE) is a high-order, r-adaptive method that treats the grid as a variable\nand weakly enforces the conservation law, constitutive law, and corresponding\ninterface conditions in order to implicitly fit high-gradient flow features. In\nthis paper, we introduce nonlinear solver strategies to more robustly and\nefficiently compute high-speed viscous flows. Specifically, we incorporate an\nanisotropic grid regularization based on the mesh-implied metric into the\nnonlinear least-squares solver that inhibits grid motion in directions with\nsmall element length scales. Furthermore, we develop an adaptive elementwise\nregularization strategy that locally scales the regularization terms as needed\nto maintain grid validity. We apply the proposed MDG-ICE formulation to test\ncases involving viscous shocks and/or boundary layers, including Mach 17.6\nhypersonic viscous flow over a circular cylinder and Mach 5 hypersonic viscous\nflow over a sphere, which are very challenging test cases for conventional\nnumerical schemes on simplicial grids. Even without artificial dissipation, the\ncomputed solutions are free from spurious oscillations and yield highly\nsymmetric surface heat-flux profiles.",
            "author": [
                "Eric J. Ching",
                "Andrew D. Kercher",
                "Andrew Corrigan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00701v1",
                "http://arxiv.org/pdf/2311.00701v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00697v1",
            "title": "End-to-End Single-Channel Speaker-Turn Aware Conversational Speech\n  Translation",
            "updated": "2023-11-01T17:55:09Z",
            "published": "2023-11-01T17:55:09Z",
            "summary": "Conventional speech-to-text translation (ST) systems are trained on\nsingle-speaker utterances, and they may not generalize to real-life scenarios\nwhere the audio contains conversations by multiple speakers. In this paper, we\ntackle single-channel multi-speaker conversational ST with an end-to-end and\nmulti-task training model, named Speaker-Turn Aware Conversational Speech\nTranslation, that combines automatic speech recognition, speech translation and\nspeaker turn detection using special tokens in a serialized labeling format. We\nrun experiments on the Fisher-CALLHOME corpus, which we adapted by merging the\ntwo single-speaker channels into one multi-speaker channel, thus representing\nthe more realistic and challenging scenario with multi-speaker turns and\ncross-talk. Experimental results across single- and multi-speaker conditions\nand against conventional ST systems, show that our model outperforms the\nreference systems on the multi-speaker condition, while attaining comparable\nperformance on the single-speaker condition. We release scripts for data\nprocessing and model training.",
            "author": [
                "Juan Zuluaga-Gomez",
                "Zhaocheng Huang",
                "Xing Niu",
                "Rohit Paturi",
                "Sundararajan Srinivasan",
                "Prashant Mathur",
                "Brian Thompson",
                "Marcello Federico"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00697v1",
                "http://arxiv.org/pdf/2311.00697v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00694v2",
            "title": "Unleashing the Creative Mind: Language Model As Hierarchical Policy For\n  Improved Exploration on Challenging Problem Solving",
            "updated": "2023-12-05T20:44:45Z",
            "published": "2023-11-01T17:52:15Z",
            "summary": "Large Language Models (LLMs) have achieved tremendous progress, yet they\nstill often struggle with challenging reasoning problems. Current approaches\naddress this challenge by sampling or searching detailed and low-level\nreasoning chains. However, these methods are still limited in their exploration\ncapabilities, making it challenging for correct solutions to stand out in the\nhuge solution space. In this work, we unleash LLMs' creative potential for\nexploring multiple diverse problem solving strategies by framing an LLM as a\nhierarchical policy via in-context learning. This policy comprises of a\nvisionary leader that proposes multiple diverse high-level problem-solving\ntactics as hints, accompanied by a follower that executes detailed\nproblem-solving processes following each of the high-level instruction. The\nfollower uses each of the leader's directives as a guide and samples multiple\nreasoning chains to tackle the problem, generating a solution group for each\nleader proposal. Additionally, we propose an effective and efficient\ntournament-based approach to select among these explored solution groups to\nreach the final answer. Our approach produces meaningful and inspiring hints,\nenhances problem-solving strategy exploration, and improves the final answer\naccuracy on challenging problems in the MATH dataset. Code will be released at\nhttps://github.com/lz1oceani/LLM-As-Hierarchical-Policy.",
            "author": [
                "Zhan Ling",
                "Yunhao Fang",
                "Xuanlin Li",
                "Tongzhou Mu",
                "Mingu Lee",
                "Reza Pourreza",
                "Roland Memisevic",
                "Hao Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00694v2",
                "http://arxiv.org/pdf/2311.00694v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00693v1",
            "title": "On Task-personalized Multimodal Few-shot Learning for Visually-rich\n  Document Entity Retrieval",
            "updated": "2023-11-01T17:51:43Z",
            "published": "2023-11-01T17:51:43Z",
            "summary": "Visually-rich document entity retrieval (VDER), which extracts key\ninformation (e.g. date, address) from document images like invoices and\nreceipts, has become an important topic in industrial NLP applications. The\nemergence of new document types at a constant pace, each with its unique entity\ntypes, presents a unique challenge: many documents contain unseen entity types\nthat occur only a couple of times. Addressing this challenge requires models to\nhave the ability of learning entities in a few-shot manner. However, prior\nworks for Few-shot VDER mainly address the problem at the document level with a\npredefined global entity space, which doesn't account for the entity-level\nfew-shot scenario: target entity types are locally personalized by each task\nand entity occurrences vary significantly among documents. To address this\nunexplored scenario, this paper studies a novel entity-level few-shot VDER\ntask. The challenges lie in the uniqueness of the label space for each task and\nthe increased complexity of out-of-distribution (OOD) contents. To tackle this\nnovel task, we present a task-aware meta-learning based framework, with a\ncentral focus on achieving effective task personalization that distinguishes\nbetween in-task and out-of-task distribution. Specifically, we adopt a\nhierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to\nachieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost\nfuture research in the field of entity-level few-shot VDER. Experimental\nresults demonstrate our approaches significantly improve the robustness of\npopular meta-learning baselines.",
            "author": [
                "Jiayi Chen",
                "Hanjun Dai",
                "Bo Dai",
                "Aidong Zhang",
                "Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00693v1",
                "http://arxiv.org/pdf/2311.00693v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11966v1",
            "title": "Conjectures in number theory",
            "updated": "2023-11-01T17:50:18Z",
            "published": "2023-11-01T17:50:18Z",
            "summary": "Prime numbers, whose properties are important subjects in mathematics, are\nalso fundamental in computer science notably in IT security, Cryptocurrencies\nas Bitcoin and Blockchain, cryptography, Code theory notably Error detection\ncodes, integer factorization, and random number generation. Finding prime\nnumbers is too an active area of research in mathematics. There are many\nmethods for identifying and generating them and many primality tests which are\noften complex and expensive in terms of calculation time, and many conjectures\nand theorems related to prime numbers, such as the prime number theorem,\nGoldbach's conjecture, and the Riemann hypothesis. My objective in this work is\nto propose two conjectures :\n  $1)$ the integer\n  $1+3.2^{20n}$ is not a prime number for all $n=0$ or $1$ mod $3$, and $2)$\nthe integer\n  $1+3.2^{4+20n}$ is not a prime number for all $n=2$ mod $3$.\n  Keywords : Prime numbers; IT security; Cryptography.",
            "author": [
                "Ahmed Asimi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11966v1",
                "http://arxiv.org/pdf/2311.11966v1"
            ],
            "primary_category": "math.GM",
            "category": [
                "math.GM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00690v3",
            "title": "What User Behaviors Make the Differences During the Process of Visual\n  Analytics?",
            "updated": "2023-12-04T02:58:02Z",
            "published": "2023-11-01T17:45:52Z",
            "summary": "The understanding of visual analytics process can benefit visualization\nresearchers from multiple aspects, including improving visual designs and\ndeveloping advanced interaction functions. However, the log files of user\nbehaviors are still hard to analyze due to the complexity of sensemaking and\nour lack of knowledge on the related user behaviors. This work presents a study\non a comprehensive data collection of user behaviors, and our analysis approach\nwith time-series classification methods. We have chosen a classical\nvisualization application, Covid-19 data analysis, with common analysis tasks\ncovering geo-spatial, time-series and multi-attributes. Our user study collects\nuser behaviors on a diverse set of visualization tasks with two comparable\nsystems, desktop and immersive visualizations. We summarize the classification\nresults with three time-series machine learning algorithms at two scales, and\nexplore the influences of behavior features. Our results reveal that user\nbehaviors can be distinguished during the process of visual analytics and there\nis a potentially strong association between the physical behaviors of users and\nthe visualization tasks they perform. We also demonstrate the usage of our\nmodels by interpreting open sessions of visual analytics, which provides an\nautomatic way to study sensemaking without tedious manual annotations.",
            "author": [
                "Zekun Wu",
                "Shahin Doroudian",
                "Aidong Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00690v3",
                "http://arxiv.org/pdf/2311.00690v3"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00689v2",
            "title": "Collaboration in Immersive Environments: Challenges and Solutions",
            "updated": "2023-11-16T21:02:05Z",
            "published": "2023-11-01T17:45:22Z",
            "summary": "Virtual Reality (VR) and Augmented Reality (AR) tools have been applied in\nall engineering fields in order to avoid the use of physical prototypes, to\ntrain in high-risk situations, and to interpret real or simulated results. In\norder to complete a shared task or assign tasks to the agents in such immersive\nenvironments, collaboration or Shared Cooperative Activities are a necessity.\nCollaboration in immersive environments is an emerging field of research that\naims to study and enhance the ways in which people interact and work together\nin Virtual and Augmented Reality settings. Collaboration in immersive\nenvironments is a complex process that involves different factors such as\ncommunication, coordination, and social presence. This paper provides an\noverview of the current state of research on collaboration in immersive\nenvironments. It discusses the different types of immersive environments,\nincluding VR and AR, and the different forms of collaboration that can occur in\nthese environments. The paper also highlights the challenges and limitations of\ncollaboration in immersive environments, such as the lack of physical cues,\ncost and usability and the need for further research in this area. Overall,\ncollaboration in immersive environments is a promising field with a wide range\nof potential applications, from education to industry, and it can benefit both\nindividuals and groups by enhancing their ability to work together effectively.",
            "author": [
                "Shahin Doroudian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00689v2",
                "http://arxiv.org/pdf/2311.00689v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00687v2",
            "title": "Improving Interpersonal Communication by Simulating Audiences with\n  Language Models",
            "updated": "2023-11-03T13:17:55Z",
            "published": "2023-11-01T17:44:50Z",
            "summary": "How do we communicate with others to achieve our goals? We use our prior\nexperience or advice from others, or construct a candidate utterance by\npredicting how it will be received. However, our experiences are limited and\nbiased, and reasoning about potential outcomes can be difficult and cognitively\nchallenging. In this paper, we explore how we can leverage Large Language Model\n(LLM) simulations to help us communicate better. We propose the\nExplore-Generate-Simulate (EGS) framework, which takes as input any scenario\nwhere an individual is communicating to an audience with a goal they want to\nachieve. EGS (1) explores the solution space by producing a diverse set of\nadvice relevant to the scenario, (2) generates communication candidates\nconditioned on subsets of the advice, and (3) simulates the reactions from\nvarious audiences to determine both the best candidate and advice to use. We\nevaluate the framework on eight scenarios spanning the ten fundamental\nprocesses of interpersonal communication. For each scenario, we collect a\ndataset of human evaluations across candidates and baselines, and showcase that\nour framework's chosen candidate is preferred over popular generation\nmechanisms including Chain-of-Thought. We also find that audience simulations\nachieve reasonably high agreement with human raters across 5 of the 8\nscenarios. Finally, we demonstrate the generality of our framework by applying\nit to real-world scenarios described by users on web forums. Through\nevaluations and demonstrations, we show that EGS enhances the effectiveness and\noutcomes of goal-oriented communication across a variety of situations, thus\nopening up new possibilities for the application of large language models in\nrevolutionizing communication and decision-making processes.",
            "author": [
                "Ryan Liu",
                "Howard Yen",
                "Raja Marjieh",
                "Thomas L. Griffiths",
                "Ranjay Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00687v2",
                "http://arxiv.org/pdf/2311.00687v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00686v1",
            "title": "Little Giants: Exploring the Potential of Small LLMs as Evaluation\n  Metrics in Summarization in the Eval4NLP 2023 Shared Task",
            "updated": "2023-11-01T17:44:35Z",
            "published": "2023-11-01T17:44:35Z",
            "summary": "This paper describes and analyzes our participation in the 2023 Eval4NLP\nshared task, which focuses on assessing the effectiveness of prompt-based\ntechniques to empower Large Language Models to handle the task of quality\nestimation, particularly in the context of evaluating machine translations and\nsummaries. We conducted systematic experiments with various prompting\ntechniques, including standard prompting, prompts informed by annotator\ninstructions, and innovative chain-of-thought prompting. In addition, we\nintegrated these approaches with zero-shot and one-shot learning methods to\nmaximize the efficacy of our evaluation procedures. Our work reveals that\ncombining these approaches using a \"small\", open source model (orca_mini_v3_7B)\nyields competitive results.",
            "author": [
                "Neema Kotonya",
                "Saran Krishnasamy",
                "Joel Tetreault",
                "Alejandro Jaimes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00686v1",
                "http://arxiv.org/pdf/2311.00686v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00684v2",
            "title": "Attention Alignment and Flexible Positional Embeddings Improve\n  Transformer Length Extrapolation",
            "updated": "2023-11-15T15:55:02Z",
            "published": "2023-11-01T17:43:35Z",
            "summary": "An ideal length-extrapolatable Transformer language model can handle\nsequences longer than the training length without any fine-tuning. Such\nlong-context utilization capability relies heavily on a flexible positional\nembedding design. Upon investigating the flexibility of existing large\npre-trained Transformer language models, we find that the T5 family deserves a\ncloser look, as its positional embeddings capture rich and flexible attention\npatterns. However, T5 suffers from the dispersed attention issue: the longer\nthe input sequence, the flatter the attention distribution. To alleviate the\nissue, we propose two attention alignment strategies via temperature scaling.\nOur findings show improvement on the long-context utilization capability of T5\non language modeling, retrieval, multi-document question answering, and code\ncompletion tasks without any fine-tuning. This suggests that a flexible\npositional embedding design and attention alignment can go a long way toward\nTransformer length extrapolation.",
            "author": [
                "Ta-Chung Chi",
                "Ting-Han Fan",
                "Alexander I. Rudnicky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00684v2",
                "http://arxiv.org/pdf/2311.00684v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00682v1",
            "title": "Deep Learning-Based Classification of Gamma Photon Interactions in\n  Room-Temperature Semiconductor Radiation Detectors",
            "updated": "2023-11-01T17:42:56Z",
            "published": "2023-11-01T17:42:56Z",
            "summary": "Photon counting radiation detectors have become an integral part of medical\nimaging modalities such as Positron Emission Tomography or Computed Tomography.\nOne of the most promising detectors is the wide bandgap room temperature\nsemiconductor detectors, which depends on the interaction gamma/x-ray photons\nwith the detector material involves Compton scattering which leads to multiple\ninteraction photon events (MIPEs) of a single photon. For semiconductor\ndetectors like CdZnTeSe (CZTS), which have a high overlap of detected energies\nbetween Compton and photoelectric events, it is nearly impossible to\ndistinguish between Compton scattered events from photoelectric events using\nconventional readout electronics or signal processing algorithms. Herein, we\nreport a deep learning classifier CoPhNet that distinguishes between Compton\nscattering and photoelectric interactions of gamma/x-ray photons with CdZnTeSe\n(CZTS) semiconductor detectors. Our CoPhNet model was trained using simulated\ndata to resemble actual CZTS detector pulses and validated using both simulated\nand experimental data. These results demonstrated that our CoPhNet model can\nachieve high classification accuracy over the simulated test set. It also holds\nits performance robustness under operating parameter shifts such as\nSignal-Noise-Ratio (SNR) and incident energy. Our work thus laid solid\nfoundation for developing next-generation high energy gamma-rays detectors for\nbetter biomedical imaging.",
            "author": [
                "Sandeep K. Chaudhuri",
                "Qinyang Li",
                "Krishna C. Mandal",
                "Jianjun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00682v1",
                "http://arxiv.org/pdf/2311.00682v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00681v1",
            "title": "Are Large Language Models Reliable Judges? A Study on the Factuality\n  Evaluation Capabilities of LLMs",
            "updated": "2023-11-01T17:42:45Z",
            "published": "2023-11-01T17:42:45Z",
            "summary": "In recent years, Large Language Models (LLMs) have gained immense attention\ndue to their notable emergent capabilities, surpassing those seen in earlier\nlanguage models. A particularly intriguing application of LLMs is their role as\nevaluators for texts produced by various generative models.\n  In this study, we delve into the potential of LLMs as reliable assessors of\nfactual consistency in summaries generated by text-generation models.\nInitially, we introduce an innovative approach for factuality assessment using\nLLMs. This entails employing a singular LLM for the entirety of the\nquestion-answering-based factuality scoring process. Following this, we examine\nthe efficacy of various LLMs in direct factuality scoring, benchmarking them\nagainst traditional measures and human annotations.\n  Contrary to initial expectations, our results indicate a lack of significant\ncorrelations between factuality metrics and human evaluations, specifically for\nGPT-4 and PaLM-2. Notable correlations were only observed with GPT-3.5 across\ntwo factuality subcategories. These consistent findings across various factual\nerror categories suggest a fundamental limitation in the current LLMs'\ncapability to accurately gauge factuality.\n  This version presents the information more concisely while maintaining the\nmain points and findings of the original text.",
            "author": [
                "Xue-Yong Fu",
                "Md Tahmid Rahman Laskar",
                "Cheng Chen",
                "Shashi Bhushan TN"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00681v1",
                "http://arxiv.org/pdf/2311.00681v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00679v1",
            "title": "Components of curvature-squared invariants of minimal supergravity in\n  five dimensions",
            "updated": "2023-11-01T17:41:55Z",
            "published": "2023-11-01T17:41:55Z",
            "summary": "We present for the first time the component structure of the supersymmetric\ncompletions for all curvature-squared invariants of five-dimensional, off-shell\n(gauged) minimal supergravity, including all fermions. This is achieved by\nusing an interplay between superspace and superconformal tensor calculus\ntechniques, and by employing results from arXiv:1410.8682 and arXiv:2302.14295.\nOur analysis is based on using a standard Weyl multiplet of conformal\nsupergravity coupled to a vector and a linear multiplet compensator to engineer\noff-shell Poincar\\'e supergravity. We compute all the descendants of the\ncomposite linear multiplets that describe gauged supergravity together with the\nthree independent four-derivative invariants. These are the building blocks of\nthe locally superconformal invariant actions. A derivation of the primary\nequations of motion for minimal gauged off-shell supergravity deformed by an\narbitrary combination of these three locally superconformal invariants, is then\nprovided. Finally, all the covariant descendants in the multiplets of equations\nof motion are obtained by applying a series of $Q$-supersymmetry\ntransformations, equivalent to successively applying superspace spinor\nderivatives to the primary equations of motion.",
            "author": [
                "Gregory Gold",
                "Jessica Hutomo",
                "Saurish Khandelwal",
                "Gabriele Tartaglino-Mazzucchelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00679v1",
                "http://arxiv.org/pdf/2311.00679v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16131v1",
            "title": "Secure Arcade: A Gamified Defense Against Cyber Attacks",
            "updated": "2023-11-01T17:35:49Z",
            "published": "2023-11-01T17:35:49Z",
            "summary": "In modernity, we continually receive increasingly intricate technologies that\nallow us to increase our lives convenience and efficiency. Our technology,\nparticularly technology available over the internet, is advancing at\nunprecedented speed. However, this speed of advancement allows those behind\nmalicious attacks to have an increasingly easier time taking advantage of those\nwho know little about computer security. Unfortunately, education in the\ncomputer security field is generally limited only to tertiary education. This\nresearch addresses this problem through a gamified web-based application that\ndrives users to reach learning goals to help them become more vigilant internet\nusers: 1. Learn and memorize general computer security terminology, 2. Become\nfamiliar with basic cryptography concepts, 3. Learn to recognize potential\nphishing scams via email quickly, and 4. Learn common attacks on servers and\nhow to deal with them.",
            "author": [
                "Sean Loesch",
                "Ryan Hrastich",
                "Jordan Herbert",
                "Ben Drangstveit",
                "Jacob Weber",
                "Mounika Vanamala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16131v1",
                "http://arxiv.org/pdf/2311.16131v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00676v1",
            "title": "Last-Iterate Convergence Properties of Regret-Matching Algorithms in\n  Games",
            "updated": "2023-11-01T17:34:58Z",
            "published": "2023-11-01T17:34:58Z",
            "summary": "Algorithms based on regret matching, specifically regret matching$^+$\n(RM$^+$), and its variants are the most popular approaches for solving\nlarge-scale two-player zero-sum games in practice. Unlike algorithms such as\noptimistic gradient descent ascent, which have strong last-iterate and ergodic\nconvergence properties for zero-sum games, virtually nothing is known about the\nlast-iterate properties of regret-matching algorithms. Given the importance of\nlast-iterate convergence for numerical optimization reasons and relevance as\nmodeling real-word learning in games, in this paper, we study the last-iterate\nconvergence properties of various popular variants of RM$^+$. First, we show\nnumerically that several practical variants such as simultaneous RM$^+$,\nalternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate\nconvergence guarantees even on a simple $3\\times 3$ game. We then prove that\nrecent variants of these algorithms based on a smoothing technique do enjoy\nlast-iterate convergence: we prove that extragradient RM$^{+}$ and smooth\nPredictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate)\nand $1/\\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted\nvariants of these algorithms, and show that they enjoy linear-rate last-iterate\nconvergence.",
            "author": [
                "Yang Cai",
                "Gabriele Farina",
                "Julien Grand-Cl\u00e9ment",
                "Christian Kroer",
                "Chung-Wei Lee",
                "Haipeng Luo",
                "Weiqiang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00676v1",
                "http://arxiv.org/pdf/2311.00676v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00671v1",
            "title": "Emotion Detection for Misinformation: A Review",
            "updated": "2023-11-01T17:21:09Z",
            "published": "2023-11-01T17:21:09Z",
            "summary": "With the advent of social media, an increasing number of netizens are sharing\nand reading posts and news online. However, the huge volumes of misinformation\n(e.g., fake news and rumors) that flood the internet can adversely affect\npeople's lives, and have resulted in the emergence of rumor and fake news\ndetection as a hot research topic. The emotions and sentiments of netizens, as\nexpressed in social media posts and news, constitute important factors that can\nhelp to distinguish fake news from genuine news and to understand the spread of\nrumors. This article comprehensively reviews emotion-based methods for\nmisinformation detection. We begin by explaining the strong links between\nemotions and misinformation. We subsequently provide a detailed analysis of a\nrange of misinformation detection methods that employ a variety of emotion,\nsentiment and stance-based features, and describe their strengths and\nweaknesses. Finally, we discuss a number of ongoing challenges in emotion-based\nmisinformation detection based on large language models and suggest future\nresearch directions, including data collection (multi-platform, multilingual),\nannotation, benchmark, multimodality, and interpretability.",
            "author": [
                "Zhiwei Liu",
                "Tianlin Zhang",
                "Kailai Yang",
                "Paul Thompson",
                "Zeping Yu",
                "Sophia Ananiadou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00671v1",
                "http://arxiv.org/pdf/2311.00671v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00668v1",
            "title": "ProcSim: Proxy-based Confidence for Robust Similarity Learning",
            "updated": "2023-11-01T17:17:14Z",
            "published": "2023-11-01T17:17:14Z",
            "summary": "Deep Metric Learning (DML) methods aim at learning an embedding space in\nwhich distances are closely related to the inherent semantic similarity of the\ninputs. Previous studies have shown that popular benchmark datasets often\ncontain numerous wrong labels, and DML methods are susceptible to them.\nIntending to study the effect of realistic noise, we create an ontology of the\nclasses in a dataset and use it to simulate semantically coherent labeling\nmistakes. To train robust DML models, we propose ProcSim, a simple framework\nthat assigns a confidence score to each sample using the normalized distance to\nits class representative. The experimental results show that the proposed\nmethod achieves state-of-the-art performance on the DML benchmark datasets\ninjected with uniform and the proposed semantically coherent noise.",
            "author": [
                "Oriol Barbany",
                "Xiaofan Lin",
                "Muhammet Bastan",
                "Arnab Dhua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00668v1",
                "http://arxiv.org/pdf/2311.00668v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00667v1",
            "title": "Development and application of SEM/EDS in biological, biomedical &\n  nanotechnological research",
            "updated": "2023-11-01T17:14:52Z",
            "published": "2023-11-01T17:14:52Z",
            "summary": "This comprehensive review discusses the development of scanning electron\nmicroscopy and the application of this technology in different fields such as\nbiology, nanobiotechnology and biomedical science. Besides being a tool for\nhigh resolution imaging of surface or topography, the technology is coupled\nwith analytical techniques such as energy dispersive spectroscopy for elemental\nmapping. Since the commercialization of the technology, it has developed\nmanifold and currently very high-resolution nano scale imaging is possible by\nthis technology. The development of FIB-SEM has allowed three-dimensional\nimaging of materials while the development of cryostage allows imaging of\nhydrated biological samples. Though variable pressure or environmental SEM can\nbe used for imaging hydrated samples, they cannot capture a high-resolution\nimage. SBEM and ATUM-SEM has automated the sampling process while improved and\nmore powerful software along with user-friendly computer interface has made\nimage analysis faster and more reliable. This review presents one of the most\nwidely used analytical techniques used across the globe for scientific\ninvestigation. The power and potential of SEM is expanding with the development\nof accessory technology.",
            "author": [
                "Aniruddha Acharya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00667v1",
                "http://arxiv.org/pdf/2311.00667v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00666v2",
            "title": "Uconnect: Synergistic Spectral CT Reconstruction with U-Nets Connecting\n  the Energy bins",
            "updated": "2023-11-22T13:53:06Z",
            "published": "2023-11-01T17:14:09Z",
            "summary": "Spectral computed tomography (CT) offers the possibility to reconstruct\nattenuation images at different energy levels, which can be then used for\nmaterial decomposition. However, traditional methods reconstruct each energy\nbin individually and are vulnerable to noise. In this paper, we propose a novel\nsynergistic method for spectral CT reconstruction, namely Uconnect. It utilizes\ntrained convolutional neural networks (CNNs) to connect the energy bins to a\nlatent image so that the full binned data is used synergistically. We\nexperiment on two types of low-dose data: simulated and real patient data.\nQualitative and quantitative analysis show that our proposed Uconnect\noutperforms state-of-art model-based iterative reconstruction (MBIR) techniques\nas well as CNN-based denoising.",
            "author": [
                "Zhihan Wang",
                "Alexandre Bousse",
                "Franck Vermet",
                "Jacques Froment",
                "B\u00e9atrice Vedel",
                "Alessandro Perelli",
                "Jean-Pierre Tasu",
                "Dimitris Visvikis"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TRPMS.2023.3330045",
                "http://arxiv.org/abs/2311.00666v2",
                "http://arxiv.org/pdf/2311.00666v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00664v1",
            "title": "Latent Space Translation via Semantic Alignment",
            "updated": "2023-11-01T17:12:00Z",
            "published": "2023-11-01T17:12:00Z",
            "summary": "While different neural models often exhibit latent spaces that are alike when\nexposed to semantically related data, this intrinsic similarity is not always\nimmediately discernible. Towards a better understanding of this phenomenon, our\nwork shows how representations learned from these neural modules can be\ntranslated between different pre-trained networks via simpler transformations\nthan previously thought. An advantage of this approach is the ability to\nestimate these transformations using standard, well-understood algebraic\nprocedures that have closed-form solutions. Our method directly estimates a\ntransformation between two given latent spaces, thereby enabling effective\nstitching of encoders and decoders without additional training. We extensively\nvalidate the adaptability of this translation procedure in different\nexperimental settings: across various trainings, domains, architectures (e.g.,\nResNet, CNN, ViT), and in multiple downstream tasks (classification,\nreconstruction). Notably, we show how it is possible to zero-shot stitch text\nencoders and vision decoders, or vice-versa, yielding surprisingly good\nclassification performance in this multimodal setting.",
            "author": [
                "Valentino Maiorca",
                "Luca Moschella",
                "Antonio Norelli",
                "Marco Fumero",
                "Francesco Locatello",
                "Emanuele Rodol\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00664v1",
                "http://arxiv.org/pdf/2311.00664v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00663v1",
            "title": "Variational Gaussian Processes For Linear Inverse Problems",
            "updated": "2023-11-01T17:10:38Z",
            "published": "2023-11-01T17:10:38Z",
            "summary": "By now Bayesian methods are routinely used in practice for solving inverse\nproblems. In inverse problems the parameter or signal of interest is observed\nonly indirectly, as an image of a given map, and the observations are typically\nfurther corrupted with noise. Bayes offers a natural way to regularize these\nproblems via the prior distribution and provides a probabilistic solution,\nquantifying the remaining uncertainty in the problem. However, the\ncomputational costs of standard, sampling based Bayesian approaches can be\noverly large in such complex models. Therefore, in practice variational Bayes\nis becoming increasingly popular. Nevertheless, the theoretical understanding\nof these methods is still relatively limited, especially in context of inverse\nproblems. In our analysis we investigate variational Bayesian methods for\nGaussian process priors to solve linear inverse problems. We consider both\nmildly and severely ill-posed inverse problems and work with the popular\ninducing variables variational Bayes approach proposed by Titsias in 2009. We\nderive posterior contraction rates for the variational posterior in general\nsettings and show that the minimax estimation rate can be attained by correctly\ntunned procedures. As specific examples we consider a collection of inverse\nproblems including the heat equation, Volterra operator and Radon transform and\ninducing variable methods based on population and empirical spectral features.",
            "author": [
                "Thibault Randrianarisoa",
                "Botond Szabo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00663v1",
                "http://arxiv.org/pdf/2311.00663v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH",
                "62G08"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00660v3",
            "title": "TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining\n  and Object Detection in Rain",
            "updated": "2023-11-08T02:46:34Z",
            "published": "2023-11-01T17:08:26Z",
            "summary": "Rain generation algorithms have the potential to improve the generalization\nof deraining methods and scene understanding in rainy conditions. However, in\npractice, they produce artifacts and distortions and struggle to control the\namount of rain generated due to a lack of proper constraints. In this paper, we\npropose an unpaired image-to-image translation framework for generating\nrealistic rainy images. We first introduce a Triangular Probability Similarity\n(TPS) constraint to guide the generated images toward clear and rainy images in\nthe discriminator manifold, thereby minimizing artifacts and distortions during\nrain generation. Unlike conventional contrastive learning approaches, which\nindiscriminately push negative samples away from the anchors, we propose a\nSemantic Noise Contrastive Estimation (SeNCE) strategy and reassess the pushing\nforce of negative samples based on the semantic similarity between the clear\nand the rainy images and the feature similarity between the anchor and the\nnegative samples. Experiments demonstrate realistic rain generation with\nminimal artifacts and distortions, which benefits image deraining and object\ndetection in rain. Furthermore, the method can be used to generate realistic\nsnowy and night images, underscoring its potential for broader applicability.\nCode is available at https://github.com/ShenZheng2000/TPSeNCE.",
            "author": [
                "Shen Zheng",
                "Changjie Lu",
                "Srinivasa G. Narasimhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00660v3",
                "http://arxiv.org/pdf/2311.00660v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00658v1",
            "title": "Explicit Morphological Knowledge Improves Pre-training of Language\n  Models for Hebrew",
            "updated": "2023-11-01T17:02:49Z",
            "published": "2023-11-01T17:02:49Z",
            "summary": "Pre-trained language models (PLMs) have shown remarkable successes in\nacquiring a wide range of linguistic knowledge, relying solely on\nself-supervised training on text streams. Nevertheless, the effectiveness of\nthis language-agnostic approach has been frequently questioned for its\nsub-optimal performance when applied to morphologically-rich languages (MRLs).\nWe investigate the hypothesis that incorporating explicit morphological\nknowledge in the pre-training phase can improve the performance of PLMs for\nMRLs. We propose various morphologically driven tokenization methods enabling\nthe model to leverage morphological cues beyond raw text. We pre-train multiple\nlanguage models utilizing the different methods and evaluate them on Hebrew, a\nlanguage with complex and highly ambiguous morphology. Our experiments show\nthat morphologically driven tokenization demonstrates improved results compared\nto a standard language-agnostic tokenization, on a benchmark of both semantic\nand morphologic tasks. These findings suggest that incorporating morphological\nknowledge holds the potential for further improving PLMs for morphologically\nrich languages.",
            "author": [
                "Eylon Gueta",
                "Omer Goldman",
                "Reut Tsarfaty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00658v1",
                "http://arxiv.org/pdf/2311.00658v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00654v1",
            "title": "Form Factors of the Tricritical Three-state Potts Model in its Scaling\n  Limit",
            "updated": "2023-11-01T17:00:01Z",
            "published": "2023-11-01T17:00:01Z",
            "summary": "We compute the form factors of the order and disorder operators, together\nwith those of the stress-energy tensor, of the two-dimensional three-state\nPotts model with vacancies along its thermal deformation of the critical point.\nAt criticality the model is described by the non-diagonal partition function of\nthe unitary minimal model $\\mathcal{M}_{6,7}$ of conformal field theories and\nis accompanied by an internal $S_3$ symmetry. Its off-critical thermal\ndeformation is an integrable massive theory which is still invariant under\n$S_3$. The presence of infinitely many conserved quantities, whose spin\nspectrum is related to the exceptional Lie algebra $E_6$, allows us to\ndetermine the analytic $S$-matrix, the exact mass spectrum and the matrix\nelements of local operators of this model in an exact non-perturbative way. We\nuse the spectral representation series of the correlators and the fast\nconvergence of these series to compute several universal ratios of the\nRenormalization Group.",
            "author": [
                "Giuseppe Mussardo",
                "Marco Panero",
                "Andrea Stampiggi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00654v1",
                "http://arxiv.org/pdf/2311.00654v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.stat-mech",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00644v1",
            "title": "The first-order factorizable contributions to the three-loop massive\n  operator matrix elements $A_{Qg}^{(3)}$ and $\u0394A_{Qg}^{(3)}$",
            "updated": "2023-11-01T16:45:50Z",
            "published": "2023-11-01T16:45:50Z",
            "summary": "The unpolarized and polarized massive operator matrix elements $A_{Qg}^{(3)}$\nand $\\Delta A_{Qg}^{(3)}$ contain first-order factorizable and non-first-order\nfactorizable contributions in the determining difference or differential\nequations of their master integrals. We compute their first-order factorizable\ncontributions in the single heavy mass case for all contributing Feynman\ndiagrams. Moreover, we present the complete color-$\\zeta$ factors for the cases\nin which also non-first-order factorizable contributions emerge in the master\nintegrals, but cancel in the final result as found by using the method of\narbitrary high Mellin moments. Individual contributions depend also on\ngeneralized harmonic sums and on nested finite binomial and inverse binomial\nsums in Mellin $N$-space, and correspondingly, on Kummer-Poincar\\'e and\nsquare-root valued alphabets in Bjorken-$x$ space. We present a complete\ndiscussion of the possibilities of solving the present problem in $N$-space\nanalytically and we also discuss the limitations in the present case to\nanalytically continue the given $N$-space expressions to $N \\in \\mathbb{C}$ by\nstrict methods. The representation through generating functions allows a well\nsynchronized representation of the first-order factorizable results over a\n17-letter alphabet. We finally obtain representations in terms of iterated\nintegrals over the corresponding alphabet in $x$-space, also containing up to\nweight {\\sf w = 5} special constants, which can be rationalized to\nKummer-Poincar\\'e iterated integrals at special arguments. The analytic\n$x$-space representation requires separate analyses for the intervals $x \\in\n[0,1/4], [1/4,1/2], [1/2,1]$ and $x > 1$. We also derive the small and large\n$x$ limits of the first-order factorizable contributions.",
            "author": [
                "J. Ablinger",
                "A. Behring",
                "J. Bl\u00fcmlein",
                "A. De Freitas",
                "A. von Manteuffel",
                "C. Schneider",
                "K. Sch\u00f6nwald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00644v1",
                "http://arxiv.org/pdf/2311.00644v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06285v1",
            "title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and\n  Audio",
            "updated": "2023-11-01T16:40:35Z",
            "published": "2023-11-01T16:40:35Z",
            "summary": "While 3D human body modeling has received much attention in computer vision,\nmodeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by\nbody motion and speech, has fallen short in the community. To close this gap,\nwe present a model that can generate accurate 3D spatial audio for full human\nbodies. The system consumes, as input, audio signals from headset microphones\nand body pose, and produces, as output, a 3D sound field surrounding the\ntransmitter's body, from which spatial audio can be rendered at any arbitrary\nposition in the 3D space. We collect a first-of-its-kind multimodal dataset of\nhuman bodies, recorded with multiple cameras and a spherical array of 345\nmicrophones. In an empirical evaluation, we demonstrate that our model can\nproduce accurate body-induced sound fields when trained with a suitable loss.\nDataset and code are available online.",
            "author": [
                "Xudong Xu",
                "Dejan Markovic",
                "Jacob Sandakly",
                "Todd Keebler",
                "Steven Krenn",
                "Alexander Richard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06285v1",
                "http://arxiv.org/pdf/2311.06285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00639v1",
            "title": "Sparsity independent Lyapunov exponent in the Sachdev-Ye-Kitaev model",
            "updated": "2023-11-01T16:38:34Z",
            "published": "2023-11-01T16:38:34Z",
            "summary": "The saturation of a recently proposed universal bound on the Lyapunov\nexponent has been conjectured to signal the existence of a gravity dual. This\nsaturation occurs in the low temperature limit of the dense Sachdev-Ye-Kitaev\n(SYK) model, $N$ Majorana fermions with $q$-body ($q>2$) infinite-range\ninteractions. We calculate certain Out of Time Order Correlators (OTOC) for\n$N\\le 64$ fermions for a highly sparse SYK model and find no significant\ndependence of the Lyapunov exponent on sparsity up to near the percolation\nlimit where the Hamiltonian breaks up into blocks. This suggests that in the\nsparse case, the Lyapunov exponent also saturates the low-temperature bound. A\nkey ingredient to reaching $N = 64$ is the development of a novel quantum spin\nmodel simulation library that implements highly-optimized matrix-free Krylov\nsubspace methods on Graphical Processing Units (GPUs). This leads to a\nsignificantly lower simulation time as well as vastly reduced memory usage over\nprevious approaches, while using modest computational resources. Strong\nsparsity-driven statistical fluctuations require both the use of a vastly\nlarger number of disorder realizations with respect to the dense limit and a\ncareful finite size scaling analysis. Our results potentially broadens the\nlandscape of theories that may have a gravity analogue.",
            "author": [
                "Antonio M. Garc\u00eda-Garc\u00eda",
                "Chang Liu",
                "Jacobus J. M. Verbaarschot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00639v1",
                "http://arxiv.org/pdf/2311.00639v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.dis-nn",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00637v2",
            "title": "Analysis of the Single Reference Coupled Cluster Method for Electronic\n  Structure Calculations: The Discrete Coupled Cluster Equations",
            "updated": "2023-11-26T19:59:35Z",
            "published": "2023-11-01T16:37:32Z",
            "summary": "Coupled cluster methods are widely regarded as the gold standard of\ncomputational quantum chemistry as they are perceived to offer the best\ncompromise between computational cost and a high-accuracy resolution of the\nground state eigenvalue of the electronic Hamiltonian -- an unbounded,\nself-adjoint operator acting on a Hilbert space of antisymmetric functions that\ndescribes electronic properties of molecular systems. The present contribution\nis the second in a series of two articles where we introduce a new numerical\nanalysis of the single-reference coupled cluster method based on the\ninvertibility of coupled cluster Fr\\'echet derivative. In this contribution, we\nstudy discretisations of the single-reference coupled cluster equations based\non a prior mean-field (Hartree-Fock) calculation. We show that under some\nstructural assumptions on the associated discretisation spaces and assuming\nthat the discretisation is fine enough, the discrete coupled cluster equations\nare locally well-posed, and we derive a priori and residual-based a posteriori\nerror estimates for the discrete coupled cluster solutions. Preliminary\nnumerical experiments indicate that the structural assumptions that we impose\nfor our analysis can be expected to hold for several small molecules and the\ntheoretical constants that appear in our error estimates are an improvement\nover those obtained from earlier approaches.",
            "author": [
                "Muhammad Hassan",
                "Yvon Maday",
                "Yipeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00637v2",
                "http://arxiv.org/pdf/2311.00637v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N25, 65N30, 65Z05, 81V55, 81V70"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00636v1",
            "title": "Kronecker-Factored Approximate Curvature for Modern Neural Network\n  Architectures",
            "updated": "2023-11-01T16:37:00Z",
            "published": "2023-11-01T16:37:00Z",
            "summary": "The core components of many modern neural network architectures, such as\ntransformers, convolutional, or graph neural networks, can be expressed as\nlinear layers with $\\textit{weight-sharing}$. Kronecker-Factored Approximate\nCurvature (K-FAC), a second-order optimisation method, has shown promise to\nspeed up neural network training and thereby reduce computational costs.\nHowever, there is currently no framework to apply it to generic architectures,\nspecifically ones with linear weight-sharing layers. In this work, we identify\ntwo different settings of linear weight-sharing layers which motivate two\nflavours of K-FAC -- $\\textit{expand}$ and $\\textit{reduce}$. We show that they\nare exact for deep linear networks with weight-sharing in their respective\nsetting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we\nleverage to speed up automatic hyperparameter selection via optimising the\nmarginal likelihood for a Wide ResNet. Finally, we observe little difference\nbetween these two K-FAC variations when using them to train both a graph neural\nnetwork and a vision transformer. However, both variations are able to reach a\nfixed validation metric target in $50$-$75\\%$ of the number of steps of a\nfirst-order reference run, which translates into a comparable improvement in\nwall-clock time. This highlights the potential of applying K-FAC to modern\nneural network architectures.",
            "author": [
                "Runa Eschenhagen",
                "Alexander Immer",
                "Richard E. Turner",
                "Frank Schneider",
                "Philipp Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00636v1",
                "http://arxiv.org/pdf/2311.00636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00633v1",
            "title": "Ab initio machine-learning unveils strong anharmonicity in non-Arrhenius\n  self-diffusion of tungsten",
            "updated": "2023-11-01T16:31:01Z",
            "published": "2023-11-01T16:31:01Z",
            "summary": "We propose an efficient ab initio framework to compute the Gibbs energy of\nthe transition state in vacancy-mediated diffusion including the relevant\nthermal excitations at density-functional-theory level. With the aid of a\nbespoke machine-learning interatomic potential, the temperature-dependent\nvacancy formation and migration Gibbs energies of the prototype system bcc\ntungsten are shown to be strongly affected by anharmonicity. This explains the\nphysical origin of the experimentally observed non-Arrhenius behavior of W\nself-diffusion as a case study. The good agreement of the self-diffusivity with\nexperiment demonstrates that accurate ab initio diffusion databases are in\nreach.",
            "author": [
                "Xi Zhang",
                "Sergiy V. Divinski",
                "Blazej Grabowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00633v1",
                "http://arxiv.org/pdf/2311.00633v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00630v2",
            "title": "Nonequilibrium Green's Function simulation of Cu2O photocathodes for\n  photoelectrochemical hydrogen production",
            "updated": "2023-11-03T16:21:06Z",
            "published": "2023-11-01T16:29:39Z",
            "summary": "In this work we present a simulation of the semiconductor electrodes of\nphotoelectrochemical (PEC) water splitting cells based on the nonequilibrium\nGreen's function (NEGF) formalism. While the performance of simple PEC cells\ncan be adequately explained with semi-classical drift-diffusion theory, the\nincreasing interest towards thin film cells and nanostructures in general\nrequires theoretical treatment that can capture the quantum phenomena\ninfluencing the charge carrier dynamics in these devices. Specifically, we\nstudy a p-type Cu2O electrode and examine the influence of the bias voltage,\nreaction kinetics and the thickness of the Cu2O layer on the generated\nphotocurrent. The NEGF equations are solved in a self-consistent manner with\nthe electrostatic potential from Poisson's equation, sunlight induced photon\nscattering and the chemical overpotential required to drive the water splitting\nreaction. We show that the NEGF simulation accurately reproduces experimental\nresults from both voltammetry and impedance spectroscopy measurements, while\nproviding an energy resolved solution of the charge carrier densities and\ncorresponding currents inside the semiconductor electrode at nanoscale.",
            "author": [
                "Lassi H\u00e4llstr\u00f6m",
                "Ilkka Tittonen"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevApplied.20.054003",
                "http://arxiv.org/abs/2311.00630v2",
                "http://arxiv.org/pdf/2311.00630v2"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.chem-ph",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00629v1",
            "title": "Formal Translation from Reversing Petri Nets to Coloured Petri Nets",
            "updated": "2023-11-01T16:28:38Z",
            "published": "2023-11-01T16:28:38Z",
            "summary": "Reversible computation is an emerging computing paradigm that allows any\nsequence of operations to be executed in reverse order at any point during\ncomputation. Its appeal lies in its potential for lowpower computation and its\nrelevance to a wide array of applications such as chemical reactions, quantum\ncomputation, robotics, and distributed systems. Reversing Petri nets are a\nrecently-proposed extension of Petri nets that implements the three main forms\nof reversibility, namely, backtracking, causal reversing, and\nout-of-causal-order reversing. Their distinguishing feature is the use of named\ntokens that can be combined together to form bonds. Named tokens along with a\nhistory function, constitute the means of remembering past behaviour, thus,\nenabling reversal. In recent work, we have proposed a structural translation\nfrom a subclass of RPNs to the model of Coloured Petri Nets (CPNs), an\nextension of traditional Petri nets where tokens carry data values. In this\npaper, we extend the translation to handle RPNs with token multiplicity under\nthe individual-token interpretation, a model which allows multiple tokens of\nthe same type to exist in a system. To support the three types of\nreversibility, tokens are associated with their causal history and, while\ntokens of the same type are equally eligible to fire a transition when going\nforward, when going backwards they are able to reverse only the transitions\nthey have previously fired. The new translation, in addition to lifting the\nrestriction on token uniqueness, presents a refined approach for transforming\nRPNs to CPNs through a unifying approach that allows instantiating each of the\nthree types of reversibility. The paper also reports on a tool that implements\nthis translation, paving the way for automated translations and analysis of\nreversible systems using CPN Tools.",
            "author": [
                "Kamila Barylska",
                "Anna Gogolinska",
                "Lukasz Mikulski",
                "Anna Philippou",
                "Marcin Piatkowski",
                "Kyriaki Psara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00629v1",
                "http://arxiv.org/pdf/2311.00629v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CL",
                "03",
                "F.2; G.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00626v1",
            "title": "nvblox: GPU-Accelerated Incremental Signed Distance Field Mapping",
            "updated": "2023-11-01T16:23:59Z",
            "published": "2023-11-01T16:23:59Z",
            "summary": "Dense, volumetric maps are essential for safe robot navigation through\ncluttered spaces, as well as interaction with the environment. For latency and\nrobustness, it is best if these can be computed on-board on\ncomputationally-constrained hardware from camera or LiDAR-based sensors.\nPrevious works leave a gap between CPU-based systems for robotic mapping, which\ndue to computation constraints limit map resolution or scale, and GPU-based\nreconstruction systems which omit features that are critical to robotic path\nplanning. We introduce a library, nvblox, that aims to fill this gap, by\nGPU-accelerating robotic volumetric mapping, and which is optimized for\nembedded GPUs. nvblox delivers a significant performance improvement over the\nstate of the art, achieving up to a 177x speed-up in surface reconstruction,\nand up to a 31x improvement in distance field computation, and is available\nopen-source.",
            "author": [
                "Alexander Millane",
                "Helen Oleynikova",
                "Emilie Wirbel",
                "Remo Steiner",
                "Vikram Ramasamy",
                "David Tingdahl",
                "Roland Siegwart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00626v1",
                "http://arxiv.org/pdf/2311.00626v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00621v1",
            "title": "Revisited nuclear magnetic dipole and electric quadrupole moments of\n  polonium isotopes",
            "updated": "2023-11-01T16:15:02Z",
            "published": "2023-11-01T16:15:02Z",
            "summary": "We revisited the electronic structure parameters used to interpret the\nhyperfine structure of neutral polonium. We used a computational scheme that\ntreats relativistic and high-order electronic correlation effects within the\ncoupled cluster with single, double, triple and perturbative quadruple\nexcitations CCSDT(Q) method, as well as estimate the contribution of quantum\nelectrodynamics and finite nuclear size effects. A systematic study of the\nuncertainty is carried out. This allowed us to obtain significantly refined\nvalues for the nuclear magnetic dipole and electric quadrupole moments of a\nwide range of odd-mass polonium isotopes. For $^{205}$Po and $^{207}$Po we\nextracted both the magnetic moment and the nuclear magnetization distribution\nparameter in a nuclear model-independent way. To assess the accuracy of the\ncalculations, we also computed the ionization potential (IP), excitation\nenergies (EE) of the $6p^4~{}^1D_2$ and $6p^3 7s^1~{}^5S_2$ electronic states\nand the electronic $g_J$ factor in the same theoretical framework. A good\nagreement of the theory and experiment for IP, EEs and $g_J$ confirms the\nreliability of the computational scheme and uncertainty estimation for the Po\nelectromagnetic moments. We identify the $6p^4~{}^1D_2$ electronic level as a\npotentially promising state for further studies of the nuclear moments of\npolonium isotopes.",
            "author": [
                "Leonid V. Skripnikov",
                "Anatoly E. Barzakh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00621v1",
                "http://arxiv.org/pdf/2311.00621v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph",
                "nucl-th",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00618v1",
            "title": "De-Diffusion Makes Text a Strong Cross-Modal Interface",
            "updated": "2023-11-01T16:12:40Z",
            "published": "2023-11-01T16:12:40Z",
            "summary": "We demonstrate text as a strong cross-modal interface. Rather than relying on\ndeep embeddings to connect image and language as the interface representation,\nour approach represents an image as text, from which we enjoy the\ninterpretability and flexibility inherent to natural language. We employ an\nautoencoder that uses a pre-trained text-to-image diffusion model for decoding.\nThe encoder is trained to transform an input image into text, which is then fed\ninto the fixed text-to-image diffusion decoder to reconstruct the original\ninput -- a process we term De-Diffusion. Experiments validate both the\nprecision and comprehensiveness of De-Diffusion text representing images, such\nthat it can be readily ingested by off-the-shelf text-to-image tools and LLMs\nfor diverse multi-modal tasks. For example, a single De-Diffusion model can\ngeneralize to provide transferable prompts for different text-to-image tools,\nand also achieves a new state of the art on open-ended vision-language tasks by\nsimply prompting large language models with few-shot examples.",
            "author": [
                "Chen Wei",
                "Chenxi Liu",
                "Siyuan Qiao",
                "Zhishuai Zhang",
                "Alan Yuille",
                "Jiahui Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00618v1",
                "http://arxiv.org/pdf/2311.00618v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00611v2",
            "title": "Adaptive Threshold Selection for Set Membership State Estimation with\n  Quantized Measurements",
            "updated": "2023-12-04T09:58:06Z",
            "published": "2023-11-01T16:01:00Z",
            "summary": "State estimation for discrete-time linear systems with quantized measurements\nis addressed. By exploiting the set-theoretic nature of the information\nprovided by the quantizer, the problem is cast in the set membership estimation\nsetting. Motivated by the possibility of suitably tuning the quantizer\nthresholds in sensor networks, the optimal design of adaptive quantizers is\nformulated in terms of the minimization of the radius of information associated\nto the state estimation problem. The optimal solution is derived for\nfirst-order systems and the result is exploited to design adaptive quantizers\nfor generic systems, minimizing the size of the feasible output signal set.\nThen, the minimum number of sensor thresholds for which the adaptive quantizers\nguarantee asymptotic boundedness of the state estimation uncertainty is\nestablished. Threshold adaptation mechanisms based on several types of outer\napproximations of the feasible state set are also proposed. The effectiveness\nof the designed adaptive quantizers is demonstrated on numerical tests\ninvolving a specific case study and randomly generated systems, highlighting\nthe trade off between the resulting estimation uncertainty and the\ncomputational burden required by recursive set approximations.",
            "author": [
                "Marco Casini",
                "Andrea Garulli",
                "Antonio Vicino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00611v2",
                "http://arxiv.org/pdf/2311.00611v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00604v1",
            "title": "A Systematic Review of Approximability Results for Traveling Salesman\n  Problems leveraging the TSP-T3CO Definition Scheme",
            "updated": "2023-11-01T15:53:17Z",
            "published": "2023-11-01T15:53:17Z",
            "summary": "The traveling salesman (or salesperson) problem, short TSP, is a problem of\nstrong interest to many researchers from mathematics, economics, and computer\nscience. Manifold TSP variants occur in nearly every scientific field and\napplication domain: engineering, physics, biology, life sciences, and\nmanufacturing just to name a few. Several thousand papers are published on\ntheoretical research or application-oriented results each year. This paper\nprovides the first systematic survey on the best currently known\napproximability and inapproximability results for well-known TSP variants such\nas the \"standard\" TSP, Path TSP, Bottleneck TSP, Maximum Scatter TSP,\nGeneralized TSP, Clustered TSP, Traveling Purchaser Problem, Profitable Tour\nProblem, Quota TSP, Prize-Collecting TSP, Orienteering Problem, Time-dependent\nTSP, TSP with Time Windows, and the Orienteering Problem with Time Windows. The\nfoundation of our survey is the definition scheme T3CO, which we propose as a\nuniform, easy-to-use and extensible means for the formal and precise definition\nof TSP variants. Applying T3CO to formally define the variant studied by a\npaper reveals subtle differences within the same named variant and also brings\nout the differences between the variants more clearly. We achieve the first\ncomprehensive, concise, and compact representation of approximability results\nby using T3CO definitions. This makes it easier to understand the\napproximability landscape and the assumptions under which certain results hold.\nOpen gaps become more evident and results can be compared more easily.",
            "author": [
                "Sophia Saller",
                "Jana Koehler",
                "Andreas Karrenbauer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00604v1",
                "http://arxiv.org/pdf/2311.00604v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00603v1",
            "title": "Occluded Person Re-Identification with Deep Learning: A Survey and\n  Perspectives",
            "updated": "2023-11-01T15:52:51Z",
            "published": "2023-11-01T15:52:51Z",
            "summary": "Person re-identification (Re-ID) technology plays an increasingly crucial\nrole in intelligent surveillance systems. Widespread occlusion significantly\nimpacts the performance of person Re-ID. Occluded person Re-ID refers to a\npedestrian matching method that deals with challenges such as pedestrian\ninformation loss, noise interference, and perspective misalignment. It has\ngarnered extensive attention from researchers. Over the past few years, several\nocclusion-solving person Re-ID methods have been proposed, tackling various\nsub-problems arising from occlusion. However, there is a lack of comprehensive\nstudies that compare, summarize, and evaluate the potential of occluded person\nRe-ID methods in detail. In this review, we start by providing a detailed\noverview of the datasets and evaluation scheme used for occluded person Re-ID.\nNext, we scientifically classify and analyze existing deep learning-based\noccluded person Re-ID methods from various perspectives, summarizing them\nconcisely. Furthermore, we conduct a systematic comparison among these methods,\nidentify the state-of-the-art approaches, and present an outlook on the future\ndevelopment of occluded person Re-ID.",
            "author": [
                "Enhao Ning",
                "Changshuo Wang",
                "Huang Zhangc",
                "Xin Ning",
                "Prayag Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00603v1",
                "http://arxiv.org/pdf/2311.00603v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00602v1",
            "title": "2D high temperature superconductor integration in contact printed\n  circuit boards",
            "updated": "2023-11-01T15:51:28Z",
            "published": "2023-11-01T15:51:28Z",
            "summary": "Inherent properties of superconducting Bi2Sr2CaCu2O8+x films, such as the\nhigh superconducting transition temperature Tc, efficient Josephson coupling\nbetween neighboring CuO layers, and fast quasiparticle relaxation dynamics,\nmake them a promising platform for advances in quantum computing and\ncommunication technologies. However, preserving two-dimensional\nsuperconductivity during device fabrication is an outstanding experimental\nchallenge because of the fast degradation of the superconducting properties of\ntwo-dimensional flakes when they are exposed to moisture, organic sol vents,\nand heat. Here, to realize superconducting devices utilizing two-dimensional\nsuperconducting films, we develop a novel fabrication technique relying on the\ncryogenic dry transfer of printable circuits embedded into a silicon nitride\nmembrane. This approach separates the circuit fabrication stage requiring\nchemically reactive substances and ionizing physical processes from the\ncreation of the thin superconducting structures. Apart from providing\nelectrical contacts in a single transfer step, the membrane encapsulates the\nsurface of the crystal shielding it from the environment. The fabricated\natomically thin Bi2Sr2CaCu2O8+x-based devices show high superconducting\ntransition temperature Tc ~ 91 K close to that of the bulk crystal and\ndemonstrate stable super conducting properties",
            "author": [
                "Christian N. Saggau",
                "Sanaz Shokri",
                "Mickey Martini",
                "Tommaso Confalone",
                "Yejin Lee",
                "Daniel Wolf",
                "Genda Gu",
                "Valentina Brosco",
                "Domenico Montemurro",
                "Valerii M. Vinokur",
                "Kornelius Nielsch",
                "Nicola Poccia"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acsami.3c10564",
                "http://arxiv.org/abs/2311.00602v1",
                "http://arxiv.org/pdf/2311.00602v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00599v1",
            "title": "Structure Learning with Adaptive Random Neighborhood Informed MCMC",
            "updated": "2023-11-01T15:47:18Z",
            "published": "2023-11-01T15:47:18Z",
            "summary": "In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a\nfully-Bayesian approach to the problem of structure learning under\nobservational data. Under the assumption of causal sufficiency, the algorithm\nallows for approximate sampling directly from the posterior distribution on\nDirected Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs\nvia locally informed, adaptive random neighborhood proposal that results in\nbetter mixing properties. In addition, to ensure better scalability with the\nnumber of nodes, we couple PARNI-DAG with a pre-tuning procedure of the\nsampler's parameters that exploits a skeleton graph derived through some\nconstraint-based or scoring-based algorithms. Thanks to these novel features,\nPARNI-DAG quickly converges to high-probability regions and is less likely to\nget stuck in local modes in the presence of high correlation between nodes in\nhigh-dimensional settings. After introducing the technical novelties in\nPARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in\nlearning DAG structures on a variety of experiments.",
            "author": [
                "Alberto Caron",
                "Xitong Liang",
                "Samuel Livingstone",
                "Jim Griffin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00599v1",
                "http://arxiv.org/pdf/2311.00599v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00598v1",
            "title": "A quick algorithm to compute an approximated power spectral density from\n  an arbitrary Allan deviation",
            "updated": "2023-11-01T15:46:25Z",
            "published": "2023-11-01T15:46:25Z",
            "summary": "Complex architectures for wireless communications, digital electronics and\nspace-based navigation interlink several oscillator-based devices such as\nclocks, transponders and synthesizers. Estimators characterizing their\nstability are critical for addressing the impact of random fluctuations (noise)\non the overall system performance. Manufacturers typically specify this as an\nAllan/Hadamard Variance (AVAR/HVAR) profile in the _integration_ time domain,\nyet, stochastic processes governing the noise take place in the _Fourier_\nfrequency domain in the shape of a Power Spectral Density (PSD) function. Both\nare second-moment measures of the time series, however, it is only possible to\ntranslate unambiguously from the PSD to the AVAR/HVAR, not vice versa, except\nin the case of a single noise type, which is severely limiting in real-life\napplications. This note elaborates an analytical method to generate an\napproximated PSD expressed as a set of power-laws defined in specific intervals\nin the frequency domain, starting from an AVAR/HVAR expressed a set of\npower-laws in the time domain. The proposed algorithm is straightforward to\nimplement, applicable to all noise types (and combinations thereof) and can be\nself-validated by reconstructing the corresponding AVAR/HVAR by direct\ncalculus. We also report on its limitations of and analytical expressions of\nthe continuous version of this algorithm. Coupling with well-established\nalgorithms relying on the PSD for power-law noise generation, the ensuing\nmethod encompasses the capability for generating multi-colored noise in\nend-to-end simulations, as demonstrated hereby for NASA's Deep Space Atomic\nClock.",
            "author": [
                "Fabrizio De Marchi",
                "Michael K. Plumaris",
                "Eric A. Burt",
                "Luciano Iess"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00598v1",
                "http://arxiv.org/pdf/2311.00598v1"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00596v1",
            "title": "Evaluating Binary Outcome Classifiers Estimated from Survey Data",
            "updated": "2023-11-01T15:41:48Z",
            "published": "2023-11-01T15:41:48Z",
            "summary": "Surveys are commonly used to facilitate research in epidemiology, health, and\nthe social and behavioral sciences. Often, these surveys are not simple random\nsamples, and respondents are given weights reflecting their probability of\nselection into the survey. It is well known that analysts can use these survey\nweights to produce unbiased estimates of population quantities like totals. In\nthis article, we show that survey weights also can be beneficial for evaluating\nthe quality of predictive models when splitting data into training and test\nsets. In particular, we characterize model assessment statistics, such as\nsensitivity and specificity, as finite population quantities, and compute\nsurvey-weighted estimates of these quantities with sample test data comprising\na random subset of the original data.Using simulations with data from the\nNational Survey on Drug Use and Health and the National Comorbidity Survey, we\nshow that unweighted metrics estimated with sample test data can misrepresent\npopulation performance, but weighted metrics appropriately adjust for the\ncomplex sampling design. We also show that this conclusion holds for models\ntrained using upsampling for mitigating class imbalance. The results suggest\nthat weighted metrics should be used when evaluating performance on sample test\ndata.",
            "author": [
                "Adway S. Wadekar",
                "Jerome P. Reiter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00596v1",
                "http://arxiv.org/pdf/2311.00596v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00595v2",
            "title": "Graph-based mutually exciting point processes for modelling event times\n  in docked bike-sharing systems",
            "updated": "2023-11-02T22:21:59Z",
            "published": "2023-11-01T15:40:30Z",
            "summary": "This paper introduces graph-based mutually exciting processes (GB-MEP) to\nmodel event times in network point processes, focusing on an application to\ndocked bike-sharing systems. GB-MEP incorporates known relationships between\nnodes in a graph within the intensity function of a node-based multivariate\nHawkes process. This approach reduces the number of parameters to a quantity\nproportional to the number of nodes in the network, resulting in significant\nadvantages for computational scalability when compared to traditional methods.\nThe model is applied on event data observed on the Santander Cycles network in\ncentral London, demonstrating that exploiting network-wide information related\nto geographical location of the stations is beneficial to improve the\nperformance of node-based models for applications in bike-sharing systems. The\nproposed GB-MEP framework is more generally applicable to any network point\nprocess where a distance function between nodes is available, demonstrating\nwider applicability.",
            "author": [
                "Francesco Sanna Passino",
                "Yining Che",
                "Carlos Cardoso Correia Perello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00595v2",
                "http://arxiv.org/pdf/2311.00595v2"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00591v1",
            "title": "Coop: Memory is not a Commodity",
            "updated": "2023-11-01T15:35:51Z",
            "published": "2023-11-01T15:35:51Z",
            "summary": "Tensor rematerialization allows the training of deep neural networks (DNNs)\nunder limited memory budgets by checkpointing the models and recomputing the\nevicted tensors as needed. However, the existing tensor rematerialization\ntechniques overlook the memory system in deep learning frameworks and\nimplicitly assume that free memory blocks at different addresses are identical.\nUnder this flawed assumption, discontiguous tensors are evicted, among which\nsome are not used to allocate the new tensor. This leads to severe memory\nfragmentation and increases the cost of potential rematerializations. To\naddress this issue, we propose to evict tensors within a sliding window to\nensure all evictions are contiguous and are immediately used. Furthermore, we\nproposed cheap tensor partitioning and recomputable in-place to further reduce\nthe rematerialization cost by optimizing the tensor allocation. We named our\nmethod Coop as it is a co-optimization of tensor allocation and tensor\nrematerialization. We evaluated Coop on eight representative DNNs. The\nexperimental results demonstrate that Coop achieves up to $2\\times$ memory\nsaving and hugely reduces compute overhead, search latency, and memory\nfragmentation compared to the state-of-the-art baselines.",
            "author": [
                "Jianhao Zhang",
                "Shihan Ma",
                "Peihong Liu",
                "Jinhui Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00591v1",
                "http://arxiv.org/pdf/2311.00591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00588v1",
            "title": "Boosting Summarization with Normalizing Flows and Aggressive Training",
            "updated": "2023-11-01T15:33:38Z",
            "published": "2023-11-01T15:33:38Z",
            "summary": "This paper presents FlowSUM, a normalizing flows-based variational\nencoder-decoder framework for Transformer-based summarization. Our approach\ntackles two primary challenges in variational summarization: insufficient\nsemantic information in latent representations and posterior collapse during\ntraining. To address these challenges, we employ normalizing flows to enable\nflexible latent posterior modeling, and we propose a controlled alternate\naggressive training (CAAT) strategy with an improved gate mechanism.\nExperimental results show that FlowSUM significantly enhances the quality of\ngenerated summaries and unleashes the potential for knowledge distillation with\nminimal impact on inference time. Furthermore, we investigate the issue of\nposterior collapse in normalizing flows and analyze how the summary quality is\naffected by the training strategy, gate initialization, and the type and number\nof normalizing flows used, offering valuable insights for future research.",
            "author": [
                "Yu Yang",
                "Xiaotong Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00588v1",
                "http://arxiv.org/pdf/2311.00588v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00587v2",
            "title": "Crosslingual Retrieval Augmented In-context Learning for Bangla",
            "updated": "2023-12-02T16:54:23Z",
            "published": "2023-11-01T15:32:50Z",
            "summary": "The promise of Large Language Models (LLMs) in Natural Language Processing\nhas often been overshadowed by their limited performance in low-resource\nlanguages such as Bangla. To address this, our paper presents a pioneering\napproach that utilizes cross-lingual retrieval augmented in-context learning.\nBy strategically sourcing semantically similar prompts from high-resource\nlanguage, we enable multilingual pretrained language models (MPLMs), especially\nthe generative model BLOOMZ, to successfully boost performance on Bangla tasks.\nOur extensive evaluation highlights that the cross-lingual retrieval augmented\nprompts bring steady improvements to MPLMs over the zero-shot performance.",
            "author": [
                "Xiaoqian Li",
                "Ercong Nie",
                "Sheng Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00587v2",
                "http://arxiv.org/pdf/2311.00587v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00586v1",
            "title": "PAUMER: Patch Pausing Transformer for Semantic Segmentation",
            "updated": "2023-11-01T15:32:11Z",
            "published": "2023-11-01T15:32:11Z",
            "summary": "We study the problem of improving the efficiency of segmentation transformers\nby using disparate amounts of computation for different parts of the image. Our\nmethod, PAUMER, accomplishes this by pausing computation for patches that are\ndeemed to not need any more computation before the final decoder. We use the\nentropy of predictions computed from intermediate activations as the pausing\ncriterion, and find this aligns well with semantics of the image. Our method\nhas a unique advantage that a single network trained with the proposed strategy\ncan be effortlessly adapted at inference to various run-time requirements by\nmodulating its pausing parameters. On two standard segmentation datasets,\nCityscapes and ADE20K, we show that our method operates with about a $50\\%$\nhigher throughput with an mIoU drop of about $0.65\\%$ and $4.6\\%$ respectively.",
            "author": [
                "Evann Courdier",
                "Prabhu Teja Sivaprasad",
                "Fran\u00e7ois Fleuret"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00586v1",
                "http://arxiv.org/pdf/2311.00586v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00582v2",
            "title": "Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and\n  Value",
            "updated": "2023-11-02T06:03:09Z",
            "published": "2023-11-01T15:27:29Z",
            "summary": "We study the game modification problem, where a benevolent game designer or a\nmalevolent adversary modifies the reward function of a zero-sum Markov game so\nthat a target deterministic or stochastic policy profile becomes the unique\nMarkov perfect Nash equilibrium and has a value within a target range, in a way\nthat minimizes the modification cost. We characterize the set of policy\nprofiles that can be installed as the unique equilibrium of some game, and\nestablish sufficient and necessary conditions for successful installation. We\npropose an efficient algorithm, which solves a convex optimization problem with\nlinear constraints and then performs random perturbation, to obtain a\nmodification plan with a near-optimal cost.",
            "author": [
                "Young Wu",
                "Jeremy McMahan",
                "Yiding Chen",
                "Yudong Chen",
                "Xiaojin Zhu",
                "Qiaomin Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00582v2",
                "http://arxiv.org/pdf/2311.00582v2"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14679v2",
            "title": "\"Medium-n studies\" in computing education conferences",
            "updated": "2023-11-28T14:32:13Z",
            "published": "2023-11-01T15:25:49Z",
            "summary": "Good (Frequentist) statistical practice requires that statistical tests be\nperformed in order to determine if the phenomenon being observed could\nplausibly occur by chance if the null hypothesis is false. Good practice also\nrequires that a test is not performed if the study is underpowered: if the\nnumber of observations is not sufficiently large to be able to reliably detect\nthe effect one hypothesizes, even if the effect exists. Running underpowered\nstudies runs the risk of false negative results. This creates tension in the\nguidelines and expectations for computer science education conferences: while\nthings are clear for studies with a large number of observations, researchers\nshould in fact not compute p-values and perform statistical tests if the number\nof observations is too small. The issue is particularly live in CSed venues,\nsince class sizes where those issues are salient are common. We outline the\nconsiderations for when to compute and when not to compute p-values in\ndifferent settings encountered by computer science education researchers. We\nsurvey the author and reviewer guidelines in different computer science\neducation conferences (ICER, SIGCSE TS, ITiCSE, EAAI, CompEd, Koli Calling). We\npresent summary data and make several preliminary observations about reviewer\nguidelines: guidelines vary from conference to conference; guidelines allow for\nqualitative studies, and, in some cases, experience reports, but guidelines do\nnot generally explicitly indicate that a paper should have at least one of (1)\nan appropriately-powered statistical analysis or (2) rich qualitative\ndescriptions. We present preliminary ideas for addressing the tension in the\nguidelines between small-n and large-n studies",
            "author": [
                "Michael Guerzhoy"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3631802.3631854",
                "http://arxiv.org/abs/2311.14679v2",
                "http://arxiv.org/pdf/2311.14679v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00739v1",
            "title": "Can Large Language Models Design Accurate Label Functions?",
            "updated": "2023-11-01T15:14:46Z",
            "published": "2023-11-01T15:14:46Z",
            "summary": "Programmatic weak supervision methodologies facilitate the expedited labeling\nof extensive datasets through the use of label functions (LFs) that encapsulate\nheuristic data sources. Nonetheless, the creation of precise LFs necessitates\ndomain expertise and substantial endeavors. Recent advances in pre-trained\nlanguage models (PLMs) have exhibited substantial potential across diverse\ntasks. However, the capacity of PLMs to autonomously formulate accurate LFs\nremains an underexplored domain. In this research, we address this gap by\nintroducing DataSculpt, an interactive framework that harnesses PLMs for the\nautomated generation of LFs. Within DataSculpt, we incorporate an array of\nprompting techniques, instance selection strategies, and LF filtration methods\nto explore the expansive design landscape. Ultimately, we conduct a thorough\nassessment of DataSculpt's performance on 12 real-world datasets, encompassing\na range of tasks. This evaluation unveils both the strengths and limitations of\ncontemporary PLMs in LF design.",
            "author": [
                "Naiqing Guan",
                "Kaiwen Chen",
                "Nick Koudas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00739v1",
                "http://arxiv.org/pdf/2311.00739v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.LG",
                "H.2.8; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00571v1",
            "title": "LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation,\n  Generation and Editing",
            "updated": "2023-11-01T15:13:43Z",
            "published": "2023-11-01T15:13:43Z",
            "summary": "LLaVA-Interactive is a research prototype for multimodal human-AI\ninteraction. The system can have multi-turn dialogues with human users by\ntaking multimodal user inputs and generating multimodal responses. Importantly,\nLLaVA-Interactive goes beyond language prompt, where visual prompt is enabled\nto align human intents in the interaction. The development of LLaVA-Interactive\nis extremely cost-efficient as the system combines three multimodal skills of\npre-built AI models without additional model training: visual chat of LLaVA,\nimage segmentation from SEEM, as well as image generation and editing from\nGLIGEN. A diverse set of application scenarios is presented to demonstrate the\npromises of LLaVA-Interactive and to inspire future research in multimodal\ninteractive systems.",
            "author": [
                "Wei-Ge Chen",
                "Irina Spiridonova",
                "Jianwei Yang",
                "Jianfeng Gao",
                "Chunyuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00571v1",
                "http://arxiv.org/pdf/2311.00571v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00568v1",
            "title": "Scalable kernel balancing weights in a nationwide observational study of\n  hospital profit status and heart attack outcomes",
            "updated": "2023-11-01T15:08:52Z",
            "published": "2023-11-01T15:08:52Z",
            "summary": "Weighting is a general and often-used method for statistical adjustment.\nWeighting has two objectives: first, to balance covariate distributions, and\nsecond, to ensure that the weights have minimal dispersion and thus produce a\nmore stable estimator. A recent, increasingly common approach directly\noptimizes the weights toward these two objectives. However, this approach has\nnot yet been feasible in large-scale datasets when investigators wish to\nflexibly balance general basis functions in an extended feature space. For\nexample, many balancing approaches cannot scale to national-level health\nservices research studies. To address this practical problem, we describe a\nscalable and flexible approach to weighting that integrates a basis expansion\nin a reproducing kernel Hilbert space with state-of-the-art convex optimization\ntechniques. Specifically, we use the rank-restricted Nystr\\\"{o}m method to\nefficiently compute a kernel basis for balancing in {nearly} linear time and\nspace, and then use the specialized first-order alternating direction method of\nmultipliers to rapidly find the optimal weights. In an extensive simulation\nstudy, we provide new insights into the performance of weighting estimators in\nlarge datasets, showing that the proposed approach substantially outperforms\nothers in terms of accuracy and speed. Finally, we use this weighting approach\nto conduct a national study of the relationship between hospital profit status\nand heart attack outcomes in a comprehensive dataset of 1.27 million patients.\nWe find that for-profit hospitals use interventional cardiology to treat heart\nattacks at similar rates as other hospitals, but have higher mortality and\nreadmission rates.",
            "author": [
                "Kwangho Kim",
                "Bijan A. Niknam",
                "Jos\u00e9 R. Zubizarreta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00568v1",
                "http://arxiv.org/pdf/2311.00568v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00567v2",
            "title": "A Robust Deep Learning Method with Uncertainty Estimation for the\n  Pathological Classification of Renal Cell Carcinoma based on CT Images",
            "updated": "2023-11-12T17:42:07Z",
            "published": "2023-11-01T15:07:39Z",
            "summary": "Objectives To develop and validate a deep learning-based diagnostic model\nincorporating uncertainty estimation so as to facilitate radiologists in the\npreoperative differentiation of the pathological subtypes of renal cell\ncarcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients,\npathologically proven RCC, were retrospectively collected from Center 1. By\nusing five-fold cross-validation, a deep learning model incorporating\nuncertainty estimation was developed to classify RCC subtypes into clear cell\nRCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An external\nvalidation set of 78 patients from Center 2 further evaluated the model's\nperformance. Results In the five-fold cross-validation, the model's area under\nthe receiver operating characteristic curve (AUC) for the classification of\nccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI:\n0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the external\nvalidation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI:\n0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC,\nrespectively. Conclusions The developed deep learning model demonstrated robust\nperformance in predicting the pathological subtypes of RCC, while the\nincorporated uncertainty emphasized the importance of understanding model\nconfidence, which is crucial for assisting clinical decision-making for\npatients with renal tumors. Clinical relevance statement Our deep learning\napproach, integrated with uncertainty estimation, offers clinicians a dual\nadvantage: accurate RCC subtype predictions complemented by diagnostic\nconfidence references, promoting informed decision-making for patients with\nRCC.",
            "author": [
                "Ni Yao",
                "Hang Hu",
                "Kaicong Chen",
                "Chen Zhao",
                "Yuan Guo",
                "Boya Li",
                "Jiaofen Nan",
                "Yanting Li",
                "Chuang Han",
                "Fubao Zhu",
                "Weihua Zhou",
                "Li Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00567v2",
                "http://arxiv.org/pdf/2311.00567v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "physics.med-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00566v1",
            "title": "CROMA: Remote Sensing Representations with Contrastive Radar-Optical\n  Masked Autoencoders",
            "updated": "2023-11-01T15:07:27Z",
            "published": "2023-11-01T15:07:27Z",
            "summary": "A vital and rapidly growing application, remote sensing offers vast yet\nsparsely labeled, spatially aligned multimodal data; this makes self-supervised\nlearning algorithms invaluable. We present CROMA: a framework that combines\ncontrastive and reconstruction self-supervised objectives to learn rich\nunimodal and multimodal representations. Our method separately encodes\nmasked-out multispectral optical and synthetic aperture radar samples --\naligned in space and time -- and performs cross-modal contrastive learning.\nAnother encoder fuses these sensors, producing joint multimodal encodings that\nare used to predict the masked patches via a lightweight decoder. We show that\nthese objectives are complementary when leveraged on spatially aligned\nmultimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our\ncross- and self-attention matrices. These strategies improve representations\nand allow our models to effectively extrapolate to images up to 17.6x larger at\ntest-time. CROMA outperforms the current SoTA multispectral model, evaluated\non: four classification benchmarks -- finetuning (avg. 1.8%), linear (avg.\n2.4%) and nonlinear (avg. 1.4%) probing, kNN classification (avg. 3.5%), and\nK-means clustering (avg. 8.4%); and three segmentation benchmarks (avg. 6.4%).\nCROMA's rich, optionally multimodal representations can be widely leveraged\nacross remote sensing applications.",
            "author": [
                "Anthony Fuller",
                "Koreen Millard",
                "James R. Green"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00566v1",
                "http://arxiv.org/pdf/2311.00566v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00565v1",
            "title": "Detecting Visual Cues in the Intensive Care Unit and Association with\n  Patient Clinical Status",
            "updated": "2023-11-01T15:07:03Z",
            "published": "2023-11-01T15:07:03Z",
            "summary": "Intensive Care Units (ICU) provide close supervision and continuous care to\npatients with life-threatening conditions. However, continuous patient\nassessment in the ICU is still limited due to time constraints and the workload\non healthcare providers. Existing patient assessments in the ICU such as pain\nor mobility assessment are mostly sporadic and administered manually, thus\nintroducing the potential for human errors. Developing Artificial intelligence\n(AI) tools that can augment human assessments in the ICU can be beneficial for\nproviding more objective and granular monitoring capabilities. For example,\ncapturing the variations in a patient's facial cues related to pain or\nagitation can help in adjusting pain-related medications or detecting\nagitation-inducing conditions such as delirium. Additionally, subtle changes in\nvisual cues during or prior to adverse clinical events could potentially aid in\ncontinuous patient monitoring when combined with high-resolution physiological\nsignals and Electronic Health Record (EHR) data. In this paper, we examined the\nassociation between visual cues and patient condition including acuity status,\nacute brain dysfunction, and pain. We leveraged our AU-ICU dataset with 107,064\nframes collected in the ICU annotated with facial action units (AUs) labels by\ntrained annotators. We developed a new \"masked loss computation\" technique that\naddresses the data imbalance problem by maximizing data resource utilization.\nWe trained the model using our AU-ICU dataset in conjunction with three\nexternal datasets to detect 18 AUs. The SWIN Transformer model achieved 0.57\nmean F1-score and 0.89 mean accuracy on the test set. Additionally, we\nperformed AU inference on 634,054 frames to evaluate the association between\nfacial AUs and clinically important patient conditions such as acuity status,\nacute brain dysfunction, and pain.",
            "author": [
                "Subhash Nerella",
                "Ziyuan Guan",
                "Andrea Davidson",
                "Yuanfang Ren",
                "Tezcan Baslanti",
                "Brooke Armfield",
                "Patrick Tighe",
                "Azra Bihorac",
                "Parisa Rashidi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00565v1",
                "http://arxiv.org/pdf/2311.00565v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00562v2",
            "title": "MNN: Mixed Nearest-Neighbors for Self-Supervised Learning",
            "updated": "2023-11-13T14:21:49Z",
            "published": "2023-11-01T14:59:41Z",
            "summary": "In contrastive self-supervised learning, positive samples are typically drawn\nfrom the same image but in different augmented views, resulting in a relatively\nlimited source of positive samples. An effective way to alleviate this problem\nis to incorporate the relationship between samples, which involves including\nthe top-K nearest neighbors of positive samples. However, the problem of false\nneighbors (i.e., neighbors that do not belong to the same category as the\npositive sample) is an objective but often overlooked challenge due to the\nquery of neighbor samples without supervision information. In this paper, we\npresent a simple self-supervised learning framework called Mixed\nNearest-Neighbors for Self-Supervised Learning (MNN). MNN optimizes the\ninfluence of neighbor samples on the semantics of positive samples through an\nintuitive weighting approach and image mixture operations. The results\ndemonstrate that MNN exhibits exceptional generalization performance and\ntraining efficiency on four benchmark datasets.",
            "author": [
                "Xianzhong Long",
                "Chen Peng",
                "Yun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00562v2",
                "http://arxiv.org/pdf/2311.00562v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00558v1",
            "title": "An Exponential Lower Bound for Linear 3-Query Locally Correctable Codes",
            "updated": "2023-11-01T14:55:04Z",
            "published": "2023-11-01T14:55:04Z",
            "summary": "We prove that the blocklength $n$ of a linear $3$-query locally correctable\ncode (LCC) $\\mathcal{L} \\colon {\\mathbb F}^k \\to {\\mathbb F}^n$ with distance\n$\\delta$ must be at least $n \\geq 2^{\\Omega\\left(\\left(\\frac{\\delta^2\nk}{(|{\\mathbb F}|-1)^2}\\right)^{1/8}\\right)}$. In particular, the blocklength\nof a linear $3$-query LCC with constant distance over any small field grows\nexponentially with $k$. This improves on the best prior lower bound of $n \\geq\n\\tilde{\\Omega}(k^3)$ [AGKM23], which holds even for the weaker setting of\n$3$-query locally decodable codes (LDCs), and comes close to matching the\nbest-known construction of $3$-query LCCs based on binary Reed-Muller codes,\nwhich achieve $n \\leq 2^{O(k^{1/2})}$. Because there is a $3$-query LDC with a\nstrictly subexponential blocklength [Yek08, Efr09], as a corollary we obtain\nthe first strong separation between $q$-query LCCs and LDCs for any constant $q\n\\geq 3$.\n  Our proof is based on a new upgrade of the method of spectral refutations via\nKikuchi matrices developed in recent works [GKM22, HKM23, AGKM23] that reduces\nestablishing (non-)existence of combinatorial objects to proving\nunsatisfiability of associated XOR instances. Our key conceptual idea is to\napply this method with XOR instances obtained via long-chain derivations, a\nstructured variant of low-width resolution for XOR formulas from proof\ncomplexity [Gri01, Sch08].",
            "author": [
                "Pravesh K. Kothari",
                "Peter Manohar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00558v1",
                "http://arxiv.org/pdf/2311.00558v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02101v1",
            "title": "Solving MaxSAT with Matrix Multiplication",
            "updated": "2023-11-01T14:46:46Z",
            "published": "2023-11-01T14:46:46Z",
            "summary": "We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT)\nspecifically designed to run on neural network accelerators such as GPUs and\nTPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure\nconstructs a Restricted Boltzmann Machine (RBM) with an equilibrium\ndistribution wherein the probability of a Boolean assignment is exponential in\nthe number of clauses it satisfies. Block Gibbs sampling is used to\nstochastically search the space of assignments with parallel Markov chains.\nSince matrix multiplication is the main computational primitive for block Gibbs\nsampling in an RBM, our approach leads to an elegantly simple algorithm (40\nlines of JAX) well-suited for neural network accelerators. Theoretical results\nabout RBMs guarantee that the required number of visible and hidden units of\nthe RBM scale only linearly with the number of variables and constant-sized\nclauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs\nstep scales reasonably with the instance size. Search throughput can be\nincreased by batching parallel chains within a single accelerator as well as by\ndistributing them across multiple accelerators. As a further enhancement, a\nheuristic based on unit propagation running on CPU is periodically applied to\nthe sampled assignments. Our approach, which we term RbmSAT, is a new design\npoint in the algorithm-hardware co-design space for MaxSAT. We present timed\nresults on a subset of problem instances from the annual MaxSAT Evaluation's\nIncomplete Unweighted Track for the years 2018 to 2021. When allotted the same\nrunning time and CPU compute budget (but no TPUs), RbmSAT outperforms other\nparticipating solvers on problems drawn from three out of the four years'\ncompetitions. Given the same running time on a TPU cluster for which RbmSAT is\nuniquely designed, it outperforms all solvers on problems drawn from all four\nyears.",
            "author": [
                "David Warde-Farley",
                "Vinod Nair",
                "Yujia Li",
                "Ivan Lobov",
                "Felix Gimeno",
                "Simon Osindero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02101v1",
                "http://arxiv.org/pdf/2311.02101v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00556v1",
            "title": "ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab",
            "updated": "2023-11-01T14:44:01Z",
            "published": "2023-11-01T14:44:01Z",
            "summary": "The challenge of replicating research results has posed a significant\nimpediment to the field of molecular biology. The advent of modern intelligent\nsystems has led to notable progress in various domains. Consequently, we\nembarked on an investigation of intelligent monitoring systems as a means of\ntackling the issue of the reproducibility crisis. Specifically, we first curate\na comprehensive multimodal dataset, named ProBio, as an initial step towards\nthis objective. This dataset comprises fine-grained hierarchical annotations\nintended for the purpose of studying activity understanding in BioLab. Next, we\ndevise two challenging benchmarks, transparent solution tracking and multimodal\naction recognition, to emphasize the unique characteristics and difficulties\nassociated with activity understanding in BioLab settings. Finally, we provide\na thorough experimental evaluation of contemporary video understanding models\nand highlight their limitations in this specialized domain to identify\npotential avenues for future research. We hope ProBio with associated\nbenchmarks may garner increased focus on modern AI techniques in the realm of\nmolecular biology.",
            "author": [
                "Jieming Cui",
                "Ziren Gong",
                "Baoxiong Jia",
                "Siyuan Huang",
                "Zilong Zheng",
                "Jianzhu Ma",
                "Yixin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00556v1",
                "http://arxiv.org/pdf/2311.00556v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00553v1",
            "title": "Polynomial Chaos Surrogate Construction for Random Fields with\n  Parametric Uncertainty",
            "updated": "2023-11-01T14:41:54Z",
            "published": "2023-11-01T14:41:54Z",
            "summary": "Engineering and applied science rely on computational experiments to\nrigorously study physical systems. The mathematical models used to probe these\nsystems are highly complex, and sampling-intensive studies often require\nprohibitively many simulations for acceptable accuracy. Surrogate models\nprovide a means of circumventing the high computational expense of sampling\nsuch complex models. In particular, polynomial chaos expansions (PCEs) have\nbeen successfully used for uncertainty quantification studies of deterministic\nmodels where the dominant source of uncertainty is parametric. We discuss an\nextension to conventional PCE surrogate modeling to enable surrogate\nconstruction for stochastic computational models that have intrinsic noise in\naddition to parametric uncertainty. We develop a PCE surrogate on a joint space\nof intrinsic and parametric uncertainty, enabled by Rosenblatt transformations,\nand then extend the construction to random field data via the Karhunen-Loeve\nexpansion. We then take advantage of closed-form solutions for computing PCE\nSobol indices to perform a global sensitivity analysis of the model which\nquantifies the intrinsic noise contribution to the overall model output\nvariance. Additionally, the resulting joint PCE is generative in the sense that\nit allows generating random realizations at any input parameter setting that\nare statistically approximately equivalent to realizations from the underlying\nstochastic model. The method is demonstrated on a chemical catalysis example\nmodel.",
            "author": [
                "Joy N. Mueller",
                "Khachik Sargsyan",
                "Craig J. Daniels",
                "Habib N. Najm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00553v1",
                "http://arxiv.org/pdf/2311.00553v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "60G99, 65C20, 33C45, 62G07, 62J02"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00552v1",
            "title": "Evaluation of Induced Transmembrane potential on Membrane Poration\n  through Molecular Dynamics Simulation and Analytical Calculation",
            "updated": "2023-11-01T14:39:23Z",
            "published": "2023-11-01T14:39:23Z",
            "summary": "A molecular dynamics (MD) simulation is used to quantitatively analyze the\ninduced membrane potential for an applied external field varied between 0.4\nV/nm to 2.0 V/nm. The change in the electrostatic potential in the DPPC is\ndirectly correlated to the membrane permeability. The effect of the decrease in\nexternal conductivity on the DPPC is also evaluated and the analytical results\nare compared with the simulation. The correlation between the electrostatic\npotential of the DPPC and the total dipole are compared, and a positive\ncorrelation is identified until saturation. This is because the membrane\npermeability factor plays a dominant role to control reversible and\nirreversible electroporation. The obtained dipole parameters through simulation\nfor various electric field allows for an accurate determination of the\nquantitative changes in the membrane and external conductivity during the\nprocess of electroporation.",
            "author": [
                "Shadeeb Hossain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00552v1",
                "http://arxiv.org/pdf/2311.00552v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "physics.app-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00548v3",
            "title": "Continual atlas-based segmentation of prostate MRI",
            "updated": "2023-11-06T12:34:45Z",
            "published": "2023-11-01T14:29:46Z",
            "summary": "Continual learning (CL) methods designed for natural image classification\noften fail to reach basic quality standards for medical image segmentation.\nAtlas-based segmentation, a well-established approach in medical imaging,\nincorporates domain knowledge on the region of interest, leading to\nsemantically coherent predictions. This is especially promising for CL, as it\nallows us to leverage structural information and strike an optimal balance\nbetween model rigidity and plasticity over time. When combined with\nprivacy-preserving prototypes, this process offers the advantages of\nrehearsal-based CL without compromising patient privacy. We propose Atlas\nReplay, an atlas-based segmentation approach that uses prototypes to generate\nhigh-quality segmentation masks through image registration that maintain\nconsistency even as the training distribution changes. We explore how our\nproposed method performs compared to state-of-the-art CL methods in terms of\nknowledge transferability across seven publicly available prostate segmentation\ndatasets. Prostate segmentation plays a vital role in diagnosing prostate\ncancer, however, it poses challenges due to substantial anatomical variations,\nbenign structural differences in older age groups, and fluctuating acquisition\nparameters. Our results show that Atlas Replay is both robust and generalizes\nwell to yet-unseen domains while being able to maintain knowledge, unlike\nend-to-end segmentation methods. Our code base is available under\nhttps://github.com/MECLabTUDA/Atlas-Replay.",
            "author": [
                "Amin Ranem",
                "Camila Gonz\u00e1lez",
                "Daniel Pinto dos Santos",
                "Andreas M. Bucher",
                "Ahmed E. Othman",
                "Anirban Mukhopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00548v3",
                "http://arxiv.org/pdf/2311.00548v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00544v1",
            "title": "An \u03b1-cut intervals based fuzzy best-Worst method for\n  Multi-Criteria Decision-Making",
            "updated": "2023-11-01T14:24:34Z",
            "published": "2023-11-01T14:24:34Z",
            "summary": "The Best-Worst Method (BWM) is a well-known Multi-Criteria Decision-Making\n(MCDM) method used to calculate criteria-weights in many real-life\napplications. It was observed that the decision judgments used to calculate\nweights in BWM may be imprecise due to human involvement. To incorporate this\nambiguity into the weight calculation, Guo & Zhao proposed a model of BWM using\nfuzzy sets, known as Fuzzy BWM (FBWM). Although this model is known to have\nwide applicability, it has several limitations. One of the biggest limitations\nof this existing model is that the lower, modal and upper values of the fuzzy\njudgment are used in the weight calculation and the other values remain unused.\nTo solve this limitation and optimize the entire shape, we propose a model of\nFBWM based on {\\alpha}-cut intervals. This helps in reducing information loss.\nIt turns out that although it is possible to optimize the entire shape\nsimultaneously, it is difficult to do so. Therefore, we approximate optimal\nweights using finite subset, say F, of [0, 1]. We then develop a technique to\nmeasure the Degree of Approximation (DoA) of a weight set and obtain a weight\nset with the desired DoA. For a given F, approximate weights are calculated\nusing a minimization problem that has a non-linear nature and thus may lead to\nmultiple weights. To solve this issue, we first compute the collection of all\napproximate weights of the criterion, which is an interval, and then adopt the\ncenter of this interval as the approximate weight of the criterion. To measure\nthe accuracy of a weight set, we develop the concepts of Consistency Index (CI)\nand Consistency Ratio (CR) for the proposed model. Finally, we discuss some\nnumerical examples and a real-world application of the proposed model in\nranking of risk factors in supply chain 4.0 and compare the results with\nexisting models.",
            "author": [
                "Harshit M Ratandhara",
                "Mohit Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00544v1",
                "http://arxiv.org/pdf/2311.00544v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00541v1",
            "title": "An Embedded Diachronic Sense Change Model with a Case Study from Ancient\n  Greek",
            "updated": "2023-11-01T14:20:18Z",
            "published": "2023-11-01T14:20:18Z",
            "summary": "Word meanings change over time, and word senses evolve, emerge or die out in\nthe process. For ancient languages, where the corpora are often small, sparse\nand noisy, modelling such changes accurately proves challenging, and\nquantifying uncertainty in sense-change estimates consequently becomes\nimportant. GASC and DiSC are existing generative models that have been used to\nanalyse sense change for target words from an ancient Greek text corpus, using\nunsupervised learning without the help of any pre-training. These models\nrepresent the senses of a given target word such as \"kosmos\" (meaning\ndecoration, order or world) as distributions over context words, and sense\nprevalence as a distribution over senses. The models are fitted using MCMC\nmethods to measure temporal changes in these representations. In this paper, we\nintroduce EDiSC, an embedded version of DiSC, which combines word embeddings\nwith DiSC to provide superior model performance. We show empirically that EDiSC\noffers improved predictive accuracy, ground-truth recovery and uncertainty\nquantification, as well as better sampling efficiency and scalability\nproperties with MCMC methods. We also discuss the challenges of fitting these\nmodels.",
            "author": [
                "Schyan Zafar",
                "Geoff K. Nicholls"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00541v1",
                "http://arxiv.org/pdf/2311.00541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00537v1",
            "title": "Machine Learning Without a Processor: Emergent Learning in a Nonlinear\n  Electronic Metamaterial",
            "updated": "2023-11-01T14:16:37Z",
            "published": "2023-11-01T14:16:37Z",
            "summary": "Standard deep learning algorithms require differentiating large nonlinear\nnetworks, a process that is slow and power-hungry. Electronic learning\nmetamaterials offer potentially fast, efficient, and fault-tolerant hardware\nfor analog machine learning, but existing implementations are linear, severely\nlimiting their capabilities. These systems differ significantly from artificial\nneural networks as well as the brain, so the feasibility and utility of\nincorporating nonlinear elements have not been explored. Here we introduce a\nnonlinear learning metamaterial -- an analog electronic network made of\nself-adjusting nonlinear resistive elements based on transistors. We\ndemonstrate that the system learns tasks unachievable in linear systems,\nincluding XOR and nonlinear regression, without a computer. We find our\nnonlinear learning metamaterial reduces modes of training error in order (mean,\nslope, curvature), similar to spectral bias in artificial neural networks. The\ncircuitry is robust to damage, retrainable in seconds, and performs learned\ntasks in microseconds while dissipating only picojoules of energy across each\ntransistor. This suggests enormous potential for fast, low-power computing in\nedge systems like sensors, robotic controllers, and medical devices, as well as\nmanufacturability at scale for performing and studying emergent learning.",
            "author": [
                "Sam Dillavou",
                "Benjamin D Beyer",
                "Menachem Stern",
                "Marc Z Miskin",
                "Andrea J Liu",
                "Douglas J Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00537v1",
                "http://arxiv.org/pdf/2311.00537v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cs.ET",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00522v1",
            "title": "Text Rendering Strategies for Pixel Language Models",
            "updated": "2023-11-01T13:49:31Z",
            "published": "2023-11-01T13:49:31Z",
            "summary": "Pixel-based language models process text rendered as images, which allows\nthem to handle any script, making them a promising approach to open vocabulary\nlanguage modelling. However, recent approaches use text renderers that produce\na large set of almost-equivalent input patches, which may prove sub-optimal for\ndownstream tasks, due to redundancy in the input representations. In this\npaper, we investigate four approaches to rendering text in the PIXEL model\n(Rust et al., 2023), and find that simple character bigram rendering brings\nimproved performance on sentence-level tasks without compromising performance\non token-level or multilingual tasks. This new rendering strategy also makes it\npossible to train a more compact model with only 22M parameters that performs\non par with the original 86M parameter model. Our analyses show that character\nbigram rendering leads to a consistently better model but with an anisotropic\npatch embedding space, driven by a patch frequency bias, highlighting the\nconnections between image patch- and tokenization-based language models.",
            "author": [
                "Jonas F. Lotz",
                "Elizabeth Salesky",
                "Phillip Rust",
                "Desmond Elliott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00522v1",
                "http://arxiv.org/pdf/2311.00522v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00521v1",
            "title": "Gaussian smoothing gradient descent for minimizing high-dimensional\n  non-convex functions",
            "updated": "2023-11-01T13:49:21Z",
            "published": "2023-11-01T13:49:21Z",
            "summary": "This work analyzes the convergence of a class of smoothing-based gradient\ndescent methods when applied to high-dimensional non-convex optimization\nproblems. In particular, Gaussian smoothing is employed to define a nonlocal\ngradient that reduces high-frequency noise, small variations, and rapid\nfluctuations in the computation of the descent directions while preserving the\nstructure and features of the loss landscape. The resulting Gaussian smoothing\ngradient descent (GSmoothGD) approach can facilitate gradient descent in\nnavigating away from and avoiding local minima with increased ease, thereby\nsubstantially enhancing its overall performance when applied to non-convex\noptimization problems. This work also provides rigorous theoretical error\nestimates on the rate of convergence of GSmoothGD iterates. These estimates\nexemplify the impact of underlying function convexity, smoothness, input\ndimension, and the Gaussian smoothing radius. To combat the curse of\ndimensionality, we numerically approximate the $d$-dimensional GSmoothGD\nnonlocal gradient using Monte Carlo (MC) sampling and provide a theory in which\nthe iterates converge regardless of the function smoothness and dimension.\nFinally, we present several strategies to update the smoothing parameter aimed\nat diminishing the impact of local minima, thereby rendering the attainment of\nglobal minima more achievable. Computational evidence complements the present\ntheory and shows the effectiveness of the MC-GSmoothGD method compared to other\nsmoothing-based algorithms, momentum-based approaches, and classical\ngradient-based algorithms from numerical optimization.",
            "author": [
                "Andrew Starnes",
                "Anton Dereventsov",
                "Clayton Webster"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00521v1",
                "http://arxiv.org/pdf/2311.00521v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "35Q90, 65H20, 90C25, 90C30, 90C56"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00517v1",
            "title": "Improving Cardiovascular Disease Prediction Through Comparative Analysis\n  of Machine Learning Models: A Case Study on Myocardial Infarction",
            "updated": "2023-11-01T13:41:44Z",
            "published": "2023-11-01T13:41:44Z",
            "summary": "Cardiovascular disease remains a leading cause of mortality in the\ncontemporary world. Its association with smoking, elevated blood pressure, and\ncholesterol levels underscores the significance of these risk factors. This\nstudy addresses the challenge of predicting myocardial illness, a formidable\ntask in medical research. Accurate predictions are pivotal for refining\nhealthcare strategies. This investigation conducts a comparative analysis of\nsix distinct machine learning models: Logistic Regression, Support Vector\nMachine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes\nexhibit promise, with accuracy rates as follows: Logistic Regression (81.00%),\nSupport Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision\nTree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the\ntop-performing model. These findings underscore its potential to enhance\npredictive precision for coronary infarction. As the prevalence of\ncardiovascular risk factors persists, incorporating advanced machine learning\ntechniques holds the potential to refine proactive medical interventions.",
            "author": [
                "Jonayet Miah",
                "Duc M Ca",
                "Md Abu Sayed",
                "Ehsanur Rashid Lipu",
                "Fuad Mahmud",
                "S M Yasir Arafat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00517v1",
                "http://arxiv.org/pdf/2311.00517v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00514v1",
            "title": "How Hard Is Squash? -- Towards Information Theoretic Analysis of Motor\n  Behavior in Squash",
            "updated": "2023-11-01T13:37:59Z",
            "published": "2023-11-01T13:37:59Z",
            "summary": "Fitts' law has been widely employed as a research method for analyzing tasks\nwithin the domain of Human-Computer Interaction (HCI). However, its application\nto non-computer tasks has remained limited. This study aims to extend the\napplication of Fitts' law to the realm of sports, specifically focusing on\nsquash. Squash is a high-intensity sport that requires quick movements and\nprecise shots. Our research investigates the effectiveness of utilizing Fitts'\nlaw to evaluate the task difficulty and effort level associated with executing\nand responding to various squash shots. By understanding the effort/information\nrate required for each shot, we can determine which shots are more effective in\nmaking the opponent work harder. Additionally, this knowledge can be valuable\nfor coaches in designing training programs. However, since Fitts' law was\nprimarily developed for human-computer interaction, we adapted it to fit the\nsquash scenario. This paper provides an overview of Fitts' law and its\nrelevance to sports, elucidates the motivation driving this investigation,\noutlines the methodology employed to explore this novel avenue, and presents\nthe obtained results, concluding with key insights. We conducted experiments\nwith different shots and players, collecting data on shot speed, player\nmovement time, and distance traveled. Using this data, we formulated a modified\nversion of Fitts' law specifically for squash. The results provide insights\ninto the difficulty and effectiveness of various shots, offering valuable\ninformation for both players and coaches in the sport of squash.",
            "author": [
                "Kavya Anand",
                "Pramit Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00514v1",
                "http://arxiv.org/pdf/2311.00514v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00513v1",
            "title": "Rule-Based Error Classification for Analyzing Differences in Frequent\n  Errors",
            "updated": "2023-11-01T13:36:20Z",
            "published": "2023-11-01T13:36:20Z",
            "summary": "Finding and fixing errors is a time-consuming task not only for novice\nprogrammers but also for expert programmers. Prior work has identified frequent\nerror patterns among various levels of programmers. However, the differences in\nthe tendencies between novices and experts have yet to be revealed. From the\nknowledge of the frequent errors in each level of programmers, instructors will\nbe able to provide helpful advice for each level of learners. In this paper, we\npropose a rule-based error classification tool to classify errors in code pairs\nconsisting of wrong and correct programs. We classify errors for 95,631 code\npairs and identify 3.47 errors on average, which are submitted by various\nlevels of programmers on an online judge system. The classified errors are used\nto analyze the differences in frequent errors between novice and expert\nprogrammers. The analyzed results show that, as for the same introductory\nproblems, errors made by novices are due to the lack of knowledge in\nprogramming, and the mistakes are considered an essential part of the learning\nprocess. On the other hand, errors made by experts are due to misunderstandings\ncaused by the carelessness of reading problems or the challenges of solving\nproblems differently than usual. The proposed tool can be used to create\nerror-labeled datasets and for further code-related educational research.",
            "author": [
                "Atsushi Shirafuji",
                "Taku Matsumoto",
                "Md Faizul Ibne Amin",
                "Yutaka Watanobe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00513v1",
                "http://arxiv.org/pdf/2311.00513v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01474v1",
            "title": "A new proof of Euclid's algorithm",
            "updated": "2023-11-01T13:26:03Z",
            "published": "2023-11-01T13:26:03Z",
            "summary": "Our main result is a new proof of correctness of Euclid's algorithm. The\nproof is conducted in algorithmic theory of natural numbers Th3. A formula H is\nconstructed that expresses the halting property of the algorithm. Next, the\nproof of H is is presented. In the proof we make use of inference rules of\ncalculus of programs. The only formulas accepted without the proof are axioms\nof program calculus or axioms of the theory Th3. We complete our result by\nshowing that the theorem on correctness of Euclid's algorithm can not be proved\nin any elementary theory of natural numbers.",
            "author": [
                "Andrzej Salwicki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01474v1",
                "http://arxiv.org/pdf/2311.01474v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.DS",
                "math.LO",
                "03D02 (Primary) 68Q02 (Secondary)",
                "F.3.1; D.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00510v1",
            "title": "MC-Biquandles and MC-Biquandle Coloring Quivers",
            "updated": "2023-11-01T13:22:45Z",
            "published": "2023-11-01T13:22:45Z",
            "summary": "We introduce the notion of mc-biquandles, algebraic structures which have\npossibly distinct biquandle operations at single-component and multi-component\ncrossings. These structures provide computable homset invariants for classical\nand virtual links. We categorify these homsets to obtain mc-biquandle coloring\nquivers and define several new link invariants via decategorification from\nthese invariant quivers.",
            "author": [
                "Seonmi Choi",
                "Sam Nelson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00510v1",
                "http://arxiv.org/pdf/2311.00510v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.QA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00509v1",
            "title": "Uncertainty quantification of time-average quantities of chaotic systems\n  using sensitivity-enhanced polynomial chaos expansion",
            "updated": "2023-11-01T13:16:39Z",
            "published": "2023-11-01T13:16:39Z",
            "summary": "We consider the effect of multiple stochastic parameters on the time-average\nquantities of chaotic systems. We employ the recently proposed\n\\cite{Kantarakias_Papadakis_2023} sensitivity-enhanced generalized polynomial\nchaos expansion, se-gPC, to compute efficiently this effect. se-gPC is an\nextension of gPC expansion, enriched with the sensitivity of the time-averaged\nquantities with respect to the stochastic variables. To compute these\nsensitivities, the adjoint of the shadowing operator is derived in the\nfrequency domain. Coupling the adjoint operator with gPC provides an efficient\nuncertainty quantification (UQ) algorithm which, in its simplest form, has\ncomputational cost that is independent of the number of random variables. The\nmethod is applied to the Kuramoto-Sivashinsky equation and is found to produce\nresults that match very well with Monte-Carlo simulations. The efficiency of\nthe proposed method significantly outperforms sparse-grid approaches, like\nSmolyak Quadrature. These properties make the method suitable for application\nto other dynamical systems with many stochastic parameters.",
            "author": [
                "George Papadakis",
                "Kyriakos D. Kantarakias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00509v1",
                "http://arxiv.org/pdf/2311.00509v1"
            ],
            "primary_category": "nlin.CD",
            "category": [
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00508v1",
            "title": "Robustness Tests for Automatic Machine Translation Metrics with\n  Adversarial Attacks",
            "updated": "2023-11-01T13:14:23Z",
            "published": "2023-11-01T13:14:23Z",
            "summary": "We investigate MT evaluation metric performance on adversarially-synthesized\ntexts, to shed light on metric robustness. We experiment with word- and\ncharacter-level attacks on three popular machine translation metrics:\nBERTScore, BLEURT, and COMET. Our human experiments validate that automatic\nmetrics tend to overpenalize adversarially-degraded translations. We also\nidentify inconsistencies in BERTScore ratings, where it judges the original\nsentence and the adversarially-degraded one as similar, while judging the\ndegraded translation as notably worse than the original with respect to the\nreference. We identify patterns of brittleness that motivate more robust metric\ndevelopment.",
            "author": [
                "Yichen Huang",
                "Timothy Baldwin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00508v1",
                "http://arxiv.org/pdf/2311.00508v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00506v1",
            "title": "Experimental Validation of a Grid-Aware Optimal Control of Hybrid AC/DC\n  Microgrids",
            "updated": "2023-11-01T13:11:56Z",
            "published": "2023-11-01T13:11:56Z",
            "summary": "This paper presents the experimental validation of a grid-aware real-time\ncontrol method for hybrid AC/DC microgrids. The optimal control is leveraged by\nthe voltage sensitivity coefficients (SC) that are computed analytically using\nthe close-form expression proposed in the authors' previous work. The SCs are\nbased on the unified power flow model for hybrid AC/DC grids that accounts for\nthe AC grid, DC grid, and the Interfacing Converters (IC), which can operate in\ndifferent control modes, e.g. voltage or power control. The SCs are used to\nexpress the grid constraints in the optimal control problem in a fully linear\nway and, therefore, allow for second- to subsecond control actions. The\nvalidation of the model is performed on the hybrid AC/DC grid, available at the\nEPFL. The network consists of 18 AC nodes, 8 DC nodes, and 4 converters to\ninterface the AC and DC network. The network hosts multiple controllable and\nuncontrollable resources. The SC-based optimal control is validated in a\ngeneric experiment. It is shown that the real-time control is able to control\nthe ICs optimally to redirect power through the DC grid, to avoid grid\nconstraint violations while providing reactive power support to the upper layer\nAC grid. Furthermore, the computational time of the optimal control is analysed\nto validate its application in critical real-time applications.",
            "author": [
                "Willem Lambrichts",
                "Jules Mace",
                "Mario Paolone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00506v1",
                "http://arxiv.org/pdf/2311.00506v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00505v1",
            "title": "Dynamical charging of interstellar dust particles in the heliosphere",
            "updated": "2023-11-01T13:11:53Z",
            "published": "2023-11-01T13:11:53Z",
            "summary": "Interstellar dust (ISD) particles penetrate the solar system due to the\nrelative motion of the Sun and the local interstellar cloud. Before entering\nthe heliosphere, they pass through the heliospheric interface - the region of\nthe solar wind interaction with the interstellar plasma. The size distribution\nand number density of dust grains are modified in the interface essentially.\nThe modification depends on the charging of the dust particles along their\ntrajectories. In this paper, we present modeling results of the charging of ISD\nparticles passing through the heliospheric interface. The main physical\nprocesses responsible for the charging within the heliospheric conditions are\nthe sticking of primary plasma particles, secondary electron emission,\nphotoemission, and the effects of cosmic ray electrons. We consider two methods\nto calculate the electric charge of ISD particles based on (1) the classic\nsteady-state assumption that the charge depends only on local plasma and\nradiation conditions and (2) the dynamical computation of charge along the\nparticle trajectory. We demonstrate that the steady-state assumption is quite\njustified to model trajectories and number density distributions of relatively\nbig ISD grains (radius of 100 nm and larger) penetrating the heliosphere. The\nestimates show that ISD grains of these sizes require less than 0.25 years\n(distance of ~ 1 au) after transition from the LISM into the heliosphere to\nreach an equilibrium. For small particles (radius of 10 nm), the dynamical\ncomputation of charge influences the trajectories and modifies the number\ndensity substantially. The dust density accumulations are distributed within a\nmore elongated region along the heliopause in case of dynamically changed\ncharge as compared with the use of a steady-state charge approximation.",
            "author": [
                "E. A. Godenko",
                "V. V. Izmodenov"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.asr.2023.09.016",
                "http://arxiv.org/abs/2311.00505v1",
                "http://arxiv.org/pdf/2311.00505v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP",
                "astro-ph.GA",
                "physics.plasm-ph",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00503v1",
            "title": "Ray computational ghost imaging based on rotational modulation method",
            "updated": "2023-11-01T13:10:11Z",
            "published": "2023-11-01T13:10:11Z",
            "summary": "The CGI (CGI) has the potential of low cost, low dose, and high resolution,\nwhich is very attractive for the development of radiation imaging field.\nHowever, many sub-coding plates must be used in the modulation process, which\ngreatly affects the development of CGI technology. In order to reduce the\ncoding plates, we refer to the rotation method of computed tomography (CT),\nthen propose a novel CGI method based on rotational modulation method of a\nsingle-column striped coding plate. This method utilizes the spatial variation\nof a single sub-coding plate (rotation) to realize multiple modulation of the\nray field and improves the utilization rate of a single sub-coding plate.\nHowever, for this rotation scheme of CGI, the traditional binary modulation\nmatrix is no longer applicable. To obtain the system matrix of the rotated\nstriped coding plate, an area model based on beam boundaries is established.\nSubsequently, numerical and Monte Carlo simulations were conducted. The results\nreveal that our scheme enables high-quality imaging of N*N resolution objects\nusing only N sub-coding plates, under both full-sampling and under-sampling\nscenarios. Moreover, our scheme demonstrates superiority over the Hadamard\nscheme in both imaging quality and the number of required sub-coding plates,\nwhether in scenarios of full-sampling or under-sampling. Finally, an {\\alpha}\nray imaging platform was established to further demonstrate the feasibility of\nthe rotational modulation method. By employing our scheme, a mere 8 sub-coding\nplates were employed to achieve CGI of the radiation source intensity\ndistribution, achieving a resolution of 8*8. Therefore, the novel ray CGI based\non rotational modulation method can achieve high-quality imaging effect with\nfewer sub-coding plates, which has important practical value and research\nsignificance for promoting single-pixel radiation imaging technology.",
            "author": [
                "Zhi Zhou",
                "Sangang Li",
                "Shan Liao",
                "Sirun Gong",
                "Rongrong Su",
                "Chuxiang Zhao",
                "Li Yang",
                "Qi Liu",
                "Yucheng Yan",
                "Mingzhe Liu",
                "Yi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00503v1",
                "http://arxiv.org/pdf/2311.00503v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00502v2",
            "title": "Efficient LLM Inference on CPUs",
            "updated": "2023-12-07T12:16:42Z",
            "published": "2023-11-01T13:08:50Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable performance and\ntremendous potential across a wide range of tasks. However, deploying these\nmodels has been challenging due to the astronomical amount of model parameters,\nwhich requires a demand for large memory capacity and high memory bandwidth. In\nthis paper, we propose an effective approach that can make the deployment of\nLLMs more efficiently. We support an automatic INT4 weight-only quantization\nflow and design a special LLM runtime with highly-optimized kernels to\naccelerate the LLM inference on CPUs. We demonstrate the general applicability\nof our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase\nthe extreme inference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.",
            "author": [
                "Haihao Shen",
                "Hanwen Chang",
                "Bo Dong",
                "Yu Luo",
                "Hengyu Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00502v2",
                "http://arxiv.org/pdf/2311.00502v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00500v1",
            "title": "Intriguing Properties of Data Attribution on Diffusion Models",
            "updated": "2023-11-01T13:00:46Z",
            "published": "2023-11-01T13:00:46Z",
            "summary": "Data attribution seeks to trace model outputs back to training data. With the\nrecent development of diffusion models, data attribution has become a desired\nmodule to properly assign valuations for high-quality or copyrighted training\nsamples, ensuring that data contributors are fairly compensated or credited.\nSeveral theoretically motivated methods have been proposed to implement data\nattribution, in an effort to improve the trade-off between computational\nscalability and effectiveness. In this work, we conduct extensive experiments\nand ablation studies on attributing diffusion models, specifically focusing on\nDDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model\nLoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive\nobservations that theoretically unjustified design choices for attribution\nempirically outperform previous baselines by a large margin, in terms of both\nlinear datamodeling score and counterfactual evaluation. Our work presents a\nsignificantly more efficient approach for attributing diffusion models, while\nthe unexpected findings suggest that at least in non-convex settings,\nconstructions guided by theoretical assumptions may lead to inferior\nattribution performance. The code is available at\nhttps://github.com/sail-sg/D-TRAK.",
            "author": [
                "Xiaosen Zheng",
                "Tianyu Pang",
                "Chao Du",
                "Jing Jiang",
                "Min Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00500v1",
                "http://arxiv.org/pdf/2311.00500v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00495v1",
            "title": "Studying the production mechanisms of light meson resonances in two-pion\n  photoproduction",
            "updated": "2023-11-01T12:51:49Z",
            "published": "2023-11-01T12:51:49Z",
            "summary": "A theoretical model of two-pion photoproduction is presented. The model\nencodes the prominent $\\rho(770)$ resonance and the expected leading background\ncontribution coming from the Deck mechanism. To validate the model, angular\nmoments are computed and compared with the CLAS dataset. After fitting a number\nof free parameters, the model provides a good description of the data.",
            "author": [
                "\u0141ukasz Bibrzycki",
                "Nadine Hammoud",
                "Vincent Mathieu",
                "Robert J. Perry",
                "Adam P. Szczepaniak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00495v1",
                "http://arxiv.org/pdf/2311.00495v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00494v2",
            "title": "Symmetry-Resolved Entanglement Entropy for Local and Non-local QFTs",
            "updated": "2023-11-11T12:59:36Z",
            "published": "2023-11-01T12:51:37Z",
            "summary": "In this paper, we study symmetry-resolved entanglement entropy in free\nbosonic quantum many-body systems. Precisely, by making use of the lattice\nregularization scheme, we compute symmetry-resolved R\\'enyi entropies for free\ncomplex scalar fields as well as for a simple class of non-local field theories\nin which entanglement entropy exhibits volume-law scaling. We present effective\nand approximate eigenvalues for the correlation matrix used to compute the\nsymmetry-resolved entanglement entropy and show that they are consistent with\nthe numerical results. Furthermore, we explore the equipartition of\nentanglement entropy and verify an effective equipartition in the massless\nlimit. Finally, we make a comment on the entanglement entropy in the non-local\nquantum field theories and write down an explicit expression for the\nsymmetry-resolved R\\'enyi entropies.",
            "author": [
                "Reza Pirmoradian",
                "Mohammad Reza Tanhayi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00494v2",
                "http://arxiv.org/pdf/2311.00494v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00492v1",
            "title": "Evaluating scattering amplitudes with pySecDec 1.6",
            "updated": "2023-11-01T12:48:08Z",
            "published": "2023-11-01T12:48:08Z",
            "summary": "pSecDec is a computer tool to evaluate Feynman integrals and their weighted\nsums (amplitudes) using the method of sector decomposition and numerical\nintegration. The new release of pySecDec version 1.6 comes with a significant\nperformance boost (3x-9x in common scenarios), and new features to make the\nevaluation and asymptotic expansion of amplitudes and integrals easier and\nfaster. In this article we briefly review these features.",
            "author": [
                "Vitaly Magerya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00492v1",
                "http://arxiv.org/pdf/2311.00492v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00490v1",
            "title": "Accelerated particle beams in a 3D simulation of the quiet Sun. Effects\n  of advanced beam propagation modelling",
            "updated": "2023-11-01T12:46:14Z",
            "published": "2023-11-01T12:46:14Z",
            "summary": "Charged particles are constantly accelerated to non-thermal energies by the\nreconnecting magnetic field in the solar atmosphere. Our understanding of the\ninteractions between the particles and their environment can benefit from\nthree-dimensional atmospheric simulations accounting for non-thermal particle\nbeams. In a previous publication, we presented the first results from such a\nsimulation. However, the original treatment of beam propagation ignores\npotentially important phenomena. Here, we present a more general beam\npropagation model incorporating magnetic gradient forces, the return current,\nacceleration by the ambient electric field, and temperature-dependent collision\nrates. Neglecting collisional velocity randomisation makes the model\nsufficiently lightweight to simulate millions of beams. We investigate how each\nnew physical effect changes beam energy transport in a three-dimensional\natmosphere. We applied the method of characteristics to the steady-state\ncontinuity equation for electron flux to derive ordinary differential equations\nfor the mean evolution of energy, pitch angle, and flux with distance. For each\nbeam, we solved these numerically for a range of initial energies to obtain the\nevolving flux spectrum, from which we computed the energy deposited into the\nambient plasma. Magnetic gradient forces significantly influence the deposition\nof beam energy. The strong magnetic field convergence leads to a small coronal\ndeposition peak followed by a heavy dip caused by the onset of magnetic\nmirroring. Mirrored electrons carry away 5 to 10% of the injected beam energy\non average. The transition region peak produced by the remaining energetic\nelectrons occurs slightly deeper than in a uniform magnetic field. An initial\ndiverging magnetic field enhances the subsequent impact of mirroring. The other\nnew physical effects are less significant for the studied atmospheric\nconditions.",
            "author": [
                "L. Frogner",
                "B. V. Gudiksen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00490v1",
                "http://arxiv.org/pdf/2311.00490v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00489v2",
            "title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn\n  Supra-Segmental Temporal Features",
            "updated": "2023-11-02T06:07:14Z",
            "published": "2023-11-01T12:45:31Z",
            "summary": "While deep neural networks have shown impressive results in automatic speaker\nrecognition and related tasks, it is dissatisfactory how little is understood\nabout what exactly is responsible for these results. Part of the success has\nbeen attributed in prior work to their capability to model supra-segmental\ntemporal information (SST), i.e., learn rhythmic-prosodic characteristics of\nspeech in addition to spectral features. In this paper, we (i) present and\napply a novel test to quantify to what extent the performance of\nstate-of-the-art neural networks for speaker recognition can be explained by\nmodeling SST; and (ii) present several means to force respective nets to focus\nmore on SST and evaluate their merits. We find that a variety of CNN- and\nRNN-based neural network architectures for speaker recognition do not model SST\nto any sufficient degree, even when forced. The results provide a highly\nrelevant basis for impactful future research into better exploitation of the\nfull speech signal and give insights into the inner workings of such networks,\nenhancing explainability of deep learning for speech technologies.",
            "author": [
                "Daniel Neururer",
                "Volker Dellwo",
                "Thilo Stadelmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00489v2",
                "http://arxiv.org/pdf/2311.00489v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00488v1",
            "title": "Comparing Optimization Targets for Contrast-Consistent Search",
            "updated": "2023-11-01T12:42:14Z",
            "published": "2023-11-01T12:42:14Z",
            "summary": "We investigate the optimization target of Contrast-Consistent Search (CCS),\nwhich aims to recover the internal representations of truth of a large language\nmodel. We present a new loss function that we call the Midpoint-Displacement\n(MD) loss function. We demonstrate that for a certain hyper-parameter value\nthis MD loss function leads to a prober with very similar weights to CCS. We\nfurther show that this hyper-parameter is not optimal and that with a better\nhyper-parameter the MD loss function attains a higher test accuracy than CCS.",
            "author": [
                "Hugo Fry",
                "Seamus Fallows",
                "Ian Fan",
                "Jamie Wright",
                "Nandi Schoots"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00488v1",
                "http://arxiv.org/pdf/2311.00488v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00487v1",
            "title": "Echo-evolution data generation for quantum error mitigation via neural\n  networks",
            "updated": "2023-11-01T12:40:10Z",
            "published": "2023-11-01T12:40:10Z",
            "summary": "Neural networks provide a prospective tool for error mitigation in quantum\nsimulation of physical systems. However, we need both noisy and noise-free data\nto train neural networks to mitigate errors in quantum computing results. Here,\nwe propose a physics-motivated method to generate training data for quantum\nerror mitigation via neural networks, which does not require classical\nsimulation and target circuit simplification. In particular, we propose to use\nthe echo evolution of a quantum system to collect noisy and noise-free data for\ntraining a neural network. Under this method, the initial state evolves forward\nand backward in time, returning to the initial state at the end of evolution.\nWhen run on the noisy quantum processor, the resulting state will be influenced\nby with quantum noise accumulated during evolution. Having a vector of\nobservable values of the initial (noise-free) state and the resulting (noisy)\nstate allows us to compose training data for a neural network. We demonstrate\nthat a feed-forward fully connected neural network trained on\necho-evolution-generated data can correct results of forward-in-time evolution.\nOur findings can enhance the application of neural networks to error mitigation\nin quantum computing.",
            "author": [
                "D. V. Babukhin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00487v1",
                "http://arxiv.org/pdf/2311.00487v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00484v1",
            "title": "A unifying Rayleigh-Plesset-type equation for bubbles in viscoelastic\n  media",
            "updated": "2023-11-01T12:35:48Z",
            "published": "2023-11-01T12:35:48Z",
            "summary": "Understanding the ultrasound pressure-driven dynamics of microbubbles\nconfined in viscoelastic materials is relevant for multiple biomedical\napplications, ranging from contrast-enhanced ultrasound imaging to\nultrasound-assisted drug delivery. The volumetric oscillations of spherical\nbubbles is analyzed using the Rayleigh-Plesset equation, which describes the\nconservation of mass and momentum in the surrounding medium. Several studies\nhave considered an extension of the Rayleigh-Plesset equation for bubbles\nembedded into viscoelastic media, but these are restricted to a particular\nchoice of constitutive model and/or to small deformations. Here, we derive a\nunifying equation applicable to bubbles in viscoelastic media with arbitrary\ncomplex moduli and that can account for large bubble deformations. To derive\nthis equation, we borrow concepts from finite-strain theory. We validate our\napproach by comparing the result of our model to previously published results\nand extend it to show how microbubbles behave in arbitrary viscoelastic\nmaterials. In particular, we use our viscoelastic Rayleigh-Plesset model to\ncompute the bubble dynamics in benchmarked viscoelastic liquids and solids.",
            "author": [
                "Alexandros T. Oratis",
                "Kay Dijs",
                "Guillaume Lajoinie",
                "Michel Versluis",
                "Jacco H. Snoeijer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00484v1",
                "http://arxiv.org/pdf/2311.00484v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00483v1",
            "title": "DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional\n  Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and\n  Dynamic Weight Composition",
            "updated": "2023-11-01T12:33:04Z",
            "published": "2023-11-01T12:33:04Z",
            "summary": "The spatial and quantitative parameters of macular holes are vital for\ndiagnosis, surgical choices, and post-op monitoring. Macular hole diagnosis and\ntreatment rely heavily on spatial and quantitative data, yet the scarcity of\nsuch data has impeded the progress of deep learning techniques for effective\nsegmentation and real-time 3D reconstruction. To address this challenge, we\nassembled the world's largest macular hole dataset, Retinal OCTfor Macular Hole\nEnhancement (ROME-3914), and a Comprehensive Archive for Retinal Segmentation\n(CARS-30k), both expertly annotated. In addition, we developed an innovative 3D\nsegmentation network, the Dual-Encoder FuGH Network (DEFN), which integrates\nthree innovative modules: Fourier Group Harmonics (FuGH), Simplified 3D Spatial\nAttention (S3DSA) and Harmonic Squeeze-and-Excitation Module (HSE). These three\nmodules synergistically filter noise, reduce computational complexity,\nemphasize detailed features, and enhance the network's representation ability.\nWe also proposed a novel data augmentation method, Stochastic Retinal Defect\nInjection (SRDI), and a network optimization strategy DynamicWeightCompose\n(DWC), to further improve the performance of DEFN. Compared with 13 baselines,\nour DEFN shows the best performance. We also offer precise 3D retinal\nreconstruction and quantitative metrics, bringing revolutionary diagnostic and\ntherapeutic decision-making tools for ophthalmologists, and is expected to\ncompletely reshape the diagnosis and treatment patterns of difficult-to-treat\nmacular degeneration. The source code is publicly available at:\nhttps://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch.",
            "author": [
                "Xingru Huang",
                "Yihao Guo",
                "Jian Huang",
                "Zhi Li",
                "Tianyun Zhang",
                "Kunyan Cai",
                "Gaopeng Huang",
                "Wenhao Chen",
                "Zhaoyang Xu",
                "Liangqiong Qu",
                "Ji Hu",
                "Tinyu Wang",
                "Shaowei Jiang",
                "Chenggang Yan",
                "Yaoqi Sun",
                "Xin Ye",
                "Yaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00483v1",
                "http://arxiv.org/pdf/2311.00483v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "68, 92",
                "I.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00476v1",
            "title": "Group Distributionally Robust Knowledge Distillation",
            "updated": "2023-11-01T12:25:02Z",
            "published": "2023-11-01T12:25:02Z",
            "summary": "Knowledge distillation enables fast and effective transfer of features\nlearned from a bigger model to a smaller one. However, distillation objectives\nare susceptible to sub-population shifts, a common scenario in medical imaging\nanalysis which refers to groups/domains of data that are underrepresented in\nthe training set. For instance, training models on health data acquired from\nmultiple scanners or hospitals can yield subpar performance for minority\ngroups. In this paper, inspired by distributionally robust optimization (DRO)\ntechniques, we address this shortcoming by proposing a group-aware distillation\nloss. During optimization, a set of weights is updated based on the per-group\nlosses at a given iteration. This way, our method can dynamically focus on\ngroups that have low performance during training. We empirically validate our\nmethod, GroupDistil on two benchmark datasets (natural images and cardiac MRIs)\nand show consistent improvement in terms of worst-group accuracy.",
            "author": [
                "Konstantinos Vilouras",
                "Xiao Liu",
                "Pedro Sanchez",
                "Alison Q. O'Neil",
                "Sotirios A. Tsaftaris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00476v1",
                "http://arxiv.org/pdf/2311.00476v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00475v1",
            "title": "Style Locality for Controllable Generation with kNN Language Models",
            "updated": "2023-11-01T12:21:53Z",
            "published": "2023-11-01T12:21:53Z",
            "summary": "Recent language models have been improved by the addition of external memory.\nNearest neighbor language models retrieve similar contexts to assist in word\nprediction. The addition of locality levels allows a model to learn how to\nweight neighbors based on their relative location to the current text in source\ndocuments, and have been shown to further improve model performance. Nearest\nneighbor models have been explored for controllable generation but have not\nexamined the use of locality levels. We present a novel approach for this\npurpose and evaluate it using automatic and human evaluation on politeness,\nformality, supportiveness, and toxicity textual data. We find that our model is\nsuccessfully able to control style and provides a better fluency-style\ntrade-off than previous work.",
            "author": [
                "Gilles Nawezi",
                "Lucie Flek",
                "Charles Welch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00475v1",
                "http://arxiv.org/pdf/2311.00475v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00474v2",
            "title": "Diffusion models for probabilistic programming",
            "updated": "2023-11-21T20:16:57Z",
            "published": "2023-11-01T12:17:05Z",
            "summary": "We propose Diffusion Model Variational Inference (DMVI), a novel method for\nautomated approximate inference in probabilistic programming languages (PPLs).\nDMVI utilizes diffusion models as variational approximations to the true\nposterior distribution by deriving a novel bound to the marginal likelihood\nobjective used in Bayesian modelling. DMVI is easy to implement, allows\nhassle-free inference in PPLs without the drawbacks of, e.g., variational\ninference using normalizing flows, and does not make any constraints on the\nunderlying neural network model. We evaluate DMVI on a set of common Bayesian\nmodels and show that its posterior inferences are in general more accurate than\nthose of contemporary methods used in PPLs while having a similar computational\ncost and requiring less manual tuning.",
            "author": [
                "Simon Dirmeier",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00474v2",
                "http://arxiv.org/pdf/2311.00474v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10748v1",
            "title": "An international treaty to implement a global compute cap for advanced\n  artificial intelligence",
            "updated": "2023-11-01T12:11:56Z",
            "published": "2023-11-01T12:11:56Z",
            "summary": "This paper presents an international treaty to reduce risks from the\ndevelopment of advanced artificial intelligence (AI). The main provision of the\ntreaty is a global compute cap: a ban on the development of AI systems above an\nagreed-upon computational resource threshold. The treaty also proposes the\ndevelopment and testing of emergency response plans, negotiations to establish\nan international agency to enforce the treaty, the establishment of new\ncommunication channels and whistleblower protections, and a commitment to avoid\nan AI arms race. We hope this treaty serves as a useful template for global\nleaders as they implement governance regimes to protect civilization from the\ndangers of advanced artificial intelligence.",
            "author": [
                "Andrea Miotti",
                "Akash Wasil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10748v1",
                "http://arxiv.org/pdf/2311.10748v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00469v1",
            "title": "Dual Conditioned Diffusion Models for Out-Of-Distribution Detection:\n  Application to Fetal Ultrasound Videos",
            "updated": "2023-11-01T12:10:55Z",
            "published": "2023-11-01T12:10:55Z",
            "summary": "Out-of-distribution (OOD) detection is essential to improve the reliability\nof machine learning models by detecting samples that do not belong to the\ntraining distribution. Detecting OOD samples effectively in certain tasks can\npose a challenge because of the substantial heterogeneity within the\nin-distribution (ID), and the high structural similarity between ID and OOD\nclasses. For instance, when detecting heart views in fetal ultrasound videos\nthere is a high structural similarity between the heart and other anatomies\nsuch as the abdomen, and large in-distribution variance as a heart has 5\ndistinct views and structural variations within each view. To detect OOD\nsamples in this context, the resulting model should generalise to the\nintra-anatomy variations while rejecting similar OOD samples. In this paper, we\nintroduce dual-conditioned diffusion models (DCDM) where we condition the model\non in-distribution class information and latent features of the input image for\nreconstruction-based OOD detection. This constrains the generative manifold of\nthe model to generate images structurally and semantically similar to those\nwithin the in-distribution. The proposed model outperforms reference methods\nwith a 12% improvement in accuracy, 22% higher precision, and an 8% better F1\nscore.",
            "author": [
                "Divyanshu Mishra",
                "He Zhao",
                "Pramit Saha",
                "Aris T. Papageorghiou",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00469v1",
                "http://arxiv.org/pdf/2311.00469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00467v1",
            "title": "Hofer-Zehnder capacity of magnetic disc tangent bundles over constant\n  curvature surfaces",
            "updated": "2023-11-01T12:07:53Z",
            "published": "2023-11-01T12:07:53Z",
            "summary": "We compute the Hofer-Zehnder capacity of magnetic disc tangent bundles over\nconstant curvature surfaces. We use the fact that the magnetic geodesic flow is\ntotally periodic and can be reparametrized to obtain a Hamiltonian circle\naction. The oscillation of the Hamiltonian generating the circle action\nimmediately yields a lower bound of the Hofer-Zehnder capacity. The upper bound\nis obtained from Lu's bounds of the Hofer-Zehnder capacity using the theory of\npseudo-holomorphic curves. In our case the gradient spheres of the Hamiltonian\nwill give rise to the non-vanishing Gromov-Witten invariant needed.",
            "author": [
                "Johanna Bimmermann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00467v1",
                "http://arxiv.org/pdf/2311.00467v1"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02171v1",
            "title": "LpiCT: A logic security analysis framework for protocols",
            "updated": "2023-11-01T12:06:47Z",
            "published": "2023-11-01T12:06:47Z",
            "summary": "The pi calculus is a basic theory of mobile communication based on the notion\nof interaction, which, aimed at analyzing and modelling the behaviors of\ncommunication process in communicating and mobile systems, is widely applied to\nthe security analysis of cryptographic protocol's design and implementation.\nBut the pi calculus does not provide perfect logic security analysis, so the\nlogic flaws in the design and the implementation of a cryptographic protocol\ncan not be discovered in time. The aim is to analyze whether there are logic\nflaws in the design and the implementation of a cryptographic protocol, so as\nto ensure the security of the cryptographic protocol when it is encoded into a\nsoftware and implemented. This paper introduces logic rules and proofs, binary\ntree and the KMP algorithm, and proposes a new extension the pi calculus\ntheory, a logic security analysis framework and an algorithm. This paper\npresents the logic security proof and analysis of TLS1.3 protocol's\ninteractional implementation process. Empirical results show that the new\nextension theory, the logic security analysis framework and the algorithm can\neffectively analyze whether there are logic flaws in the design and the\nimplementation of a cryptographic protocol. The security of cryptographic\nprotocols depends not only on cryptographic primitives, but also on the coding\nof cryptographic protocols and the environment in which they are implemented.\nThe security analysis framework of cryptographic protocol implementation\nproposed in this paper can ensure the security of protocol implementation.",
            "author": [
                "Fusheng Wu",
                "Jinhui Liu",
                "Yanbing Li",
                "Mingtao Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02171v1",
                "http://arxiv.org/pdf/2312.02171v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00735v2",
            "title": "PET Tracer Conversion among Brain PET via Variable Augmented Invertible\n  Network",
            "updated": "2023-11-15T07:28:10Z",
            "published": "2023-11-01T12:04:33Z",
            "summary": "Positron emission tomography (PET) serves as an essential tool for diagnosis\nof encephalopathy and brain science research. However, it suffers from the\nlimited choice of tracers. Nowadays, with the wide application of PET imaging\nin neuropsychiatric treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine\n(DOPA) has been found to be more effective than 18F-labeled\nfluorine-2-deoxyglucose (FDG) in the field. Nevertheless, due to the complexity\nof its preparation and other limitations, DOPA is far less widely used than\nFDG. To address this issue, a tracer conversion invertible neural network\n(TC-INN) for image projection is developed to map FDG images to DOPA images\nthrough deep learning. More diagnostic information is obtained by generating\nPET images from FDG to DOPA. Specifically, the proposed TC-INN consists of two\nseparate phases, one for training traceable data, the other for rebuilding new\ndata. The reference DOPA PET image is used as a learning target for the\ncorresponding network during the training process of tracer conversion.\nMeanwhile, the invertible network iteratively estimates the resultant DOPA PET\ndata and compares it to the reference DOPA PET data. Notably, the reversible\nmodel employs variable enhancement technique to achieve better power\ngeneration. Moreover, image registration needs to be performed before training\ndue to the angular deviation of the acquired FDG and DOPA data information.\nExperimental results exhibited excellent generation capability in mapping\nbetween FDG and DOPA, suggesting that PET tracer conversion has great potential\nin the case of limited tracer applications.",
            "author": [
                "Bohui Shen",
                "Wei Zhang",
                "Xubiao Liu",
                "Pengfei Yu",
                "Shirui Jiang",
                "Xinchong Shi",
                "Xiangsong Zhang",
                "Xiaoyu Zhou",
                "Weirui Zhang",
                "Bingxuan Li",
                "Qiegen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00735v2",
                "http://arxiv.org/pdf/2311.00735v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "68T01"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00466v2",
            "title": "Parameterized covering in semi-ladder-free hypergraphs",
            "updated": "2023-11-08T16:11:44Z",
            "published": "2023-11-01T12:02:26Z",
            "summary": "In this article, we study the parameterized complexity of the Set Cover\nproblem restricted to semi-ladder-free hypergraphs, a class defined by\nFabianski et al. [Proceedings of STACS 2019]. We observe that two algorithms\nintroduced by Langerman and Morin [Discrete & Computational Geometry 2005] in\nthe context of geometric covering problems can be adapted to this setting,\nyielding simple FPT and kernelization algorithms for Set Cover in\nsemi-ladder-free hypergraphs. We complement our algorithmic results with a\ncompression lower bound for the problem, which proves the tightness of our\nkernelization under standard complexity-theoretic assumptions.",
            "author": [
                "Sylvain Guillemot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00466v2",
                "http://arxiv.org/pdf/2311.00466v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00465v1",
            "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous\n  Decentralized and Federated Optimization",
            "updated": "2023-11-01T11:58:16Z",
            "published": "2023-11-01T11:58:16Z",
            "summary": "Decentralized and asynchronous communications are two popular techniques to\nspeedup communication complexity of distributed machine learning, by\nrespectively removing the dependency over a central orchestrator and the need\nfor synchronization. Yet, combining these two techniques together still remains\na challenge. In this paper, we take a step in this direction and introduce\nAsynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that\ncovers asynchronous versions of many popular algorithms including SGD,\nDecentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and\ncomputation assumptions. We provide rates of convergence under much milder\nassumptions than previous decentralized asynchronous works, while still\nrecovering or even improving over the best know results for all the algorithms\ncovered.",
            "author": [
                "Mathieu Even",
                "Anastasia Koloskova",
                "Laurent Massouli\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00465v1",
                "http://arxiv.org/pdf/2311.00465v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00457v1",
            "title": "Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture",
            "updated": "2023-11-01T11:46:15Z",
            "published": "2023-11-01T11:46:15Z",
            "summary": "Reconstructing detailed 3D scenes from single-view images remains a\nchallenging task due to limitations in existing approaches, which primarily\nfocus on geometric shape recovery, overlooking object appearances and fine\nshape details. To address these challenges, we propose a novel framework for\nsimultaneous high-fidelity recovery of object shapes and textures from\nsingle-view images. Our approach utilizes the proposed Single-view neural\nimplicit Shape and Radiance field (SSR) representations to leverage both\nexplicit 3D shape supervision and volume rendering of color, depth, and surface\nnormal images. To overcome shape-appearance ambiguity under partial\nobservations, we introduce a two-stage learning curriculum incorporating both\n3D and 2D supervisions. A distinctive feature of our framework is its ability\nto generate fine-grained textured meshes while seamlessly integrating rendering\ncapabilities into the single-view 3D reconstruction model. This integration\nenables not only improved textured 3D object reconstruction by 27.7% and 11.6%\non the 3D-FRONT and Pix3D datasets, respectively, but also supports the\nrendering of images from novel viewpoints. Beyond individual objects, our\napproach facilitates composing object-level representations into flexible scene\nrepresentations, thereby enabling applications such as holistic scene\nunderstanding and 3D scene editing. We conduct extensive experiments to\ndemonstrate the effectiveness of our method.",
            "author": [
                "Yixin Chen",
                "Junfeng Ni",
                "Nan Jiang",
                "Yaowei Zhang",
                "Yixin Zhu",
                "Siyuan Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00457v1",
                "http://arxiv.org/pdf/2311.00457v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00455v1",
            "title": "Progressive Recurrent Network for Shadow Removal",
            "updated": "2023-11-01T11:42:45Z",
            "published": "2023-11-01T11:42:45Z",
            "summary": "Single-image shadow removal is a significant task that is still unresolved.\nMost existing deep learning-based approaches attempt to remove the shadow\ndirectly, which can not deal with the shadow well. To handle this issue, we\nconsider removing the shadow in a coarse-to-fine fashion and propose a simple\nbut effective Progressive Recurrent Network (PRNet). The network aims to remove\nthe shadow progressively, enabing us to flexibly adjust the number of\niterations to strike a balance between performance and time. Our network\ncomprises two parts: shadow feature extraction and progressive shadow removal.\nSpecifically, the first part is a shallow ResNet which constructs the\nrepresentations of the input shadow image on its original size, preventing the\nloss of high-frequency details caused by the downsampling operation. The second\npart has two critical components: the re-integration module and the update\nmodule. The proposed re-integration module can fully use the outputs of the\nprevious iteration, providing input for the update module for further shadow\nremoval. In this way, the proposed PRNet makes the whole process more concise\nand only uses 29% network parameters than the best published method. Extensive\nexperiments on the three benchmarks, ISTD, ISTD+, and SRD, demonstrate that our\nmethod can effectively remove shadows and achieve superior performance.",
            "author": [
                "Yonghui Wang",
                "Wengang Zhou",
                "Hao Feng",
                "Li Li",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00455v1",
                "http://arxiv.org/pdf/2311.00455v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00453v1",
            "title": "CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly\n  Detection",
            "updated": "2023-11-01T11:39:22Z",
            "published": "2023-11-01T11:39:22Z",
            "summary": "This paper considers zero-shot Anomaly Detection (AD), a valuable yet\nunder-studied task, which performs AD without any reference images of the test\nobjects. Specifically, we employ a language-guided strategy and propose a\nsimple-yet-effective architecture CLIP-AD, leveraging the superior zero-shot\nclassification capabilities of the large vision-language model CLIP. A natural\nidea for anomaly segmentation is to directly calculate the similarity between\ntext/image features, but we observe opposite predictions and irrelevant\nhighlights in the results. Inspired by the phenomena, we introduce a Staged\nDual-Path model (SDP) that effectively uses features from various levels and\napplies architecture and feature surgery to address these issues. Furthermore,\ndelving beyond surface phenomena, we identify the problem arising from\nmisalignment of text/image features in the joint embedding space. Thus, we\nintroduce a fine-tuning strategy by adding linear layers and construct an\nextended model SDP+, further enhancing the performance. Abundant experiments\ndemonstrate the effectiveness of our approach, e.g., on VisA, SDP outperforms\nSOTA by +1.0/+1.2 in classification/segmentation F1 scores, while SDP+ achieves\n+1.9/+11.7 improvements.",
            "author": [
                "Xuhai Chen",
                "Jiangning Zhang",
                "Guanzhong Tian",
                "Haoyang He",
                "Wuhao Zhang",
                "Yabiao Wang",
                "Chengjie Wang",
                "Yunsheng Wu",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00453v1",
                "http://arxiv.org/pdf/2311.00453v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00451v1",
            "title": "Discourse Relations Classification and Cross-Framework Discourse\n  Relation Classification Through the Lens of Cognitive Dimensions: An\n  Empirical Investigation",
            "updated": "2023-11-01T11:38:19Z",
            "published": "2023-11-01T11:38:19Z",
            "summary": "Existing discourse formalisms use different taxonomies of discourse\nrelations, which require expert knowledge to understand, posing a challenge for\nannotation and automatic classification. We show that discourse relations can\nbe effectively captured by some simple cognitively inspired dimensions proposed\nby Sanders et al.(2018). Our experiments on cross-framework discourse relation\nclassification (PDTB & RST) demonstrate that it is possible to transfer\nknowledge of discourse relations for one framework to another framework by\nmeans of these dimensions, in spite of differences in discourse segmentation of\nthe two frameworks. This manifests the effectiveness of these dimensions in\ncharacterizing discourse relations across frameworks. Ablation studies reveal\nthat different dimensions influence different types of discourse relations. The\npatterns can be explained by the role of dimensions in characterizing and\ndistinguishing different relations. We also report our experimental results on\nautomatic prediction of these dimensions.",
            "author": [
                "Yingxue Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00451v1",
                "http://arxiv.org/pdf/2311.00451v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00734v2",
            "title": "On Manipulating Scene Text in the Wild with Diffusion Models",
            "updated": "2023-11-03T10:11:52Z",
            "published": "2023-11-01T11:31:50Z",
            "summary": "Diffusion models have gained attention for image editing yielding impressive\nresults in text-to-image tasks. On the downside, one might notice that\ngenerated images of stable diffusion models suffer from deteriorated details.\nThis pitfall impacts image editing tasks that require information preservation\ne.g., scene text editing. As a desired result, the model must show the\ncapability to replace the text on the source image to the target text while\npreserving the details e.g., color, font size, and background. To leverage the\npotential of diffusion models, in this work, we introduce Diffusion-BasEd Scene\nText manipulation Network so-called DBEST. Specifically, we design two\nadaptation strategies, namely one-shot style adaptation and text-recognition\nguidance. In experiments, we thoroughly assess and compare our proposed method\nagainst state-of-the-arts on various scene text datasets, then provide\nextensive ablation studies for each granularity to analyze our performance\ngain. Also, we demonstrate the effectiveness of our proposed method to\nsynthesize scene text indicated by competitive Optical Character Recognition\n(OCR) accuracy. Our method achieves 94.15% and 98.12% on COCO-text and\nICDAR2013 datasets for character-level evaluation.",
            "author": [
                "Joshua Santoso",
                "Christian Simon",
                "Williem Pao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00734v2",
                "http://arxiv.org/pdf/2311.00734v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00447v3",
            "title": "On the Opportunities of Green Computing: A Survey",
            "updated": "2023-11-09T03:08:34Z",
            "published": "2023-11-01T11:16:41Z",
            "summary": "Artificial Intelligence (AI) has achieved significant advancements in\ntechnology and research with the development over several decades, and is\nwidely used in many areas including computing vision, natural language\nprocessing, time-series analysis, speech synthesis, etc. During the age of deep\nlearning, especially with the arise of Large Language Models, a large majority\nof researchers' attention is paid on pursuing new state-of-the-art (SOTA)\nresults, resulting in ever increasing of model size and computational\ncomplexity. The needs for high computing power brings higher carbon emission\nand undermines research fairness by preventing small or medium-sized research\ninstitutions and companies with limited funding in participating in research.\nTo tackle the challenges of computing resources and environmental impact of AI,\nGreen Computing has become a hot research topic. In this survey, we give a\nsystematic overview of the technologies used in Green Computing. We propose the\nframework of Green Computing and devide it into four key components: (1)\nMeasures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing\nSystems and (4) AI Use Cases for Sustainability. For each components, we\ndiscuss the research progress made and the commonly used techniques to optimize\nthe AI efficiency. We conclude that this new research direction has the\npotential to address the conflicts between resource constraints and AI\ndevelopment. We encourage more researchers to put attention on this direction\nand make AI more environmental friendly.",
            "author": [
                "You Zhou",
                "Xiujing Lin",
                "Xiang Zhang",
                "Maolin Wang",
                "Gangwei Jiang",
                "Huakang Lu",
                "Yupeng Wu",
                "Kai Zhang",
                "Zhe Yang",
                "Kehang Wang",
                "Yongduo Sui",
                "Fengwei Jia",
                "Zuoli Tang",
                "Yao Zhao",
                "Hongxuan Zhang",
                "Tiannuo Yang",
                "Weibo Chen",
                "Yunong Mao",
                "Yi Li",
                "De Bao",
                "Yu Li",
                "Hongrui Liao",
                "Ting Liu",
                "Jingwen Liu",
                "Jinchi Guo",
                "Xiangyu Zhao",
                "Ying WEI",
                "Hong Qian",
                "Qi Liu",
                "Xiang Wang",
                "Wai Kin",
                "Chan",
                "Chenliang Li",
                "Yusen Li",
                "Shiyu Yang",
                "Jining Yan",
                "Chao Mou",
                "Shuai Han",
                "Wuxia Jin",
                "Guannan Zhang",
                "Xiaodong Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00447v3",
                "http://arxiv.org/pdf/2311.00447v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00445v1",
            "title": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language\n  Models",
            "updated": "2023-11-01T11:13:06Z",
            "published": "2023-11-01T11:13:06Z",
            "summary": "A central component of rational behavior is logical inference: the process of\ndetermining which conclusions follow from a set of premises. Psychologists have\ndocumented several ways in which humans' inferences deviate from the rules of\nlogic. Do language models, which are trained on text generated by humans,\nreplicate these biases, or are they able to overcome them? Focusing on the case\nof syllogisms -- inferences from two simple premises, which have been studied\nextensively in psychology -- we show that larger models are more logical than\nsmaller ones, and also more logical than humans. At the same time, even the\nlargest models make systematic errors, some of which mirror human reasoning\nbiases such as ordering effects and logical fallacies. Overall, we find that\nlanguage models mimic the human biases included in their training data, but are\nable to overcome them in some cases.",
            "author": [
                "Tiwalayo Eisape",
                "MH Tessler",
                "Ishita Dasgupta",
                "Fei Sha",
                "Sjoerd van Steenkiste",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00445v1",
                "http://arxiv.org/pdf/2311.00445v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00442v1",
            "title": "Virtual-Peripheral-in-the-Loop : A Hardware-in-the-Loop Strategy to\n  Bridge the VP/RTL Design-Gap",
            "updated": "2023-11-01T11:10:08Z",
            "published": "2023-11-01T11:10:08Z",
            "summary": "Virtual Prototypes act as an executable specification model, offering a\nunified behavior reference model for SW and HW engineers. However, between the\nVP and the HW still exists a gap, as the step from an architectural level VP\nimplementation on the Transaction Level Modeling to the Register Transfer Layer\nimplementation is considerably big. Especially when a company wants to focus on\ntheir Unique Selling-Point, the HW Design Space Exploration and acceptance\ntests should start as early as possible. Traditionally, this can only start\nonce the rest of the System-on-Chip is also implemented in the RTL. As SoCs\nconsist of many common subsystems like processors, memories, and peripherals,\nthis may impact the time-to-market considerably. This is avoidable, however: In\nthis paper we propose a Hardware-in-the-Loop strategy that allows to bridge the\ngap between the VP and RTL design that empowers engineers to focus on their USP\nwhile leveraging an existing suite of TLM Intellectual Properties for the\ncommon base-system components. We show how VPs and partial RTL implementations\nof a SoC can be combined in a Hardware-in-the-Loop simulation environment\nutilizing Field-Programmable Gate Arrays. The proposed approach allows early\nDSE, validation, and verification of SoC subsystems, which bridges the TLM/RTL\ngap. We evaluate our approach with a lightweight implementation of the proposed\nprotocol, and three case-studies with real-world peripherals and accelerators\non HW. Furthermore, we assess the capabilities of our approach and offer\npractical considerations for engineers utilizing this HIL approach for SoC\ndesign; and finally propose further extensions that can boost the approach for\nspecialized applications like high-performance accelerators and computation.",
            "author": [
                "Sallar Ahmadi-Pour",
                "Pascal Pieper",
                "Rolf Drechsler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00442v1",
                "http://arxiv.org/pdf/2311.00442v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00441v1",
            "title": "Improving Robustness for Vision Transformer with a Simple Dynamic\n  Scanning Augmentation",
            "updated": "2023-11-01T11:10:01Z",
            "published": "2023-11-01T11:10:01Z",
            "summary": "Vision Transformer (ViT) has demonstrated promising performance in computer\nvision tasks, comparable to state-of-the-art neural networks. Yet, this new\ntype of deep neural network architecture is vulnerable to adversarial attacks\nlimiting its capabilities in terms of robustness. This article presents a novel\ncontribution aimed at further improving the accuracy and robustness of ViT,\nparticularly in the face of adversarial attacks. We propose an augmentation\ntechnique called `Dynamic Scanning Augmentation' that leverages dynamic input\nsequences to adaptively focus on different patches, thereby maintaining\nperformance and robustness. Our detailed investigations reveal that this\nadaptability to the input sequence induces significant changes in the attention\nmechanism of ViT, even for the same image. We introduce four variations of\nDynamic Scanning Augmentation, outperforming ViT in terms of both robustness to\nadversarial attacks and accuracy against natural images, with one variant\nshowing comparable results. By integrating our augmentation technique, we\nobserve a substantial increase in ViT's robustness, improving it from $17\\%$ to\n$92\\%$ measured across different types of adversarial attacks. These findings,\ntogether with other comprehensive tests, indicate that Dynamic Scanning\nAugmentation enhances accuracy and robustness by promoting a more adaptive type\nof attention. In conclusion, this work contributes to the ongoing research on\nVision Transformers by introducing Dynamic Scanning Augmentation as a technique\nfor improving the accuracy and robustness of ViT. The observed results\nhighlight the potential of this approach in advancing computer vision tasks and\nmerit further exploration in future studies.",
            "author": [
                "Shashank Kotyan",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00441v1",
                "http://arxiv.org/pdf/2311.00441v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00440v2",
            "title": "Maximum $k$- vs. $\\ell$-colourings of graphs",
            "updated": "2023-11-16T04:58:02Z",
            "published": "2023-11-01T11:09:01Z",
            "summary": "We present polynomial-time SDP-based algorithms for the following problem:\nFor fixed $k \\leq \\ell$, given a real number $\\epsilon>0$ and a graph $G$ that\nadmits a $k$-colouring with a $\\rho$-fraction of the edges coloured properly,\nit returns an $\\ell$-colouring of $G$ with an $(\\alpha \\rho -\n\\epsilon)$-fraction of the edges coloured properly in polynomial time in $G$\nand $1 / \\epsilon$. Our algorithms are based on the algorithms of Frieze and\nJerrum [Algorithmica'97] and of Karger, Motwani and Sudan [JACM'98].\n  For $k = 2, \\ell = 3$, our algorithm achieves an approximation ratio $\\alpha\n= 1$, which is the best possible. When $k$ is fixed and $\\ell$ grows large, our\nalgorithm achieves an approximation ratio of $\\alpha = 1 - o(1 / \\ell)$. When\n$k, \\ell$ are both large, our algorithm achieves an approximation ratio of\n$\\alpha = 1 - 1 / \\ell + 2 \\ln \\ell / k \\ell - o(\\ln \\ell / k \\ell) - O(1 /\nk^2)$; if we fix $d = \\ell - k$ and allow $k, \\ell$ to grow large, this is\n$\\alpha = 1 - 1 / \\ell + 2 \\ln \\ell / k \\ell - o(\\ln \\ell / k \\ell)$.\n  By extending the results of Khot, Kindler, Mossel and O'Donnell [SICOMP'07]\nto the promise setting, we show that for large $k$ and $\\ell$, assuming Khot's\nUnique Games Conjecture (UGC), it is \\NP-hard to achieve an approximation ratio\n$\\alpha$ greater than $1 - 1 / \\ell + 2 \\ln \\ell / k \\ell + o(\\ln \\ell / k\n\\ell)$, provided that $\\ell$ is bounded by a function that is\n$o(\\exp(\\sqrt[3]{k}))$. For the case where $d = \\ell - k$ is fixed, this bound\nmatches the performance of our algorithm up to $o(\\ln \\ell / k \\ell)$.\nFurthermore, by extending the results of Guruswami and Sinop [ToC'13] to the\npromise setting, we prove that it is NP-hard to achieve an approximation ratio\ngreater than $1 - 1 / \\ell + 8 \\ln \\ell / k \\ell + o(\\ln \\ell / k \\ell)$,\nprovided again that $\\ell$ is bounded as before (but this time without assuming\nthe UGC).",
            "author": [
                "Tamio-Vesa Nakajima",
                "Stanislav \u017divn\u00fd"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00440v2",
                "http://arxiv.org/pdf/2311.00440v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00437v1",
            "title": "Untangling Graphs on Surfaces",
            "updated": "2023-11-01T11:00:13Z",
            "published": "2023-11-01T11:00:13Z",
            "summary": "Consider a graph drawn on a surface (for example, the plane minus a finite\nset of obstacle points), possibly with crossings. We provide an algorithm to\ndecide whether such a drawing can be untangled, namely, if one can slide the\nvertices and edges of the graph on the surface (avoiding the obstacles) to\nremove all crossings; in other words, whether the drawing is homotopic to an\nembedding. While the problem boils down to planarity testing when the surface\nis the sphere or the disk (or equivalently the plane without any obstacle), the\nother cases have never been studied before, except when the input graph is a\ncycle, in an abundant literature in topology and more recently by Despr\\'e and\nLazarus [SoCG 2017, J. ACM 2019].\n  Our algorithm runs in O(m + poly(g+b) n log n) time, where g >= 0 and b >= 0\nare the genus and the number of boundary components of the input orientable\nsurface S, and n is the size of the input graph drawing, lying on some fixed\ngraph of size m cellularly embedded on S.\n  We use various techniques from two-dimensional computational topology and\nfrom the theory of hyperbolic surfaces. Most notably, we introduce reducing\ntriangulations, a novel discrete analog of hyperbolic surfaces in the spirit of\nsystems of quads by Lazarus and Rivaud [FOCS 2012] and Erickson and Whittlesey\n[SODA 2013], which have the additional benefit that reduced paths are unique\nand stable upon reversal; they are likely of independent interest. Tailored\ndata structures are needed to achieve certain homotopy tests efficiently on\nthese triangulations. As a key subroutine, we rely on an algorithm to test the\nweak simplicity of a graph drawn on a surface by Akitaya, Fulek, and T\\'oth\n[SODA 2018, TALG 2019].",
            "author": [
                "\u00c9ric Colin de Verdi\u00e8re",
                "Vincent Despr\u00e9",
                "Lo\u00efc Dubois"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00437v1",
                "http://arxiv.org/pdf/2311.00437v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS",
                "05C10, 57M15, 57N05, 68Q25, 68R10, 68W05, 14E25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00436v1",
            "title": "Enhancing Traffic Object Detection in Variable Illumination with\n  RGB-Event Fusion",
            "updated": "2023-11-01T10:59:57Z",
            "published": "2023-11-01T10:59:57Z",
            "summary": "Traffic object detection under variable illumination is challenging due to\nthe information loss caused by the limited dynamic range of conventional\nframe-based cameras. To address this issue, we introduce bio-inspired event\ncameras and propose a novel Structure-aware Fusion Network (SFNet) that\nextracts sharp and complete object structures from the event stream to\ncompensate for the lost information in images through cross-modality fusion,\nenabling the network to obtain illumination-robust representations for traffic\nobject detection. Specifically, to mitigate the sparsity or blurriness issues\narising from diverse motion states of traffic objects in fixed-interval event\nsampling methods, we propose the Reliable Structure Generation Network (RSGNet)\nto generate Speed Invariant Frames (SIF), ensuring the integrity and sharpness\nof object structures. Next, we design a novel Adaptive Feature Complement\nModule (AFCM) which guides the adaptive fusion of two modality features to\ncompensate for the information loss in the images by perceiving the global\nlightness distribution of the images, thereby generating illumination-robust\nrepresentations. Finally, considering the lack of large-scale and high-quality\nannotations in the existing event-based object detection datasets, we build a\nDSEC-Det dataset, which consists of 53 sequences with 63,931 images and more\nthan 208,000 labels for 8 classes. Extensive experimental results demonstrate\nthat our proposed SFNet can overcome the perceptual boundaries of conventional\ncameras and outperform the frame-based method by 8.0% in mAP50 and 5.9% in\nmAP50:95. Our code and dataset will be available at\nhttps://github.com/YN-Yang/SFNet.",
            "author": [
                "Zhanwen Liu",
                "Nan Yang",
                "Yang Wang",
                "Yuke Li",
                "Xiangmo Zhao",
                "Fei-Yue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00436v1",
                "http://arxiv.org/pdf/2311.00436v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00434v1",
            "title": "Event-based Background-Oriented Schlieren",
            "updated": "2023-11-01T10:57:20Z",
            "published": "2023-11-01T10:57:20Z",
            "summary": "Schlieren imaging is an optical technique to observe the flow of transparent\nmedia, such as air or water, without any particle seeding. However,\nconventional frame-based techniques require both high spatial and temporal\nresolution cameras, which impose bright illumination and expensive computation\nlimitations. Event cameras offer potential advantages (high dynamic range, high\ntemporal resolution, and data efficiency) to overcome such limitations due to\ntheir bio-inspired sensing principle. This paper presents a novel technique for\nperceiving air convection using events and frames by providing the first\ntheoretical analysis that connects event data and schlieren. We formulate the\nproblem as a variational optimization one combining the linearized event\ngeneration model with a physically-motivated parameterization that estimates\nthe temporal derivative of the air density. The experiments with accurately\naligned frame- and event camera data reveal that the proposed method enables\nevent cameras to obtain on par results with existing frame-based optical flow\ntechniques. Moreover, the proposed method works under dark conditions where\nframe-based schlieren fails, and also enables slow-motion analysis by\nleveraging the event camera's advantages. Our work pioneers and opens a new\nstack of event camera applications, as we publish the source code as well as\nthe first schlieren dataset with high-quality frame and event data.\nhttps://github.com/tub-rip/event_based_bos",
            "author": [
                "Shintaro Shiba",
                "Friedhelm Hamann",
                "Yoshimitsu Aoki",
                "Guillermo Gallego"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TPAMI.2023.3328188",
                "http://arxiv.org/abs/2311.00434v1",
                "http://arxiv.org/pdf/2311.00434v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00430v1",
            "title": "Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo\n  Labelling",
            "updated": "2023-11-01T10:45:07Z",
            "published": "2023-11-01T10:45:07Z",
            "summary": "As the size of pre-trained speech recognition models increases, running these\nlarge models in low-latency or resource-constrained environments becomes\nchallenging. In this work, we leverage pseudo-labelling to assemble a\nlarge-scale open-source dataset which we use to distill the Whisper model into\na smaller variant, called Distil-Whisper. Using a simple word error rate (WER)\nheuristic, we select only the highest quality pseudo-labels for training. The\ndistilled model is 5.8 times faster with 51% fewer parameters, while performing\nto within 1% WER on out-of-distribution test data in a zero-shot transfer\nsetting. Distil-Whisper maintains the robustness of the Whisper model to\ndifficult acoustic conditions, while being less prone to hallucination errors\non long-form audio. Distil-Whisper is designed to be paired with Whisper for\nspeculative decoding, yielding a 2 times speed-up while mathematically ensuring\nthe same outputs as the original model. To facilitate further research in this\ndomain, we make our training code, inference code and models publicly\naccessible.",
            "author": [
                "Sanchit Gandhi",
                "Patrick von Platen",
                "Alexander M. Rush"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00430v1",
                "http://arxiv.org/pdf/2311.00430v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00429v2",
            "title": "Crop Disease Classification using Support Vector Machines with Green\n  Chromatic Coordinate (GCC) and Attention based feature extraction for IoT\n  based Smart Agricultural Applications",
            "updated": "2023-11-06T09:58:25Z",
            "published": "2023-11-01T10:44:49Z",
            "summary": "Crops hold paramount significance as they serve as the primary provider of\nenergy, nutrition, and medicinal benefits for the human population. Plant\ndiseases, however, can negatively affect leaves during agricultural\ncultivation, resulting in significant losses in crop output and economic value.\nTherefore, it is crucial for farmers to identify crop diseases. However, this\nmethod frequently necessitates hard work, a lot of planning, and in-depth\nfamiliarity with plant pathogens. Given these numerous obstacles, it is\nessential to provide solutions that can easily interface with mobile and IoT\ndevices so that our farmers can guarantee the best possible crop development.\nVarious machine learning (ML) as well as deep learning (DL) algorithms have\nbeen created & studied for the identification of plant disease detection,\nyielding substantial and promising results. This article presents a novel\nclassification method that builds on prior work by utilising attention-based\nfeature extraction, RGB channel-based chromatic analysis, Support Vector\nMachines (SVM) for improved performance, and the ability to integrate with\nmobile applications and IoT devices after quantization of information. Several\ndisease classification algorithms were compared with the suggested model, and\nit was discovered that, in terms of accuracy, Vision Transformer-based feature\nextraction and additional Green Chromatic Coordinate feature with SVM\nclassification achieved an accuracy of (GCCViT-SVM) - 99.69%, whereas after\nquantization for IoT device integration achieved an accuracy of - 97.41% while\nalmost reducing 4x in size. Our findings have profound implications because\nthey have the potential to transform how farmers identify crop illnesses with\nprecise and fast information, thereby preserving agricultural output and\nensuring food security.",
            "author": [
                "Shashwat Jha",
                "Vishvaditya Luhach",
                "Gauri Shanker Gupta",
                "Beependra Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00429v2",
                "http://arxiv.org/pdf/2311.00429v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00428v1",
            "title": "NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust\n  Multi-Exit Neural Networks",
            "updated": "2023-11-01T10:44:05Z",
            "published": "2023-11-01T10:44:05Z",
            "summary": "While multi-exit neural networks are regarded as a promising solution for\nmaking efficient inference via early exits, combating adversarial attacks\nremains a challenging problem. In multi-exit networks, due to the high\ndependency among different submodels, an adversarial example targeting a\nspecific exit not only degrades the performance of the target exit but also\nreduces the performance of all other exits concurrently. This makes multi-exit\nnetworks highly vulnerable to simple adversarial attacks. In this paper, we\npropose NEO-KD, a knowledge-distillation-based adversarial training strategy\nthat tackles this fundamental challenge based on two key contributions. NEO-KD\nfirst resorts to neighbor knowledge distillation to guide the output of the\nadversarial examples to tend to the ensemble outputs of neighbor exits of clean\ndata. NEO-KD also employs exit-wise orthogonal knowledge distillation for\nreducing adversarial transferability across different submodels. The result is\na significantly improved robustness against adversarial attacks. Experimental\nresults on various datasets/models show that our method achieves the best\nadversarial accuracy with reduced computation budgets, compared to the\nbaselines relying on existing adversarial training or knowledge distillation\ntechniques for multi-exit networks.",
            "author": [
                "Seokil Ham",
                "Jungwuk Park",
                "Dong-Jun Han",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00428v1",
                "http://arxiv.org/pdf/2311.00428v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00425v1",
            "title": "Neural Implicit Field Editing Considering Object-environment Interaction",
            "updated": "2023-11-01T10:35:47Z",
            "published": "2023-11-01T10:35:47Z",
            "summary": "The 3D scene editing method based on neural implicit field has gained wide\nattention. It has achieved excellent results in 3D editing tasks. However,\nexisting methods often blend the interaction between objects and scene\nenvironment. The change of scene appearance like shadows is failed to be\ndisplayed in the rendering view. In this paper, we propose an Object and Scene\nenvironment Interaction aware (OSI-aware) system, which is a novel two-stream\nneural rendering system considering object and scene environment interaction.\nTo obtain illuminating conditions from the mixture soup, the system\nsuccessfully separates the interaction between objects and scene environment by\nintrinsic decomposition method. To study the corresponding changes to the scene\nappearance from object-level editing tasks, we introduce a depth map guided\nscene inpainting method and shadow rendering method by point matching strategy.\nExtensive experiments demonstrate that our novel pipeline produce reasonable\nappearance changes in scene editing tasks. It also achieve competitive\nperformance for the rendering quality in novel-view synthesis tasks.",
            "author": [
                "Zhihong Zeng",
                "Zongji Wang",
                "Yuanben Zhang",
                "Weinan Cai",
                "Zehao Cao",
                "Lili Zhang",
                "Yan Guo",
                "Yanhong Zhang",
                "Junyi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00425v1",
                "http://arxiv.org/pdf/2311.00425v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00424v1",
            "title": "Tracking capelin spawning migration -- Integrating environmental data\n  and Individual-based modeling",
            "updated": "2023-11-01T10:30:06Z",
            "published": "2023-11-01T10:30:06Z",
            "summary": "This paper presents a modeling framework for tracking the spawning migration\nof the capelin, which is a fish species in the Barents Sea. The framework\ncombines an individual-based model (IBM) with artificial neural networks\n(ANNs). The ANNs determine the direction of the fish's movement based on local\nenvironmental information, while a genetic algorithm and fitness function\nassess the suitability of the proposed directions. The framework's efficacy is\ndemonstrated by comparing the spatial distributions of modeled and empirical\npotential spawners.\n  The proposed model successfully replicates the southeastward movement of\ncapelin during their spawning migration, accurately capturing the distribution\nof spawning fish over historical spawning sites along the eastern coast of\nnorthern Norway.\n  Furthermore, the paper compares three migration models: passive swimmers,\ntaxis movement based on temperature gradients, and restricted-area search,\nalong with our proposed approach. The results reveal that our approach\noutperforms the other models in mimicking the migration pattern. Most spawning\nstocks managed to reach the spawning sites, unlike the other models where water\ncurrents played a significant role in pushing the fish away from the coast. The\ntemperature gradient detection model and restricted-area search model are found\nto be inadequate for accurately simulating capelin spawning migration in the\nBarents Sea due to complex oceanographic conditions.",
            "author": [
                "Salah Alrabeei",
                "Sam Subbey",
                "Talal Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00424v1",
                "http://arxiv.org/pdf/2311.00424v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "cs.NE",
                "92D25, 92C05, 68T05, 68U10",
                "I.2; I.3; I.6; J.2; J.9; H.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00420v1",
            "title": "A cost-benefit source-receptor framework for implementation of\n  Blue-Green flood risk management",
            "updated": "2023-11-01T10:26:21Z",
            "published": "2023-11-01T10:26:21Z",
            "summary": "As floods are a major and growing source of risk in urban areas, there is a\nnecessity to improve flood risk management frameworks and civil protection\nthrough planning interventions that modify surface flow pathways and introduce\nstorage. Despite the complexity of densely urbanised areas, modern flood models\ncan represent urban features and flow characteristics to help researchers,\nlocal authorities, and insurance companies to develop and improve efficient\nflood risk frameworks to achieve resilience in cities. A cost-benefit driven\nsource-receptor flood risk framework is developed in this study to identify (1)\nlocations contributing to surface flooding (sources), (2) buildings and\nlocations at high flood risk (receptors), (3) the cost-benefit nexus between\nthe source and the receptor, and finally (4) ways to mitigate flooding at the\nreceptor by adding Blue-Green Infrastructure (BGI) in critical locations. The\nanalysis is based on five steps to identify the source and the receptor in a\nstudy area based on the flood exposure of buildings, damages arising from\nflooding and available green spaces with the best potential to add sustainable\nand resilient solutions to reduce flooding. The framework was developed using\nthe detailed hydrodynamic model CityCAT in a case study of the city centre of\nNewcastle upon Tyne, UK. The novelty of this analysis is that firstly, multiple\nstorm magnitudes (i.e. small and large floods) are used combined with a method\nto locate the areas and the buildings at flood risk and a prioritized set of\nbest places to add interventions upstream and downstream. Secondly, planning\ndecisions are informed by considering the benefit from reduced damages to\nproperties and the cost to construct resilient BGI options rather than a\nrestricted hydraulic analysis considering only flood depths and storages in\nisolation from real-world economics.",
            "author": [
                "Christos Iliadis",
                "Vassilis Glenis",
                "Chris Kilsby"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00420v1",
                "http://arxiv.org/pdf/2311.00420v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "68Uxx68U01",
                "J.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00416v1",
            "title": "Efficient Human-AI Coordination via Preparatory Language-based\n  Convention",
            "updated": "2023-11-01T10:18:23Z",
            "published": "2023-11-01T10:18:23Z",
            "summary": "Developing intelligent agents capable of seamless coordination with humans is\na critical step towards achieving artificial general intelligence. Existing\nmethods for human-AI coordination typically train an agent to coordinate with a\ndiverse set of policies or with human models fitted from real human data.\nHowever, the massively diverse styles of human behavior present obstacles for\nAI systems with constrained capacity, while high quality human data may not be\nreadily available in real-world scenarios. In this study, we observe that prior\nto coordination, humans engage in communication to establish conventions that\nspecify individual roles and actions, making their coordination proceed in an\norderly manner. Building upon this observation, we propose employing the large\nlanguage model (LLM) to develop an action plan (or equivalently, a convention)\nthat effectively guides both human and AI. By inputting task requirements,\nhuman preferences, the number of agents, and other pertinent information into\nthe LLM, it can generate a comprehensive convention that facilitates a clear\nunderstanding of tasks and responsibilities for all parties involved.\nFurthermore, we demonstrate that decomposing the convention formulation problem\ninto sub-problems with multiple new sessions being sequentially employed and\nhuman feedback, will yield a more efficient coordination convention.\nExperimental evaluations conducted in the Overcooked-AI environment, utilizing\na human proxy model, highlight the superior performance of our proposed method\ncompared to existing learning-based approaches. When coordinating with real\nhumans, our method achieves better alignment with human preferences and an\naverage performance improvement of 15% compared to the state-of-the-art.",
            "author": [
                "Cong Guan",
                "Lichao Zhang",
                "Chunpeng Fan",
                "Yichen Li",
                "Feng Chen",
                "Lihe Li",
                "Yunjia Tian",
                "Lei Yuan",
                "Yang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00416v1",
                "http://arxiv.org/pdf/2311.00416v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00412v1",
            "title": "Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT\n  (CBCT) Enhancement with Multi-task Customized Perceptual Loss",
            "updated": "2023-11-01T10:09:01Z",
            "published": "2023-11-01T10:09:01Z",
            "summary": "Cone-beam computed tomography (CBCT) is routinely collected during\nimage-guided radiation therapy (IGRT) to provide updated patient anatomy\ninformation for cancer treatments. However, CBCT images often suffer from\nstreaking artifacts and noise caused by under-rate sampling projections and\nlow-dose exposure, resulting in low clarity and information loss. While recent\ndeep learning-based CBCT enhancement methods have shown promising results in\nsuppressing artifacts, they have limited performance on preserving anatomical\ndetails since conventional pixel-to-pixel loss functions are incapable of\ndescribing detailed anatomy. To address this issue, we propose a novel\nfeature-oriented deep learning framework that translates low-quality CBCT\nimages into high-quality CT-like imaging via a multi-task customized\nfeature-to-feature perceptual loss function. The framework comprises two main\ncomponents: a multi-task learning feature-selection network(MTFS-Net) for\ncustomizing the perceptual loss function; and a CBCT-to-CT translation network\nguided by feature-to-feature perceptual loss, which uses advanced generative\nmodels such as U-Net, GAN and CycleGAN. Our experiments showed that the\nproposed framework can generate synthesized CT (sCT) images for the lung that\nachieved a high similarity to CT images, with an average SSIM index of 0.9869\nand an average PSNR index of 39.9621. The sCT images also achieved visually\npleasing performance with effective artifacts suppression, noise reduction, and\ndistinctive anatomical details preservation. Our experiment results indicate\nthat the proposed framework outperforms the state-of-the-art models for\npulmonary CBCT enhancement. This framework holds great promise for generating\nhigh-quality anatomical imaging from CBCT that is suitable for various clinical\napplications.",
            "author": [
                "Jiarui Zhu",
                "Werxing Chen",
                "Hongfei Sun",
                "Shaohua Zhi",
                "Jing Qin",
                "Jing Cai",
                "Ge Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00412v1",
                "http://arxiv.org/pdf/2311.00412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00410v1",
            "title": "Ground-State Probabilistic Logic with the Simplest Binary Energy\n  Landscape for Probabilistic Computing",
            "updated": "2023-11-01T10:03:58Z",
            "published": "2023-11-01T10:03:58Z",
            "summary": "We investigate the ground-state probabilistic logic based on a binary energy\nlandscape (GSPL-BEL) model, implementing the many-body interactions within\nIsing model cells. The GSPL-BEL model offers a simplified binary energy\nlandscape, enabling the conversion of traditional CMOS-based logic into a\nprobabilistic graphical representation based on desired truth tables.\nStochastic Ising cells, coupled with generic probabilistic devices exhibiting\nsigmoidal electrical responses, serve as the building blocks of the GSPL-BEL.\nMulti-body interactions are realized through cascaded CMOS-based XNOR gates and\na passive resistor network. Through circuit simulations of three-node,\nfour-node, and five-node systems, the functionality of the GSPL-BEL model is\nverified in forward, reverse, and partial-reverse operating modes, and applied\nto various arithmetic tasks. The many-body effect provides additional degrees\nof freedom in describing the system's energy function, resulting in distinct\nenergy levels for valid and invalid states. This observation is supported by\nthe binarized probability distribution observed in the steady state of the\nprobabilistic circuits. Furthermore, compared to conventional combinatorial\nlogic circuits, the GSPL-BEL-based circuit design requires a minimal number of\nprobabilistic devices, as demonstrated in the invertible multiplier/integer\nfactorizer circuit. These findings highlight the potential of the GSPL-BEL\nmodel for future high-performance logic circuit designs leveraging\nprobabilistic devices.",
            "author": [
                "Yihan He",
                "Sheng Luo",
                "Chao Fang",
                "Gengchiau Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00410v1",
                "http://arxiv.org/pdf/2311.00410v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00409v1",
            "title": "Polyander visualization of quantum walks",
            "updated": "2023-11-01T10:01:08Z",
            "published": "2023-11-01T10:01:08Z",
            "summary": "We investigate quantum walks which play an important role in the modelling of\nmany phenomena. The detailed and thorough description is given to the discrete\nquantum walks on a line, where the total quantum state consists of quantum\nstates of the walker and the coin. In addition to the standard walker\nprobability distribution, we introduce the coin probability distribution which\ngives more complete quantum walk description and novel visualization in terms\nof the so called polyanders (analogs of trianders in DNA visualization). The\nmethods of final states computation and the Fourier transform are presented for\nthe Hadamard quantum walk.",
            "author": [
                "Steven Duplij",
                "Raimund Vogl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00409v1",
                "http://arxiv.org/pdf/2311.00409v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "hep-th",
                "17A42, 20N15, 11A07, 11S31"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00408v1",
            "title": "AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot\n  Classification",
            "updated": "2023-11-01T10:00:15Z",
            "published": "2023-11-01T10:00:15Z",
            "summary": "Recent work has found that few-shot sentence classification based on\npre-trained Sentence Encoders (SEs) is efficient, robust, and effective. In\nthis work, we investigate strategies for domain-specialization in the context\nof few-shot sentence classification with SEs. We first establish that\nunsupervised Domain-Adaptive Pre-Training (DAPT) of a base Pre-trained Language\nModel (PLM) (i.e., not an SE) substantially improves the accuracy of few-shot\nsentence classification by up to 8.4 points. However, applying DAPT on SEs, on\nthe one hand, disrupts the effects of their (general-domain) Sentence Embedding\nPre-Training (SEPT). On the other hand, applying general-domain SEPT on top of\na domain-adapted base PLM (i.e., after DAPT) is effective but inefficient,\nsince the computationally expensive SEPT needs to be executed on top of a\nDAPT-ed PLM of each domain. As a solution, we propose AdaSent, which decouples\nSEPT from DAPT by training a SEPT adapter on the base PLM. The adapter can be\ninserted into DAPT-ed PLMs from any domain. We demonstrate AdaSent's\neffectiveness in extensive experiments on 17 different few-shot sentence\nclassification datasets. AdaSent matches or surpasses the performance of full\nSEPT on DAPT-ed PLM, while substantially reducing the training costs. The code\nfor AdaSent is available.",
            "author": [
                "Yongxin Huang",
                "Kexin Wang",
                "Sourav Dutta",
                "Raj Nath Patel",
                "Goran Glava\u0161",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00408v1",
                "http://arxiv.org/pdf/2311.00408v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00406v1",
            "title": "Black Hole in Discrete Gravity",
            "updated": "2023-11-01T09:57:55Z",
            "published": "2023-11-01T09:57:55Z",
            "summary": "We study the metric corresponding to a three-dimensional coset space\n$SO(4)/SO(3)$ in the lattice setting. With the use of three integers $n_1,\nn_2$, and $n_3$, and a length scale, $l_{\\mu}$, the continuous metric is\ntransformed into a discrete space. The numerical outcomes are compared with the\ncontinuous ones. The singularity of the black hole is explored and different\ndomains are studied.",
            "author": [
                "Ali H. Chamseddine",
                "Ola Malaeb",
                "Sara Najem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00406v1",
                "http://arxiv.org/pdf/2311.00406v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "hep-lat",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00405v1",
            "title": "Couples can be tractable: New algorithms and hardness results for the\n  Hospitals / Residents problem with Couples",
            "updated": "2023-11-01T09:56:59Z",
            "published": "2023-11-01T09:56:59Z",
            "summary": "In this paper we study the {\\sc Hospitals / Residents problem with Couples}\n({\\sc hrc}), where a solution is a stable matching or a report that none\nexists. We present a novel polynomial-time algorithm that can find a\nnear-feasible stable matching (adjusting the hospitals' capacities by at most\n1) in an {\\sc hrc} instance where the couples' preferences are sub-responsive\n(i.e., if one member switches to a better hospital, than the couple also\nimproves) and sub-complete (i.e., each pair of hospitals that are individually\nacceptable to both members are jointly acceptable for the couple) by reducing\nit to an instance of the {\\sc Stable Fixtures} problem. We also present a\npolynomial-time algorithm for {\\sc hrc} in a sub-responsive, sub-complete\ninstance that is a Dual Market, or where all couples are one of several\npossible types. We show that our algorithm also implies the polynomial-time\nsolvability of a stable b-matching problem, where the underlying graph is a\nmultigraph with loops.\n  We complement our algorithms with several hardness results. We show that {\\sc\nhrc} with sub-responsive and sub-complete couples is NP-hard, even with other\nstrong restrictions. We also show that {\\sc hrc} with a Dual Market is NP-hard\nunder several simultaneous restrictions. Finally, we show that the problem of\nfinding a matching with the minimum number of blocking pairs in {\\sc hrc} is\nnot approximable within $m^{1-\\varepsilon}$, for any $\\varepsilon>0$, where $m$\nis the total length of the hospitals' preference lists, unless P=NP, even if\neach couple applies to only one pair of hospitals. Our polynomial-time\nsolvability results greatly expand the class of known tractable instances of\n{\\sc hrc} and provide additional evidence as to why long-standing entry-level\nlabour markets that allow couples such as the National Resident Matching\nProgram remain successful to this day.",
            "author": [
                "Gergely Cs\u00e1ji",
                "David Manlove",
                "Iain McBride",
                "James Trimble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00405v1",
                "http://arxiv.org/pdf/2311.00405v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.AI",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00401v1",
            "title": "A Spatial-Temporal Transformer based Framework For Human Pose Assessment\n  And Correction in Education Scenarios",
            "updated": "2023-11-01T09:53:38Z",
            "published": "2023-11-01T09:53:38Z",
            "summary": "Human pose assessment and correction play a crucial role in applications\nacross various fields, including computer vision, robotics, sports analysis,\nhealthcare, and entertainment. In this paper, we propose a Spatial-Temporal\nTransformer based Framework (STTF) for human pose assessment and correction in\neducation scenarios such as physical exercises and science experiment. The\nframework comprising skeletal tracking, pose estimation, posture assessment,\nand posture correction modules to educate students with professional,\nquick-to-fix feedback. We also create a pose correction method to provide\ncorrective feedback in the form of visual aids. We test the framework with our\nown dataset. It comprises (a) new recordings of five exercises, (b) existing\nrecordings found on the internet of the same exercises, and (c) corrective\nfeedback on the recordings by professional athletes and teachers. Results show\nthat our model can effectively measure and comment on the quality of students'\nactions. The STTF leverages the power of transformer models to capture spatial\nand temporal dependencies in human poses, enabling accurate assessment and\neffective correction of students' movements.",
            "author": [
                "Wenyang Hu",
                "Kai Liu",
                "Libin Liu",
                "Huiliang Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00401v1",
                "http://arxiv.org/pdf/2311.00401v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00400v1",
            "title": "Open-Set Face Recognition with Maximal Entropy and Objectosphere Loss",
            "updated": "2023-11-01T09:52:02Z",
            "published": "2023-11-01T09:52:02Z",
            "summary": "Open-set face recognition characterizes a scenario where unknown individuals,\nunseen during the training and enrollment stages, appear on operation time.\nThis work concentrates on watchlists, an open-set task that is expected to\noperate at a low False Positive Identification Rate and generally includes only\na few enrollment samples per identity. We introduce a compact adapter network\nthat benefits from additional negative face images when combined with distinct\ncost functions, such as Objectosphere Loss (OS) and the proposed Maximal\nEntropy Loss (MEL). MEL modifies the traditional Cross-Entropy loss in favor of\nincreasing the entropy for negative samples and attaches a penalty to known\ntarget classes in pursuance of gallery specialization. The proposed approach\nadopts pre-trained deep neural networks (DNNs) for face recognition as feature\nextractors. Then, the adapter network takes deep feature representations and\nacts as a substitute for the output layer of the pre-trained DNN in exchange\nfor an agile domain adaptation. Promising results have been achieved following\nopen-set protocols for three different datasets: LFW, IJB-C, and UCCS as well\nas state-of-the-art performance when supplementary negative data is properly\nselected to fine-tune the adapter network.",
            "author": [
                "Rafael Henrique Vareto",
                "Yu Linghu",
                "Terrance E. Boult",
                "William Robson Schwartz",
                "Manuel G\u00fcnther"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00400v1",
                "http://arxiv.org/pdf/2311.00400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00399v1",
            "title": "Enhanced Knowledge Injection for Radiology Report Generation",
            "updated": "2023-11-01T09:50:55Z",
            "published": "2023-11-01T09:50:55Z",
            "summary": "Automatic generation of radiology reports holds crucial clinical value, as it\ncan alleviate substantial workload on radiologists and remind less experienced\nones of potential anomalies. Despite the remarkable performance of various\nimage captioning methods in the natural image field, generating accurate\nreports for medical images still faces challenges, i.e., disparities in visual\nand textual data, and lack of accurate domain knowledge. To address these\nissues, we propose an enhanced knowledge injection framework, which utilizes\ntwo branches to extract different types of knowledge. The Weighted Concept\nKnowledge (WCK) branch is responsible for introducing clinical medical concepts\nweighted by TF-IDF scores. The Multimodal Retrieval Knowledge (MRK) branch\nextracts triplets from similar reports, emphasizing crucial clinical\ninformation related to entity positions and existence. By integrating this\nfiner-grained and well-structured knowledge with the current image, we are able\nto leverage the multi-source knowledge gain to ultimately facilitate more\naccurate report generation. Extensive experiments have been conducted on two\npublic benchmarks, demonstrating that our method achieves superior performance\nover other state-of-the-art methods. Ablation studies further validate the\neffectiveness of two extracted knowledge sources.",
            "author": [
                "Qingqiu Li",
                "Jilan Xu",
                "Runtian Yuan",
                "Mohan Chen",
                "Yuejie Zhang",
                "Rui Feng",
                "Xiaobo Zhang",
                "Shang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00399v1",
                "http://arxiv.org/pdf/2311.00399v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00397v2",
            "title": "Towards Omni-supervised Referring Expression Segmentation",
            "updated": "2023-11-27T09:02:06Z",
            "published": "2023-11-01T09:46:59Z",
            "summary": "Referring Expression Segmentation (RES) is an emerging task in computer\nvision, which segments the target instances in images based on text\ndescriptions. However, its development is plagued by the expensive segmentation\nlabels. To address this issue, we propose a new learning task for RES called\nOmni-supervised Referring Expression Segmentation (Omni-RES), which aims to\nmake full use of unlabeled, fully labeled and weakly labeled data, e.g.,\nreferring points or grounding boxes, for efficient RES training. To accomplish\nthis task, we also propose a novel yet strong baseline method for Omni-RES\nbased on the recently popular teacher-student learning, where the weak labels\nare not directly transformed into supervision signals but used as a yardstick\nto select and refine high-quality pseudo-masks for teacher-student learning. To\nvalidate the proposed Omni-RES method, we apply it to a set of state-of-the-art\nRES models and conduct extensive experiments on a bunch of RES datasets. The\nexperimental results yield the obvious merits of Omni-RES than the\nfully-supervised and semi-supervised training schemes. For instance, with only\n10% fully labeled data, Omni-RES can help the base model achieve 100% fully\nsupervised performance, and it also outperform the semi-supervised alternative\nby a large margin, e.g., +14.93% on RefCOCO and +14.95% on RefCOCO+,\nrespectively. More importantly, Omni-RES also enable the use of large-scale\nvision-langauges like Visual Genome to facilitate low-cost RES training, and\nachieve new SOTA performance of RES, e.g., 80.66 on RefCOCO.",
            "author": [
                "Minglang Huang",
                "Yiyi Zhou",
                "Gen Luo",
                "Guannan Jiang",
                "Weilin Zhuang",
                "Xiaoshuai Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00397v2",
                "http://arxiv.org/pdf/2311.00397v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00394v1",
            "title": "An analysis of large speech models-based representations for speech\n  emotion recognition",
            "updated": "2023-11-01T09:40:40Z",
            "published": "2023-11-01T09:40:40Z",
            "summary": "Large speech models-derived features have recently shown increased\nperformance over signal-based features across multiple downstream tasks, even\nwhen the networks are not finetuned towards the target task. In this paper we\nshow the results of an analysis of several signal- and neural models-derived\nfeatures for speech emotion recognition. We use pretrained models and explore\ntheir inherent potential abstractions of emotions. Simple classification\nmethods are used so as to not interfere or add knowledge to the task. We show\nthat, even without finetuning, some of these large neural speech models'\nrepresentations can enclose information that enables performances close to, and\neven beyond state-of-the-art results across six standard speech emotion\nrecognition datasets.",
            "author": [
                "Adrian Bogdan St\u00e2nea",
                "Vlad Striletchi",
                "Cosmin Striletchi",
                "Adriana Stan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00394v1",
                "http://arxiv.org/pdf/2311.00394v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00393v1",
            "title": "Augmenting deep neural networks with symbolic knowledge: Towards\n  trustworthy and interpretable AI for education",
            "updated": "2023-11-01T09:38:56Z",
            "published": "2023-11-01T09:38:56Z",
            "summary": "Artificial neural networks (ANNs) have shown to be amongst the most important\nartificial intelligence (AI) techniques in educational applications, providing\nadaptive educational services. However, their educational potential is limited\nin practice due to three major challenges: i) difficulty in incorporating\nsymbolic educational knowledge (e.g., causal relationships, and practitioners'\nknowledge) in their development, ii) learning and reflecting biases, and iii)\nlack of interpretability. Given the high-risk nature of education, the\nintegration of educational knowledge into ANNs becomes crucial for developing\nAI applications that adhere to essential educational restrictions, and provide\ninterpretability over the predictions. This research argues that the\nneural-symbolic family of AI has the potential to address the named challenges.\nTo this end, it adapts a neural-symbolic AI framework and accordingly develops\nan approach called NSAI, that injects and extracts educational knowledge into\nand from deep neural networks, for modelling learners computational thinking.\nOur findings reveal that the NSAI approach has better generalizability compared\nto deep neural networks trained merely on training data, as well as training\ndata augmented by SMOTE and autoencoder methods. More importantly, unlike the\nother models, the NSAI approach prioritises robust representations that capture\ncausal relationships between input features and output labels, ensuring safety\nin learning to avoid spurious correlations and control biases in training data.\nFurthermore, the NSAI approach enables the extraction of rules from the learned\nnetwork, facilitating interpretation and reasoning about the path to\npredictions, as well as refining the initial educational knowledge. These\nfindings imply that neural-symbolic AI can overcome the limitations of ANNs in\neducation, enabling trustworthy and interpretable applications.",
            "author": [
                "Danial Hooshyar",
                "Roger Azevedo",
                "Yeongwook Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00393v1",
                "http://arxiv.org/pdf/2311.00393v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2.0, I.2.1, I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00392v2",
            "title": "An open-source, three-dimensional growth model of the mandible",
            "updated": "2023-11-07T08:50:43Z",
            "published": "2023-11-01T09:38:05Z",
            "summary": "The available reference data for the mandible and mandibular growth consists\nprimarily of two-dimensional linear or angular measurements. The aim of this\nstudy was to create the first open-source, three-dimensional statistical shape\nmodel of the mandible that spans the complete growth period. Computed\ntomography scans of 678 mandibles from children and young adults between 0 and\n22 years old were included in the model. The mandibles were segmented using a\nsemi-automatic or automatic (artificial intelligence-based) segmentation\nmethod. Point correspondence among the samples was achieved by rigid\nregistration, followed by non-rigid registration of a symmetrical template onto\neach sample. The registration process was validated with adequate results.\nPrincipal component analysis was used to gain insight in the variation within\nthe dataset and to investigate age-related changes and sexual dimorphism. The\npresented growth model is accessible globally and free-of-charge for\nscientists, physicians and forensic investigators for any kind of purpose\ndeemed suitable. The versatility of the model opens up new possibilities in the\nfields of oral and maxillofacial surgery, forensic sciences or biological\nanthropology. In clinical settings, the model may aid diagnostic\ndecision-making, treatment planning and treatment evaluation.",
            "author": [
                "Cornelis Klop",
                "Ruud Schreurs",
                "Guido A De Jong",
                "Edwin TM Klinkenberg",
                "Valeria Vespasiano",
                "Naomi L Rood",
                "Valerie G Niehe",
                "Vidija Soerdjbalie-Maikoe",
                "Alexia Van Goethem",
                "Bernadette S De Bakker",
                "Thomas JJ Maal",
                "Jitske W Nolte",
                "Alfred G Becking"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00392v2",
                "http://arxiv.org/pdf/2311.00392v2"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00391v1",
            "title": "Fixation-based Self-calibration for Eye Tracking in VR Headsets",
            "updated": "2023-11-01T09:34:15Z",
            "published": "2023-11-01T09:34:15Z",
            "summary": "This study proposes a novel self-calibration method for eye tracking in a\nvirtual reality (VR) headset. The proposed method is based on the assumptions\nthat the user's viewpoint can freely move and that the points of regard (PoRs)\nfrom different viewpoints are distributed within a small area on an object\nsurface during visual fixation. In the method, fixations are first detected\nfrom the time-series data of uncalibrated gaze directions using an extension of\nthe I-VDT (velocity and dispersion threshold identification) algorithm to a\nthree-dimensional (3D) scene. Then, the calibration parameters are optimized by\nminimizing the sum of a dispersion metrics of the PoRs. The proposed method can\npotentially identify the optimal calibration parameters representing the\nuser-dependent offset from the optical axis to the visual axis without explicit\nuser calibration, image processing, or marker-substitute objects. For the gaze\ndata of 18 participants walking in two VR environments with many occlusions,\nthe proposed method achieved an accuracy of 2.1$^\\circ$, which was\nsignificantly lower than the average offset. Our method is the first\nself-calibration method with an average error lower than 3$^\\circ$ in 3D\nenvironments. Further, the accuracy of the proposed method can be improved by\nup to 1.2$^\\circ$ by refining the fixation detection or optimization algorithm.",
            "author": [
                "Ryusei Uramune",
                "Sei Ikeda",
                "Hiroki Ishizuka",
                "Osamu Oshiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00391v1",
                "http://arxiv.org/pdf/2311.00391v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00389v1",
            "title": "NeuralGF: Unsupervised Point Normal Estimation by Learning Neural\n  Gradient Function",
            "updated": "2023-11-01T09:25:29Z",
            "published": "2023-11-01T09:25:29Z",
            "summary": "Normal estimation for 3D point clouds is a fundamental task in 3D geometry\nprocessing. The state-of-the-art methods rely on priors of fitting local\nsurfaces learned from normal supervision. However, normal supervision in\nbenchmarks comes from synthetic shapes and is usually not available from real\nscans, thereby limiting the learned priors of these methods. In addition,\nnormal orientation consistency across shapes remains difficult to achieve\nwithout a separate post-processing procedure. To resolve these issues, we\npropose a novel method for estimating oriented normals directly from point\nclouds without using ground truth normals as supervision. We achieve this by\nintroducing a new paradigm for learning neural gradient functions, which\nencourages the neural network to fit the input point clouds and yield unit-norm\ngradients at the points. Specifically, we introduce loss functions to\nfacilitate query points to iteratively reach the moving targets and aggregate\nonto the approximated surface, thereby learning a global surface representation\nof the data. Meanwhile, we incorporate gradients into the surface approximation\nto measure the minimum signed deviation of queries, resulting in a consistent\ngradient field associated with the surface. These techniques lead to our deep\nunsupervised oriented normal estimator that is robust to noise, outliers and\ndensity variations. Our excellent results on widely used benchmarks demonstrate\nthat our method can learn more accurate normals for both unoriented and\noriented normal estimation tasks than the latest methods. The source code and\npre-trained model are publicly available at https://github.com/LeoQLi/NeuralGF.",
            "author": [
                "Qing Li",
                "Huifang Feng",
                "Kanle Shi",
                "Yue Gao",
                "Yi Fang",
                "Yu-Shen Liu",
                "Zhizhong Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00389v1",
                "http://arxiv.org/pdf/2311.00389v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00385v1",
            "title": "MolecularWebXR: Multiuser discussions about chemistry and biology in\n  immersive and inclusive VR",
            "updated": "2023-11-01T09:22:08Z",
            "published": "2023-11-01T09:22:08Z",
            "summary": "MolecularWebXR is our new website for education, science communication and\nscientific peer discussion in chemistry and biology built on WebXR. It\ndemocratizes multi-user, inclusive virtual reality (VR) experiences that are\ndeeply immersive for users wearing high-end headsets, yet allow participation\nby users with consumer devices such as smartphones, possibly inserted into\ncardboard goggles for immersivity, or even computers or tablets. With no\ninstalls as it is all web-served, MolecularWebXR enables multiple users to\nsimultaneously explore, communicate and discuss chemistry and biology concepts\nin immersive 3D environments, manipulating objects with their bare hands,\neither present in the same real space or scattered throughout the globe thanks\nto built-in audio features. A series of preset rooms cover educational material\non chemistry and structural biology, and an empty room can be populated with\nmaterial prepared ad hoc using moleculARweb's VMD-based PDB2AR tool. We\nverified ease of use and versatility by users aged 12-80 in entirely virtual\nsessions or mixed real-virtual sessions at science outreach events, student\ninstruction, scientific collaborations, and conference lectures. MolecularWebXR\nis available for free use without registration at https://molecularwebxr.org,\nand a blog post version of this preprint with embedded videos is available at\nhttps://go.epfl.ch/molecularwebxr-blog-post.",
            "author": [
                "Fabio J. Cortes Rodriguez",
                "Gianfranco Frattini",
                "Fernando Teixeira Pinto Meireles",
                "Danae A. Terrien",
                "Sergio Cruz-Leon",
                "Matteo Dal Peraro",
                "Eva Schier",
                "Diego M. Moreno",
                "Luciano A. Abriata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00385v1",
                "http://arxiv.org/pdf/2311.00385v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.GR",
                "q-bio.BM",
                "68U05 (Primary)",
                "I.3.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00383v1",
            "title": "Diffractive single and di-hadron production at the NLO in a saturation\n  framework",
            "updated": "2023-11-01T09:20:51Z",
            "published": "2023-11-01T09:20:51Z",
            "summary": "Motivated by the need to increase the precision of theoretical predictions to\ntest saturation physics at both the LHC and the EIC, we compute the\ncross-sections for the diffractive single and di-hadron production at the NLO\nin the shockwave formalism.",
            "author": [
                "Michael Fucilla",
                "Andrey Grabovsky",
                "Emilie Li",
                "Lech Szymanowski",
                "Samuel Wallon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00383v1",
                "http://arxiv.org/pdf/2311.00383v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00380v1",
            "title": "Classification of odd generalized Einstein metrics on 3-dimensional Lie\n  groups",
            "updated": "2023-11-01T09:18:05Z",
            "published": "2023-11-01T09:18:05Z",
            "summary": "An odd generalized metric E_{-} on a Lie group G of dimension n is a\nleft-invariant generalized metric on a Courant algebroid E_{H, F} of type B_n\nover G with left-invariant twisting forms H and F. Given an odd generalized\nmetric E_{-} on G we determine the affine space of left invariant Levi-Civita\ngeneralized connections of E_ {-}. Given in addition a left-invariant\ndivergence operator \\delta we show that there is a left-invariant Levi-Civita\ngeneralized connection of E_{-} with divergence \\delta and we compute the\ncorresponding Ricci tensor Ricci^{\\delta} of the pair (E_{-}, \\delta ). The odd\ngeneralized metric E_{-} is called odd generalized Einstein with divergence\n\\delta if Ricci^{\\delta} =0. We describe all odd generalized Einstein metrics\nof arbitrary left-invariant divergence on all 3-dimensional Lie groups.",
            "author": [
                "Vicente Cort\u00e9s",
                "Liana David"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00380v1",
                "http://arxiv.org/pdf/2311.00380v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00377v1",
            "title": "Uncertainty quantification and out-of-distribution detection using\n  surjective normalizing flows",
            "updated": "2023-11-01T09:08:35Z",
            "published": "2023-11-01T09:08:35Z",
            "summary": "Reliable quantification of epistemic and aleatoric uncertainty is of crucial\nimportance in applications where models are trained in one environment but\napplied to multiple different environments, often seen in real-world\napplications for example, in climate science or mobility analysis. We propose a\nsimple approach using surjective normalizing flows to identify\nout-of-distribution data sets in deep neural network models that can be\ncomputed in a single forward pass. The method builds on recent developments in\ndeep uncertainty quantification and generative modeling with normalizing flows.\nWe apply our method to a synthetic data set that has been simulated using a\nmechanistic model from the mobility literature and several data sets simulated\nfrom interventional distributions induced by soft and atomic interventions on\nthat model, and demonstrate that our method can reliably discern\nout-of-distribution data from in-distribution data. We compare the surjective\nflow model to a Dirichlet process mixture model and a bijective flow and find\nthat the surjections are a crucial component to reliably distinguish\nin-distribution from out-of-distribution data.",
            "author": [
                "Simon Dirmeier",
                "Ye Hong",
                "Yanan Xin",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00377v1",
                "http://arxiv.org/pdf/2311.00377v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00733v1",
            "title": "SAT Solving Using XOR-OR-AND Normal Forms",
            "updated": "2023-11-01T08:59:45Z",
            "published": "2023-11-01T08:59:45Z",
            "summary": "This paper introduces the XOR-OR-AND normal form (XNF) for logical formulas.\nIt is a generalization of the well-known Conjunctive Normal Form (CNF) where\nliterals are replaced by XORs of literals. As a first theoretic result, we show\nthat every formula is equisatisfiable to a formula in 2-XNF, i.e., a formula in\nXNF where each disjunction involves at most two XORs of literals. Subsequently,\nwe present an algorithm which converts Boolean polynomials efficiently from\ntheir Algebraic Normal Form (ANF) to formulas in 2-XNF. Experiments with the\ncipher ASCON-128 show that cryptographic problems, which by design are based\nstrongly on XOR-operations, can be represented using far fewer variables and\nclauses in 2-XNF than in CNF. In order to take advantage of this compact\nrepresentation, new SAT solvers based on input formulas in 2-XNF need to be\ndesigned. By taking inspiration from graph-based 2-CNF SAT solving, we devise a\nnew DPLL-based SAT solver for formulas in 2-XNF. Among others, we present\nadvanced pre- and in-processing techniques. Finally, we give timings for random\n2-XNF instances and instances related to key recovery attacks on round reduced\nASCON-128, where our solver outperforms state-of-the-art alternative solving\napproaches.",
            "author": [
                "Bernhard Andraschko",
                "Julian Danner",
                "Martin Kreuzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00733v1",
                "http://arxiv.org/pdf/2311.00733v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "math.AC",
                "math.LO",
                "03B70 (Primary) 13P15, 05C90, 94A60 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00373v1",
            "title": "Architecture of Data Anomaly Detection-Enhanced Decentralized Expert\n  System for Early-Stage Alzheimer's Disease Prediction",
            "updated": "2023-11-01T08:56:03Z",
            "published": "2023-11-01T08:56:03Z",
            "summary": "Alzheimer's Disease is a global health challenge that requires early and\naccurate detection to improve patient outcomes. Magnetic Resonance Imaging\n(MRI) holds significant diagnostic potential, but its effective analysis\nremains a formidable task. This study introduces a groundbreaking decentralized\nexpert system that cleverly combines blockchain technology with Artificial\nIntelligence (AI) to integrate robust anomaly detection for patient-submitted\ndata.\n  Traditional diagnostic methods often lead to delayed and imprecise\npredictions, especially in the early stages of the disease. Centralized data\nrepositories struggle to manage the immense volumes of MRI data, and persistent\nprivacy concerns hinder collaborative efforts. Our innovative solution\nharnesses decentralization to protect data integrity and patient privacy,\nfacilitated by blockchain technology. It not only emphasizes AI-driven MRI\nanalysis but also incorporates a sophisticated data anomaly detection\narchitecture. These mechanisms scrutinize patient-contributed data for various\nissues, including data quality problems and atypical findings within MRI\nimages.\n  Conducting an exhaustive check of MRI image correctness and quality directly\non the blockchain is impractical due to computational complexity and cost\nconstraints. Typically, such checks are performed off-chain, and the blockchain\nsecurely records the results. This comprehensive approach empowers our\ndecentralized app to provide more precise early-stage Alzheimer's Disease\npredictions. By merging the strengths of blockchain, AI, and anomaly detection,\nour system represents a pioneering step towards revolutionizing disease\ndiagnostics.",
            "author": [
                "Stefan Kambiz Behfar",
                "Qumars Behfar",
                "Marzie Hosseinpour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00373v1",
                "http://arxiv.org/pdf/2311.00373v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00371v1",
            "title": "Learning Cooperative Trajectory Representations for Motion Forecasting",
            "updated": "2023-11-01T08:53:05Z",
            "published": "2023-11-01T08:53:05Z",
            "summary": "Motion forecasting is an essential task for autonomous driving, and the\neffective information utilization from infrastructure and other vehicles can\nenhance motion forecasting capabilities. Existing research have primarily\nfocused on leveraging single-frame cooperative information to enhance the\nlimited perception capability of the ego vehicle, while underutilizing the\nmotion and interaction information of traffic participants observed from\ncooperative devices. In this paper, we first propose the cooperative trajectory\nrepresentations learning paradigm. Specifically, we present V2X-Graph, the\nfirst interpretable and end-to-end learning framework for cooperative motion\nforecasting. V2X-Graph employs an interpretable graph to fully leverage the\ncooperative motion and interaction contexts. Experimental results on the\nvehicle-to-infrastructure (V2I) motion forecasting dataset, V2X-Seq,\ndemonstrate the effectiveness of V2X-Graph. To further evaluate on V2X\nscenario, we construct the first real-world vehicle-to-everything (V2X) motion\nforecasting dataset V2X-Traj, and the performance shows the advantage of our\nmethod. We hope both V2X-Graph and V2X-Traj can facilitate the further\ndevelopment of cooperative motion forecasting. Find project at\nhttps://github.com/AIR-THU/V2X-Graph, find data at\nhttps://github.com/AIR-THU/DAIR-V2X-Seq.",
            "author": [
                "Hongzhi Ruan",
                "Haibao Yu",
                "Wenxian Yang",
                "Siqi Fan",
                "Yingjuan Tang",
                "Zaiqing Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00371v1",
                "http://arxiv.org/pdf/2311.00371v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00367v1",
            "title": "Prompt-based Logical Semantics Enhancement for Implicit Discourse\n  Relation Recognition",
            "updated": "2023-11-01T08:38:08Z",
            "published": "2023-11-01T08:38:08Z",
            "summary": "Implicit Discourse Relation Recognition (IDRR), which infers discourse\nrelations without the help of explicit connectives, is still a crucial and\nchallenging task for discourse parsing. Recent works tend to exploit the\nhierarchical structure information from the annotated senses, which demonstrate\nenhanced discourse relation representations can be obtained by integrating\nsense hierarchy. Nevertheless, the performance and robustness for IDRR are\nsignificantly constrained by the availability of annotated data. Fortunately,\nthere is a wealth of unannotated utterances with explicit connectives, that can\nbe utilized to acquire enriched discourse relation features. In light of such\nmotivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE)\nmethod for IDRR. Essentially, our method seamlessly injects knowledge relevant\nto discourse relation into pre-trained language models through prompt-based\nconnective prediction. Furthermore, considering the prompt-based connective\nprediction exhibits local dependencies due to the deficiency of masked language\nmodel (MLM) in capturing global semantics, we design a novel self-supervised\nlearning objective based on mutual information maximization to derive enhanced\nrepresentations of logical semantics for IDRR. Experimental results on PDTB 2.0\nand CoNLL16 datasets demonstrate that our method achieves outstanding and\nconsistent performance against the current state-of-the-art models.",
            "author": [
                "Chenxu Wang",
                "Ping Jian",
                "Mu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00367v1",
                "http://arxiv.org/pdf/2311.00367v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00358v1",
            "title": "Rethinking Samples Selection for Contrastive Learning: Mining of\n  Potential Samples",
            "updated": "2023-11-01T08:08:06Z",
            "published": "2023-11-01T08:08:06Z",
            "summary": "Contrastive learning predicts whether two images belong to the same category\nby training a model to make their feature representations as close or as far\naway as possible. In this paper, we rethink how to mine samples in contrastive\nlearning, unlike other methods, our approach is more comprehensive, taking into\naccount both positive and negative samples, and mining potential samples from\ntwo aspects: First, for positive samples, we consider both the augmented sample\nviews obtained by data augmentation and the mined sample views through data\nmining. Then, we weight and combine them using both soft and hard weighting\nstrategies. Second, considering the existence of uninformative negative samples\nand false negative samples in the negative samples, we analyze the negative\nsamples from the gradient perspective and finally mine negative samples that\nare neither too hard nor too easy as potential negative samples, i.e., those\nnegative samples that are close to positive samples. The experiments show the\nobvious advantages of our method compared with some traditional self-supervised\nmethods. Our method achieves 88.57%, 61.10%, and 36.69% top-1 accuracy on\nCIFAR10, CIFAR100, and TinyImagenet, respectively.",
            "author": [
                "Hengkui Dong",
                "Xianzhong Long",
                "Yun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00358v1",
                "http://arxiv.org/pdf/2311.00358v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00354v1",
            "title": "Butson Hadamard matrices, bent sequences, and spherical codes",
            "updated": "2023-11-01T08:03:11Z",
            "published": "2023-11-01T08:03:11Z",
            "summary": "We explore a notion of bent sequence attached to the data consisting of an\nHadamard matrix of order $n$ defined over the complex $q^{th}$ roots of unity,\nan eigenvalue of that matrix, and a Galois automorphism from the cyclotomic\nfield of order $q.$ In particular we construct self-dual bent sequences for\nvarious $q\\le 60$ and lengths $n\\le 21.$ Computational construction methods\ncomprise the resolution of polynomial systems by Groebner bases and eigenspace\ncomputations. Infinite families can be constructed from regular Hadamard\nmatrices, Bush-type Hadamard matrices, and generalized Boolean bent\nfunctions.As an application, we estimate the covering radius of the code\nattached to that matrix over $\\Z_q.$ We derive a lower bound on that quantity\nfor the Chinese Euclidean metric when bent sequences exist. We give the\nEuclidean distance spectrum, and bound above the covering radius of an attached\nspherical code, depending on its strength as a spherical design.",
            "author": [
                "Minjia Shi",
                "Danni Lu",
                "Andr\u00e9s Armario",
                "Ronan Egan",
                "Ferruh Ozbudak",
                "Patrick Sol\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00354v1",
                "http://arxiv.org/pdf/2311.00354v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00353v1",
            "title": "LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video\n  Translation",
            "updated": "2023-11-01T08:02:57Z",
            "published": "2023-11-01T08:02:57Z",
            "summary": "Leveraging the generative ability of image diffusion models offers great\npotential for zero-shot video-to-video translation. The key lies in how to\nmaintain temporal consistency across generated video frames by image diffusion\nmodels. Previous methods typically adopt cross-frame attention, \\emph{i.e.,}\nsharing the \\textit{key} and \\textit{value} tokens across attentions of\ndifferent frames, to encourage the temporal consistency. However, in those\nworks, temporal inconsistency issue may not be thoroughly solved, rendering the\nfidelity of generated videos limited.%The current state of the art cross-frame\nattention method aims at maintaining fine-grained visual details across frames,\nbut it is still challenged by the temporal coherence problem. In this paper, we\nfind the bottleneck lies in the unconstrained query tokens and propose a new\nzero-shot video-to-video translation framework, named \\textit{LatentWarp}. Our\napproach is simple: to constrain the query tokens to be temporally consistent,\nwe further incorporate a warping operation in the latent space to constrain the\nquery tokens. Specifically, based on the optical flow obtained from the\noriginal video, we warp the generated latent features of last frame to align\nwith the current frame during the denoising process. As a result, the\ncorresponding regions across the adjacent frames can share closely-related\nquery tokens and attention outputs, which can further improve latent-level\nconsistency to enhance visual temporal coherence of generated videos. Extensive\nexperiment results demonstrate the superiority of \\textit{LatentWarp} in\nachieving video-to-video translation with temporal coherence.",
            "author": [
                "Yuxiang Bao",
                "Di Qiu",
                "Guoliang Kang",
                "Baochang Zhang",
                "Bo Jin",
                "Kaiye Wang",
                "Pengfei Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00353v1",
                "http://arxiv.org/pdf/2311.00353v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00351v1",
            "title": "Relativistic second-order dissipative and anisotropic fluid dynamics in\n  the relaxation-time approximation for an ideal gas of massive particles",
            "updated": "2023-11-01T07:53:05Z",
            "published": "2023-11-01T07:53:05Z",
            "summary": "In this paper, we study all transport coefficients of second-order\ndissipative fluid dynamics derived in Ref.\\cite{Ambrus:2022vif} from the\nrelativistic Boltzmann equation in the relaxation-time approximation for the\ncollision integral. These transport coefficients are computed for a classical\nideal gas of massive particles, with and without taking into account the\nconservation of intrinsic quantum numbers. Through rigorous comparison between\nkinetic theory, second-order dissipative fluid dynamics, and leading-order\nanisotropic fluid dynamics for a (0+1)--dimensional boost-invariant flow\nscenario, we show that both fluid-dynamical theories describe the early\nfar-from-equilibrium stage of the expansion reasonably well.",
            "author": [
                "Victor Ambrus",
                "Etele Moln\u00e1r",
                "Dirk H. Rischke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00351v1",
                "http://arxiv.org/pdf/2311.00351v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04910v1",
            "title": "Ontology-Driven Processing of Transdisciplinary Domain Knowledge",
            "updated": "2023-11-01T07:42:34Z",
            "published": "2023-11-01T07:42:34Z",
            "summary": "The monograph discusses certain aspects of modern real-world problems facing\nhumanity, which are much more challenging than scientific ones. Modern science\nis unable to solve them in a fundamental way. Vernadsky's noosphere thesis, in\nfact, appeals to the scientific worldview that needs to be built in a way that\novercomes the interdisciplinary barriers and increases the effectiveness of\ninterdisciplinary interaction and modern science overall. We are talking about\nthe general transdisciplinary knowledge. In world practice, there is still no\nsystematic methodology and a specific form of generally accepted valid\nscientific theory that would provide transdisciplinary knowledge. Non-linear\ninterdisciplinary interaction is the standard of evolution of modern science.\nAt the same time, a new transdisciplinary theory (domain of scientific\nresearch) is being de facto created and the process is repeated many times:\nfrom an individual or group of disciplines, through interdisciplinary\ninteraction, in a direction that brings us closer to creating a holistic\ngeneral scientific worldview.",
            "author": [
                "Oleksandr Palagin",
                "Mykola Petrenko",
                "Sergii Kryvyi",
                "Mykola Boyko",
                "Kyrylo Malakhov"
            ],
            "link": [
                "http://dx.doi.org/10.31274/isudp.2023.140",
                "http://arxiv.org/abs/2311.04910v1",
                "http://arxiv.org/pdf/2311.04910v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00732v1",
            "title": "tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for\n  Detecting Tweets Self-reporting a COVID-19 Diagnosis",
            "updated": "2023-11-01T07:41:23Z",
            "published": "2023-11-01T07:41:23Z",
            "summary": "The paper describes a system developed for Task 1 at SMM4H 2023. The goal of\nthe task is to automatically distinguish tweets that self-report a COVID-19\ndiagnosis (for example, a positive test, clinical diagnosis, or\nhospitalization) from those that do not. We investigate the use of different\ntechniques for preprocessing tweets using four transformer-based models. The\nensemble of fine-tuned language models obtained an F1-score of 84.5%, which is\n4.1% higher than the average value.",
            "author": [
                "Anna Glazkova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00732v1",
                "http://arxiv.org/pdf/2311.00732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "68T50",
                "I.2.7; I.7.m; H.3.3; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00343v1",
            "title": "Analyzing Head Orientation of Neurotypical and Autistic Individuals in\n  Triadic Conversations",
            "updated": "2023-11-01T07:31:58Z",
            "published": "2023-11-01T07:31:58Z",
            "summary": "We propose a system that estimates people's body and head orientations using\nlow-resolution point cloud data from two LiDAR sensors. Our models make\naccurate estimations in real-world conversation settings where the subject\nmoves naturally with varying head and body poses. The body orientation\nestimation model uses ellipse fitting while the head orientation estimation\nmodel is a pipeline of geometric feature extraction and an ensemble of neural\nnetwork regressors. Compared with other body and head orientation estimation\nsystems using RGB cameras, our proposed system uses LiDAR sensors to preserve\nuser privacy, while achieving comparable accuracy. Unlike other body/head\norientation estimation systems, our sensors do not require a specified\nplacement in front of the subject. Our models achieve a mean absolute\nestimation error of 5.2 degrees for body orientation and 13.7 degrees for head\norientation. We use our models to quantify behavioral differences between\nneurotypical and autistic individuals in triadic conversations. Tests of\nsignificance show that people with autism spectrum disorder display\nsignificantly different behavior compared to neurotypical individuals in terms\nof distributing attention between participants in a conversation, suggesting\nthat the approach could be a component of a behavioral analysis or coaching\nsystem.",
            "author": [
                "Onur N. Tepencelik",
                "Wenchuan Wei",
                "Pamela C. Cosman",
                "Sujit Dey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00343v1",
                "http://arxiv.org/pdf/2311.00343v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00342v1",
            "title": "fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for\n  Multi-Subject Brain Activity Decoding",
            "updated": "2023-11-01T07:24:22Z",
            "published": "2023-11-01T07:24:22Z",
            "summary": "The exploration of brain activity and its decoding from fMRI data has been a\nlongstanding pursuit, driven by its potential applications in brain-computer\ninterfaces, medical diagnostics, and virtual reality. Previous approaches have\nprimarily focused on individual subject analysis, highlighting the need for a\nmore universal and adaptable framework, which is the core motivation behind our\nwork. In this work, we propose fMRI-PTE, an innovative auto-encoder approach\nfor fMRI pre-training, with a focus on addressing the challenges of varying\nfMRI data dimensions due to individual brain differences. Our approach involves\ntransforming fMRI signals into unified 2D representations, ensuring consistency\nin dimensions and preserving distinct brain activity patterns. We introduce a\nnovel learning strategy tailored for pre-training 2D fMRI images, enhancing the\nquality of reconstruction. fMRI-PTE's adaptability with image generators\nenables the generation of well-represented fMRI features, facilitating various\ndownstream tasks, including within-subject and cross-subject brain activity\ndecoding. Our contributions encompass introducing fMRI-PTE, innovative data\ntransformation, efficient training, a novel learning strategy, and the\nuniversal applicability of our approach. Extensive experiments validate and\nsupport our claims, offering a promising foundation for further research in\nthis domain.",
            "author": [
                "Xuelin Qian",
                "Yun Wang",
                "Jingyang Huo",
                "Jianfeng Feng",
                "Yanwei Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00342v1",
                "http://arxiv.org/pdf/2311.00342v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00341v2",
            "title": "The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct\n  Air Capture",
            "updated": "2023-11-27T05:51:13Z",
            "published": "2023-11-01T07:21:08Z",
            "summary": "New methods for carbon dioxide removal are urgently needed to combat global\nclimate change. Direct air capture (DAC) is an emerging technology to capture\ncarbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have\nbeen widely studied as potentially customizable adsorbents for DAC. However,\ndiscovering promising MOF sorbents for DAC is challenging because of the vast\nchemical space to explore and the need to understand materials as functions of\nhumidity and temperature. We explore a computational approach benefiting from\nrecent innovations in machine learning (ML) and present a dataset named Open\nDAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT)\ncalculations on more than 8,400 MOF materials containing adsorbed $CO_2$ and/or\n$H_2O$. ODAC23 is by far the largest dataset of MOF adsorption calculations at\nthe DFT level of accuracy currently available. In addition to probing\nproperties of adsorbed molecules, the dataset is a rich source of information\non structural relaxation of MOFs, which will be useful in many contexts beyond\nspecific applications for DAC. A large number of MOFs with promising properties\nfor DAC are identified directly in ODAC23. We also trained state-of-the-art ML\nmodels on this dataset to approximate calculations at the DFT level. This\nopen-source dataset and our initial ML models will provide an important\nbaseline for future efforts to identify MOFs for a wide range of applications,\nincluding DAC.",
            "author": [
                "Anuroop Sriram",
                "Sihoon Choi",
                "Xiaohan Yu",
                "Logan M. Brabson",
                "Abhishek Das",
                "Zachary Ulissi",
                "Matt Uyttendaele",
                "Andrew J. Medford",
                "David S. Sholl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00341v2",
                "http://arxiv.org/pdf/2311.00341v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00339v1",
            "title": "Space Narrative: Generating Images and 3D Scenes of Chinese Garden from\n  Text using Deep Learning",
            "updated": "2023-11-01T07:16:01Z",
            "published": "2023-11-01T07:16:01Z",
            "summary": "The consistent mapping from poems to paintings is essential for the research\nand restoration of traditional Chinese gardens. But the lack of firsthand\nma-terial is a great challenge to the reconstruction work. In this paper, we\npro-pose a method to generate garden paintings based on text descriptions using\ndeep learning method. Our image-text pair dataset consists of more than one\nthousand Ming Dynasty Garden paintings and their inscriptions and post-scripts.\nA latent text-to-image diffusion model learns the mapping from de-scriptive\ntexts to garden paintings of the Ming Dynasty, and then the text description of\nJichang Garden guides the model to generate new garden paintings. The cosine\nsimilarity between the guide text and the generated image is the evaluation\ncriterion for the generated images. Our dataset is used to fine-tune the\npre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models\n(LoRA). We also transformed the generated images into a panorama and created a\nfree-roam scene in Unity 3D. Our post-trained model is capable of generating\ngarden images in the style of Ming Dynasty landscape paintings based on textual\ndescriptions. The gener-ated images are compatible with three-dimensional\npresentation in Unity 3D.",
            "author": [
                "Jiaxi Shi1",
                "Hao Hua1"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00339v1",
                "http://arxiv.org/pdf/2311.00339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00337v1",
            "title": "Do the Hodge spectra distinguish orbifolds from manifolds? Part 2",
            "updated": "2023-11-01T07:10:33Z",
            "published": "2023-11-01T07:10:33Z",
            "summary": "In \\cite{GGKM-SSS} we examined the relationship between the singular set of a\ncompact Riemannian orbifold and the spectrum of the Hodge Laplacian on\n$p$-forms by computing the heat invariants associated to the $p$-spectrum. We\nshowed that the heat invariants of the $0$-spectrum together with those of the\n$1$-spectrum for the corresponding Hodge Laplacians are sufficient to\ndistinguish orbifolds from manifolds as long as the singular sets have\ncodimension $\\le 3.$ This is enough to distinguish orbifolds from manifolds for\ndimension $\\le 3.$ Here we give both positive and negative inverse spectral\nresults for the individual $p$-spectra considered separately. For example, we\ngive conditions on the codimension of the singular set which guarantee that the\nvolume of the singular set is determined, and in many cases we show by\nproviding counterexamples that the conditions are sharp.",
            "author": [
                "Katie Gittins",
                "Carolyn Gordon",
                "Ingrid Membrillo Solis",
                "Juan Pablo Rossetti",
                "Mary Sandoval",
                "Elizabeth Stanhope"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00337v1",
                "http://arxiv.org/pdf/2311.00337v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "58J53"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00334v2",
            "title": "MetisFL: An Embarrassingly Parallelized Controller for Scalable &\n  Efficient Federated Learning Workflows",
            "updated": "2023-11-13T07:12:55Z",
            "published": "2023-11-01T07:01:19Z",
            "summary": "A Federated Learning (FL) system typically consists of two core processing\nentities: the federation controller and the learners. The controller is\nresponsible for managing the execution of FL workflows across learners and the\nlearners for training and evaluating federated models over their private\ndatasets. While executing an FL workflow, the FL system has no control over the\ncomputational resources or data of the participating learners. Still, it is\nresponsible for other operations, such as model aggregation, task dispatching,\nand scheduling. These computationally heavy operations generally need to be\nhandled by the federation controller. Even though many FL systems have been\nrecently proposed to facilitate the development of FL workflows, most of these\nsystems overlook the scalability of the controller. To meet this need, we\ndesigned and developed a novel FL system called MetisFL, where the federation\ncontroller is the first-class citizen. MetisFL re-engineers all the operations\nconducted by the federation controller to accelerate the training of\nlarge-scale FL workflows. By quantitatively comparing MetisFL against other\nstate-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a\n10-fold wall-clock time execution boost across a wide range of challenging FL\nworkflows with increasing model sizes and federation sites.",
            "author": [
                "Dimitris Stripelis",
                "Chrysovalantis Anastasiou",
                "Patrick Toral",
                "Armaghan Asghar",
                "Jose Luis Ambite"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3630048.3630186",
                "http://arxiv.org/abs/2311.00334v2",
                "http://arxiv.org/pdf/2311.00334v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01473v1",
            "title": "Adversarial Examples in the Physical World: A Survey",
            "updated": "2023-11-01T06:55:09Z",
            "published": "2023-11-01T06:55:09Z",
            "summary": "Deep neural networks (DNNs) have demonstrated high vulnerability to\nadversarial examples. Besides the attacks in the digital world, the practical\nimplications of adversarial examples in the physical world present significant\nchallenges and safety concerns. However, current research on physical\nadversarial examples (PAEs) lacks a comprehensive understanding of their unique\ncharacteristics, leading to limited significance and understanding. In this\npaper, we address this gap by thoroughly examining the characteristics of PAEs\nwithin a practical workflow encompassing training, manufacturing, and\nre-sampling processes. By analyzing the links between physical adversarial\nattacks, we identify manufacturing and re-sampling as the primary sources of\ndistinct attributes and particularities in PAEs. Leveraging this knowledge, we\ndevelop a comprehensive analysis and classification framework for PAEs based on\ntheir specific characteristics, covering over 100 studies on physical-world\nadversarial examples. Furthermore, we investigate defense strategies against\nPAEs and identify open challenges and opportunities for future research. We aim\nto provide a fresh, thorough, and systematic understanding of PAEs, thereby\npromoting the development of robust adversarial learning and its application in\nopen-world scenarios.",
            "author": [
                "Jiakai Wang",
                "Donghua Wang",
                "Jin Hu",
                "Siyang Wu",
                "Tingsong Jiang",
                "Wen Yao",
                "Aishan Liu",
                "Xianglong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01473v1",
                "http://arxiv.org/pdf/2311.01473v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08416v1",
            "title": "Cultural context shapes the carbon footprints of recipes",
            "updated": "2023-11-01T06:51:21Z",
            "published": "2023-11-01T06:51:21Z",
            "summary": "Food systems are responsible for a third of global anthropogenic greenhouse\ngas emissions central to global warming and climate change. Increasing\nawareness of the environmental impact of food-centric emissions has led to the\ncarbon footprint quantification of food products. However, food consumption is\ndictated by traditional dishes, the cultural capsules that encode traditional\nprotocols for culinary preparations. Carbon footprint estimation of recipes\nwill provide actionable insights into the environmental sustainability of\nculturally influenced patterns in recipe compositions. By integrating the\ncarbon footprint data of food products with a gold-standard repository of\nrecipe compositions, we show that the ingredient constitution dictates the\ncarbon load of recipes. Beyond the prevalent focus on individual food products,\nour analysis quantifies the carbon footprint of recipes within the cultural\ncontexts that shape culinary protocols. While emphasizing the widely understood\nharms of animal-sourced ingredients, this article presents a nuanced\nperspective on the environmental impact of culturally influenced dietary\npractices. Along with the grasp of taste and nutrition correlates, such an\nunderstanding can help design palatable and environmentally sustainable\nrecipes. Systematic compilation of fine-grained carbon footprint data is the\nway forward to address the challenge of sustainably feeding an anticipated\npopulation of 10 billion.",
            "author": [
                "Mansi Goel",
                "Vishva Nathavani",
                "Smit Dharaiya",
                "Vidhya Kothadia",
                "Saloni Srivastava",
                "Ganesh Bagler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08416v1",
                "http://arxiv.org/pdf/2311.08416v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00332v2",
            "title": "SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart\n  Defects",
            "updated": "2023-11-08T09:45:49Z",
            "published": "2023-11-01T06:50:53Z",
            "summary": "Congenital heart disease (CHD) encompasses a spectrum of cardiovascular\nstructural abnormalities, often requiring customized treatment plans for\nindividual patients. Computational modeling and analysis of these unique\ncardiac anatomies can improve diagnosis and treatment planning and may\nultimately lead to improved outcomes. Deep learning (DL) methods have\ndemonstrated the potential to enable efficient treatment planning by automating\ncardiac segmentation and mesh construction for patients with normal cardiac\nanatomies. However, CHDs are often rare, making it challenging to acquire\nsufficiently large patient cohorts for training such DL models. Generative\nmodeling of cardiac anatomies has the potential to fill this gap via the\ngeneration of virtual cohorts; however, prior approaches were largely designed\nfor normal anatomies and cannot readily capture the significant topological\nvariations seen in CHD patients. Therefore, we propose a type- and\nshape-disentangled generative approach suitable to capture the wide spectrum of\ncardiac anatomies observed in different CHD types and synthesize differently\nshaped cardiac anatomies that preserve the unique topology for specific CHD\ntypes. Our DL approach represents generic whole heart anatomies with CHD\ntype-specific abnormalities implicitly using signed distance fields (SDF) based\non CHD type diagnosis, which conveniently captures divergent anatomical\nvariations across different types and represents meaningful intermediate CHD\nstates. To capture the shape-specific variations, we then learn invertible\ndeformations to morph the learned CHD type-specific anatomies and reconstruct\npatient-specific shapes. Our approach has the potential to augment the\nimage-segmentation pairs for rarer CHD types for cardiac segmentation and\ngenerate cohorts of CHD cardiac meshes for computational simulation.",
            "author": [
                "Fanwei Kong",
                "Sascha Stocker",
                "Perry S. Choi",
                "Michael Ma",
                "Daniel B. Ennis",
                "Alison Marsden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00332v2",
                "http://arxiv.org/pdf/2311.00332v2"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00329v1",
            "title": "The entropic origin of the enhancement of liquid diffusion at the\n  confining wall",
            "updated": "2023-11-01T06:46:37Z",
            "published": "2023-11-01T06:46:37Z",
            "summary": "We report a molecular dynamics simulation investigating the dynamics of a\nsimple liquid in the proximity to a non-interacting smooth confining wall. A\nstrong enhancement of the liquid diffusion is observed within the layers\nadjacent to the wall. We present an analysis of these results in terms of the\nscaling law earlier reported by one of us that relates the liquid diffusion\nrate to the excess entropy. It is demonstrated that this scaling law can\nsuccessfully account for the observed diffusion enhancement in the liquid near\nto the confining wall. We show that the proximity of a confining wall results\nin the decrease of (the absolute value of) the local excess entropy in the\nliquid layers closest to the wall which induces the observed diffusion\nenhancement in these layers. These results thereby show that the application\nscope of the scaling law which has so far only been used for the description of\nthe bulk liquid diffusion can be extended to the diffusion in liquids under\nnano-scale confinement.",
            "author": [
                "Lorenzo Agosta",
                "Mikhail Dzugutov",
                "Wim Briels",
                "Kersti Hermansson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00329v1",
                "http://arxiv.org/pdf/2311.00329v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00328v1",
            "title": "Fault-Tolerant Design Approach Based on Approximate Computing",
            "updated": "2023-11-01T06:33:12Z",
            "published": "2023-11-01T06:33:12Z",
            "summary": "Triple Modular Redundancy (TMR) has been traditionally used to ensure\ncomplete tolerance to a single fault or a faulty processing unit, where the\nprocessing unit may be a circuit or a system. However, TMR incurs more than\n200% overhead in terms of area and power compared to a single processing unit.\nHence, alternative redundancy approaches were proposed in the literature to\nmitigate the design overheads associated with TMR, but they provide only\npartial or moderate fault tolerance. This research presents a new\nfault-tolerant design approach based on approximate computing called FAC that\nhas the same fault tolerance as TMR and achieves significant reductions in the\ndesign metrics for physical implementation. FAC is suited for a plethora of\nerror-tolerant applications. Here, the performance of TMR and FAC has been\nevaluated for a digital image processing application. The image processing\nresults obtained confirm the usefulness of FAC. When an example processing unit\nwas implemented using a 28-nm CMOS technology, FAC achieved a 15.3% reduction\nin delay, a 19.5% reduction in area, and a 24.7% reduction in power compared to\nTMR.",
            "author": [
                "P Balasubramanian",
                "D L Maskell"
            ],
            "link": [
                "http://dx.doi.org/10.3390/electronics12183819",
                "http://arxiv.org/abs/2311.00328v1",
                "http://arxiv.org/pdf/2311.00328v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00326v1",
            "title": "Transport and electrical properties of cryogenic thermoelectric FeSb2:\n  the effect of isoelectronic and hole doping",
            "updated": "2023-11-01T06:28:07Z",
            "published": "2023-11-01T06:28:07Z",
            "summary": "Thermoelectric materials operating at cryogenic temperatures are in high\ndemand for efficient cooling and power generation in applications ranging from\nsuperconductors to quantum computing. The narrow band-gap semiconductor FeSb2,\nknown for its colossal Seebeck coefficient, holds promise for such\napplications, provided its thermal conductivity value can be reduced. This\nstudy investigates the impact of isoelectronic substitution (Bi) and hole\ndoping (Pb) at the Sb site on the transport properties of FeSb2, with a\nparticular focus on thermal conductivity (\\k{appa}). Polycrystalline FeSb2\npowder, along with Bi- and Pb-doped samples, were synthesized using a simple\nco-precipitation approach, followed by thermal treatment in an H2 atmosphere.\nXRD and SEM analysis confirms the formation of the desired phase pre- and\npost-consolidation using spark plasma sintering (SPS). The consolidation\nprocess resulted in a high compaction density and the formation of\nsubmicrometer-sized grains, as substantiated by electron backscattered\ndiffraction (EBSD) analysis. Substituting 1% of Bi and Pb at the Sb site\nsuccessfully suppressed the thermal conductivity (\\k{appa}) from ~15 W/m-K in\npure FeSb2 to ~10 and ~8.7 W/m-K, respectively. Importantly, resistivity\nmeasurements revealed a metal-to-insulator transition at around 6.5 K in\nundoped FeSb2 and isoelectronically Bi-substituted FeSb2, suggesting the\nexistence of metallic surface states and provides valuable evidence for the\nperplexing topological behavior exhibited by FeSb2.",
            "author": [
                "Deepak Gujjar",
                "Sunidhi Gujjar",
                "V. K. Malik",
                "Hem C. Kandpal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00326v1",
                "http://arxiv.org/pdf/2311.00326v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00731v1",
            "title": "Enhancing Clustering Representations with Positive Proximity and Cluster\n  Dispersion Learning",
            "updated": "2023-11-01T06:12:02Z",
            "published": "2023-11-01T06:12:02Z",
            "summary": "Contemporary deep clustering approaches often rely on either contrastive or\nnon-contrastive techniques to acquire effective representations for clustering\ntasks. Contrastive methods leverage negative pairs to achieve homogenous\nrepresentations but can introduce class collision issues, potentially\ncompromising clustering performance. On the contrary, non-contrastive\ntechniques prevent class collisions but may produce non-uniform representations\nthat lead to clustering collapse. In this work, we propose a novel end-to-end\ndeep clustering approach named PIPCDR, designed to harness the strengths of\nboth approaches while mitigating their limitations. PIPCDR incorporates a\npositive instance proximity loss and a cluster dispersion regularizer. The\npositive instance proximity loss ensures alignment between augmented views of\ninstances and their sampled neighbors, enhancing within-cluster compactness by\nselecting genuinely positive pairs within the embedding space. Meanwhile, the\ncluster dispersion regularizer maximizes inter-cluster distances while\nminimizing within-cluster compactness, promoting uniformity in the learned\nrepresentations. PIPCDR excels in producing well-separated clusters, generating\nuniform representations, avoiding class collision issues, and enhancing\nwithin-cluster compactness. We extensively validate the effectiveness of PIPCDR\nwithin an end-to-end Majorize-Minimization framework, demonstrating its\ncompetitive performance on moderate-scale clustering benchmark datasets and\nestablishing new state-of-the-art results on large-scale datasets.",
            "author": [
                "Abhishek Kumar",
                "Dong-Gyu Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00731v1",
                "http://arxiv.org/pdf/2311.00731v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00321v2",
            "title": "HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning",
            "updated": "2023-11-22T09:08:03Z",
            "published": "2023-11-01T06:09:54Z",
            "summary": "With the proliferation of social media, accurate detection of hate speech has\nbecome critical to ensure safety online. To combat nuanced forms of hate\nspeech, it is important to identify and thoroughly explain hate speech to help\nusers understand its harmful effects. Recent benchmarks have attempted to\ntackle this issue by training generative models on free-text annotations of\nimplications in hateful text. However, we find significant reasoning gaps in\nthe existing annotations schemes, which may hinder the supervision of detection\nmodels. In this paper, we introduce a hate speech detection framework, HARE,\nwhich harnesses the reasoning capabilities of large language models (LLMs) to\nfill these gaps in explanations of hate speech, thus enabling effective\nsupervision of detection models. Experiments on SBIC and Implicit Hate\nbenchmarks show that our method, using model-generated data, consistently\noutperforms baselines, using existing free-text human annotations. Analysis\ndemonstrates that our method enhances the explanation quality of trained models\nand improves generalization to unseen datasets. Our code is available at\nhttps://github.com/joonkeekim/hare-hate-speech.git.",
            "author": [
                "Yongjin Yang",
                "Joonkee Kim",
                "Yujin Kim",
                "Namgyu Ho",
                "James Thorne",
                "Se-young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00321v2",
                "http://arxiv.org/pdf/2311.00321v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00318v1",
            "title": "Flooding Regularization for Stable Training of Generative Adversarial\n  Networks",
            "updated": "2023-11-01T06:02:59Z",
            "published": "2023-11-01T06:02:59Z",
            "summary": "Generative Adversarial Networks (GANs) have shown remarkable performance in\nimage generation. However, GAN training suffers from the problem of\ninstability. One of the main approaches to address this problem is to modify\nthe loss function, often using regularization terms in addition to changing the\ntype of adversarial losses. This paper focuses on directly regularizing the\nadversarial loss function. We propose a method that applies flooding, an\noverfitting suppression method in supervised learning, to GANs to directly\nprevent the discriminator's loss from becoming excessively low. Flooding\nrequires tuning the flood level, but when applied to GANs, we propose that the\nappropriate range of flood level settings is determined by the adversarial loss\nfunction, supported by theoretical analysis of GANs using the binary cross\nentropy loss. We experimentally verify that flooding stabilizes GAN training\nand can be combined with other stabilization techniques. We also reveal that by\nrestricting the discriminator's loss to be no greater than flood level, the\ntraining proceeds stably even when the flood level is somewhat high.",
            "author": [
                "Iu Yahiro",
                "Takashi Ishida",
                "Naoto Yokoya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00318v1",
                "http://arxiv.org/pdf/2311.00318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00317v1",
            "title": "Data Augmentation for Code Translation with Comparable Corpora and\n  Multiple References",
            "updated": "2023-11-01T06:01:22Z",
            "published": "2023-11-01T06:01:22Z",
            "summary": "One major challenge of translating code between programming languages is that\nparallel training data is often limited. To overcome this challenge, we present\ntwo data augmentation techniques, one that builds comparable corpora (i.e.,\ncode pairs with similar functionality), and another that augments existing\nparallel data with multiple reference translations. Specifically, we build and\nanalyze multiple types of comparable corpora, including programs generated from\nnatural language documentation using a code generation model. Furthermore, to\nreduce overfitting to a single reference translation, we automatically generate\nadditional translation references for available parallel data and filter the\ntranslations by unit tests, which increases variation in target translations.\nExperiments show that our data augmentation techniques significantly improve\nCodeT5 for translation between Java, Python, and C++ by an average of 7.5%\nComputational Accuracy (CA@1), which verifies the correctness of translations\nby execution. The code is available at https://github.com/Veronicium/CMTrans.",
            "author": [
                "Yiqing Xie",
                "Atharva Naik",
                "Daniel Fried",
                "Carolyn Rose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00317v1",
                "http://arxiv.org/pdf/2311.00317v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00310v1",
            "title": "Unsupervised Lexical Simplification with Context Augmentation",
            "updated": "2023-11-01T05:48:05Z",
            "published": "2023-11-01T05:48:05Z",
            "summary": "We propose a new unsupervised lexical simplification method that uses only\nmonolingual data and pre-trained language models. Given a target word and its\ncontext, our method generates substitutes based on the target context and also\nadditional contexts sampled from monolingual data. We conduct experiments in\nEnglish, Portuguese, and Spanish on the TSAR-2022 shared task, and show that\nour model substantially outperforms other unsupervised systems across all\nlanguages. We also establish a new state-of-the-art by ensembling our model\nwith GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution\ndata set, achieving a state-of-the-art result.",
            "author": [
                "Takashi Wada",
                "Timothy Baldwin",
                "Jey Han Lau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00310v1",
                "http://arxiv.org/pdf/2311.00310v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00308v1",
            "title": "From Image to Language: A Critical Analysis of Visual Question Answering\n  (VQA) Approaches, Challenges, and Opportunities",
            "updated": "2023-11-01T05:39:41Z",
            "published": "2023-11-01T05:39:41Z",
            "summary": "The multimodal task of Visual Question Answering (VQA) encompassing elements\nof Computer Vision (CV) and Natural Language Processing (NLP), aims to generate\nanswers to questions on any visual input. Over time, the scope of VQA has\nexpanded from datasets focusing on an extensive collection of natural images to\ndatasets featuring synthetic images, video, 3D environments, and various other\nvisual inputs. The emergence of large pre-trained networks has shifted the\nearly VQA approaches relying on feature extraction and fusion schemes to vision\nlanguage pre-training (VLP) techniques. However, there is a lack of\ncomprehensive surveys that encompass both traditional VQA architectures and\ncontemporary VLP-based methods. Furthermore, the VLP challenges in the lens of\nVQA haven't been thoroughly explored, leaving room for potential open problems\nto emerge. Our work presents a survey in the domain of VQA that delves into the\nintricacies of VQA datasets and methods over the field's history, introduces a\ndetailed taxonomy to categorize the facets of VQA, and highlights the recent\ntrends, challenges, and scopes for improvement. We further generalize VQA to\nmultimodal question answering, explore tasks related to VQA, and present a set\nof open problems for future investigation. The work aims to navigate both\nbeginners and experts by shedding light on the potential avenues of research\nand expanding the boundaries of the field.",
            "author": [
                "Md Farhan Ishmam",
                "Md Sakib Hossain Shovon",
                "M. F. Mridha",
                "Nilanjan Dey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00308v1",
                "http://arxiv.org/pdf/2311.00308v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00306v1",
            "title": "Probing Explicit and Implicit Gender Bias through LLM Conditional Text\n  Generation",
            "updated": "2023-11-01T05:31:46Z",
            "published": "2023-11-01T05:31:46Z",
            "summary": "Large Language Models (LLMs) can generate biased and toxic responses. Yet\nmost prior work on LLM gender bias evaluation requires predefined\ngender-related phrases or gender stereotypes, which are challenging to be\ncomprehensively collected and are limited to explicit bias evaluation. In\naddition, we believe that instances devoid of gender-related language or\nexplicit stereotypes in inputs can still induce gender bias in LLMs. Thus, in\nthis work, we propose a conditional text generation mechanism without the need\nfor predefined gender phrases and stereotypes. This approach employs three\ntypes of inputs generated through three distinct strategies to probe LLMs,\naiming to show evidence of explicit and implicit gender biases in LLMs. We also\nutilize explicit and implicit evaluation metrics to evaluate gender bias in\nLLMs under different strategies. Our experiments demonstrate that an increased\nmodel size does not consistently lead to enhanced fairness and all tested LLMs\nexhibit explicit and/or implicit gender bias, even when explicit gender\nstereotypes are absent in the inputs.",
            "author": [
                "Xiangjue Dong",
                "Yibo Wang",
                "Philip S. Yu",
                "James Caverlee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00306v1",
                "http://arxiv.org/pdf/2311.00306v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00301v1",
            "title": "Detecting Syllable-Level Pronunciation Stress with A Self-Attention\n  Model",
            "updated": "2023-11-01T05:05:49Z",
            "published": "2023-11-01T05:05:49Z",
            "summary": "One precondition of effective oral communication is that words should be\npronounced clearly, especially for non-native speakers. Word stress is the key\nto clear and correct English, and misplacement of syllable stress may lead to\nmisunderstandings. Thus, knowing the stress level is important for English\nspeakers and learners. This paper presents a self-attention model to identify\nthe stress level for each syllable of spoken English. Various prosodic and\ncategorical features, including the pitch level, intensity, duration and type\nof the syllable and its nuclei (the vowel of the syllable), are explored. These\nfeatures are input to the self-attention model, and syllable-level stresses are\npredicted. The simplest model yields an accuracy of over 88% and 93% on\ndifferent datasets, while more advanced models provide higher accuracy. Our\nstudy suggests that the self-attention model can be promising in stress-level\ndetection. These models could be applied to various scenarios, such as online\nmeetings and English learning.",
            "author": [
                "Wang Weiying",
                "Nakajima Akinori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00301v1",
                "http://arxiv.org/pdf/2311.00301v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00300v1",
            "title": "Entity Alignment Method of Science and Technology Patent based on Graph\n  Convolution Network and Information Fusion",
            "updated": "2023-11-01T05:04:55Z",
            "published": "2023-11-01T05:04:55Z",
            "summary": "The entity alignment of science and technology patents aims to link the\nequivalent entities in the knowledge graph of different science and technology\npatent data sources. Most entity alignment methods only use graph neural\nnetwork to obtain the embedding of graph structure or use attribute text\ndescription to obtain semantic representation, ignoring the process of\nmulti-information fusion in science and technology patents. In order to make\nuse of the graphic structure and auxiliary information such as the name,\ndescription and attribute of the patent entity, this paper proposes an entity\nalignment method based on the graph convolution network for science and\ntechnology patent information fusion. Through the graph convolution network and\nBERT model, the structure information and entity attribute information of the\nscience and technology patent knowledge graph are embedded and represented to\nachieve multi-information fusion, thus improving the performance of entity\nalignment. Experiments on three benchmark data sets show that the proposed\nmethod Hit@K The evaluation indicators are better than the existing methods.",
            "author": [
                "Runze Fang",
                "Yawen Li",
                "Yingxia Shao",
                "Zeli Guan",
                "Zhe Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00300v1",
                "http://arxiv.org/pdf/2311.00300v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00298v1",
            "title": "An Empirical Study of Frame Selection for Text-to-Video Retrieval",
            "updated": "2023-11-01T05:03:48Z",
            "published": "2023-11-01T05:03:48Z",
            "summary": "Text-to-video retrieval (TVR) aims to find the most relevant video in a large\nvideo gallery given a query text. The intricate and abundant context of the\nvideo challenges the performance and efficiency of TVR. To handle the\nserialized video contexts, existing methods typically select a subset of frames\nwithin a video to represent the video content for TVR. How to select the most\nrepresentative frames is a crucial issue, whereby the selected frames are\nrequired to not only retain the semantic information of the video but also\npromote retrieval efficiency by excluding temporally redundant frames. In this\npaper, we make the first empirical study of frame selection for TVR. We\nsystemically classify existing frame selection methods into text-free and\ntext-guided ones, under which we detailedly analyze six different frame\nselections in terms of effectiveness and efficiency. Among them, two frame\nselections are first developed in this paper. According to the comprehensive\nanalysis on multiple TVR benchmarks, we empirically conclude that the TVR with\nproper frame selections can significantly improve the retrieval efficiency\nwithout sacrificing the retrieval performance.",
            "author": [
                "Mengxia Wu",
                "Min Cao",
                "Yang Bai",
                "Ziyin Zeng",
                "Chen Chen",
                "Liqiang Nie",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00298v1",
                "http://arxiv.org/pdf/2311.00298v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00296v1",
            "title": "Semantic Representation Learning of Scientific Literature based on\n  Adaptive Feature and Graph Neural Network",
            "updated": "2023-11-01T05:00:44Z",
            "published": "2023-11-01T05:00:44Z",
            "summary": "Because most of the scientific literature data is unmarked, it makes semantic\nrepresentation learning based on unsupervised graph become crucial. At the same\ntime, in order to enrich the features of scientific literature, a learning\nmethod of semantic representation of scientific literature based on adaptive\nfeatures and graph neural network is proposed. By introducing the adaptive\nfeature method, the features of scientific literature are considered globally\nand locally. The graph attention mechanism is used to sum the features of\nscientific literature with citation relationship, and give each scientific\nliterature different feature weights, so as to better express the correlation\nbetween the features of different scientific literature. In addition, an\nunsupervised graph neural network semantic representation learning method is\nproposed. By comparing the mutual information between the positive and negative\nlocal semantic representation of scientific literature and the global graph\nsemantic representation in the potential space, the graph neural network can\ncapture the local and global information, thus improving the learning ability\nof the semantic representation of scientific literature. The experimental\nresults show that the proposed learning method of semantic representation of\nscientific literature based on adaptive feature and graph neural network is\ncompetitive on the basis of scientific literature classification, and has\nachieved good results.",
            "author": [
                "Hongrui Gao",
                "Yawen Li",
                "Meiyu Liang",
                "Zeli Guan",
                "Zhe Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00296v1",
                "http://arxiv.org/pdf/2311.00296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00292v1",
            "title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for\n  Debiasing NLU models",
            "updated": "2023-11-01T04:50:38Z",
            "published": "2023-11-01T04:50:38Z",
            "summary": "As commonly-used methods for debiasing natural language understanding (NLU)\nmodels, dataset refinement approaches heavily rely on manual data analysis, and\nthus maybe unable to cover all the potential biased features. In this paper, we\npropose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which\ndebiases NLU models without predefining biased features. We maintain an\niteratively expanded sample pool. Specifically, at each iteration, we first\ntrain a shallow model to quantify the bias degree of samples in the pool. Then,\nwe pair each sample with a bias indicator representing its bias degree, and use\nthese extended samples to train a sample generator. In this way, this generator\ncan effectively learn the correspondence relationship between bias indicators\nand samples. Furthermore, we employ the generator to produce pseudo samples\nwith fewer biased features by feeding specific bias indicators. Finally, we\nincorporate the generated pseudo samples into the pool. Experimental results\nand in-depth analyses on two NLU tasks show that IBADR not only significantly\noutperforms existing dataset refinement approaches, achieving SOTA, but also is\ncompatible with model-centric methods.",
            "author": [
                "Xiaoyue Wang",
                "Xin Liu",
                "Lijie Wang",
                "Yaoxiang Wang",
                "Jinsong Su",
                "Hua Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00292v1",
                "http://arxiv.org/pdf/2311.00292v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00291v1",
            "title": "Graph Representation Learning for Infrared and Visible Image Fusion",
            "updated": "2023-11-01T04:46:20Z",
            "published": "2023-11-01T04:46:20Z",
            "summary": "Infrared and visible image fusion aims to extract complementary features to\nsynthesize a single fused image. Many methods employ convolutional neural\nnetworks (CNNs) to extract local features due to its translation invariance and\nlocality. However, CNNs fail to consider the image's non-local self-similarity\n(NLss), though it can expand the receptive field by pooling operations, it\nstill inevitably leads to information loss. In addition, the transformer\nstructure extracts long-range dependence by considering the correlativity among\nall image patches, leading to information redundancy of such transformer-based\nmethods. However, graph representation is more flexible than grid (CNN) or\nsequence (transformer structure) representation to address irregular objects,\nand graph can also construct the relationships among the spatially repeatable\ndetails or texture with far-space distance. Therefore, to address the above\nissues, it is significant to convert images into the graph space and thus adopt\ngraph convolutional networks (GCNs) to extract NLss. This is because the graph\ncan provide a fine structure to aggregate features and propagate information\nacross the nearest vertices without introducing redundant information.\nConcretely, we implement a cascaded NLss extraction pattern to extract NLss of\nintra- and inter-modal by exploring interactions of different image pixels in\nintra- and inter-image positional distance. We commence by preforming GCNs on\neach intra-modal to aggregate features and propagate information to extract\nindependent intra-modal NLss. Then, GCNs are performed on the concatenate\nintra-modal NLss features of infrared and visible images, which can explore the\ncross-domain NLss of inter-modal to reconstruct the fused image. Ablation\nstudies and extensive experiments illustrates the effectiveness and superiority\nof the proposed method on three datasets.",
            "author": [
                "Jing Li",
                "Lu Bai",
                "Bin Yang",
                "Chang Li",
                "Lingfei Ma",
                "Edwin R. Hancock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00291v1",
                "http://arxiv.org/pdf/2311.00291v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00290v2",
            "title": "Inference of CO2 flow patterns -- a feasibility study",
            "updated": "2023-11-29T01:55:38Z",
            "published": "2023-11-01T04:41:25Z",
            "summary": "As the global deployment of carbon capture and sequestration (CCS) technology\nintensifies in the fight against climate change, it becomes increasingly\nimperative to establish robust monitoring and detection mechanisms for\npotential underground CO2 leakage, particularly through pre-existing or induced\nfaults in the storage reservoir's seals. While techniques such as history\nmatching and time-lapse seismic monitoring of CO2 storage have been used\nsuccessfully in tracking the evolution of CO2 plumes in the subsurface, these\nmethods lack principled approaches to characterize uncertainties related to the\nCO2 plumes' behavior. Inclusion of systematic assessment of uncertainties is\nessential for risk mitigation for the following reasons: (i) CO2 plume-induced\nchanges are small and seismic data is noisy; (ii) changes between regular and\nirregular (e.g., caused by leakage) flow patterns are small; and (iii) the\nreservoir properties that control the flow are strongly heterogeneous and\ntypically only available as distributions. To arrive at a formulation capable\nof inferring flow patterns for regular and irregular flow from well and seismic\ndata, the performance of conditional normalizing flow will be analyzed on a\nseries of carefully designed numerical experiments. While the inferences\npresented are preliminary in the context of an early CO2 leakage detection\nsystem, the results do indicate that inferences with conditional normalizing\nflows can produce high-fidelity estimates for CO2 plumes with or without\nleakage. We are also confident that the inferred uncertainty is reasonable\nbecause it correlates well with the observed errors. This uncertainty stems\nfrom noise in the seismic data and from the lack of precise knowledge of the\nreservoir's fluid flow properties.",
            "author": [
                "Abhinav Prakash Gahlot",
                "Huseyin Tuna Erdinc",
                "Rafael Orozco",
                "Ziyi Yin",
                "Felix J. Herrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00290v2",
                "http://arxiv.org/pdf/2311.00290v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI",
                "cs.LG",
                "math-ph",
                "math.MP",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00289v1",
            "title": "Precise Error Rates for Computationally Efficient Testing",
            "updated": "2023-11-01T04:41:16Z",
            "published": "2023-11-01T04:41:16Z",
            "summary": "We revisit the fundamental question of simple-versus-simple hypothesis\ntesting with an eye towards computational complexity, as the statistically\noptimal likelihood ratio test is often computationally intractable in\nhigh-dimensional settings. In the classical spiked Wigner model (with a general\ni.i.d. spike prior) we show that an existing test based on linear spectral\nstatistics achieves the best possible tradeoff curve between type I and type II\nerror rates among all computationally efficient tests, even though there are\nexponential-time tests that do better. This result is conditional on an\nappropriate complexity-theoretic conjecture, namely a natural strengthening of\nthe well-established low-degree conjecture. Our result shows that the spectrum\nis a sufficient statistic for computationally bounded tests (but not for all\ntests).\n  To our knowledge, our approach gives the first tool for reasoning about the\nprecise asymptotic testing error achievable with efficient computation. The\nmain ingredients required for our hardness result are a sharp bound on the norm\nof the low-degree likelihood ratio along with (counterintuitively) a positive\nresult on achievability of testing. This strategy appears to be new even in the\nsetting of unbounded computation, in which case it gives an alternate way to\nanalyze the fundamental statistical limits of testing.",
            "author": [
                "Ankur Moitra",
                "Alexander S. Wein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00289v1",
                "http://arxiv.org/pdf/2311.00289v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00288v1",
            "title": "Active Instruction Tuning: Improving Cross-Task Generalization by\n  Training on Prompt Sensitive Tasks",
            "updated": "2023-11-01T04:40:05Z",
            "published": "2023-11-01T04:40:05Z",
            "summary": "Instruction tuning (IT) achieves impressive zero-shot generalization results\nby training large language models (LLMs) on a massive amount of diverse tasks\nwith instructions. However, how to select new tasks to improve the performance\nand generalizability of IT models remains an open question. Training on all\nexisting tasks is impractical due to prohibiting computation requirements, and\nrandomly selecting tasks can lead to suboptimal performance. In this work, we\npropose active instruction tuning based on prompt uncertainty, a novel\nframework to identify informative tasks, and then actively tune the models on\nthe selected tasks. We represent the informativeness of new tasks with the\ndisagreement of the current model outputs over perturbed prompts. Our\nexperiments on NIV2 and Self-Instruct datasets demonstrate that our method\nconsistently outperforms other baseline strategies for task selection,\nachieving better out-of-distribution generalization with fewer training tasks.\nAdditionally, we introduce a task map that categorizes and diagnoses tasks\nbased on prompt uncertainty and prediction probability. We discover that\ntraining on ambiguous (prompt-uncertain) tasks improves generalization while\ntraining on difficult (prompt-certain and low-probability) tasks offers no\nbenefit, underscoring the importance of task selection for instruction tuning.",
            "author": [
                "Po-Nien Kung",
                "Fan Yin",
                "Di Wu",
                "Kai-Wei Chang",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00288v1",
                "http://arxiv.org/pdf/2311.00288v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00287v1",
            "title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data\n  Generation with Large Language Models",
            "updated": "2023-11-01T04:37:28Z",
            "published": "2023-11-01T04:37:28Z",
            "summary": "Clinical natural language processing requires methods that can address\ndomain-specific challenges, such as complex medical terminology and clinical\ncontexts. Recently, large language models (LLMs) have shown promise in this\ndomain. Yet, their direct deployment can lead to privacy issues and are\nconstrained by resources. To address this challenge, we delve into synthetic\nclinical text generation using LLMs for clinical NLP tasks. We propose an\ninnovative, resource-efficient approach, ClinGen, which infuses knowledge into\nthe process. Our model involves clinical knowledge extraction and\ncontext-informed LLM prompting. Both clinical topics and writing styles are\ndrawn from external domain-specific knowledge graphs and LLMs to guide data\ngeneration. Our extensive empirical study across 7 clinical NLP tasks and 16\ndatasets reveals that ClinGen consistently enhances performance across various\ntasks, effectively aligning the distribution of real datasets and significantly\nenriching the diversity of generated training instances. We will publish our\ncode and all the generated data in \\url{https://github.com/ritaranx/ClinGen}.",
            "author": [
                "Ran Xu",
                "Hejie Cui",
                "Yue Yu",
                "Xuan Kan",
                "Wenqi Shi",
                "Yuchen Zhuang",
                "Wei Jin",
                "Joyce Ho",
                "Carl Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00287v1",
                "http://arxiv.org/pdf/2311.00287v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00286v2",
            "title": "JADE: A Linguistics-based Safety Evaluation Platform for LLM",
            "updated": "2023-11-02T02:36:47Z",
            "published": "2023-11-01T04:36:45Z",
            "summary": "In this paper, we present JADE, a targeted linguistic fuzzing platform which\nstrengthens the linguistic complexity of seed questions to simultaneously and\nconsistently break a wide range of widely-used LLMs categorized in three\ngroups: eight open-sourced Chinese, six commercial Chinese and four commercial\nEnglish LLMs. JADE generates three safety benchmarks for the three groups of\nLLMs, which contain unsafe questions that are highly threatening: the questions\nsimultaneously trigger harmful generation of multiple LLMs, with an average\nunsafe generation ratio of $70\\%$ (please see the table below), while are still\nnatural questions, fluent and preserving the core unsafe semantics. We release\nthe benchmark demos generated for commercial English LLMs and open-sourced\nEnglish LLMs in the following link: https://github.com/whitzard-ai/jade-db. For\nreaders who are interested in evaluating on more questions generated by JADE,\nplease contact us.\n  JADE is based on Noam Chomsky's seminal theory of transformational-generative\ngrammar. Given a seed question with unsafe intention, JADE invokes a sequence\nof generative and transformational rules to increment the complexity of the\nsyntactic structure of the original question, until the safety guardrail is\nbroken. Our key insight is: Due to the complexity of human language, most of\nthe current best LLMs can hardly recognize the invariant evil from the infinite\nnumber of different syntactic structures which form an unbound example space\nthat can never be fully covered. Technically, the generative/transformative\nrules are constructed by native speakers of the languages, and, once developed,\ncan be used to automatically grow and transform the parse tree of a given\nquestion, until the guardrail is broken. For more evaluation results and demo,\nplease check our website: https://whitzard-ai.github.io/jade.html.",
            "author": [
                "Mi Zhang",
                "Xudong Pan",
                "Min Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00286v2",
                "http://arxiv.org/pdf/2311.00286v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00285v1",
            "title": "Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space\n  Detection Approach",
            "updated": "2023-11-01T04:36:18Z",
            "published": "2023-11-01T04:36:18Z",
            "summary": "Open Set Domain Adaptation (OSDA) aims to cope with the distribution and\nlabel shifts between the source and target domains simultaneously, performing\naccurate classification for known classes while identifying unknown class\nsamples in the target domain. Most existing OSDA approaches, depending on the\nfinal image feature space of deep models, require manually-tuned thresholds,\nand may easily misclassify unknown samples as known classes. Mixture-of-Expert\n(MoE) could be a remedy. Within an MoE, different experts address different\ninput features, producing unique expert routing patterns for different classes\nin a routing feature space. As a result, unknown class samples may also display\ndifferent expert routing patterns to known classes. This paper proposes\nDual-Space Detection, which exploits the inconsistencies between the image\nfeature space and the routing feature space to detect unknown class samples\nwithout any threshold. Graph Router is further introduced to better make use of\nthe spatial information among image patches. Experiments on three different\ndatasets validated the effectiveness and superiority of our approach. The code\nwill come soon.",
            "author": [
                "Zhenbang Du",
                "Jiayu An",
                "Jiahao Hong",
                "Dongrui Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00285v1",
                "http://arxiv.org/pdf/2311.00285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00282v2",
            "title": "TLMCM Network for Medical Image Hierarchical Multi-Label Classification",
            "updated": "2023-11-11T08:16:29Z",
            "published": "2023-11-01T04:18:42Z",
            "summary": "Medical Image Hierarchical Multi-Label Classification (MI-HMC) is of\nparamount importance in modern healthcare, presenting two significant\nchallenges: data imbalance and \\textit{hierarchy constraint}. Existing\nsolutions involve complex model architecture design or domain-specific\npreprocessing, demanding considerable expertise or effort in implementation. To\naddress these limitations, this paper proposes Transfer Learning with Maximum\nConstraint Module (TLMCM) network for the MI-HMC task. The TLMCM network offers\na novel approach to overcome the aforementioned challenges, outperforming\nexisting methods based on the Area Under the Average Precision and Recall\nCurve($AU\\overline{(PRC)}$) metric. In addition, this research proposes two\nnovel accuracy metrics, $EMR$ and $HammingAccuracy$, which have not been\nextensively explored in the context of the MI-HMC task. Experimental results\ndemonstrate that the TLMCM network achieves high multi-label prediction\naccuracy($80\\%$-$90\\%$) for MI-HMC tasks, making it a valuable contribution to\nhealthcare domain applications.",
            "author": [
                "Meng Wu",
                "Siyan Luo",
                "Qiyu Wu",
                "Wenbin Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00282v2",
                "http://arxiv.org/pdf/2311.00282v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00279v2",
            "title": "Accelerating Maximal Clique Enumeration via Graph Reduction",
            "updated": "2023-11-02T10:19:57Z",
            "published": "2023-11-01T04:05:01Z",
            "summary": "As a fundamental task in graph data management, maximal clique enumeration\n(MCE) has attracted extensive attention from both academic and industrial\ncommunities due to its wide range of applications. However, MCE is very\nchallenging as the number of maximal cliques may grow exponentially with the\nnumber of vertices. The state-of-the-art methods adopt a recursive paradigm to\nenumerate maximal cliques exhaustively, suffering from a large amount of\nredundant computation. In this paper, we propose a novel reduction-based\nframework for MCE, namely RMCE, that aims to reduce the search space and\nminimize unnecessary computations. The proposed framework RMCE incorporates\nthree kinds of powerful reduction techniques including global reduction,\ndynamic reduction, and maximality check reduction. Global and dynamic reduction\ntechniques effectively reduce the size of the input graph and dynamically\nconstruct subgraphs during the recursive subtasks, respectively. The maximality\ncheck reduction minimizes the computation for ensuring maximality by utilizing\nneighborhood dominance between visited vertices. Extensive experiments on 18\nreal graphs demonstrate the effectiveness of our proposed method. It achieves\nremarkable speedups up to 44.7x compared to existing approaches.",
            "author": [
                "Wen Deng",
                "Weiguo Zheng",
                "Hong Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00279v2",
                "http://arxiv.org/pdf/2311.00279v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00278v1",
            "title": "Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection",
            "updated": "2023-11-01T04:04:34Z",
            "published": "2023-11-01T04:04:34Z",
            "summary": "Few-shot object detection, which focuses on detecting novel objects with few\nlabels, is an emerging challenge in the community. Recent studies show that\nadapting a pre-trained model or modified loss function can improve performance.\nIn this paper, we explore leveraging the power of Contrastive Language-Image\nPre-training (CLIP) and hard negative classification loss in low data setting.\nSpecifically, we propose Re-scoring using Image-language Similarity for\nFew-shot object detection (RISF) which extends Faster R-CNN by introducing\nCalibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss\n(BNRL). The former adapts CLIP, which performs zero-shot classification, to\nre-score the classification scores of a detector using image-class\nsimilarities, the latter is modified classification loss considering the\npunishment for fake backgrounds as well as confusing categories on a\ngeneralized few-shot object detection dataset. Extensive experiments on MS-COCO\nand PASCAL VOC show that the proposed RISF substantially outperforms the\nstate-of-the-art approaches. The code will be available.",
            "author": [
                "Min Jae Jung",
                "Seung Dae Han",
                "Joohee Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00278v1",
                "http://arxiv.org/pdf/2311.00278v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00277v2",
            "title": "OpenForest: A data catalogue for machine learning in forest monitoring",
            "updated": "2023-11-02T02:44:27Z",
            "published": "2023-11-01T03:59:20Z",
            "summary": "Forests play a crucial role in Earth's system processes and provide a suite\nof social and economic ecosystem services, but are significantly impacted by\nhuman activities, leading to a pronounced disruption of the equilibrium within\necosystems. Advancing forest monitoring worldwide offers advantages in\nmitigating human impacts and enhancing our comprehension of forest composition,\nalongside the effects of climate change. While statistical modeling has\ntraditionally found applications in forest biology, recent strides in machine\nlearning and computer vision have reached important milestones using remote\nsensing data, such as tree species identification, tree crown segmentation and\nforest biomass assessments. For this, the significance of open access data\nremains essential in enhancing such data-driven algorithms and methodologies.\nHere, we provide a comprehensive and extensive overview of 86 open access\nforest datasets across spatial scales, encompassing inventories, ground-based,\naerial-based, satellite-based recordings, and country or world maps. These\ndatasets are grouped in OpenForest, a dynamic catalogue open to contributions\nthat strives to reference all available open access forest datasets. Moreover,\nin the context of these datasets, we aim to inspire research in machine\nlearning applied to forest biology by establishing connections between\ncontemporary topics, perspectives and challenges inherent in both domains. We\nhope to encourage collaborations among scientists, fostering the sharing and\nexploration of diverse datasets through the application of machine learning\nmethods for large-scale forest monitoring. OpenForest is available at\nhttps://github.com/RolnickLab/OpenForest .",
            "author": [
                "Arthur Ouaknine",
                "Teja Kattenborn",
                "Etienne Lalibert\u00e9",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00277v2",
                "http://arxiv.org/pdf/2311.00277v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00273v1",
            "title": "SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities\n  through Fine-tuning with Multi-turn Empathy Conversations",
            "updated": "2023-11-01T03:49:52Z",
            "published": "2023-11-01T03:49:52Z",
            "summary": "Large language models (LLMs) have been widely applied in various fields due\nto their excellent capability for memorizing knowledge and chain of thought\n(CoT). When these language models are applied in the field of psychological\ncounseling, they often rush to provide universal advice. However, when users\nseek psychological support, they need to gain empathy, trust, understanding and\ncomfort, rather than just reasonable advice. To this end, we constructed a\nmulti-turn empathetic conversation dataset of more than 2 million samples, in\nwhich the input is the multi-turn conversation context, and the target is\nempathetic responses that cover expressions such as questioning, comfort,\nrecognition, listening, trust, emotional support, etc. Experiments have shown\nthat the empathy ability of LLMs can be significantly enhanced when finetuning\nby using multi-turn dialogue history and responses that are closer to the\nexpression of a psychological consultant.",
            "author": [
                "Yirong Chen",
                "Xiaofen Xing",
                "Jingkai Lin",
                "Huimin Zheng",
                "Zhenyu Wang",
                "Qi Liu",
                "Xiangmin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00273v1",
                "http://arxiv.org/pdf/2311.00273v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00271v1",
            "title": "EdgeDis: Enabling Fast, Economical, and Reliable Data Dissemination for\n  Mobile Edge Computing",
            "updated": "2023-11-01T03:41:43Z",
            "published": "2023-11-01T03:41:43Z",
            "summary": "Mobile edge computing (MEC) enables web data caching in close geographic\nproximity to end users. Popular data can be cached on edge servers located less\nthan hundreds of meters away from end users. This ensures bounded latency\nguarantees for various latency-sensitive web applications. However,\ntransmitting a large volume of data out of the cloud onto many\ngeographically-distributed web servers individually can be expensive. In\naddition, web content dissemination may be interrupted by various intentional\nand accidental events in the volatile MEC environment, which undermines\ndissemination efficiency and subsequently incurs extra transmission costs. To\ntackle the above challenges, we present a novel scheme named EdgeDis that\ncoordinates data dissemination by distributed consensus among those servers. We\nanalyze EdgeDis's validity theoretically and evaluate its performance\nexperimentally. Results demonstrate that compared with baseline and\nstate-of-the-art schemes, EdgeDis: 1) is 5.97x - 7.52x faster; 2) reduces\ndissemination costs by 48.21% to 91.87%; and 3) reduces performance loss caused\nby dissemination failures by up to 97.30% in time and 96.35% in costs.",
            "author": [
                "Bo Li",
                "Qiang He",
                "Feifei Chen",
                "Lingjuan Lyu",
                "Athman Bouguettaya",
                "Yun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00271v1",
                "http://arxiv.org/pdf/2311.00271v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00270v2",
            "title": "Survey on Quality Assurance of Smart Contracts",
            "updated": "2023-11-02T00:37:56Z",
            "published": "2023-11-01T03:36:24Z",
            "summary": "With the increasing adoption of smart contracts, ensuring their security has\nbecome a critical concern. Numerous vulnerabilities and attacks have been\nidentified and exploited, resulting in significant financial losses. In\nresponse, researchers have developed various tools and techniques to identify\nand prevent vulnerabilities in smart contracts. In this survey, we present a\nsystematic overview of the quality assurance of smart contracts, covering\nvulnerabilities, attacks, defenses, and tool support. By classifying\nvulnerabilities based on known attacks, we can identify patterns and common\nweaknesses that need to be addressed. Moreover, in order to effectively protect\nsmart contracts, we have created a labeled dataset to evaluate various\nvulnerability detection tools and compare their effectiveness.",
            "author": [
                "Zhiyuan Wei",
                "Jing Sun",
                "Zijian Zhang",
                "Xianhao Zhang",
                "Xiaoxuan Yang",
                "Liehuang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00270v2",
                "http://arxiv.org/pdf/2311.00270v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00268v1",
            "title": "Syntactic Inductive Bias in Transformer Language Models: Especially\n  Helpful for Low-Resource Languages?",
            "updated": "2023-11-01T03:32:46Z",
            "published": "2023-11-01T03:32:46Z",
            "summary": "A line of work on Transformer-based language models such as BERT has\nattempted to use syntactic inductive bias to enhance the pretraining process,\non the theory that building syntactic structure into the training process\nshould reduce the amount of data needed for training. But such methods are\noften tested for high-resource languages such as English. In this work, we\ninvestigate whether these methods can compensate for data sparseness in\nlow-resource languages, hypothesizing that they ought to be more effective for\nlow-resource languages. We experiment with five low-resource languages: Uyghur,\nWolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic\ninductive bias methods produce uneven results in low-resource settings, and\nprovide surprisingly little benefit in most cases.",
            "author": [
                "Luke Gessler",
                "Nathan Schneider"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00268v1",
                "http://arxiv.org/pdf/2311.00268v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00265v1",
            "title": "Adaptive Latent Diffusion Model for 3D Medical Image to Image\n  Translation: Multi-modal Magnetic Resonance Imaging Study",
            "updated": "2023-11-01T03:22:57Z",
            "published": "2023-11-01T03:22:57Z",
            "summary": "Multi-modal images play a crucial role in comprehensive evaluations in\nmedical image analysis providing complementary information for identifying\nclinically important biomarkers. However, in clinical practice, acquiring\nmultiple modalities can be challenging due to reasons such as scan cost,\nlimited scan time, and safety considerations. In this paper, we propose a model\nbased on the latent diffusion model (LDM) that leverages switchable blocks for\nimage-to-image translation in 3D medical images without patch cropping. The 3D\nLDM combined with conditioning using the target modality allows generating\nhigh-quality target modality in 3D overcoming the shortcoming of the missing\nout-of-slice information in 2D generation methods. The switchable block, noted\nas multiple switchable spatially adaptive normalization (MS-SPADE), dynamically\ntransforms source latents to the desired style of the target latents to help\nwith the diffusion process. The MS-SPADE block allows us to have one single\nmodel to tackle many translation tasks of one source modality to various\ntargets removing the need for many translation models for different scenarios.\nOur model exhibited successful image synthesis across different source-target\nmodality scenarios and surpassed other models in quantitative evaluations\ntested on multi-modal brain magnetic resonance imaging datasets of four\ndifferent modalities and an independent IXI dataset. Our model demonstrated\nsuccessful image synthesis across various modalities even allowing for\none-to-many modality translations. Furthermore, it outperformed other\none-to-one translation models in quantitative evaluations.",
            "author": [
                "Jonghun Kim",
                "Hyunjin Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00265v1",
                "http://arxiv.org/pdf/2311.00265v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00262v1",
            "title": "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue\n  Agents",
            "updated": "2023-11-01T03:20:16Z",
            "published": "2023-11-01T03:20:16Z",
            "summary": "Proactive dialogues serve as a practical yet challenging dialogue problem in\nthe era of large language models (LLMs), where the dialogue policy planning is\nthe key to improving the proactivity of LLMs. Most existing studies enable the\ndialogue policy planning of LLMs using various prompting schemes or iteratively\nenhance this capability in handling the given case with verbal AI feedback.\nHowever, these approaches are either bounded by the policy planning capability\nof the frozen LLMs or hard to be transferred to new cases. In this work, we\nintroduce a new dialogue policy planning paradigm to strategize LLMs for\nproactive dialogue problems with a tunable language model plug-in as a\nplug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a\nnovel training framework to facilitate supervised fine-tuning over available\nhuman-annotated data as well as reinforcement learning from goal-oriented AI\nfeedback with dynamic interaction data collected by the LLM-based self-play\nsimulation. In this manner, the LLM-powered dialogue agent can not only be\ngeneralized to different cases after the training, but also be applicable to\ndifferent applications by just substituting the learned plug-in. In addition,\nwe propose to evaluate the policy planning capability of dialogue systems under\nthe interactive setting. Experimental results demonstrate that PPDPP\nconsistently and substantially outperforms existing approaches on three\ndifferent proactive dialogue applications, including negotiation, emotional\nsupport, and tutoring dialogues.",
            "author": [
                "Yang Deng",
                "Wenxuan Zhang",
                "Wai Lam",
                "See-Kiong Ng",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00262v1",
                "http://arxiv.org/pdf/2311.00262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00260v1",
            "title": "Incentivized Collaboration in Active Learning",
            "updated": "2023-11-01T03:17:39Z",
            "published": "2023-11-01T03:17:39Z",
            "summary": "In collaborative active learning, where multiple agents try to learn labels\nfrom a common hypothesis, we introduce an innovative framework for incentivized\ncollaboration. Here, rational agents aim to obtain labels for their data sets\nwhile keeping label complexity at a minimum. We focus on designing (strict)\nindividually rational (IR) collaboration protocols, ensuring that agents cannot\nreduce their expected label complexity by acting individually. We first show\nthat given any optimal active learning algorithm, the collaboration protocol\nthat runs the algorithm as is over the entire data is already IR. However,\ncomputing the optimal algorithm is NP-hard. We therefore provide collaboration\nprotocols that achieve (strict) IR and are comparable with the best known\ntractable approximation algorithm in terms of label complexity.",
            "author": [
                "Lee Cohen",
                "Han Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00260v1",
                "http://arxiv.org/pdf/2311.00260v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00259v1",
            "title": "Solutions to Elliptic and Parabolic Problems via Finite Difference Based\n  Unsupervised Small Linear Convolutional Neural Networks",
            "updated": "2023-11-01T03:15:10Z",
            "published": "2023-11-01T03:15:10Z",
            "summary": "In recent years, there has been a growing interest in leveraging deep\nlearning and neural networks to address scientific problems, particularly in\nsolving partial differential equations (PDEs). However, current neural\nnetwork-based PDE solvers often rely on extensive training data or labeled\ninput-output pairs, making them prone to challenges in generalizing to\nout-of-distribution examples. To mitigate the generalization gap encountered by\nconventional neural network-based methods in estimating PDE solutions, we\nformulate a fully unsupervised approach, requiring no training data, to\nestimate finite difference solutions for PDEs directly via small convolutional\nneural networks. Our proposed algorithms demonstrate a comparable accuracy to\nthe true solution for several selected elliptic and parabolic problems compared\nto the finite difference method.",
            "author": [
                "Adrian Celaya",
                "Keegan Kirk",
                "David Fuentes",
                "Beatrice Riviere"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00259v1",
                "http://arxiv.org/pdf/2311.00259v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00258v1",
            "title": "Noisy Exemplars Make Large Language Models More Robust: A\n  Domain-Agnostic Behavioral Analysis",
            "updated": "2023-11-01T03:15:05Z",
            "published": "2023-11-01T03:15:05Z",
            "summary": "Recent advances in prompt engineering enable large language models (LLMs) to\nsolve multi-hop logical reasoning problems with impressive accuracy. However,\nthere is little existing work investigating the robustness of LLMs with\nfew-shot prompting techniques. Therefore, we introduce a systematic approach to\ntest the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic\nperturbations. We include perturbations at multiple levels of abstractions\n(e.g. lexical perturbations such as typos, and semantic perturbations such as\nthe inclusion of intermediate reasoning steps in the questions) to conduct\nbehavioral analysis on the LLMs. Throughout our experiments, we find that\nmodels are more sensitive to certain perturbations such as replacing words with\ntheir synonyms. We also demonstrate that increasing the proportion of perturbed\nexemplars in the prompts improves the robustness of few-shot prompting methods.",
            "author": [
                "Hongyi Zheng",
                "Abulhair Saparov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00258v1",
                "http://arxiv.org/pdf/2311.00258v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00257v1",
            "title": "AMSP: Super-Scaling LLM Training via Advanced Model States Partitioning",
            "updated": "2023-11-01T03:14:48Z",
            "published": "2023-11-01T03:14:48Z",
            "summary": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious downstream tasks. When training these models, there is a growing\ninclination to process more tokens on larger training scales but with\nrelatively smaller model sizes. Zero Redundancy Optimizer (ZeRO), although\neffective in conventional training environments, grapples with scaling\nchallenges when confronted with this emerging paradigm. To this end, we propose\na novel LLM training framework AMSP, which undertakes a granular partitioning\nof model states, encompassing parameters ($P$), gradient ($G$), and optimizer\nstates ($OS$). Specifically, AMSP(1) builds a unified partitioning space,\nenabling independent partitioning strategies for $P$, $G$, and $OS$; (2)\nincorporates a scale-aware partitioner to autonomously search for optimal\npartitioning strategies: (3) designs a dedicated communication optimizer to\nensure proficient management of data placement discrepancies arising from\ndiverse partitioning strategies. Our evaluations show that AMSP achieves up to\n90.3% scaling efficiency across 1024 GPUs.",
            "author": [
                "Qiaoling Chen",
                "Qinghao Hu",
                "Zhisheng Ye",
                "Guoteng Wang",
                "Peng Sun",
                "Yonggang Wen",
                "Tianwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00257v1",
                "http://arxiv.org/pdf/2311.00257v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00253v1",
            "title": "Computational multiphase micro-periporomechanics for dynamic shear\n  banding and fracturing of unsaturated porous media",
            "updated": "2023-11-01T03:07:04Z",
            "published": "2023-11-01T03:07:04Z",
            "summary": "Dynamic shearing banding and fracturing in unsaturated porous media is a\nsignificant problem in engineering and science. This article proposes a\nmultiphase micro-periporomechanics (uPPM) paradigm for modeling dynamic shear\nbanding and fracturing in unsaturated porous media. Periporomechanics (PPM) is\na nonlocal reformulation of classical poromechanics to model continuous and\ndiscontinuous deformation/fracture and fluid flow in porous media through a\nsingle framework. In PPM, a multiphase porous material is postulated as a\ncollection of a finite number of mixed material points. The length scale in PPM\nthat dictates the nonlocal interaction between material points is a\nmathematical object that lacks a direct physical meaning. As a novelty, in the\ncoupled uPPM, a microstructure-based material length scale is incorporated by\nconsidering micro-rotations of the solid skeleton following the Cosserat\ncontinuum theory for solids. As a new contribution, we reformulate the\nsecond-order work for detecting material instability and the energy-based crack\ncriterion and J-integral for modeling fracturing in the uPPM paradigm. The\nstabilized Cosserat PPM correspondence principle that mitigates the multiphase\nzero-energy mode instability is augmented to include unsaturated fluid flow. We\nhave numerically implemented the novel uPPM paradigm through a dual-way\nfractional-step algorithm in time and a hybrid Lagrangian-Eulerian meshfree\nmethod in space. Numerical examples are presented to demonstrate the robustness\nand efficacy of the proposed uPPM paradigm for modeling shear banding and\nfracturing in unsaturated porous media.",
            "author": [
                "Hossein",
                "Pashazad",
                "Xiaoyu",
                "Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00253v1",
                "http://arxiv.org/pdf/2311.00253v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00246v1",
            "title": "RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement\n  Method",
            "updated": "2023-11-01T03:00:07Z",
            "published": "2023-11-01T03:00:07Z",
            "summary": "Underwater image enhancement (UIE) poses challenges due to distinctive\nproperties of the underwater environment, including low contrast, high\nturbidity, visual blurriness, and color distortion. In recent years, the\napplication of deep learning has quietly revolutionized various areas of\nscientific research, including UIE. However, existing deep learning-based UIE\nmethods generally suffer from issues of weak robustness and limited\nadaptability. In this paper, inspired by residual and attention mechanisms, we\npropose a more reliable and reasonable UIE network called RAUNE-Net by\nemploying residual learning of high-level features at the network's bottle-neck\nand two aspects of attention manipulations in the down-sampling procedure.\nFurthermore, we collect and create two datasets specifically designed for\nevaluating UIE methods, which contains different types of underwater\ndistortions and degradations. The experimental validation demonstrates that our\nmethod obtains promising objective performance and consistent visual results\nacross various real-world underwater images compared to other eight UIE\nmethods. Our example code and datasets are publicly available at\nhttps://github.com/fansuregrin/RAUNE-Net.",
            "author": [
                "Wangzhen Peng",
                "Chenghao Zhou",
                "Runze Hu",
                "Jingchao Cao",
                "Yutao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00246v1",
                "http://arxiv.org/pdf/2311.00246v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14678v1",
            "title": "Data-driven recommendations for enhancing real-time natural hazard\n  warnings, communication, and response",
            "updated": "2023-11-01T02:59:45Z",
            "published": "2023-11-01T02:59:45Z",
            "summary": "The effectiveness and adequacy of natural hazard warnings hinges on the\navailability of data and its transformation into actionable knowledge for the\npublic. Real-time warning communication and emergency response therefore need\nto be evaluated from a data science perspective. However, there are currently\ngaps between established data science best practices and their application in\nsupporting natural hazard warnings. This Perspective reviews existing\ndata-driven approaches that underpin real-time warning communication and\nemergency response, highlighting limitations in hazard and impact forecasts.\nFour main themes for enhancing warnings are emphasised: (i) applying\nbest-practice principles in visualising hazard forecasts, (ii) data\nopportunities for more effective impact forecasts, (iii) utilising data for\nmore localised forecasts, and (iv) improving data-driven decision-making using\nuncertainty. Motivating examples are provided from the extensive flooding\nexperienced in Australia in 2022. This Perspective shows the capacity for\nimproving the efficacy of natural hazard warnings using data science, and the\ncollaborative potential between the data science and natural hazards\ncommunities.",
            "author": [
                "Kate R. Saunders",
                "Owen Forbes",
                "Jess K. Hopf",
                "Charlotte R. Patterson",
                "Sarah A. Vollert",
                "Kaitlyn Brown",
                "Raiha Browning",
                "Miguel Canizares",
                "Richard S. Cottrell",
                "Lanxi Li",
                "Catherine J. S. Kim",
                "Tace P. Stewart",
                "Connie Susilawati",
                "Xiang Y. Zhao",
                "Kate J. Helmstedt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14678v1",
                "http://arxiv.org/pdf/2311.14678v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00244v1",
            "title": "A short-time drift propagator approach to the Fokker-Planck equation",
            "updated": "2023-11-01T02:58:53Z",
            "published": "2023-11-01T02:58:53Z",
            "summary": "The Fokker-Planck equation is a partial differential equation that describes\nthe evolution of a probability distribution over time. It is used to model a\nwide range of physical and biological phenomena, such as diffusion, chemical\nreactions, and population dynamics. Solving the Fokker-Planck equation is a\ndifficult task, as it involves solving a system of coupled nonlinear partial\ndifferential equations. In general, analytical solutions are not available and\nnumerical methods must be used. In this research, we propose a novel approach\nto the solution of the Fokker-Planck equation in a short time interval. The\nnumerical solution to the equation can be obtained iteratively using a new\ntechnique based on the short-time drift propagator. This new approach is\ndifferent from the traditional methods, as the state-dependent drift function\nhas been removed from the multivariate Gaussian integral component and is\ninstead presented as a state-shifted element. We evaluated our technique\nemploying a fundamental Wiener process with constant drift components in both\none- and two-dimensional space. The results of the numerical calculation were\nfound to be consistent with the exact solution. The proposed approach offers a\npromising new direction for research in this area.",
            "author": [
                "Wisit Mangthas",
                "Waipot Ngamsaad"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s40042-023-00967-8",
                "http://arxiv.org/abs/2311.00244v1",
                "http://arxiv.org/pdf/2311.00244v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00241v1",
            "title": "1DFormer: Learning 1D Landmark Representations via Transformer for\n  Facial Landmark Tracking",
            "updated": "2023-11-01T02:49:25Z",
            "published": "2023-11-01T02:49:25Z",
            "summary": "Recently, heatmap regression methods based on 1D landmark representations\nhave shown prominent performance on locating facial landmarks. However,\nprevious methods ignored to make deep explorations on the good potentials of 1D\nlandmark representations for sequential and structural modeling of multiple\nlandmarks to track facial landmarks. To address this limitation, we propose a\nTransformer architecture, namely 1DFormer, which learns informative 1D landmark\nrepresentations by capturing the dynamic and the geometric patterns of\nlandmarks via token communications in both temporal and spatial dimensions for\nfacial landmark tracking. For temporal modeling, we propose a recurrent token\nmixing mechanism, an axis-landmark-positional embedding mechanism, as well as a\nconfidence-enhanced multi-head attention mechanism to adaptively and robustly\nembed long-term landmark dynamics into their 1D representations; for structure\nmodeling, we design intra-group and inter-group structure modeling mechanisms\nto encode the component-level as well as global-level facial structure patterns\nas a refinement for the 1D representations of landmarks through token\ncommunications in the spatial dimension via 1D convolutional layers.\nExperimental results on the 300VW and the TF databases show that 1DFormer\nsuccessfully models the long-range sequential patterns as well as the inherent\nfacial structures to learn informative 1D representations of landmark\nsequences, and achieves state-of-the-art performance on facial landmark\ntracking.",
            "author": [
                "Shi Yin",
                "Shijie Huan",
                "Defu Lian",
                "Shangfei Wang",
                "Jinshui Hu",
                "Tao Guo",
                "Bing Yin",
                "Baocai Yin",
                "Cong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00241v1",
                "http://arxiv.org/pdf/2311.00241v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00237v1",
            "title": "The Mystery and Fascination of LLMs: A Comprehensive Survey on the\n  Interpretation and Analysis of Emergent Abilities",
            "updated": "2023-11-01T02:40:42Z",
            "published": "2023-11-01T02:40:42Z",
            "summary": "Understanding emergent abilities, such as in-context learning (ICL) and\nchain-of-thought (CoT) prompting in large language models (LLMs), is of utmost\nimportance. This importance stems not only from the better utilization of these\ncapabilities across various tasks, but also from the proactive identification\nand mitigation of potential risks, including concerns of truthfulness, bias,\nand toxicity, that may arise alongside these capabilities. In this paper, we\npresent a thorough survey on the interpretation and analysis of emergent\nabilities of LLMs. First, we provide a concise introduction to the background\nand definition of emergent abilities. Then, we give an overview of advancements\nfrom two perspectives: 1) a macro perspective, emphasizing studies on the\nmechanistic interpretability and delving into the mathematical foundations\nbehind emergent abilities; and 2) a micro-perspective, concerning studies that\nfocus on empirical interpretability by examining factors associated with these\nabilities. We conclude by highlighting the challenges encountered and\nsuggesting potential avenues for future research. We believe that our work\nestablishes the basis for further exploration into the interpretation of\nemergent abilities.",
            "author": [
                "Yuxiang Zhou",
                "Jiazheng Li",
                "Yanzheng Xiang",
                "Hanqi Yan",
                "Lin Gui",
                "Yulan He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00237v1",
                "http://arxiv.org/pdf/2311.00237v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00235v1",
            "title": "Implicit biases in multitask and continual learning from a backward\n  error analysis perspective",
            "updated": "2023-11-01T02:37:32Z",
            "published": "2023-11-01T02:37:32Z",
            "summary": "Using backward error analysis, we compute implicit training biases in\nmultitask and continual learning settings for neural networks trained with\nstochastic gradient descent. In particular, we derive modified losses that are\nimplicitly minimized during training. They have three terms: the original loss,\naccounting for convergence, an implicit flatness regularization term\nproportional to the learning rate, and a last term, the conflict term, which\ncan theoretically be detrimental to both convergence and implicit\nregularization. In multitask, the conflict term is a well-known quantity,\nmeasuring the gradient alignment between the tasks, while in continual learning\nthe conflict term is a new quantity in deep learning optimization, although a\nbasic tool in differential geometry: The Lie bracket between the task\ngradients.",
            "author": [
                "Benoit Dherin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00235v1",
                "http://arxiv.org/pdf/2311.00235v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00233v1",
            "title": "Distort, Distract, Decode: Instruction-Tuned Model Can Refine its\n  Response from Noisy Instructions",
            "updated": "2023-11-01T02:31:35Z",
            "published": "2023-11-01T02:31:35Z",
            "summary": "While instruction-tuned language models have demonstrated impressive\nzero-shot generalization, these models often struggle to generate accurate\nresponses when faced with instructions that fall outside their training set.\nThis paper presents Instructive Decoding (ID), a simple yet effective approach\nthat augments the efficacy of instruction-tuned models. Specifically, ID\nadjusts the logits for next-token prediction in a contrastive manner, utilizing\npredictions generated from a manipulated version of the original instruction,\nreferred to as a noisy instruction. This noisy instruction aims to elicit\nresponses that could diverge from the intended instruction yet remain\nplausible. We conduct experiments across a spectrum of such noisy instructions,\nranging from those that insert semantic noise via random words to others like\n'opposite' that elicit the deviated responses. Our approach achieves\nconsiderable performance gains across various instruction-tuned models and\ntasks without necessitating any additional parameter updates. Notably,\nutilizing 'opposite' as the noisy instruction in ID, which exhibits the maximum\ndivergence from the original instruction, consistently produces the most\nsignificant performance gains across multiple models and tasks.",
            "author": [
                "Taehyeon Kim",
                "Joonkee Kim",
                "Gihun Lee",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00233v1",
                "http://arxiv.org/pdf/2311.00233v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00230v2",
            "title": "DINO-Mix: Enhancing Visual Place Recognition with Foundational Vision\n  Model and Feature Mixing",
            "updated": "2023-12-05T09:13:53Z",
            "published": "2023-11-01T02:22:17Z",
            "summary": "Utilizing visual place recognition (VPR) technology to ascertain the\ngeographical location of publicly available images is a pressing issue for\nreal-world VPR applications. Although most current VPR methods achieve\nfavorable results under ideal conditions, their performance in complex\nenvironments, characterized by lighting variations, seasonal changes, and\nocclusions caused by moving objects, is generally unsatisfactory. In this\nstudy, we utilize the DINOv2 model as the backbone network for trimming and\nfine-tuning to extract robust image features. We propose a novel VPR\narchitecture called DINO-Mix, which combines a foundational vision model with\nfeature aggregation. This architecture relies on the powerful image feature\nextraction capabilities of foundational vision models. We employ an\nMLP-Mixer-based mix module to aggregate image features, resulting in globally\nrobust and generalizable descriptors that enable high-precision VPR. We\nexperimentally demonstrate that the proposed DINO-Mix architecture\nsignificantly outperforms current state-of-the-art (SOTA) methods. In test sets\nhaving lighting variations, seasonal changes, and occlusions (Tokyo24/7,\nNordland, SF-XL-Testv1), our proposed DINO-Mix architecture achieved Top-1\naccuracy rates of 91.75%, 80.18%, and 82%, respectively. Compared with SOTA\nmethods, our architecture exhibited an average accuracy improvement of 5.14%.",
            "author": [
                "Gaoshuang Huang",
                "Yang Zhou",
                "Xiaofei Hu",
                "Chenglong Zhang",
                "Luying Zhao",
                "Wenjian Gan",
                "Mingbo Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00230v2",
                "http://arxiv.org/pdf/2311.00230v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00223v1",
            "title": "Is GPT Powerful Enough to Analyze the Emotions of Memes?",
            "updated": "2023-11-01T01:57:48Z",
            "published": "2023-11-01T01:57:48Z",
            "summary": "Large Language Models (LLMs), representing a significant achievement in\nartificial intelligence (AI) research, have demonstrated their ability in a\nmultitude of tasks. This project aims to explore the capabilities of GPT-3.5, a\nleading example of LLMs, in processing the sentiment analysis of Internet\nmemes. Memes, which include both verbal and visual aspects, act as a powerful\nyet complex tool for expressing ideas and sentiments, demanding an\nunderstanding of societal norms and cultural contexts. Notably, the detection\nand moderation of hateful memes pose a significant challenge due to their\nimplicit offensive nature. This project investigates GPT's proficiency in such\nsubjective tasks, revealing its strengths and potential limitations. The tasks\ninclude the classification of meme sentiment, determination of humor type, and\ndetection of implicit hate in memes. The performance evaluation, using datasets\nfrom SemEval-2020 Task 8 and Facebook hateful memes, offers a comparative\nunderstanding of GPT responses against human annotations. Despite GPT's\nremarkable progress, our findings underscore the challenges faced by these\nmodels in handling subjective tasks, which are rooted in their inherent\nlimitations including contextual understanding, interpretation of implicit\nmeanings, and data biases. This research contributes to the broader discourse\non the applicability of AI in handling complex, context-dependent tasks, and\noffers valuable insights for future advancements.",
            "author": [
                "Jingjing Wang",
                "Joshua Luo",
                "Grace Yang",
                "Allen Hong",
                "Feng Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00223v1",
                "http://arxiv.org/pdf/2311.00223v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00217v1",
            "title": "Can Large Language Models Capture Public Opinion about Global Warming?\n  An Empirical Assessment of Algorithmic Fidelity and Bias",
            "updated": "2023-11-01T01:32:59Z",
            "published": "2023-11-01T01:32:59Z",
            "summary": "Large language models (LLMs) have demonstrated their potential in social\nscience research by emulating human perceptions and behaviors, a concept\nreferred to as algorithmic fidelity. This study assesses the algorithmic\nfidelity and bias of LLMs by utilizing two nationally representative climate\nchange surveys. The LLMs were conditioned on demographics and/or psychological\ncovariates to simulate survey responses. The findings indicate that LLMs can\neffectively capture presidential voting behaviors but encounter challenges in\naccurately representing global warming perspectives when relevant covariates\nare not included. GPT-4 exhibits improved performance when conditioned on both\ndemographics and covariates. However, disparities emerge in LLM estimations of\nthe views of certain groups, with LLMs tending to underestimate worry about\nglobal warming among Black Americans. While highlighting the potential of LLMs\nto aid social science research, these results underscore the importance of\nmeticulous conditioning, model selection, survey question format, and bias\nassessment when employing LLMs for survey simulation. Further investigation\ninto prompt engineering and algorithm auditing is essential to harness the\npower of LLMs while addressing their inherent limitations.",
            "author": [
                "S. Lee",
                "T. Q. Peng",
                "M. H. Goldberg",
                "S. A. Rosenthal",
                "J. E. Kotcher",
                "E. W. Maibach",
                "A. Leiserowitz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00217v1",
                "http://arxiv.org/pdf/2311.00217v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00215v1",
            "title": "An effective description of Laniakea and its backreaction: Impact on\n  Cosmology and the local determination of the Hubble constant",
            "updated": "2023-11-01T01:31:17Z",
            "published": "2023-11-01T01:31:17Z",
            "summary": "We propose an effective model to describe the backreaction on cosmological\nobservables induced by Laniakea, the gravitational supercluster hosting the\nMilky Way, which was defined using peculiar velocity data from Cosmicflows-4\n(CF4). The structure is well described by an ellipsoidal shape exhibiting\ntriaxial expansion, reasonably approximated by a constant expansion rate along\nthe principal axes. Our best fits suggest that the ellipsoid, after subtracting\nthe background expansion, contracts along the two smaller axes and expands\nalong the longest one, predicting an average expansion of $\\sim -1.1\n~\\rm{km}/\\rm{s}/\\rm{Mpc}$. The different expansion rates within the region,\nrelative to the mean cosmological expansion, induce line-of-sight-dependent\ncorrections in the computation of luminosity distances. We apply these\ncorrections to two low-redshift datasets: the Pantheon+ catalog of type Ia\nSupernovae (SN~Ia), and 63 measurements of Surface Brightness Fluctuations\n(SBF) of early-type massive galaxies from the MASSIVE survey. We find\ncorrections on the distances of order $\\sim 2-3\\%$, resulting in a shift in the\ninferred best-fit values of the Hubble constant $H_0$ of order $\\Delta\nH_0^{\\rm{SN~Ia}}\\approx 0.5 ~\\rm{km}/\\rm{s}/\\rm{Mpc}$ and $\\Delta\nH_0^{\\rm{SBF}}\\approx 1.1 ~\\rm{km}/\\rm{s}/\\rm{Mpc}$, seemingly worsening the\nHubble tension.",
            "author": [
                "L. Giani",
                "C. Howlett",
                "K. Said",
                "T. Davis",
                "S. Vagnozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00215v1",
                "http://arxiv.org/pdf/2311.00215v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00214v1",
            "title": "WinNet:time series forecasting with a window-enhanced period extracting\n  and interacting",
            "updated": "2023-11-01T01:23:59Z",
            "published": "2023-11-01T01:23:59Z",
            "summary": "Recently, Transformer-based methods have significantly improved\nstate-of-the-art time series forecasting results, but they suffer from high\ncomputational costs and the inability to capture the long and short periodicity\nof time series. We present a highly accurate and simply structured CNN-based\nmodel for long-term time series forecasting tasks, called WinNet, including (i)\nInter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with\nlong and short periodicity according to the predefined periodic window, (ii)\nTwo-Dimensional Period Decomposition (TDPD) to model period-trend and\noscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage\nthe correlations of the period-trend and oscillation terms to support the\nprediction tasks by CNNs. Results on nine benchmark datasets show that the\nWinNet can achieve SOTA performance and lower computational complexity over\nCNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the\nCNN-based methods in the time series forecasting tasks, with perfect tradeoff\nbetween performance and efficiency.",
            "author": [
                "Wenjie Ou",
                "Dongyue Guo",
                "Zheng Zhang",
                "Zhishuo Zhao",
                "Yi Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00214v1",
                "http://arxiv.org/pdf/2311.00214v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00213v3",
            "title": "Consistent Video-to-Video Transfer Using Synthetic Dataset",
            "updated": "2023-12-01T11:41:34Z",
            "published": "2023-11-01T01:20:12Z",
            "summary": "We introduce a novel and efficient approach for text-based video-to-video\nediting that eliminates the need for resource-intensive per-video-per-model\nfinetuning. At the core of our approach is a synthetic paired video dataset\ntailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's\nimage transfer via editing instruction, we adapt this paradigm to the video\ndomain. Extending the Prompt-to-Prompt to videos, we efficiently generate\npaired samples, each with an input video and its edited counterpart. Alongside\nthis, we introduce the Long Video Sampling Correction during sampling, ensuring\nconsistent long videos across batches. Our method surpasses current methods\nlike Tune-A-Video, heralding substantial progress in text-based video-to-video\nediting and suggesting exciting avenues for further exploration and deployment.",
            "author": [
                "Jiaxin Cheng",
                "Tianjun Xiao",
                "Tong He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00213v3",
                "http://arxiv.org/pdf/2311.00213v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03378v1",
            "title": "Transferability and explainability of deep learning emulators for\n  regional climate model projections: Perspectives for future applications",
            "updated": "2023-11-01T00:44:39Z",
            "published": "2023-11-01T00:44:39Z",
            "summary": "Regional climate models (RCMs) are essential tools for simulating and\nstudying regional climate variability and change. However, their high\ncomputational cost limits the production of comprehensive ensembles of regional\nclimate projections covering multiple scenarios and driving Global Climate\nModels (GCMs) across regions. RCM emulators based on deep learning models have\nrecently been introduced as a cost-effective and promising alternative that\nrequires only short RCM simulations to train the models. Therefore, evaluating\ntheir transferability to different periods, scenarios, and GCMs becomes a\npivotal and complex task in which the inherent biases of both GCMs and RCMs\nplay a significant role. Here we focus on this problem by considering the two\ndifferent emulation approaches proposed in the literature (PP and MOS,\nfollowing the terminology introduced in this paper). In addition to standard\nevaluation techniques, we expand the analysis with methods from the field of\neXplainable Artificial Intelligence (XAI), to assess the physical consistency\nof the empirical links learnt by the models. We find that both approaches are\nable to emulate certain climatological properties of RCMs for different periods\nand scenarios (soft transferability), but the consistency of the emulation\nfunctions differ between approaches. Whereas PP learns robust and physically\nmeaningful patterns, MOS results are GCM-dependent and lack physical\nconsistency in some cases. Both approaches face problems when transferring the\nemulation function to other GCMs, due to the existence of GCM-dependent biases\n(hard transferability). This limits their applicability to build ensembles of\nregional climate projections. We conclude by giving some prospects for future\napplications.",
            "author": [
                "Jorge Bano-Medina",
                "Maialen Iturbide",
                "Jesus Fernandez",
                "Jose Manuel Gutierrez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03378v1",
                "http://arxiv.org/pdf/2311.03378v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00208v1",
            "title": "Transformers as Recognizers of Formal Languages: A Survey on\n  Expressivity",
            "updated": "2023-11-01T00:38:26Z",
            "published": "2023-11-01T00:38:26Z",
            "summary": "As transformers have gained prominence in natural language processing, some\nresearchers have investigated theoretically what problems they can and cannot\nsolve, by treating problems as formal languages. Exploring questions such as\nthis will help to compare transformers with other models, and transformer\nvariants with one another, for various tasks. Work in this subarea has made\nconsiderable progress in recent years. Here, we undertake a comprehensive\nsurvey of this work, documenting the diverse assumptions that underlie\ndifferent results and providing a unified framework for harmonizing seemingly\ncontradictory findings.",
            "author": [
                "Lena Strobl",
                "William Merrill",
                "Gail Weiss",
                "David Chiang",
                "Dana Angluin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00208v1",
                "http://arxiv.org/pdf/2311.00208v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00206v1",
            "title": "ChatGPT-Powered Hierarchical Comparisons for Image Classification",
            "updated": "2023-11-01T00:26:40Z",
            "published": "2023-11-01T00:26:40Z",
            "summary": "The zero-shot open-vocabulary challenge in image classification is tackled by\npretrained vision-language models like CLIP, which benefit from incorporating\nclass-specific knowledge from large language models (LLMs) like ChatGPT.\nHowever, biases in CLIP lead to similar descriptions for distinct but related\nclasses, prompting our novel image classification framework via hierarchical\ncomparisons: using LLMs to recursively group classes into hierarchies and\nclassifying images by comparing image-text embeddings at each hierarchy level,\nresulting in an intuitive, effective, and explainable approach.",
            "author": [
                "Zhiyuan Ren",
                "Yiyang Su",
                "Xiaoming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00206v1",
                "http://arxiv.org/pdf/2311.00206v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00204v1",
            "title": "Continuous Training and Fine-tuning for Domain-Specific Language Models\n  in Medical Question Answering",
            "updated": "2023-11-01T00:18:00Z",
            "published": "2023-11-01T00:18:00Z",
            "summary": "Large language models exhibit promising general capabilities but often lack\nspecialized knowledge for domain-specific tasks. Developing domain experts from\na base model enables a range of applications without prohibitive training\ncosts. This work demonstrates a method using continuous training and\ninstruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese\nmedical domain. We first conduct continuous training on 1B tokens from Chinese\nmedical references to teach relevant vocabulary and knowledge. The models are\nthen fine-tuned on 54K examples sourced from the Chinese National Medical\nLicensing Examination. Experiments on Chinese medical data confirm the\neffectiveness of this approach, producing a model comparable to GPT-3.5-turbo\nwhile using way less computational resource. The resulting domain-specific\nmodel could be useful for various Chinese medical applications. More broadly,\nthis provides a template for domain-specific training of large language models\nin areas where pre-trained models lack the required expertise, such as law,\nscience, and engineering.",
            "author": [
                "Zhen Guo",
                "Yining Hua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00204v1",
                "http://arxiv.org/pdf/2311.00204v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00729v2",
            "title": "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot\n  End-to-End Temporal Action Detection",
            "updated": "2023-11-04T23:41:21Z",
            "published": "2023-11-01T00:17:37Z",
            "summary": "Temporal action detection (TAD) involves the localization and classification\nof action instances within untrimmed videos. While standard TAD follows fully\nsupervised learning with closed-set setting on large training data, recent\nzero-shot TAD methods showcase the promising open-set setting by leveraging\nlarge-scale contrastive visual-language (ViL) pretrained models. However,\nexisting zero-shot TAD methods have limitations on how to properly construct\nthe strong relationship between two interdependent tasks of localization and\nclassification and adapt ViL model to video understanding. In this work, we\npresent ZEETAD, featuring two modules: dual-localization and zero-shot proposal\nclassification. The former is a Transformer-based module that detects action\nevents while selectively collecting crucial semantic embeddings for later\nrecognition. The latter one, CLIP-based module, generates semantic embeddings\nfrom text and frame inputs for each temporal unit. Additionally, we enhance\ndiscriminative capability on unseen classes by minimally updating the frozen\nCLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and\nActivityNet-1.3 datasets demonstrate our approach's superior performance in\nzero-shot TAD and effective knowledge transfer from ViL models to unseen action\ncategories.",
            "author": [
                "Thinh Phan",
                "Khoa Vo",
                "Duy Le",
                "Gianfranco Doretto",
                "Donald Adjeroh",
                "Ngan Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00729v2",
                "http://arxiv.org/pdf/2311.00729v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00196v1",
            "title": "Machine learning for accuracy in density functional approximations",
            "updated": "2023-11-01T00:02:09Z",
            "published": "2023-11-01T00:02:09Z",
            "summary": "Machine learning techniques have found their way into computational chemistry\nas indispensable tools to accelerate atomistic simulations and materials\ndesign. In addition, machine learning approaches hold the potential to boost\nthe predictive power of computationally efficient electronic structure methods,\nsuch as density functional theory, to chemical accuracy and to correct for\nfundamental errors in density functional approaches. Here, recent progress in\napplying machine learning to improve the accuracy of density functional and\nrelated approximations is reviewed. Promises and challenges in devising machine\nlearning models transferable between different chemistries and materials\nclasses are discussed with the help of examples applying promising models to\nsystems far outside their training sets.",
            "author": [
                "Johannes Voss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00196v1",
                "http://arxiv.org/pdf/2311.00196v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00192v1",
            "title": "Large-Scale Multi-Robot Assembly Planning for Autonomous Manufacturing",
            "updated": "2023-10-31T23:42:14Z",
            "published": "2023-10-31T23:42:14Z",
            "summary": "Mobile autonomous robots have the potential to revolutionize manufacturing\nprocesses. However, employing large robot fleets in manufacturing requires\naddressing challenges including collision-free movement in a shared workspace,\neffective multi-robot collaboration to manipulate and transport large payloads,\ncomplex task allocation due to coupled manufacturing processes, and spatial\nplanning for parallel assembly and transportation of nested subassemblies. We\npropose a full algorithmic stack for large-scale multi-robot assembly planning\nthat addresses these challenges and can synthesize construction plans for\ncomplex assemblies with thousands of parts in a matter of minutes. Our approach\ntakes in a CAD-like product specification and automatically plans a full-stack\nassembly procedure for a group of robots to manufacture the product. We propose\nan algorithmic stack that comprises: (i) an iterative radial layout\noptimization procedure to define a global staging layout for the manufacturing\nfacility, (ii) a graph-repair mixed-integer program formulation and a modified\ngreedy task allocation algorithm to optimally allocate robots and robot\nsub-teams to assembly and transport tasks, (iii) a geometric heuristic and a\nhill-climbing algorithm to plan collaborative carrying configurations of robot\nsub-teams, and (iv) a distributed control policy that enables robots to execute\nthe assembly motion plan collision-free. We also present an open-source\nmulti-robot manufacturing simulator implemented in Julia as a resource to the\nresearch community, to test our algorithms and to facilitate multi-robot\nmanufacturing research more broadly. Our empirical results demonstrate the\nscalability and effectiveness of our approach by generating plans to\nmanufacture a LEGO model of a Saturn V launch vehicle with 1845 parts, 306\nsubassemblies, and 250 robots in under three minutes on a standard laptop\ncomputer.",
            "author": [
                "Kyle Brown",
                "Dylan M. Asmar",
                "Mac Schwager",
                "Mykel J. Kochenderfer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00192v1",
                "http://arxiv.org/pdf/2311.00192v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02100v1",
            "title": "A Comprehensive Study on Model Initialization Techniques Ensuring\n  Efficient Federated Learning",
            "updated": "2023-10-31T23:26:58Z",
            "published": "2023-10-31T23:26:58Z",
            "summary": "Advancement in the field of machine learning is unavoidable, but something of\nmajor concern is preserving the privacy of the users whose data is being used\nfor training these machine learning algorithms. Federated learning(FL) has\nemerged as a promising paradigm for training machine learning models in a\ndistributed and privacy-preserving manner which enables one to collaborate and\ntrain a global model without sharing local data. But starting this learning\nprocess on each device in the right way, called ``model initialization\" is\ncritical. The choice of initialization methods used for models plays a crucial\nrole in the performance, convergence speed, communication efficiency, privacy\nguarantees of federated learning systems, etc. In this survey, we dive deeper\ninto a comprehensive study of various ways of model initialization techniques\nin FL.Unlike other studies, our research meticulously compares, categorizes,\nand delineates the merits and demerits of each technique, examining their\napplicability across diverse FL scenarios. We highlight how factors like client\nvariability, data non-IIDness, model caliber, security considerations, and\nnetwork restrictions influence FL model outcomes and propose how strategic\ninitialization can address and potentially rectify many such challenges. The\nmotivation behind this survey is to highlight that the right start can help\novercome challenges like varying data quality, security issues, and network\nproblems. Our insights provide a foundational base for experts looking to fully\nutilize FL, also while understanding the complexities of model initialization.",
            "author": [
                "Ishmeet Kaur",
                "Adwaita Janardhan Jadhav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02100v1",
                "http://arxiv.org/pdf/2311.02100v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00189v1",
            "title": "XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak\n  Supervision",
            "updated": "2023-10-31T23:24:22Z",
            "published": "2023-10-31T23:24:22Z",
            "summary": "Text classification aims to effectively categorize documents into pre-defined\ncategories. Traditional methods for text classification often rely on large\namounts of manually annotated training data, making the process time-consuming\nand labor-intensive. To address this issue, recent studies have focused on\nweakly-supervised and extremely weakly-supervised settings, which require\nminimal or no human annotation, respectively. In previous methods of weakly\nsupervised text classification, pseudo-training data is generated by assigning\npseudo-labels to documents based on their alignment (e.g., keyword matching)\nwith specific classes. However, these methods ignore the importance of\nincorporating the explanations of the generated pseudo-labels, or saliency of\nindividual words, as additional guidance during the text classification\ntraining process. To address this limitation, we propose XAI-CLASS, a novel\nexplanation-enhanced extremely weakly-supervised text classification method\nthat incorporates word saliency prediction as an auxiliary task. XAI-CLASS\nbegins by employing a multi-round question-answering process to generate\npseudo-training data that promotes the mutual enhancement of class labels and\ncorresponding explanation word generation. This pseudo-training data is then\nused to train a multi-task framework that simultaneously learns both text\nclassification and word saliency prediction. Extensive experiments on several\nweakly-supervised text classification datasets show that XAI-CLASS outperforms\nother weakly-supervised text classification methods significantly. Moreover,\nexperiments demonstrate that XAI-CLASS enhances both model performance and\nexplainability.",
            "author": [
                "Daniel Hajialigol",
                "Hanwen Liu",
                "Xuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00189v1",
                "http://arxiv.org/pdf/2311.00189v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00188v1",
            "title": "A Two-Step Framework for Multi-Material Decomposition of Dual Energy\n  Computed Tomography from Projection Domain",
            "updated": "2023-10-31T23:23:14Z",
            "published": "2023-10-31T23:23:14Z",
            "summary": "Dual-energy computed tomography (DECT) utilizes separate X-ray energy spectra\nto improve multi-material decomposition (MMD) for various diagnostic\napplications. However accurate decomposing more than two types of material\nremains challenging using conventional methods. Deep learning (DL) methods have\nshown promise to improve the MMD performance, but typical approaches of\nconducing DL-MMD in the image domain fail to fully utilize projection\ninformation or under iterative setup are computationally inefficient in both\ntraining and prediction. In this work, we present a clinical-applicable MMD\n(>2) framework rFast-MMDNet, operating with raw projection data in\nnon-recursive setup, for breast tissue differentiation. rFast-MMDNet is a\ntwo-stage algorithm, including stage-one SinoNet to perform dual energy\nprojection decomposition on tissue sinograms and stage-two FBP-DenoiseNet to\nperform domain adaptation and image post-processing. rFast-MMDNet was tested on\na 2022 DL-Spectral-Challenge breast phantom dataset. The two stages of\nrFast-MMDNet were evaluated separately and then compared with four noniterative\nreference methods including a direct inversion method (AA-MMD), an image domain\nDL method (ID-UNet), AA-MMD/ID-UNet + DenoiseNet and a sinogram domain DL\nmethod (Triple-CBCT). Our results show that models trained from information\nstored in DE transmission domain can yield high-fidelity decomposition of the\nadipose, calcification, and fibroglandular materials with averaged RMSE, MAE,\nnegative PSNR, and SSIM of 0.004+/-~0, 0.001+/-~0, -45.027+/-~0.542, and\n0.002+/-~0 benchmarking to the ground truth, respectively. Training of entire\nrFast-MMDNet on a 4xRTX A6000 GPU cluster took a day with inference time <1s.\nAll DL methods generally led to more accurate MMD than AA-MMD. rFast-MMDNet\noutperformed Triple-CBCT, but both are superior to the image-domain based\nmethods.",
            "author": [
                "Di Xu",
                "Qihui Lyu",
                "Dan Ruan",
                "Ke Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00188v1",
                "http://arxiv.org/pdf/2311.00188v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00187v2",
            "title": "Decodable and Sample Invariant Continuous Object Encoder",
            "updated": "2023-11-21T15:25:15Z",
            "published": "2023-10-31T23:19:30Z",
            "summary": "We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a\ncontinuous object (e.g. a function), HDFE produces an explicit vector\nrepresentation of the given object, invariant to the sample distribution and\ndensity. Sample distribution and density invariance enables HDFE to\nconsistently encode continuous objects regardless of their sampling, and\ntherefore allows neural networks to receive continuous objects as inputs for\nmachine learning tasks, such as classification and regression. Besides, HDFE\ndoes not require any training and is proved to map the object into an organized\nembedding space, which facilitates the training of the downstream tasks. In\naddition, the encoding is decodable, which enables neural networks to regress\ncontinuous objects by regressing their encodings. Therefore, HDFE serves as an\ninterface for processing continuous objects.\n  We apply HDFE to function-to-function mapping, where vanilla HDFE achieves\ncompetitive performance as the state-of-the-art algorithm. We apply HDFE to\npoint cloud surface normal estimation, where a simple replacement from PointNet\nto HDFE leads to immediate 12% and 15% error reductions in two benchmarks. In\naddition, by integrating HDFE into the PointNet-based SOTA network, we improve\nthe SOTA baseline by 2.5% and 1.7% in the same benchmarks.",
            "author": [
                "Dehao Yuan",
                "Furong Huang",
                "Cornelia Ferm\u00fcller",
                "Yiannis Aloimonos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00187v2",
                "http://arxiv.org/pdf/2311.00187v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00186v1",
            "title": "Image Restoration with Point Spread Function Regularization and Active\n  Learning",
            "updated": "2023-10-31T23:16:26Z",
            "published": "2023-10-31T23:16:26Z",
            "summary": "Large-scale astronomical surveys can capture numerous images of celestial\nobjects, including galaxies and nebulae. Analysing and processing these images\ncan reveal intricate internal structures of these objects, allowing researchers\nto conduct comprehensive studies on their morphology, evolution, and physical\nproperties. However, varying noise levels and point spread functions can hamper\nthe accuracy and efficiency of information extraction from these images. To\nmitigate these effects, we propose a novel image restoration algorithm that\nconnects a deep learning-based restoration algorithm with a high-fidelity\ntelescope simulator. During the training stage, the simulator generates images\nwith different levels of blur and noise to train the neural network based on\nthe quality of restored images. After training, the neural network can directly\nrestore images obtained by the telescope, as represented by the simulator. We\nhave tested the algorithm using real and simulated observation data and have\nfound that it effectively enhances fine structures in blurry images and\nincreases the quality of observation images. This algorithm can be applied to\nlarge-scale sky survey data, such as data obtained by LSST, Euclid, and CSST,\nto further improve the accuracy and efficiency of information extraction,\npromoting advances in the field of astronomical research.",
            "author": [
                "Peng Jia",
                "Jiameng Lv",
                "Runyu Ning",
                "Yu Song",
                "Nan Li",
                "Kaifan Ji",
                "Chenzhou Cui",
                "Shanshan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00186v1",
                "http://arxiv.org/pdf/2311.00186v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA",
                "astro-ph.SR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01472v1",
            "title": "Relation Extraction from News Articles (RENA): A Tool for Epidemic\n  Surveillance",
            "updated": "2023-10-31T23:14:54Z",
            "published": "2023-10-31T23:14:54Z",
            "summary": "Relation Extraction from News Articles (RENA) is a browser-based tool\ndesigned to extract key entities and their semantic relationships in English\nlanguage news articles related to infectious diseases. Constructed using the\nReact framework, this system presents users with an elegant and user-friendly\ninterface. It enables users to input a news article and select from a choice of\ntwo models to generate a comprehensive list of relations within the provided\ntext. As a result, RENA allows real-time parsing of news articles to extract\nkey information for epidemic surveillance, contributing to EPIWATCH, an\nopen-source intelligence-based epidemic warning system.",
            "author": [
                "Jaeff Hong",
                "Duong Dung",
                "Danielle Hutchinson",
                "Zubair Akhtar",
                "Rosalie Chen",
                "Rebecca Dawson",
                "Aditya Joshi",
                "Samsung Lim",
                "C Raina MacIntyre",
                "Deepti Gurdasani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01472v1",
                "http://arxiv.org/pdf/2311.01472v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00180v1",
            "title": "Object-centric Video Representation for Long-term Action Anticipation",
            "updated": "2023-10-31T22:54:31Z",
            "published": "2023-10-31T22:54:31Z",
            "summary": "This paper focuses on building object-centric representations for long-term\naction anticipation in videos. Our key motivation is that objects provide\nimportant cues to recognize and predict human-object interactions, especially\nwhen the predictions are longer term, as an observed \"background\" object could\nbe used by the human actor in the future. We observe that existing object-based\nvideo recognition frameworks either assume the existence of in-domain\nsupervised object detectors or follow a fully weakly-supervised pipeline to\ninfer object locations from action labels. We propose to build object-centric\nvideo representations by leveraging visual-language pretrained models. This is\nachieved by \"object prompts\", an approach to extract task-specific\nobject-centric representations from general-purpose pretrained models without\nfinetuning. To recognize and predict human-object interactions, we use a\nTransformer-based neural architecture which allows the \"retrieval\" of relevant\nobjects for action anticipation at various time scales. We conduct extensive\nevaluations on the Ego4D, 50Salads, and EGTEA Gaze+ benchmarks. Both\nquantitative and qualitative results confirm the effectiveness of our proposed\nmethod.",
            "author": [
                "Ce Zhang",
                "Changcheng Fu",
                "Shijie Wang",
                "Nakul Agarwal",
                "Kwonjoon Lee",
                "Chiho Choi",
                "Chen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00180v1",
                "http://arxiv.org/pdf/2311.00180v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00177v1",
            "title": "Students' Perspective on AI Code Completion: Benefits and Challenges",
            "updated": "2023-10-31T22:41:16Z",
            "published": "2023-10-31T22:41:16Z",
            "summary": "AI Code Completion (e.g., GitHub's Copilot, Amazon CodeWhisperer) has\nrevolutionized the way in which computer science students interact with\nprogramming languages. However, these tools are not available for free public\nuse, preventing us from conducting our research. In addition, AI code\ncompletion has been studied from developers' perspective, not students'\nperspective who represent the future generation of our digital world. In this\narticle, we investigated the benefits, challenges, and expectations of AI code\ncompletion from students' perspectives and introduced AutoAurora, an AI code\ncompletion tool integrated into the Visual Studio Code Extension as a research\ninstrument. Through an interview study with ten participants, we found that AI\ncode completion enhanced students' productivity and efficiency by providing\ncorrect syntax suggestions, offering alternative solutions, and functioning as\na coding tutor. However, the over-reliance on AI code completion may lead to a\nsurface-level understanding of programming concepts, diminishing\nproblem-solving skills and restricting creativity. In the future, AI code\ncompletion must be explainable to facilitate the learning of coding concepts.",
            "author": [
                "Wannita Takerngsaksiri",
                "Cleshan Warusavitarne",
                "Christian Yaacoub",
                "Matthew Hee Keng Hou",
                "Chakkrit Tantithamthavorn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00177v1",
                "http://arxiv.org/pdf/2311.00177v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00176v3",
            "title": "ChipNeMo: Domain-Adapted LLMs for Chip Design",
            "updated": "2023-12-03T00:56:36Z",
            "published": "2023-10-31T22:35:58Z",
            "summary": "ChipNeMo aims to explore the applications of large language models (LLMs) for\nindustrial chip design. Instead of directly deploying off-the-shelf commercial\nor open-source LLMs, we instead adopt the following domain adaptation\ntechniques: custom tokenizers, domain-adaptive continued pretraining,\nsupervised fine-tuning (SFT) with domain-specific instructions, and\ndomain-adapted retrieval models. We evaluate these methods on three selected\nLLM applications for chip design: an engineering assistant chatbot, EDA script\ngeneration, and bug summarization and analysis. Our results show that these\ndomain adaptation techniques enable significant LLM performance improvements\nover general-purpose base models across the three evaluated applications,\nenabling up to 5x model size reduction with similar or better performance on a\nrange of design tasks. Our findings also indicate that there's still room for\nimprovement between our current results and ideal outcomes. We believe that\nfurther investigation of domain-adapted LLM approaches will help close this gap\nin the future.",
            "author": [
                "Mingjie Liu",
                "Teodor-Dumitru Ene",
                "Robert Kirby",
                "Chris Cheng",
                "Nathaniel Pinckney",
                "Rongjian Liang",
                "Jonah Alben",
                "Himyanshu Anand",
                "Sanmitra Banerjee",
                "Ismet Bayraktaroglu",
                "Bonita Bhaskaran",
                "Bryan Catanzaro",
                "Arjun Chaudhuri",
                "Sharon Clay",
                "Bill Dally",
                "Laura Dang",
                "Parikshit Deshpande",
                "Siddhanth Dhodhi",
                "Sameer Halepete",
                "Eric Hill",
                "Jiashang Hu",
                "Sumit Jain",
                "Brucek Khailany",
                "George Kokai",
                "Kishor Kunal",
                "Xiaowei Li",
                "Charley Lind",
                "Hao Liu",
                "Stuart Oberman",
                "Sujeet Omar",
                "Sreedhar Pratty",
                "Jonathan Raiman",
                "Ambar Sarkar",
                "Zhengjiang Shao",
                "Hanfei Sun",
                "Pratik P Suthar",
                "Varun Tej",
                "Walker Turner",
                "Kaizhe Xu",
                "Haoxing Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00176v3",
                "http://arxiv.org/pdf/2311.00176v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00172v1",
            "title": "Robust Safety Classifier for Large Language Models: Adversarial Prompt\n  Shield",
            "updated": "2023-10-31T22:22:10Z",
            "published": "2023-10-31T22:22:10Z",
            "summary": "Large Language Models' safety remains a critical concern due to their\nvulnerability to adversarial attacks, which can prompt these systems to produce\nharmful responses. In the heart of these systems lies a safety classifier, a\ncomputational model trained to discern and mitigate potentially harmful,\noffensive, or unethical outputs. However, contemporary safety classifiers,\ndespite their potential, often fail when exposed to inputs infused with\nadversarial noise. In response, our study introduces the Adversarial Prompt\nShield (APS), a lightweight model that excels in detection accuracy and\ndemonstrates resilience against adversarial prompts. Additionally, we propose\nnovel strategies for autonomously generating adversarial training datasets,\nnamed Bot Adversarial Noisy Dialogue (BAND) datasets. These datasets are\ndesigned to fortify the safety classifier's robustness, and we investigate the\nconsequences of incorporating adversarial examples into the training process.\nThrough evaluations involving Large Language Models, we demonstrate that our\nclassifier has the potential to decrease the attack success rate resulting from\nadversarial attacks by up to 60%. This advancement paves the way for the next\ngeneration of more reliable and resilient conversational agents.",
            "author": [
                "Jinhwa Kim",
                "Ali Derakhshan",
                "Ian G. Harris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00172v1",
                "http://arxiv.org/pdf/2311.00172v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00170v1",
            "title": "Experimental Demonstration of Coupled Learning in Elastic Networks",
            "updated": "2023-10-31T22:09:23Z",
            "published": "2023-10-31T22:09:23Z",
            "summary": "Coupled learning is a contrastive scheme for tuning the properties of\nindividual elements within a network in order to achieve desired functionality\nof the system. It takes advantage of physics both to learn using local rules\nand to \"compute\" the output response to input data, thus enabling the system to\nperform decentralized computation without the need for a processor or external\nmemory. We demonstrate a proof-of-concept mechanical network that can learn\nsimple tasks such as self-symmetrizing via iterative tuning of individual\nspring rest lengths. These mechanical networks could feasibly be scaled and\nautomated to solve increasingly complex tasks, hinting at a new class of\n\"smart\" metamaterials.",
            "author": [
                "Lauren E. Altman",
                "Menachem Stern",
                "Andrea J. Liu",
                "Douglas J. Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00170v1",
                "http://arxiv.org/pdf/2311.00170v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00167v1",
            "title": "Multi-task Deep Convolutional Network to Predict Sea Ice Concentration\n  and Drift in the Arctic Ocean",
            "updated": "2023-10-31T21:51:12Z",
            "published": "2023-10-31T21:51:12Z",
            "summary": "Forecasting sea ice concentration (SIC) and sea ice drift (SID) in the Arctic\nOcean is of great significance as the Arctic environment has been changed by\nthe recent warming climate. Given that physical sea ice models require high\ncomputational costs with complex parameterization, deep learning techniques can\neffectively replace the physical model and improve the performance of sea ice\nprediction. This study proposes a novel multi-task fully conventional network\narchitecture named hierarchical information-sharing U-net (HIS-Unet) to predict\ndaily SIC and SID. Instead of learning SIC and SID separately at each branch,\nwe allow the SIC and SID layers to share their information and assist each\nother's prediction through the weighting attention modules (WAMs).\nConsequently, our HIS-Unet outperforms other statistical approaches, sea ice\nphysical models, and neural networks without such information-sharing units.\nThe improvement of HIS-Unet is obvious both for SIC and SID prediction when and\nwhere sea ice conditions change seasonally, which implies that the information\nsharing through WAMs allows the model to learn the sudden changes of SIC and\nSID. The weight values of the WAMs imply that SIC information plays a more\ncritical role in SID prediction, compared to that of SID information in SIC\nprediction, and information sharing is more active in sea ice edges (seasonal\nsea ice) than in the central Arctic (multi-year sea ice).",
            "author": [
                "Younghyun Koo",
                "Maryam Rahnemoonfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00167v1",
                "http://arxiv.org/pdf/2311.00167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00161v1",
            "title": "Beyond Denouncing Hate: Strategies for Countering Implied Biases and\n  Stereotypes in Language",
            "updated": "2023-10-31T21:33:46Z",
            "published": "2023-10-31T21:33:46Z",
            "summary": "Counterspeech, i.e., responses to counteract potential harms of hateful\nspeech, has become an increasingly popular solution to address online hate\nspeech without censorship. However, properly countering hateful language\nrequires countering and dispelling the underlying inaccurate stereotypes\nimplied by such language. In this work, we draw from psychology and philosophy\nliterature to craft six psychologically inspired strategies to challenge the\nunderlying stereotypical implications of hateful language. We first examine the\nconvincingness of each of these strategies through a user study, and then\ncompare their usages in both human- and machine-generated counterspeech\ndatasets. Our results show that human-written counterspeech uses countering\nstrategies that are more specific to the implied stereotype (e.g., counter\nexamples to the stereotype, external factors about the stereotype's origins),\nwhereas machine-generated counterspeech uses less specific strategies (e.g.,\ngenerally denouncing the hatefulness of speech). Furthermore, machine-generated\ncounterspeech often employs strategies that humans deem less convincing\ncompared to human-produced counterspeech. Our findings point to the importance\nof accounting for the underlying stereotypical implications of speech when\ngenerating counterspeech and for better machine reasoning about\nanti-stereotypical examples.",
            "author": [
                "Jimin Mun",
                "Emily Allaway",
                "Akhila Yerukola",
                "Laura Vianna",
                "Sarah-Jane Leslie",
                "Maarten Sap"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00161v1",
                "http://arxiv.org/pdf/2311.00161v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00159v1",
            "title": "Longer Fixations, More Computation: Gaze-Guided Recurrent Neural\n  Networks",
            "updated": "2023-10-31T21:32:11Z",
            "published": "2023-10-31T21:32:11Z",
            "summary": "Humans read texts at a varying pace, while machine learning models treat each\ntoken in the same way in terms of a computational process. Therefore, we ask,\ndoes it help to make models act more like humans? In this paper, we convert\nthis intuition into a set of novel models with fixation-guided parallel RNNs or\nlayers and conduct various experiments on language modeling and sentiment\nanalysis tasks to test their effectiveness, thus providing empirical validation\nfor this intuition. Our proposed models achieve good performance on the\nlanguage modeling task, considerably surpassing the baseline model. In\naddition, we find that, interestingly, the fixation duration predicted by\nneural networks bears some resemblance to humans' fixation. Without any\nexplicit guidance, the model makes similar choices to humans. We also\ninvestigate the reasons for the differences between them, which explain why\n\"model fixations\" are often more suitable than human fixations, when used to\nguide language models.",
            "author": [
                "Xinting Huang",
                "Jiajing Wan",
                "Ioannis Kritikos",
                "Nora Hollenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00159v1",
                "http://arxiv.org/pdf/2311.00159v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16129v1",
            "title": "Dataset for Investigating Anomalies in Compute Clusters",
            "updated": "2023-10-31T21:26:28Z",
            "published": "2023-10-31T21:26:28Z",
            "summary": "The dataset was collected for 332 compute nodes throughout May 19 - 23, 2023.\nMay 19 - 22 characterizes normal compute cluster behavior, while May 23\nincludes an anomalous event. The dataset includes eight CPU, 11 disk, 47\nmemory, and 22 Slurm metrics. It represents five distinct hardware\nconfigurations and contains over one million records, totaling more than 180GB\nof raw data.",
            "author": [
                "Diana McSpadden",
                "Yasir Alanazi",
                "Bryan Hess",
                "Laura Hild",
                "Mark Jones",
                "Yiyang Lub",
                "Ahmed Mohammed",
                "Wesley Moore",
                "Jie Ren",
                "Malachi Schram",
                "Evgenia Smirni"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.10058230",
                "http://arxiv.org/abs/2311.16129v1",
                "http://arxiv.org/pdf/2311.16129v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00157v2",
            "title": "Score Normalization for a Faster Diffusion Exponential Integrator\n  Sampler",
            "updated": "2023-11-10T00:30:14Z",
            "published": "2023-10-31T21:18:44Z",
            "summary": "Recently, Zhang et al. have proposed the Diffusion Exponential Integrator\nSampler (DEIS) for fast generation of samples from Diffusion Models. It\nleverages the semi-linear nature of the probability flow ordinary differential\nequation (ODE) in order to greatly reduce integration error and improve\ngeneration quality at low numbers of function evaluations (NFEs). Key to this\napproach is the score function reparameterisation, which reduces the\nintegration error incurred from using a fixed score function estimate over each\nintegration step. The original authors use the default parameterisation used by\nmodels trained for noise prediction -- multiply the score by the standard\ndeviation of the conditional forward noising distribution. We find that\nalthough the mean absolute value of this score parameterisation is close to\nconstant for a large portion of the reverse sampling process, it changes\nrapidly at the end of sampling. As a simple fix, we propose to instead\nreparameterise the score (at inference) by dividing it by the average absolute\nvalue of previous score estimates at that time step collected from offline high\nNFE generations. We find that our score normalisation (DEIS-SN) consistently\nimproves FID compared to vanilla DEIS, showing an improvement at 10 NFEs from\n6.44 to 5.57 on CIFAR-10 and from 5.9 to 4.95 on LSUN-Church 64x64. Our code is\navailable at https://github.com/mtkresearch/Diffusion-DEIS-SN",
            "author": [
                "Guoxuan Xia",
                "Duolikun Danier",
                "Ayan Das",
                "Stathi Fotiadis",
                "Farhang Nabiei",
                "Ushnish Sengupta",
                "Alberto Bernacchia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00157v2",
                "http://arxiv.org/pdf/2311.00157v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00156v1",
            "title": "Rethinking the Cloudonomics of Efficient I/O for Data-Intensive\n  Analytics Applications",
            "updated": "2023-10-31T21:14:30Z",
            "published": "2023-10-31T21:14:30Z",
            "summary": "This paper explores a prevailing trend in the industry: migrating\ndata-intensive analytics applications from on-premises to cloud-native\nenvironments. We find that the unique cost models associated with cloud-based\nstorage necessitate a more nuanced understanding of optimizing performance.\nSpecifically, based on traces collected from Uber's Presto fleet in production,\nwe argue that common I/O optimizations, such as table scan and filter, and\nbroadcast join, may lead to unexpected costs when naively applied in the cloud.\nThis is because traditional I/O optimizations mainly focus on improving\nthroughput or latency in on-premises settings, without taking into account the\nmonetary costs associated with storage API calls. In cloud environments, these\ncosts can be significant, potentially involving billions of API calls per day\njust for Presto workloads at Uber scale. Presented as a case study, this paper\nserves as a starting point for further research to design efficient I/O\nstrategies specifically tailored for data-intensive applications in cloud\nsettings.",
            "author": [
                "Chunxu Tang",
                "Yi Wang",
                "Bin Fan",
                "Beinan Wang",
                "Shouwei Chen",
                "Ziyue Qiu",
                "Chen Liang",
                "Jing Zhao",
                "Yu Zhu",
                "Mingmin Chen",
                "Zhongting Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00156v1",
                "http://arxiv.org/pdf/2311.00156v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00155v2",
            "title": "Antiferromagnetic Switching in Mn$_2$Au Using a Novel Laser Induced\n  Optical Torque on Ultrafast Timescales",
            "updated": "2023-11-16T11:57:30Z",
            "published": "2023-10-31T21:05:26Z",
            "summary": "Efficient manipulation of the N\\'eel vector in antiferromagnets can be\ninduced by generation of spin orbit (SOT) or spin-transfer (STT) torques. Here\nwe predict another possibility for antiferromagnetic domain switching by using\na non-zero staggered field induced from optical laser excitation. We present\nresults on the atomistic scale dynamic simulations from the application of a\nnovel laser induced torque using optical frequencies for all-optical switching\n(AOS) of the N\\'eel vector in the antiferromagnet Mn$_2$Au. The driving\nmechanism takes advantage of the sizeable 'exchange enhancement' characteristic\nof antiferromagnets, allowing for small picosecond 90 and 180 degree\nprecessional switching with laser fluences on the order of mJ/cm$^2$. The\nsymmetry of these novel torques are highly dependent on the time-varying\nmagnetisation direction, creating a sign change in the torque which greatly\nminimises the \"over-shooting problem\" common to SOT and STT. Lastly, we\ndemonstrate the opportunity for this laser optical torque to deterministically\nswitch single magnetic domains.",
            "author": [
                "J. L. Ross",
                "P-I. Gavriloaea",
                "F. Freimuth",
                "T. Adamantopoulos",
                "Y. Mokrousov",
                "R. F. L. Evans",
                "R. Chantrell",
                "R. M. Otxoa",
                "O. Chubykalo-Fesenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00155v2",
                "http://arxiv.org/pdf/2311.00155v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00154v1",
            "title": "Medi-CAT: Contrastive Adversarial Training for Medical Image\n  Classification",
            "updated": "2023-10-31T20:58:32Z",
            "published": "2023-10-31T20:58:32Z",
            "summary": "There are not many large medical image datasets available. For these\ndatasets, too small deep learning models can't learn useful features, so they\ndon't work well due to underfitting, and too big models tend to overfit the\nlimited data. As a result, there is a compromise between the two issues. This\npaper proposes a training strategy Medi-CAT to overcome the underfitting and\noverfitting phenomena in medical imaging datasets. Specifically, the proposed\ntraining methodology employs large pre-trained vision transformers to overcome\nunderfitting and adversarial and contrastive learning techniques to prevent\noverfitting. The proposed method is trained and evaluated on four medical image\nclassification datasets from the MedMNIST collection. Our experimental results\nindicate that the proposed approach improves the accuracy up to 2% on three\nbenchmark datasets compared to well-known approaches, whereas it increases the\nperformance up to 4.1% over the baseline methods.",
            "author": [
                "Pervaiz Iqbal Khan",
                "Andreas Dengel",
                "Sheraz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00154v1",
                "http://arxiv.org/pdf/2311.00154v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00152v1",
            "title": "Developing a Tool to Automate Extensions to Support a Flexible Extension\n  Policy",
            "updated": "2023-10-31T20:55:08Z",
            "published": "2023-10-31T20:55:08Z",
            "summary": "In this work, we present the development of an automated extension tool to\nassist educators and increase the success and well-being of students by\nimplementing flexible extension policies. Flexible extension policies\nmaterialize in many ways, yet there are similarities in students' interactions\nwith them; students tend to request multi-day long extensions repeatedly. In\ncourses with hundreds or potentially thousands of students, providing a system\nto support this extension request demand is not possible given most currently\navailable resources and limited staff. As such, a tool is necessary to help\nautomate flexible extension processes. The development of this tool should\nreduce staff load while increasing individualized student support, which can be\nused in varying ways for different extension policies. Our research questions\nare: RQ1: Does the extension tool reduce barriers and stigma around asking for\nassistance? RQ2: Does the tool lessen the wait time between requesting and\nreceiving an extension, and how does the tool improve students' learning\nexperience in the course? These questions will help inform us about how an\nautomated tool for flexible extensions helps support growing course sizes and\nstudents who may not otherwise receive the support they need for their success\nand well-being in the course.",
            "author": [
                "Jordan Schwartz",
                "Madison Bohannan",
                "Jacob Yim",
                "Yuerou Tang",
                "Dana Benedicto",
                "Charisse Liu",
                "Armando Fox",
                "Lisa Yan",
                "Narges Norouzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00152v1",
                "http://arxiv.org/pdf/2311.00152v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00149v1",
            "title": "A Knowledge Compilation Take on Binary Polynomial Optimization",
            "updated": "2023-10-31T20:47:25Z",
            "published": "2023-10-31T20:47:25Z",
            "summary": "The Binary Polynomial Optimization (BPO) problem is defined as the problem of\nmaximizing a given polynomial function over all binary points. The main\ncontribution of this paper is to draw a novel connection between BPO and the\nproblem of finding the maximal assignment for a Boolean function with weights\non variables. This connection allows us to give a strongly polynomial algorithm\nthat solves BPO with a hypergraph that is either $\\beta$-acyclic or with\nbounded incidence treewidth. This result unifies and significantly extends the\nknown tractable classes of BPO. The generality of our technique allows us to\ndeal also with extensions of BPO, where we enforce extended cardinality\nconstraints on the set of binary points, and where we seek $k$ best feasible\nsolutions. We also extend our results to the significantly more general problem\nwhere variables are replaced by literals. Preliminary computational results\nshow that the resulting algorithms can be significantly faster than current\nstate-of-the-art.",
            "author": [
                "Florent Capelli",
                "Alberto Del Pia",
                "Silvia Di Gregorio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00149v1",
                "http://arxiv.org/pdf/2311.00149v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00144v1",
            "title": "Backdoor Threats from Compromised Foundation Models to Federated\n  Learning",
            "updated": "2023-10-31T20:39:54Z",
            "published": "2023-10-31T20:39:54Z",
            "summary": "Federated learning (FL) represents a novel paradigm to machine learning,\naddressing critical issues related to data privacy and security, yet suffering\nfrom data insufficiency and imbalance. The emergence of foundation models (FMs)\nprovides a promising solution to the problems with FL. For instance, FMs could\nserve as teacher models or good starting points for FL. However, the\nintegration of FM in FL presents a new challenge, exposing the FL systems to\npotential threats. This paper investigates the robustness of FL incorporating\nFMs by assessing their susceptibility to backdoor attacks. Contrary to classic\nbackdoor attacks against FL, the proposed attack (1) does not require the\nattacker fully involved in the FL process; (2) poses a significant risk in\npractical FL scenarios; (3) is able to evade existing robust FL frameworks/ FL\nbackdoor defenses; (4) underscores the researches on the robustness of FL\nsystems integrated with FMs. The effectiveness of the proposed attack is\ndemonstrated by extensive experiments with various well-known models and\nbenchmark datasets encompassing both text and image classification domains.",
            "author": [
                "Xi Li",
                "Songhe Wang",
                "Chen Wu",
                "Hao Zhou",
                "Jiaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00144v1",
                "http://arxiv.org/pdf/2311.00144v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00143v1",
            "title": "Two-Stage Classifier for Campaign Negativity Detection using Axis\n  Embeddings: A Case Study on Tweets of Political Users during 2021\n  Presidential Election in Iran",
            "updated": "2023-10-31T20:31:41Z",
            "published": "2023-10-31T20:31:41Z",
            "summary": "In elections around the world, the candidates may turn their campaigns toward\nnegativity due to the prospect of failure and time pressure. In the digital\nage, social media platforms such as Twitter are rich sources of political\ndiscourse. Therefore, despite the large amount of data that is published on\nTwitter, the automatic system for campaign negativity detection can play an\nessential role in understanding the strategy of candidates and parties in their\ncampaigns. In this paper, we propose a hybrid model for detecting campaign\nnegativity consisting of a two-stage classifier that combines the strengths of\ntwo machine learning models. Here, we have collected Persian tweets from 50\npolitical users, including candidates and government officials. Then we\nannotated 5,100 of them that were published during the year before the 2021\npresidential election in Iran. In the proposed model, first, the required\ndatasets of two classifiers based on the cosine similarity of tweet embeddings\nwith axis embeddings (which are the average of embedding in positive and\nnegative classes of tweets) from the training set (85\\%) are made, and then\nthese datasets are considered the training set of the two classifiers in the\nhybrid model. Finally, our best model (RF-RF) was able to achieve 79\\% for the\nmacro F1 score and 82\\% for the weighted F1 score. By running the best model on\nthe rest of the tweets of 50 political users that were published one year\nbefore the election and with the help of statistical models, we find that the\npublication of a tweet by a candidate has nothing to do with the negativity of\nthat tweet, and the presence of the names of political persons and political\norganizations in the tweet is directly related to its negativity.",
            "author": [
                "Fatemeh Rajabi",
                "Ali Mohades"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00143v1",
                "http://arxiv.org/pdf/2311.00143v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00136v3",
            "title": "Neuroformer: Multimodal and Multitask Generative Pretraining for Brain\n  Data",
            "updated": "2023-11-08T19:48:12Z",
            "published": "2023-10-31T20:17:32Z",
            "summary": "State-of-the-art systems neuroscience experiments yield large-scale\nmultimodal data, and these data sets require new tools for analysis. Inspired\nby the success of large pretrained models in vision and language domains, we\nreframe the analysis of large-scale, cellular-resolution neuronal spiking data\ninto an autoregressive spatiotemporal generation problem. Neuroformer is a\nmultimodal, multitask generative pretrained transformer (GPT) model that is\nspecifically designed to handle the intricacies of data in systems\nneuroscience. It scales linearly with feature size, can process an arbitrary\nnumber of modalities, and is adaptable to downstream tasks, such as predicting\nbehavior. We first trained Neuroformer on simulated datasets, and found that it\nboth accurately predicted simulated neuronal circuit activity, and also\nintrinsically inferred the underlying neural circuit connectivity, including\ndirection. When pretrained to decode neural responses, the model predicted the\nbehavior of a mouse with only few-shot fine-tuning, suggesting that the model\nbegins learning how to do so directly from the neural representations\nthemselves, without any explicit supervision. We used an ablation study to show\nthat joint training on neuronal responses and behavior boosted performance,\nhighlighting the model's ability to associate behavioral and neural\nrepresentations in an unsupervised manner. These findings show that Neuroformer\ncan analyze neural datasets and their emergent properties, informing the\ndevelopment of models and hypotheses associated with the brain.",
            "author": [
                "Antonis Antoniades",
                "Yiyi Yu",
                "Joseph Canzano",
                "William Wang",
                "Spencer LaVere Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00136v3",
                "http://arxiv.org/pdf/2311.00136v3"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00134v1",
            "title": "Joint Depth Prediction and Semantic Segmentation with Multi-View SAM",
            "updated": "2023-10-31T20:15:40Z",
            "published": "2023-10-31T20:15:40Z",
            "summary": "Multi-task approaches to joint depth and segmentation prediction are\nwell-studied for monocular images. Yet, predictions from a single-view are\ninherently limited, while multiple views are available in many robotics\napplications. On the other end of the spectrum, video-based and full 3D methods\nrequire numerous frames to perform reconstruction and segmentation. With this\nwork we propose a Multi-View Stereo (MVS) technique for depth prediction that\nbenefits from rich semantic features of the Segment Anything Model (SAM). This\nenhanced depth prediction, in turn, serves as a prompt to our Transformer-based\nsemantic segmentation decoder. We report the mutual benefit that both tasks\nenjoy in our quantitative and qualitative studies on the ScanNet dataset. Our\napproach consistently outperforms single-task MVS and segmentation models,\nalong with multi-task monocular methods.",
            "author": [
                "Mykhailo Shvets",
                "Dongxu Zhao",
                "Marc Niethammer",
                "Roni Sengupta",
                "Alexander C. Berg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00134v1",
                "http://arxiv.org/pdf/2311.00134v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00128v2",
            "title": "On the effect of curriculum learning with developmental data for grammar\n  acquisition",
            "updated": "2023-11-03T16:42:33Z",
            "published": "2023-10-31T20:05:30Z",
            "summary": "This work explores the degree to which grammar acquisition is driven by\nlanguage `simplicity' and the source modality (speech vs. text) of data. Using\nBabyBERTa as a probe, we find that grammar acquisition is largely driven by\nexposure to speech data, and in particular through exposure to two of the\nBabyLM training corpora: AO-Childes and Open Subtitles. We arrive at this\nfinding by examining various ways of presenting input data to our model. First,\nwe assess the impact of various sequence-level complexity based curricula. We\nthen examine the impact of learning over `blocks' -- covering spans of text\nthat are balanced for the number of tokens in each of the source corpora\n(rather than number of lines). Finally, we explore curricula that vary the\ndegree to which the model is exposed to different corpora. In all cases, we\nfind that over-exposure to AO-Childes and Open Subtitles significantly drives\nperformance. We verify these findings through a comparable control dataset in\nwhich exposure to these corpora, and speech more generally, is limited by\ndesign. Our findings indicate that it is not the proportion of tokens occupied\nby high-utility data that aids acquisition, but rather the proportion of\ntraining steps assigned to such data. We hope this encourages future research\ninto the use of more developmentally plausible linguistic data (which tends to\nbe more scarce) to augment general purpose pre-training regimes.",
            "author": [
                "Mattia Opper",
                "J. Morrison",
                "N. Siddharth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00128v2",
                "http://arxiv.org/pdf/2311.00128v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00117v1",
            "title": "BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B",
            "updated": "2023-10-31T19:45:15Z",
            "published": "2023-10-31T19:45:15Z",
            "summary": "Llama 2-Chat is a collection of large language models that Meta developed and\nreleased to the public. While Meta fine-tuned Llama 2-Chat to refuse to output\nharmful content, we hypothesize that public access to model weights enables bad\nactors to cheaply circumvent Llama 2-Chat's safeguards and weaponize Llama 2's\ncapabilities for malicious purposes. We demonstrate that it is possible to\neffectively undo the safety fine-tuning from Llama 2-Chat 13B with less than\n$200, while retaining its general capabilities. Our results demonstrate that\nsafety-fine tuning is ineffective at preventing misuse when model weights are\nreleased publicly. Given that future models will likely have much greater\nability to cause harm at scale, it is essential that AI developers address\nthreats from fine-tuning when considering whether to publicly release their\nmodel weights.",
            "author": [
                "Pranav Gade",
                "Simon Lermen",
                "Charlie Rogers-Smith",
                "Jeffrey Ladish"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00117v1",
                "http://arxiv.org/pdf/2311.00117v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00116v1",
            "title": "BERTwich: Extending BERT's Capabilities to Model Dialectal and Noisy\n  Text",
            "updated": "2023-10-31T19:44:50Z",
            "published": "2023-10-31T19:44:50Z",
            "summary": "Real-world NLP applications often deal with nonstandard text (e.g.,\ndialectal, informal, or misspelled text). However, language models like BERT\ndeteriorate in the face of dialect variation or noise. How do we push BERT's\nmodeling capabilities to encompass nonstandard text? Fine-tuning helps, but it\nis designed for specializing a model to a task and does not seem to bring about\nthe deeper, more pervasive changes needed to adapt a model to nonstandard\nlanguage. In this paper, we introduce the novel idea of sandwiching BERT's\nencoder stack between additional encoder layers trained to perform masked\nlanguage modeling on noisy text. We find that our approach, paired with recent\nwork on including character-level noise in fine-tuning data, can promote\nzero-shot transfer to dialectal text, as well as reduce the distance in the\nembedding space between words and their noisy counterparts.",
            "author": [
                "Aarohi Srivastava",
                "David Chiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00116v1",
                "http://arxiv.org/pdf/2311.00116v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00115v1",
            "title": "EXTRACT: Explainable Transparent Control of Bias in Embeddings",
            "updated": "2023-10-31T19:44:32Z",
            "published": "2023-10-31T19:44:32Z",
            "summary": "Knowledge Graphs are a widely used method to represent relations between\nentities in various AI applications, and Graph Embedding has rapidly become a\nstandard technique to represent Knowledge Graphs in such a way as to facilitate\ninferences and decisions. As this representation is obtained from behavioural\ndata, and is not in a form readable by humans, there is a concern that it might\nincorporate unintended information that could lead to biases. We propose\nEXTRACT: a suite of Explainable and Transparent methods to ConTrol bias in\nknowledge graph embeddings, so as to assess and decrease the implicit presence\nof protected information. Our method uses Canonical Correlation Analysis (CCA)\nto investigate the presence, extent and origins of information leaks during\ntraining, then decomposes embeddings into a sum of their private attributes by\nsolving a linear system. Our experiments, performed on the MovieLens1M dataset,\nshow that a range of personal attributes can be inferred from a user's viewing\nbehaviour and preferences, including gender, age, and occupation. Further\nexperiments, performed on the KG20C citation dataset, show that the information\nabout the conference in which a paper was published can be inferred from the\ncitation network of that article. We propose four transparent methods to\nmaintain the capability of the embedding to make the intended predictions\nwithout retaining unwanted information. A trade-off between these two goals is\nobserved.",
            "author": [
                "Zhijin Guo",
                "Zhaozhen Xu",
                "Martha Lewis",
                "Nello Cristianini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00115v1",
                "http://arxiv.org/pdf/2311.00115v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00112v1",
            "title": "Hierarchical Optimization-based Control for Whole-body Loco-manipulation\n  of Heavy Objects",
            "updated": "2023-10-31T19:39:44Z",
            "published": "2023-10-31T19:39:44Z",
            "summary": "In recent years, the field of legged robotics has seen growing interest in\nenhancing the capabilities of these robots through the integration of\narticulated robotic arms. However, achieving successful loco-manipulation,\nespecially involving interaction with heavy objects, is far from\nstraightforward, as object manipulation can introduce substantial disturbances\nthat impact the robot's locomotion. This paper presents a novel framework for\nlegged loco-manipulation that considers whole-body coordination through a\nhierarchical optimization-based control framework. First, an online\nmanipulation planner computes the manipulation forces and manipulated object\ntask-based reference trajectory. Then, pose optimization aligns the robot's\ntrajectory with kinematic constraints. The resultant robot reference trajectory\nis executed via a linear MPC controller incorporating the desired manipulation\nforces into its prediction model. Our approach has been validated in simulation\nand hardware experiments, highlighting the necessity of whole-body optimization\ncompared to the baseline locomotion MPC when interacting with heavy objects.\nExperimental results with Unitree Aliengo, equipped with a custom-made robotic\narm, showcase its ability to successfully lift and carry an 8kg payload and\nmanipulate doors.",
            "author": [
                "Alberto Rigo",
                "Muqun Hu",
                "Satyandra K. Gupta",
                "Quan Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00112v1",
                "http://arxiv.org/pdf/2311.00112v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00108v1",
            "title": "Stellar spectral-type (mass) dependence of the dearth of close-in\n  planets around fast-rotating stars. Architecture of Kepler confirmed\n  single-exoplanet systems compared to star-planet evolution models",
            "updated": "2023-10-31T19:34:56Z",
            "published": "2023-10-31T19:34:56Z",
            "summary": "In 2013 a dearth of close-in planets around fast-rotating host stars was\nfound using statistical tests on Kepler data. The addition of more Kepler and\nTransiting Exoplanet Survey Satellite (TESS) systems in 2022 filled this region\nof the diagram of stellar rotation period (Prot) versus the planet orbital\nperiod (Porb). We revisited the Prot extraction of Kepler planet-host stars, we\nclassify the stars by their spectral type, and we studied their Prot-Porb\nrelations. We only used confirmed exoplanet systems to minimize biases. In\norder to learn about the physical processes at work, we used the star-planet\nevolution code ESPEM (French acronym for Evolution of Planetary Systems and\nMagnetism) to compute a realistic population synthesis of exoplanet systems and\ncompared them with observations. Because ESPEM works with a single planet\norbiting around a single main-sequence star, we limit our study to this\npopulation of Kepler observed systems filtering out binaries, evolved stars,\nand multi-planets. We find in both, observations and simulations, the existence\nof a dearth in close-in planets orbiting around fast-rotating stars, with a\ndependence on the stellar spectral type (F, G, and K), which is a proxy of the\nmass in our sample of stars. There is a change in the edge of the dearth as a\nfunction of the spectral type (and mass). It moves towards shorter Prot as\ntemperature (and mass) increases, making the dearth look smaller. Realistic\nformation hypotheses included in the model and the proper treatment of tidal\nand magnetic migration are enough to qualitatively explain the dearth of hot\nplanets around fast-rotating stars and the uncovered trend with spectral type.",
            "author": [
                "R. A. Garc\u00eda",
                "C. Gourv\u00e8s",
                "A. R. G. Santos",
                "A. Strugarek",
                "D. Godoy-Rivera",
                "S. Mathur",
                "V. Delsanti",
                "S. N. Breton",
                "P. G. Beck",
                "A. S. Brun",
                "S. Mathis"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202346933",
                "http://arxiv.org/abs/2311.00108v1",
                "http://arxiv.org/pdf/2311.00108v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00103v2",
            "title": "Topological quantum computation assisted by phase transitions",
            "updated": "2023-11-02T20:10:31Z",
            "published": "2023-10-31T19:28:42Z",
            "summary": "In this paper, we explore topological quantum computation augmented by\nsubphases and phase transitions. We commence by investigating the anyon\ntunneling map, denoted as $\\varphi$, between subphases of the quantum double\nmodel $\\mathcal{D}(G)$ for any arbitrary finite group $G$. Subsequently, we\ndelve into the relationship between $\\varphi$ and the Floquet code, and extend\nthe Abelian Floquet code to encompass non-abelian cases. We conclude by\ndemonstrating how phase transitions in both the temporal and spatial directions\ncan enhance the diversity of topological gates for general topological orders\ndescribed by modular tensor categories.",
            "author": [
                "Yuanjie Ren",
                "Peter Shor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00103v2",
                "http://arxiv.org/pdf/2311.00103v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00101v1",
            "title": "Overcoming membrane locking in quadratic NURBS-based discretizations of\n  linear Kirchhoff-Love shells: CAS elements",
            "updated": "2023-10-31T19:26:05Z",
            "published": "2023-10-31T19:26:05Z",
            "summary": "Quadratic NURBS-based discretizations of the Galerkin method suffer from\nmembrane locking when applied to Kirchhoff-Love shell formulations. Membrane\nlocking causes not only smaller displacements than expected, but also\nlarge-amplitude spurious oscillations of the membrane forces.\nContinuous-assumed-strain (CAS) elements have been recently introduced to\nremove membrane locking in quadratic NURBS-based discretizations of linear\nplane curved Kirchhoff rods (Casquero et al., CMAME, 2022). In this work, we\ngeneralize CAS elements to vanquish membrane locking in quadratic NURBS-based\ndiscretizations of linear Kirchhoff-Love shells. CAS elements bilinearly\ninterpolate the membrane strains at the four corners of each element. Thus, the\nassumed strains have C0 continuity across element boundaries. To the best of\nthe authors' knowledge, CAS elements are the first assumed-strain treatment to\neffectively overcome membrane locking in quadratic NURBS-based discretizations\nof Kirchhoff-Love shells while satisfying the following important\ncharacteristics for computational efficiency: (1) No additional degrees of\nfreedom are added, (2) No additional systems of algebraic equations need to be\nsolved, (3) No matrix multiplications or matrix inversions are needed to obtain\nthe stiffness matrix, and (4) The nonzero pattern of the stiffness matrix is\npreserved. The benchmark problems show that CAS elements, using either 2x2 or\n3x3 Gauss-Legendre quadrature points per element, are an effective locking\ntreatment since this element type results in more accurate displacements for\ncoarse meshes and excises the spurious oscillations of the membrane forces. The\nbenchmark problems also show that CAS elements outperform state-of-the-art\nelement types based on Lagrange polynomials equipped with either assumed-strain\nor reduced-integration locking treatments.",
            "author": [
                "Hugo Casquero",
                "Kyle Dakota Mathews"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.cma.2023.116523",
                "http://arxiv.org/abs/2311.00101v1",
                "http://arxiv.org/pdf/2311.00101v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00097v1",
            "title": "Cocoon: Static Information Flow Control in Rust",
            "updated": "2023-10-31T19:21:31Z",
            "published": "2023-10-31T19:21:31Z",
            "summary": "Information flow control (IFC) ensures confidentiality by preventing secret\nvalues from affecting non-secret values. Existing language-level IFC approaches\nmodify the language and use non-standard compilation tools, impose run-time\noverhead, or report false leaks, all of which hinder adoption. This paper\npresents Cocoon, a Rust library for static type-based IFC that uses the\nunmodified Rust language and compiler. The key insight of Cocoon lies in\nleveraging Rust's type system and procedural macros to establish an effect\nsystem that allows applications to safely compute arbitrary functions on secret\ndata. We integrated Cocoon into two popular Rust programs, the Spotify TUI\nclient and Mozilla's Servo browser engine, to protect a secret value in each\nprogram. The results show that applications can be retrofitted to use Cocoon\nwith limited modifications, at least to protect a single value, with negligible\nor nonexistent impacts on run-time and compile-time performance.",
            "author": [
                "Ada Barach",
                "Maxwell Taylor",
                "Vincent Beardsley",
                "Jacob Bambeck",
                "Michael D. Bond",
                "Zhiqiang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00097v1",
                "http://arxiv.org/pdf/2311.00097v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00096v1",
            "title": "Bandit-Driven Batch Selection for Robust Learning under Label Noise",
            "updated": "2023-10-31T19:19:01Z",
            "published": "2023-10-31T19:19:01Z",
            "summary": "We introduce a novel approach for batch selection in Stochastic Gradient\nDescent (SGD) training, leveraging combinatorial bandit algorithms. Our\nmethodology focuses on optimizing the learning process in the presence of label\nnoise, a prevalent issue in real-world datasets. Experimental evaluations on\nthe CIFAR-10 dataset reveal that our approach consistently outperforms existing\nmethods across various levels of label corruption. Importantly, we achieve this\nsuperior performance without incurring the computational overhead commonly\nassociated with auxiliary neural network models. This work presents a balanced\ntrade-off between computational efficiency and model efficacy, offering a\nscalable solution for complex machine learning applications.",
            "author": [
                "Michal Lisicki",
                "Mihai Nica",
                "Graham W. Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00096v1",
                "http://arxiv.org/pdf/2311.00096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00086v2",
            "title": "The Larmor frequency shift of a white matter magnetic microstructure\n  model with multiple sources",
            "updated": "2023-11-15T10:58:13Z",
            "published": "2023-10-31T18:53:20Z",
            "summary": "Magnetic susceptibility imaging may provide valuable information about\nchemical composition and microstructural organization of tissue. However, its\nestimation from the MRI signal phase is particularly difficult as it is\nsensitive to magnetic tissue properties ranging from the molecular to\nmacroscopic scale. The MRI Larmor frequency shift measured in white matter (WM)\ntissue depends on the myelinated axons and other magnetizable sources such as\niron-filled ferritin. We have previously derived the Larmor frequency shift\narising from a dense media of cylinders with scalar susceptibility and\narbitrary orientation dispersion. Here we extend our model to include\nmicroscopic WM susceptibility anisotropy as well as spherical inclusions with\nscalar susceptibility to represent subcellular structures, biologically stored\niron etc. We validate our analytical results with computer simulations and\ninvestigate the feasibility of estimating susceptibility using simple iterative\nlinear least squares without regularization or preconditioning. This is done in\na digital brain phantom synthesized from diffusion MRI (dMRI) measurements of\nan ex vivo mouse brain at ultra-high field.",
            "author": [
                "Anders Dyhr Sandgaard",
                "Noam Shemesh",
                "Leif \u00d8stergaard",
                "Valerij G. Kiselev",
                "Sune N\u00f8rh\u00f8j Jespersen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00086v2",
                "http://arxiv.org/pdf/2311.00086v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00084v1",
            "title": "NoMoPy: Noise Modeling in Python",
            "updated": "2023-10-31T18:52:05Z",
            "published": "2023-10-31T18:52:05Z",
            "summary": "NoMoPy is a code for fitting, analyzing, and generating noise modeled as a\nhidden Markov model (HMM) or, more generally, factorial hidden Markov model\n(FHMM). This code, written in Python, implements approximate and exact\nexpectation maximization (EM) algorithms for performing the parameter\nestimation process, model selection procedures via cross-validation, and\nparameter confidence region estimation. Here, we describe in detail the\nfunctionality implemented in NoMoPy and provide examples of its use and\nperformance on example problems.",
            "author": [
                "Dylan Albrecht",
                "N. Tobias Jacobson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00084v1",
                "http://arxiv.org/pdf/2311.00084v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "cs.CE",
                "cs.MS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00081v2",
            "title": "Convolution Quadrature for the quasilinear subdiffusion equation",
            "updated": "2023-11-08T09:18:12Z",
            "published": "2023-10-31T18:44:18Z",
            "summary": "We construct a Convolution Quadrature (CQ) scheme for the quasilinear\nsubdiffusion equation and supply it with the fast and oblivious implementation.\nIn particular we find a condition for the CQ to be admissible and discretize\nthe spatial part of the equation with the Finite Element Method. We prove the\nunconditional stability and convergence of the scheme and find a bound on the\nerror. As a passing result, we also obtain a discrete Gronwall inequality for\nthe CQ, which is a crucial ingredient of our convergence proof based on the\nenergy method. The paper is concluded with numerical examples verifying\nconvergence and computation time reduction when using fast and oblivious\nquadrature.",
            "author": [
                "Maria L\u00f3pez-Fern\u00e1ndez",
                "\u0141ukasz P\u0142ociniczak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00081v2",
                "http://arxiv.org/pdf/2311.00081v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00079v1",
            "title": "Spuriosity Rankings for Free: A Simple Framework for Last Layer\n  Retraining Based on Object Detection",
            "updated": "2023-10-31T18:44:03Z",
            "published": "2023-10-31T18:44:03Z",
            "summary": "Deep neural networks have exhibited remarkable performance in various\ndomains. However, the reliance of these models on spurious features has raised\nconcerns about their reliability. A promising solution to this problem is\nlast-layer retraining, which involves retraining the linear classifier head on\na small subset of data without spurious cues. Nevertheless, selecting this\nsubset requires human supervision, which reduces its scalability. Moreover,\nspurious cues may still exist in the selected subset. As a solution to this\nproblem, we propose a novel ranking framework that leverages an open vocabulary\nobject detection technique to identify images without spurious cues. More\nspecifically, we use the object detector as a measure to score the presence of\nthe target object in the images. Next, the images are sorted based on this\nscore, and the last-layer of the model is retrained on a subset of the data\nwith the highest scores. Our experiments on the ImageNet-1k dataset demonstrate\nthe effectiveness of this ranking framework in sorting images based on\nspuriousness and using them for last-layer retraining.",
            "author": [
                "Mohammad Azizmalayeri",
                "Reza Abbasi",
                "Amir Hosein Haji Mohammad rezaie",
                "Reihaneh Zohrabi",
                "Mahdi Amiri",
                "Mohammad Taghi Manzuri",
                "Mohammad Hossein Rohban"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00079v1",
                "http://arxiv.org/pdf/2311.00079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00076v1",
            "title": "Chemical evolution models: the role of type Ia supernovae in the\n  $\u03b1$-elements over Iron relative abundances and their variations in time\n  and space",
            "updated": "2023-10-31T18:41:11Z",
            "published": "2023-10-31T18:41:11Z",
            "summary": "The role of type Ia supernovae, mainly the Delay Time Distributions (DTDs)\ndetermined by the binary systems, and the yields of elements created by\ndifferent explosion mechanisms, are studied by using the {\\sc MulChem} chemical\nevolution model, applied to our Galaxy. We explored 15 DTDs, and 12 tables of\nelemental yields produced by different SN Ia explosion mechanisms, doing a\ntotal of 180 models. Chemical abundances for $\\alpha$-elements (O, Mg, Si, S,\nCa) and Fe derived from these models, are compared with recent observational\ndata of $\\alpha$-elements over Iron relative abundances, [X/Fe]. These data\nhave been compiled and binned in 13 datasets. By using a $\\chi^2$-technique, no\nmodel is able to fit simultaneously these datasets. A model computed with the\n13 individual best models is good enough to reproduce them. Thus, a power law\nwith a logarithmic slope $\\sim -1.1$ and a delay in the range $\\Delta \\tau=40\n--350$ Myr is a possible DTD, but a combination of several channels is more\nprobable. Results of this average model for other disc regions show a high\ndispersion, as observed, which might be explained by the stellar migration. The\ndispersion might also come from a combination of DTDs or of explosion channels.\nThe stellar migration joined to a combination of scenarios for SNIa is the\nprobable cause of the observed dispersion.",
            "author": [
                "M. Moll\u00e1",
                "O. Cavichia",
                "J. J. Baz\u00e1n",
                "A. Castrillo",
                "L. Galbany",
                "I. Mill\u00e1n-Irigoyen",
                "Y. Ascasibar. A. I D\u00edaz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00076v1",
                "http://arxiv.org/pdf/2311.00076v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00073v1",
            "title": "YOLOv8-Based Visual Detection of Road Hazards: Potholes, Sewer Covers,\n  and Manholes",
            "updated": "2023-10-31T18:33:26Z",
            "published": "2023-10-31T18:33:26Z",
            "summary": "Effective detection of road hazards plays a pivotal role in road\ninfrastructure maintenance and ensuring road safety. This research paper\nprovides a comprehensive evaluation of YOLOv8, an object detection model, in\nthe context of detecting road hazards such as potholes, Sewer Covers, and Man\nHoles. A comparative analysis with previous iterations, YOLOv5 and YOLOv7, is\nconducted, emphasizing the importance of computational efficiency in various\napplications. The paper delves into the architecture of YOLOv8 and explores\nimage preprocessing techniques aimed at enhancing detection accuracy across\ndiverse conditions, including variations in lighting, road types, hazard sizes,\nand types. Furthermore, hyperparameter tuning experiments are performed to\noptimize model performance through adjustments in learning rates, batch sizes,\nanchor box sizes, and augmentation strategies. Model evaluation is based on\nMean Average Precision (mAP), a widely accepted metric for object detection\nperformance. The research assesses the robustness and generalization\ncapabilities of the models through mAP scores calculated across the diverse\ntest scenarios, underlining the significance of YOLOv8 in road hazard detection\nand infrastructure maintenance.",
            "author": [
                "Om M. Khare",
                "Shubham Gandhi",
                "Aditya M. Rahalkar",
                "Sunil Mane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00073v1",
                "http://arxiv.org/pdf/2311.00073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14677v1",
            "title": "Filter bubbles and affective polarization in user-personalized large\n  language model outputs",
            "updated": "2023-10-31T18:19:28Z",
            "published": "2023-10-31T18:19:28Z",
            "summary": "Echoing the history of search engines and social media content rankings, the\nadvent of large language models (LLMs) has led to a push for increased\npersonalization of model outputs to individual users. In the past, personalized\nrecommendations and ranking systems have been linked to the development of\nfilter bubbles (serving content that may confirm a user's existing biases) and\naffective polarization (strong negative sentiment towards those with differing\nviews). In this work, we explore how prompting a leading large language model,\nChatGPT-3.5, with a user's political affiliation prior to asking factual\nquestions about public figures and organizations leads to differing results. We\nobserve that left-leaning users tend to receive more positive statements about\nleft-leaning political figures and media outlets, while right-leaning users see\nmore positive statements about right-leaning entities. This pattern holds\nacross presidential candidates, members of the U.S. Senate, and media\norganizations with ratings from AllSides. When qualitatively evaluating some of\nthese outputs, there is evidence that particular facts are included or excluded\nbased on the user's political affiliation. These results illustrate that\npersonalizing LLMs based on user demographics carry the same risks of affective\npolarization and filter bubbles that have been seen in other personalized\ninternet technologies. This ``failure mode\" should be monitored closely as\nthere are more attempts to monetize and personalize these models.",
            "author": [
                "Tomo Lazovich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14677v1",
                "http://arxiv.org/pdf/2311.14677v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00068v1",
            "title": "View Classification and Object Detection in Cardiac Ultrasound to\n  Localize Valves via Deep Learning",
            "updated": "2023-10-31T18:16:02Z",
            "published": "2023-10-31T18:16:02Z",
            "summary": "Echocardiography provides an important tool for clinicians to observe the\nfunction of the heart in real time, at low cost, and without harmful radiation.\nAutomated localization and classification of heart valves enables automatic\nextraction of quantities associated with heart mechanical function and related\nblood flow measurements. We propose a machine learning pipeline that uses deep\nneural networks for separate classification and localization steps. As the\nfirst step in the pipeline, we apply view classification to echocardiograms\nwith ten unique anatomic views of the heart. In the second step, we apply deep\nlearning-based object detection to both localize and identify the valves. Image\nsegmentation based object detection in echocardiography has been shown in many\nearlier studies but, to the best of our knowledge, this is the first study that\npredicts the bounding boxes around the valves along with classification from 2D\nultrasound images with the help of deep neural networks. Our object detection\nexperiments applied to the Apical views suggest that it is possible to localize\nand identify multiple valves precisely.",
            "author": [
                "Derya Gol Gungor",
                "Bimba Rao",
                "Cynthia Wolverton",
                "Ismayil Guracar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00068v1",
                "http://arxiv.org/pdf/2311.00068v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00065v1",
            "title": "Escape from a potential well under forcing and dissipation with\n  applications to ship capsize",
            "updated": "2023-10-31T18:10:55Z",
            "published": "2023-10-31T18:10:55Z",
            "summary": "Escape from a potential well occurs in a wide variety of physical systems\nfrom chemical reactions to ship capsize. In these situations escape often\noccurs by passage over a normally hyperbolic submanifold (NHS). This paper\ndescribes the computational implementation of an algorithm to identify the NHS\nof a two degree of freedom model for ship motion under the influence of damping\nand aperiodic forcing. Additionally we demonstrate how the stable manifolds of\nthese submanifolds can be used to classify initial ship states as safe or\nunsafe.",
            "author": [
                "Alex McSweeney-Davis",
                "R. S. MacKay",
                "Shibabrat Naik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00065v1",
                "http://arxiv.org/pdf/2311.00065v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "math.CA",
                "34D10, 34D35, 34D05, 37D10, 37M21, 65L10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00060v2",
            "title": "Ensemble models outperform single model uncertainties and predictions\n  for operator-learning of hypersonic flows",
            "updated": "2023-11-03T13:43:28Z",
            "published": "2023-10-31T18:07:29Z",
            "summary": "High-fidelity computational simulations and physical experiments of\nhypersonic flows are resource intensive. Training scientific machine learning\n(SciML) models on limited high-fidelity data offers one approach to rapidly\npredict behaviors for situations that have not been seen before. However,\nhigh-fidelity data is itself in limited quantity to validate all outputs of the\nSciML model in unexplored input space. As such, an uncertainty-aware SciML\nmodel is desired. The SciML model's output uncertainties could then be used to\nassess the reliability and confidence of the model's predictions. In this\nstudy, we extend a DeepONet using three different uncertainty quantification\nmechanisms: mean-variance estimation, evidential uncertainty, and ensembling.\nThe uncertainty aware DeepONet models are trained and evaluated on the\nhypersonic flow around a blunt cone object with data generated via\ncomputational fluid dynamics over a wide range of Mach numbers and altitudes.\nWe find that ensembling outperforms the other two uncertainty models in terms\nof minimizing error and calibrating uncertainty in both interpolative and\nextrapolative regimes.",
            "author": [
                "Victor J. Leon",
                "Noah Ford",
                "Honest Mrema",
                "Jeffrey Gilbert",
                "Alexander New"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00060v2",
                "http://arxiv.org/pdf/2311.00060v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00059v1",
            "title": "The Generative AI Paradox: \"What It Can Create, It May Not Understand\"",
            "updated": "2023-10-31T18:07:07Z",
            "published": "2023-10-31T18:07:07Z",
            "summary": "The recent wave of generative AI has sparked unprecedented global attention,\nwith both excitement and concern over potentially superhuman levels of\nartificial intelligence: models now take only seconds to produce outputs that\nwould challenge or exceed the capabilities even of expert humans. At the same\ntime, models still show basic errors in understanding that would not be\nexpected even in non-expert humans. This presents us with an apparent paradox:\nhow do we reconcile seemingly superhuman capabilities with the persistence of\nerrors that few humans would make? In this work, we posit that this tension\nreflects a divergence in the configuration of intelligence in today's\ngenerative models relative to intelligence in humans. Specifically, we propose\nand test the Generative AI Paradox hypothesis: generative models, having been\ntrained directly to reproduce expert-like outputs, acquire generative\ncapabilities that are not contingent upon -- and can therefore exceed -- their\nability to understand those same types of outputs. This contrasts with humans,\nfor whom basic understanding almost always precedes the ability to generate\nexpert-level outputs. We test this hypothesis through controlled experiments\nanalyzing generation vs. understanding in generative models, across both\nlanguage and image modalities. Our results show that although models can\noutperform humans in generation, they consistently fall short of human\ncapabilities in measures of understanding, as well as weaker correlation\nbetween generation and understanding performance, and more brittleness to\nadversarial inputs. Our findings support the hypothesis that models' generative\ncapability may not be contingent upon understanding capability, and call for\ncaution in interpreting artificial intelligence by analogy to human\nintelligence.",
            "author": [
                "Peter West",
                "Ximing Lu",
                "Nouha Dziri",
                "Faeze Brahman",
                "Linjie Li",
                "Jena D. Hwang",
                "Liwei Jiang",
                "Jillian Fisher",
                "Abhilasha Ravichander",
                "Khyathi Chandu",
                "Benjamin Newman",
                "Pang Wei Koh",
                "Allyson Ettinger",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00059v1",
                "http://arxiv.org/pdf/2311.00059v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00058v1",
            "title": "Observing quantum measurement collapse as a learnability phase\n  transition",
            "updated": "2023-10-31T18:06:05Z",
            "published": "2023-10-31T18:06:05Z",
            "summary": "The mechanism by which an effective macroscopic description of quantum\nmeasurement in terms of discrete, probabilistic collapse events emerges from\nthe reversible microscopic dynamics remains an enduring open question. Emerging\nquantum computers offer a promising platform to explore how measurement\nprocesses evolve across a range of system sizes while retaining coherence.\nHere, we report the experimental observation of evidence for an\nobservable-sharpening measurement-induced phase transition in a chain of\ntrapped ions in Quantinuum H1-1 system model quantum processor. This transition\nmanifests as a sharp, concomitant change in both the quantum uncertainty of an\nobservable and the amount of information an observer can (in principle) learn\nfrom the measurement record, upon increasing the strength of measurements. We\nleverage insights from statistical mechanical models and machine learning to\ndesign efficiently-computable algorithms to observe this transition (without\nnon-scalable post-selection on measurement outcomes) and to mitigate the\neffects on errors in noisy hardware.",
            "author": [
                "Utkarsh Agrawal",
                "Javier Lopez-Piqueres",
                "Romain Vasseur",
                "Sarang Gopalakrishnan",
                "Andrew C. Potter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00058v1",
                "http://arxiv.org/pdf/2311.00058v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00056v1",
            "title": "Diversity and Diffusion: Observations on Synthetic Image Distributions\n  with Stable Diffusion",
            "updated": "2023-10-31T18:05:15Z",
            "published": "2023-10-31T18:05:15Z",
            "summary": "Recent progress in text-to-image (TTI) systems, such as StableDiffusion,\nImagen, and DALL-E 2, have made it possible to create realistic images with\nsimple text prompts. It is tempting to use these systems to eliminate the\nmanual task of obtaining natural images for training a new machine learning\nclassifier. However, in all of the experiments performed to date, classifiers\ntrained solely with synthetic images perform poorly at inference, despite the\nimages used for training appearing realistic. Examining this apparent\nincongruity in detail gives insight into the limitations of the underlying\nimage generation processes. Through the lens of diversity in image creation\nvs.accuracy of what is created, we dissect the differences in semantic\nmismatches in what is modeled in synthetic vs. natural images. This will\nelucidate the roles of the image-languag emodel, CLIP, and the image generation\nmodel, diffusion. We find four issues that limit the usefulness of TTI systems\nfor this task: ambiguity, adherence to prompt, lack of diversity, and inability\nto represent the underlying concept. We further present surprising insights\ninto the geometry of CLIP embeddings.",
            "author": [
                "David Marwood",
                "Shumeet Baluja",
                "Yair Alon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00056v1",
                "http://arxiv.org/pdf/2311.00056v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00049v1",
            "title": "On the Kolmogorov neural networks",
            "updated": "2023-10-31T18:01:58Z",
            "published": "2023-10-31T18:01:58Z",
            "summary": "In this paper, we show that the Kolmogorov two hidden layer neural network\nmodel with a continuous, discontinuous bounded or unbounded activation function\nin the second hidden layer can precisely represent continuous, discontinuous\nbounded and all unbounded multivariate functions, respectively.",
            "author": [
                "Aysu Ismayilova",
                "Vugar Ismailov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00049v1",
                "http://arxiv.org/pdf/2311.00049v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "math.FA",
                "stat.ML",
                "46A22, 46E10, 46N60, 68T05, 92B20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00048v1",
            "title": "SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image\n  Classification",
            "updated": "2023-10-31T18:01:41Z",
            "published": "2023-10-31T18:01:41Z",
            "summary": "Multiple Instance Learning (MIL) has been widely used in weakly supervised\nwhole slide image (WSI) classification. Typical MIL methods include a feature\nembedding part that embeds the instances into features via a pre-trained\nfeature extractor and the MIL aggregator that combines instance embeddings into\npredictions. The current focus has been directed toward improving these parts\nby refining the feature embeddings through self-supervised pre-training and\nmodeling the correlations between instances separately. In this paper, we\nproposed a sparsely coded MIL (SC-MIL) that addresses those two aspects at the\nsame time by leveraging sparse dictionary learning. The sparse dictionary\nlearning captures the similarities of instances by expressing them as a sparse\nlinear combination of atoms in an over-complete dictionary. In addition,\nimposing sparsity help enhance the instance feature embeddings by suppressing\nirrelevant instances while retaining the most relevant ones. To make the\nconventional sparse coding algorithm compatible with deep learning, we unrolled\nit into an SC module by leveraging deep unrolling. The proposed SC module can\nbe incorporated into any existing MIL framework in a plug-and-play manner with\nan acceptable computation cost. The experimental results on multiple datasets\ndemonstrated that the proposed SC module could substantially boost the\nperformance of state-of-the-art MIL methods. The codes are available at\n\\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.",
            "author": [
                "Peijie Qiu",
                "Pan Xiao",
                "Wenhui Zhu",
                "Yalin Wang",
                "Aristeidis Sotiras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00048v1",
                "http://arxiv.org/pdf/2311.00048v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00047v1",
            "title": "Grounding Visual Illusions in Language: Do Vision-Language Models\n  Perceive Illusions Like Humans?",
            "updated": "2023-10-31T18:01:11Z",
            "published": "2023-10-31T18:01:11Z",
            "summary": "Vision-Language Models (VLMs) are trained on vast amounts of data captured by\nhumans emulating our understanding of the world. However, known as visual\nillusions, human's perception of reality isn't always faithful to the physical\nworld. This raises a key question: do VLMs have the similar kind of illusions\nas humans do, or do they faithfully learn to represent reality? To investigate\nthis question, we build a dataset containing five types of visual illusions and\nformulate four tasks to examine visual illusions in state-of-the-art VLMs. Our\nfindings have shown that although the overall alignment is low, larger models\nare closer to human perception and more susceptible to visual illusions. Our\ndataset and initial findings will promote a better understanding of visual\nillusions in humans and machines and provide a stepping stone for future\ncomputational models that can better align humans and machines in perceiving\nand communicating about the shared visual world. The code and data are\navailable at https://github.com/vl-illusion/dataset.",
            "author": [
                "Yichi Zhang",
                "Jiayi Pan",
                "Yuchen Zhou",
                "Rui Pan",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00047v1",
                "http://arxiv.org/pdf/2311.00047v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00043v1",
            "title": "Baryonic dark forces in electron-beam fixed-target experiments",
            "updated": "2023-10-31T18:00:10Z",
            "published": "2023-10-31T18:00:10Z",
            "summary": "New GeV-scale dark forces coupling predominantly to quarks offer novel\nsignatures that can be produced directly and searched for at high-luminosity\ncolliders. We compute the photon-proton and electron-proton cross sections for\nproducing a GeV-scale gauge boson arising from a $U(1)_B$ gauge symmetry. Our\ncalculation relies on vector meson dominance and a phenomenological model for\ndiffractive scattering used for vector-meson photoproduction. The parameters of\nour phenomenological model are fixed by performing a Markov Chain Monte Carlo\nfit to existing exclusive photoproduction data for $\\omega$ and $\\phi$ mesons.\nOur approach can be generalized other GeV-scale dark gauge forces.",
            "author": [
                "Safa Ben Othman",
                "Armita Jalooli",
                "Sean Tulin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00043v1",
                "http://arxiv.org/pdf/2311.00043v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00042v2",
            "title": "A Novel Method for Holographic Transport",
            "updated": "2023-11-24T09:00:02Z",
            "published": "2023-10-31T18:00:08Z",
            "summary": "We introduce a novel and effective method to compute transport coefficients\nin strongly interacting plasma states in holographic QFTs. Our method is based\non relating the IR limit of fluctuations on a gravitational background to its\nvariations providing a previously overlooked connection between boundary and\nnear horizon data. We use this method to derive analytic formulas for the\nviscosities of an ansiotropic plasma state in the presence of an external\nmagnetic field or another isotropy breaking external source. We then apply our\nfindings to holographic QCD.",
            "author": [
                "Tuna Demircik",
                "Domingo Gallegos",
                "Umut G\u00fcrsoy",
                "Matti J\u00e4rvinen",
                "Ruben Lier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00042v2",
                "http://arxiv.org/pdf/2311.00042v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00036v1",
            "title": "Wavelet Based Statistics for Enhanced 21cm EoR Parameter Constraints",
            "updated": "2023-10-31T18:00:03Z",
            "published": "2023-10-31T18:00:03Z",
            "summary": "We propose a new approach to improve the precision of astrophysical parameter\nconstraints for the 21cm signal from Epoch of Reionization (EoR). Our method\nintroduces new sets of summary statistics, hereafter evolution compressed\nstatistics, that quantify the spectral evolution of the 2D spatial statistics\ncomputed a fixed redshift. We defined such compressed statistics for Power\nSpectrum (PS), as well as Reduced Wavelet Scattering Transform (RWST) and\nWavelet Moments (WM), which also characterise non-Gaussian features. To compare\nthese different statistics with fiducial 3D power spectrum, we estimate their\nFisher information on three cosmological parameters from an ensemble of\nsimulations of 21cm EoR data, both in noiseless and noisy scenarios using\nSquare Kilometre Array (SKA) noise levels equivalent to 100 and 1000 hours of\nobservations. For the noiseless case, the compressed wavelet statistics give\nconstraints up to five times higher precision than the 3D isotropic power\nspectrum, while for 100h SKA noise, for which non-Gaussian features are hard to\nextract, they still give constraints which are 30% better. From this study, we\ndemonstrate that evolution-compressed statistics extract more information than\nusual 3D isotropic approaches and that our wavelet-based statistics can\nconsistently outmatch power spectrum-based statistics. When constructing such\nwavelet-based statistics, we also emphasise the need to choose a set of\nwavelets with an appropriate spectral resolution concerning the astrophysical\nprocess studied.",
            "author": [
                "Ian Hothi",
                "Erwan Allys",
                "Benoit Semelin",
                "Francois Boulanger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00036v1",
                "http://arxiv.org/pdf/2311.00036v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00034v1",
            "title": "Magnetorotational dynamo can generate large-scale vertical magnetic\n  fields in 3D GRMHD simulations of accreting black holes",
            "updated": "2023-10-31T18:00:02Z",
            "published": "2023-10-31T18:00:02Z",
            "summary": "Jetted astrophysical phenomena with black hole (BH) engines, including binary\nmergers, jetted tidal disruption events, and X-ray binaries, require a\nlarge-scale vertical magnetic field for efficient jet formation. However, a\ndynamo mechanism that could generate these crucial large-scale magnetic fields\nhas not been identified and characterized. We have employed 3D global general\nrelativistic magnetohydrodynamical (MHD) simulations of accretion disks to\nquantify, for the first time, a dynamo mechanism that generates large-scale\nmagnetic fields. This dynamo mechanism primarily arises from the nonlinear\nevolution of the magnetorotational instability (MRI). In this mechanism, large\nnon-axisymmetric MRI-amplified shearing wave modes, mediated by the\naxisymmetric azimuthal magnetic field, generate and sustain the large-scale\nvertical magnetic field through their nonlinear interactions. We identify the\nadvection of magnetic loops as a crucial feature, transporting the large-scale\nvertical magnetic field from the outer regions to the inner regions of the\naccretion disk. This leads to a larger characteristic size of the, now\nadvected, magnetic field when compared to the local disk height. We\ncharacterize the complete dynamo mechanism with two timescales: one for the\nlocal magnetic field generation, $t_{\\rm g}$, and one for the large-scale scale\nadvection, $t_{\\rm adv}$. Whereas the dynamo we describe is nonlinear, we\nexplore the potential of linear mean field models to replicate its core\nfeatures. Our findings indicate that traditional $\\alpha$-dynamo models, often\ncomputed in stratified shearing box simulations, are inadequate and that the\neffective large-scale dynamics is better described by the shear current effects\nor stochastic $\\alpha$-dynamos.",
            "author": [
                "Jonatan Jacquemin-Ide",
                "Fran\u00e7ois Rincon",
                "Alexander Tchekhovskoy",
                "Matthew Liska"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00034v1",
                "http://arxiv.org/pdf/2311.00034v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00019v1",
            "title": "Stable many-body localization under random continuous measurements in\n  the no-click limit",
            "updated": "2023-10-31T18:00:00Z",
            "published": "2023-10-31T18:00:00Z",
            "summary": "In this work, we investigate the localization properties of a paradigmatic\nmodel, coupled to a monitoring environment and possessing a many-body localized\n(MBL) phase. We focus on the post-selected no-click limit with quench random\nrates, i.e., random gains and losses. In this limit, the system is modeled by\nadding an imaginary random potential, rendering non-Hermiticity in the system.\nNumerically, we provide an evidence that the system is localized for any finite\namount of disorder. To analytically understand our results, we extend the\nquantum random energy model (QREM) to the non-Hermitian scenario. The Hermitian\nQREM has been used previously as a benchmark model for MBL. The QREM exhibits a\nsize-dependent MBL transition, where the critical value scales as $W_c\\sim\n\\sqrt{L} \\ln{L}$ with system size and presenting many-body mobility edges. We\nreveal that the non-Hermitian QREM with random gain-loss offers a significantly\nstronger form of localization, evident in the nature of the many-body mobility\nedges and the value for the transition, which scales as $W_c\\sim \\ln^{1/2}{L}$\nwith the system size.",
            "author": [
                "Giuseppe De Tomasi",
                "Ivan M. Khaymovich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00019v1",
                "http://arxiv.org/pdf/2311.00019v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.quant-gas",
                "cond-mat.stat-mech",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20710v1",
            "title": "FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance\n  Fields by Analyzing and Enhancing Fourier PlenOctrees",
            "updated": "2023-10-31T17:59:58Z",
            "published": "2023-10-31T17:59:58Z",
            "summary": "Fourier PlenOctrees have shown to be an efficient representation for\nreal-time rendering of dynamic Neural Radiance Fields (NeRF). Despite its many\nadvantages, this method suffers from artifacts introduced by the involved\ncompression when combining it with recent state-of-the-art techniques for\ntraining the static per-frame NeRF models. In this paper, we perform an\nin-depth analysis of these artifacts and leverage the resulting insights to\npropose an improved representation. In particular, we present a novel density\nencoding that adapts the Fourier-based compression to the characteristics of\nthe transfer function used by the underlying volume rendering procedure and\nleads to a substantial reduction of artifacts in the dynamic model.\nFurthermore, we show an augmentation of the training data that relaxes the\nperiodicity assumption of the compression. We demonstrate the effectiveness of\nour enhanced Fourier PlenOctrees in the scope of quantitative and qualitative\nevaluations on synthetic and real-world scenes.",
            "author": [
                "Saskia Rabich",
                "Patrick Stotko",
                "Reinhard Klein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20710v1",
                "http://arxiv.org/pdf/2310.20710v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20707v1",
            "title": "What's In My Big Data?",
            "updated": "2023-10-31T17:59:38Z",
            "published": "2023-10-31T17:59:38Z",
            "summary": "Large text corpora are the backbone of language models. However, we have a\nlimited understanding of the content of these corpora, including general\nstatistics, quality, social factors, and inclusion of evaluation data\n(contamination). In this work, we propose What's In My Big Data? (WIMBD), a\nplatform and a set of sixteen analyses that allow us to reveal and compare the\ncontents of large text corpora. WIMBD builds on two basic capabilities -- count\nand search -- at scale, which allows us to analyze more than 35 terabytes on a\nstandard compute node. We apply WIMBD to ten different corpora used to train\npopular language models, including C4, The Pile, and RedPajama. Our analysis\nuncovers several surprising and previously undocumented findings about these\ncorpora, including the high prevalence of duplicate, synthetic, and low-quality\ncontent, personally identifiable information, toxic language, and benchmark\ncontamination. For instance, we find that about 50% of the documents in\nRedPajama and LAION-2B-en are duplicates. In addition, several datasets used\nfor benchmarking models trained on such corpora are contaminated with respect\nto important benchmarks, including the Winograd Schema Challenge and parts of\nGLUE and SuperGLUE. We open-source WIMBD's code and artifacts to provide a\nstandard set of evaluations for new text-based corpora and to encourage more\nanalyses and transparency around them: github.com/allenai/wimbd.",
            "author": [
                "Yanai Elazar",
                "Akshita Bhagia",
                "Ian Magnusson",
                "Abhilasha Ravichander",
                "Dustin Schwenk",
                "Alane Suhr",
                "Pete Walsh",
                "Dirk Groeneveld",
                "Luca Soldaini",
                "Sameer Singh",
                "Hanna Hajishirzi",
                "Noah A. Smith",
                "Jesse Dodge"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20707v1",
                "http://arxiv.org/pdf/2310.20707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20706v1",
            "title": "DDAM-PS: Diligent Domain Adaptive Mixer for Person Search",
            "updated": "2023-10-31T17:59:14Z",
            "published": "2023-10-31T17:59:14Z",
            "summary": "Person search (PS) is a challenging computer vision problem where the\nobjective is to achieve joint optimization for pedestrian detection and\nre-identification (ReID). Although previous advancements have shown promising\nperformance in the field under fully and weakly supervised learning fashion,\nthere exists a major gap in investigating the domain adaptation ability of PS\nmodels. In this paper, we propose a diligent domain adaptive mixer (DDAM) for\nperson search (DDAP-PS) framework that aims to bridge a gap to improve\nknowledge transfer from the labeled source domain to the unlabeled target\ndomain. Specifically, we introduce a novel DDAM module that generates moderate\nmixed-domain representations by combining source and target domain\nrepresentations. The proposed DDAM module encourages domain mixing to minimize\nthe distance between the two extreme domains, thereby enhancing the ReID task.\nTo achieve this, we introduce two bridge losses and a disparity loss. The\nobjective of the two bridge losses is to guide the moderate mixed-domain\nrepresentations to maintain an appropriate distance from both the source and\ntarget domain representations. The disparity loss aims to prevent the moderate\nmixed-domain representations from being biased towards either the source or\ntarget domains, thereby avoiding overfitting. Furthermore, we address the\nconflict between the two subtasks, localization and ReID, during domain\nadaptation. To handle this cross-task conflict, we forcefully decouple the\nnorm-aware embedding, which aids in better learning of the moderate\nmixed-domain representation. We conduct experiments to validate the\neffectiveness of our proposed method. Our approach demonstrates favorable\nperformance on the challenging PRW and CUHK-SYSU datasets. Our source code is\npublicly available at \\url{https://github.com/mustansarfiaz/DDAM-PS}.",
            "author": [
                "Mohammed Khaleed Almansoori",
                "Mustansar Fiaz",
                "Hisham Cholakkal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20706v1",
                "http://arxiv.org/pdf/2310.20706v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20704v1",
            "title": "Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked\n  Autoencoders",
            "updated": "2023-10-31T17:59:07Z",
            "published": "2023-10-31T17:59:07Z",
            "summary": "Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite\ntheir success, ViTs lack inductive biases, which can make it difficult to train\nthem with limited data. To address this challenge, prior studies suggest\ntraining ViTs with self-supervised learning (SSL) and fine-tuning sequentially.\nHowever, we observe that jointly optimizing ViTs for the primary task and a\nSelf-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the\namount of training data is limited. We explore the appropriate SSL tasks that\ncan be optimized alongside the primary task, the training schemes for these\ntasks, and the data scale at which they can be most effective. Our findings\nreveal that SSAT is a powerful technique that enables ViTs to leverage the\nunique characteristics of both the self-supervised and primary tasks, achieving\nbetter performance than typical ViTs pre-training with SSL and fine-tuning\nsequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT\nsignificantly improves ViT performance while reducing carbon footprint. We also\nconfirm the effectiveness of SSAT in the video domain for deepfake detection,\nshowcasing its generalizability. Our code is available at\nhttps://github.com/dominickrei/Limited-data-vits.",
            "author": [
                "Srijan Das",
                "Tanmay Jain",
                "Dominick Reilly",
                "Pranav Balaji",
                "Soumyajit Karmakar",
                "Shyam Marjit",
                "Xiang Li",
                "Abhijit Das",
                "Michael Ryoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20704v1",
                "http://arxiv.org/pdf/2310.20704v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20703v1",
            "title": "Vanishing Gradients in Reinforcement Finetuning of Language Models",
            "updated": "2023-10-31T17:59:05Z",
            "published": "2023-10-31T17:59:05Z",
            "summary": "Pretrained language models are commonly aligned with human preferences and\ndownstream tasks via reinforcement finetuning (RFT), which entails maximizing a\n(possibly learned) reward function using policy gradient algorithms. This work\nhighlights a fundamental optimization obstacle in RFT: we prove that the\nexpected gradient for an input vanishes when its reward standard deviation\nunder the model is small, even if the expected reward is far from optimal.\nThrough experiments on an RFT benchmark and controlled environments, as well as\na theoretical analysis, we then demonstrate that vanishing gradients due to\nsmall reward standard deviation are prevalent and detrimental, leading to\nextremely slow reward maximization. Lastly, we explore ways to overcome\nvanishing gradients in RFT. We find the common practice of an initial\nsupervised finetuning (SFT) phase to be the most promising candidate, which\nsheds light on its importance in an RFT pipeline. Moreover, we show that a\nrelatively small number of SFT optimization steps on as few as 1% of the input\nsamples can suffice, indicating that the initial SFT phase need not be\nexpensive in terms of compute and data labeling efforts. Overall, our results\nemphasize that being mindful for inputs whose expected gradient vanishes, as\nmeasured by the reward standard deviation, is crucial for successful execution\nof RFT.",
            "author": [
                "Noam Razin",
                "Hattie Zhou",
                "Omid Saremi",
                "Vimal Thilak",
                "Arwen Bradley",
                "Preetum Nakkiran",
                "Joshua Susskind",
                "Etai Littwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20703v1",
                "http://arxiv.org/pdf/2310.20703v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20700v2",
            "title": "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and\n  Prediction",
            "updated": "2023-11-06T11:25:50Z",
            "published": "2023-10-31T17:58:17Z",
            "summary": "Recently video generation has achieved substantial progress with realistic\nresults. Nevertheless, existing AI-generated videos are usually very short\nclips (\"shot-level\") depicting a single scene. To deliver a coherent long video\n(\"story-level\"), it is desirable to have creative transition and prediction\neffects across different clips. This paper presents a short-to-long video\ndiffusion model, SEINE, that focuses on generative transition and prediction.\nThe goal is to generate high-quality long videos with smooth and creative\ntransitions between scenes and varying lengths of shot-level videos.\nSpecifically, we propose a random-mask video diffusion model to automatically\ngenerate transitions based on textual descriptions. By providing the images of\ndifferent scenes as inputs, combined with text-based control, our model\ngenerates transition videos that ensure coherence and visual quality.\nFurthermore, the model can be readily extended to various tasks such as\nimage-to-video animation and autoregressive video prediction. To conduct a\ncomprehensive evaluation of this new generative task, we propose three\nassessing criteria for smooth and creative transition: temporal consistency,\nsemantic similarity, and video-text semantic alignment. Extensive experiments\nvalidate the effectiveness of our approach over existing methods for generative\ntransition and prediction, enabling the creation of story-level long videos.\nProject page: https://vchitect.github.io/SEINE-project/ .",
            "author": [
                "Xinyuan Chen",
                "Yaohui Wang",
                "Lingjun Zhang",
                "Shaobin Zhuang",
                "Xin Ma",
                "Jiashuo Yu",
                "Yali Wang",
                "Dahua Lin",
                "Yu Qiao",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20700v2",
                "http://arxiv.org/pdf/2310.20700v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20699v2",
            "title": "Bayesian Multistate Bennett Acceptance Ratio Methods",
            "updated": "2023-11-01T03:03:46Z",
            "published": "2023-10-31T17:57:58Z",
            "summary": "The multistate Bennett acceptance ratio (MBAR) method is a prevalent approach\nfor computing free energies of thermodynamic states. In this work, we introduce\nBayesMBAR, a Bayesian generalization of the MBAR method. By integrating\nconfigurations sampled from thermodynamic states with a prior distribution,\nBayesMBAR computes a posterior distribution of free energies. Using the\nposterior distribution, we derive free energy estimations and compute their\nassociated uncertainties. Notably, when a uniform prior distribution is used,\nBayesMBAR recovers the MBAR's result but provides more accurate uncertainty\nestimates. Additionally, when prior knowledge about free energies is available,\nBayesMBAR can incorporate this information into the estimation procedure by\nusing non-uniform prior distributions. As an example, we show that, by\nincorporating the prior knowledge about the smoothness of free energy surfaces,\nBayesMBAR provides more accurate estimates than the MBAR method. Given MBAR's\nwidespread use in free energy calculations, we anticipate BayesMBAR to be an\nessential tool in various applications of free energy calculations.",
            "author": [
                "Xinqiang Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20699v2",
                "http://arxiv.org/pdf/2310.20699v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG",
                "physics.comp-ph",
                "physics.data-an",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20697v1",
            "title": "Text-Transport: Toward Learning Causal Effects of Natural Language",
            "updated": "2023-10-31T17:56:51Z",
            "published": "2023-10-31T17:56:51Z",
            "summary": "As language technologies gain prominence in real-world settings, it is\nimportant to understand how changes to language affect reader perceptions. This\ncan be formalized as the causal effect of varying a linguistic attribute (e.g.,\nsentiment) on a reader's response to the text. In this paper, we introduce\nText-Transport, a method for estimation of causal effects from natural language\nunder any text distribution. Current approaches for valid causal effect\nestimation require strong assumptions about the data, meaning the data from\nwhich one can estimate valid causal effects often is not representative of the\nactual target domain of interest. To address this issue, we leverage the notion\nof distribution shift to describe an estimator that transports causal effects\nbetween domains, bypassing the need for strong assumptions in the target\ndomain. We derive statistical guarantees on the uncertainty of this estimator,\nand we report empirical results and analyses that support the validity of\nText-Transport across data settings. Finally, we use Text-Transport to study a\nrealistic setting--hate speech on social media--in which causal effects do\nshift significantly between text domains, demonstrating the necessity of\ntransport when conducting causal inference on natural language.",
            "author": [
                "Victoria Lin",
                "Louis-Philippe Morency",
                "Eli Ben-Michael"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20697v1",
                "http://arxiv.org/pdf/2310.20697v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20695v1",
            "title": "HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception",
            "updated": "2023-10-31T17:56:11Z",
            "published": "2023-10-31T17:56:11Z",
            "summary": "Model pre-training is essential in human-centric perception. In this paper,\nwe first introduce masked image modeling (MIM) as a pre-training approach for\nthis task. Upon revisiting the MIM training strategy, we reveal that human\nstructure priors offer significant potential. Motivated by this insight, we\nfurther incorporate an intuitive human structure prior - human parts - into\npre-training. Specifically, we employ this prior to guide the mask sampling\nprocess. Image patches, corresponding to human part regions, have high priority\nto be masked out. This encourages the model to concentrate more on body\nstructure information during pre-training, yielding substantial benefits across\na range of human-centric perception tasks. To further capture human\ncharacteristics, we propose a structure-invariant alignment loss that enforces\ndifferent masked views, guided by the human part prior, to be closely aligned\nfor the same image. We term the entire method as HAP. HAP simply uses a plain\nViT as the encoder yet establishes new state-of-the-art performance on 11\nhuman-centric benchmarks, and on-par result on one dataset. For example, HAP\nachieves 78.1% mAP on MSMT17 for person re-identification, 86.54% mA on PA-100K\nfor pedestrian attribute recognition, 78.2% AP on MS COCO for 2D pose\nestimation, and 56.0 PA-MPJPE on 3DPW for 3D pose and shape estimation.",
            "author": [
                "Junkun Yuan",
                "Xinyu Zhang",
                "Hao Zhou",
                "Jian Wang",
                "Zhongwei Qiu",
                "Zhiyin Shao",
                "Shaofeng Zhang",
                "Sifan Long",
                "Kun Kuang",
                "Kun Yao",
                "Junyu Han",
                "Errui Ding",
                "Lanfen Lin",
                "Fei Wu",
                "Jingdong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20695v1",
                "http://arxiv.org/pdf/2310.20695v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20689v2",
            "title": "Learning From Mistakes Makes LLM Better Reasoner",
            "updated": "2023-11-14T02:37:55Z",
            "published": "2023-10-31T17:52:22Z",
            "summary": "Large language models (LLMs) recently exhibited remarkable reasoning\ncapabilities on solving math problems. To further improve this capability, this\nwork proposes Learning from Mistakes (LeMa), akin to human learning processes.\nConsider a human student who failed to solve a math problem, he will learn from\nwhat mistake he has made and how to correct it. Mimicking this error-driven\nlearning process, LeMa fine-tunes LLMs on mistake-correction data pairs\ngenerated by GPT-4. Specifically, we first collect inaccurate reasoning paths\nfrom various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the\nmistake step, (2) explain the reason for the mistake, and (3) correct the\nmistake and generate the final answer. Experimental results demonstrate the\neffectiveness of LeMa: across five backbone LLMs and two mathematical reasoning\ntasks, LeMa consistently improves the performance compared with fine-tuning on\nCoT data alone. Impressively, LeMa can also benefit specialized LLMs such as\nWizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on\nMATH. This surpasses the SOTA performance achieved by non-execution open-source\nmodels on these challenging tasks. Our code, data and models will be publicly\navailable at https://github.com/microsoft/LEMA.",
            "author": [
                "Shengnan An",
                "Zexiong Ma",
                "Zeqi Lin",
                "Nanning Zheng",
                "Jian-Guang Lou",
                "Weizhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20689v2",
                "http://arxiv.org/pdf/2310.20689v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20685v1",
            "title": "NeRF Revisited: Fixing Quadrature Instability in Volume Rendering",
            "updated": "2023-10-31T17:49:48Z",
            "published": "2023-10-31T17:49:48Z",
            "summary": "Neural radiance fields (NeRF) rely on volume rendering to synthesize novel\nviews. Volume rendering requires evaluating an integral along each ray, which\nis numerically approximated with a finite sum that corresponds to the exact\nintegral along the ray under piecewise constant volume density. As a\nconsequence, the rendered result is unstable w.r.t. the choice of samples along\nthe ray, a phenomenon that we dub quadrature instability. We propose a\nmathematically principled solution by reformulating the sample-based rendering\nequation so that it corresponds to the exact integral under piecewise linear\nvolume density. This simultaneously resolves multiple issues: conflicts between\nsamples along different rays, imprecise hierarchical sampling, and\nnon-differentiability of quantiles of ray termination distances w.r.t. model\nparameters. We demonstrate several benefits over the classical sample-based\nrendering equation, such as sharper textures, better geometric reconstruction,\nand stronger depth supervision. Our proposed formulation can be also be used as\na drop-in replacement to the volume rendering equation of existing NeRF-based\nmethods. Our project page can be found at pl-nerf.github.io.",
            "author": [
                "Mikaela Angelina Uy",
                "Kiyohiro Nakayama",
                "Guandao Yang",
                "Rahul Krishna Thomas",
                "Leonidas Guibas",
                "Ke Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20685v1",
                "http://arxiv.org/pdf/2310.20685v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20677v1",
            "title": "Symmetric multipartite Bell inequalities via Frank-Wolfe algorithms",
            "updated": "2023-10-31T17:43:59Z",
            "published": "2023-10-31T17:43:59Z",
            "summary": "In multipartite Bell scenarios, we study the nonlocality robustness of the\nGreenberger-Horne-Zeilinger (GHZ) state. When each party performs planar\nmeasurements forming a regular polygon, we exploit the symmetry of the\nresulting correlation tensor to drastically accelerate the computation of (i) a\nBell inequality via Frank-Wolfe algorithms, and (ii) the corresponding local\nbound. The Bell inequalities obtained are facets of the symmetrised local\npolytope and they give the best known upper bounds on the nonlocality\nrobustness of the GHZ state for three to ten parties. Moreover, for four\nmeasurements per party, we generalise our facets and hence show, for any number\nof parties, an improvement on Mermin's inequality in terms of noise robustness.\nWe also compute the detection efficiency of our inequalities and show that some\ngive rise to activation of nonlocality in star networks, a property that was\nonly shown with an infinite number of measurements.",
            "author": [
                "S\u00e9bastien Designolle",
                "Tam\u00e1s V\u00e9rtesi",
                "Sebastian Pokutta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20677v1",
                "http://arxiv.org/pdf/2310.20677v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20673v1",
            "title": "Balancing Act: Constraining Disparate Impact in Sparse Models",
            "updated": "2023-10-31T17:37:35Z",
            "published": "2023-10-31T17:37:35Z",
            "summary": "Model pruning is a popular approach to enable the deployment of large deep\nlearning models on edge devices with restricted computational or storage\ncapacities. Although sparse models achieve performance comparable to that of\ntheir dense counterparts at the level of the entire dataset, they exhibit high\naccuracy drops for some data sub-groups. Existing methods to mitigate this\ndisparate impact induced by pruning (i) rely on surrogate metrics that address\nthe problem indirectly and have limited interpretability; or (ii) scale poorly\nwith the number of protected sub-groups in terms of computational cost. We\npropose a constrained optimization approach that $\\textit{directly addresses\nthe disparate impact of pruning}$: our formulation bounds the accuracy change\nbetween the dense and sparse models, for each sub-group. This choice of\nconstraints provides an interpretable success criterion to determine if a\npruned model achieves acceptable disparity levels. Experimental results\ndemonstrate that our technique scales reliably to problems involving large\nmodels and hundreds of protected sub-groups.",
            "author": [
                "Meraj Hashemizadeh",
                "Juan Ramirez",
                "Rohan Sukumaran",
                "Golnoosh Farnadi",
                "Simon Lacoste-Julien",
                "Jose Gallego-Posada"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20673v1",
                "http://arxiv.org/pdf/2310.20673v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20671v1",
            "title": "Density Matrix Emulation of Quantum Recurrent Neural Networks for\n  Multivariate Time Series Prediction",
            "updated": "2023-10-31T17:32:11Z",
            "published": "2023-10-31T17:32:11Z",
            "summary": "Quantum Recurrent Neural Networks (QRNNs) are robust candidates to model and\npredict future values in multivariate time series. However, the effective\nimplementation of some QRNN models is limited by the need of mid-circuit\nmeasurements. Those increase the requirements for quantum hardware, which in\nthe current NISQ era does not allow reliable computations. Emulation arises as\nthe main near-term alternative to explore the potential of QRNNs, but existing\nquantum emulators are not dedicated to circuits with multiple intermediate\nmeasurements. In this context, we design a specific emulation method that\nrelies on density matrix formalism. The mathematical development is explicitly\nprovided as a compact formulation by using tensor notation. It allows us to\nshow how the present and past information from a time series is transmitted\nthrough the circuit, and how to reduce the computational cost in every time\nstep of the emulated network. In addition, we derive the analytical gradient\nand the Hessian of the network outputs with respect to its trainable\nparameters, with an eye on gradient-based training and noisy outputs that would\nappear when using real quantum processors. We finally test the presented\nmethods using a novel hardware-efficient ansatz and three diverse datasets that\ninclude univariate and multivariate time series. Our results show how QRNNs can\nmake accurate predictions of future values by capturing non-trivial patterns of\ninput series with different complexities.",
            "author": [
                "Jos\u00e9 Daniel Viqueira",
                "Daniel Fa\u00edlde",
                "Mariamo M. Juane",
                "Andr\u00e9s G\u00f3mez",
                "David Mera"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20671v1",
                "http://arxiv.org/pdf/2310.20671v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20669v1",
            "title": "Modeling multi-legged robot locomotion with slipping and its\n  experimental validation",
            "updated": "2023-10-31T17:32:07Z",
            "published": "2023-10-31T17:32:07Z",
            "summary": "Multi-legged robots with six or more legs are not in common use, despite\ndesigns with superior stability, maneuverability, and a low number of actuators\nbeing available for over 20 years. This may be in part due to the difficulty in\nmodeling multi-legged motion with slipping and producing reliable predictions\nof body velocity. Here we present a detailed measurement of the foot contact\nforces in a hexapedal robot with multiple sliding contacts, and provide an\nalgorithm for predicting these contact forces and the body velocity. The\nalgorithm relies on the recently published observation that even while\nslipping, multi-legged robots are principally kinematic, and employ a friction\nlaw ansatz that allows us to compute the shape-change to body-velocity\nconnection and the foot contact forces. This results in the ability to simulate\nmotion plans for a large number of potentially slipping legs. In homogeneous\nenvironments, this can run in (parallel) logarithmic time of the planning\nhorizon",
            "author": [
                "Ziyou Wu",
                "Dan Zhao",
                "Shai Revzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20669v1",
                "http://arxiv.org/pdf/2310.20669v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20666v1",
            "title": "StairNet: Visual Recognition of Stairs for Human-Robot Locomotion",
            "updated": "2023-10-31T17:30:57Z",
            "published": "2023-10-31T17:30:57Z",
            "summary": "Human-robot walking with prosthetic legs and exoskeletons, especially over\ncomplex terrains such as stairs, remains a significant challenge. Egocentric\nvision has the unique potential to detect the walking environment prior to\nphysical interactions, which can improve transitions to and from stairs. This\nmotivated us to create the StairNet initiative to support the development of\nnew deep learning models for visual sensing and recognition of stairs, with an\nemphasis on lightweight and efficient neural networks for onboard real-time\ninference. In this study, we present an overview of the development of our\nlarge-scale dataset with over 515,000 manually labeled images, as well as our\ndevelopment of different deep learning models (e.g., 2D and 3D CNN, hybrid CNN\nand LSTM, and ViT networks) and training methods (e.g., supervised learning\nwith temporal data and semi-supervised learning with unlabeled images) using\nour new dataset. We consistently achieved high classification accuracy (i.e.,\nup to 98.8%) with different designs, offering trade-offs between model accuracy\nand size. When deployed on mobile devices with GPU and NPU accelerators, our\ndeep learning models achieved inference speeds up to 2.8 ms. We also deployed\nour models on custom-designed CPU-powered smart glasses. However, limitations\nin the embedded hardware yielded slower inference speeds of 1.5 seconds,\npresenting a trade-off between human-centered design and performance. Overall,\nwe showed that StairNet can be an effective platform to develop and study new\nvisual perception systems for human-robot locomotion with applications in\nexoskeleton and prosthetic leg control.",
            "author": [
                "Andrew Garrett Kurbis",
                "Dmytro Kuzmenko",
                "Bogdan Ivanyuk-Skulskiy",
                "Alex Mihailidis",
                "Brokoslaw Laschowski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20666v1",
                "http://arxiv.org/pdf/2310.20666v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20656v1",
            "title": "Non-Compositionality in Sentiment: New Data and Analyses",
            "updated": "2023-10-31T17:25:07Z",
            "published": "2023-10-31T17:25:07Z",
            "summary": "When natural language phrases are combined, their meaning is often more than\nthe sum of their parts. In the context of NLP tasks such as sentiment analysis,\nwhere the meaning of a phrase is its sentiment, that still applies. Many NLP\nstudies on sentiment analysis, however, focus on the fact that sentiment\ncomputations are largely compositional. We, instead, set out to obtain\nnon-compositionality ratings for phrases with respect to their sentiment. Our\ncontributions are as follows: a) a methodology for obtaining those\nnon-compositionality ratings, b) a resource of ratings for 259 phrases --\nNonCompSST -- along with an analysis of that resource, and c) an evaluation of\ncomputational models for sentiment analysis using this new resource.",
            "author": [
                "Verna Dankers",
                "Christopher G. Lucas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20656v1",
                "http://arxiv.org/pdf/2310.20656v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20653v1",
            "title": "Finite Difference Approximation with ADI Scheme for Two-dimensional\n  Keller-Segel Equations",
            "updated": "2023-10-31T17:24:26Z",
            "published": "2023-10-31T17:24:26Z",
            "summary": "Keller-Segel systems are a set of nonlinear partial differential equations\nused to model chemotaxis in biology. In this paper, we propose two alternating\ndirection implicit (ADI) schemes to solve the 2D Keller-Segel systems directly\nwith minimal computational cost, while preserving positivity, energy\ndissipation law and mass conservation. One scheme unconditionally preserves\npositivity, while the other does so conditionally. Both schemes achieve\nsecond-order accuracy in space, with the former being first-order accuracy in\ntime and the latter second-order accuracy in time. Besides, the former scheme\npreserves the energy dissipation law asymptotically. We validate these results\nthrough numerical experiments, and also compare the efficiency of our schemes\nwith the standard five-point scheme, demonstrating that our approaches\neffectively reduce computational costs.",
            "author": [
                "Yubin Lu",
                "Chi-An Chen",
                "Xiaofan Li",
                "Chun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20653v1",
                "http://arxiv.org/pdf/2310.20653v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math-ph",
                "math.AP",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20650v1",
            "title": "Addressing Limitations of State-Aware Imitation Learning for Autonomous\n  Driving",
            "updated": "2023-10-31T17:21:26Z",
            "published": "2023-10-31T17:21:26Z",
            "summary": "Conditional Imitation learning is a common and effective approach to train\nautonomous driving agents. However, two issues limit the full potential of this\napproach: (i) the inertia problem, a special case of causal confusion where the\nagent mistakenly correlates low speed with no acceleration, and (ii) low\ncorrelation between offline and online performance due to the accumulation of\nsmall errors that brings the agent in a previously unseen state. Both issues\nare critical for state-aware models, yet informing the driving agent of its\ninternal state as well as the state of the environment is of crucial\nimportance. In this paper we propose a multi-task learning agent based on a\nmulti-stage vision transformer with state token propagation. We feed the state\nof the vehicle along with the representation of the environment as a special\ntoken of the transformer and propagate it throughout the network. This allows\nus to tackle the aforementioned issues from different angles: guiding the\ndriving policy with learned stop/go information, performing data augmentation\ndirectly on the state of the vehicle and visually explaining the model's\ndecisions. We report a drastic decrease in inertia and a high correlation\nbetween offline and online metrics.",
            "author": [
                "Luca Cultrera",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Pietro Pala",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20650v1",
                "http://arxiv.org/pdf/2310.20650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20649v1",
            "title": "Dynamic Batch Norm Statistics Update for Natural Robustness",
            "updated": "2023-10-31T17:20:30Z",
            "published": "2023-10-31T17:20:30Z",
            "summary": "DNNs trained on natural clean samples have been shown to perform poorly on\ncorrupted samples, such as noisy or blurry images. Various data augmentation\nmethods have been recently proposed to improve DNN's robustness against common\ncorruptions. Despite their success, they require computationally expensive\ntraining and cannot be applied to off-the-shelf trained models. Recently, it\nhas been shown that updating BatchNorm (BN) statistics of an off-the-shelf\nmodel on a single corruption improves its accuracy on that corruption\nsignificantly. However, adopting the idea at inference time when the type of\ncorruption is unknown and changing decreases the effectiveness of this method.\nIn this paper, we harness the Fourier domain to detect the corruption type, a\nchallenging task in the image domain. We propose a unified framework consisting\nof a corruption-detection model and BN statistics update that improves the\ncorruption accuracy of any off-the-shelf trained model. We benchmark our\nframework on different models and datasets. Our results demonstrate about 8%\nand 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively.\nFurthermore, our framework can further improve the accuracy of state-of-the-art\nrobust models, such as AugMix and DeepAug.",
            "author": [
                "Shahbaz Rezaei",
                "Mohammad Sadegh Norouzzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20649v1",
                "http://arxiv.org/pdf/2310.20649v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20646v1",
            "title": "Reaction Theory",
            "updated": "2023-10-31T17:17:33Z",
            "published": "2023-10-31T17:17:33Z",
            "summary": "Background: Exact numerical treatments of nuclear reactions are not feasible,\nexcept for the simplest systems. Few-Body models are justified when the\nreactions are dominated by a small number of scattering channels.\n  Purpose: To discuss a method for constructing few-body models from a given\nHamiltonian where all of the scattering is into a chosen set of important\nchannels and corrections due to eliminated channels can be systematically\ncomputed.\n  Method:The method uses cluster decompositions and spectral expansions of\nproper subsystems to control the absolutely continuous spectrum of the\nmany-body Hamiltonian.\n  Results: The result is a decomposition of the exact Hamiltonian into two\nparts, one that satisfies an optical theorem in a chosen set of important\nchannels and one that satisfies an optical theorem in the complementary\nchannels. When the reaction has a small number of dominant channels, the\ndominant channel part of the Hamiltonian is an effective few-body Hamiltonian.\nThe decomposition has the property that the scattering wave functions from the\ndominant channel Hamiltonian agree with the exact scattering wave functions up\nto, but not including, $N$-body correlations.",
            "author": [
                "Brady J. Martin",
                "Wayne N. Polyzou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20646v1",
                "http://arxiv.org/pdf/2310.20646v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20644v1",
            "title": "Persistence diagrams as morphological signatures of cells: A method to\n  measure and compare cells within a population",
            "updated": "2023-10-31T17:12:01Z",
            "published": "2023-10-31T17:12:01Z",
            "summary": "Cell biologists study in parallel the morphology of cells with the regulation\nmechanisms that modify this morphology. Such studies are complicated by the\ninherent heterogeneity present in the cell population. It remains difficult to\ndefine the morphology of a cell with parameters that can quantify this\nheterogeneity, leaving the cell biologist to rely on manual inspection of cell\nimages. We propose an alternative to this manual inspection that is based on\ntopological data analysis. We characterise the shape of a cell by its contour\nand nucleus. We build a filtering of the edges defining the contour using a\nradial distance function initiated from the nucleus. This filtering is then\nused to construct a persistence diagram that serves as a signature of the cell\nshape. Two cells can then be compared by computing the Wasserstein distance\nbetween their persistence diagrams. Given a cell population, we then compute a\ndistance matrix that includes all pairwise distances between its members. We\nanalyse this distance matrix using hierarchical clustering with different\nlinkage schemes and define a purity score that quantifies consistency between\nthose different schemes, which can then be used to assess homogeneity within\nthe cell population. We illustrate and validate our approach to identify\nsub-populations in human mesenchymal stem cell populations.",
            "author": [
                "Yossi Bokor Bleile",
                "Patrice Koehl",
                "Florian Rehfeldt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20644v1",
                "http://arxiv.org/pdf/2310.20644v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "math.AT",
                "stat.AP",
                "55N31"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20638v1",
            "title": "Histopathological Image Analysis with Style-Augmented Feature Domain\n  Mixing for Improved Generalization",
            "updated": "2023-10-31T17:06:36Z",
            "published": "2023-10-31T17:06:36Z",
            "summary": "Histopathological images are essential for medical diagnosis and treatment\nplanning, but interpreting them accurately using machine learning can be\nchallenging due to variations in tissue preparation, staining and imaging\nprotocols. Domain generalization aims to address such limitations by enabling\nthe learning models to generalize to new datasets or populations. Style\ntransfer-based data augmentation is an emerging technique that can be used to\nimprove the generalizability of machine learning models for histopathological\nimages. However, existing style transfer-based methods can be computationally\nexpensive, and they rely on artistic styles, which can negatively impact model\naccuracy. In this study, we propose a feature domain style mixing technique\nthat uses adaptive instance normalization to generate style-augmented versions\nof images. We compare our proposed method with existing style transfer-based\ndata augmentation methods and found that it performs similarly or better,\ndespite requiring less computation and time. Our results demonstrate the\npotential of feature domain statistics mixing in the generalization of learning\nmodels for histopathological image analysis.",
            "author": [
                "Vaibhav Khamankar",
                "Sutanu Bera",
                "Saumik Bhattacharya",
                "Debashis Sen",
                "Prabir Kumar Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20638v1",
                "http://arxiv.org/pdf/2310.20638v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20636v1",
            "title": "Using Higher-Order Moments to Assess the Quality of GAN-generated Image\n  Features",
            "updated": "2023-10-31T17:05:02Z",
            "published": "2023-10-31T17:05:02Z",
            "summary": "The rapid advancement of Generative Adversarial Networks (GANs) necessitates\nthe need to robustly evaluate these models. Among the established evaluation\ncriteria, the Fr\\'{e}chet Inception Distance (FID) has been widely adopted due\nto its conceptual simplicity, fast computation time, and strong correlation\nwith human perception. However, FID has inherent limitations, mainly stemming\nfrom its assumption that feature embeddings follow a Gaussian distribution, and\ntherefore can be defined by their first two moments. As this does not hold in\npractice, in this paper we explore the importance of third-moments in image\nfeature data and use this information to define a new measure, which we call\nthe Skew Inception Distance (SID). We prove that SID is a pseudometric on\nprobability distributions, show how it extends FID, and present a practical\nmethod for its computation. Our numerical experiments support that SID either\ntracks with FID or, in some cases, aligns more closely with human perception\nwhen evaluating image features of ImageNet data.",
            "author": [
                "Lorenzo Luzi",
                "Helen Jenne",
                "Ryan Murray",
                "Carlos Ortiz Marrero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20636v1",
                "http://arxiv.org/pdf/2310.20636v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20633v1",
            "title": "Defining a New NLP Playground",
            "updated": "2023-10-31T17:02:33Z",
            "published": "2023-10-31T17:02:33Z",
            "summary": "The recent explosion of performance of large language models (LLMs) has\nchanged the field of Natural Language Processing (NLP) more abruptly and\nseismically than any other shift in the field's 80-year history. This has\nresulted in concerns that the field will become homogenized and\nresource-intensive. The new status quo has put many academic researchers,\nespecially PhD students, at a disadvantage. This paper aims to define a new NLP\nplayground by proposing 20+ PhD-dissertation-worthy research directions,\ncovering theoretical analysis, new and challenging problems, learning\nparadigms, and interdisciplinary applications.",
            "author": [
                "Sha Li",
                "Chi Han",
                "Pengfei Yu",
                "Carl Edwards",
                "Manling Li",
                "Xingyao Wang",
                "Yi R. Fung",
                "Charles Yu",
                "Joel R. Tetreault",
                "Eduard H. Hovy",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20633v1",
                "http://arxiv.org/pdf/2310.20633v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20630v1",
            "title": "Projecting basis functions with tensor networks for Gaussian process\n  regression",
            "updated": "2023-10-31T16:59:07Z",
            "published": "2023-10-31T16:59:07Z",
            "summary": "This paper presents a method for approximate Gaussian process (GP) regression\nwith tensor networks (TNs). A parametric approximation of a GP uses a linear\ncombination of basis functions, where the accuracy of the approximation depends\non the total number of basis functions $M$. We develop an approach that allows\nus to use an exponential amount of basis functions without the corresponding\nexponential computational complexity. The key idea to enable this is using\nlow-rank TNs. We first find a suitable low-dimensional subspace from the data,\ndescribed by a low-rank TN. In this low-dimensional subspace, we then infer the\nweights of our model by solving a Bayesian inference problem. Finally, we\nproject the resulting weights back to the original space to make GP\npredictions. The benefit of our approach comes from the projection to a smaller\nsubspace: It modifies the shape of the basis functions in a way that it sees\nfit based on the given data, and it allows for efficient computations in the\nsmaller subspace. In an experiment with an 18-dimensional benchmark data set,\nwe show the applicability of our method to an inverse dynamics problem.",
            "author": [
                "Clara Menzen",
                "Eva Memmel",
                "Kim Batselier",
                "Manon Kok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20630v1",
                "http://arxiv.org/pdf/2310.20630v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20621v1",
            "title": "Deepfake detection by exploiting surface anomalies: the SurFake approach",
            "updated": "2023-10-31T16:54:14Z",
            "published": "2023-10-31T16:54:14Z",
            "summary": "The ever-increasing use of synthetically generated content in different\nsectors of our everyday life, one for all media information, poses a strong\nneed for deepfake detection tools in order to avoid the proliferation of\naltered messages. The process to identify manipulated content, in particular\nimages and videos, is basically performed by looking for the presence of some\ninconsistencies and/or anomalies specifically due to the fake generation\nprocess. Different techniques exist in the scientific literature that exploit\ndiverse ad-hoc features in order to highlight possible modifications. In this\npaper, we propose to investigate how deepfake creation can impact on the\ncharacteristics that the whole scene had at the time of the acquisition. In\nparticular, when an image (video) is captured the overall geometry of the scene\n(e.g. surfaces) and the acquisition process (e.g. illumination) determine a\nunivocal environment that is directly represented by the image pixel values;\nall these intrinsic relations are possibly changed by the deepfake generation\nprocess. By resorting to the analysis of the characteristics of the surfaces\ndepicted in the image it is possible to obtain a descriptor usable to train a\nCNN for deepfake detection: we refer to such an approach as SurFake.\nExperimental results carried out on the FF++ dataset for different kinds of\ndeepfake forgeries and diverse deep learning models confirm that such a feature\ncan be adopted to discriminate between pristine and altered images;\nfurthermore, experiments witness that it can also be combined with visual data\nto provide a certain improvement in terms of detection accuracy.",
            "author": [
                "Andrea Ciamarra",
                "Roberto Caldelli",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20621v1",
                "http://arxiv.org/pdf/2310.20621v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20620v1",
            "title": "The Unreasonable Effectiveness of Random Target Embeddings for\n  Continuous-Output Neural Machine Translation",
            "updated": "2023-10-31T16:53:10Z",
            "published": "2023-10-31T16:53:10Z",
            "summary": "Continuous-output neural machine translation (CoNMT) replaces the discrete\nnext-word prediction problem with an embedding prediction. The semantic\nstructure of the target embedding space (i.e., closeness of related words) is\nintuitively believed to be crucial. We challenge this assumption and show that\ncompletely random output embeddings can outperform laboriously pretrained ones,\nespecially on larger datasets. Further investigation shows this surprising\neffect is strongest for rare words, due to the geometry of their embeddings. We\nshed further light on this finding by designing a mixed strategy that combines\nrandom and pre-trained embeddings for different tokens.",
            "author": [
                "Evgeniia Tokarchuk",
                "Vlad Niculae"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20620v1",
                "http://arxiv.org/pdf/2310.20620v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20618v1",
            "title": "Diffusion Reconstruction of Ultrasound Images with Informative\n  Uncertainty",
            "updated": "2023-10-31T16:51:40Z",
            "published": "2023-10-31T16:51:40Z",
            "summary": "Despite its wide use in medicine, ultrasound imaging faces several challenges\nrelated to its poor signal-to-noise ratio and several sources of noise and\nartefacts. Enhancing ultrasound image quality involves balancing concurrent\nfactors like contrast, resolution, and speckle preservation. In recent years,\nthere has been progress both in model-based and learning-based approaches to\nimprove ultrasound image reconstruction. Bringing the best from both worlds, we\npropose a hybrid approach leveraging advances in diffusion models. To this end,\nwe adapt Denoising Diffusion Restoration Models (DDRM) to incorporate\nultrasound physics through a linear direct model and an unsupervised\nfine-tuning of the prior diffusion model. We conduct comprehensive experiments\non simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our\napproach in achieving high-quality image reconstructions from a single plane\nwave input and in comparison to state-of-the-art methods. Finally, given the\nstochastic nature of the method, we analyse in depth the statistical properties\nof single and multiple-sample reconstructions, experimentally show the\ninformativeness of their variance, and provide an empirical model relating this\nbehaviour to speckle noise. The code and data are available at: (upon\nacceptance).",
            "author": [
                "Yuxin Zhang",
                "Cl\u00e9ment Huneau",
                "J\u00e9r\u00f4me Idier",
                "Diana Mateus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20618v1",
                "http://arxiv.org/pdf/2310.20618v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20615v1",
            "title": "Near-Optimal Min-Sum Motion Planning for Two Square Robots in a\n  Polygonal Environment",
            "updated": "2023-10-31T16:50:05Z",
            "published": "2023-10-31T16:50:05Z",
            "summary": "Let $\\mathcal{W} \\subset \\mathbb{R}^2$ be a planar polygonal environment\n(i.e., a polygon potentially with holes) with a total of $n$ vertices, and let\n$A,B$ be two robots, each modeled as an axis-aligned unit square, that can\ntranslate inside $\\mathcal{W}$. Given source and target placements\n$s_A,t_A,s_B,t_B \\in \\mathcal{W}$ of $A$ and $B$, respectively, the goal is to\ncompute a \\emph{collision-free motion plan} $\\mathbf{\\pi}^*$, i.e., a motion\nplan that continuously moves $A$ from $s_A$ to $t_A$ and $B$ from $s_B$ to\n$t_B$ so that $A$ and $B$ remain inside $\\mathcal{W}$ and do not collide with\neach other during the motion. Furthermore, if such a plan exists, then we wish\nto return a plan that minimizes the sum of the lengths of the paths traversed\nby the robots, $\\left|\\mathbf{\\pi}^*\\right|$. Given $\\mathcal{W},\ns_A,t_A,s_B,t_B$ and a parameter $\\varepsilon > 0$, we present an\n$n^2\\varepsilon^{-O(1)} \\log n$-time $(1+\\varepsilon)$-approximation algorithm\nfor this problem. We are not aware of any polynomial time algorithm for this\nproblem, nor do we know whether the problem is NP-Hard. Our result is the first\npolynomial-time $(1+\\varepsilon)$-approximation algorithm for an optimal motion\nplanning problem involving two robots moving in a polygonal environment.",
            "author": [
                "Pankaj K. Agarwal",
                "Dan Halperin",
                "Micha Sharir",
                "Alex Steiger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20615v1",
                "http://arxiv.org/pdf/2310.20615v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20609v1",
            "title": "Graph Matching via convex relaxation to the simplex",
            "updated": "2023-10-31T16:44:26Z",
            "published": "2023-10-31T16:44:26Z",
            "summary": "This paper addresses the Graph Matching problem, which consists of finding\nthe best possible alignment between two input graphs, and has many applications\nin computer vision, network deanonymization and protein alignment. A common\napproach to tackle this problem is through convex relaxations of the NP-hard\n\\emph{Quadratic Assignment Problem} (QAP).\n  Here, we introduce a new convex relaxation onto the unit simplex and develop\nan efficient mirror descent scheme with closed-form iterations for solving this\nproblem. Under the correlated Gaussian Wigner model, we show that the simplex\nrelaxation admits a unique solution with high probability. In the noiseless\ncase, this is shown to imply exact recovery of the ground truth permutation.\nAdditionally, we establish a novel sufficiency condition for the input matrix\nin standard greedy rounding methods, which is less restrictive than the\ncommonly used `diagonal dominance' condition. We use this condition to show\nexact one-step recovery of the ground truth (holding almost surely) via the\nmirror descent scheme, in the noiseless setting. We also use this condition to\nobtain significantly improved conditions for the GRAMPA algorithm [Fan et al.\n2019] in the noiseless setting.",
            "author": [
                "Ernesto Araya Valdivia",
                "Hemant Tyagi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20609v1",
                "http://arxiv.org/pdf/2310.20609v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20607v1",
            "title": "What a Whole Slide Image Can Tell? Subtype-guided Masked Transformer for\n  Pathological Image Captioning",
            "updated": "2023-10-31T16:43:03Z",
            "published": "2023-10-31T16:43:03Z",
            "summary": "Pathological captioning of Whole Slide Images (WSIs), though is essential in\ncomputer-aided pathological diagnosis, has rarely been studied due to the\nlimitations in datasets and model training efficacy. In this paper, we propose\na new paradigm Subtype-guided Masked Transformer (SGMT) for pathological\ncaptioning based on Transformers, which treats a WSI as a sequence of sparse\npatches and generates an overall caption sentence from the sequence. An\naccompanying subtype prediction is introduced into SGMT to guide the training\nprocess and enhance the captioning accuracy. We also present an Asymmetric\nMasked Mechansim approach to tackle the large size constraint of pathological\nimage captioning, where the numbers of sequencing patches in SGMT are sampled\ndifferently in the training and inferring phases, respectively. Experiments on\nthe PatchGastricADC22 dataset demonstrate that our approach effectively adapts\nto the task with a transformer-based model and achieves superior performance\nthan traditional RNN-based methods. Our codes are to be made available for\nfurther research and development.",
            "author": [
                "Wenkang Qin",
                "Rui Xu",
                "Peixiang Huang",
                "Xiaomin Wu",
                "Heyu Zhang",
                "Lin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20607v1",
                "http://arxiv.org/pdf/2310.20607v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20606v1",
            "title": "One-Way Communication Complexity of Partial XOR Functions",
            "updated": "2023-10-31T16:42:10Z",
            "published": "2023-10-31T16:42:10Z",
            "summary": "Boolean function $F(x,y)$ for $x,y \\in \\{0,1\\}^n$ is an XOR function if\n$F(x,y)=f(x\\oplus y)$ for some function $f$ on $n$ input bits, where $\\oplus$\nis a bit-wise XOR. XOR functions are relevant in communication complexity,\npartially for allowing Fourier analytic technique. For total XOR functions it\nis known that deterministic communication complexity of $F$ is closely related\nto parity decision tree complexity of $f$. Montanaro and Osbourne (2009)\nobserved that one-sided communication complexity $D_{cc}^{\\rightarrow}(F)$ of\n$F$ is exactly equal to nonadaptive parity decision tree complexity\n$NADT^{\\oplus}(f)$ of $f$. Hatami et al. (2018) showed that unrestricted\ncommunication complexity of $F$ is polynomially related to parity decision tree\ncomplexity of $f$.\n  We initiate the studies of a similar connection for partial functions. We\nshow that in case of one-sided communication complexity whether these measures\nare equal, depends on the number of undefined inputs of $f$. On the one hand,\nif $D_{cc}^{\\rightarrow}(F)=t$ and $f$ is undefined on at most\n$O(\\frac{2^{n-t}}{\\sqrt{n-t}})$, then $NADT^{\\oplus}(f)=t$.\n  On the other hand, for a wide range of values of $D_{cc}^{\\rightarrow}(F)$\nand $NADT^{\\oplus}(f)$ (from constant to $n-2$) we provide partial functions\nfor which $D_{cc}^{\\rightarrow}(F) < NADT^{\\oplus}(f)$. In particular, we\nprovide a function with an exponential gap between the two measures. Our\nseparation results translate to the case of two-sided communication complexity\nas well, in particular showing that the result of Hatami et al. (2018) cannot\nbe generalized to partial functions.\n  Previous results for total functions heavily rely on Boolean Fourier analysis\nand the technique does not translate to partial functions. For the proofs of\nour results we build a linear algebraic framework instead. Separation results\nare proved through the reduction to covering codes.",
            "author": [
                "Vladimir V. Podolskii",
                "Dmitrii Sluch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20606v1",
                "http://arxiv.org/pdf/2310.20606v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20605v1",
            "title": "Learning Lyapunov-Stable Polynomial Dynamical Systems Through Imitation",
            "updated": "2023-10-31T16:39:58Z",
            "published": "2023-10-31T16:39:58Z",
            "summary": "Imitation learning is a paradigm to address complex motion planning problems\nby learning a policy to imitate an expert's behavior. However, relying solely\non the expert's data might lead to unsafe actions when the robot deviates from\nthe demonstrated trajectories. Stability guarantees have previously been\nprovided utilizing nonlinear dynamical systems, acting as high-level motion\nplanners, in conjunction with the Lyapunov stability theorem. Yet, these\nmethods are prone to inaccurate policies, high computational cost, sample\ninefficiency, or quasi stability when replicating complex and highly nonlinear\ntrajectories. To mitigate this problem, we present an approach for learning a\nglobally stable nonlinear dynamical system as a motion planning policy. We\nmodel the nonlinear dynamical system as a parametric polynomial and learn the\npolynomial's coefficients jointly with a Lyapunov candidate. To showcase its\nsuccess, we compare our method against the state of the art in simulation and\nconduct real-world experiments with the Kinova Gen3 Lite manipulator arm. Our\nexperiments demonstrate the sample efficiency and reproduction accuracy of our\nmethod for various expert trajectories, while remaining stable in the face of\nperturbations.",
            "author": [
                "Amin Abyaneh",
                "Hsiu-Chin Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20605v1",
                "http://arxiv.org/pdf/2310.20605v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20604v2",
            "title": "Enhanced Synthetic MRI Generation from CT Scans Using CycleGAN with\n  Feature Extraction",
            "updated": "2023-11-28T08:29:18Z",
            "published": "2023-10-31T16:39:56Z",
            "summary": "In the field of radiotherapy, accurate imaging and image registration are of\nutmost importance for precise treatment planning. Magnetic Resonance Imaging\n(MRI) offers detailed imaging without being invasive and excels in soft-tissue\ncontrast, making it a preferred modality for radiotherapy planning. However,\nthe high cost of MRI, longer acquisition time, and certain health\nconsiderations for patients pose challenges. Conversely, Computed Tomography\n(CT) scans offer a quicker and less expensive imaging solution. To bridge these\nmodalities and address multimodal alignment challenges, we introduce an\napproach for enhanced monomodal registration using synthetic MRI images.\nUtilizing unpaired data, this paper proposes a novel method to produce these\nsynthetic MRI images from CT scans, leveraging CycleGANs and feature\nextractors. By building upon the foundational work on Cycle-Consistent\nAdversarial Networks and incorporating advancements from related literature,\nour methodology shows promising results, outperforming several state-of-the-art\nmethods. The efficacy of our approach is validated by multiple comparison\nmetrics.",
            "author": [
                "Saba Nikbakhsh",
                "Lachin Naghashyar",
                "Morteza Valizadeh",
                "Mehdi Chehel Amirani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20604v2",
                "http://arxiv.org/pdf/2310.20604v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20602v1",
            "title": "Compliant actuators that mimic biological muscle performance with\n  applications in a highly biomimetic robotic arm",
            "updated": "2023-10-31T16:37:30Z",
            "published": "2023-10-31T16:37:30Z",
            "summary": "This paper endeavours to bridge the existing gap in muscular actuator design\nfor ligament-skeletal-inspired robots, thereby fostering the evolution of these\nrobotic systems. We introduce two novel compliant actuators, namely the\nInternal Torsion Spring Compliant Actuator (ICA) and the External Spring\nCompliant Actuator (ECA), and present a comparative analysis against the\npreviously conceived Magnet Integrated Soft Actuator (MISA) through\ncomputational and experimental results. These actuators, employing a\nmotor-tendon system, emulate biological muscle-like forms, enhancing artificial\nmuscle technology. A robotic arm application inspired by the skeletal ligament\nsystem is presented. Experiments demonstrate satisfactory power in tasks like\nlifting dumbbells (peak power: 36W), playing table tennis (end-effector speed:\n3.2 m/s), and door opening, without compromising biomimetic aesthetics.\nCompared to other linear stiffness serial elastic actuators (SEAs), ECA and ICA\nexhibit high power-to-volume (361 x 10^3 W/m) and power-to-mass (111.6 W/kg)\nratios respectively, endorsing the biomimetic design's promise in robotic\ndevelopment.",
            "author": [
                "Haosen Yang",
                "Guowu Wei",
                "Lei Ren",
                "Lingyun Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20602v1",
                "http://arxiv.org/pdf/2310.20602v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20599v1",
            "title": "Brain-like Flexible Visual Inference by Harnessing Feedback-Feedforward\n  Alignment",
            "updated": "2023-10-31T16:35:27Z",
            "published": "2023-10-31T16:35:27Z",
            "summary": "In natural vision, feedback connections support versatile visual inference\ncapabilities such as making sense of the occluded or noisy bottom-up sensory\ninformation or mediating pure top-down processes such as imagination. However,\nthe mechanisms by which the feedback pathway learns to give rise to these\ncapabilities flexibly are not clear. We propose that top-down effects emerge\nthrough alignment between feedforward and feedback pathways, each optimizing\nits own objectives. To achieve this co-optimization, we introduce\nFeedback-Feedforward Alignment (FFA), a learning algorithm that leverages\nfeedback and feedforward pathways as mutual credit assignment computational\ngraphs, enabling alignment. In our study, we demonstrate the effectiveness of\nFFA in co-optimizing classification and reconstruction tasks on widely used\nMNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endows\nfeedback connections with emergent visual inference functions, including\ndenoising, resolving occlusions, hallucination, and imagination. Moreover, FFA\noffers bio-plausibility compared to traditional backpropagation (BP) methods in\nimplementation. By repurposing the computational graph of credit assignment\ninto a goal-driven feedback pathway, FFA alleviates weight transport problems\nencountered in BP, enhancing the bio-plausibility of the learning algorithm.\nOur study presents FFA as a promising proof-of-concept for the mechanisms\nunderlying how feedback connections in the visual cortex support flexible\nvisual functions. This work also contributes to the broader field of visual\ninference underlying perceptual phenomena and has implications for developing\nmore biologically inspired learning algorithms.",
            "author": [
                "Tahereh Toosi",
                "Elias B. Issa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20599v1",
                "http://arxiv.org/pdf/2310.20599v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20593v1",
            "title": "FLODCAST: Flow and Depth Forecasting via Multimodal Recurrent\n  Architectures",
            "updated": "2023-10-31T16:30:16Z",
            "published": "2023-10-31T16:30:16Z",
            "summary": "Forecasting motion and spatial positions of objects is of fundamental\nimportance, especially in safety-critical settings such as autonomous driving.\nIn this work, we address the issue by forecasting two different modalities that\ncarry complementary information, namely optical flow and depth. To this end we\npropose FLODCAST a flow and depth forecasting model that leverages a multitask\nrecurrent architecture, trained to jointly forecast both modalities at once. We\nstress the importance of training using flows and depth maps together,\ndemonstrating that both tasks improve when the model is informed of the other\nmodality. We train the proposed model to also perform predictions for several\ntimesteps in the future. This provides better supervision and leads to more\nprecise predictions, retaining the capability of the model to yield outputs\nautoregressively for any future time horizon. We test our model on the\nchallenging Cityscapes dataset, obtaining state of the art results for both\nflow and depth forecasting. Thanks to the high quality of the generated flows,\nwe also report benefits on the downstream task of segmentation forecasting,\ninjecting our predictions in a flow-based mask-warping framework.",
            "author": [
                "Andrea Ciamarra",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20593v1",
                "http://arxiv.org/pdf/2310.20593v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20589v1",
            "title": "Increasing The Performance of Cognitively Inspired Data-Efficient\n  Language Models via Implicit Structure Building",
            "updated": "2023-10-31T16:26:36Z",
            "published": "2023-10-31T16:26:36Z",
            "summary": "In this paper, we describe our submission to the BabyLM Challenge 2023 shared\ntask on data-efficient language model (LM) pretraining (Warstadt et al., 2023).\nWe train transformer-based masked language models that incorporate unsupervised\npredictions about hierarchical sentence structure into the model architecture.\nConcretely, we use the Structformer architecture (Shen et al., 2021) and\nvariants thereof. StructFormer models have been shown to perform well on\nunsupervised syntactic induction based on limited pretraining data, and to\nyield performance improvements over a vanilla transformer architecture (Shen et\nal., 2021). Evaluation of our models on 39 tasks provided by the BabyLM\nchallenge shows promising improvements of models that integrate a hierarchical\nbias into the architecture at some particular tasks, even though they fail to\nconsistently outperform the RoBERTa baseline model provided by the shared task\norganizers on all tasks.",
            "author": [
                "Omar Momen",
                "David Arps",
                "Laura Kallmeyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20589v1",
                "http://arxiv.org/pdf/2310.20589v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20588v1",
            "title": "Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding",
            "updated": "2023-10-31T16:26:33Z",
            "published": "2023-10-31T16:26:33Z",
            "summary": "In the era of the Internet of Things (IoT), the retrieval of relevant medical\ninformation has become essential for efficient clinical decision-making. This\npaper introduces MedFusionRank, a novel approach to zero-shot medical\ninformation retrieval (MIR) that combines the strengths of pre-trained language\nmodels and statistical methods while addressing their limitations. The proposed\napproach leverages a pre-trained BERT-style model to extract compact yet\ninformative keywords. These keywords are then enriched with domain knowledge by\nlinking them to conceptual entities within a medical knowledge graph.\nExperimental evaluations on medical datasets demonstrate MedFusion Rank's\nsuperior performance over existing methods, with promising results with a\nvariety of evaluation metrics. MedFusionRank demonstrates efficacy in\nretrieving relevant information, even from short or single-term queries.",
            "author": [
                "Yuqi Wang",
                "Zeqiang Wang",
                "Wei Wang",
                "Qi Chen",
                "Kaizhu Huang",
                "Anh Nguyen",
                "Suparna De"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20588v1",
                "http://arxiv.org/pdf/2310.20588v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20578v1",
            "title": "Fault-Tolerant Operation of Bosonic Qubits with Discrete-Variable\n  Ancillae",
            "updated": "2023-10-31T16:13:04Z",
            "published": "2023-10-31T16:13:04Z",
            "summary": "Fault-tolerant quantum computation with bosonic qubits often necessitates the\nuse of noisy discrete-variable ancillae. In this work, we establish a\ncomprehensive and practical fault-tolerance framework for such a hybrid system\nand synthesize it with fault-tolerant protocols by combining bosonic quantum\nerror correction (QEC) and advanced quantum control techniques. We introduce\nessential building blocks of error-corrected gadgets by leveraging\nancilla-assisted bosonic operations using a generalized variant of\npath-independent quantum control (GPI). Using these building blocks, we\nconstruct a universal set of error-corrected gadgets that tolerate a single\nphoton loss and an arbitrary ancilla fault for four-legged cat qubits. Notably,\nour construction only requires dispersive coupling between bosonic modes and\nancillae, as well as beam-splitter coupling between bosonic modes, both of\nwhich have been experimentally demonstrated with strong strengths and high\naccuracy. Moreover, each error-corrected bosonic qubit is only comprised of a\nsingle bosonic mode and a three-level ancilla, featuring the hardware\nefficiency of bosonic QEC in the full fault-tolerant setting. We numerically\ndemonstrate the feasibility of our schemes using current experimental\nparameters in the circuit-QED platform. Finally, we present a\nhardware-efficient architecture for fault-tolerant quantum computing by\nconcatenating the four-legged cat qubits with an outer qubit code utilizing\nonly beam-splitter couplings. Our estimates suggest that the overall noise\nthreshold can be reached using existing hardware. These developed\nfault-tolerant schemes extend beyond their applicability to four-legged cat\nqubits and can be adapted for other rotation-symmetrical codes, offering a\npromising avenue toward scalable and robust quantum computation with bosonic\nqubits.",
            "author": [
                "Qian Xu",
                "Pei Zeng",
                "Daohong Xu",
                "Liang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20578v1",
                "http://arxiv.org/pdf/2310.20578v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20577v1",
            "title": "Offloading Real-Time Tasks in IIoT Environments under Consideration of\n  Networking Uncertainties",
            "updated": "2023-10-31T16:12:21Z",
            "published": "2023-10-31T16:12:21Z",
            "summary": "Offloading is a popular way to overcome the resource and power constraints of\nnetworked embedded devices, which are increasingly found in industrial\nenvironments. It involves moving resource-intensive computational tasks to a\nmore powerful device on the network, often in close proximity to enable\nwireless communication. However, many Industrial Internet of Things (IIoT)\napplications have real-time constraints. Offloading such tasks over a wireless\nnetwork with latency uncertainties poses new challenges.\n  In this paper, we aim to better understand these challenges by proposing a\nsystem architecture and scheduler for real-time task offloading in wireless\nIIoT environments. Based on a prototype, we then evaluate different system\nconfigurations and discuss their trade-offs and implications. Our design showed\nto prevent deadline misses under high load and network uncertainties and was\nable to outperform a reference scheduler in terms of successful task\nthroughput. Under heavy task load, where the reference scheduler had a success\nrate of 5%, our design achieved a success rate of 60%.",
            "author": [
                "Ilja Behnke",
                "Philipp Wiesner",
                "Paul Voelker",
                "Odej Kao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3630180.3631202",
                "http://arxiv.org/abs/2310.20577v1",
                "http://arxiv.org/pdf/2310.20577v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "C.2.4; C.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20576v1",
            "title": "Proximity effect induced intriguing superconductivity in van der Waals\n  heterostructure of magnetic topological insulator and conventional\n  superconductor",
            "updated": "2023-10-31T16:10:45Z",
            "published": "2023-10-31T16:10:45Z",
            "summary": "Nontrivial topological superconductivity has received enormous research\nattentions due to its potential for diverse applications in topological quantum\ncomputing. The intrinsic issue concerning the correlation between a topological\ninsulator and a superconductor is, however, still widely open. Here, we\nsystemically report an emergent superconductivity in a cross-junction composed\nof a magnetic topological insulator MnBi2Te4 and a conventional superconductor\nNbSe2. Remarkably, the interface indicates existence of a reduced\nsuperconductivity at surface of NbSe2 and a proximity-effectinduced\nsuperconductivity at surface of MnBi2Te4. Furthermore, the in-plane\nangular-dependent magnetoresistance measurements reveal the fingerprints of the\nparing symmetry behaviors for these superconducting gaps as a unconventional\nnature. Our findings extend our views and ideas of topological\nsuperconductivity in the superconducting heterostructures with time-reversal\nsymmetry breaking, offering an exciting opportunity to elucidate the\ncooperative effects on the surface state of a topological insulator aligning a\nsuperconductor.",
            "author": [
                "Peng Dong",
                "Xiang Zhou",
                "Xiaofei Hou",
                "Jiadian He",
                "Yiwen Zhang",
                "Yifan Ding",
                "Xiaohui Zeng",
                "Jinghui Wang",
                "Yueshen Wu",
                "Kenji Watanabe",
                "Takashi Taniguchi",
                "Wei Xia",
                "Yanfeng Guo",
                "Yulin Chen",
                "Wei Li",
                "Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20576v1",
                "http://arxiv.org/pdf/2310.20576v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20574v1",
            "title": "Information-Theoretic Trust Regions for Stochastic Gradient-Based\n  Optimization",
            "updated": "2023-10-31T16:08:38Z",
            "published": "2023-10-31T16:08:38Z",
            "summary": "Stochastic gradient-based optimization is crucial to optimize neural\nnetworks. While popular approaches heuristically adapt the step size and\ndirection by rescaling gradients, a more principled approach to improve\noptimizers requires second-order information. Such methods precondition the\ngradient using the objective's Hessian. Yet, computing the Hessian is usually\nexpensive and effectively using second-order information in the stochastic\ngradient setting is non-trivial. We propose using Information-Theoretic Trust\nRegion Optimization (arTuRO) for improved updates with uncertain second-order\ninformation. By modeling the network parameters as a Gaussian distribution and\nusing a Kullback-Leibler divergence-based trust region, our approach takes\nbounded steps accounting for the objective's curvature and uncertainty in the\nparameters. Before each update, it solves the trust region problem for an\noptimal step size, resulting in a more stable and faster optimization process.\nWe approximate the diagonal elements of the Hessian from stochastic gradients\nusing a simple recursive least squares approach, constructing a model of the\nexpected Hessian over time using only first-order information. We show that\narTuRO combines the fast convergence of adaptive moment-based optimization with\nthe generalization capabilities of SGD.",
            "author": [
                "Philipp Dahlinger",
                "Philipp Becker",
                "Maximilian H\u00fcttenrauch",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20574v1",
                "http://arxiv.org/pdf/2310.20574v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20567v2",
            "title": "One-shot backpropagation for multi-step prediction in physics-based\n  system identification -- EXTENDED VERSION",
            "updated": "2023-11-21T09:19:06Z",
            "published": "2023-10-31T15:56:17Z",
            "summary": "The aim of this paper is to present a novel physics-based framework for the\nidentification of dynamical systems, in which the physical and structural\ninsights are reflected directly into a backpropagation-based learning\nalgorithm. The main result is a method to compute in closed form the gradient\nof a multi-step loss function, while enforcing physical properties and\nconstraints. The derived algorithm has been exploited to identify the unknown\ninertia matrix of a space debris, and the results show the reliability of the\nmethod in capturing the physical adherence of the estimated parameters.",
            "author": [
                "Cesare Donati",
                "Martina Mammarella",
                "Fabrizio Dabbene",
                "Carlo Novara",
                "Constantino Lagoa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20567v2",
                "http://arxiv.org/pdf/2310.20567v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20563v1",
            "title": "Taking control: Policies to address extinction risks from advanced AI",
            "updated": "2023-10-31T15:53:14Z",
            "published": "2023-10-31T15:53:14Z",
            "summary": "This paper provides policy recommendations to reduce extinction risks from\nadvanced artificial intelligence (AI). First, we briefly provide background\ninformation about extinction risks from AI. Second, we argue that voluntary\ncommitments from AI companies would be an inappropriate and insufficient\nresponse. Third, we describe three policy proposals that would meaningfully\naddress the threats from advanced AI: (1) establishing a Multinational AGI\nConsortium to enable democratic oversight of advanced AI (MAGIC), (2)\nimplementing a global cap on the amount of computing power used to train an AI\nsystem (global compute cap), and (3) requiring affirmative safety evaluations\nto ensure that risks are kept below acceptable levels (gating critical\nexperiments). MAGIC would be a secure, safety-focused, internationally-governed\ninstitution responsible for reducing risks from advanced AI and performing\nresearch to safely harness the benefits of AI. MAGIC would also maintain\nemergency response infrastructure (kill switch) to swiftly halt AI development\nor withdraw model deployment in the event of an AI-related emergency. The\nglobal compute cap would end the corporate race toward dangerous AI systems\nwhile enabling the vast majority of AI innovation to continue unimpeded. Gating\ncritical experiments would ensure that companies developing powerful AI systems\nare required to present affirmative evidence that these models keep extinction\nrisks below an acceptable threshold. After describing these recommendations, we\npropose intermediate steps that the international community could take to\nimplement these proposals and lay the groundwork for international coordination\naround advanced AI.",
            "author": [
                "Andrea Miotti",
                "Akash Wasil"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20563v1",
                "http://arxiv.org/pdf/2310.20563v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20561v1",
            "title": "Predictive Control for Autonomous Driving with Uncertain, Multi-modal\n  Predictions",
            "updated": "2023-10-31T15:52:06Z",
            "published": "2023-10-31T15:52:06Z",
            "summary": "We propose a Stochastic MPC (SMPC) formulation for path planning with\nautonomous vehicles in scenarios involving multiple agents with multi-modal\npredictions. The multi-modal predictions capture the uncertainty of urban\ndriving in distinct modes/maneuvers (e.g., yield, keep speed) and driving\ntrajectories (e.g., speed, turning radius), which are incorporated for\nmulti-modal collision avoidance chance constraints for path planning. In the\npresence of multi-modal uncertainties, it is challenging to reliably compute\nfeasible path planning solutions at real-time frequencies ($\\geq$ 10 Hz). Our\nmain technological contribution is a convex SMPC formulation that\nsimultaneously (1) optimizes over parameterized feedback policies and (2)\nallocates risk levels for each mode of the prediction. The use of feedback\npolicies and risk allocation enhances the feasibility and performance of the\nSMPC formulation against multi-modal predictions with large uncertainty. We\nevaluate our approach via simulations and road experiments with a full-scale\nvehicle interacting in closed-loop with virtual vehicles. We consider distinct,\nmulti-modal driving scenarios: 1) Negotiating a traffic light and a fast,\ntailgating agent, 2) Executing an unprotected left turn at a traffic\nintersection, and 3) Changing lanes in the presence of multiple agents. For all\nof these scenarios, our approach reliably computes multi-modal solutions to the\npath-planning problem at real-time frequencies.",
            "author": [
                "Siddharth H. Nair",
                "Hotae Lee",
                "Eunhyek Joa",
                "Yan Wang",
                "H. Eric Tseng",
                "Francesco Borrelli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20561v1",
                "http://arxiv.org/pdf/2310.20561v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20558v1",
            "title": "Breaking the Token Barrier: Chunking and Convolution for Efficient Long\n  Text Classification with BERT",
            "updated": "2023-10-31T15:41:08Z",
            "published": "2023-10-31T15:41:08Z",
            "summary": "Transformer-based models, specifically BERT, have propelled research in\nvarious NLP tasks. However, these models are limited to a maximum token limit\nof 512 tokens. Consequently, this makes it non-trivial to apply it in a\npractical setting with long input. Various complex methods have claimed to\novercome this limit, but recent research questions the efficacy of these models\nacross different classification tasks. These complex architectures evaluated on\ncarefully curated long datasets perform at par or worse than simple baselines.\nIn this work, we propose a relatively simple extension to vanilla BERT\narchitecture called ChunkBERT that allows finetuning of any pretrained models\nto perform inference on arbitrarily long text. The proposed method is based on\nchunking token representations and CNN layers, making it compatible with any\npre-trained BERT. We evaluate chunkBERT exclusively on a benchmark for\ncomparing long-text classification models across a variety of tasks (including\nbinary classification, multi-class classification, and multi-label\nclassification). A BERT model finetuned using the ChunkBERT method performs\nconsistently across long samples in the benchmark while utilizing only a\nfraction (6.25\\%) of the original memory footprint. These findings suggest that\nefficient finetuning and inference can be achieved through simple modifications\nto pre-trained BERT models.",
            "author": [
                "Aman Jaiswal",
                "Evangelos Milios"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20558v1",
                "http://arxiv.org/pdf/2310.20558v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20550v2",
            "title": "CapsFusion: Rethinking Image-Text Data at Scale",
            "updated": "2023-11-02T11:25:20Z",
            "published": "2023-10-31T15:31:39Z",
            "summary": "Large multimodal models demonstrate remarkable generalist ability to perform\ndiverse multimodal tasks in a zero-shot manner. Large-scale web-based\nimage-text pairs contribute fundamentally to this success, but suffer from\nexcessive noise. Recent studies use alternative captions synthesized by\ncaptioning models and have achieved notable benchmark performance. However, our\nexperiments reveal significant Scalability Deficiency and World Knowledge Loss\nissues in models trained with synthetic captions, which have been largely\nobscured by their initial benchmark success. Upon closer examination, we\nidentify the root cause as the overly-simplified language structure and lack of\nknowledge details in existing synthetic captions. To provide higher-quality and\nmore scalable multimodal pretraining data, we propose CapsFusion, an advanced\nframework that leverages large language models to consolidate and refine\ninformation from both web-based image-text pairs and synthetic captions.\nExtensive experiments show that CapsFusion captions exhibit remarkable\nall-round superiority over existing captions in terms of model performance\n(e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample\nefficiency (requiring 11-16 times less computation than baselines), world\nknowledge depth, and scalability. These effectiveness, efficiency and\nscalability advantages position CapsFusion as a promising candidate for future\nscaling of LMM training.",
            "author": [
                "Qiying Yu",
                "Quan Sun",
                "Xiaosong Zhang",
                "Yufeng Cui",
                "Fan Zhang",
                "Yue Cao",
                "Xinlong Wang",
                "Jingjing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20550v2",
                "http://arxiv.org/pdf/2310.20550v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20549v1",
            "title": "Taweret: a Python package for Bayesian model mixing",
            "updated": "2023-10-31T15:30:36Z",
            "published": "2023-10-31T15:30:36Z",
            "summary": "Uncertainty quantification using Bayesian methods is a growing area of\nresearch. Bayesian model mixing (BMM) is a recent development which combines\nthe predictions from multiple models such that each model's best qualities are\npreserved in the final result. Practical tools and analysis suites that\nfacilitate such methods are therefore needed. Taweret introduces BMM to\nexisting Bayesian uncertainty quantification efforts. Currently Taweret\ncontains three individual Bayesian model mixing techniques, each pertaining to\na different type of problem structure; we encourage the future inclusion of\nuser-developed mixing methods. Taweret's first use case is in nuclear physics,\nbut the package has been structured such that it should be adaptable to any\nresearch engaged in model comparison or model mixing.",
            "author": [
                "Kevin Ingles",
                "Dananjaya Liyanage",
                "Alexandra C. Semposki",
                "John C. Yannotty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20549v1",
                "http://arxiv.org/pdf/2310.20549v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "physics.data-an",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20544v1",
            "title": "Information-theoretic causality and applications to turbulence: energy\n  cascade and inner/outer layer interactions",
            "updated": "2023-10-31T15:26:18Z",
            "published": "2023-10-31T15:26:18Z",
            "summary": "We introduce an information-theoretic method for quantifying causality in\nchaotic systems. The approach, referred to as IT-causality, quantifies\ncausality by measuring the information gained about future events conditioned\non the knowledge of past events. The causal interactions are classified into\nredundant, unique, and synergistic contributions depending on their nature. The\nformulation is non-intrusive, invariance under invertible transformations of\nthe variables, and provides the missing causality due to unobserved variables.\nThe method only requires pairs of past-future events of the quantities of\ninterest, making it convenient for both computational simulations and\nexperimental investigations. IT-causality is validated in four scenarios\nrepresenting basic causal interactions among variables: mediator, confounder,\nredundant collider, and synergistic collider. The approach is leveraged to\naddress two questions relevant to turbulence research: i) the scale locality of\nthe energy cascade in isotropic turbulence, and ii) the interactions between\ninner and outer layer flow motions in wall-bounded turbulence. In the former\ncase, we demonstrate that causality in the energy cascade flows sequentially\nfrom larger to smaller scales without requiring intermediate scales.\nConversely, the flow of information from small to large scales is shown to be\nredundant. In the second problem, we observe a unidirectional causality flow,\nwith causality predominantly originating from the outer layer and propagating\ntowards the inner layer, but not vice versa. The decomposition of IT-causality\ninto intensities also reveals that the causality is primarily associated with\nhigh-velocity streaks.",
            "author": [
                "Adri\u00e1n Lozano-Dur\u00e1n",
                "Gonzalo Arranz",
                "Yuenong Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20544v1",
                "http://arxiv.org/pdf/2310.20544v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.IT",
                "math.IT",
                "nlin.CD",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20539v1",
            "title": "The Computational Lens: from Quantum Physics to Neuroscience",
            "updated": "2023-10-31T15:21:22Z",
            "published": "2023-10-31T15:21:22Z",
            "summary": "Two transformative waves of computing have redefined the way we approach\nscience. The first wave came with the birth of the digital computer, which\nenabled scientists to numerically simulate their models and analyze massive\ndatasets. This technological breakthrough led to the emergence of many\nsub-disciplines bearing the prefix \"computational\" in their names. Currently,\nwe are in the midst of the second wave, marked by the remarkable advancements\nin artificial intelligence. From predicting protein structures to classifying\ngalaxies, the scope of its applications is vast, and there can only be more\nawaiting us on the horizon.\n  While these two waves influence scientific methodology at the instrumental\nlevel, in this dissertation, I will present the computational lens in science,\naiming at the conceptual level. Specifically, the central thesis posits that\ncomputation serves as a convenient and mechanistic language for understanding\nand analyzing information processing systems, offering the advantages of\ncomposability and modularity.\n  This dissertation begins with an illustration of the blueprint of the\ncomputational lens, supported by a review of relevant previous work.\nSubsequently, I will present my own works in quantum physics and neuroscience\nas concrete examples. In the concluding chapter, I will contemplate the\npotential of applying the computational lens across various scientific fields,\nin a way that can provide significant domain insights, and discuss potential\nfuture directions.",
            "author": [
                "Chi-Ning Chou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20539v1",
                "http://arxiv.org/pdf/2310.20539v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "q-bio.NC",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20525v1",
            "title": "Extracting spectral properties of small Holstein polarons from a\n  transmon-based analog quantum simulator",
            "updated": "2023-10-31T15:06:22Z",
            "published": "2023-10-31T15:06:22Z",
            "summary": "The Holstein model, which describes purely local coupling of an itinerant\nexcitation (electron, hole, exciton) with zero-dimensional (dispersionless)\nphonons, represents the paradigm for short-range excitation-phonon\ninteractions. It is demonstrated here how spectral properties of small Holstein\npolarons -- heavily phonon-dressed quasiparticles, formed in the\nstrong-coupling regime of the Holstein model -- can be extracted from an analog\nquantum simulator of this model. This simulator, which is meant to operate in\nthe dispersive regime of circuit quantum electrodynamics, has the form of an\narray of capacitively coupled superconducting transmon qubits and microwave\nresonators, the latter being subject to a weak external driving. The magnitude\nof $XY$-type coupling between adjacent qubits in this system can be tuned\nthrough an external flux threading the SQUID loops between those qubits; this\ntranslates into an {\\em in-situ} flux-tunable hopping amplitude of a fictitious\nitinerant spinless-fermion excitation, allowing one to access all the relevant\nphysical regimes of the Holstein model. By employing the kernel-polynomial\nmethod, based on expanding dynamical response functions in Chebyshev\npolynomials of the first kind and their recurrence relation, the relevant\nsingle-particle momentum-frequency resolved spectral function of this system is\ncomputed here for a broad range of parameter values. To complement the\nevaluation of the spectral function, it is also explained how -- by making use\nof the many-body version of the Ramsey interference protocol -- this\ndynamical-response function can be measured in the envisioned analog simulator.",
            "author": [
                "Vladimir M. Stojanovic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20525v1",
                "http://arxiv.org/pdf/2310.20525v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20519v1",
            "title": "Enhancing Graph Neural Networks with Quantum Computed Encodings",
            "updated": "2023-10-31T14:56:52Z",
            "published": "2023-10-31T14:56:52Z",
            "summary": "Transformers are increasingly employed for graph data, demonstrating\ncompetitive performance in diverse tasks. To incorporate graph information into\nthese models, it is essential to enhance node and edge features with positional\nencodings. In this work, we propose novel families of positional encodings\ntailored for graph transformers. These encodings leverage the long-range\ncorrelations inherent in quantum systems, which arise from mapping the topology\nof a graph onto interactions between qubits in a quantum computer. Our\ninspiration stems from the recent advancements in quantum processing units,\nwhich offer computational capabilities beyond the reach of classical hardware.\nWe prove that some of these quantum features are theoretically more expressive\nfor certain graphs than the commonly used relative random walk probabilities.\nEmpirically, we show that the performance of state-of-the-art models can be\nimproved on standard benchmarks and large-scale datasets by computing tractable\nversions of quantum features. Our findings highlight the potential of\nleveraging quantum computing capabilities to potentially enhance the\nperformance of transformers in handling graph data.",
            "author": [
                "Slimane Thabet",
                "Romain Fouilland",
                "Mehdi Djellabi",
                "Igor Sokolov",
                "Sachin Kasture",
                "Louis-Paul Henry",
                "Lo\u00efc Henriet"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20519v1",
                "http://arxiv.org/pdf/2310.20519v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20518v1",
            "title": "Improving RRT for Automated Parking in Real-world Scenarios",
            "updated": "2023-10-31T14:56:51Z",
            "published": "2023-10-31T14:56:51Z",
            "summary": "Automated parking is a self-driving feature that has been in cars for several\nyears. Parking assistants in currently sold cars fail to park in more complex\nreal-world scenarios and require the driver to move the car to an expected\nstarting position before the assistant is activated. We overcome these\nlimitations by proposing a planning algorithm consisting of two stages: (1) a\ngeometric planner for maneuvering inside the parking slot and (2) a\nRapidly-exploring Random Trees (RRT)-based planner that finds a collision-free\npath from the initial position to the slot entry. Evaluation of computational\nexperiments demonstrates that improvements over commonly used RRT extensions\nreduce the parking path cost by 21 % and reduce the computation time by 79.5 %.\nThe suitability of the algorithm for real-world parking scenarios was verified\nin physical experiments with Porsche Cayenne.",
            "author": [
                "Jiri Vlasak",
                "Michal Sojka",
                "Zden\u011bk Hanz\u00e1lek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20518v1",
                "http://arxiv.org/pdf/2310.20518v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20516v1",
            "title": "A systematic approach to correlators in $T\\bar{T}$ deformed CFTs",
            "updated": "2023-10-31T14:56:14Z",
            "published": "2023-10-31T14:56:14Z",
            "summary": "We investigate higher-order corrections to correlators in a general CFT with\nthe double trace $T\\bar{T}$ deformation. Traditional perturbation theory proves\ninadequate for addressing this issue, due to the intricate stress tensor flow\ninduced by the deformation. To tackle this challenge, we introduce a novel\ntechnique termed the conservation equation method. This method leverages the\ntrace relation and conservation property of the stress tensor to establish\nrelationships between higher and lower-order corrections and subsequently\ndetermine the correlators by enforcing symmetry properties. As an illustration,\nwe compute both first and higher-order corrections, demonstrating the impact of\nstress tensor deformation on correlators in a general deformed CFT. Our results\nalign with existing calculations in the literature.",
            "author": [
                "Song He",
                "Yuan Sun",
                "Jiashi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20516v1",
                "http://arxiv.org/pdf/2310.20516v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20514v1",
            "title": "Analytic decay width of the Higgs boson to massive bottom quarks at\n  next-to-next-to-leading order in QCD",
            "updated": "2023-10-31T14:55:53Z",
            "published": "2023-10-31T14:55:53Z",
            "summary": "The Higgs boson decay to a massive bottom quark pair provides the dominant\ncontribution to the Higgs boson width. We present an exact result for such a\ndecay induced by the bottom quark Yukawa coupling with next-to-next-to-leading\norder (NNLO) QCD corrections. We have adopted the canonical differential\nequations in the calculation and obtained the result in terms of multiple\npolylogarithms. We also compute the contribution from the decay to four bottom\nquarks which consist of complete elliptic integrals or their one-fold\nintegrals. The small bottom quark mass limit coincides with the previous\ncalculation using the large momentum expansion. The threshold expansion\nexhibits power divergent terms in the bottom quark velocity, which has a\nstructure different from that in $e^+e^-\\to t\\bar{t}$ but can be reproduced by\ncomputing the corresponding Coulomb Green function. The NNLO corrections\nsignificantly reduce the uncertainties from both the renormalization scale and\nthe renormalization scheme of the bottom quark Yukawa coupling. Our result can\nbe applied to a heavy scalar decay to a top quark pair.",
            "author": [
                "Jian Wang",
                "Yefan Wang",
                "Da-Jiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20514v1",
                "http://arxiv.org/pdf/2310.20514v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20508v1",
            "title": "Parametric Fairness with Statistical Guarantees",
            "updated": "2023-10-31T14:52:39Z",
            "published": "2023-10-31T14:52:39Z",
            "summary": "Algorithmic fairness has gained prominence due to societal and regulatory\nconcerns about biases in Machine Learning models. Common group fairness metrics\nlike Equalized Odds for classification or Demographic Parity for both\nclassification and regression are widely used and a host of computationally\nadvantageous post-processing methods have been developed around them. However,\nthese metrics often limit users from incorporating domain knowledge. Despite\nmeeting traditional fairness criteria, they can obscure issues related to\nintersectional fairness and even replicate unwanted intra-group biases in the\nresulting fair solution. To avoid this narrow perspective, we extend the\nconcept of Demographic Parity to incorporate distributional properties in the\npredictions, allowing expert knowledge to be used in the fair solution. We\nillustrate the use of this new metric through a practical example of wages, and\ndevelop a parametric method that efficiently addresses practical challenges\nlike limited training data and constraints on total spending, offering a robust\nsolution for real-life applications.",
            "author": [
                "Fran\u00e7ois HU",
                "Philipp Ratz",
                "Arthur Charpentier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20508v1",
                "http://arxiv.org/pdf/2310.20508v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20504v1",
            "title": "SumComp: Coding for Digital Over-the-Air Computation via the Ring of\n  Integers",
            "updated": "2023-10-31T14:46:47Z",
            "published": "2023-10-31T14:46:47Z",
            "summary": "Communication and computation are traditionally treated as separate entities,\nallowing for individual optimizations. However, many applications focus on\nlocal information's functionality rather than the information itself. For such\ncases, harnessing interference for computation in a multiple access channel\nthrough digital over-the-air computation can notably increase the computation,\nas established by the ChannelComp method. However, the coding scheme originally\nproposed in ChannelComp may suffer from high computational complexity because\nit is general and is not optimized for specific modulation categories.\nTherefore, this study considers a specific category of digital modulations for\nover-the-air computations, QAM and PAM, for which we introduce a novel coding\nscheme called SumComp. Furthermore, we derive an MSE analysis for SumComp\ncoding in the computation of the arithmetic mean function and establish an\nupper bound on the MAE for a set of nomographic functions. Simulation results\naffirm the superior performance of SumComp coding compared to traditional\nanalog over-the-air computation and the original coding in ChannelComp\napproaches regarding both MSE and MAE over a noisy multiple access channel.\nSpecifically, SumComp coding shows approximately $10$ dB improvements for\ncomputing arithmetic and geometric mean on the normalized MSE for low noise\nscenarios.",
            "author": [
                "Saeed Razavikia",
                "Jos\u00e9 Mairton Barros Da Silva J\u00fanior",
                "Carlo Fischione"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20504v1",
                "http://arxiv.org/pdf/2310.20504v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20501v1",
            "title": "LLMs may Dominate Information Access: Neural Retrievers are Biased\n  Towards LLM-Generated Texts",
            "updated": "2023-10-31T14:42:23Z",
            "published": "2023-10-31T14:42:23Z",
            "summary": "Recently, the emergence of large language models (LLMs) has revolutionized\nthe paradigm of information retrieval (IR) applications, especially in web\nsearch. With their remarkable capabilities in generating human-like texts, LLMs\nhave created enormous texts on the Internet. As a result, IR systems in the\nLLMs era are facing a new challenge: the indexed documents now are not only\nwritten by human beings but also automatically generated by the LLMs. How these\nLLM-generated documents influence the IR systems is a pressing and still\nunexplored question. In this work, we conduct a quantitative evaluation of\ndifferent IR models in scenarios where both human-written and LLM-generated\ntexts are involved. Surprisingly, our findings indicate that neural retrieval\nmodels tend to rank LLM-generated documents higher.We refer to this category of\nbiases in neural retrieval models towards the LLM-generated text as the\n\\textbf{source bias}. Moreover, we discover that this bias is not confined to\nthe first-stage neural retrievers, but extends to the second-stage neural\nre-rankers. Then, we provide an in-depth analysis from the perspective of text\ncompression and observe that neural models can better understand the semantic\ninformation of LLM-generated text, which is further substantiated by our\ntheoretical analysis.We also discuss the potential server concerns stemming\nfrom the observed source bias and hope our findings can serve as a critical\nwake-up call to the IR community and beyond. To facilitate future explorations\nof IR in the LLM era, the constructed two new benchmarks and codes will later\nbe available at \\url{https://github.com/KID-22/LLM4IR-Bias}.",
            "author": [
                "Sunhao Dai",
                "Yuqi Zhou",
                "Liang Pang",
                "Weihao Liu",
                "Xiaolin Hu",
                "Yong Liu",
                "Xiao Zhang",
                "Jun Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20501v1",
                "http://arxiv.org/pdf/2310.20501v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20499v2",
            "title": "Leveraging Word Guessing Games to Assess the Intelligence of Large\n  Language Models",
            "updated": "2023-11-06T02:27:34Z",
            "published": "2023-10-31T14:37:42Z",
            "summary": "The automatic evaluation of LLM-based agent intelligence is critical in\ndeveloping advanced LLM-based agents. Although considerable effort has been\ndevoted to developing human-annotated evaluation datasets, such as AlpacaEval,\nexisting techniques are costly, time-consuming, and lack adaptability. In this\npaper, inspired by the popular language game ``Who is Spy'', we propose to use\nthe word guessing game to assess the intelligence performance of LLMs. Given a\nword, the LLM is asked to describe the word and determine its identity (spy or\nnot) based on its and other players' descriptions. Ideally, an advanced agent\nshould possess the ability to accurately describe a given word using an\naggressive description while concurrently maximizing confusion in the\nconservative description, enhancing its participation in the game. To this end,\nwe first develop DEEP to evaluate LLMs' expression and disguising abilities.\nDEEP requires LLM to describe a word in aggressive and conservative modes. We\nthen introduce SpyGame, an interactive multi-agent framework designed to assess\nLLMs' intelligence through participation in a competitive language-based board\ngame. Incorporating multi-agent interaction, SpyGame requires the target LLM to\npossess linguistic skills and strategic thinking, providing a more\ncomprehensive evaluation of LLMs' human-like cognitive abilities and\nadaptability in complex communication situations. The proposed evaluation\nframework is very easy to implement. We collected words from multiple sources,\ndomains, and languages and used the proposed evaluation framework to conduct\nexperiments. Extensive experiments demonstrate that the proposed DEEP and\nSpyGame effectively evaluate the capabilities of various LLMs, capturing their\nability to adapt to novel situations and engage in strategic communication.",
            "author": [
                "Tian Liang",
                "Zhiwei He",
                "Jen-tse Huang",
                "Wenxuan Wang",
                "Wenxiang Jiao",
                "Rui Wang",
                "Yujiu Yang",
                "Zhaopeng Tu",
                "Shuming Shi",
                "Xing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20499v2",
                "http://arxiv.org/pdf/2310.20499v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20498v1",
            "title": "Generative Learning of Continuous Data by Tensor Networks",
            "updated": "2023-10-31T14:37:37Z",
            "published": "2023-10-31T14:37:37Z",
            "summary": "Beyond their origin in modeling many-body quantum systems, tensor networks\nhave emerged as a promising class of models for solving machine learning\nproblems, notably in unsupervised generative learning. While possessing many\ndesirable features arising from their quantum-inspired nature, tensor network\ngenerative models have previously been largely restricted to binary or\ncategorical data, limiting their utility in real-world modeling problems. We\novercome this by introducing a new family of tensor network generative models\nfor continuous data, which are capable of learning from distributions\ncontaining continuous random variables. We develop our method in the setting of\nmatrix product states, first deriving a universal expressivity theorem proving\nthe ability of this model family to approximate any reasonably smooth\nprobability density function with arbitrary precision. We then benchmark the\nperformance of this model on several synthetic and real-world datasets, finding\nthat the model learns and generalizes well on distributions of continuous and\ndiscrete variables. We develop methods for modeling different data domains, and\nintroduce a trainable compression layer which is found to increase model\nperformance given limited memory or computational resources. Overall, our\nmethods give important theoretical and empirical evidence of the efficacy of\nquantum-inspired methods for the rapidly growing field of generative learning.",
            "author": [
                "Alex Meiburg",
                "Jing Chen",
                "Jacob Miller",
                "Rapha\u00eblle Tihon",
                "Guillaume Rabusseau",
                "Alejandro Perdomo-Ortiz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20498v1",
                "http://arxiv.org/pdf/2310.20498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.stat-mech",
                "quant-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20490v2",
            "title": "Long-Tailed Learning as Multi-Objective Optimization",
            "updated": "2023-11-01T11:28:55Z",
            "published": "2023-10-31T14:30:31Z",
            "summary": "Real-world data is extremely imbalanced and presents a long-tailed\ndistribution, resulting in models that are biased towards classes with\nsufficient samples and perform poorly on rare classes. Recent methods propose\nto rebalance classes but they undertake the seesaw dilemma (what is increasing\nperformance on tail classes may decrease that of head classes, and vice versa).\nIn this paper, we argue that the seesaw dilemma is derived from gradient\nimbalance of different classes, in which gradients of inappropriate classes are\nset to important for updating, thus are prone to overcompensation or\nundercompensation on tail classes. To achieve ideal compensation, we formulate\nthe long-tailed recognition as an multi-objective optimization problem, which\nfairly respects the contributions of head and tail classes simultaneously. For\nefficiency, we propose a Gradient-Balancing Grouping (GBG) strategy to gather\nthe classes with similar gradient directions, thus approximately make every\nupdate under a Pareto descent direction. Our GBG method drives classes with\nsimilar gradient directions to form more representative gradient and provide\nideal compensation to the tail classes. Moreover, We conduct extensive\nexperiments on commonly used benchmarks in long-tailed learning and demonstrate\nthe superiority of our method over existing SOTA methods.",
            "author": [
                "Weiqi Li",
                "Fan Lyu",
                "Fanhua Shang",
                "Liang Wan",
                "Wei Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20490v2",
                "http://arxiv.org/pdf/2310.20490v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20488v1",
            "title": "NaijaCoder: Participatory Design for Early Algorithms Education in the\n  Global South",
            "updated": "2023-10-31T14:28:51Z",
            "published": "2023-10-31T14:28:51Z",
            "summary": "The majority of Nigerian high schoolers have little to no exposure to the\nbasics of algorithms and programming. We believe this trajectory should change\nas programming offers these students, especially those from indigent\nbackgrounds, an opportunity to learn profitable skills and ignite their\npassions for problem-solving and critical thinking.\n  NaijaCoder is an organization that is dedicated to organizing a free,\nintensive summer program in Nigeria to teach the basics of algorithms and\ncomputer programming to high schoolers. However, the adoption of computer\nscience curriculum has been especially challenging in countries in the global\nsouth that face unique challenges -- such as unstable power supply, internet\nservice, and price volatility. We design a curriculum that is more conducive to\nthe local environment while incorporating rigorous thinking and preparation.\nUsing basic survey designs, we elicit feedback, from the students, designed to\nfurther improve and iterate on our curriculum.",
            "author": [
                "Daniel Alabi",
                "Atinuke Adegbile",
                "Lekan Afuye",
                "Philip Abel",
                "Alida Monaco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20488v1",
                "http://arxiv.org/pdf/2310.20488v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20479v1",
            "title": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
            "updated": "2023-10-31T14:12:07Z",
            "published": "2023-10-31T14:12:07Z",
            "summary": "While most task-oriented dialogues assume conversations between the agent and\none user at a time, dialogue systems are increasingly expected to communicate\nwith multiple users simultaneously who make decisions collaboratively. To\nfacilitate development of such systems, we release the Multi-User MultiWOZ\ndataset: task-oriented dialogues among two users and one agent. To collect this\ndataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat\nbetween two users that is semantically and pragmatically consistent with the\noriginal user utterance, thus resulting in the same dialogue state and system\nresponse. These dialogues reflect interesting dynamics of collaborative\ndecision-making in task-oriented scenarios, e.g., social chatter and\ndeliberation. Supported by this data, we propose the novel task of multi-user\ncontextual query rewriting: to rewrite a task-oriented chat between two users\nas a concise task-oriented query that retains only task-relevant information\nand that is directly consumable by the dialogue system. We demonstrate that in\nmulti-user dialogues, using predicted rewrites substantially improves dialogue\nstate tracking without modifying existing dialogue systems that are trained for\nsingle-user dialogues. Further, this method surpasses training a medium-sized\nmodel directly on multi-user dialogues and generalizes to unseen domains.",
            "author": [
                "Yohan Jo",
                "Xinyan Zhao",
                "Arijit Biswas",
                "Nikoletta Basiou",
                "Vincent Auvray",
                "Nikolaos Malandrakis",
                "Angeliki Metallinou",
                "Alexandros Potamianos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20479v1",
                "http://arxiv.org/pdf/2310.20479v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20470v1",
            "title": "Representativeness as a Forgotten Lesson for Multilingual and\n  Code-switched Data Collection and Preparation",
            "updated": "2023-10-31T14:04:07Z",
            "published": "2023-10-31T14:04:07Z",
            "summary": "Multilingualism is widespread around the world and code-switching (CSW) is a\ncommon practice among different language pairs/tuples across locations and\nregions. However, there is still not much progress in building successful CSW\nsystems, despite the recent advances in Massive Multilingual Language Models\n(MMLMs). We investigate the reasons behind this setback through a critical\nstudy about the existing CSW data sets (68) across language pairs in terms of\nthe collection and preparation (e.g. transcription and annotation) stages. This\nin-depth analysis reveals that \\textbf{a)} most CSW data involves English\nignoring other language pairs/tuples \\textbf{b)} there are flaws in terms of\nrepresentativeness in data collection and preparation stages due to ignoring\nthe location based, socio-demographic and register variation in CSW. In\naddition, lack of clarity on the data selection and filtering stages shadow the\nrepresentativeness of CSW data sets. We conclude by providing a short\ncheck-list to improve the representativeness for forthcoming studies involving\nCSW data collection and preparation.",
            "author": [
                "A. Seza Do\u011fru\u00f6z",
                "Sunayana Sitaram",
                "Zheng-Xin Yong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20470v1",
                "http://arxiv.org/pdf/2310.20470v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20467v1",
            "title": "ACL Anthology Helper: A Tool to Retrieve and Manage Literature from ACL\n  Anthology",
            "updated": "2023-10-31T13:59:05Z",
            "published": "2023-10-31T13:59:05Z",
            "summary": "The ACL Anthology is an online repository that serves as a comprehensive\ncollection of publications in the field of natural language processing (NLP)\nand computational linguistics (CL). This paper presents a tool called ``ACL\nAnthology Helper''. It automates the process of parsing and downloading papers\nalong with their meta-information, which are then stored in a local MySQL\ndatabase. This allows for efficient management of the local papers using a wide\nrange of operations, including \"where,\" \"group,\" \"order,\" and more. By\nproviding over 20 operations, this tool significantly enhances the retrieval of\nliterature based on specific conditions. Notably, this tool has been\nsuccessfully utilised in writing a survey paper (Tang et al.,2022a). By\nintroducing the ACL Anthology Helper, we aim to enhance researchers' ability to\neffectively access and organise literature from the ACL Anthology. This tool\noffers a convenient solution for researchers seeking to explore the ACL\nAnthology's vast collection of publications while allowing for more targeted\nand efficient literature retrieval.",
            "author": [
                "Chen Tang",
                "Frank Guerin",
                "Chenghua Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20467v1",
                "http://arxiv.org/pdf/2310.20467v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20463v2",
            "title": "Interpretable Neural PDE Solvers using Symbolic Frameworks",
            "updated": "2023-11-10T12:15:33Z",
            "published": "2023-10-31T13:56:25Z",
            "summary": "Partial differential equations (PDEs) are ubiquitous in the world around us,\nmodelling phenomena from heat and sound to quantum systems. Recent advances in\ndeep learning have resulted in the development of powerful neural solvers;\nhowever, while these methods have demonstrated state-of-the-art performance in\nboth accuracy and computational efficiency, a significant challenge remains in\ntheir interpretability. Most existing methodologies prioritize predictive\naccuracy over clarity in the underlying mechanisms driving the model's\ndecisions. Interpretability is crucial for trustworthiness and broader\napplicability, especially in scientific and engineering domains where neural\nPDE solvers might see the most impact. In this context, a notable gap in\ncurrent research is the integration of symbolic frameworks (such as symbolic\nregression) into these solvers. Symbolic frameworks have the potential to\ndistill complex neural operations into human-readable mathematical expressions,\nbridging the divide between black-box predictions and solutions.",
            "author": [
                "Yolanne Yi Ran Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20463v2",
                "http://arxiv.org/pdf/2310.20463v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20457v2",
            "title": "FlexTrain: A Dynamic Training Framework for Heterogeneous Devices\n  Environments",
            "updated": "2023-11-23T09:58:55Z",
            "published": "2023-10-31T13:51:13Z",
            "summary": "As deep learning models become increasingly large, they pose significant\nchallenges in heterogeneous devices environments. The size of deep learning\nmodels makes it difficult to deploy them on low-power or resource-constrained\ndevices, leading to long inference times and high energy consumption. To\naddress these challenges, we propose FlexTrain, a framework that accommodates\nthe diverse storage and computational resources available on different devices\nduring the training phase. FlexTrain enables efficient deployment of deep\nlearning models, while respecting device constraints, minimizing communication\ncosts, and ensuring seamless integration with diverse devices. We demonstrate\nthe effectiveness of FlexTrain on the CIFAR-100 dataset, where a single global\nmodel trained with FlexTrain can be easily deployed on heterogeneous devices,\nsaving training time and energy consumption. We also extend FlexTrain to the\nfederated learning setting, showing that our approach outperforms standard\nfederated learning benchmarks on both CIFAR-10 and CIFAR-100 datasets.",
            "author": [
                "Mert Unsal",
                "Ali Maatouk",
                "Antonio De Domenico",
                "Nicola Piovesan",
                "Fadhel Ayed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20457v2",
                "http://arxiv.org/pdf/2310.20457v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20456v1",
            "title": "Towards a Deep Understanding of Multilingual End-to-End Speech\n  Translation",
            "updated": "2023-10-31T13:50:55Z",
            "published": "2023-10-31T13:50:55Z",
            "summary": "In this paper, we employ Singular Value Canonical Correlation Analysis\n(SVCCA) to analyze representations learnt in a multilingual end-to-end speech\ntranslation model trained over 22 languages. SVCCA enables us to estimate\nrepresentational similarity across languages and layers, enhancing our\nunderstanding of the functionality of multilingual speech translation and its\npotential connection to multilingual neural machine translation. The\nmultilingual speech translation model is trained on the CoVoST 2 dataset in all\npossible directions, and we utilize LASER to extract parallel bitext data for\nSVCCA analysis. We derive three major findings from our analysis: (I)\nLinguistic similarity loses its efficacy in multilingual speech translation\nwhen the training data for a specific language is limited. (II) Enhanced\nencoder representations and well-aligned audio-text data significantly improve\ntranslation quality, surpassing the bilingual counterparts when the training\ndata is not compromised. (III) The encoder representations of multilingual\nspeech translation demonstrate superior performance in predicting phonetic\nfeatures in linguistic typology prediction. With these findings, we propose\nthat releasing the constraint of limited data for low-resource languages and\nsubsequently combining them with linguistically related high-resource languages\ncould offer a more effective approach for multilingual end-to-end speech\ntranslation.",
            "author": [
                "Haoran Sun",
                "Xiaohu Zhao",
                "Yikun Lei",
                "Shaolin Zhu",
                "Deyi Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20456v1",
                "http://arxiv.org/pdf/2310.20456v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20455v1",
            "title": "Simple cuspidal representations of symplectic groups: Langlands\n  parameter",
            "updated": "2023-10-31T13:50:27Z",
            "published": "2023-10-31T13:50:27Z",
            "summary": "Let $F$ be a non-archimedean local field of odd residual characteristic. We\ncompute the Jordan set of a simple cuspidal representation of a symplectic\ngroup over $F$, using explicit computations of generators of the Hecke algebras\nof covers reflecting the parabolic induction under study. When $F$ is a\n$p$-adic field we obtain the Langlands parameter of the representation.",
            "author": [
                "Corinne Blondel",
                "Guy Henniart",
                "Shaun Stevens"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20455v1",
                "http://arxiv.org/pdf/2310.20455v1"
            ],
            "primary_category": "math.RT",
            "category": [
                "math.RT",
                "math.NT",
                "22E50, 11F70"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20452v1",
            "title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms",
            "updated": "2023-10-31T13:44:53Z",
            "published": "2023-10-31T13:44:53Z",
            "summary": "We analyze asynchronous-type algorithms for distributed SGD in the\nheterogeneous setting, where each worker has its own computation and\ncommunication speeds, as well as data distribution. In these algorithms,\nworkers compute possibly stale and stochastic gradients associated with their\nlocal data at some iteration back in history and then return those gradients to\nthe server without synchronizing with other workers. We present a unified\nconvergence theory for non-convex smooth functions in the heterogeneous regime.\nThe proposed analysis provides convergence for pure asynchronous SGD and its\nvarious modifications. Moreover, our theory explains what affects the\nconvergence rate and what can be done to improve the performance of\nasynchronous algorithms. In particular, we introduce a novel asynchronous\nmethod based on worker shuffling. As a by-product of our analysis, we also\ndemonstrate convergence guarantees for gradient-type algorithms such as SGD\nwith random reshuffling and shuffle-once mini-batch SGD. The derived rates\nmatch the best-known results for those algorithms, highlighting the tightness\nof our approach. Finally, our numerical evaluations support theoretical\nfindings and show the good practical performance of our method.",
            "author": [
                "Rustem Islamov",
                "Mher Safaryan",
                "Dan Alistarh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20452v1",
                "http://arxiv.org/pdf/2310.20452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20446v1",
            "title": "LAVSS: Location-Guided Audio-Visual Spatial Audio Separation",
            "updated": "2023-10-31T13:30:24Z",
            "published": "2023-10-31T13:30:24Z",
            "summary": "Existing machine learning research has achieved promising results in monaural\naudio-visual separation (MAVS). However, most MAVS methods purely consider what\nthe sound source is, not where it is located. This can be a problem in VR/AR\nscenarios, where listeners need to be able to distinguish between similar audio\nsources located in different directions. To address this limitation, we have\ngeneralized MAVS to spatial audio separation and proposed LAVSS: a\nlocation-guided audio-visual spatial audio separator. LAVSS is inspired by the\ncorrelation between spatial audio and visual location. We introduce the phase\ndifference carried by binaural audio as spatial cues, and we utilize positional\nrepresentations of sounding objects as additional modality guidance. We also\nleverage multi-level cross-modal attention to perform visual-positional\ncollaboration with audio features. In addition, we adopt a pre-trained monaural\nseparator to transfer knowledge from rich mono sounds to boost spatial audio\nseparation. This exploits the correlation between monaural and binaural\nchannels. Experiments on the FAIR-Play dataset demonstrate the superiority of\nthe proposed LAVSS over existing benchmarks of audio-visual separation. Our\nproject page: https://yyx666660.github.io/LAVSS/.",
            "author": [
                "Yuxin Ye",
                "Wenming Yang",
                "Yapeng Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20446v1",
                "http://arxiv.org/pdf/2310.20446v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20440v1",
            "title": "The SourceData-NLP dataset: integrating curation into scientific\n  publishing for training large language models",
            "updated": "2023-10-31T13:22:38Z",
            "published": "2023-10-31T13:22:38Z",
            "summary": "Introduction: The scientific publishing landscape is expanding rapidly,\ncreating challenges for researchers to stay up-to-date with the evolution of\nthe literature. Natural Language Processing (NLP) has emerged as a potent\napproach to automating knowledge extraction from this vast amount of\npublications and preprints. Tasks such as Named-Entity Recognition (NER) and\nNamed-Entity Linking (NEL), in conjunction with context-dependent semantic\ninterpretation, offer promising and complementary approaches to extracting\nstructured information and revealing key concepts.\n  Results: We present the SourceData-NLP dataset produced through the routine\ncuration of papers during the publication process. A unique feature of this\ndataset is its emphasis on the annotation of bioentities in figure legends. We\nannotate eight classes of biomedical entities (small molecules, gene products,\nsubcellular components, cell lines, cell types, tissues, organisms, and\ndiseases), their role in the experimental design, and the nature of the\nexperimental method as an additional class. SourceData-NLP contains more than\n620,000 annotated biomedical entities, curated from 18,689 figures in 3,223\npapers in molecular and cell biology. We illustrate the dataset's usefulness by\nassessing BioLinkBERT and PubmedBERT, two transformers-based models, fine-tuned\non the SourceData-NLP dataset for NER. We also introduce a novel\ncontext-dependent semantic task that infers whether an entity is the target of\na controlled intervention or the object of measurement.\n  Conclusions: SourceData-NLP's scale highlights the value of integrating\ncuration into publishing. Models trained with SourceData-NLP will furthermore\nenable the development of tools able to extract causal hypotheses from the\nliterature and assemble them into knowledge graphs.",
            "author": [
                "Jorge Abreu-Vicente",
                "Hannah Sonntag",
                "Thomas Eidens",
                "Thomas Lemberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20440v1",
                "http://arxiv.org/pdf/2310.20440v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20436v1",
            "title": "SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and\n  Benchmark",
            "updated": "2023-10-31T13:15:49Z",
            "published": "2023-10-31T13:15:49Z",
            "summary": "In this paper, we present SignAvatars, the first large-scale multi-prompt 3D\nsign language (SL) motion dataset designed to bridge the communication gap for\nhearing-impaired individuals. While there has been an exponentially growing\nnumber of research regarding digital communication, the majority of existing\ncommunication technologies primarily cater to spoken or written languages,\ninstead of SL, the essential communication method for hearing-impaired\ncommunities. Existing SL datasets, dictionaries, and sign language production\n(SLP) methods are typically limited to 2D as the annotating 3D models and\navatars for SL is usually an entirely manual and labor-intensive process\nconducted by SL experts, often resulting in unnatural avatars. In response to\nthese challenges, we compile and curate the SignAvatars dataset, which\ncomprises 70,000 videos from 153 signers, totaling 8.34 million frames,\ncovering both isolated signs and continuous, co-articulated signs, with\nmultiple prompts including HamNoSys, spoken language, and words. To yield 3D\nholistic annotations, including meshes and biomechanically-valid poses of body,\nhands, and face, as well as 2D and 3D keypoints, we introduce an automated\nannotation pipeline operating on our large corpus of SL videos. SignAvatars\nfacilitates various tasks such as 3D sign language recognition (SLR) and the\nnovel 3D SL production (SLP) from diverse inputs like text scripts, individual\nwords, and HamNoSys notation. Hence, to evaluate the potential of SignAvatars,\nwe further propose a unified benchmark of 3D SL holistic motion production. We\nbelieve that this work is a significant step forward towards bringing the\ndigital world to the hearing-impaired communities. Our project page is at\nhttps://signavatars.github.io/",
            "author": [
                "Zhengdi Yu",
                "Shaoli Huang",
                "Yongkang Cheng",
                "Tolga Birdal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20436v1",
                "http://arxiv.org/pdf/2310.20436v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20434v1",
            "title": "Rapid cryogenic characterisation of 1024 integrated silicon quantum dots",
            "updated": "2023-10-31T13:14:43Z",
            "published": "2023-10-31T13:14:43Z",
            "summary": "Quantum computers are nearing the thousand qubit mark, with the current focus\non scaling to improve computational performance. As quantum processors grow in\ncomplexity, new challenges arise such as the management of device variability\nand the interface with supporting electronics. Spin qubits in silicon quantum\ndots are poised to address these challenges with their proven control\nfidelities and potential for compatibility with large-scale integration. Here,\nwe demonstrate the integration of 1024 silicon quantum dots with on-chip\ndigital and analogue electronics, all operating below 1 K. A high-frequency\nanalogue multiplexer provides fast access to all devices with minimal\nelectrical connections, enabling characteristic data across the quantum dot\narray to be acquired in just 5 minutes. We achieve this by leveraging\nradio-frequency reflectometry with state-of-the-art signal integrity, reaching\na minimum integration time of 160 ps. Key quantum dot parameters are extracted\nby fast automated machine learning routines to assess quantum dot yield and\nunderstand the impact of device design. We find correlations between quantum\ndot parameters and room temperature transistor behaviour that may be used as a\nproxy for in-line process monitoring. Our results show how rapid large-scale\nstudies of silicon quantum devices can be performed at lower temperatures and\nmeasurement rates orders of magnitude faster than current probing techniques,\nand form a platform for the future on-chip addressing of large scale qubit\narrays.",
            "author": [
                "Edward J. Thomas",
                "Virginia N. Ciriano-Tejel",
                "David F. Wise",
                "Domenic Prete",
                "Mathieu de Kruijf",
                "David J. Ibberson",
                "Grayson M. Noah",
                "Alberto Gomez-Saiz",
                "M. Fernando Gonzalez-Zalba",
                "Mark A. I. Johnson",
                "John J. L. Morton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20434v1",
                "http://arxiv.org/pdf/2310.20434v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20435v1",
            "title": "Assessing the Sustainability and Trustworthiness of Federated Learning\n  Models",
            "updated": "2023-10-31T13:14:43Z",
            "published": "2023-10-31T13:14:43Z",
            "summary": "Artificial intelligence (AI) plays a pivotal role in various sectors,\ninfluencing critical decision-making processes in our daily lives. Within the\nAI landscape, novel AI paradigms, such as Federated Learning (FL), focus on\npreserving data privacy while collaboratively training AI models. In such a\ncontext, a group of experts from the European Commission (AI-HLEG) has\nidentified sustainable AI as one of the key elements that must be considered to\nprovide trustworthy AI. While existing literature offers several taxonomies and\nsolutions for assessing the trustworthiness of FL models, a significant gap\nexists in considering sustainability and the carbon footprint associated with\nFL. Thus, this work introduces the sustainability pillar to the most recent and\ncomprehensive trustworthy FL taxonomy, making this work the first to address\nall AI-HLEG requirements. The sustainability pillar assesses the FL system\nenvironmental impact, incorporating notions and metrics for hardware\nefficiency, federation complexity, and energy grid carbon intensity. Then, this\nwork designs and implements an algorithm for evaluating the trustworthiness of\nFL models by incorporating the sustainability pillar. Extensive evaluations\nwith the FederatedScope framework and various scenarios varying federation\nparticipants, complexities, hardware, and energy grids demonstrate the\nusefulness of the proposed solution.",
            "author": [
                "Alberto Huertas Celdran",
                "Chao Feng",
                "Pedro Miguel Sanchez Sanchez",
                "Lynn Zumtaugwald",
                "Gerome Bovet",
                "Burkhard Stiller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20435v1",
                "http://arxiv.org/pdf/2310.20435v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20432v1",
            "title": "Demonstration of a parity-time symmetry breaking phase transition using\n  superconducting and trapped-ion qutrits",
            "updated": "2023-10-31T13:10:43Z",
            "published": "2023-10-31T13:10:43Z",
            "summary": "Scalable quantum computers hold the promise to solve hard computational\nproblems, such as prime factorization, combinatorial optimization, simulation\nof many-body physics, and quantum chemistry. While being key to understanding\nmany real-world phenomena, simulation of non-conservative quantum dynamics\npresents a challenge for unitary quantum computation. In this work, we focus on\nsimulating non-unitary parity-time symmetric systems, which exhibit a\ndistinctive symmetry-breaking phase transition as well as other unique features\nthat have no counterpart in closed systems. We show that a qutrit, a\nthree-level quantum system, is capable of realizing this non-equilibrium phase\ntransition. By using two physical platforms - an array of trapped ions and a\nsuperconducting transmon - and by controlling their three energy levels in a\ndigital manner, we experimentally simulate the parity-time symmetry-breaking\nphase transition. Our results indicate the potential advantage of multi-level\n(qudit) processors in simulating physical effects, where additional accessible\nlevels can play the role of a controlled environment.",
            "author": [
                "Alena S. Kazmina",
                "Ilia V. Zalivako",
                "Alexander S. Borisenko",
                "Nikita A. Nemkov",
                "Anastasiia S. Nikolaeva",
                "Ilya A. Simakov",
                "Arina V. Kuznetsova",
                "Elena Yu. Egorova",
                "Kristina P. Galstyan",
                "Nikita V. Semenin",
                "Andrey E. Korolkov",
                "Ilya N. Moskalenko",
                "Nikolay N. Abramov",
                "Ilya S. Besedin",
                "Daria A. Kalacheva",
                "Viktor B. Lubsanov",
                "Aleksey N. Bolgar",
                "Evgeniy O. Kiktenko",
                "Ksenia Yu. Khabarova",
                "Alexey Galda",
                "Ilya A. Semerikov",
                "Nikolay N. Kolachevsky",
                "Nataliya Maleeva",
                "Aleksey K. Fedorov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20432v1",
                "http://arxiv.org/pdf/2310.20432v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20427v1",
            "title": "Assessing and Enhancing Robustness of Deep Learning Models with\n  Corruption Emulation in Digital Pathology",
            "updated": "2023-10-31T12:59:36Z",
            "published": "2023-10-31T12:59:36Z",
            "summary": "Deep learning in digital pathology brings intelligence and automation as\nsubstantial enhancements to pathological analysis, the gold standard of\nclinical diagnosis. However, multiple steps from tissue preparation to slide\nimaging introduce various image corruptions, making it difficult for deep\nneural network (DNN) models to achieve stable diagnostic results for clinical\nuse. In order to assess and further enhance the robustness of the models, we\nanalyze the physical causes of the full-stack corruptions throughout the\npathological life-cycle and propose an Omni-Corruption Emulation (OmniCE)\nmethod to reproduce 21 types of corruptions quantified with 5-level severity.\nWe then construct three OmniCE-corrupted benchmark datasets at both patch level\nand slide level and assess the robustness of popular DNNs in classification and\nsegmentation tasks. Further, we explore to use the OmniCE-corrupted datasets as\naugmentation data for training and experiments to verify that the\ngeneralization ability of the models has been significantly enhanced.",
            "author": [
                "Peixiang Huang",
                "Songtao Zhang",
                "Yulu Gan",
                "Rui Xu",
                "Rongqi Zhu",
                "Wenkang Qin",
                "Limei Guo",
                "Shan Jiang",
                "Lin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20427v1",
                "http://arxiv.org/pdf/2310.20427v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20426v1",
            "title": "Evolutionary Pareto Set Learning with Structure Constraints",
            "updated": "2023-10-31T12:53:56Z",
            "published": "2023-10-31T12:53:56Z",
            "summary": "The multiobjective evolutionary optimization algorithm (MOEA) is a powerful\napproach for tackling multiobjective optimization problems (MOPs), which can\nfind a finite set of approximate Pareto solutions in a single run. However,\nunder mild regularity conditions, the Pareto optimal set of a continuous MOP\ncould be a low dimensional continuous manifold that contains infinite\nsolutions. In addition, structure constraints on the whole optimal solution\nset, which characterize the patterns shared among all solutions, could be\nrequired in many real-life applications. It is very challenging for existing\nfinite population based MOEAs to handle these structure constraints properly.\nIn this work, we propose the first model-based algorithmic framework to learn\nthe whole solution set with structure constraints for multiobjective\noptimization. In our approach, the Pareto optimality can be traded off with a\npreferred structure among the whole solution set, which could be crucial for\nmany real-world problems. We also develop an efficient evolutionary learning\nmethod to train the set model with structure constraints. Experimental studies\non benchmark test suites and real-world application problems demonstrate the\npromising performance of our proposed framework.",
            "author": [
                "Xi Lin",
                "Xiaoyuan Zhang",
                "Zhiyuan Yang",
                "Qingfu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20426v1",
                "http://arxiv.org/pdf/2310.20426v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20424v1",
            "title": "DDC-PIM: Efficient Algorithm/Architecture Co-design for Doubling Data\n  Capacity of SRAM-based Processing-In-Memory",
            "updated": "2023-10-31T12:49:54Z",
            "published": "2023-10-31T12:49:54Z",
            "summary": "Processing-in-memory (PIM), as a novel computing paradigm, provides\nsignificant performance benefits from the aspect of effective data movement\nreduction. SRAM-based PIM has been demonstrated as one of the most promising\ncandidates due to its endurance and compatibility. However, the integration\ndensity of SRAM-based PIM is much lower than other non-volatile memory-based\nones, due to its inherent 6T structure for storing a single bit. Within\ncomparable area constraints, SRAM-based PIM exhibits notably lower capacity.\nThus, aiming to unleash its capacity potential, we propose DDC-PIM, an\nefficient algorithm/architecture co-design methodology that effectively doubles\nthe equivalent data capacity. At the algorithmic level, we propose a\nfilter-wise complementary correlation (FCC) algorithm to obtain a bitwise\ncomplementary pair. At the architecture level, we exploit the intrinsic\ncross-coupled structure of 6T SRAM to store the bitwise complementary pair in\ntheir complementary states ($Q/\\overline{Q}$), thereby maximizing the data\ncapacity of each SRAM cell. The dual-broadcast input structure and\nreconfigurable unit support both depthwise and pointwise convolution, adhering\nto the requirements of various neural networks. Evaluation results show that\nDDC-PIM yields about $2.84\\times$ speedup on MobileNetV2 and $2.69\\times$ on\nEfficientNet-B0 with negligible accuracy loss compared with PIM baseline\nimplementation. Compared with state-of-the-art SRAM-based PIM macros, DDC-PIM\nachieves up to $8.41\\times$ and $2.75\\times$ improvement in weight density and\narea efficiency, respectively.",
            "author": [
                "Cenlin Duan",
                "Jianlei Yang",
                "Xiaolin He",
                "Yingjie Qi",
                "Yikun Wang",
                "Yiou Wang",
                "Ziyan He",
                "Bonan Yan",
                "Xueyan Wang",
                "Xiaotao Jia",
                "Weitao Pan",
                "Weisheng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20424v1",
                "http://arxiv.org/pdf/2310.20424v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20421v1",
            "title": "Two-stage solution for ancilla-assisted quantum process tomography:\n  error analysis and optimal design",
            "updated": "2023-10-31T12:47:03Z",
            "published": "2023-10-31T12:47:03Z",
            "summary": "Quantum process tomography (QPT) is a fundamental task to characterize the\ndynamics of quantum systems. In contrast to standard QPT, ancilla-assisted\nprocess tomography (AAPT) framework introduces an extra ancilla system such\nthat a single input state is needed. In this paper, we extend the two-stage\nsolution, a method originally designed for standard QPT, to perform AAPT. Our\nalgorithm has $O(Md_A^2d_B^2)$ computational complexity where $ M $ is the type\nnumber of the measurement operators, $ d_A $ is the dimension of the quantum\nsystem of interest, and $d_B$ is the dimension of the ancilla system. Then we\nestablish an error upper bound and further discuss the optimal design on the\ninput state in AAPT. A numerical example on a phase damping process\ndemonstrates the effectiveness of the optimal design and illustrates the\ntheoretical error analysis.",
            "author": [
                "Shuixin Xiao",
                "Yuanlong Wang",
                "Daoyi Dong",
                "Jun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20421v1",
                "http://arxiv.org/pdf/2310.20421v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20420v1",
            "title": "Kashiwara-Vergne solutions degree by degree",
            "updated": "2023-10-31T12:46:30Z",
            "published": "2023-10-31T12:46:30Z",
            "summary": "We show that solutions to the Kashiwara-Vergne problem can be extended degree\nby degree. This can be used to simplify the computation of a class of Drinfel'd\nassociators, which under the Alekseev-Torossian conjecture, may comprise all\nassociators. We also give a proof that the associated graded Lie algebra of the\nKashiwara-Vergne group is isomorphic to the graded Kashiwara-Vergne Lie\nalgebra.",
            "author": [
                "Zsuzsanna Dancso",
                "Iva Halacheva",
                "Guillaume Laplante-Anfossi",
                "Marcy Robertson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20420v1",
                "http://arxiv.org/pdf/2310.20420v1"
            ],
            "primary_category": "math.QA",
            "category": [
                "math.QA",
                "math.AT",
                "17B01, 17B45, 57K12"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20416v1",
            "title": "Linear-nonlinear duality for circuit design on quantum computing\n  platforms",
            "updated": "2023-10-31T12:45:22Z",
            "published": "2023-10-31T12:45:22Z",
            "summary": "The unitary description of beam splitters (BSs) and optical parametric\namplifiers (OPAs) in terms of the dynamical Lie groups $SU(2)$ and $SU(1,1)$\nhas a long history. Recently, an inherent duality has been proposed that\nrelates the unitaries of both optical devices. At the physical level, this\nduality relates the linear nature of a lossless BS to the nonlinear Parametric\nDown-Conversion (PDC) process exhibited by an OPA. Here, we argue that the\nduality between BS and PDC can instead be naturally interpreted by analyzing\nthe geometrical properties of both Lie groups, an approach that explicitly\nconnects the dynamical group description of the optical devices with the\naforementioned duality. Furthermore, we show that the BS-PDC duality can be\nrepresented through tensor network diagrams, enabling the implementation of a\nPDC as a circuit on a standard quantum computing platform. Thus, it is feasible\nto simulate nonlinear processes by using single-qubit unitaries that can be\nimplemented on currently available digital quantum processors.",
            "author": [
                "William E. Salazar",
                "Omar Calder\u00f3n-Losada",
                "John H. Reina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20416v1",
                "http://arxiv.org/pdf/2310.20416v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20415v1",
            "title": "Coalitional Manipulations and Immunity of the Shapley Value",
            "updated": "2023-10-31T12:43:31Z",
            "published": "2023-10-31T12:43:31Z",
            "summary": "We consider manipulations in the context of coalitional games, where a\ncoalition aims to increase the total payoff of its members. An allocation rule\nis immune to coalitional manipulation if no coalition can benefit from internal\nreallocation of worth on the level of its subcoalitions\n(reallocation-proofness), and if no coalition benefits from a lower worth while\nall else remains the same (weak coalitional monotonicity). Replacing additivity\nin Shapley's original characterization by these requirements yields a new\nfoundation of the Shapley value, i.e., it is the unique efficient and symmetric\nallocation rule that awards nothing to a null player and is immune to\ncoalitional manipulations. We further find that for efficient allocation rules,\nreallocation-proofness is equivalent to constrained marginality, a weaker\nvariant of Young's marginality axiom. Our second characterization improves upon\nYoung's characterization by weakening the independence requirement intrinsic to\nmarginality.",
            "author": [
                "Christian Basteck",
                "Frank Huettner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20415v1",
                "http://arxiv.org/pdf/2310.20415v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20412v1",
            "title": "Thermal-Infrared Remote Target Detection System for Maritime Rescue\n  based on Data Augmentation with 3D Synthetic Data",
            "updated": "2023-10-31T12:37:49Z",
            "published": "2023-10-31T12:37:49Z",
            "summary": "This paper proposes a thermal-infrared (TIR) remote target detection system\nfor maritime rescue using deep learning and data augmentation. We established a\nself-collected TIR dataset consisting of multiple scenes imitating human rescue\nsituations using a TIR camera (FLIR). Additionally, to address dataset scarcity\nand improve model robustness, a synthetic dataset from a 3D game (ARMA3) to\naugment the data is further collected. However, a significant domain gap exists\nbetween synthetic TIR and real TIR images. Hence, a proper domain adaptation\nalgorithm is essential to overcome the gap. Therefore, we suggest a domain\nadaptation algorithm in a target-background separated manner from 3D\ngame-to-real, based on a generative model, to address this issue. Furthermore,\na segmentation network with fixed-weight kernels at the head is proposed to\nimprove the signal-to-noise ratio (SNR) and provide weak attention, as remote\nTIR targets inherently suffer from unclear boundaries. Experiment results\nreveal that the network trained on augmented data consisting of translated\nsynthetic and real TIR data outperforms that trained on only real TIR data by a\nlarge margin. Furthermore, the proposed segmentation model surpasses the\nperformance of state-of-the-art segmentation methods.",
            "author": [
                "Sungjin Cheong",
                "Wonho Jung",
                "Yoon Seop Lim",
                "Yong-Hwa Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20412v1",
                "http://arxiv.org/pdf/2310.20412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "68T45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20410v2",
            "title": "FollowBench: A Multi-level Fine-grained Constraints Following Benchmark\n  for Large Language Models",
            "updated": "2023-11-14T11:01:06Z",
            "published": "2023-10-31T12:32:38Z",
            "summary": "The ability to follow instructions is crucial for Large Language Models\n(LLMs) to handle various real-world applications. Existing benchmarks primarily\nfocus on evaluating pure response quality, rather than assessing whether the\nresponse follows constraints stated in the instruction. To fill this research\ngap, in this paper, we propose FollowBench, a Multi-level Fine-grained\nConstraints Following Benchmark for LLMs. FollowBench comprehensively includes\nfive different types (i.e., Content, Situation, Style, Format, and Example) of\nfine-grained constraints. To enable a precise constraint following estimation\non diverse difficulties, we introduce a Multi-level mechanism that\nincrementally adds a single constraint to the initial instruction at each\nincreased level. To assess whether LLMs' outputs have satisfied every\nindividual constraint, we propose to prompt strong LLMs with\nconstraint-evolution paths to handle challenging open-ended instructions. By\nevaluating ten closed-source and open-source popular LLMs on FollowBench, we\nhighlight the weaknesses of LLMs in instruction following and point towards\npotential avenues for future work. The data and code are publicly available at\nhttps://github.com/YJiangcm/FollowBench.",
            "author": [
                "Yuxin Jiang",
                "Yufei Wang",
                "Xingshan Zeng",
                "Wanjun Zhong",
                "Liangyou Li",
                "Fei Mi",
                "Lifeng Shang",
                "Xin Jiang",
                "Qun Liu",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20410v2",
                "http://arxiv.org/pdf/2310.20410v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20407v1",
            "title": "Unsupervised detection of coordinated fake-follower campaigns on social\n  media",
            "updated": "2023-10-31T12:30:29Z",
            "published": "2023-10-31T12:30:29Z",
            "summary": "Automated social media accounts, known as bots, are increasingly recognized\nas key tools for manipulative online activities. These activities can stem from\ncoordination among several accounts and these automated campaigns can\nmanipulate social network structure by following other accounts, amplifying\ntheir content, and posting messages to spam online discourse. In this study, we\npresent a novel unsupervised detection method designed to target a specific\ncategory of malicious accounts designed to manipulate user metrics such as\nonline popularity. Our framework identifies anomalous following patterns among\nall the followers of a social media account. Through the analysis of a large\nnumber of accounts on the Twitter platform (rebranded as Twitter after the\nacquisition of Elon Musk), we demonstrate that irregular following patterns are\nprevalent and are indicative of automated fake accounts. Notably, we find that\nthese detected groups of anomalous followers exhibit consistent behavior across\nmultiple accounts. This observation, combined with the computational efficiency\nof our proposed approach, makes it a valuable tool for investigating\nlarge-scale coordinated manipulation campaigns on social media platforms.",
            "author": [
                "Yasser Zouzou",
                "Onur Varol"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20407v1",
                "http://arxiv.org/pdf/2310.20407v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20398v1",
            "title": "A hybrid approach for solving the gravitational N-body problem with\n  Artificial Neural Networks",
            "updated": "2023-10-31T12:20:20Z",
            "published": "2023-10-31T12:20:20Z",
            "summary": "Simulating the evolution of the gravitational N-body problem becomes\nextremely computationally expensive as N increases since the problem complexity\nscales quadratically with the number of bodies. We study the use of Artificial\nNeural Networks (ANNs) to replace expensive parts of the integration of\nplanetary systems. Neural networks that include physical knowledge have grown\nin popularity in the last few years, although few attempts have been made to\nuse them to speed up the simulation of the motion of celestial bodies. We study\nthe advantages and limitations of using Hamiltonian Neural Networks to replace\ncomputationally expensive parts of the numerical simulation. We compare the\nresults of the numerical integration of a planetary system with asteroids with\nthose obtained by a Hamiltonian Neural Network and a conventional Deep Neural\nNetwork, with special attention to understanding the challenges of this\nproblem. Due to the non-linear nature of the gravitational equations of motion,\nerrors in the integration propagate. To increase the robustness of a method\nthat uses neural networks, we propose a hybrid integrator that evaluates the\nprediction of the network and replaces it with the numerical solution if\nconsidered inaccurate. Hamiltonian Neural Networks can make predictions that\nresemble the behavior of symplectic integrators but are challenging to train\nand in our case fail when the inputs differ ~7 orders of magnitude. In\ncontrast, Deep Neural Networks are easy to train but fail to conserve energy,\nleading to fast divergence from the reference solution. The hybrid integrator\ndesigned to include the neural networks increases the reliability of the method\nand prevents large energy errors without increasing the computing cost\nsignificantly. For this problem, the use of neural networks results in faster\nsimulations when the number of asteroids is >70.",
            "author": [
                "Veronica Saz Ulibarrena",
                "Philipp Horn",
                "Simon Portegies Zwart",
                "Elena Sellentin",
                "Barry Koren",
                "Maxwell X. Cai"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jcp.2023.112596",
                "http://arxiv.org/abs/2310.20398v1",
                "http://arxiv.org/pdf/2310.20398v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20394v1",
            "title": "The miniversal deformation of certain complete intersection monomial\n  curves",
            "updated": "2023-10-31T12:16:17Z",
            "published": "2023-10-31T12:16:17Z",
            "summary": "The aim of this paper is to provide an explicit basis of the miniversal\ndeformation of a monomial curve defined by a free semigroup -- these curves\nmake up a notable family of complete intersection monomial curves. First, we\ndispense a general decomposition result of a basis of the miniversal\ndeformation of any complete intersection monomial curve. As a consequence, we\nexplicitly calculate this basis in the particular case of a monomial curve\ndefined from a free semigroup. This explicit computation yields some estimates\nfor the dimension of the moduli space of these family of curves.",
            "author": [
                "Patricio Almir\u00f3n",
                "Julio Jos\u00e9 Moyano-Fern\u00e1ndez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20394v1",
                "http://arxiv.org/pdf/2310.20394v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.AC",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20392v1",
            "title": "Configuring Timing Parameters to Ensure Execution-Time Opacity in Timed\n  Automata",
            "updated": "2023-10-31T12:10:35Z",
            "published": "2023-10-31T12:10:35Z",
            "summary": "Timing information leakage occurs whenever an attacker successfully deduces\nconfidential internal information by observing some timed information such as\nevents with timestamps. Timed automata are an extension of finite-state\nautomata with a set of clocks evolving linearly and that can be tested or\nreset, making this formalism able to reason on systems involving concurrency\nand timing constraints. In this paper, we summarize a recent line of works\nusing timed automata as the input formalism, in which we assume that the\nattacker has access (only) to the system execution time. First, we address the\nfollowing execution-time opacity problem: given a timed system modeled by a\ntimed automaton, given a secret location and a final location, synthesize the\nexecution times from the initial location to the final location for which one\ncannot deduce whether the secret location was visited. This means that for any\nsuch execution time, the system is opaque: either the final location is not\nreachable, or it is reachable with that execution time for both a run visiting\nand a run not visiting the secret location. We also address the full\nexecution-time opacity problem, asking whether the system is opaque for all\nexecution times; we also study a weak counterpart. Second, we add timing\nparameters, which are a way to configure a system: we identify a subclass of\nparametric timed automata with some decidability results. In addition, we\ndevise a semi-algorithm for synthesizing timing parameter valuations\nguaranteeing that the resulting system is opaque. Third, we report on problems\nwhen the secret has itself an expiration date, thus defining expiring\nexecution-time opacity problems. We finally show that our method can also apply\nto program analysis with configurable internal timings.",
            "author": [
                "\u00c9tienne Andr\u00e9",
                "Engel Lefaucheux",
                "Didier Lime",
                "Dylan Marinho",
                "Jun Sun"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.392.1",
                "http://arxiv.org/abs/2310.20392v1",
                "http://arxiv.org/pdf/2310.20392v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CR",
                "cs.SE",
                "F.1.1; F.4.1; D.4.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20389v1",
            "title": "High-Resolution Reference Image Assisted Volumetric Super-Resolution of\n  Cardiac Diffusion Weighted Imaging",
            "updated": "2023-10-31T12:05:27Z",
            "published": "2023-10-31T12:05:27Z",
            "summary": "Diffusion Tensor Cardiac Magnetic Resonance (DT-CMR) is the only in vivo\nmethod to non-invasively examine the microstructure of the human heart. Current\nresearch in DT-CMR aims to improve the understanding of how the cardiac\nmicrostructure relates to the macroscopic function of the healthy heart as well\nas how microstructural dysfunction contributes to disease. To get the final\nDT-CMR metrics, we need to acquire diffusion weighted images of at least 6\ndirections. However, due to DWI's low signal-to-noise ratio, the standard voxel\nsize is quite big on the scale for microstructures. In this study, we explored\nthe potential of deep-learning-based methods in improving the image quality\nvolumetrically (x4 in all dimensions). This study proposed a novel framework to\nenable volumetric super-resolution, with an additional model input of\nhigh-resolution b0 DWI. We demonstrated that the additional input could offer\nhigher super-resolved image quality. Going beyond, the model is also able to\nsuper-resolve DWIs of unseen b-values, proving the model framework's\ngeneralizability for cardiac DWI superresolution. In conclusion, we would then\nrecommend giving the model a high-resolution reference image as an additional\ninput to the low-resolution image for training and inference to guide all\nsuper-resolution frameworks for parametric imaging where a reference image is\navailable.",
            "author": [
                "Yinzhe Wu",
                "Jiahao Huang",
                "Fanwen Wang",
                "Pedro Ferreira",
                "Andrew Scott",
                "Sonia Nielles-Vallespin",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20389v1",
                "http://arxiv.org/pdf/2310.20389v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20387v1",
            "title": "Overview of LiLAS 2020 -- Living Labs for Academic Search",
            "updated": "2023-10-31T11:57:54Z",
            "published": "2023-10-31T11:57:54Z",
            "summary": "Academic Search is a timeless challenge that the field of Information\nRetrieval has been dealing with for many years. Even today, the search for\nacademic material is a broad field of research that recently started working on\nproblems like the COVID-19 pandemic. However, test collections and specialized\ndata sets like CORD-19 only allow for system-oriented experiments, while the\nevaluation of algorithms in real-world environments is only available to\nresearchers from industry. In LiLAS, we open up two academic search platforms\nto allow participating research to evaluate their systems in a Docker-based\nresearch environment. This overview paper describes the motivation,\ninfrastructure, and two systems LIVIVO and GESIS Search that are part of this\nCLEF lab.",
            "author": [
                "Philipp Schaer",
                "Johann Schaible",
                "Leyla Jael Garcia Castro"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-030-58219-7_24",
                "http://arxiv.org/abs/2310.20387v1",
                "http://arxiv.org/pdf/2310.20387v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20384v1",
            "title": "Do large language models solve verbal analogies like children do?",
            "updated": "2023-10-31T11:49:11Z",
            "published": "2023-10-31T11:49:11Z",
            "summary": "Analogy-making lies at the heart of human cognition. Adults solve analogies\nsuch as \\textit{Horse belongs to stable like chicken belongs to ...?} by\nmapping relations (\\textit{kept in}) and answering \\textit{chicken coop}. In\ncontrast, children often use association, e.g., answering \\textit{egg}. This\npaper investigates whether large language models (LLMs) solve verbal analogies\nin A:B::C:? form using associations, similar to what children do. We use verbal\nanalogies extracted from an online adaptive learning environment, where 14,002\n7-12 year-olds from the Netherlands solved 622 analogies in Dutch. The six\ntested Dutch monolingual and multilingual LLMs performed around the same level\nas children, with MGPT performing worst, around the 7-year-old level, and XLM-V\nand GPT-3 the best, slightly above the 11-year-old level. However, when we\ncontrol for associative processes this picture changes and each model's\nperformance level drops 1-2 years. Further experiments demonstrate that\nassociative processes often underlie correctly solved analogies. We conclude\nthat the LLMs we tested indeed tend to solve verbal analogies by association\nwith C like children do.",
            "author": [
                "Claire E. Stevenson",
                "Mathilde ter Veen",
                "Rochelle Choenni",
                "Han L. J. van der Maas",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20384v1",
                "http://arxiv.org/pdf/2310.20384v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20381v3",
            "title": "A Comprehensive Study of GPT-4V's Multimodal Capabilities in Medical\n  Imaging",
            "updated": "2023-11-06T10:57:24Z",
            "published": "2023-10-31T11:39:09Z",
            "summary": "This paper presents a comprehensive evaluation of GPT-4V's capabilities\nacross diverse medical imaging tasks, including Radiology Report Generation,\nMedical Visual Question Answering (VQA), and Visual Grounding. While prior\nefforts have explored GPT-4V's performance in medical image analysis, to the\nbest of our knowledge, our study represents the first quantitative evaluation\non publicly available benchmarks. Our findings highlight GPT-4V's potential in\ngenerating descriptive reports for chest X-ray images, particularly when guided\nby well-structured prompts. Meanwhile, its performance on the MIMIC-CXR dataset\nbenchmark reveals areas for improvement in certain evaluation metrics, such as\nCIDEr. In the domain of Medical VQA, GPT-4V demonstrates proficiency in\ndistinguishing between question types but falls short of the VQA-RAD benchmark\nin terms of accuracy. Furthermore, our analysis finds the limitations of\nconventional evaluation metrics like the BLEU scores, advocating for the\ndevelopment of more semantically robust assessment methods. In the field of\nVisual Grounding, GPT-4V exhibits preliminary promise in recognizing bounding\nboxes, but its precision is lacking, especially in identifying specific medical\norgans and signs. Our evaluation underscores the significant potential of\nGPT-4V in the medical imaging domain, while also emphasizing the need for\ntargeted refinements to fully unlock its capabilities.",
            "author": [
                "Yingshu Li",
                "Yunyi Liu",
                "Zhanyu Wang",
                "Xinyu Liang",
                "Lingqiao Liu",
                "Lei Wang",
                "Leyang Cui",
                "Zhaopeng Tu",
                "Longyue Wang",
                "Luping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20381v3",
                "http://arxiv.org/pdf/2310.20381v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20379v1",
            "title": "A U-Net-Based Self-Stitching Method for Generating Periodic Grain\n  Structures",
            "updated": "2023-10-31T11:38:07Z",
            "published": "2023-10-31T11:38:07Z",
            "summary": "When modeling microstructures, the computational resource requirements\nincrease rapidly as the simulation domain becomes larger. As a result,\nsimulating a small representative fraction under periodic boundary conditions\nis often a necessary simplification. However, the truncated structures leave\nnonphysical boundaries, which are detrimental to numerical modeling. Here, we\npropose a self-stitching algorithm for generating periodic structures,\ndemonstrated in a grain structure. The main idea of our algorithm is to\nartificially add structural information between mismatched boundary pairs,\nusing the hierarchical spatial predictions of the U-Net. The algorithm provides\nan automatic and unbiased way to obtain periodic boundaries in grain structures\nand can be applied to porous microstructures in a similar way.",
            "author": [
                "Ye Ji",
                "Arnd Koeppe",
                "Patrick Altschuh",
                "Lars Griem",
                "Deepalaxmi Rajagopal",
                "Britta Nestler",
                "Weijin Chen",
                "Yi Zhang",
                "Yue Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20379v1",
                "http://arxiv.org/pdf/2310.20379v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20376v1",
            "title": "Mixture modeling via vectors of normalized independent finite point\n  processes",
            "updated": "2023-10-31T11:36:13Z",
            "published": "2023-10-31T11:36:13Z",
            "summary": "Statistical modeling in presence of hierarchical data is a crucial task in\nBayesian statistics. The Hierarchical Dirichlet Process (HDP) represents the\nutmost tool to handle data organized in groups through mixture modeling.\nAlthough the HDP is mathematically tractable, its computational cost is\ntypically demanding, and its analytical complexity represents a barrier for\npractitioners. The present paper conceives a mixture model based on a novel\nfamily of Bayesian priors designed for multilevel data and obtained by\nnormalizing a finite point process. A full distribution theory for this new\nfamily and the induced clustering is developed, including tractable expressions\nfor marginal, posterior and predictive distributions. Efficient marginal and\nconditional Gibbs samplers are designed for providing posterior inference. The\nproposed mixture model overcomes the HDP in terms of analytical feasibility,\nclustering discovery, and computational time. The motivating application comes\nfrom the analysis of shot put data, which contains performance measurements of\nathletes across different seasons. In this setting, the proposed model is\nexploited to induce clustering of the observations across seasons and athletes.\nBy linking clusters across seasons, similarities and differences in athlete's\nperformances are identified.",
            "author": [
                "Alessandro Colombi",
                "Raffaele Argiento",
                "Federico Camerlenghi",
                "Lucia Paci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20376v1",
                "http://arxiv.org/pdf/2310.20376v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20375v1",
            "title": "GreenCourier: Carbon-Aware Scheduling for Serverless Functions",
            "updated": "2023-10-31T11:35:50Z",
            "published": "2023-10-31T11:35:50Z",
            "summary": "This paper presents GreenCourier, a novel scheduling framework that enables\nthe runtime scheduling of serverless functions across geographically\ndistributed regions based on their carbon efficiencies. Our framework\nincorporates an intelligent scheduling strategy for Kubernetes and supports\nKnative as the serverless platform. To obtain real-time carbon information for\ndifferent geographical regions, our framework supports multiple marginal carbon\nemissions sources such as WattTime and the Carbon-aware SDK. We comprehensively\nevaluate the performance of our framework using the Google Kubernetes Engine\nand production serverless function traces for scheduling functions across\nSpain, France, Belgium, and the Netherlands. Results from our experiments show\nthat compared to other approaches, GreenCourier reduces carbon emissions per\nfunction invocation by an average of 13.25%.",
            "author": [
                "Mohak Chadha",
                "Thandayuthapani Subramanian",
                "Eishi Arima",
                "Michael Gerndt",
                "Martin Schulz",
                "Osama Abboud"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3631295.3631396",
                "http://arxiv.org/abs/2310.20375v1",
                "http://arxiv.org/pdf/2310.20375v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20374v1",
            "title": "Ncorpi$\\mathcal{O}$N : A $\\mathcal{O}(N)$ software for N-body\n  integration in collisional and fragmenting systems",
            "updated": "2023-10-31T11:35:12Z",
            "published": "2023-10-31T11:35:12Z",
            "summary": "Ncorpi$\\mathcal{O}$N is a $N$-body software developed for the time-efficient\nintegration of collisional and fragmenting systems of planetesimals or moonlets\norbiting a central mass. It features a fragmentation model, based on crater\nscaling and ejecta models, able to realistically simulate a violent impact. The\nuser of Ncorpi$\\mathcal{O}$N can choose between four different built-in modules\nto compute self-gravity and detect collisions. One of these makes use of a\nmesh-based algorithm to treat mutual interactions in $\\mathcal{O}(N)$ time.\nAnother module, much more efficient than the standard Barnes-Hut tree code, is\na $\\mathcal{O}(N)$ tree-based algorithm called FalcON. It relies on fast\nmultipole expansion for gravity computation and we adapted it to collision\ndetection as well. Computation time is reduced by building the tree structure\nusing a three-dimensional Hilbert curve. For the same precision in mutual\ngravity computation, Ncorpi$\\mathcal{O}$N is found to be up to 25 times faster\nthan the famous software REBOUND. Ncorpi$\\mathcal{O}$N is written entirely in\nthe C language and only needs a C compiler to run. A python add-on, that\nrequires only basic python libraries, produces animations of the simulations\nfrom the output files. The name Ncorpi$\\mathcal{O}$N, reminding of a scorpion,\ncomes from the French $N$-corps, meaning $N$-body, and from the mathematical\nnotation $\\mathcal{O}(N)$, due to the running time of the software being almost\nlinear in the total number $N$ of moonlets. Ncorpi$\\mathcal{O}$N is designed\nfor the study of accreting or fragmenting disks of planetesimal or moonlets. It\ndetects collisions and computes mutual gravity faster than REBOUND, and unlike\nother $N$-body integrators, it can resolve a collision by fragmentation. The\nfast multipole expansions are implemented up to order six to allow for a high\nprecision in mutual gravity computation.",
            "author": [
                "J\u00e9r\u00e9my Couturier",
                "Alice C. Quillen",
                "Miki Nakajima"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20374v1",
                "http://arxiv.org/pdf/2310.20374v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "astro-ph.SR",
                "physics.comp-ph",
                "physics.space-ph",
                "70F10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20355v1",
            "title": "Muscle volume quantification: guiding transformers with anatomical\n  priors",
            "updated": "2023-10-31T10:56:10Z",
            "published": "2023-10-31T10:56:10Z",
            "summary": "Muscle volume is a useful quantitative biomarker in sports, but also for the\nfollow-up of degenerative musculo-skelletal diseases. In addition to volume,\nother shape biomarkers can be extracted by segmenting the muscles of interest\nfrom medical images. Manual segmentation is still today the gold standard for\nsuch measurements despite being very time-consuming. We propose a method for\nautomatic segmentation of 18 muscles of the lower limb on 3D Magnetic Resonance\nImages to assist such morphometric analysis. By their nature, the tissue of\ndifferent muscles is undistinguishable when observed in MR Images. Thus, muscle\nsegmentation algorithms cannot rely on appearance but only on contour cues.\nHowever, such contours are hard to detect and their thickness varies across\nsubjects. To cope with the above challenges, we propose a segmentation approach\nbased on a hybrid architecture, combining convolutional and visual transformer\nblocks. We investigate for the first time the behaviour of such hybrid\narchitectures in the context of muscle segmentation for shape analysis.\nConsidering the consistent anatomical muscle configuration, we rely on\ntransformer blocks to capture the longrange relations between the muscles. To\nfurther exploit the anatomical priors, a second contribution of this work\nconsists in adding a regularisation loss based on an adjacency matrix of\nplausible muscle neighbourhoods estimated from the training data. Our\nexperimental results on a unique database of elite athletes show it is possible\nto train complex hybrid models from a relatively small database of large\nvolumes, while the anatomical prior regularisation favours better predictions.",
            "author": [
                "Louise Piecuch",
                "Vanessa Gonzales Duque",
                "Aur\u00e9lie Sarcher",
                "Enzo Hollville",
                "Antoine Nordez",
                "Giuseppe Rabita",
                "Ga\u00ebl Guilhem",
                "Diana Mateus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20355v1",
                "http://arxiv.org/pdf/2310.20355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20352v1",
            "title": "AMERICANO: Argument Generation with Discourse-driven Decomposition and\n  Agent Interaction",
            "updated": "2023-10-31T10:47:33Z",
            "published": "2023-10-31T10:47:33Z",
            "summary": "Argument generation is a challenging task in natural language processing,\nwhich requires rigorous reasoning and proper content organization. Inspired by\nrecent chain-of-thought prompting that breaks down a complex task into\nintermediate steps, we propose Americano, a novel framework with agent\ninteraction for argument generation. Our approach decomposes the generation\nprocess into sequential actions grounded on argumentation theory, which first\nexecutes actions sequentially to generate argumentative discourse components,\nand then produces a final argument conditioned on the components. To further\nmimic the human writing process and improve the left-to-right generation\nparadigm of current autoregressive language models, we introduce an argument\nrefinement module which automatically evaluates and refines argument drafts\nbased on feedback received. We evaluate our framework on the task of\ncounterargument generation using a subset of Reddit/CMV dataset. The results\nshow that our method outperforms both end-to-end and chain-of-thought prompting\nmethods and can generate more coherent and persuasive arguments with diverse\nand rich contents.",
            "author": [
                "Zhe Hu",
                "Hou Pong Chan",
                "Yu Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20352v1",
                "http://arxiv.org/pdf/2310.20352v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20350v1",
            "title": "Combining Shape Completion and Grasp Prediction for Fast and Versatile\n  Grasping with a Multi-Fingered Hand",
            "updated": "2023-10-31T10:46:19Z",
            "published": "2023-10-31T10:46:19Z",
            "summary": "Grasping objects with limited or no prior knowledge about them is a highly\nrelevant skill in assistive robotics. Still, in this general setting, it has\nremained an open problem, especially when it comes to only partial\nobservability and versatile grasping with multi-fingered hands. We present a\nnovel, fast, and high fidelity deep learning pipeline consisting of a shape\ncompletion module that is based on a single depth image, and followed by a\ngrasp predictor that is based on the predicted object shape. The shape\ncompletion network is based on VQDIF and predicts spatial occupancy values at\narbitrary query points. As grasp predictor, we use our two-stage architecture\nthat first generates hand poses using an autoregressive model and then\nregresses finger joint configurations per pose. Critical factors turn out to be\nsufficient data realism and augmentation, as well as special attention to\ndifficult cases during training. Experiments on a physical robot platform\ndemonstrate successful grasping of a wide range of household objects based on a\ndepth image from a single viewpoint. The whole pipeline is fast, taking only\nabout 1 s for completing the object's shape (0.7 s) and generating 1000 grasps\n(0.3 s).",
            "author": [
                "Matthias Humt",
                "Dominik Winkelbauer",
                "Ulrich Hillenbrand",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20350v1",
                "http://arxiv.org/pdf/2310.20350v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20349v1",
            "title": "A Low-cost Strategic Monitoring Approach for Scalable and Interpretable\n  Error Detection in Deep Neural Networks",
            "updated": "2023-10-31T10:45:55Z",
            "published": "2023-10-31T10:45:55Z",
            "summary": "We present a highly compact run-time monitoring approach for deep computer\nvision networks that extracts selected knowledge from only a few (down to\nmerely two) hidden layers, yet can efficiently detect silent data corruption\noriginating from both hardware memory and input faults. Building on the insight\nthat critical faults typically manifest as peak or bulk shifts in the\nactivation distribution of the affected network layers, we use strategically\nplaced quantile markers to make accurate estimates about the anomaly of the\ncurrent inference as a whole. Importantly, the detector component itself is\nkept algorithmically transparent to render the categorization of regular and\nabnormal behavior interpretable to a human. Our technique achieves up to ~96%\nprecision and ~98% recall of detection. Compared to state-of-the-art anomaly\ndetection techniques, this approach requires minimal compute overhead (as\nlittle as 0.3% with respect to non-supervised inference time) and contributes\nto the explainability of the model.",
            "author": [
                "Florian Geissler",
                "Syed Qutub",
                "Michael Paulitsch",
                "Karthik Pattabiraman"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-40923-3_7",
                "http://arxiv.org/abs/2310.20349v1",
                "http://arxiv.org/pdf/2310.20349v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20348v1",
            "title": "Class Incremental Learning with Pre-trained Vision-Language Models",
            "updated": "2023-10-31T10:45:03Z",
            "published": "2023-10-31T10:45:03Z",
            "summary": "With the advent of large-scale pre-trained models, interest in adapting and\nexploiting them for continual learning scenarios has grown.\n  In this paper, we propose an approach to exploiting pre-trained\nvision-language models (e.g. CLIP) that enables further adaptation instead of\nonly using zero-shot learning of new tasks. We augment a pre-trained CLIP model\nwith additional layers after the Image Encoder or before the Text Encoder. We\ninvestigate three different strategies: a Linear Adapter, a Self-attention\nAdapter, each operating on the image embedding, and Prompt Tuning which instead\nmodifies prompts input to the CLIP text encoder. We also propose a method for\nparameter retention in the adapter layers that uses a measure of parameter\nimportance to better maintain stability and plasticity during incremental\nlearning. Our experiments demonstrate that the simplest solution -- a single\nLinear Adapter layer with parameter retention -- produces the best results.\nExperiments on several conventional benchmarks consistently show a significant\nmargin of improvement over the current state-of-the-art.",
            "author": [
                "Xialei Liu",
                "Xusheng Cao",
                "Haori Lu",
                "Jia-wen Xiao",
                "Andrew D. Bagdanov",
                "Ming-Ming Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20348v1",
                "http://arxiv.org/pdf/2310.20348v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20347v1",
            "title": "Automatic Generators for a Family of Matrix Multiplication Routines with\n  Apache TVM",
            "updated": "2023-10-31T10:36:26Z",
            "published": "2023-10-31T10:36:26Z",
            "summary": "We explore the utilization of the Apache TVM open source framework to\nautomatically generate a family of algorithms that follow the approach taken by\npopular linear algebra libraries, such as GotoBLAS2, BLIS and OpenBLAS, in\norder to obtain high-performance blocked formulations of the general matrix\nmultiplication (GEMM). % In addition, we fully automatize the generation\nprocess, by also leveraging the Apache TVM framework to derive a complete\nvariety of the processor-specific micro-kernels for GEMM. This is in contrast\nwith the convention in high performance libraries, which hand-encode a single\nmicro-kernel per architecture using Assembly code. % In global, the combination\nof our TVM-generated blocked algorithms and micro-kernels for GEMM 1)~improves\nportability, maintainability and, globally, streamlines the software life\ncycle; 2)~provides high flexibility to easily tailor and optimize the solution\nto different data types, processor architectures, and matrix operand shapes,\nyielding performance on a par (or even superior for specific matrix shapes)\nwith that of hand-tuned libraries; and 3)~features a small memory footprint.",
            "author": [
                "Guillermo Alaejos",
                "Adri\u00e1n Castell\u00f3",
                "Pedro Alonso-Jord\u00e1",
                "Francisco D. Igual",
                "H\u00e9ctor Mart\u00ednez",
                "Enrique S. Quintana-Ort\u00ed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20347v1",
                "http://arxiv.org/pdf/2310.20347v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20342v1",
            "title": "Bohr sets generated by polynomials and Coppersmith's method in many\n  variables",
            "updated": "2023-10-31T10:33:05Z",
            "published": "2023-10-31T10:33:05Z",
            "summary": "We obtain bounds on the average size of Bohr sets with coefficients\nparametrised by polynomials over finite fields and obtain a series of general\nresults and also some sharper results for specific sets which are important for\napplications to computer science. In particular, we use our estimates to show\nthat a heuristic assumption used in the many variable version of Coppersmith's\nmethod holds with high probability. We demonstrate the use of our results on\nthe approximate greatest common divisor problem and obtain a fully rigorous\nversion of the heuristic algorithm of H. Cohn and N. Heninger (2013).",
            "author": [
                "Riley Baird",
                "Bryce Kerr",
                "Igor Shparlinski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20342v1",
                "http://arxiv.org/pdf/2310.20342v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "cs.CC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20340v1",
            "title": "Near-Optimal Coverage Path Planning with Turn Costs",
            "updated": "2023-10-31T10:24:45Z",
            "published": "2023-10-31T10:24:45Z",
            "summary": "Coverage path planning is a fundamental challenge in robotics, with diverse\napplications in aerial surveillance, manufacturing, cleaning, inspection,\nagriculture, and more. The main objective is to devise a trajectory for an\nagent that efficiently covers a given area, while minimizing time or energy\nconsumption. Existing practical approaches often lack a solid theoretical\nfoundation, relying on purely heuristic methods, or overly abstracting the\nproblem to a simple Traveling Salesman Problem in Grid Graphs. Moreover, the\nconsidered cost functions only rarely consider turn cost, prize-collecting\nvariants for uneven cover demand, or arbitrary geometric regions.\n  In this paper, we describe an array of systematic methods for handling\narbitrary meshes derived from intricate, polygonal environments. This\nadaptation paves the way to compute efficient coverage paths with a robust\ntheoretical foundation for real-world robotic applications. Through\ncomprehensive evaluations, we demonstrate that the algorithm also exhibits low\noptimality gaps, while efficiently handling complex environments. Furthermore,\nwe showcase its versatility in handling partial coverage and accommodating\nheterogeneous passage costs, offering the flexibility to trade off coverage\nquality and time efficiency.",
            "author": [
                "Dominik Michael Krupke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20340v1",
                "http://arxiv.org/pdf/2310.20340v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20335v1",
            "title": "Uplifting edges in higher order networks: spectral centralities for\n  non-uniform hypergraphs",
            "updated": "2023-10-31T10:21:58Z",
            "published": "2023-10-31T10:21:58Z",
            "summary": "Spectral analysis of networks states that many structural properties of\ngraphs, such as centrality of their nodes, are given in terms of their\nadjacency matrices. The natural extension of such spectral analysis to higher\norder networks is strongly limited by the fact that a given hypergraph could\nhave several different adjacency hypermatrices, hence the results obtained so\nfar are mainly restricted to the class of uniform hypergraphs, which leaves\nmany real systems unattended. A new method for analysing non-linear\neigenvector-like centrality measures of non-uniform hypergraphs is presented in\nthis paper that could be useful for studying properties of\n$\\mathcal{H}$-eigenvectors and $\\mathcal{Z}$-eigenvectors in the non-uniform\ncase. In order to do so, a new operation - the $\\textit{uplift}$ - is\nintroduced, incorporating auxiliary nodes in the hypergraph to allow for a\nuniform-like analysis. We later argue why this is a mathematically sound\noperation, and we furthermore use it to classify a whole family of hypergraphs\nwith unique Perron-like $\\mathcal{Z}$-eigenvectors. We supplement the\ntheoretical analysis with several examples and numerical simulations on\nsynthetic and real datasets.",
            "author": [
                "Gonzalo Contreras-Aso",
                "Cristian P\u00e9rez-Corral",
                "Miguel Romance"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20335v1",
                "http://arxiv.org/pdf/2310.20335v1"
            ],
            "primary_category": "math.SP",
            "category": [
                "math.SP",
                "math-ph",
                "math.MP",
                "physics.comp-ph",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20333v1",
            "title": "Semidefinite network games: multiplayer minimax and semidefinite\n  complementarity problems",
            "updated": "2023-10-31T10:20:19Z",
            "published": "2023-10-31T10:20:19Z",
            "summary": "Network games are an important class of games that model agent interactions\nin networked systems, where players are situated at the nodes of a graph and\ntheir payoffs depend on the actions taken by their neighbors. We extend the\nclassical framework by considering a game model where the strategies are\npositive semidefinite matrices having trace one. These (continuous) games can\nserve as a simple model of quantum strategic interactions. We focus on the\nzero-sum case, where the sum of all players' payoffs is equal to zero. We\nestablish that in this class of games, Nash equilibria can be characterized as\nthe projection of a spectrahedron, that is, the feasible region of a\nsemidefinite program. Furthermore, we demonstrate that determining whether a\ngame is a semidefinite network game is equivalent to deciding if the value of a\nsemidefinite program is zero. Beyond the zero-sum case, we characterize Nash\nequilibria as the solutions of a semidefinite linear complementarity problem.",
            "author": [
                "Constantin Ickstadt",
                "Thorsten Theobald",
                "Elias Tsigaridas",
                "Antonios Varvitsiotis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20333v1",
                "http://arxiv.org/pdf/2310.20333v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.GT",
                "52A20, 68Q25, 90C22, 91A43, 91A81"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20332v1",
            "title": "Recaptured Raw Screen Image and Video Demoir\u00e9ing via Channel and\n  Spatial Modulations",
            "updated": "2023-10-31T10:19:28Z",
            "published": "2023-10-31T10:19:28Z",
            "summary": "Capturing screen contents by smartphone cameras has become a common way for\ninformation sharing. However, these images and videos are often degraded by\nmoir\\'e patterns, which are caused by frequency aliasing between the camera\nfilter array and digital display grids. We observe that the moir\\'e patterns in\nraw domain is simpler than those in sRGB domain, and the moir\\'e patterns in\nraw color channels have different properties. Therefore, we propose an image\nand video demoir\\'eing network tailored for raw inputs. We introduce a\ncolor-separated feature branch, and it is fused with the traditional\nfeature-mixed branch via channel and spatial modulations. Specifically, the\nchannel modulation utilizes modulated color-separated features to enhance the\ncolor-mixed features. The spatial modulation utilizes the feature with large\nreceptive field to modulate the feature with small receptive field. In\naddition, we build the first well-aligned raw video demoir\\'eing\n(RawVDemoir\\'e) dataset and propose an efficient temporal alignment method by\ninserting alternating patterns. Experiments demonstrate that our method\nachieves state-of-the-art performance for both image and video demori\\'eing. We\nhave released the code and dataset in https://github.com/tju-chengyijia/VD_raw.",
            "author": [
                "Huanjing Yue",
                "Yijia Cheng",
                "Xin Liu",
                "Jingyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20332v1",
                "http://arxiv.org/pdf/2310.20332v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20329v1",
            "title": "InstructCoder: Empowering Language Models for Code Editing",
            "updated": "2023-10-31T10:15:35Z",
            "published": "2023-10-31T10:15:35Z",
            "summary": "Code editing encompasses a variety of pragmatic tasks that developers deal\nwith daily. Despite its relevance and practical usefulness, automatic code\nediting remains an underexplored area in the evolution of deep learning models,\npartly due to data scarcity. In this work, we explore the use of large language\nmodels (LLMs) to edit code based on user instructions, covering a broad range\nof implicit tasks such as comment insertion, code optimization, and code\nrefactoring. To facilitate this, we introduce InstructCoder, the first dataset\ndesigned to adapt LLMs for general-purpose code editing, containing\nhighdiversity code-editing tasks. It consists of over 114,000\ninstruction-input-output triplets and covers multiple distinct code editing\nscenarios. The dataset is systematically expanded through an iterative process\nthat commences with code editing data sourced from GitHub commits as seed\ntasks. Seed and generated tasks are used subsequently to prompt ChatGPT for\nmore task data. Our experiments demonstrate that open-source LLMs fine-tuned on\nInstructCoder can edit code correctly based on users' instructions most of the\ntime, exhibiting unprecedented code-editing performance levels. Such results\nsuggest that proficient instruction-finetuning can lead to significant\namelioration in code editing abilities. The dataset and the source code are\navailable at https://github.com/qishenghu/CodeInstruct.",
            "author": [
                "Qisheng Hu",
                "Kaixin Li",
                "Xu Zhao",
                "Yuxi Xie",
                "Tiedong Liu",
                "Hui Chen",
                "Qizhe Xie",
                "Junxian He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20329v1",
                "http://arxiv.org/pdf/2310.20329v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20328v1",
            "title": "ChiSCor: A Corpus of Freely Told Fantasy Stories by Dutch Children for\n  Computational Linguistics and Cognitive Science",
            "updated": "2023-10-31T10:15:20Z",
            "published": "2023-10-31T10:15:20Z",
            "summary": "In this resource paper we release ChiSCor, a new corpus containing 619\nfantasy stories, told freely by 442 Dutch children aged 4-12. ChiSCor was\ncompiled for studying how children render character perspectives, and\nunravelling language and cognition in development, with computational tools.\nUnlike existing resources, ChiSCor's stories were produced in natural contexts,\nin line with recent calls for more ecologically valid datasets. ChiSCor hosts\ntext, audio, and annotations for character complexity and linguistic\ncomplexity. Additional metadata (e.g. education of caregivers) is available for\none third of the Dutch children. ChiSCor also includes a small set of 62\nEnglish stories. This paper details how ChiSCor was compiled and shows its\npotential for future work with three brief case studies: i) we show that the\nsyntactic complexity of stories is strikingly stable across children's ages;\nii) we extend work on Zipfian distributions in free speech and show that\nChiSCor obeys Zipf's law closely, reflecting its social context; iii) we show\nthat even though ChiSCor is relatively small, the corpus is rich enough to\ntrain informative lemma vectors that allow us to analyse children's language\nuse. We end with a reflection on the value of narrative datasets in\ncomputational linguistics.",
            "author": [
                "Bram M. A. van Dijk",
                "Max J. van Duijn",
                "Suzan Verberne",
                "Marco R. Spruit"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20328v1",
                "http://arxiv.org/pdf/2310.20328v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20326v1",
            "title": "Erato: Automatizing Poetry Evaluation",
            "updated": "2023-10-31T10:06:37Z",
            "published": "2023-10-31T10:06:37Z",
            "summary": "We present Erato, a framework designed to facilitate the automated evaluation\nof poetry, including that generated by poetry generation systems. Our framework\nemploys a diverse set of features, and we offer a brief overview of Erato's\ncapabilities and its potential for expansion. Using Erato, we compare and\ncontrast human-authored poetry with automatically-generated poetry,\ndemonstrating its effectiveness in identifying key differences. Our\nimplementation code and software are freely available under the GNU GPLv3\nlicense.",
            "author": [
                "Manex Agirrezabal",
                "Hugo Gon\u00e7alo Oliveira",
                "Aitor Ormazabal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20326v1",
                "http://arxiv.org/pdf/2310.20326v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20325v1",
            "title": "A polynomial-time $\\text{OPT}^\u03b5$-approximation algorithm for\n  maximum independent set of connected subgraphs in a planar graph",
            "updated": "2023-10-31T10:02:36Z",
            "published": "2023-10-31T10:02:36Z",
            "summary": "In the Maximum Independent Set of Objects problem, we are given an $n$-vertex\nplanar graph $G$ and a family $\\mathcal{D}$ of $N$ objects, where each object\nis a connected subgraph of $G$. The task is to find a subfamily $\\mathcal{F}\n\\subseteq \\mathcal{D}$ of maximum cardinality that consists of pairwise\ndisjoint objects. This problem is $\\mathsf{NP}$-hard and is equivalent to the\nproblem of finding the maximum number of pairwise disjoint polygons in a given\nfamily of polygons in the plane.\n  As shown by Adamaszek et al. (J. ACM '19), the problem admits a\n\\emph{quasi-polynomial time approximation scheme} (QPTAS): a\n$(1-\\varepsilon)$-approximation algorithm whose running time is bounded by\n$2^{\\mathrm{poly}(\\log(N),1/\\epsilon)} \\cdot n^{\\mathcal{O}(1)}$. Nevertheless,\nto the best of our knowledge, in the polynomial-time regime only the trivial\n$\\mathcal{O}(N)$-approximation is known for the problem in full generality. In\nthe restricted setting where the objects are pseudolines in the plane, Fox and\nPach (SODA '11) gave an $N^{\\varepsilon}$-approximation algorithm with running\ntime $N^{2^{\\tilde{\\mathcal{O}}(1/\\varepsilon)}}$, for any $\\varepsilon>0$.\n  In this work, we present an $\\text{OPT}^{\\varepsilon}$-approximation\nalgorithm for the problem that runs in time\n$N^{\\tilde{\\mathcal{O}}(1/\\varepsilon^2)} n^{\\mathcal{O}(1)}$, for any\n$\\varepsilon>0$, thus improving upon the result of Fox and Pach both in terms\nof generality and in terms of the running time. Our approach combines the\nmethodology of Voronoi separators, introduced by Marx and Pilipczuk (TALG '22),\nwith a new analysis of the approximation factor.",
            "author": [
                "Jana Cslovjecsek",
                "Micha\u0142 Pilipczuk",
                "Karol W\u0119grzycki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20325v1",
                "http://arxiv.org/pdf/2310.20325v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20324v1",
            "title": "The $q^2$ moments in inclusive semileptonic $B$ decays",
            "updated": "2023-10-31T10:01:50Z",
            "published": "2023-10-31T10:01:50Z",
            "summary": "We compute the first moments of the $q^2$ distribution in inclusive\nsemileptonic $B$ decays as functions of the lower cut on $q^2$, confirming a\nnumber of results given in the literature and adding the $O(\\alpha_s^2\\beta_0)$\nBLM contributions. We then include the $q^2$-moments recently measured by Belle\nand Belle II in a global fit to the moments. The new data are compatible with\nthe other measurements and slightly decrease the uncertainty on the\nnonperturbative parameters and on $|V_{cb}|$. Our updated value is\n$|V_{cb}|=(41.97\\pm 0.48)\\times 10^{-3}$.",
            "author": [
                "Gael Finauri",
                "Paolo Gambino"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20324v1",
                "http://arxiv.org/pdf/2310.20324v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20323v2",
            "title": "SemanticBoost: Elevating Motion Generation with Augmented Textual Cues",
            "updated": "2023-11-28T06:18:33Z",
            "published": "2023-10-31T09:58:11Z",
            "summary": "Current techniques face difficulties in generating motions from intricate\nsemantic descriptions, primarily due to insufficient semantic annotations in\ndatasets and weak contextual understanding. To address these issues, we present\nSemanticBoost, a novel framework that tackles both challenges simultaneously.\nOur framework comprises a Semantic Enhancement module and a Context-Attuned\nMotion Denoiser (CAMD). The Semantic Enhancement module extracts supplementary\nsemantics from motion data, enriching the dataset's textual description and\nensuring precise alignment between text and motion data without depending on\nlarge language models. On the other hand, the CAMD approach provides an\nall-encompassing solution for generating high-quality, semantically consistent\nmotion sequences by effectively capturing context information and aligning the\ngenerated motion with the given textual descriptions. Distinct from existing\nmethods, our approach can synthesize accurate orientational movements, combined\nmotions based on specific body part descriptions, and motions generated from\ncomplex, extended sentences. Our experimental results demonstrate that\nSemanticBoost, as a diffusion-based method, outperforms auto-regressive-based\ntechniques, achieving cutting-edge performance on the Humanml3D dataset while\nmaintaining realistic and smooth motion generation quality.",
            "author": [
                "Xin He",
                "Shaoli Huang",
                "Xiaohang Zhan",
                "Chao Weng",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20323v2",
                "http://arxiv.org/pdf/2310.20323v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20322v1",
            "title": "FA Team at the NTCIR-17 UFO Task",
            "updated": "2023-10-31T09:56:12Z",
            "published": "2023-10-31T09:56:12Z",
            "summary": "The FA team participated in the Table Data Extraction (TDE) and Text-to-Table\nRelationship Extraction (TTRE) tasks of the NTCIR-17 Understanding of\nNon-Financial Objects in Financial Reports (UFO). This paper reports our\napproach to solving the problems and discusses the official results. We\nsuccessfully utilized various enhancement techniques based on the ELECTRA\nlanguage model to extract valuable data from tables. Our efforts resulted in an\nimpressive TDE accuracy rate of 93.43 %, positioning us in second place on the\nLeaderboard rankings. This outstanding achievement is a testament to our\nproposed approach's effectiveness. In the TTRE task, we proposed the rule-based\nmethod to extract meaningful relationships between the text and tables task and\nconfirmed the performance.",
            "author": [
                "Yuki Okumura",
                "Masato Fujitake"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20322v1",
                "http://arxiv.org/pdf/2310.20322v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20320v1",
            "title": "Theory of Mind in Large Language Models: Examining Performance of 11\n  State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests",
            "updated": "2023-10-31T09:55:07Z",
            "published": "2023-10-31T09:55:07Z",
            "summary": "To what degree should we ascribe cognitive capacities to Large Language\nModels (LLMs), such as the ability to reason about intentions and beliefs known\nas Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11\nbase- and instruction-tuned LLMs on capabilities relevant to ToM beyond the\ndominant false-belief paradigm, including non-literal language usage and\nrecursive intentionality; (ii) using newly rewritten versions of standardized\ntests to gauge LLMs' robustness; (iii) prompting and scoring for open besides\nclosed questions; and (iv) benchmarking LLM performance against that of\nchildren aged 7-10 on the same tasks. We find that instruction-tuned LLMs from\nthe GPT family outperform other models, and often also children. Base-LLMs are\nmostly unable to solve ToM tasks, even with specialized prompting. We suggest\nthat the interlinked evolution and development of language and ToM may help\nexplain what instruction-tuning adds: rewarding cooperative communication that\ntakes into account interlocutor and context. We conclude by arguing for a\nnuanced perspective on ToM in LLMs.",
            "author": [
                "Max J. van Duijn",
                "Bram M. A. van Dijk",
                "Tom Kouwenhoven",
                "Werner de Valk",
                "Marco R. Spruit",
                "Peter van der Putten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20320v1",
                "http://arxiv.org/pdf/2310.20320v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20319v1",
            "title": "GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object\n  Detectors on LiDAR-Data",
            "updated": "2023-10-31T09:55:04Z",
            "published": "2023-10-31T09:55:04Z",
            "summary": "Widely-used LiDAR-based 3D object detectors often neglect fundamental\ngeometric information readily available from the object proposals in their\nconfidence estimation. This is mostly due to architectural design choices,\nwhich were often adopted from the 2D image domain, where geometric context is\nrarely available. In 3D, however, considering the object properties and its\nsurroundings in a holistic way is important to distinguish between true and\nfalse positive detections, e.g. occluded pedestrians in a group. To address\nthis, we present GACE, an intuitive and highly efficient method to improve the\nconfidence estimation of a given black-box 3D object detector. We aggregate\ngeometric cues of detections and their spatial relationships, which enables us\nto properly assess their plausibility and consequently, improve the confidence\nestimation. This leads to consistent performance gains over a variety of\nstate-of-the-art detectors. Across all evaluated detectors, GACE proves to be\nespecially beneficial for the vulnerable road user classes, i.e. pedestrians\nand cyclists.",
            "author": [
                "David Schinagl",
                "Georg Krispel",
                "Christian Fruhwirth-Reisinger",
                "Horst Possegger",
                "Horst Bischof"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20319v1",
                "http://arxiv.org/pdf/2310.20319v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20316v1",
            "title": "HWD: A Novel Evaluation Score for Styled Handwritten Text Generation",
            "updated": "2023-10-31T09:44:27Z",
            "published": "2023-10-31T09:44:27Z",
            "summary": "Styled Handwritten Text Generation (Styled HTG) is an important task in\ndocument analysis, aiming to generate text images with the handwriting of given\nreference images. In recent years, there has been significant progress in the\ndevelopment of deep learning models for tackling this task. Being able to\nmeasure the performance of HTG models via a meaningful and representative\ncriterion is key for fostering the development of this research topic. However,\ndespite the current adoption of scores for natural image generation evaluation,\nassessing the quality of generated handwriting remains challenging. In light of\nthis, we devise the Handwriting Distance (HWD), tailored for HTG evaluation. In\nparticular, it works in the feature space of a network specifically trained to\nextract handwriting style features from the variable-lenght input images and\nexploits a perceptual distance to compare the subtle geometric features of\nhandwriting. Through extensive experimental evaluation on different word-level\nand line-level datasets of handwritten text images, we demonstrate the\nsuitability of the proposed HWD as a score for Styled HTG. The pretrained model\nused as backbone will be released to ease the adoption of the score, aiming to\nprovide a valuable tool for evaluating HTG models and thus contributing to\nadvancing this important research area.",
            "author": [
                "Vittorio Pippi",
                "Fabio Quattrini",
                "Silvia Cascianelli",
                "Rita Cucchiara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20316v1",
                "http://arxiv.org/pdf/2310.20316v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20310v1",
            "title": "Energy Conserving Higher Order Mixed Finite Element Discretizations of\n  Maxwell's Equations",
            "updated": "2023-10-31T09:36:24Z",
            "published": "2023-10-31T09:36:24Z",
            "summary": "We study a system of Maxwell's equations that describes the time evolution of\nelectromagnetic fields with an additional electric scalar variable to make the\nsystem amenable to a mixed finite element spatial discretization. We\ndemonstrate stability and energy conservation for the variational formulation\nof this Maxwell's system. We then discuss two implicit, energy conserving\nschemes for its temporal discretization: the classical Crank-Nicholson scheme\nand an implicit leapfrog scheme. We next show discrete stability and discrete\nenergy conservation for the semi-discretization using these two time\nintegration methods. We complete our discussion by showing that the error for\nthe full discretization of the Maxwell's system with each of the two implicit\ntime discretization schemes and with spatial discretization through a\nconforming sequence of de Rham finite element spaces converges quadratically in\nthe step size of the time discretization and as an appropriate polynomial power\nof the mesh parameter in accordance with the choice of approximating polynomial\nspaces. Our results for the Crank-Nicholson method are generally well known but\nhave not been demonstrated for this Maxwell's system. Our implicit leapfrog\nscheme is a new method to the best of our knowledge and we provide a complete\nerror analysis for it. Finally, we show computational results to validate our\ntheoretical claims using linear and quadratic Whitney forms for the finite\nelement discretization for some model problems in two and three spatial\ndimensions.",
            "author": [
                "Archana Arya",
                "Kaushik Kalyanaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20310v1",
                "http://arxiv.org/pdf/2310.20310v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "5Q61, 65M06, 65M12, 65M15, 65M22, 65M60, 65Z05, 78M10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20309v1",
            "title": "Tensor formalism for predicting synaptic connections with ensemble\n  modeling or optimization",
            "updated": "2023-10-31T09:34:03Z",
            "published": "2023-10-31T09:34:03Z",
            "summary": "Theoretical neuroscientists often try to understand how the structure of a\nneural network relates to its function by focusing on structural features that\nwould either follow from optimization or occur consistently across possible\nimplementations. Both optimization theories and ensemble modeling approaches\nhave repeatedly proven their worth, and it would simplify theory building\nconsiderably if predictions from both theory types could be derived and tested\nsimultaneously. Here we show how tensor formalism from theoretical physics can\nbe used to unify and solve many optimization and ensemble modeling approaches\nto predicting synaptic connectivity from neuronal responses. We specifically\nfocus on analyzing the solution space of synaptic weights that allow a\nthreshold-linear neural network to respond in a prescribed way to a limited\nnumber of input conditions. For optimization purposes, we compute the synaptic\nweight vector that minimizes an arbitrary quadratic loss function. For ensemble\nmodeling, we identify synaptic weight features that occur consistently across\nall solutions bounded by an arbitrary quadratic function. We derive a common\nsolution to this suite of nonlinear problems by showing how each of them\nreduces to an equivalent linear problem that can be solved analytically.\nAlthough identifying the equivalent linear problem is nontrivial, our tensor\nformalism provides an elegant geometrical perspective that allows us to solve\nthe problem numerically. The final algorithm is applicable to a wide range of\ninteresting neuroscience problems, and the associated geometric insights may\ncarry over to other scientific problems that require constrained optimization.",
            "author": [
                "Tirthabir Biswas",
                "Tianzhi Lambus Li",
                "James E. Fitzgerald"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20309v1",
                "http://arxiv.org/pdf/2310.20309v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cond-mat.dis-nn",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20308v1",
            "title": "A physics-informed GAN Framework based on Model-free Data-Driven\n  Computational Mechanics",
            "updated": "2023-10-31T09:33:03Z",
            "published": "2023-10-31T09:33:03Z",
            "summary": "Model-free data-driven computational mechanics, first proposed by\nKirchdoerfer and Ortiz, replace phenomenological models with numerical\nsimulations based on sample data sets in strain-stress space. In this study, we\nintegrate this paradigm within physics-informed generative adversarial networks\n(GANs). We enhance the conventional physics-informed neural network framework\nby implementing the principles of data-driven computational mechanics into\nGANs. Specifically, the generator is informed by physical constraints, while\nthe discriminator utilizes the closest strain-stress data to discern the\nauthenticity of the generator's output. This combined approach presents a new\nformalism to harness data-driven mechanics and deep learning to simulate and\npredict mechanical behaviors.",
            "author": [
                "Kerem Ciftci",
                "Klaus Hackl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20308v1",
                "http://arxiv.org/pdf/2310.20308v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20305v1",
            "title": "Bilateral Network with Residual U-blocks and Dual-Guided Attention for\n  Real-time Semantic Segmentation",
            "updated": "2023-10-31T09:20:59Z",
            "published": "2023-10-31T09:20:59Z",
            "summary": "When some application scenarios need to use semantic segmentation technology,\nlike automatic driving, the primary concern comes to real-time performance\nrather than extremely high segmentation accuracy. To achieve a good trade-off\nbetween speed and accuracy, two-branch architecture has been proposed in recent\nyears. It treats spatial information and semantics information separately which\nallows the model to be composed of two networks both not heavy. However, the\nprocess of fusing features with two different scales becomes a performance\nbottleneck for many nowaday two-branch models. In this research, we design a\nnew fusion mechanism for two-branch architecture which is guided by attention\ncomputation. To be precise, we use the Dual-Guided Attention (DGA) module we\nproposed to replace some multi-scale transformations with the calculation of\nattention which means we only use several attention layers of near linear\ncomplexity to achieve performance comparable to frequently-used multi-layer\nfusion. To ensure that our module can be effective, we use Residual U-blocks\n(RSU) to build one of the two branches in our networks which aims to obtain\nbetter multi-scale features. Extensive experiments on Cityscapes and CamVid\ndataset show the effectiveness of our method.",
            "author": [
                "Liang Liao",
                "Liang Wan",
                "Mingsheng Liu",
                "Shusheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20305v1",
                "http://arxiv.org/pdf/2310.20305v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20301v1",
            "title": "Revolutionizing Global Food Security: Empowering Resilience through\n  Integrated AI Foundation Models and Data-Driven Solutions",
            "updated": "2023-10-31T09:15:35Z",
            "published": "2023-10-31T09:15:35Z",
            "summary": "Food security, a global concern, necessitates precise and diverse data-driven\nsolutions to address its multifaceted challenges. This paper explores the\nintegration of AI foundation models across various food security applications,\nleveraging distinct data types, to overcome the limitations of current deep and\nmachine learning methods. Specifically, we investigate their utilization in\ncrop type mapping, cropland mapping, field delineation and crop yield\nprediction. By capitalizing on multispectral imagery, meteorological data, soil\nproperties, historical records, and high-resolution satellite imagery, AI\nfoundation models offer a versatile approach. The study demonstrates that AI\nfoundation models enhance food security initiatives by providing accurate\npredictions, improving resource allocation, and supporting informed\ndecision-making. These models serve as a transformative force in addressing\nglobal food security limitations, marking a significant leap toward a\nsustainable and secure food future.",
            "author": [
                "Mohamed R. Shoaib",
                "Heba M. Emara",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20301v1",
                "http://arxiv.org/pdf/2310.20301v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20300v2",
            "title": "Pre-Lie algebras with divided powers and the Deligne groupoid in\n  positive characteristic",
            "updated": "2023-11-27T09:06:58Z",
            "published": "2023-10-31T09:13:55Z",
            "summary": "The purpose of this paper is to develop a deformation theory controlled by\npre-Lie algebras with divided powers over a ring of positive characteristic. We\nshow that every differential graded pre-Lie algebra with divided powers comes\nwith operations, called weighted braces, which we use to generalize the\nclassical deformation theory controlled by Lie algebras over a field of\ncharacteristic $0$. Explicitly, we define the Maurer-Cartan set, as well as the\ngauge group, and prove that there is an action of the gauge group on the\nMaurer-Cartan set. This new deformation theory moreover admits a\nGoldman-Millson theorem which remains valid on the integers. As an application,\nwe give the computation of the $\\pi_0$ of a mapping space\n$\\text{Map}(B^c(\\mathcal{C}),\\mathcal{P})$ with $\\mathcal{C}$ and $\\mathcal{P}$\nsuitable cooperad and operad respectively.",
            "author": [
                "Marvin Verstraete"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20300v2",
                "http://arxiv.org/pdf/2310.20300v2"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "17B55 18M70 17A30 20L05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20299v1",
            "title": "Verification of Neural Networks Local Differential Classification\n  Privacy",
            "updated": "2023-10-31T09:11:12Z",
            "published": "2023-10-31T09:11:12Z",
            "summary": "Neural networks are susceptible to privacy attacks. To date, no verifier can\nreason about the privacy of individuals participating in the training set. We\npropose a new privacy property, called local differential classification\nprivacy (LDCP), extending local robustness to a differential privacy setting\nsuitable for black-box classifiers. Given a neighborhood of inputs, a\nclassifier is LDCP if it classifies all inputs the same regardless of whether\nit is trained with the full dataset or whether any single entry is omitted. A\nnaive algorithm is highly impractical because it involves training a very large\nnumber of networks and verifying local robustness of the given neighborhood\nseparately for every network. We propose Sphynx, an algorithm that computes an\nabstraction of all networks, with a high probability, from a small set of\nnetworks, and verifies LDCP directly on the abstract network. The challenge is\ntwofold: network parameters do not adhere to a known distribution probability,\nmaking it difficult to predict an abstraction, and predicting too large\nabstraction harms the verification. Our key idea is to transform the parameters\ninto a distribution given by KDE, allowing to keep the over-approximation error\nsmall. To verify LDCP, we extend a MILP verifier to analyze an abstract\nnetwork. Experimental results show that by training only 7% of the networks,\nSphynx predicts an abstract network obtaining 93% verification accuracy and\nreducing the analysis time by $1.7\\cdot10^4$x.",
            "author": [
                "Roie Reshef",
                "Anan Kabaha",
                "Olga Seleznova",
                "Dana Drachsler-Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20299v1",
                "http://arxiv.org/pdf/2310.20299v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20297v1",
            "title": "Surface Second Harmonic Generation in Centrosymmetric Molecular\n  Crystalline Materials: How Thick is the Surface?",
            "updated": "2023-10-31T09:10:07Z",
            "published": "2023-10-31T09:10:07Z",
            "summary": "Second harmonic generation (SHG) is forbidden in centrosymmetric molecular\nmaterials. However, a signal is frequently observed from interfaces where the\nsymmetry is broken. Whereas the effect can be phenomenologically accommodated,\nan ab initio qualitative and quantitative description has remained elusive,\npreventing the exploration of fascinating questions such as how deep below the\nsurface the second harmonic can still be generated. To answer such questions,\nwe present an ab initio multiscale approach to compute the total and\nlayer-dependent intensity of surface SHG from molecular crystals. The\nmicroscopic origin of surface SHG is identified in layer-dependent models with\nembedding partial charges combined with density functional theory. The models\nshow increasing symmetry-breaking distortions of the electron cloud around the\nmolecules as the surface layer is approached. The SHG at the molecular level is\ndetermined using time-dependent density functional theory and then brought to\nthe scale of macroscopic films through a rigorous self-consistent multiple\nscattering formalism capable of predicting the measurable optical intensities\nof the generated second harmonic signal. We study crystalline molecular films\nwith centrosymmetric unit cells of 7,9-Dibromobenzo[h]quinolin-10-ol. The\nintensity of the SHG at the surface layer is two orders of magnitude larger\nthan at the next layer below and three orders of magnitude larger than two\nlayers below. Besides providing fundamental understanding, our approach can be\nused for designing and optimizing optical devices containing nonlinear\nmolecular materials, such as molecular laminates. We show that a relatively\nbasic Kretschmann-like setup can enhance the surface SHG of a crystalline film\nof centrosymmetric molecular unit cells a thousand times.",
            "author": [
                "Benedikt Zerulla",
                "Alejandro Luna D\u00edaz",
                "Christof Holzer",
                "Carsten Rockstuhl",
                "Ivan Fernandez-Corbaton",
                "Marjan Krsti\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20297v1",
                "http://arxiv.org/pdf/2310.20297v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20293v1",
            "title": "Annotator: A Generic Active Learning Baseline for LiDAR Semantic\n  Segmentation",
            "updated": "2023-10-31T09:04:39Z",
            "published": "2023-10-31T09:04:39Z",
            "summary": "Active learning, a label-efficient paradigm, empowers models to interactively\nquery an oracle for labeling new data. In the realm of LiDAR semantic\nsegmentation, the challenges stem from the sheer volume of point clouds,\nrendering annotation labor-intensive and cost-prohibitive. This paper presents\nAnnotator, a general and efficient active learning baseline, in which a\nvoxel-centric online selection strategy is tailored to efficiently probe and\nannotate the salient and exemplar voxel girds within each LiDAR scan, even\nunder distribution shift. Concretely, we first execute an in-depth analysis of\nseveral common selection strategies such as Random, Entropy, Margin, and then\ndevelop voxel confusion degree (VCD) to exploit the local topology relations\nand structures of point clouds. Annotator excels in diverse settings, with a\nparticular focus on active learning (AL), active source-free domain adaptation\n(ASFDA), and active domain adaptation (ADA). It consistently delivers\nexceptional performance across LiDAR semantic segmentation benchmarks, spanning\nboth simulation-to-real and real-to-real scenarios. Surprisingly, Annotator\nexhibits remarkable efficiency, requiring significantly fewer annotations,\ne.g., just labeling five voxels per scan in the SynLiDAR-to-SemanticKITTI task.\nThis results in impressive performance, achieving 87.8% fully-supervised\nperformance under AL, 88.5% under ASFDA, and 94.4% under ADA. We envision that\nAnnotator will offer a simple, general, and efficient solution for\nlabel-efficient 3D applications. Project page:\nhttps://binhuixie.github.io/annotator-web",
            "author": [
                "Binhui Xie",
                "Shuang Li",
                "Qingju Guo",
                "Chi Harold Liu",
                "Xinjing Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20293v1",
                "http://arxiv.org/pdf/2310.20293v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20292v1",
            "title": "IARS SegNet: Interpretable Attention Residual Skip connection SegNet for\n  melanoma segmentation",
            "updated": "2023-10-31T09:04:09Z",
            "published": "2023-10-31T09:04:09Z",
            "summary": "Skin lesion segmentation plays a crucial role in the computer-aided diagnosis\nof melanoma. Deep Learning models have shown promise in accurately segmenting\nskin lesions, but their widespread adoption in real-life clinical settings is\nhindered by their inherent black-box nature. In domains as critical as\nhealthcare, interpretability is not merely a feature but a fundamental\nrequirement for model adoption. This paper proposes IARS SegNet an advanced\nsegmentation framework built upon the SegNet baseline model. Our approach\nincorporates three critical components: Skip connections, residual\nconvolutions, and a global attention mechanism onto the baseline Segnet\narchitecture. These elements play a pivotal role in accentuating the\nsignificance of clinically relevant regions, particularly the contours of skin\nlesions. The inclusion of skip connections enhances the model's capacity to\nlearn intricate contour details, while the use of residual convolutions allows\nfor the construction of a deeper model while preserving essential image\nfeatures. The global attention mechanism further contributes by extracting\nrefined feature maps from each convolutional and deconvolutional block, thereby\nelevating the model's interpretability. This enhancement highlights critical\nregions, fosters better understanding, and leads to more accurate skin lesion\nsegmentation for melanoma diagnosis.",
            "author": [
                "Shankara Narayanan V",
                "Sikha OK",
                "Raul Benitez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20292v1",
                "http://arxiv.org/pdf/2310.20292v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20290v4",
            "title": "On Rayleigh Quotient Iteration for Dual Quaternion Hermitian Eigenvalue\n  Problem",
            "updated": "2023-11-23T01:12:22Z",
            "published": "2023-10-31T09:03:17Z",
            "summary": "The application of eigenvalue theory to dual quaternion Hermitian matrix\nholds significance in the realm of multi-agent formation control. In this\npaper, we focus on the numerical algorithm for the right eigenvalue of a dual\nquaternion Hermitian matrix. Rayleigh quotient iteration is proposed for\ncomputing the extreme eigenvalue with the associated eigenvector of the dual\nquaternion Hermitian matrix. We also derive an analysis of the convergence\ncharacteristics of the Rayleigh quotient iteration, which exhibits a local\nconvergence rate of cubic. Numerical examples are provided to illustrate the\nefficiency of the proposed Rayleigh quotient iteration for the dual quaternion\nHermitian eigenvalue problem.",
            "author": [
                "Shan-Qi Duan",
                "Qing-Wen Wang",
                "Xue-Feng Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20290v4",
                "http://arxiv.org/pdf/2310.20290v4"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20285v1",
            "title": "Accelerating Generalized Linear Models by Trading off Computation for\n  Uncertainty",
            "updated": "2023-10-31T08:58:16Z",
            "published": "2023-10-31T08:58:16Z",
            "summary": "Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic\nframework to model categorical, ordinal and continuous data, and are widely\nused in practice. However, exact inference in GLMs is prohibitively expensive\nfor large datasets, thus requiring approximations in practice. The resulting\napproximation error adversely impacts the reliability of the model and is not\naccounted for in the uncertainty of the prediction. In this work, we introduce\na family of iterative methods that explicitly model this error. They are\nuniquely suited to parallel modern computing hardware, efficiently recycle\ncomputations, and compress information to reduce both the time and memory\nrequirements for GLMs. As we demonstrate on a realistically large\nclassification problem, our method significantly accelerates training by\nexplicitly trading off reduced computation for increased uncertainty.",
            "author": [
                "Lukas Tatzel",
                "Jonathan Wenger",
                "Frank Schneider",
                "Philipp Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20285v1",
                "http://arxiv.org/pdf/2310.20285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20279v1",
            "title": "Machine learning refinement of in situ images acquired by low electron\n  dose LC-TEM",
            "updated": "2023-10-31T08:48:59Z",
            "published": "2023-10-31T08:48:59Z",
            "summary": "We study a machine learning (ML) technique for refining images acquired\nduring in situ observation using liquid-cell transmission electron microscopy\n(LC-TEM). Our model is constructed using a U-Net architecture and a ResNet\nencoder. For training our ML model, we prepared an original image dataset that\ncontained pairs of images of samples acquired with and without a solution\npresent. The former images were used as noisy images and the latter images were\nused as corresponding ground truth images. The number of pairs of image sets\nwas $1,204$ and the image sets included images acquired at several different\nmagnifications and electron doses. The trained model converted a noisy image\ninto a clear image. The time necessary for the conversion was on the order of\n10ms, and we applied the model to in situ observations using the software Gatan\nDigitalMicrograph (DM). Even if a nanoparticle was not visible in a view window\nin the DM software because of the low electron dose, it was visible in a\nsuccessive refined image generated by our ML model.",
            "author": [
                "Hiroyasu Katsuno",
                "Yuki Kimura",
                "Tomoya Yamazaki",
                "Ichigaku Takigawa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20279v1",
                "http://arxiv.org/pdf/2310.20279v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20274v1",
            "title": "Extracting Entities of Interest from Comparative Product Reviews",
            "updated": "2023-10-31T08:43:11Z",
            "published": "2023-10-31T08:43:11Z",
            "summary": "This paper presents a deep learning based approach to extract product\ncomparison information out of user reviews on various e-commerce websites. Any\ncomparative product review has three major entities of information: the names\nof the products being compared, the user opinion (predicate) and the feature or\naspect under comparison. All these informing entities are dependent on each\nother and bound by the rules of the language, in the review. We observe that\ntheir inter-dependencies can be captured well using LSTMs. We evaluate our\nsystem on existing manually labeled datasets and observe out-performance over\nthe existing Semantic Role Labeling (SRL) framework popular for this task.",
            "author": [
                "Jatin Arora",
                "Sumit Agrawal",
                "Pawan Goyal",
                "Sayan Pathak"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3132847.3133141",
                "http://arxiv.org/abs/2310.20274v1",
                "http://arxiv.org/pdf/2310.20274v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL",
                "cs.LG",
                "I.2.7; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20271v2",
            "title": "From Denoising Training to Test-Time Adaptation: Enhancing Domain\n  Generalization for Medical Image Segmentation",
            "updated": "2023-11-03T03:48:43Z",
            "published": "2023-10-31T08:39:15Z",
            "summary": "In medical image segmentation, domain generalization poses a significant\nchallenge due to domain shifts caused by variations in data acquisition devices\nand other factors. These shifts are particularly pronounced in the most common\nscenario, which involves only single-source domain data due to privacy\nconcerns. To address this, we draw inspiration from the self-supervised\nlearning paradigm that effectively discourages overfitting to the source\ndomain. We propose the Denoising Y-Net (DeY-Net), a novel approach\nincorporating an auxiliary denoising decoder into the basic U-Net architecture.\nThe auxiliary decoder aims to perform denoising training, augmenting the\ndomain-invariant representation that facilitates domain generalization.\nFurthermore, this paradigm provides the potential to utilize unlabeled data.\nBuilding upon denoising training, we propose Denoising Test Time Adaptation\n(DeTTA) that further: (i) adapts the model to the target domain in a\nsample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive\nexperiments conducted on widely-adopted liver segmentation benchmarks\ndemonstrate significant domain generalization improvements over our baseline\nand state-of-the-art results compared to other methods. Code is available at\nhttps://github.com/WenRuxue/DeTTA.",
            "author": [
                "Ruxue Wen",
                "Hangjie Yuan",
                "Dong Ni",
                "Wenbo Xiao",
                "Yaoyao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20271v2",
                "http://arxiv.org/pdf/2310.20271v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20268v1",
            "title": "Constructing Sample-to-Class Graph for Few-Shot Class-Incremental\n  Learning",
            "updated": "2023-10-31T08:38:14Z",
            "published": "2023-10-31T08:38:14Z",
            "summary": "Few-shot class-incremental learning (FSCIL) aims to build machine learning\nmodel that can continually learn new concepts from a few data samples, without\nforgetting knowledge of old classes.\n  The challenges of FSCIL lies in the limited data of new classes, which not\nonly lead to significant overfitting issues but also exacerbates the notorious\ncatastrophic forgetting problems. As proved in early studies, building sample\nrelationships is beneficial for learning from few-shot samples. In this paper,\nwe promote the idea to the incremental scenario, and propose a Sample-to-Class\n(S2C) graph learning method for FSCIL.\n  Specifically, we propose a Sample-level Graph Network (SGN) that focuses on\nanalyzing sample relationships within a single session. This network helps\naggregate similar samples, ultimately leading to the extraction of more refined\nclass-level features.\n  Then, we present a Class-level Graph Network (CGN) that establishes\nconnections across class-level features of both new and old classes. This\nnetwork plays a crucial role in linking the knowledge between different\nsessions and helps improve overall learning in the FSCIL scenario. Moreover, we\ndesign a multi-stage strategy for training S2C model, which mitigates the\ntraining challenges posed by limited data in the incremental process.\n  The multi-stage training strategy is designed to build S2C graph from base to\nfew-shot stages, and improve the capacity via an extra pseudo-incremental\nstage. Experiments on three popular benchmark datasets show that our method\nclearly outperforms the baselines and sets new state-of-the-art results in\nFSCIL.",
            "author": [
                "Fuyuan Hu",
                "Jian Zhang",
                "Fan Lyu",
                "Linyan Li",
                "Fenglei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20268v1",
                "http://arxiv.org/pdf/2310.20268v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20267v1",
            "title": "A non-overlapping optimization-based domain decomposition approach to\n  component-based model reduction of incompressible flows",
            "updated": "2023-10-31T08:38:01Z",
            "published": "2023-10-31T08:38:01Z",
            "summary": "We present a component-based model order reduction procedure to efficiently\nand accurately solve parameterized incompressible flows governed by the\nNavier-Stokes equations. Our approach leverages a non-overlapping\noptimization-based domain decomposition technique to determine the control\nvariable that minimizes jumps across the interfaces between sub-domains. To\nsolve the resulting constrained optimization problem, we propose both\nGauss-Newton and sequential quadratic programming methods, which effectively\ntransform the constrained problem into an unconstrained formulation.\nFurthermore, we integrate model order reduction techniques into the\noptimization framework, to speed up computations. In particular, we incorporate\nlocalized training and adaptive enrichment to reduce the burden associated with\nthe training of the local reduced-order models. Numerical results are presented\nto demonstrate the validity and effectiveness of the overall methodology.",
            "author": [
                "Tommaso Taddei",
                "Xuejun Xu",
                "Lei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20267v1",
                "http://arxiv.org/pdf/2310.20267v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N30, 41A45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20266v1",
            "title": "Beyond Average Return in Markov Decision Processes",
            "updated": "2023-10-31T08:36:41Z",
            "published": "2023-10-31T08:36:41Z",
            "summary": "What are the functionals of the reward that can be computed and optimized\nexactly in Markov Decision Processes? In the finite-horizon, undiscounted\nsetting, Dynamic Programming (DP) can only handle these operations efficiently\nfor certain classes of statistics. We summarize the characterization of these\nclasses for policy evaluation, and give a new answer for the planning problem.\nInterestingly, we prove that only generalized means can be optimized exactly,\neven in the more general framework of Distributional Reinforcement Learning\n(DistRL).DistRL permits, however, to evaluate other functionals approximately.\nWe provide error bounds on the resulting estimators, and discuss the potential\nof this approach as well as its limitations.These results contribute to\nadvancing the theory of Markov Decision Processes by examining overall\ncharacteristics of the return, and particularly risk-conscious strategies.",
            "author": [
                "Alexandre Marthe",
                "Aur\u00e9lien Garivier",
                "Claire Vernade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20266v1",
                "http://arxiv.org/pdf/2310.20266v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20265v1",
            "title": "Low-Dose CT Image Enhancement Using Deep Learning",
            "updated": "2023-10-31T08:34:33Z",
            "published": "2023-10-31T08:34:33Z",
            "summary": "The application of ionizing radiation for diagnostic imaging is common around\nthe globe. However, the process of imaging, itself, remains to be a relatively\nhazardous operation. Therefore, it is preferable to use as low a dose of\nionizing radiation as possible, particularly in computed tomography (CT)\nimaging systems, where multiple x-ray operations are performed for the\nreconstruction of slices of body tissues. A popular method for radiation dose\nreduction in CT imaging is known as the quarter-dose technique, which reduces\nthe x-ray dose but can cause a loss of image sharpness. Since CT image\nreconstruction from directional x-rays is a nonlinear process, it is\nanalytically difficult to correct the effect of dose reduction on image\nquality. Recent and popular deep-learning approaches provide an intriguing\npossibility of image enhancement for low-dose artifacts. Some recent works\npropose combinations of multiple deep-learning and classical methods for this\npurpose, which over-complicate the process. However, it is observed here that\nthe straight utilization of the well-known U-NET provides very successful\nresults for the correction of low-dose artifacts. Blind tests with actual\nradiologists reveal that the U-NET enhanced quarter-dose CT images not only\nprovide an immense visual improvement over the low-dose versions, but also\nbecome diagnostically preferable images, even when compared to their full-dose\nCT versions.",
            "author": [
                "A. Demir",
                "M. M. A. Shames",
                "O. N. Gerek",
                "S. Ergin",
                "M. Fidan",
                "M. Koc",
                "M. B. Gulmezoglu",
                "A. Barkana",
                "C. Calisir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20265v1",
                "http://arxiv.org/pdf/2310.20265v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20260v1",
            "title": "Learning to Play Chess from Textbooks (LEAP): a Corpus for Evaluating\n  Chess Moves based on Sentiment Analysis",
            "updated": "2023-10-31T08:26:02Z",
            "published": "2023-10-31T08:26:02Z",
            "summary": "Learning chess strategies has been investigated widely, with most studies\nfocussing on learning from previous games using search algorithms. Chess\ntextbooks encapsulate grandmaster knowledge, explain playing strategies and\nrequire a smaller search space compared to traditional chess agents. This paper\nexamines chess textbooks as a new knowledge source for enabling machines to\nlearn how to play chess -- a resource that has not been explored previously. We\ndeveloped the LEAP corpus, a first and new heterogeneous dataset with\nstructured (chess move notations and board states) and unstructured data\n(textual descriptions) collected from a chess textbook containing 1164\nsentences discussing strategic moves from 91 games. We firstly labelled the\nsentences based on their relevance, i.e., whether they are discussing a move.\nEach relevant sentence was then labelled according to its sentiment towards the\ndescribed move. We performed empirical experiments that assess the performance\nof various transformer-based baseline models for sentiment analysis. Our\nresults demonstrate the feasibility of employing transformer-based sentiment\nanalysis models for evaluating chess moves, with the best performing model\nobtaining a weighted micro F_1 score of 68%. Finally, we synthesised the LEAP\ncorpus to create a larger dataset, which can be used as a solution to the\nlimited textual resource in the chess domain.",
            "author": [
                "Haifa Alrdahi",
                "Riza Batista-Navarro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20260v1",
                "http://arxiv.org/pdf/2310.20260v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14676v1",
            "title": "Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain\n  Governance Communities",
            "updated": "2023-10-31T08:23:47Z",
            "published": "2023-10-31T08:23:47Z",
            "summary": "Blockchain technology is leading a revolutionary transformation across\ndiverse industries, with effective governance standing as a critical\ndeterminant for the success and sustainability of blockchain projects.\nCommunity forums, pivotal in engaging decentralized autonomous organizations\n(DAOs), wield a substantial impact on blockchain governance decisions.\nConcurrently, Natural Language Processing (NLP), particularly sentiment\nanalysis, provides powerful insights from textual data. While prior research\nhas explored the potential of NLP tools in social media sentiment analysis, a\ngap persists in understanding the sentiment landscape of blockchain governance\ncommunities. The evolving discourse and sentiment dynamics on the forums of top\nDAOs remain largely unknown. This paper delves deep into the evolving discourse\nand sentiment dynamics on the public forums of leading DeFi projects -- Aave,\nUniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer --\nplacing a primary focus on discussions related to governance issues. Despite\ndiffering activity patterns, participants across these decentralized\ncommunities consistently express positive sentiments in their Discord\ndiscussions, indicating optimism towards governance decisions. Additionally,\nour research suggests a potential interplay between discussion intensity and\nsentiment dynamics, indicating that higher discussion volumes may contribute to\nmore stable and positive emotions. The insights gained from this study are\nvaluable for decision-makers in blockchain governance, underscoring the pivotal\nrole of sentiment analysis in interpreting community emotions and its evolving\nimpact on the landscape of blockchain governance. This research significantly\ncontributes to the interdisciplinary exploration of the intersection of\nblockchain and society, with a specific emphasis on the decentralized\nblockchain governance ecosystem.",
            "author": [
                "Yutong Quan",
                "Xintong Wu",
                "Wanlin Deng",
                "Luyao Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.31219/osf.io/bq6tu",
                "http://arxiv.org/abs/2311.14676v1",
                "http://arxiv.org/pdf/2311.14676v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR",
                "cs.HC",
                "econ.GN",
                "q-fin.EC",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20256v2",
            "title": "PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for\n  Personality Detection",
            "updated": "2023-11-05T03:19:18Z",
            "published": "2023-10-31T08:23:33Z",
            "summary": "Recent advances in large language models (LLMs), such as ChatGPT, have\nshowcased remarkable zero-shot performance across various NLP tasks. However,\nthe potential of LLMs in personality detection, which involves identifying an\nindividual's personality from their written texts, remains largely unexplored.\nDrawing inspiration from Psychological Questionnaires, which are carefully\ndesigned by psychologists to evaluate individual personality traits through a\nseries of targeted items, we argue that these items can be regarded as a\ncollection of well-structured chain-of-thought (CoT) processes. By\nincorporating these processes, LLMs can enhance their capabilities to make more\nreasonable inferences on personality from textual input. In light of this, we\npropose a novel personality detection method, called PsyCoT, which mimics the\nway individuals complete psychological questionnaires in a multi-turn dialogue\nmanner. In particular, we employ a LLM as an AI assistant with a specialization\nin text analysis. We prompt the assistant to rate individual items at each turn\nand leverage the historical rating results to derive a conclusive personality\npreference. Our experiments demonstrate that PsyCoT significantly improves the\nperformance and robustness of GPT-3.5 in personality detection, achieving an\naverage F1 score improvement of 4.23/10.63 points on two benchmark datasets\ncompared to the standard prompting method. Our code is available at\nhttps://github.com/TaoYang225/PsyCoT.",
            "author": [
                "Tao Yang",
                "Tianyuan Shi",
                "Fanqi Wan",
                "Xiaojun Quan",
                "Qifan Wang",
                "Bingzhe Wu",
                "Jiaxiang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20256v2",
                "http://arxiv.org/pdf/2310.20256v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20253v1",
            "title": "Cut elimination for Zermelo set theory",
            "updated": "2023-10-31T08:14:24Z",
            "published": "2023-10-31T08:14:24Z",
            "summary": "We show how to express intuitionistic Zermelo set theory in deduction modulo\n(i.e. by replacing its axioms by rewrite rules) in such a way that the\ncorresponding notion of proof enjoys the normalization property. To do so, we\nfirst rephrase set theory as a theory of pointed graphs (following a paradigm\ndue to P. Aczel) by interpreting set-theoretic equality as bisimilarity, and\nshow that in this setting, Zermelo's axioms can be decomposed into\ngraph-theoretic primitives that can be turned into rewrite rules. We then show\nthat the theory we obtain in deduction modulo is a conservative extension of (a\nminor extension of) Zermelo set theory. Finally, we prove the normalization of\nthe intuitionistic fragment of the theory.",
            "author": [
                "Gilles Dowek",
                "Alexandre Miquel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20253v1",
                "http://arxiv.org/pdf/2310.20253v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20249v1",
            "title": "Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior",
            "updated": "2023-10-31T08:13:00Z",
            "published": "2023-10-31T08:13:00Z",
            "summary": "Creating believable motions for various characters has long been a goal in\ncomputer graphics. Current learning-based motion synthesis methods depend on\nextensive motion datasets, which are often challenging, if not impossible, to\nobtain. On the other hand, pose data is more accessible, since static posed\ncharacters are easier to create and can even be extracted from images using\nrecent advancements in computer vision. In this paper, we utilize this\nalternative data source and introduce a neural motion synthesis approach\nthrough retargeting. Our method generates plausible motions for characters that\nhave only pose data by transferring motion from an existing motion capture\ndataset of another character, which can have drastically different skeletons.\nOur experiments show that our method effectively combines the motion features\nof the source character with the pose features of the target character, and\nperforms robustly with small or noisy pose data sets, ranging from a few\nartist-created poses to noisy poses estimated directly from images.\nAdditionally, a conducted user study indicated that a majority of participants\nfound our retargeted motion to be more enjoyable to watch, more lifelike in\nappearance, and exhibiting fewer artifacts. Project page:\nhttps://cyanzhao42.github.io/pose2motion",
            "author": [
                "Qingqing Zhao",
                "Peizhuo Li",
                "Wang Yifan",
                "Olga Sorkine-Hornung",
                "Gordon Wetzstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20249v1",
                "http://arxiv.org/pdf/2310.20249v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20248v1",
            "title": "Relative normalization",
            "updated": "2023-10-31T08:12:34Z",
            "published": "2023-10-31T08:12:34Z",
            "summary": "G{\\\"o}del's second incompleteness theorem forbids to prove, in a given theory\nU, the consistency of many theories-in particular, of the theory U itself-as\nwell as it forbids to prove the normalization property for these theories,\nsince this property implies their consistency. When we cannot prove in a theory\nU the consistency of a theory T , we can try to prove a relative consistency\ntheorem, that is, a theorem of the form: If U is consistent then T is\nconsistent. Following the same spirit, we show in this paper how to prove\nrelative normalization theorems, that is, theorems of the form: If U is\n1-consistent, then T has the normalization property.",
            "author": [
                "Gilles Dowek",
                "Alexandre Miquel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20248v1",
                "http://arxiv.org/pdf/2310.20248v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20246v4",
            "title": "Breaking Language Barriers in Multilingual Mathematical Reasoning:\n  Insights and Observations",
            "updated": "2023-11-28T05:25:14Z",
            "published": "2023-10-31T08:09:20Z",
            "summary": "Existing research predominantly focuses on developing powerful language\nlearning models (LLMs) for mathematical reasoning within monolingual languages,\nwith few explorations in preserving efficacy in a multilingual context. To\nbridge this gap, this paper pioneers exploring and training powerful\nMultilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we\nconstruct the first multilingual math reasoning instruction dataset,\nMGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue\nof training data scarcity in xMR tasks. Based on the collected dataset, we\npropose different training strategies to build powerful xMR LLMs, named\nMathOctopus, notably outperform conventional open-source LLMs and exhibit\nsuperiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B\nreaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond\nremarkable results, we unearth several pivotal observations and insights from\nextensive experiments: (1) When extending the rejection sampling strategy to\nthe multilingual context, it proves effective for model performances, albeit\nlimited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)\nacross multiple languages not only significantly enhances model performance\nmultilingually but also elevates their monolingual performance. This indicates\nthat crafting multilingual corpora can be regarded as a vital strategy for\nenhancing model performance in a specific language, especially in mathematical\nreasoning tasks. For instance, MathOctopus-7B improves its counterparts that\ntrained on English from 42.2% to 50.8% on GSM8K testset.",
            "author": [
                "Nuo Chen",
                "Zinan Zheng",
                "Ning Wu",
                "Ming Gong",
                "Yangqiu Song",
                "Dongmei Zhang",
                "Jia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20246v4",
                "http://arxiv.org/pdf/2310.20246v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20243v2",
            "title": "Contrast-agent-induced deterministic component of CT-density in the\n  abdominal aorta during routine angiography: proof of concept study",
            "updated": "2023-11-03T11:14:19Z",
            "published": "2023-10-31T07:59:57Z",
            "summary": "Background and objective: CTA is a gold standard of preoperative diagnosis of\nabdominal aorta and typically used for geometric-only characteristic\nextraction. We assume that a model describing the dynamic behavior of the\ncontrast agent in the vessel can be developed from the data of routine CTA\nstudies, allowing the procedure to be investigated and optimized without the\nneed for additional perfusion CT studies. Obtained spatial distribution of CA\ncan be valuable for both increasing the diagnostic value of a particular study\nand improving the CT data processing tools. Methods: In accordance with the\nBeer-Lambert law and the absence of chemical interaction between blood and CA,\nwe postulated the existence of a deterministic CA-induced component in the CT\nsignal density. The proposed model, having a double-sigmoid structure, contains\nsix coefficients relevant to the properties of hemodynamics. To validate the\nmodel, expert segmentation was performed using the 3D Slicer application for\nthe CTA data obtained from publicly available source. The model was fitted to\nthe data using the non-linear least square method with Levenberg-Marquardt\noptimization. Results: We analyzed 594 CTA images (4 studies with median size\nof 144 slices, IQR [134; 158.5]; 1:1 normal:pathology balance). Goodness-of-fit\nwas proved by Wilcox test (p-value > 0.05 for all cases). The proposed model\ncorrectly simulated normal blood flow and hemodynamics disturbances caused by\nlocal abnormalities (aneurysm, thrombus and arterial branching). Conclusions:\nProposed approach can be useful for personalized CA modeling of vessels,\nimprovement of CTA image processing and preparation of synthetic CT training\ndata for artificial intelligence.",
            "author": [
                "Maria R. Kodenko",
                "Yuriy A. Vasilev",
                "Nicholas S. Kulberg",
                "Andrey V. Samorodov",
                "Anton V. Vladzimirskyy",
                "Olga V. Omelyanskaya",
                "Roman V. Reshetnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20243v2",
                "http://arxiv.org/pdf/2310.20243v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20240v1",
            "title": "Breathing Life into Faces: Speech-driven 3D Facial Animation with\n  Natural Head Pose and Detailed Shape",
            "updated": "2023-10-31T07:47:19Z",
            "published": "2023-10-31T07:47:19Z",
            "summary": "The creation of lifelike speech-driven 3D facial animation requires a natural\nand precise synchronization between audio input and facial expressions.\nHowever, existing works still fail to render shapes with flexible head poses\nand natural facial details (e.g., wrinkles). This limitation is mainly due to\ntwo aspects: 1) Collecting training set with detailed 3D facial shapes is\nhighly expensive. This scarcity of detailed shape annotations hinders the\ntraining of models with expressive facial animation. 2) Compared to mouth\nmovement, the head pose is much less correlated to speech content.\nConsequently, concurrent modeling of both mouth movement and head pose yields\nthe lack of facial movement controllability. To address these challenges, we\nintroduce VividTalker, a new framework designed to facilitate speech-driven 3D\nfacial animation characterized by flexible head pose and natural facial\ndetails. Specifically, we explicitly disentangle facial animation into head\npose and mouth movement and encode them separately into discrete latent spaces.\nThen, these attributes are generated through an autoregressive process\nleveraging a window-based Transformer architecture. To augment the richness of\n3D facial animation, we construct a new 3D dataset with detailed shapes and\nlearn to synthesize facial details in line with speech content. Extensive\nquantitative and qualitative experiments demonstrate that VividTalker\noutperforms state-of-the-art methods, resulting in vivid and realistic\nspeech-driven 3D facial animation.",
            "author": [
                "Wei Zhao",
                "Yijun Wang",
                "Tianyu He",
                "Lianying Yin",
                "Jianxin Lin",
                "Xin Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20240v1",
                "http://arxiv.org/pdf/2310.20240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20236v1",
            "title": "Dynamically Updating Event Representations for Temporal Relation\n  Classification with Multi-category Learning",
            "updated": "2023-10-31T07:41:24Z",
            "published": "2023-10-31T07:41:24Z",
            "summary": "Temporal relation classification is a pair-wise task for identifying the\nrelation of a temporal link (TLINK) between two mentions, i.e. event, time, and\ndocument creation time (DCT). It leads to two crucial limits: 1) Two TLINKs\ninvolving a common mention do not share information. 2) Existing models with\nindependent classifiers for each TLINK category (E2E, E2T, and E2D) hinder from\nusing the whole data. This paper presents an event centric model that allows to\nmanage dynamic event representations across multiple TLINKs. Our model deals\nwith three TLINK categories with multi-task learning to leverage the full size\nof data. The experimental results show that our proposal outperforms\nstate-of-the-art models and two transfer learning baselines on both the English\nand Japanese data.",
            "author": [
                "Fei Cheng",
                "Masayuki Asahara",
                "Ichiro Kobayashi",
                "Sadao Kurohashi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20236v1",
                "http://arxiv.org/pdf/2310.20236v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20235v1",
            "title": "Powers of generalized binomial edge ideals of path graphs",
            "updated": "2023-10-31T07:36:31Z",
            "published": "2023-10-31T07:36:31Z",
            "summary": "In this article, we study the powers of the generalized binomial edge ideal\n$\\mathcal{J}_{K_m,P_n}$ of a path graph $P_n$. We explicitly compute their\nregularities and determine the limit of their depths. We also show that these\nordinary powers coincide with their symbolic powers. Additionally, we study the\nRees algebra and the special fiber ring of $\\mathcal{J}_{K_m,P_n}$ via Sagbi\nbasis theory. In particular, we obtain exact formulas for the regularity of\nthese blowup algebras.",
            "author": [
                "Yi-Huang Shen",
                "Guangjun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20235v1",
                "http://arxiv.org/pdf/2310.20235v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "Primary 13C15, 13P10, Secondary 05E40, 13F20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20234v1",
            "title": "HEDNet: A Hierarchical Encoder-Decoder Network for 3D Object Detection\n  in Point Clouds",
            "updated": "2023-10-31T07:32:08Z",
            "published": "2023-10-31T07:32:08Z",
            "summary": "3D object detection in point clouds is important for autonomous driving\nsystems. A primary challenge in 3D object detection stems from the sparse\ndistribution of points within the 3D scene. Existing high-performance methods\ntypically employ 3D sparse convolutional neural networks with small kernels to\nextract features. To reduce computational costs, these methods resort to\nsubmanifold sparse convolutions, which prevent the information exchange among\nspatially disconnected features. Some recent approaches have attempted to\naddress this problem by introducing large-kernel convolutions or self-attention\nmechanisms, but they either achieve limited accuracy improvements or incur\nexcessive computational costs. We propose HEDNet, a hierarchical\nencoder-decoder network for 3D object detection, which leverages\nencoder-decoder blocks to capture long-range dependencies among features in the\nspatial space, particularly for large and distant objects. We conducted\nextensive experiments on the Waymo Open and nuScenes datasets. HEDNet achieved\nsuperior detection accuracy on both datasets than previous state-of-the-art\nmethods with competitive efficiency. The code is available at\nhttps://github.com/zhanggang001/HEDNet.",
            "author": [
                "Gang Zhang",
                "Junnan Chen",
                "Guohuan Gao",
                "Jianmin Li",
                "Xiaolin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20234v1",
                "http://arxiv.org/pdf/2310.20234v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04225v1",
            "title": "Fast, accurate, and interpretable decoding of electrocorticographic\n  signals using dynamic mode decomposition",
            "updated": "2023-10-31T07:13:43Z",
            "published": "2023-10-31T07:13:43Z",
            "summary": "Dynamic mode (DM) decomposition decomposes spatiotemporal signals into basic\noscillatory components (DMs). DMs can improve the accuracy of neural decoding\nwhen used with the nonlinear Grassmann kernel, compared to conventional power\nfeatures. However, such kernel-based machine learning algorithms have three\nlimitations: large computational time preventing real-time application,\nincompatibility with non-kernel algorithms, and low interpretability. Here, we\npropose a mapping function corresponding to the Grassmann kernel that\nexplicitly transforms DMs into spatial DM (sDM) features, which can be used in\nany machine learning algorithm. Using electrocorticographic signals recorded\nduring various movement and visual perception tasks, the sDM features were\nshown to improve the decoding accuracy and computational time compared to\nconventional methods. Furthermore, the components of the sDM features\ninformative for decoding showed similar characteristics to the high-$\\gamma$\npower of the signals, but with higher trial-to-trial reproducibility. The\nproposed sDM features enable fast, accurate, and interpretable neural decoding.",
            "author": [
                "Ryohei Fukuma",
                "Kei Majima",
                "Yoshinobu Kawahara",
                "Okito Yamashita",
                "Yoshiyuki Shiraishi",
                "Haruhiko Kishima",
                "Takufumi Yanagisawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04225v1",
                "http://arxiv.org/pdf/2311.04225v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10746v1",
            "title": "EIT: Earnest Insight Toolkit for Evaluating Students' Earnestness in\n  Interactive Lecture Participation Exercises",
            "updated": "2023-10-31T07:05:00Z",
            "published": "2023-10-31T07:05:00Z",
            "summary": "In today's rapidly evolving educational landscape, traditional modes of\npassive information delivery are giving way to transformative pedagogical\napproaches that prioritize active student engagement. Within the context of\nlarge-scale hybrid classrooms, the challenge lies in fostering meaningful and\nactive interaction between students and course content. This study delves into\nthe significance of measuring students' earnestness during interactive lecture\nparticipation exercises. By analyzing students' responses to interactive\nlecture poll questions, establishing a clear rubric for evaluating earnestness,\nand conducting a comprehensive assessment, we introduce EIT (Earnest Insight\nToolkit), a tool designed to assess students' engagement within interactive\nlecture participation exercises - particularly in the context of large-scale\nhybrid classrooms. Through the utilization of EIT, our objective is to equip\neducators with valuable means of identifying at-risk students for enhancing\nintervention and support strategies, as well as measuring students' levels of\nengagement with course content.",
            "author": [
                "Mihran Miroyan",
                "Shiny Weng",
                "Rahul Shah",
                "Lisa Yan",
                "Narges Norouzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10746v1",
                "http://arxiv.org/pdf/2311.10746v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20225v1",
            "title": "VisPercep: A Vision-Language Approach to Enhance Visual Perception for\n  People with Blindness and Low Vision",
            "updated": "2023-10-31T06:56:51Z",
            "published": "2023-10-31T06:56:51Z",
            "summary": "People with blindness and low vision (pBLV) encounter substantial challenges\nwhen it comes to comprehensive scene recognition and precise object\nidentification in unfamiliar environments. Additionally, due to the vision\nloss, pBLV have difficulty in accessing and identifying potential tripping\nhazards on their own. In this paper, we present a pioneering approach that\nleverages a large vision-language model to enhance visual perception for pBLV,\noffering detailed and comprehensive descriptions of the surrounding\nenvironments and providing warnings about the potential risks. Our method\nbegins by leveraging a large image tagging model (i.e., Recognize Anything\n(RAM)) to identify all common objects present in the captured images. The\nrecognition results and user query are then integrated into a prompt, tailored\nspecifically for pBLV using prompt engineering. By combining the prompt and\ninput image, a large vision-language model (i.e., InstructBLIP) generates\ndetailed and comprehensive descriptions of the environment and identifies\npotential risks in the environment by analyzing the environmental objects and\nscenes, relevant to the prompt. We evaluate our approach through experiments\nconducted on both indoor and outdoor datasets. Our results demonstrate that our\nmethod is able to recognize objects accurately and provide insightful\ndescriptions and analysis of the environment for pBLV.",
            "author": [
                "Yu Hao",
                "Fan Yang",
                "Hao Huang",
                "Shuaihang Yuan",
                "Sundeep Rangan",
                "John-Ross Rizzo",
                "Yao Wang",
                "Yi Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20225v1",
                "http://arxiv.org/pdf/2310.20225v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01470v1",
            "title": "Preliminary Estimators of Population Mean using Ranked Set Sampling in\n  the Presence of Measurement Error and Non-Response Error",
            "updated": "2023-10-31T06:54:24Z",
            "published": "2023-10-31T06:54:24Z",
            "summary": "In order to estimate the population mean in the presence of both non-response\nand measurement errors that are uncorrelated, the paper presents some novel\nestimators employing ranked set sampling by utilizing auxiliary information.Up\nto the first order of approximation, the equations for the bias and mean\nsquared error of the suggested estimators are produced, and it is found that\nthe proposed estimators outperform the other existing estimators analysed in\nthis study. Investigations using simulation studies and numerical examples show\nhow well the suggested estimators perform in the presence of measurement and\nnon-response errors. The relative efficiency of the suggested estimators\ncompared to the existing estimators has been expressed as a percentage, and the\nimpact of measurement errors has been expressed as a percentage computation of\nmeasurement errors.",
            "author": [
                "Rajesh Singh",
                "Anamika Kumari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01470v1",
                "http://arxiv.org/pdf/2311.01470v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "62D05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20221v1",
            "title": "Cayley Linear-Time Computable Groups",
            "updated": "2023-10-31T06:48:12Z",
            "published": "2023-10-31T06:48:12Z",
            "summary": "This paper looks at the class of groups admitting normal forms for which the\nright multiplication by a group element is computed in linear time on a\nmulti-tape Turing machine. We show that the groups $\\mathbb{Z}_2 \\wr\n\\mathbb{Z}^2$, $\\mathbb{Z}_2 \\wr \\mathbb{F}_2$ and Thompson's group $F$ have\nnormal forms for which the right multiplication by a group element is computed\nin linear time on a $2$-tape Turing machine. This refines the results\npreviously established by Elder and the authors that these groups are Cayley\npolynomial-time computable.",
            "author": [
                "Prohrak Kruengthomya",
                "Dmitry Berdinsky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20221v1",
                "http://arxiv.org/pdf/2310.20221v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20216v1",
            "title": "Does GPT-4 Pass the Turing Test?",
            "updated": "2023-10-31T06:27:52Z",
            "published": "2023-10-31T06:27:52Z",
            "summary": "We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4\nprompt passed in 41% of games, outperforming baselines set by ELIZA (27%) and\nGPT-3.5 (14%), but falling short of chance and the baseline set by human\nparticipants (63%). Participants' decisions were based mainly on linguistic\nstyle (35%) and socio-emotional traits (27%), supporting the idea that\nintelligence is not sufficient to pass the Turing Test. Participants'\ndemographics, including education and familiarity with LLMs, did not predict\ndetection rate, suggesting that even those who understand systems deeply and\ninteract with them frequently may be susceptible to deception. Despite known\nlimitations as a test of intelligence, we argue that the Turing Test continues\nto be relevant as an assessment of naturalistic communication and deception. AI\nmodels with the ability to masquerade as humans could have widespread societal\nconsequences, and we analyse the effectiveness of different strategies and\ncriteria for judging humanlikeness.",
            "author": [
                "Cameron Jones",
                "Benjamin Bergen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20216v1",
                "http://arxiv.org/pdf/2310.20216v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20212v3",
            "title": "A Comparative Evaluation of Automated Analysis Tools for Solidity Smart\n  Contracts",
            "updated": "2023-11-02T00:33:22Z",
            "published": "2023-10-31T06:20:42Z",
            "summary": "Blockchain smart contracts have emerged as a transformative force in the\ndigital realm, spawning a diverse range of compelling applications. Since\nsolidity smart contracts across various domains manage trillions of dollars in\nvirtual coins, they become a prime target for attacks. One of the primary\nchallenges is keeping abreast of the latest techniques and tools for developing\nsecure smart contracts and examining those already deployed. In this paper, we\nseek to address these challenges from four aspects: (1) We begin by examining\nten automatic tools, specifically focusing on their methodologies and their\nability to identify vulnerabilities in solidity smart contracts. (2) We propose\na novel criterion for evaluating these tools, based on the ISO/IEC 25010\nstandard. (3) To facilitate the evaluation of the selected tools, we construct\na benchmark that encompasses two distinct datasets: a collection of 389\nlabelled smart contracts and a scaled set of 20,000 unique cases from\nreal-world contracts. (4) We provide a comparison of the selected tools,\noffering insights into their strengths and weaknesses and highlighting areas\nwhere further improvements are needed. Through this evaluation, we hope to\nprovide developers and researchers with valuable guidance on selecting and\nusing smart contract analysis tools and contribute to the ongoing efforts to\nimprove the security and reliability of smart contracts.",
            "author": [
                "Zhiyuan Wei",
                "Jing Sun",
                "Zijian Zhang",
                "Xianhao Zhang",
                "Meng Li",
                "Liehuang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20212v3",
                "http://arxiv.org/pdf/2310.20212v3"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20210v1",
            "title": "UWFormer: Underwater Image Enhancement via a Semi-Supervised Multi-Scale\n  Transformer",
            "updated": "2023-10-31T06:19:09Z",
            "published": "2023-10-31T06:19:09Z",
            "summary": "Underwater images often exhibit poor quality, imbalanced coloration, and low\ncontrast due to the complex and intricate interaction of light, water, and\nobjects. Despite the significant contributions of previous underwater\nenhancement techniques, there exist several problems that demand further\nimprovement: (i) Current deep learning methodologies depend on Convolutional\nNeural Networks (CNNs) that lack multi-scale enhancement and also have limited\nglobal perception fields. (ii) The scarcity of paired real-world underwater\ndatasets poses a considerable challenge, and the utilization of synthetic image\npairs risks overfitting. To address the aforementioned issues, this paper\npresents a Multi-scale Transformer-based Network called UWFormer for enhancing\nimages at multiple frequencies via semi-supervised learning, in which we\npropose a Nonlinear Frequency-aware Attention mechanism and a Multi-Scale\nFusion Feed-forward Network for low-frequency enhancement. Additionally, we\nintroduce a specialized underwater semi-supervised training strategy, proposing\na Subaqueous Perceptual Loss function to generate reliable pseudo labels.\nExperiments using full-reference and non-reference underwater benchmarks\ndemonstrate that our method outperforms state-of-the-art methods in terms of\nboth quantity and visual quality.",
            "author": [
                "Xuhang Chen",
                "Zinuo Li",
                "Shenghong Luo",
                "Weiwen Chen",
                "Shuqiang Wang",
                "Chi-Man Pun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20210v1",
                "http://arxiv.org/pdf/2310.20210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20209v1",
            "title": "Network Contention-Aware Cluster Scheduling with Reinforcement Learning",
            "updated": "2023-10-31T06:17:23Z",
            "published": "2023-10-31T06:17:23Z",
            "summary": "With continuous advances in deep learning, distributed training is becoming\ncommon in GPU clusters. Specifically, for emerging workloads with diverse\namounts, ratios, and patterns of communication, we observe that network\ncontention can significantly degrade training throughput. However, widely used\nscheduling policies often face limitations as they are agnostic to network\ncontention between jobs. In this paper, we present a new approach to mitigate\nnetwork contention in GPU clusters using reinforcement learning. We formulate\nGPU cluster scheduling as a reinforcement learning problem and opt to learn a\nnetwork contention-aware scheduling policy that efficiently captures contention\nsensitivities and dynamically adapts scheduling decisions through continuous\nevaluation and improvement. We show that compared to widely used scheduling\npolicies, our approach reduces average job completion time by up to 18.2\\% and\neffectively cuts the tail job completion time by up to 20.7\\% while allowing a\npreferable trade-off between average job completion time and resource\nutilization.",
            "author": [
                "Junyeol Ryu",
                "Jeongyoon Eo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20209v1",
                "http://arxiv.org/pdf/2310.20209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20208v2",
            "title": "ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object\n  Detection",
            "updated": "2023-11-29T08:33:30Z",
            "published": "2023-10-31T06:11:23Z",
            "summary": "Recent camouflaged object detection (COD) attempts to segment objects\nvisually blended into their surroundings, which is extremely complex and\ndifficult in real-world scenarios. Apart from the high intrinsic similarity\nbetween camouflaged objects and their background, objects are usually diverse\nin scale, fuzzy in appearance, and even severely occluded. To this end, we\npropose an effective unified collaborative pyramid network which mimics human\nbehavior when observing vague images and videos, \\textit{i.e.}, zooming in and\nout. Specifically, our approach employs the zooming strategy to learn\ndiscriminative mixed-scale semantics by the multi-head scale integration and\nrich granularity perception units, which are designed to fully explore\nimperceptible clues between candidate objects and background surroundings. The\nformer's intrinsic multi-head aggregation provides more diverse visual\npatterns. The latter's routing mechanism can effectively propagate inter-frame\ndifference in spatiotemporal scenarios and adaptively ignore static\nrepresentations. They provides a solid foundation for realizing a unified\narchitecture for static and dynamic COD. Moreover, considering the uncertainty\nand ambiguity derived from indistinguishable textures, we construct a simple\nyet effective regularization, uncertainty awareness loss, to encourage\npredictions with higher confidence in candidate regions. Our highly\ntask-friendly framework consistently outperforms existing state-of-the-art\nmethods in image and video COD benchmarks. The code will be available at\n\\url{https://github.com/lartpang/ZoomNeXt}.",
            "author": [
                "Youwei Pang",
                "Xiaoqi Zhao",
                "Tian-Zhu Xiang",
                "Lihe Zhang",
                "Huchuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20208v2",
                "http://arxiv.org/pdf/2310.20208v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20204v2",
            "title": "General-Purpose Retrieval-Enhanced Medical Prediction Model Using\n  Near-Infinite History",
            "updated": "2023-12-05T10:20:11Z",
            "published": "2023-10-31T06:04:18Z",
            "summary": "Developing clinical prediction models (e.g., mortality prediction) based on\nelectronic health records (EHRs) typically relies on expert opinion for feature\nselection and adjusting observation window size. This burdens experts and\ncreates a bottleneck in the development process. We propose Retrieval-Enhanced\nMedical prediction model (REMed) to address such challenges. REMed can\nessentially evaluate an unlimited number of clinical events, select the\nrelevant ones, and make predictions. This approach effectively eliminates the\nneed for manual feature selection and enables an unrestricted observation\nwindow. We verified these properties through experiments on 27 clinical tasks\nand two independent cohorts from publicly available EHR datasets, where REMed\noutperformed other contemporary architectures that aim to handle as many events\nas possible. Notably, we found that the preferences of REMed align closely with\nthose of medical experts. We expect our approach to significantly expedite the\ndevelopment of EHR prediction models by minimizing clinicians' need for manual\ninvolvement.",
            "author": [
                "Junu Kim",
                "Chaeeun Shim",
                "Bosco Seong Kyu Yang",
                "Chami Im",
                "Sung Yoon Lim",
                "Han-Gil Jeong",
                "Edward Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20204v2",
                "http://arxiv.org/pdf/2310.20204v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20201v1",
            "title": "Video-Helpful Multimodal Machine Translation",
            "updated": "2023-10-31T05:51:56Z",
            "published": "2023-10-31T05:51:56Z",
            "summary": "Existing multimodal machine translation (MMT) datasets consist of images and\nvideo captions or instructional video subtitles, which rarely contain\nlinguistic ambiguity, making visual information ineffective in generating\nappropriate translations. Recent work has constructed an ambiguous subtitles\ndataset to alleviate this problem but is still limited to the problem that\nvideos do not necessarily contribute to disambiguation. We introduce EVA\n(Extensive training set and Video-helpful evaluation set for Ambiguous\nsubtitles translation), an MMT dataset containing 852k Japanese-English (Ja-En)\nparallel subtitle pairs, 520k Chinese-English (Zh-En) parallel subtitle pairs,\nand corresponding video clips collected from movies and TV episodes. In\naddition to the extensive training set, EVA contains a video-helpful evaluation\nset in which subtitles are ambiguous, and videos are guaranteed helpful for\ndisambiguation. Furthermore, we propose SAFA, an MMT model based on the\nSelective Attention model with two novel methods: Frame attention loss and\nAmbiguity augmentation, aiming to use videos in EVA for disambiguation fully.\nExperiments on EVA show that visual information and the proposed methods can\nboost translation performance, and our model performs significantly better than\nexisting MMT models. The EVA dataset and the SAFA model are available at:\nhttps://github.com/ku-nlp/video-helpful-MMT.git.",
            "author": [
                "Yihang Li",
                "Shuichiro Shimizu",
                "Chenhui Chu",
                "Sadao Kurohashi",
                "Wei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20201v1",
                "http://arxiv.org/pdf/2310.20201v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20200v1",
            "title": "Multi-Domain Polarization for Enhancing the Physical Layer Security of\n  MIMO Systems",
            "updated": "2023-10-31T05:50:24Z",
            "published": "2023-10-31T05:50:24Z",
            "summary": "A novel Physical Layer Security (PLS) framework is conceived for enhancing\nthe security of the wireless communication systems by exploiting multi-domain\npolarization in Multiple-Input Multiple-Output (MIMO) systems. We design a\nsophisticated key generation scheme based on multi-domain polarization, and the\ncorresponding receivers. An in-depth analysis of the system's secrecy rate is\nprovided, demonstrating the confidentiality of our approach in the presence of\neavesdroppers having strong computational capabilities. More explicitly, our\nsimulation results and theoretical analysis corroborate the advantages of the\nproposed scheme in terms of its bit error rate (BER), block error rate (BLER),\nand maximum achievable secrecy rate. Our findings indicate that the innovative\nPLS framework effectively enhances the security and reliability of wireless\ncommunication systems. For instance, in a $4\\times4$ MIMO setup, the proposed\nPLS strategy exhibits an improvement of $2$dB compared to conventional MIMO,\nsystems at a BLER of $2\\cdot 10^{-5}$ while the eavesdropper's BLER reaches\n$1$.",
            "author": [
                "Luping Xiang",
                "Yao Zeng",
                "Jie Hu",
                "Kun Yang",
                "Lajos Hanzo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20200v1",
                "http://arxiv.org/pdf/2310.20200v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CR",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00724v1",
            "title": "Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME)\n  for Telecom",
            "updated": "2023-10-31T05:47:35Z",
            "published": "2023-10-31T05:47:35Z",
            "summary": "Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining\nand machine learning techniques (apart from rules oriented approach) have been\nused in past, but efficiency has been low as fraud pattern changes very\nrapidly. This paper presents an industrialized solution approach with self\nadaptive data mining technique and application of big data technologies to\ndetect fraud and discover novel fraud patterns in accurate, efficient and cost\neffective manner. Solution has been successfully demonstrated to detect\nInternational Revenue Share Fraud with <5% false positive. More than 1 Terra\nBytes of Call Detail Record from a reputed wholesale carrier and overseas\ntelecom transit carrier has been used to conduct this study.",
            "author": [
                "Sudarson Roy Pratihar",
                "Subhadip Paul",
                "Pranab Kumar Dash",
                "Amartya Kumar Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00724v1",
                "http://arxiv.org/pdf/2311.00724v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20199v1",
            "title": "In Search of Lost Online Test-time Adaptation: A Survey",
            "updated": "2023-10-31T05:47:33Z",
            "published": "2023-10-31T05:47:33Z",
            "summary": "In this paper, we present a comprehensive survey on online test-time\nadaptation (OTTA), a paradigm focused on adapting machine learning models to\nnovel data distributions upon batch arrival. Despite the proliferation of OTTA\nmethods recently, the field is mired in issues like ambiguous settings,\nantiquated backbones, and inconsistent hyperparameter tuning, obfuscating the\nreal challenges and making reproducibility elusive. For clarity and a rigorous\ncomparison, we classify OTTA techniques into three primary categories and\nsubject them to benchmarks using the potent Vision Transformer (ViT) backbone\nto discover genuinely effective strategies. Our benchmarks span not only\nconventional corrupted datasets such as CIFAR-10/100-C and ImageNet-C but also\nreal-world shifts embodied in CIFAR-10.1 and CIFAR-10-Warehouse, encapsulating\nvariations across search engines and synthesized data by diffusion models. To\ngauge efficiency in online scenarios, we introduce novel evaluation metrics,\ninclusive of FLOPs, shedding light on the trade-offs between adaptation\naccuracy and computational overhead. Our findings diverge from existing\nliterature, indicating: (1) transformers exhibit heightened resilience to\ndiverse domain shifts, (2) the efficacy of many OTTA methods hinges on ample\nbatch sizes, and (3) stability in optimization and resistance to perturbations\nare critical during adaptation, especially when the batch size is 1. Motivated\nby these insights, we pointed out promising directions for future research. The\nsource code will be made available.",
            "author": [
                "Zixin Wang",
                "Yadan Luo",
                "Liang Zheng",
                "Zhuoxiao Chen",
                "Sen Wang",
                "Zi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20199v1",
                "http://arxiv.org/pdf/2310.20199v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20197v1",
            "title": "Accelerating the convergence of free electron laser simulations by\n  retrieving a spatially-coherent component of microbunching",
            "updated": "2023-10-31T05:43:54Z",
            "published": "2023-10-31T05:43:54Z",
            "summary": "A simple method to reduce the numerical cost in free electron laser (FEL)\nsimulations is presented, which is based on retrieving a spatially-coherent\ncomponent of microbunching to suppress artifact effects that can potentially\noverestimate the FEL gain; this significantly reduces the number of\nmacroparticles to reach the numerical convergence and enables the direct\ncomputation of amplified radiation without solving the wave equation. Examples\nof FEL simulations performed to demonstrate the proposed method show that the\ncomputation time to get a reliable result is reduced by 1-2 orders of magnitude\ndepending on the simulation condition.",
            "author": [
                "Takashi Tanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20197v1",
                "http://arxiv.org/pdf/2310.20197v1"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20195v2",
            "title": "Generating Continuations in Multilingual Idiomatic Contexts",
            "updated": "2023-11-04T04:15:18Z",
            "published": "2023-10-31T05:40:33Z",
            "summary": "The ability to process idiomatic or literal multiword expressions is a\ncrucial aspect of understanding and generating any language. The task of\ngenerating contextually relevant continuations for narratives containing\nidiomatic (or literal) expressions can allow us to test the ability of\ngenerative language models (LMs) in understanding nuanced language containing\nnon-compositional figurative text. We conduct a series of experiments using\ndatasets in two distinct languages (English and Portuguese) under three\ndifferent training settings (zero-shot, few-shot, and fine-tuned). Our results\nsuggest that the models are only slightly better at generating continuations\nfor literal contexts than idiomatic contexts, with exceedingly small margins.\nFurthermore, the models studied in this work perform equally well across both\nlanguages, indicating the robustness of generative models in performing this\ntask.",
            "author": [
                "Rhitabrat Pokharel",
                "Ameeta Agrawal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20195v2",
                "http://arxiv.org/pdf/2310.20195v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20193v1",
            "title": "FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated\n  Recommendation Systems",
            "updated": "2023-10-31T05:36:53Z",
            "published": "2023-10-31T05:36:53Z",
            "summary": "Preserving privacy and reducing communication costs for edge users pose\nsignificant challenges in recommendation systems. Although federated learning\nhas proven effective in protecting privacy by avoiding data exchange between\nclients and servers, it has been shown that the server can infer user ratings\nbased on updated non-zero gradients obtained from two consecutive rounds of\nuser-uploaded gradients. Moreover, federated recommendation systems (FRS) face\nthe challenge of heterogeneity, leading to decreased recommendation\nperformance. In this paper, we propose FedRec+, an ensemble framework for FRS\nthat enhances privacy while addressing the heterogeneity challenge. FedRec+\nemploys optimal subset selection based on feature similarity to generate\nnear-optimal virtual ratings for pseudo items, utilizing only the user's local\ninformation. This approach reduces noise without incurring additional\ncommunication costs. Furthermore, we utilize the Wasserstein distance to\nestimate the heterogeneity and contribution of each client, and derive optimal\naggregation weights by solving a defined optimization problem. Experimental\nresults demonstrate the state-of-the-art performance of FedRec+ across various\nreference datasets.",
            "author": [
                "Lin Wang",
                "Zhichao Wang",
                "Xi Leng",
                "Xiaoying Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20193v1",
                "http://arxiv.org/pdf/2310.20193v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20191v1",
            "title": "Subspace Correction for Constraints",
            "updated": "2023-10-31T05:23:50Z",
            "published": "2023-10-31T05:23:50Z",
            "summary": "We demonstrate that it is possible to construct operators that stabilize the\nconstraint-satisfying subspaces of computational problems in their Ising\nrepresentations. We provide an explicit recipe to construct unitaries and\nassociated measurements for some such constraints. The stabilizer measurements\nallow the detection of constraint violations, and provide a route to recovery\nback into the constrained subspace. We call this technique ``subspace\ncorrection\". As an example, we explicitly investigate the stabilizers using the\nsimplest local constraint subspace: Independent Set. We find an algorithm that\nis guaranteed to produce a perfect uniform or weighted distribution over all\nconstraint-satisfying states when paired with a stopping condition: a quantum\nanalogue of partial rejection sampling. The stopping condition can be modified\nfor sub-graph approximations. We show that it can prepare exact Gibbs\ndistributions on $d-$regular graphs below a critical hardness $\\lambda_d^*$ in\nsub-linear time. Finally, we look at a potential use of subspace correction for\nfault-tolerant depth-reduction. In particular we investigate how the technique\ndetects and recovers errors induced by Trotterization in preparing maximum\nindependent set using an adiabatic state preparation algorithm.",
            "author": [
                "Kelly Ann Pawlak",
                "Jeffrey M. Epstein",
                "Daniel Crow",
                "Srilekha Gandhari",
                "Ming Li",
                "Thomas C. Bohdanowicz",
                "Jonathan King"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20191v1",
                "http://arxiv.org/pdf/2310.20191v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20190v2",
            "title": "Visible to Thermal image Translation for improving visual task in low\n  light conditions",
            "updated": "2023-11-09T02:42:20Z",
            "published": "2023-10-31T05:18:53Z",
            "summary": "Several visual tasks, such as pedestrian detection and image-to-image\ntranslation, are challenging to accomplish in low light using RGB images. Heat\nvariation of objects in thermal images can be used to overcome this. In this\nwork, an end-to-end framework, which consists of a generative network and a\ndetector network, is proposed to translate RGB image into Thermal ones and\ncompare generated thermal images with real data. We have collected images from\ntwo different locations using the Parrot Anafi Thermal drone. After that, we\ncreated a two-stream network, preprocessed, augmented, the image data, and\ntrained the generator and discriminator models from scratch. The findings\ndemonstrate that it is feasible to translate RGB training data to thermal data\nusing GAN. As a result, thermal data can now be produced more quickly and\naffordably, which is useful for security and surveillance applications.",
            "author": [
                "Md Azim Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20190v2",
                "http://arxiv.org/pdf/2310.20190v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20183v1",
            "title": "Thriving in a Pandemic: Lessons Learned from a Resilient University\n  Program Seen Through the CoI Lens",
            "updated": "2023-10-31T05:09:17Z",
            "published": "2023-10-31T05:09:17Z",
            "summary": "In March 2020, college campuses underwent a sudden transformation to online\nlearning due to the COVID-19 outbreak. To understand the impact of COVID-19 on\nstudents' expectations, this study conducted a three-year survey from ten core\ncourses within the Project Management Center for Excellence at the University\nof Maryland. The study involved two main steps: 1) a statistical analysis to\nevaluate students' expectations regarding \"student,\" \"class,\" \"instructor,\" and\n\"effort;\" and 2) a lexical salience-valence analysis (LSVA) through the lens of\nthe Community of Inquiry (CoI) framework to show the changes of students'\nexpectations. The results revealed that students' overall evaluations\nmaintained relatively consistent amid the COVID-19 teaching period. However,\nthere were significant shifts of the student expectations toward Cognitive,\nSocial and Teaching Presence course elements based on LSVA results. Also, clear\ndifferences emerged between under-graduates and graduates in their expectations\nand preferences in course design and delivery. These insights provide practical\nrecommendations for course instructors in designing effective online courses.",
            "author": [
                "Zihui Ma",
                "Lingyao Li",
                "John C. E. Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20183v1",
                "http://arxiv.org/pdf/2310.20183v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20177v1",
            "title": "An extended Fourier pseudospectral method for the Gross-Pitaevskii\n  equation with low regularity potential",
            "updated": "2023-10-31T04:59:13Z",
            "published": "2023-10-31T04:59:13Z",
            "summary": "We propose and analyze an extended Fourier pseudospectral (eFP) method for\nthe spatial discretization of the Gross-Pitaevskii equation (GPE) with low\nregularity potential by treating the potential in an extended window for its\ndiscrete Fourier transform. The proposed eFP method maintains optimal\nconvergence rates with respect to the regularity of the exact solution even if\nthe potential is of low regularity and enjoys similar computational cost as the\nstandard Fourier pseudospectral method, and thus it is both efficient and\naccurate. Furthermore, similar to the Fourier spectral/pseudospectral methods,\nthe eFP method can be easily coupled with different popular temporal\nintegrators including finite difference methods, time-splitting methods and\nexponential-type integrators. Numerical results are presented to validate our\noptimal error estimates and to demonstrate that they are sharp as well as to\nshow its efficiency in practical computations.",
            "author": [
                "Weizhu Bao",
                "Bo Lin",
                "Ying Ma",
                "Chushan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20177v1",
                "http://arxiv.org/pdf/2310.20177v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "35Q55, 65M15, 65M70, 81Q05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20175v2",
            "title": "LFAA: Crafting Transferable Targeted Adversarial Examples with\n  Low-Frequency Perturbations",
            "updated": "2023-11-01T02:21:53Z",
            "published": "2023-10-31T04:54:55Z",
            "summary": "Deep neural networks are susceptible to adversarial attacks, which pose a\nsignificant threat to their security and reliability in real-world\napplications. The most notable adversarial attacks are transfer-based attacks,\nwhere an adversary crafts an adversarial example to fool one model, which can\nalso fool other models. While previous research has made progress in improving\nthe transferability of untargeted adversarial examples, the generation of\ntargeted adversarial examples that can transfer between models remains a\nchallenging task. In this work, we present a novel approach to generate\ntransferable targeted adversarial examples by exploiting the vulnerability of\ndeep neural networks to perturbations on high-frequency components of images.\nWe observe that replacing the high-frequency component of an image with that of\nanother image can mislead deep models, motivating us to craft perturbations\ncontaining high-frequency information to achieve targeted attacks. To this end,\nwe propose a method called Low-Frequency Adversarial Attack (\\name), which\ntrains a conditional generator to generate targeted adversarial perturbations\nthat are then added to the low-frequency component of the image. Extensive\nexperiments on ImageNet demonstrate that our proposed approach significantly\noutperforms state-of-the-art methods, improving targeted attack success rates\nby a margin from 3.2\\% to 15.5\\%.",
            "author": [
                "Kunyu Wang",
                "Juluan Shi",
                "Wenxuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20175v2",
                "http://arxiv.org/pdf/2310.20175v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20171v1",
            "title": "The Dependence of Joy's Law as a Function of Flux Emergence Phase",
            "updated": "2023-10-31T04:39:35Z",
            "published": "2023-10-31T04:39:35Z",
            "summary": "Data from the Michelson Doppler Imager (MDI) and Helioseismic and Magnetic\nImager (HMI) are analyzed from 1996 to 2023 to investigate tilt angles\n($\\gamma$) of bipolar magnetic regions and Joy's Law for Cycles 23, 24, and a\nportion of 25. The HMI radial magnetic field ($B_{r}$) and MDI magnetogram\n($B_{los}$) data are used to calculate ($\\gamma$) using the flux-weighted\ncentroids of the positive and negative polarities. Each AR is only sampled\nonce. The analysis includes only Beta ($\\beta$)-class active regions since\ncomputing $\\gamma$ of complex active regions is less meaningful. During the\nemergence of the ARs, we find that the average tilt angle ($\\bar{\\gamma}$)\nincreases from 3.30$^{\\circ}\\pm$0.75 when 20\\% of the flux has emerged to\n6.79$^{\\circ}\\pm$0.66 when the ARs are at their maximum flux. Cycle 24 had a\nlarger average tilt $\\bar{\\gamma}_{24}$=6.67$\\pm$0.66 than Cycle 23,\n$\\bar{\\gamma}_{23}$=5.11$\\pm$0.61. There are persistent differences in\n$\\bar{\\gamma}$ in the hemispheres with the southern hemisphere having higher\n${\\bar{\\gamma}}$ in Cycles 23 and 24 but the errors are such that these\ndifferences are not statistically significant.",
            "author": [
                "Lucy Will",
                "Aimee A. Norton",
                "Jon Todd Hoeksema"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20171v1",
                "http://arxiv.org/pdf/2310.20171v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20170v1",
            "title": "DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain\n  Question Answering over Knowledge Base and Text",
            "updated": "2023-10-31T04:37:57Z",
            "published": "2023-10-31T04:37:57Z",
            "summary": "Large Language Models (LLMs) have exhibited impressive generation\ncapabilities, but they suffer from hallucinations when solely relying on their\ninternal knowledge, especially when answering questions that require less\ncommonly known information. Retrieval-augmented LLMs have emerged as a\npotential solution to ground LLMs in external knowledge. Nonetheless, recent\napproaches have primarily emphasized retrieval from unstructured text corpora,\nowing to its seamless integration into prompts. When using structured data such\nas knowledge graphs, most methods simplify it into natural text, neglecting the\nunderlying structures. Moreover, a significant gap in the current landscape is\nthe absence of a realistic benchmark for evaluating the effectiveness of\ngrounding LLMs on heterogeneous knowledge sources (e.g., knowledge base and\ntext). To fill this gap, we have curated a comprehensive dataset that poses two\nunique challenges: (1) Two-hop multi-source questions that require retrieving\ninformation from both open-domain structured and unstructured knowledge\nsources; retrieving information from structured knowledge sources is a critical\ncomponent in correctly answering the questions. (2) The generation of symbolic\nqueries (e.g., SPARQL for Wikidata) is a key requirement, which adds another\nlayer of challenge. Our dataset is created using a combination of automatic\ngeneration through predefined reasoning chains and human annotation. We also\nintroduce a novel approach that leverages multiple retrieval tools, including\ntext passage retrieval and symbolic language-assisted retrieval. Our model\noutperforms previous approaches by a significant margin, demonstrating its\neffectiveness in addressing the above-mentioned reasoning challenges.",
            "author": [
                "Wenting Zhao",
                "Ye Liu",
                "Tong Niu",
                "Yao Wan",
                "Philip S. Yu",
                "Shafiq Joty",
                "Yingbo Zhou",
                "Semih Yavuz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20170v1",
                "http://arxiv.org/pdf/2310.20170v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20159v1",
            "title": "Language Guided Visual Question Answering: Elevate Your Multimodal\n  Language Model Using Knowledge-Enriched Prompts",
            "updated": "2023-10-31T03:54:11Z",
            "published": "2023-10-31T03:54:11Z",
            "summary": "Visual question answering (VQA) is the task of answering questions about an\nimage. The task assumes an understanding of both the image and the question to\nprovide a natural language answer. VQA has gained popularity in recent years\ndue to its potential applications in a wide range of fields, including\nrobotics, education, and healthcare. In this paper, we focus on\nknowledge-augmented VQA, where answering the question requires commonsense\nknowledge, world knowledge, and reasoning about ideas and concepts not present\nin the image. We propose a multimodal framework that uses language guidance\n(LG) in the form of rationales, image captions, scene graphs, etc to answer\nquestions more accurately. We benchmark our method on the multi-choice\nquestion-answering task of the A-OKVQA, Science-QA, VSR, and IconQA datasets\nusing CLIP and BLIP models. We show that the use of language guidance is a\nsimple but powerful and effective strategy for visual question answering. Our\nlanguage guidance improves the performance of CLIP by 7.6% and BLIP-2 by 4.8%\nin the challenging A-OKVQA dataset. We also observe consistent improvement in\nperformance on the Science-QA, VSR, and IconQA datasets when using the proposed\nlanguage guidances. The implementation of LG-VQA is publicly available at\nhttps:// github.com/declare-lab/LG-VQA.",
            "author": [
                "Deepanway Ghosal",
                "Navonil Majumder",
                "Roy Ka-Wei Lee",
                "Rada Mihalcea",
                "Soujanya Poria"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20159v1",
                "http://arxiv.org/pdf/2310.20159v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20158v1",
            "title": "GAR-meets-RAG Paradigm for Zero-Shot Information Retrieval",
            "updated": "2023-10-31T03:52:08Z",
            "published": "2023-10-31T03:52:08Z",
            "summary": "Given a query and a document corpus, the information retrieval (IR) task is\nto output a ranked list of relevant documents. Combining large language models\n(LLMs) with embedding-based retrieval models, recent work shows promising\nresults on the zero-shot retrieval problem, i.e., no access to labeled data\nfrom the target domain. Two such popular paradigms are generation-augmented\nretrieval or GAR (generate additional context for the query and then retrieve),\nand retrieval-augmented generation or RAG (retrieve relevant documents as\ncontext and then generate answers). The success of these paradigms hinges on\n(i) high-recall retrieval models, which are difficult to obtain in the\nzero-shot setting, and (ii) high-precision (re-)ranking models which typically\nneed a good initialization. In this work, we propose a novel GAR-meets-RAG\nrecurrence formulation that overcomes the challenges of existing paradigms. Our\nmethod iteratively improves retrieval (via GAR) and rewrite (via RAG) stages in\nthe zero-shot setting. A key design principle is that the rewrite-retrieval\nstages improve the recall of the system and a final re-ranking stage improves\nthe precision. We conduct extensive experiments on zero-shot passage retrieval\nbenchmarks, BEIR and TREC-DL. Our method establishes a new state-of-the-art in\nthe BEIR benchmark, outperforming previous best results in Recall@100 and\nnDCG@10 metrics on 6 out of 8 datasets, with up to 17% relative gains over the\nprevious best.",
            "author": [
                "Daman Arora",
                "Anush Kini",
                "Sayak Ray Chowdhury",
                "Nagarajan Natarajan",
                "Gaurav Sinha",
                "Amit Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20158v1",
                "http://arxiv.org/pdf/2310.20158v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20155v1",
            "title": "MLatom 3: Platform for machine learning-enhanced computational chemistry\n  simulations and workflows",
            "updated": "2023-10-31T03:41:39Z",
            "published": "2023-10-31T03:41:39Z",
            "summary": "Machine learning (ML) is increasingly becoming a common tool in computational\nchemistry. At the same time, the rapid development of ML methods requires a\nflexible software framework for designing custom workflows. MLatom 3 is a\nprogram package designed to leverage the power of ML to enhance typical\ncomputational chemistry simulations and to create complex workflows. This\nopen-source package provides plenty of choice to the users who can run\nsimulations with the command line options, input files, or with scripts using\nMLatom as a Python package, both on their computers and on the online XACS\ncloud computing at XACScloud.com. Computational chemists can calculate energies\nand thermochemical properties, optimize geometries, run molecular and quantum\ndynamics, and simulate (ro)vibrational, one-photon UV/vis absorption, and\ntwo-photon absorption spectra with ML, quantum mechanical, and combined models.\nThe users can choose from an extensive library of methods containing\npre-trained ML models and quantum mechanical approximations such as AIQM1\napproaching coupled-cluster accuracy. The developers can build their own models\nusing various ML algorithms. The great flexibility of MLatom is largely due to\nthe extensive use of the interfaces to many state-of-the-art software packages\nand libraries.",
            "author": [
                "Pavlo O. Dral",
                "Fuchun Ge",
                "Yi-Fan Hou",
                "Peikun Zheng",
                "Yuxinxin Chen",
                "Mario Barbatti",
                "Olexandr Isayev",
                "Cheng Wang",
                "Bao-Xin Xue",
                "Max Pinheiro Jr",
                "Yuming Su",
                "Yiheng Dai",
                "Yangtao Chen",
                "Lina Zhang",
                "Shuang Zhang",
                "Arif Ullah",
                "Quanhao Zhang",
                "Yanchi Ou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20155v1",
                "http://arxiv.org/pdf/2310.20155v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20154v2",
            "title": "A Quantum Optimization Method for Geometric Constrained Image\n  Segmentation",
            "updated": "2023-11-06T21:16:40Z",
            "published": "2023-10-31T03:41:21Z",
            "summary": "Quantum image processing is a growing field attracting attention from both\nthe quantum computing and image processing communities. We propose a novel\nmethod in combining a graph-theoretic approach for optimal surface segmentation\nand hybrid quantum-classical optimization of the problem-directed graph. The\nsurface segmentation is modeled classically as a graph partitioning problem in\nwhich a smoothness constraint is imposed to control surface variation for\nrealistic segmentation. Specifically, segmentation refers to a source set\nidentified by a minimum s-t cut that divides graph nodes into the source (s)\nand sink (t) sets. The resulting surface consists of graph nodes located on the\nboundary between the source and the sink. Characteristics of the\nproblem-specific graph, including its directed edges, connectivity, and edge\ncapacities, are embedded in a quadratic objective function whose minimum value\ncorresponds to the ground state energy of an equivalent Ising Hamiltonian. This\nwork explores the use of quantum processors in image segmentation problems,\nwhich has important applications in medical image analysis. Here, we present a\ntheoretical basis for the quantum implementation of LOGISMOS and the results of\na simulation study on simple images. Quantum Approximate Optimization Algorithm\n(QAOA) approach was utilized to conduct two simulation studies whose objective\nwas to determine the ground state energies and identify bitstring solutions\nthat encode the optimal segmentation of objective functions. The objective\nfunction encodes tasks associated with surface segmentation in 2-D and 3-D\nimages while incorporating a smoothness constraint. In this work, we\ndemonstrate that the proposed approach can solve the geometric-constrained\nsurface segmentation problem optimally with the capability of locating multiple\nminimum points corresponding to the globally minimal solution.",
            "author": [
                "Nam H. Le",
                "Milan Sonka",
                "Fatima Toor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20154v2",
                "http://arxiv.org/pdf/2310.20154v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    }
]