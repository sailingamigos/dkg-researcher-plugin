[
    {
        "public": [
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02418v1/1.0",
                "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
                "year": 2024,
                "abstract": "Foundational vision-language models such as CLIP are becoming a new paradigm\nin vision, due to their excellent generalization abilities. However, adapting\nthese models for downstream tasks while maintaining their generalization\nremains a challenge. In literature, one branch of methods adapts CLIP by\nlearning prompts using visual information. While effective, most of these works\nrequire labeled data which is not practical, and often struggle to generalize\ntowards new datasets due to over-fitting on the source data. An alternative\napproach resorts to training-free methods by generating class descriptions from\nlarge language models (LLMs) and perform prompt ensembling. However, these\nmethods often generate class specific prompts that cannot be transferred to\nother classes, which incur higher costs by generating LLM descriptions for each\nclass separately. In this work, we propose to combine the strengths of these\nboth streams of methods by learning prompts using only text data derived from\nLLMs. As supervised training of prompts is not trivial due to absence of\nimages, we develop a training approach that allows prompts to extract rich\ncontextual knowledge from LLM data. Moreover, with LLM contextual data mapped\nwithin the learned prompts, it enables zero-shot transfer of prompts to new\nclasses and datasets potentially cutting the LLM prompt engineering cost. To\nthe best of our knowledge, this is the first work that learns generalized\nprompts using text only data. We perform extensive evaluations on 4 benchmarks\nwhere our method improves over prior ensembling works while being competitive\nto those utilizing labeled images. Our code and pre-trained models are\navailable at https://github.com/muzairkhattak/ProText.",
                "authors": [
                    "Muhammad Uzair Khattak",
                    "Muhammad Ferjad Naeem",
                    "Muzammal Naseer",
                    "Luc Van Gool",
                    "Federico Tombari"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02418v1",
                    "http://arxiv.org/pdf/2401.02418v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02417v1/1.0",
                "title": "Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic\n  Speech Recognition",
                "year": 2024,
                "abstract": "While word error rates of automatic speech recognition (ASR) systems have\nconsistently fallen, natural language understanding (NLU) applications built on\ntop of ASR systems still attribute significant numbers of failures to\nlow-quality speech recognition results. Existing assistant systems collect\nlarge numbers of these unsuccessful interactions, but these systems usually\nfail to learn from these interactions, even in an offline fashion. In this\nwork, we introduce CLC: Contrastive Learning for Conversations, a family of\nmethods for contrastive fine-tuning of models in a self-supervised fashion,\nmaking use of easily detectable artifacts in unsuccessful conversations with\nassistants. We demonstrate that our CLC family of approaches can improve the\nperformance of ASR models on OD3, a new public large-scale semi-synthetic\nmeta-dataset of audio task-oriented dialogues, by up to 19.2%. These gains\ntransfer to real-world systems as well, where we show that CLC can help to\nimprove performance by up to 6.7% over baselines. We make OD3 publicly\navailable at https://github.com/amazon-science/amazon-od3 .",
                "authors": [
                    "David M. Chan",
                    "Shalini Ghosh",
                    "Hitesh Tulsiani",
                    "Ariya Rastrow",
                    "Bj\u00f6rn Hoffmeister"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02417v1",
                    "http://arxiv.org/pdf/2401.02417v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.CL",
                    "cs.LG",
                    "cs.SD"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02416v1/1.0",
                "title": "ODIN: A Single Model for 2D and 3D Perception",
                "year": 2024,
                "abstract": "State-of-the-art models on contemporary 3D perception benchmarks like ScanNet\nconsume and label dataset-provided 3D point clouds, obtained through post\nprocessing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website: https://odin-seg.github.io.",
                "authors": [
                    "Ayush Jain",
                    "Pushkal Katara",
                    "Nikolaos Gkanatsios",
                    "Adam W. Harley",
                    "Gabriel Sarch",
                    "Kriti Aggarwal",
                    "Vishrav Chaudhary",
                    "Katerina Fragkiadaki"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02416v1",
                    "http://arxiv.org/pdf/2401.02416v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG",
                    "cs.RO"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02415v1/1.0",
                "title": "LLaMA Pro: Progressive LLaMA with Block Expansion",
                "year": 2024,
                "abstract": "Humans generally acquire new skills without compromising the old; however,\nthe opposite holds for Large Language Models (LLMs), e.g., from LLaMA to\nCodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with\nan expansion of Transformer blocks. We tune the expanded blocks using only new\ncorpus, efficiently and effectively improving the model's knowledge without\ncatastrophic forgetting. In this paper, we experiment on the corpus of code and\nmath, yielding LLaMA Pro-8.3B, a versatile foundation model initialized from\nLLaMA2-7B, excelling in general tasks, programming, and mathematics. LLaMA Pro\nand its instruction-following counterpart (LLaMA Pro-Instruct) achieve advanced\nperformance among various benchmarks, demonstrating superiority over existing\nopen models in the LLaMA family and the immense potential of reasoning and\naddressing diverse tasks as an intelligent agent. Our findings provide valuable\ninsights into integrating natural and programming languages, laying a solid\nfoundation for developing advanced language agents that operate effectively in\nvarious environments.",
                "authors": [
                    "Chengyue Wu",
                    "Yukang Gan",
                    "Yixiao Ge",
                    "Zeyu Lu",
                    "Jiahao Wang",
                    "Ye Feng",
                    "Ping Luo",
                    "Ying Shan"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02415v1",
                    "http://arxiv.org/pdf/2401.02415v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02414v1/1.0",
                "title": "Bring Metric Functions into Diffusion Models",
                "year": 2024,
                "abstract": "We introduce a Cascaded Diffusion Model (Cas-DM) that improves a Denoising\nDiffusion Probabilistic Model (DDPM) by effectively incorporating additional\nmetric functions in training. Metric functions such as the LPIPS loss have been\nproven highly effective in consistency models derived from the score matching.\nHowever, for the diffusion counterparts, the methodology and efficacy of adding\nextra metric functions remain unclear. One major challenge is the mismatch\nbetween the noise predicted by a DDPM at each step and the desired clean image\nthat the metric function works well on. To address this problem, we propose\nCas-DM, a network architecture that cascades two network modules to effectively\napply metric functions to the diffusion model training. The first module,\nsimilar to a standard DDPM, learns to predict the added noise and is unaffected\nby the metric function. The second cascaded module learns to predict the clean\nimage, thereby facilitating the metric function computation. Experiment results\nshow that the proposed diffusion model backbone enables the effective use of\nthe LPIPS loss, leading to state-of-the-art image quality (FID, sFID, IS) on\nvarious established benchmarks.",
                "authors": [
                    "Jie An",
                    "Zhengyuan Yang",
                    "Jianfeng Wang",
                    "Linjie Li",
                    "Zicheng Liu",
                    "Lijuan Wang",
                    "Jiebo Luo"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02414v1",
                    "http://arxiv.org/pdf/2401.02414v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02413v1/1.0",
                "title": "Simulation-Based Inference with Quantile Regression",
                "year": 2024,
                "abstract": "We present Neural Quantile Estimation (NQE), a novel Simulation-Based\nInference (SBI) method based on conditional quantile regression. NQE\nautoregressively learns individual one dimensional quantiles for each posterior\ndimension, conditioned on the data and previous posterior dimensions. Posterior\nsamples are obtained by interpolating the predicted quantiles using monotonic\ncubic Hermite spline, with specific treatment for the tail behavior and\nmulti-modal distributions. We introduce an alternative definition for the\nBayesian credible region using the local Cumulative Density Function (CDF),\noffering substantially faster evaluation than the traditional Highest Posterior\nDensity Region (HPDR). In case of limited simulation budget and/or known model\nmisspecification, a post-processing broadening step can be integrated into NQE\nto ensure the unbiasedness of the posterior estimation with negligible\nadditional computational cost. We demonstrate that the proposed NQE method\nachieves state-of-the-art performance on a variety of benchmark problems.",
                "authors": [
                    "He Jia"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02413v1",
                    "http://arxiv.org/pdf/2401.02413v1"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.LG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02412v1/1.0",
                "title": "LLM Augmented LLMs: Expanding Capabilities through Composition",
                "year": 2024,
                "abstract": "Foundational models with billions of parameters which have been trained on\nlarge corpora of data have demonstrated non-trivial skills in a variety of\ndomains. However, due to their monolithic structure, it is challenging and\nexpensive to augment them or impart new skills. On the other hand, due to their\nadaptation abilities, several new instances of these models are being trained\ntowards new domains and tasks. In this work, we study the problem of efficient\nand practical composition of existing foundation models with more specific\nmodels to enable newer capabilities. To this end, we propose CALM --\nComposition to Augment Language Models -- which introduces cross-attention\nbetween models to compose their representations and enable new capabilities.\nSalient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'\nexisting LLMs along with a few additional parameters and data, (ii) Existing\nmodel weights are kept intact, and hence preserves existing capabilities, and\n(iii) Applies to diverse domains and settings. We illustrate that augmenting\nPaLM2-S with a smaller model trained on low-resource languages results in an\nabsolute improvement of up to 13\\% on tasks like translation into English and\narithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is\naugmented with a code-specific model, we see a relative improvement of 40\\%\nover the base model for code generation and explanation tasks -- on-par with\nfully fine-tuned counterparts.",
                "authors": [
                    "Rachit Bansal",
                    "Bidisha Samanta",
                    "Siddharth Dalmia",
                    "Nitish Gupta",
                    "Shikhar Vashishth",
                    "Sriram Ganapathy",
                    "Abhishek Bapna",
                    "Prateek Jain",
                    "Partha Talukdar"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02412v1",
                    "http://arxiv.org/pdf/2401.02412v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL",
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02411v1/1.0",
                "title": "What You See is What You GAN: Rendering Every Pixel for High-Fidelity\n  Geometry in 3D GANs",
                "year": 2024,
                "abstract": "3D-aware Generative Adversarial Networks (GANs) have shown remarkable\nprogress in learning to generate multi-view-consistent images and 3D geometries\nof scenes from collections of 2D images via neural volume rendering. Yet, the\nsignificant memory and computational costs of dense sampling in volume\nrendering have forced 3D GANs to adopt patch-based training or employ\nlow-resolution rendering with post-processing 2D super resolution, which\nsacrifices multiview consistency and the quality of resolved geometry.\nConsequently, 3D GANs have not yet been able to fully resolve the rich 3D\ngeometry present in 2D images. In this work, we propose techniques to scale\nneural volume rendering to the much higher resolution of native 2D images,\nthereby resolving fine-grained 3D geometry with unprecedented detail. Our\napproach employs learning-based samplers for accelerating neural rendering for\n3D GAN training using up to 5 times fewer depth samples. This enables us to\nexplicitly \"render every pixel\" of the full-resolution image during training\nand inference without post-processing superresolution in 2D. Together with our\nstrategy to learn high-quality surface geometry, our method synthesizes\nhigh-resolution 3D geometry and strictly view-consistent images while\nmaintaining image quality on par with baselines relying on post-processing\nsuper resolution. We demonstrate state-of-the-art 3D gemetric quality on FFHQ\nand AFHQ, setting a new standard for unsupervised learning of 3D shapes in 3D\nGANs.",
                "authors": [
                    "Alex Trevithick",
                    "Matthew Chan",
                    "Towaki Takikawa",
                    "Umar Iqbal",
                    "Shalini De Mello",
                    "Manmohan Chandraker",
                    "Ravi Ramamoorthi",
                    "Koki Nagano"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02411v1",
                    "http://arxiv.org/pdf/2401.02411v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.GR",
                    "cs.LG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02410v1/1.0",
                "title": "asimulation: Domain formation and impact on observables in resolved\n  cosmological simulations of the (a)symmetron",
                "year": 2024,
                "abstract": "The symmetron is a dark energy and dark matter candidate that forms\ntopological defects in the late-time universe and holds promise to resolve some\nof the cosmological tensions. We perform high resolution simulations of the\ndynamical and non-linear (a)symmetron using the recently developed relativistic\nN-body code asevolution. By extensively testing the temporal and spatial\nconvergence of domain decompositioning and domain wall stability, we find\ncriteria and physical intuition for the convergence. We apply the resolution\ncriteria to run five high resolution, $1280^3$ grids and 500 Mpc/h boxsize,\nsimulations of the (a)symmetron and consider the behaviour of the scalar field\nand the domain walls in each scenario. We find the effect on the matter power\nspectra, the halo mass function and observables computed over the past\nlightcone of an observer such as the integrated Sachs-Wolfe and non-linear\nRees-Sciama effect (ISW-RS) and the lensing, compared to LCDM. We show local\noscillations of the fifth force strength and the formation of planar structures\nin the density field. The dynamics of the field is visualised in animations\nwith high resolution in time. The simulation code is made publicly available.",
                "authors": [
                    "\u00d8yvind Christiansen",
                    "Farbod Hassani",
                    "David F. Mota"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02410v1",
                    "http://arxiv.org/pdf/2401.02410v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "gr-qc",
                    "hep-th"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02404v1/1.0",
                "title": "Correctness Comparison of ChatGPT-4, Bard, Claude-2, and Copilot for\n  Spatial Tasks",
                "year": 2024,
                "abstract": "Generative AI including large language models (LLMs) have recently gained\nsignificant interest in the geo-science community through its versatile\ntask-solving capabilities including coding, spatial computations, generation of\nsample data, time-series forecasting, toponym recognition, or image\nclassification. So far, the assessment of LLMs for spatial tasks has primarily\nfocused on ChatGPT, arguably the most prominent AI chatbot, whereas other\nchatbots received less attention. To narrow this research gap, this study\nevaluates the correctness of responses for a set of 54 spatial tasks assigned\nto four prominent chatbots, i.e., ChatGPT-4, Bard, Claude-2, and Copilot.\nOverall, the chatbots performed well on spatial literacy, GIS theory, and\ninterpretation of programming code and given functions, but revealed weaknesses\nin mapping, code generation, and code translation. ChatGPT-4 outperformed other\nchatbots across most task categories.",
                "authors": [
                    "Hartwig H. Hochmair",
                    "Levente Juhasz",
                    "Takoda Kemp"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02404v1",
                    "http://arxiv.org/pdf/2401.02404v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02403v1/1.0",
                "title": "Real-Time 2D Temperature Field Prediction in Metal Additive\n  Manufacturing Using Physics-Informed Neural Networks",
                "year": 2024,
                "abstract": "Accurately predicting the temperature field in metal additive manufacturing\n(AM) processes is critical to preventing overheating, adjusting process\nparameters, and ensuring process stability. While physics-based computational\nmodels offer precision, they are often time-consuming and unsuitable for\nreal-time predictions and online control in iterative design scenarios.\nConversely, machine learning models rely heavily on high-quality datasets,\nwhich can be costly and challenging to obtain within the metal AM domain. Our\nwork addresses this by introducing a physics-informed neural network framework\nspecifically designed for temperature field prediction in metal AM. This\nframework incorporates a physics-informed input, physics-informed loss\nfunction, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture.\nUtilizing real-time temperature data from the process, our model predicts 2D\ntemperature fields for future timestamps across diverse geometries, deposition\npatterns, and process parameters. We validate the proposed framework in two\nscenarios: full-field temperature prediction for a thin wall and 2D temperature\nfield prediction for cylinder and cubic parts, demonstrating errors below 3%\nand 1%, respectively. Our proposed framework exhibits the flexibility to be\napplied across diverse scenarios with varying process parameters, geometries,\nand deposition patterns.",
                "authors": [
                    "Pouyan Sajadi",
                    "Mostafa Rahmani Dehaghani",
                    "Yifan Tang",
                    "G. Gary Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02403v1",
                    "http://arxiv.org/pdf/2401.02403v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02402v1/1.0",
                "title": "3D Open-Vocabulary Panoptic Segmentation with 2D-3D Vision-Language\n  Distillation",
                "year": 2024,
                "abstract": "3D panoptic segmentation is a challenging perception task, which aims to\npredict both semantic and instance annotations for 3D points in a scene.\nAlthough prior 3D panoptic segmentation approaches have achieved great\nperformance on closed-set benchmarks, generalizing to novel categories remains\nan open problem. For unseen object categories, 2D open-vocabulary segmentation\nhas achieved promising results that solely rely on frozen CLIP backbones and\nensembling multiple classification outputs. However, we find that simply\nextending these 2D models to 3D does not achieve good performance due to poor\nper-mask classification quality on novel categories. In this paper, we propose\nthe first method to tackle 3D open-vocabulary panoptic segmentation. Our model\ntakes advantage of the fusion between learnable LiDAR features and dense frozen\nvision CLIP features, using a single classification head to make predictions\nfor both base and novel classes. To further improve the classification\nperformance on novel classes and leverage the CLIP model, we propose two novel\nloss functions: object-level distillation loss and voxel-level distillation\nloss. Our experiments on the nuScenes and SemanticKITTI datasets show that our\nmethod outperforms strong baselines by a large margin.",
                "authors": [
                    "Zihao Xiao",
                    "Longlong Jing",
                    "Shangxuan Wu",
                    "Alex Zihao Zhu",
                    "Jingwei Ji",
                    "Chiyu Max Jiang",
                    "Wei-Chih Hung",
                    "Thomas Funkhouser",
                    "Weicheng Kuo",
                    "Anelia Angelova",
                    "Yin Zhou",
                    "Shiwei Sheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02402v1",
                    "http://arxiv.org/pdf/2401.02402v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02400v1/1.0",
                "title": "Learning the 3D Fauna of the Web",
                "year": 2024,
                "abstract": "Learning 3D models of all animals on the Earth requires massively scaling up\nexisting solutions. With this ultimate goal in mind, we develop 3D-Fauna, an\napproach that learns a pan-category deformable 3D animal model for more than\n100 animal species jointly. One crucial bottleneck of modeling animals is the\nlimited availability of training data, which we overcome by simply learning\nfrom 2D Internet images. We show that prior category-specific attempts fail to\ngeneralize to rare species with limited training images. We address this\nchallenge by introducing the Semantic Bank of Skinned Models (SBSM), which\nautomatically discovers a small set of base animal shapes by combining\ngeometric inductive priors with semantic knowledge implicitly captured by an\noff-the-shelf self-supervised feature extractor. To train such a model, we also\ncontribute a new large-scale dataset of diverse animal species. At inference\ntime, given a single image of any quadruped animal, our model reconstructs an\narticulated 3D mesh in a feed-forward fashion within seconds.",
                "authors": [
                    "Zizhang Li",
                    "Dor Litvak",
                    "Ruining Li",
                    "Yunzhi Zhang",
                    "Tomas Jakab",
                    "Christian Rupprecht",
                    "Shangzhe Wu",
                    "Andrea Vedaldi",
                    "Jiajun Wu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02400v1",
                    "http://arxiv.org/pdf/2401.02400v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02398v1/1.0",
                "title": "Generating synthetic data for neural operators",
                "year": 2024,
                "abstract": "Numerous developments in the recent literature show the promising potential\nof deep learning in obtaining numerical solutions to partial differential\nequations (PDEs) beyond the reach of current numerical solvers. However,\ndata-driven neural operators all suffer from the same problem: the data needed\nto train a network depends on classical numerical solvers such as finite\ndifference or finite element, among others. In this paper, we propose a new\napproach to generating synthetic functional training data that does not require\nsolving a PDE numerically. The way we do this is simple: we draw a large number\n$N$ of independent and identically distributed `random functions' $u_j$ from\nthe underlying solution space (e.g., $H_0^1(\\Omega)$) in which we know the\nsolution lies according to classical theory. We then plug each such random\ncandidate solution into the equation and get a corresponding right-hand side\nfunction $f_j$ for the equation, and consider $(f_j, u_j)_{j=1}^N$ as\nsupervised training data for learning the underlying inverse problem $f\n\\rightarrow u$. This `backwards' approach to generating training data only\nrequires derivative computations, in contrast to standard `forward' approaches,\nwhich require a numerical PDE solver, enabling us to generate a large number of\nsuch data points quickly and efficiently. While the idea is simple, we hope\nthat this method will expand the potential for developing neural PDE solvers\nthat do not depend on classical numerical solvers.",
                "authors": [
                    "Erisa Hasani",
                    "Rachel A. Ward"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02398v1",
                    "http://arxiv.org/pdf/2401.02398v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NA",
                    "math.NA"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02395v1/1.0",
                "title": "Analyzing Misinformation Claims During the 2022 Brazilian General\n  Election on WhatsApp, Twitter, and Kwai",
                "year": 2024,
                "abstract": "This study analyzes misinformation from WhatsApp, Twitter, and Kwai during\nthe 2022 Brazilian general election. Given the democratic importance of\naccurate information during elections, multiple fact-checking organizations\ncollaborated to identify and respond to misinformation via WhatsApp tiplines\nand power a fact-checking feature within a chatbot operated by Brazil's\nelection authority, the TSE. WhatsApp is installed on over 99% of smartphones\nin Brazil, and the TSE chatbot was used by millions of citizens in the run-up\nto the elections. During the same period, we collected social media data from\nTwitter (now X) and Kwai (a popular video-sharing app similar to TikTok). Using\nthe WhatsApp, Kwai, and Twitter data along with fact-checks from three\nBrazilian fact-checking organizations, we find unique claims on each platform.\nEven when the same claims are present on different platforms, they often differ\nin format, detail, length, or other characteristics. Our research highlights\nthe limitations of current claim matching algorithms to match claims across\nplatforms with such differences and identifies areas for further algorithmic\ndevelopment. Finally, we perform a descriptive analysis examining the formats\n(image, video, audio, text) and content themes of popular misinformation\nclaims.",
                "authors": [
                    "Scott A. Hale",
                    "Adriano Belisario",
                    "Ahmed Mostafa",
                    "Chico Camargo"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02395v1",
                    "http://arxiv.org/pdf/2401.02395v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.SI",
                    "physics.soc-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02393v1/1.0",
                "title": "A PDE approach for solving the characteristic function of the\n  generalised signature process",
                "year": 2024,
                "abstract": "The signature of a path, as a fundamental object in Rough path theory, serves\nas a generating function for non-communicative monomials on path space. It\ntransforms the path into a grouplike element in the tensor algebra space,\nsummarising the path faithfully up to a generalised form of re-parameterisation\n(a negligible equivalence class in this context). Our paper concerns stochastic\nprocesses and studies the characteristic function of the path signature of the\nstochastic process. In contrast to the expected signature, it determines the\nlaw on the random signatures without any regularity condition. The computation\nof the characteristic function of the random signature offers potential\napplications in stochastic analysis and machine learning, where the expected\nsignature plays an important role. In this paper, we focus on a\ntime-homogeneous It\\^o diffusion process, and adopt a PDE approach to derive\nthe characteristic function of its signature defined at any fixed time horizon.\nA key ingredient of our approach is the introduction of the\ngeneralised-signature process. This lifting enables us to establish the\nFeynman-Kac-type theorem for the characteristic function of the\ngeneralised-signature process by following the martingale approach. Moreover,\nas an application of our results, we present a novel derivation of the joint\ncharacteristic function of Brownian motion coupled with the L\\'evy area,\nleveraging the structure theorem of anti-symmetric matrices.",
                "authors": [
                    "Terry Lyons",
                    "Hao Ni",
                    "Jiajie Tao"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02393v1",
                    "http://arxiv.org/pdf/2401.02393v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "math.AP"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02391v1/1.0",
                "title": "Updated numerical study of transverse single-spin asymmetries in\n  single-inclusive pion production from lepton-nucleon collisions",
                "year": 2024,
                "abstract": "We revisit the analysis of transverse single-spin asymmetries $A_N$ in\nlepton-nucleon scattering where only a single pion is detected in the final\nstate, $\\ell\\,N^\\uparrow\\to h\\, X$. This observable is the Electron-Ion\nCollider (EIC) analogue to $A_N$ in proton-proton collisions, $p^\\uparrow p\\to\nh\\,X$, that has been studied intensely for decades, especially at the\nRelativistic Heavy Ion Collider (RHIC). We incorporate new theoretical\ndevelopments in the collinear twist-3 framework and utilize recent extractions\nof (Sivers-like and Collins-like) quark-gluon-quark correlators in the\nnumerical computations. We compare our calculations to HERMES measurements as\nwell as make predictions for Jefferson Lab, COMPASS, and EIC kinematics. We\nfurther explore the role of next-to-leading order (NLO) corrections to the\n(twist-2) unpolarized cross section (denominator of $A_N$) and consider what\ncan be deduced empirically about the potential numerical significance of the\nfull NLO calculation of $A_N$ in this process. We consider sources of\ntheoretical uncertainty in our predictions, which present potential\nopportunities then for future measurements to improve our understanding of\n$A_N$ and multi-parton correlations in hadrons.",
                "authors": [
                    "Sophia Fitzgibbons",
                    "Michel Malda",
                    "Jacob Marsh",
                    "Daniel Pitonyak",
                    "Penn Smith"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02391v1",
                    "http://arxiv.org/pdf/2401.02391v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "hep-ex",
                    "nucl-ex",
                    "nucl-th"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02387v1/1.0",
                "title": "Assessing Time Series Correlation Significance: A Parametric Approach\n  with Application to Physiological Signals",
                "year": 2024,
                "abstract": "Correlation coefficients play a pivotal role in quantifying linear\nrelationships between random variables. Yet, their application to time series\ndata is very challenging due to temporal dependencies. This paper introduces a\nnovel approach to estimate the statistical significance of correlation\ncoefficients in time series data, addressing the limitations of traditional\nmethods based on the concept of effective degrees of freedom (or effective\nsample size, ESS). These effective degrees of freedom represent the independent\nsample size that would yield comparable test statistics under the assumption of\nno temporal correlation. We propose to assume a parametric Gaussian form for\nthe autocorrelation function. We show that this assumption, motivated by a\nLaplace approximation, enables a simple estimator of the ESS that depends only\non the temporal derivatives of the time series. Through numerical experiments,\nwe show that the proposed approach yields accurate statistics while\nsignificantly reducing computational overhead. In addition, we evaluate the\nadequacy of our approach on real physiological signals, for assessing the\nconnectivity measures in electrophysiology and detecting correlated arm\nmovements in motion capture data. Our methodology provides a simple tool for\nresearchers working with time series data, enabling robust hypothesis testing\nin the presence of temporal dependencies.",
                "authors": [
                    "Johan Medrano",
                    "Abderrahmane Kheddar",
                    "Sofiane Ramdani"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02387v1",
                    "http://arxiv.org/pdf/2401.02387v1"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME",
                    "q-bio.QM",
                    "stat.AP"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02385v1/1.0",
                "title": "TinyLlama: An Open-Source Small Language Model",
                "year": 2024,
                "abstract": "We present TinyLlama, a compact 1.1B language model pretrained on around 1\ntrillion tokens for approximately 3 epochs. Building on the architecture and\ntokenizer of Llama 2, TinyLlama leverages various advances contributed by the\nopen-source community (e.g., FlashAttention), achieving better computational\nefficiency. Despite its relatively small size, TinyLlama demonstrates\nremarkable performance in a series of downstream tasks. It significantly\noutperforms existing open-source language models with comparable sizes. Our\nmodel checkpoints and code are publicly available on GitHub at\nhttps://github.com/jzhang38/TinyLlama.",
                "authors": [
                    "Peiyuan Zhang",
                    "Guangtao Zeng",
                    "Tianduo Wang",
                    "Wei Lu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02385v1",
                    "http://arxiv.org/pdf/2401.02385v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02384v1/1.0",
                "title": "ChartAssisstant: A Universal Chart Multimodal Language Model via\n  Chart-to-Table Pre-training and Multitask Instruction Tuning",
                "year": 2024,
                "abstract": "Charts play a vital role in data visualization, understanding data patterns,\nand informed decision-making. However, their unique combination of graphical\nelements (e.g., bars, lines) and textual components (e.g., labels, legends)\nposes challenges for general-purpose multimodal models. While vision-language\nmodels trained on chart data excel in comprehension, they struggle with\ngeneralization and require task-specific fine-tuning. To address these\nchallenges, we propose ChartAssistant, a chart-based vision-language model for\nuniversal chart comprehension and reasoning. ChartAssistant leverages ChartSFT,\na comprehensive dataset covering diverse chart-related tasks with basic and\nspecialized chart types. It undergoes a two-stage training process, starting\nwith pre-training on chart-to-table parsing to align chart and text, followed\nby multitask instruction-following fine-tuning. This approach enables\nChartAssistant to achieve competitive performance across various chart tasks\nwithout task-specific fine-tuning. Experimental results demonstrate significant\nperformance gains over the state-of-the-art UniChart method, outperforming\nOpenAI's GPT-4V(ision) on real-world chart data. The code and data are\navailable at https://github.com/OpenGVLab/ChartAst.",
                "authors": [
                    "Fanqing Meng",
                    "Wenqi Shao",
                    "Quanfeng Lu",
                    "Peng Gao",
                    "Kaipeng Zhang",
                    "Yu Qiao",
                    "Ping Luo"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02384v1",
                    "http://arxiv.org/pdf/2401.02384v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02383v1/1.0",
                "title": "Survey of 3D Human Body Pose and Shape Estimation Methods for\n  Contemporary Dance Applications",
                "year": 2024,
                "abstract": "3D human body shape and pose estimation from RGB images is a challenging\nproblem with potential applications in augmented/virtual reality, healthcare\nand fitness technology and virtual retail. Recent solutions have focused on\nthree types of inputs: i) single images, ii) multi-view images and iii) videos.\nIn this study, we surveyed and compared 3D body shape and pose estimation\nmethods for contemporary dance and performing arts, with a special focus on\nhuman body pose and dressing, camera viewpoint, illumination conditions and\nbackground conditions. We demonstrated that multi-frame methods, such as PHALP,\nprovide better results than single-frame method for pose estimation when\ndancers are performing contemporary dances.",
                "authors": [
                    "Darshan Venkatrayappa",
                    "Alain Tremeau",
                    "Damien Muselet",
                    "Philippe Colantoni"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02383v1",
                    "http://arxiv.org/pdf/2401.02383v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02380v1/1.0",
                "title": "Byzantine-Resilient Gradient Coding through Local Gradient Computations",
                "year": 2024,
                "abstract": "We consider gradient coding in the presence of an adversary controlling\nso-called malicious workers trying to corrupt the computations. Previous works\npropose the use of MDS codes to treat the responses from malicious workers as\nerrors and correct them using the error-correction properties of the code. This\ncomes at the expense of increasing the replication, i.e., the number of workers\neach partial gradient is computed by. In this work, we propose a way to reduce\nthe replication to $s+1$ instead of $2s+1$ in the presence of $s$ malicious\nworkers. Our method detects erroneous inputs from the malicious workers,\ntransforming them into erasures. This comes at the expense of $s$ additional\nlocal computations at the main node and additional rounds of light\ncommunication between the main node and the workers. We define a general\nframework and give fundamental limits for fractional repetition data\nallocations. Our scheme is optimal in terms of replication and local\ncomputation and incurs a communication cost that is asymptotically, in the size\nof the dataset, a multiplicative factor away from the derived bound. We\nfurthermore show how additional redundancy can be exploited to reduce the\nnumber of local computations and communication cost, or, alternatively,\ntolerate straggling workers.",
                "authors": [
                    "Christoph Hofmeister",
                    "Luis Ma\u00dfny",
                    "Eitan Yaakobi",
                    "Rawad Bitar"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02380v1",
                    "http://arxiv.org/pdf/2401.02380v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "math.IT"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02379v1/1.0",
                "title": "Detection and Discovery of Misinformation Sources using Attributed\n  Webgraphs",
                "year": 2024,
                "abstract": "Website reliability labels underpin almost all research in misinformation\ndetection. However, misinformation sources often exhibit transient behavior,\nwhich makes many such labeled lists obsolete over time. We demonstrate that\nSearch Engine Optimization (SEO) attributes provide strong signals for\npredicting news site reliability. We introduce a novel attributed webgraph\ndataset with labeled news domains and their connections to outlinking and\nbacklinking domains. We demonstrate the success of graph neural networks in\ndetecting news site reliability using these attributed webgraphs, and show that\nour baseline news site reliability classifier outperforms current SoTA methods\non the PoliticalNews dataset, achieving an F1 score of 0.96. Finally, we\nintroduce and evaluate a novel graph-based algorithm for discovering previously\nunknown misinformation news sources.",
                "authors": [
                    "Peter Carragher",
                    "Evan M. Williams",
                    "Kathleen M. Carley"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02379v1",
                    "http://arxiv.org/pdf/2401.02379v1"
                ],
                "primary_category": "cs.SI",
                "categories": [
                    "cs.SI",
                    "cs.CY"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02375v1/1.0",
                "title": "Wave theory of lattice dynamics",
                "year": 2024,
                "abstract": "I present the mathematical structure of classical phonon theory in a general\nform, which emphasizes the wave natures of phonons, and which can serve as a\nrobust foundation for further development of the theory of strongly interacting\nphonons. I also show that the Fourier transform (FT) of the mass-weighted\nvelocity-velocity correlation function (mVVCF) is exactly the distribution of\nthe classical kinetic energy among frequencies and wavevectors. Because this\nresult is classically exact, it is general: It is as valid, theoretically, for\na liquid or a molecule in a non-thermal non-stationary state as it is for a\ncrystal at thermal equilibrium at a low temperature. Therefore, as well as\nbeing of fundamental importance to physical theory, this result implies that\ncalculating the FT of the mVVCF from atomistic simulations is a much more\npowerful computational tool than it is believed to be. Existing theory shows\nonly that the FT of the mVVCF is proportional to the vibrational density of\nstates at thermal equilibrium, and under the simplifying assumption that the\nnumber of available vibrational states is equal to the number of degrees of\nfreedom.",
                "authors": [
                    "Paul Tangney"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02375v1",
                    "http://arxiv.org/pdf/2401.02375v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci",
                    "math-ph",
                    "math.MP"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02369v1/1.0",
                "title": "SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded\n  Entity Retrieval",
                "year": 2024,
                "abstract": "Clinician must write a lengthy summary each time a patient is discharged from\nthe hospital. This task is time-consuming due to the sheer number of unique\nclinical concepts covered in the admission. Identifying and covering salient\nentities is vital for the summary to be clinically useful. We fine-tune\nopen-source LLMs (Mistral-7B-Instruct and Zephyr-7B-\\b{eta}) on the task and\nfind that they generate incomplete and unfaithful summaries. To increase entity\ncoverage, we train a smaller, encoder-only model to predict salient entities,\nwhich are treated as content-plans to guide the LLM. To encourage the LLM to\nfocus on specific mentions in the source notes, we propose SPEER:\nSentence-level Planning via Embedded Entity Retrieval. Specifically, we mark\neach salient entity span with special \"{{ }}\" boundary tags and instruct the\nLLM to retrieve marked spans before generating each sentence. Sentence-level\nplanning acts as a form of state tracking in that the model is explicitly\nrecording the entities it uses. We fine-tune Mistral and Zephyr variants on a\nlarge-scale, diverse dataset of ~167k in-patient hospital admissions and\nevaluate on 3 datasets. SPEER shows gains in both coverage and faithfulness\nmetrics over non-guided and guided baselines.",
                "authors": [
                    "Griffin Adams",
                    "Jason Zucker",
                    "No\u00e9mie Elhadad"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02369v1",
                    "http://arxiv.org/pdf/2401.02369v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02368v1/1.0",
                "title": "Quantum 2-SAT on low dimensional systems is $\\mathsf{QMA}_1$-complete:\n  Direct embeddings and black-box simulation",
                "year": 2024,
                "abstract": "Despite the fundamental role the Quantum Satisfiability (QSAT) problem has\nplayed in quantum complexity theory, a central question remains open: At which\nlocal dimension does the complexity of QSAT transition from \"easy\" to \"hard\"?\nHere, we study QSAT with each constraint acting on a $k$-dimensional and\n$l$-dimensional qudit pair, denoted $(k,l)$-QSAT. Our first main result shows\nthat, surprisingly, QSAT on qubits can remain $\\mathsf{QMA}_1$-hard, in that\n$(2,5)$-QSAT is $\\mathsf{QMA}_1$-complete. In contrast, $2$-SAT on qubits is\nwell-known to be poly-time solvable [Bravyi, 2006]. Our second main result\nproves that $(3,d)$-QSAT on the 1D line with $d\\in O(1)$ is also\n$\\mathsf{QMA}_1$-hard. Finally, we initiate the study of 1D $(2,d)$-QSAT by\ngiving a frustration-free 1D Hamiltonian with a unique, entangled ground state.\n  Our first result uses a direct embedding, combining a novel clock\nconstruction with the 2D circuit-to-Hamiltonian construction of [Gosset, Nagaj,\n2013]. Of note is a new simplified and analytic proof for the latter (as\nopposed to a partially numeric proof in [GN13]). This exploits Unitary Labelled\nGraphs [Bausch, Cubitt, Ozols, 2017] together with a new \"Nullspace Connection\nLemma\", allowing us to break low energy analyses into small patches of\nprojectors, and to improve the soundness analysis of [GN13] from\n$\\Omega(1/T^6)$ to $\\Omega(1/T^2)$, for $T$ the number of gates. Our second\nresult goes via black-box reduction: Given an arbitrary 1D Hamiltonian $H$ on\n$d'$-dimensional qudits, we show how to embed it into an effective null-space\nof a 1D $(3,d)$-QSAT instance, for $d\\in O(1)$. Our approach may be viewed as a\nweaker notion of \"simulation\" (\\`a la [Bravyi, Hastings 2017], [Cubitt,\nMontanaro, Piddock 2018]). As far as we are aware, this gives the first\n\"black-box simulation\"-based $\\mathsf{QMA}_1$-hardness result, i.e. for\nfrustration-free Hamiltonians.",
                "authors": [
                    "Dorian Rudolph",
                    "Sevag Gharibian",
                    "Daniel Nagaj"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02368v1",
                    "http://arxiv.org/pdf/2401.02368v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "cs.CC"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02365v1/1.0",
                "title": "Towards the determination of the 3-dimensional structure of the proton\n  using lattice QCD simulations",
                "year": 2024,
                "abstract": "State-of-the-art lattice QCD simulations enable the evaluation of nucleon\nform factors and Mellin moments with controlled systematics, yielding results\nwith unprecedented accuracy. At the same time, new theoretical approaches are\nallowing the direct computation of nucleon generalized parton distributions. We\nreview recent lattice QCD results on these quantities that are paving the way\nfor extracting a wealth of information on the 3-dimensional structure of the\nnucleon.",
                "authors": [
                    "Constantia Alexandrou",
                    "Simone Bacchio"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02365v1",
                    "http://arxiv.org/pdf/2401.02365v1"
                ],
                "primary_category": "hep-lat",
                "categories": [
                    "hep-lat",
                    "nucl-ex",
                    "nucl-th"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02363v1/1.0",
                "title": "Integration of physics-informed operator learning and finite element\n  method for parametric learning of partial differential equations",
                "year": 2024,
                "abstract": "We present a method that employs physics-informed deep learning techniques\nfor parametrically solving partial differential equations. The focus is on the\nsteady-state heat equations within heterogeneous solids exhibiting significant\nphase contrast. Similar equations manifest in diverse applications like\nchemical diffusion, electrostatics, and Darcy flow. The neural network aims to\nestablish the link between the complex thermal conductivity profiles and\ntemperature distributions, as well as heat flux components within the\nmicrostructure, under fixed boundary conditions. A distinctive aspect is our\nindependence from classical solvers like finite element methods for data. A\nnoteworthy contribution lies in our novel approach to defining the loss\nfunction, based on the discretized weak form of the governing equation. This\nnot only reduces the required order of derivatives but also eliminates the need\nfor automatic differentiation in the construction of loss terms, accepting\npotential numerical errors from the chosen discretization method. As a result,\nthe loss function in this work is an algebraic equation that significantly\nenhances training efficiency. We benchmark our methodology against the standard\nfinite element method, demonstrating accurate yet faster predictions using the\ntrained neural network for temperature and flux profiles. We also show higher\naccuracy by using the proposed method compared to purely data-driven approaches\nfor unforeseen scenarios.",
                "authors": [
                    "Shahed Rezaei",
                    "Ahmad Moeineddin",
                    "Michael Kaliske",
                    "Markus Apel"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02363v1",
                    "http://arxiv.org/pdf/2401.02363v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CE"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02361v1/1.0",
                "title": "An Open and Comprehensive Pipeline for Unified Object Grounding and\n  Detection",
                "year": 2024,
                "abstract": "Grounding-DINO is a state-of-the-art open-set detection model that tackles\nmultiple vision tasks including Open-Vocabulary Detection (OVD), Phrase\nGrounding (PG), and Referring Expression Comprehension (REC). Its effectiveness\nhas led to its widespread adoption as a mainstream architecture for various\ndownstream applications. However, despite its significance, the original\nGrounding-DINO model lacks comprehensive public technical details due to the\nunavailability of its training code. To bridge this gap, we present\nMM-Grounding-DINO, an open-source, comprehensive, and user-friendly baseline,\nwhich is built with the MMDetection toolbox. It adopts abundant vision datasets\nfor pre-training and various detection and grounding datasets for fine-tuning.\nWe give a comprehensive analysis of each reported result and detailed settings\nfor reproduction. The extensive experiments on the benchmarks mentioned\ndemonstrate that our MM-Grounding-DINO-Tiny outperforms the Grounding-DINO-Tiny\nbaseline. We release all our models to the research community. Codes and\ntrained models are released at\nhttps://github.com/open-mmlab/mmdetection/configs/mm_grounding_dino.",
                "authors": [
                    "Xiangyu Zhao",
                    "Yicheng Chen",
                    "Shilin Xu",
                    "Xiangtai Li",
                    "Xinjiang Wang",
                    "Yining Li",
                    "Haian Huang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02361v1",
                    "http://arxiv.org/pdf/2401.02361v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02358v1/1.0",
                "title": "A novel method to enhance pneumonia detection via a model-level\n  ensembling of CNN and vision transformer",
                "year": 2024,
                "abstract": "Pneumonia remains a leading cause of morbidity and mortality worldwide. Chest\nX-ray (CXR) imaging is a fundamental diagnostic tool, but traditional analysis\nrelies on time-intensive expert evaluation. Recently, deep learning has shown\nimmense potential for automating pneumonia detection from CXRs. This paper\nexplores applying neural networks to improve CXR-based pneumonia diagnosis. We\ndeveloped a novel model fusing Convolution Neural networks (CNN) and Vision\nTransformer networks via model-level ensembling. Our fusion architecture\ncombines a ResNet34 variant and a Multi-Axis Vision Transformer small model.\nBoth base models are initialized with ImageNet pre-trained weights. The output\nlayers are removed, and features are combined using a flattening layer before\nfinal classification. Experiments used the Kaggle pediatric pneumonia dataset\ncontaining 1,341 normal and 3,875 pneumonia CXR images. We compared our model\nagainst standalone ResNet34, Vision Transformer, and Swin Transformer Tiny\nbaseline models using identical training procedures. Extensive data\naugmentation, Adam optimization, learning rate warmup, and decay were employed.\nThe fusion model achieved a state-of-the-art accuracy of 94.87%, surpassing the\nbaselines. We also attained excellent sensitivity, specificity, kappa score,\nand positive predictive value. Confusion matrix analysis confirms fewer\nmisclassifications. The ResNet34 and Vision Transformer combination enables\njointly learning robust features from CNNs and Transformer paradigms. This\nmodel-level ensemble technique effectively integrates their complementary\nstrengths for enhanced pneumonia classification.",
                "authors": [
                    "Sandeep Angara",
                    "Nishith Reddy Mannuru",
                    "Aashrith Mannuru",
                    "Sharath Thirunagaru"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02358v1",
                    "http://arxiv.org/pdf/2401.02358v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02357v1/1.0",
                "title": "Fit-NGP: Fitting Object Models to Neural Graphics Primitives",
                "year": 2024,
                "abstract": "Accurate 3D object pose estimation is key to enabling many robotic\napplications that involve challenging object interactions. In this work, we\nshow that the density field created by a state-of-the-art efficient radiance\nfield reconstruction method is suitable for highly accurate and robust pose\nestimation for objects with known 3D models, even when they are very small and\nwith challenging reflective surfaces. We present a fully automatic object pose\nestimation system based on a robot arm with a single wrist-mounted camera,\nwhich can scan a scene from scratch, detect and estimate the 6-Degrees of\nFreedom (DoF) poses of multiple objects within a couple of minutes of\noperation. Small objects such as bolts and nuts are estimated with accuracy on\norder of 1mm.",
                "authors": [
                    "Marwan Taher",
                    "Ignacio Alzugaray",
                    "Andrew J. Davison"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02357v1",
                    "http://arxiv.org/pdf/2401.02357v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02347v1/1.0",
                "title": "Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via\n  Text-Only Training",
                "year": 2024,
                "abstract": "Image captioning aims at generating descriptive and meaningful textual\ndescriptions of images, enabling a broad range of vision-language applications.\nPrior works have demonstrated that harnessing the power of Contrastive Image\nLanguage Pre-training (CLIP) offers a promising approach to achieving zero-shot\ncaptioning, eliminating the need for expensive caption annotations. However,\nthe widely observed modality gap in the latent space of CLIP harms the\nperformance of zero-shot captioning by breaking the alignment between paired\nimage-text features. To address this issue, we conduct an analysis on the CLIP\nlatent space which leads to two findings. Firstly, we observe that the CLIP's\nvisual feature of image subregions can achieve closer proximity to the paired\ncaption due to the inherent information loss in text descriptions. In addition,\nwe show that the modality gap between a paired image-text can be empirically\nmodeled as a zero-mean Gaussian distribution. Motivated by the findings, we\npropose a novel zero-shot image captioning framework with text-only training to\nreduce the modality gap. In particular, we introduce a subregion feature\naggregation to leverage local region information, which produces a compact\nvisual representation for matching text representation. Moreover, we\nincorporate a noise injection and CLIP reranking strategy to boost captioning\nperformance. We also extend our framework to build a zero-shot VQA pipeline,\ndemonstrating its generality. Through extensive experiments on common\ncaptioning and VQA datasets such as MSCOCO, Flickr30k and VQAV2, we show that\nour method achieves remarkable performance improvements. Code is available at\nhttps://github.com/Artanic30/MacCap.",
                "authors": [
                    "Longtian Qiu",
                    "Shan Ning",
                    "Xuming He"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02347v1",
                    "http://arxiv.org/pdf/2401.02347v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02345v1/1.0",
                "title": "An entropy bound due to symmetries",
                "year": 2024,
                "abstract": "Let $H$ be a local net of real Hilbert subspaces of a complex Hilbert space\non the family of double cones of the spacetime $\\mathbb{R}^{d+1}$, covariant\nwith respect to a positive energy, unitary representation $U$ of the Poincar\\'e\ngroup, with the Bisognano-Wichmann property for the wedge modular group. We set\nan upper bound on the local entropy $S_H(\\phi|\\! | C)$ of a vector in a region\n$C$ that depends only on $U$ and the PCT anti-unitary canonically associated\nwith $H$. A similar result holds for local, M\\\"obius covariant nets of standard\nsubspaces on the circle. We compute the entropy increase and illustrate this\nbound for the nets associated with the $U(1)$-current derivatives.",
                "authors": [
                    "Roberto Longo",
                    "Vincenzo Morinelli"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02345v1",
                    "http://arxiv.org/pdf/2401.02345v1"
                ],
                "primary_category": "math.OA",
                "categories": [
                    "math.OA",
                    "hep-th",
                    "math-ph",
                    "math.MP",
                    "81T05, 81P45, 94A17, 46L60, 81T40"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02341v1/1.0",
                "title": "Deflection angle and shadow of slowly rotating black holes in galactic\n  nuclei",
                "year": 2024,
                "abstract": "In this paper, we construct the slowly rotating case of an asymptotically\nflat supermassive black hole embedded in dark matter using Newman-Janis\nprocedure. Our analysis is carried with respect to the involved parameters\nincluding the halo total mass $M$ and the galaxy's lengthscale $a_0$.\nConcretly, we investigate the dark matter impact on the effective potential and\nthe photon sphere. In particular, we find that the lengthscale $a_0$ controles\nsuch potential values. Indeed, for low $a_0$ values, we find that the halo\ntotal mass $M$ decreases the potential values significantly while for high\n$a_0$ values such impact is diluted. Regarding the shadow aspects, we show that\nthe shadow size is much smaller for high values of $a_0$ while the opposite\neffect is observed when the halo total mass $M$ is increased. By comparing our\ncase to the slowly rotating case, we notice that the former exhibits a shadow\nshifted from its center to the left side. Finally, we compute the deflection\nangle in the weak-limit approximation and inspect the dark matter parameters\ninfluence. By ploting such quantity, we observe that one should expect lower\nbending angle values for black holes in galactic nuclei.",
                "authors": [
                    "A. El Balali",
                    "M. Benali",
                    "M. Oualaid"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02341v1",
                    "http://arxiv.org/pdf/2401.02341v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02335v1/1.0",
                "title": "Linguistic Profiling of Deepfakes: An Open Database for Next-Generation\n  Deepfake Detection",
                "year": 2024,
                "abstract": "The emergence of text-to-image generative models has revolutionized the field\nof deepfakes, enabling the creation of realistic and convincing visual content\ndirectly from textual descriptions. However, this advancement presents\nconsiderably greater challenges in detecting the authenticity of such content.\nExisting deepfake detection datasets and methods often fall short in\neffectively capturing the extensive range of emerging deepfakes and offering\nsatisfactory explanatory information for detection. To address the significant\nissue, this paper introduces a deepfake database (DFLIP-3K) for the development\nof convincing and explainable deepfake detection. It encompasses about 300K\ndiverse deepfake samples from approximately 3K generative models, which boasts\nthe largest number of deepfake models in the literature. Moreover, it collects\naround 190K linguistic footprints of these deepfakes. The two distinguished\nfeatures enable DFLIP-3K to develop a benchmark that promotes progress in\nlinguistic profiling of deepfakes, which includes three sub-tasks namely\ndeepfake detection, model identification, and prompt prediction. The deepfake\nmodel and prompt are two essential components of each deepfake, and thus\ndissecting them linguistically allows for an invaluable exploration of\ntrustworthy and interpretable evidence in deepfake detection, which we believe\nis the key for the next-generation deepfake detection. Furthermore, DFLIP-3K is\nenvisioned as an open database that fosters transparency and encourages\ncollaborative efforts to further enhance its growth. Our extensive experiments\non the developed benchmark verify that our DFLIP-3K database is capable of\nserving as a standardized resource for evaluating and comparing\nlinguistic-based deepfake detection, identification, and prompt prediction\ntechniques.",
                "authors": [
                    "Yabin Wang",
                    "Zhiwu Huang",
                    "Zhiheng Ma",
                    "Xiaopeng Hong"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02335v1",
                    "http://arxiv.org/pdf/2401.02335v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02333v1/1.0",
                "title": "Beyond Extraction: Contextualising Tabular Data for Efficient\n  Summarisation by Language Models",
                "year": 2024,
                "abstract": "The conventional use of the Retrieval-Augmented Generation (RAG) architecture\nhas proven effective for retrieving information from diverse documents.\nHowever, challenges arise in handling complex table queries, especially within\nPDF documents containing intricate tabular structures.This research introduces\nan innovative approach to enhance the accuracy of complex table queries in\nRAG-based systems. Our methodology involves storing PDFs in the retrieval\ndatabase and extracting tabular content separately. The extracted tables\nundergo a process of context enrichment, concatenating headers with\ncorresponding values. To ensure a comprehensive understanding of the enriched\ndata, we employ a fine-tuned version of the Llama-2-chat language model for\nsummarisation within the RAG architecture. Furthermore, we augment the tabular\ndata with contextual sense using the ChatGPT 3.5 API through a one-shot prompt.\nThis enriched data is then fed into the retrieval database alongside other\nPDFs. Our approach aims to significantly improve the precision of complex table\nqueries, offering a promising solution to a longstanding challenge in\ninformation retrieval.",
                "authors": [
                    "Uday Allu",
                    "Biddwan Ahmed",
                    "Vishesh Tripathi"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02333v1",
                    "http://arxiv.org/pdf/2401.02333v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02331v1/1.0",
                "title": "A finite difference scheme for two-dimensional singularly perturbed\n  convection-diffusion problem with discontinuous source term",
                "year": 2024,
                "abstract": "We propose a finite difference scheme for the numerical solution of a\ntwo-dimensional singularly perturbed convection-diffusion partial differential\nequation whose solution features interacting boundary and interior layers, the\nlatter due to discontinuities in source term. The problem is posed on the unit\nsquare. The second derivative is multiplied by a singular perturbation\nparameter, $\\epsilon$, while the nature of the first derivative term is such\nthat flow is aligned with a boundary. These two facts mean that solutions tend\nto exhibit layers of both exponential and characteristic type. We solve the\nproblem using a finite difference method, specially adapted to the\ndiscontinuities, and applied on a piecewise-uniform (Shishkin). We prove that\nthat the computed solution converges to the true one at a rate that is\nindependent of the perturbation parameter, and is nearly first-order. We\npresent numerical results that verify that these results are sharp.",
                "authors": [
                    "Ram Shiromani",
                    "Niall Madden",
                    "V. Shanthi"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02331v1",
                    "http://arxiv.org/pdf/2401.02331v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.NA",
                    "35J25, 35J40, 35B25, 65N06, 65N12, 65N15"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02330v1/1.0",
                "title": "LLaVA-$\u03c6$: Efficient Multi-Modal Assistant with Small Language Model",
                "year": 2024,
                "abstract": "In this paper, we introduce LLaVA-$\\phi$ (LLaVA-Phi), an efficient\nmulti-modal assistant that harnesses the power of the recently advanced small\nlanguage model, Phi-2, to facilitate multi-modal dialogues. LLaVA-Phi marks a\nnotable advancement in the realm of compact multi-modal models. It demonstrates\nthat even smaller language models, with as few as 2.7B parameters, can\neffectively engage in intricate dialogues that integrate both textual and\nvisual elements, provided they are trained with high-quality corpora. Our model\ndelivers commendable performance on publicly available benchmarks that\nencompass visual comprehension, reasoning, and knowledge-based perception.\nBeyond its remarkable performance in multi-modal dialogue tasks, our model\nopens new avenues for applications in time-sensitive environments and systems\nthat require real-time interaction, such as embodied agents. It highlights the\npotential of smaller language models to achieve sophisticated levels of\nunderstanding and interaction, while maintaining greater resource\nefficiency.The project is available at {https://github.com/zhuyiche/llava-phi}.",
                "authors": [
                    "Yichen Zhu",
                    "Minjie Zhu",
                    "Ning Liu",
                    "Zhicai Ou",
                    "Xiaofeng Mou",
                    "Jian Tang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02330v1",
                    "http://arxiv.org/pdf/2401.02330v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02326v1/1.0",
                "title": "ClassWise-SAM-Adapter: Parameter Efficient Fine-tuning Adapts Segment\n  Anything to SAR Domain for Semantic Segmentation",
                "year": 2024,
                "abstract": "In the realm of artificial intelligence, the emergence of foundation models,\nbacked by high computing capabilities and extensive data, has been\nrevolutionary. Segment Anything Model (SAM), built on the Vision Transformer\n(ViT) model with millions of parameters and vast training dataset SA-1B, excels\nin various segmentation scenarios relying on its significance of semantic\ninformation and generalization ability. Such achievement of visual foundation\nmodel stimulates continuous researches on specific downstream tasks in computer\nvision. The ClassWise-SAM-Adapter (CWSAM) is designed to adapt the\nhigh-performing SAM for landcover classification on space-borne Synthetic\nAperture Radar (SAR) images. The proposed CWSAM freezes most of SAM's\nparameters and incorporates lightweight adapters for parameter efficient\nfine-tuning, and a classwise mask decoder is designed to achieve semantic\nsegmentation task. This adapt-tuning method allows for efficient landcover\nclassification of SAR images, balancing the accuracy with computational demand.\nIn addition, the task specific input module injects low frequency information\nof SAR images by MLP-based layers to improve the model performance. Compared to\nconventional state-of-the-art semantic segmentation algorithms by extensive\nexperiments, CWSAM showcases enhanced performance with fewer computing\nresources, highlighting the potential of leveraging foundational models like\nSAM for specific downstream tasks in the SAR domain. The source code is\navailable at: https://github.com/xypu98/CWSAM.",
                "authors": [
                    "Xinyang Pu",
                    "Hecheng Jia",
                    "Linghao Zheng",
                    "Feng Wang",
                    "Feng Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02326v1",
                    "http://arxiv.org/pdf/2401.02326v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02323v1/1.0",
                "title": "Multi-Agent Context Learning Strategy for Interference-Aware Beam\n  Allocation in mmWave Vehicular Communications",
                "year": 2024,
                "abstract": "Millimeter wave (mmWave) has been recognized as one of key technologies for\n5G and beyond networks due to its potential to enhance channel bandwidth and\nnetwork capacity. The use of mmWave for various applications including\nvehicular communications has been extensively discussed. However, applying\nmmWave to vehicular communications faces challenges of high mobility nodes and\nnarrow coverage along the mmWave beams. Due to high mobility in dense networks,\noverlapping beams can cause strong interference which leads to performance\ndegradation. As a remedy, beam switching capability in mmWave can be utilized.\nThen, frequent beam switching and cell change become inevitable to manage\ninterference, which increase computational and signalling complexity. In order\nto deal with the complexity in interference control, we develop a new strategy\ncalled Multi-Agent Context Learning (MACOL), which utilizes Contextual Bandit\nto manage interference while allocating mmWave beams to serve vehicles in the\nnetwork. Our approach demonstrates that by leveraging knowledge of neighbouring\nbeam status, the machine learning agent can identify and avoid potential\ninterfering transmissions to other ongoing transmissions. Furthermore, we show\nthat even under heavy traffic loads, our proposed MACOL strategy is able to\nmaintain low interference levels at around 10%.",
                "authors": [
                    "Abdulkadir Kose",
                    "Haeyoung Lee",
                    "Chuan Heng Foh",
                    "Mohammad Shojafar"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02323v1",
                    "http://arxiv.org/pdf/2401.02323v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.LG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02321v1/1.0",
                "title": "Deep Learning for Optical Tweezers",
                "year": 2024,
                "abstract": "Optical tweezers exploit light--matter interactions to trap particles ranging\nfrom single atoms to micrometer-sized eukaryotic cells. For this reason,\noptical tweezers are a ubiquitous tool in physics, biology, and nanotechnology.\nRecently, the use of deep learning has started to enhance optical tweezers by\nimproving their design, calibration, and real-time control as well as the\ntracking and analysis of the trapped objects, often outperforming classical\nmethods thanks to the higher computational speed and versatility of deep\nlearning. Here, we review how deep learning has already remarkably improved\noptical tweezers, while exploring the exciting, new future possibilities\nenabled by this dynamic synergy. Furthermore, we offer guidelines on\nintegrating deep learning with optical trapping and optical manipulation in a\nreliable and trustworthy way.",
                "authors": [
                    "Antonio Ciarlo",
                    "David Bronte Ciriza",
                    "Martin Selin",
                    "Onofrio M. Marag\u00f2",
                    "Antonio Sasso",
                    "Giuseppe Pesce",
                    "Giovanni Volpe",
                    "Mattias Goks\u00f6r"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02321v1",
                    "http://arxiv.org/pdf/2401.02321v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "physics.ins-det",
                    "78-02"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02317v1/1.0",
                "title": "BA-SAM: Scalable Bias-Mode Attention Mask for Segment Anything Model",
                "year": 2024,
                "abstract": "In this paper, we address the challenge of image resolution variation for the\nSegment Anything Model (SAM). SAM, known for its zero-shot generalizability,\nexhibits a performance degradation when faced with datasets with varying image\nsizes. Previous approaches tend to resize the image to a fixed size or adopt\nstructure modifications, hindering the preservation of SAM's rich prior\nknowledge. Besides, such task-specific tuning necessitates a complete\nretraining of the model, which is cost-expensive and unacceptable for\ndeployment in the downstream tasks. In this paper, we reformulate this issue as\na length extrapolation problem, where token sequence length varies while\nmaintaining a consistent patch size for images of different sizes. To this end,\nwe propose Scalable Bias-Mode Attention Mask (BA-SAM) to enhance SAM's\nadaptability to varying image resolutions while eliminating the need for\nstructure modifications. Firstly, we introduce a new scaling factor to ensure\nconsistent magnitude in the attention layer's dot product values when the token\nsequence length changes. Secondly, we present a bias-mode attention mask that\nallows each token to prioritize neighboring information, mitigating the impact\nof untrained distant information. Our BA-SAM demonstrates efficacy in two\nscenarios: zero-shot and fine-tuning. Extensive evaluation on diverse datasets,\nincluding DIS5K, DUTS, ISIC, COD10K, and COCO, reveals its ability to\nsignificantly mitigate performance degradation in the zero-shot setting and\nachieve state-of-the-art performance with minimal fine-tuning. Furthermore, we\npropose a generalized model and benchmark, showcasing BA-SAM's generalizability\nacross all four datasets simultaneously.",
                "authors": [
                    "Yiran Song",
                    "Qianyu Zhou",
                    "Xiangtai Li",
                    "Deng-Ping Fan",
                    "Xuequan Lu",
                    "Lizhuang Ma"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02317v1",
                    "http://arxiv.org/pdf/2401.02317v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02314v1/1.0",
                "title": "Applying the Viterbi Algorithm to Planetary-Mass Black Hole Searches",
                "year": 2024,
                "abstract": "The search for subsolar mass primordial black holes (PBHs) poses a\nchallenging problem due to the low signal-to-noise ratio, extended signal\nduration, and computational cost demands, compared to solar mass binary black\nhole events. In this paper, we explore the possibility of investigating the\nmass range between subsolar and planetary masses, which is not accessible using\nstandard matched filtering and continuous wave searches. We propose a\nsystematic approach employing the Viterbi algorithm, a dynamic programming\nalgorithm that identifies the most likely sequence of hidden Markov states\ngiven a sequence of observations, to detect signals from small mass PBH\nbinaries. We formulate the methodology, provide the optimal length for\nshort-time Fourier transforms, and estimate sensitivity. Subsequently, we\ndemonstrate the effectiveness of the Viterbi algorithm in identifying signals\nwithin mock data containing Gaussian noise. Our approach offers the primary\nadvantage of being agnostic and computationally efficient.",
                "authors": [
                    "George Alestas",
                    "Gonzalo Morras",
                    "Takahiro S. Yamamoto",
                    "Juan Garcia-Bellido",
                    "Sachiko Kuroyanagi",
                    "Savvas Nesseris"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02314v1",
                    "http://arxiv.org/pdf/2401.02314v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "astro-ph.IM",
                    "gr-qc"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02313v1/1.0",
                "title": "SuperEdge: Towards a Generalization Model for Self-Supervised Edge\n  Detection",
                "year": 2024,
                "abstract": "Edge detection is a fundamental technique in various computer vision tasks.\nEdges are indeed effectively delineated by pixel discontinuity and can offer\nreliable structural information even in textureless areas. State-of-the-art\nheavily relies on pixel-wise annotations, which are labor-intensive and subject\nto inconsistencies when acquired manually. In this work, we propose a novel\nself-supervised approach for edge detection that employs a multi-level,\nmulti-homography technique to transfer annotations from synthetic to real-world\ndatasets. To fully leverage the generated edge annotations, we developed\nSuperEdge, a streamlined yet efficient model capable of concurrently extracting\nedges at pixel-level and object-level granularity. Thanks to self-supervised\ntraining, our method eliminates the dependency on manual annotated edge labels,\nthereby enhancing its generalizability across diverse datasets. Comparative\nevaluations reveal that SuperEdge advances edge detection, demonstrating\nimprovements of 4.9% in ODS and 3.3% in OIS over the existing STEdge method on\nBIPEDv2.",
                "authors": [
                    "Leng Kai",
                    "Zhang Zhijie",
                    "Liu Jie",
                    "Zed Boukhers",
                    "Sui Wei",
                    "Cong Yang",
                    "Li Zhijun"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02313v1",
                    "http://arxiv.org/pdf/2401.02313v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02311v1/1.0",
                "title": "Fourier neural operator based fluid-structure interaction for predicting\n  the vesicle dynamics",
                "year": 2024,
                "abstract": "Solving complex fluid-structure interaction (FSI) problems, characterized by\nnonlinear partial differential equations, is crucial in various scientific and\nengineering applications. Traditional computational fluid dynamics (CFD)\nsolvers are insufficient to meet the growing requirements for large-scale and\nlong-period simulations. Fortunately, the rapid advancement in neural networks,\nespecially neural operator learning mappings between function spaces, has\nintroduced novel approaches to tackle these challenges via data-driven\nmodeling. In this paper, we propose a Fourier neural operator-based\nfluid-structure interaction solver (FNO-based FSI solver) for efficient\nsimulation of FSI problems, where the solid solver based on the finite\ndifference method is seamlessly integrated with the Fourier neural operator to\npredict incompressible flow using the immersed boundary method. We analyze the\nperformance of the FNO-based FSI solver in the following three situations:\ntraining data with or without the steady state, training method with one-step\nlabel or multi-step labels, and prediction in interpolation or extrapolation.\nWe find that the best performance for interpolation is achieved by training the\noperator with multi-step labels using steady-state data. Finally, we train the\nFNO-based FSI solver using this optimal training method and apply it to vesicle\ndynamics. The results show that the FNO-based FSI solver is capable of\ncapturing the variations in the fluid and the vesicle.",
                "authors": [
                    "Wang Xiao",
                    "Ting Gao",
                    "Kai Liu",
                    "Jinqiao Duan",
                    "Meng Zhao"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02311v1",
                    "http://arxiv.org/pdf/2401.02311v1"
                ],
                "primary_category": "math.DS",
                "categories": [
                    "math.DS"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02309v1/1.0",
                "title": "TR-DETR: Task-Reciprocal Transformer for Joint Moment Retrieval and\n  Highlight Detection",
                "year": 2024,
                "abstract": "Video moment retrieval (MR) and highlight detection (HD) based on natural\nlanguage queries are two highly related tasks, which aim to obtain relevant\nmoments within videos and highlight scores of each video clip. Recently,\nseveral methods have been devoted to building DETR-based networks to solve both\nMR and HD jointly. These methods simply add two separate task heads after\nmulti-modal feature extraction and feature interaction, achieving good\nperformance. Nevertheless, these approaches underutilize the reciprocal\nrelationship between two tasks. In this paper, we propose a task-reciprocal\ntransformer based on DETR (TR-DETR) that focuses on exploring the inherent\nreciprocity between MR and HD. Specifically, a local-global multi-modal\nalignment module is first built to align features from diverse modalities into\na shared latent space. Subsequently, a visual feature refinement is designed to\neliminate query-irrelevant information from visual features for modal\ninteraction. Finally, a task cooperation module is constructed to refine the\nretrieval pipeline and the highlight score prediction process by utilizing the\nreciprocity between MR and HD. Comprehensive experiments on QVHighlights,\nCharades-STA and TVSum datasets demonstrate that TR-DETR outperforms existing\nstate-of-the-art methods. Codes are available at\n\\url{https://github.com/mingyao1120/TR-DETR}.",
                "authors": [
                    "Hao Sun",
                    "Mingyao Zhou",
                    "Wenjing Chen",
                    "Wei Xie"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02309v1",
                    "http://arxiv.org/pdf/2401.02309v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.MM"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02307v1/1.0",
                "title": "Hydrodynamic Simulations of Oxygen-Neon Classical Novae as Galactic\n  $^7$Li Producers and Potential Accretion Induced Collapse Progenitors",
                "year": 2024,
                "abstract": "We report on studies of Classical Nova (CN) explosions where we follow the\nevolution of thermonuclear runaways (TNRs) on oxygen-neon (ONe) white dwarfs\n(WDs). Using NOVA, a one-dimensional hydrodynamic computer code, we accrete\nSolar matter until the TNR is ongoing and then switch to a mixed composition.\nThis approach is guided by the results of multi-dimensional studies of TNRs in\nWDs which find that sufficient mixing with WD core material occurs after the\nTNR is well underway, and levels of enrichment of the CNONeMg elements are\nreached that agree with observations of CN ejecta abundances. Because the\namount of accreted material is inversely proportional to the oxygen abundance,\nby first accreting Solar matter, the amount of accreted material is larger than\nin those simulations with an initially enriched composition. We vary the mass\nof the WD (from 0.6 Msun to 1.35 Msun) and the composition of the mixed\nmaterials. Our results show large enrichments of 7Be in the ejected gases\nimplying that ONe CNe and CO CNe (Starrfield et al. 2020) may be responsible\nfor a significant fraction (about 100 Msun) of the galactic 7Li ( about 1000\nMsun). The production of 22Na and 26Al in CN explosions and the gamma-ray\nemission predicted by our simulations is discussed. The WDs in all our\nsimulations eject less material than they accrete and we predict that the WD is\ngrowing in mass as a consequence of the CN outburst. ONe CNe, therefore, may be\nan important channel for accretion induced collapse (AIC) events.",
                "authors": [
                    "Sumner Starrfield",
                    "Maitrayee Bose",
                    "Christian Iliadis",
                    "W. Raphael Hix",
                    "Charles E. Woodward",
                    "R. Mark Wagner"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02307v1",
                    "http://arxiv.org/pdf/2401.02307v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "astro-ph.HE",
                    "nucl-th"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02306v1/1.0",
                "title": "Secure Control of Connected and Automated Vehicles Using Trust-Aware\n  Robust Event-Triggered Control Barrier Functions",
                "year": 2024,
                "abstract": "We address the security of a network of Connected and Automated Vehicles\n(CAVs) cooperating to safely navigate through a conflict area (e.g., traffic\nintersections, merging roadways, roundabouts). Previous studies have shown that\nsuch a network can be targeted by adversarial attacks causing traffic jams or\nsafety violations ending in collisions. We focus on attacks targeting the V2X\ncommunication network used to share vehicle data and consider as well\nuncertainties due to noise in sensor measurements and communication channels.\nTo combat these, motivated by recent work on the safe control of CAVs, we\npropose a trust-aware robust event-triggered decentralized control and\ncoordination framework that can provably guarantee safety. We maintain a trust\nmetric for each vehicle in the network computed based on their behavior and\nused to balance the tradeoff between conservativeness (when deeming every\nvehicle as untrustworthy) and guaranteed safety and security. It is important\nto highlight that our framework is invariant to the specific choice of the\ntrust framework. Based on this framework, we propose an attack detection and\nmitigation scheme which has twofold benefits: (i) the trust framework is immune\nto false positives, and (ii) it provably guarantees safety against false\npositive cases. We use extensive simulations (in SUMO and CARLA) to validate\nthe theoretical guarantees and demonstrate the efficacy of our proposed scheme\nto detect and mitigate adversarial attacks.",
                "authors": [
                    "H M Sabbir Ahmad",
                    "Ehsan Sabouni",
                    "Akua Dickson",
                    "Wei Xiao",
                    "Christos G. Cassandras",
                    "Wenchao Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02306v1",
                    "http://arxiv.org/pdf/2401.02306v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02303v1/1.0",
                "title": "Estimating the link budget of satellite-based Quantum Key Distribution\n  (QKD) for uplink transmission through the atmosphere",
                "year": 2024,
                "abstract": "Satellite-based quantum communications including quantum key distribution\n(QKD) represent one of the most promising approaches toward global-scale\nquantum communications. To determine the viability of transmitting quantum\nsignals through the atmosphere, it is essential to conduct atmospheric\nsimulations for both uplink and downlink quantum communications. In the case of\nthe uplink scenario, the initial phase of the beam's propagation involves\ninteraction with the atmosphere, making simulation particularly critical. To\nanalyze the atmosphere over the Indian subcontinent, we begin by validating our\napproach by utilizing atmospheric data obtained from the experiments carried\nout in the Canary Islands within the framework of Quantum Communication (QC).\nWe also verify our simulation methodology by reproducing simulation outcomes\nfrom diverse Canadian locations, taking into account both uplink and downlink\nscenarios in Low Earth Orbit (LEO). In this manuscript, we explore the\npracticality of utilizing three different ground station locations in India for\nuplink-based QC, while also considering beacon signals for both uplink and\ndownlink scenarios. The atmospheric conditions of various geographical regions\nin India are simulated, and a dedicated link budget analysis is performed for\neach location, specifically focusing on three renowned observatories: IAO\nHanle, Aries Nainital, and Mount Abu. The analysis involves computing the\noverall losses of the signal and beacon beams. The findings indicate that the\nIAO Hanle site is a more suitable choice for uplink-based QC when compared to\nthe other two sites.",
                "authors": [
                    "Satya Ranjan Behera",
                    "Urbasi Sinha"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02303v1",
                    "http://arxiv.org/pdf/2401.02303v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02301v1/1.0",
                "title": "A Generalized Variable Projection Algorithm for Least Squares Problems\n  in Atmospheric Remote Sensing",
                "year": 2024,
                "abstract": "This paper presents a solution for efficiently and accurately solving\nseparable least squares problems with multiple datasets. These problems involve\ndetermining linear parameters that are specific to each dataset while ensuring\nthat the nonlinear parameters remain consistent across all datasets. A\nwell-established approach for solving such problems is the variable projection\nalgorithm introduced by Golub and LeVeque, which effectively reduces a\nseparable problem to its nonlinear component. However, this algorithm assumes\nthat the datasets have equal sizes and identical auxiliary model parameters.\nThis article is motivated by a real-world remote sensing application where\nthese assumptions do not apply. Consequently, we propose a generalized\nalgorithm that extends the original theory to overcome these limitations. The\nnew algorithm has been implemented and tested using both synthetic and real\nsatellite data for atmospheric carbon dioxide retrievals. It has also been\ncompared to conventional state-of-the-art solvers, and its advantages are\nthoroughly discussed. The experimental results demonstrate that the proposed\nalgorithm significantly outperforms all other methods in terms of computation\ntime, while maintaining comparable accuracy and stability. Hence, this novel\nmethod can have a positive impact on future applications in remote sensing and\ncould be valuable for other scientific fitting problems with similar\nproperties.",
                "authors": [
                    "Adelina B\u00e4rligea",
                    "Philipp Hochstaffl",
                    "Franz Schreier"
                ],
                "url": [
                    "http://dx.doi.org/10.3390/math11132839",
                    "http://arxiv.org/abs/2401.02301v1",
                    "http://arxiv.org/pdf/2401.02301v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "astro-ph.EP",
                    "astro-ph.IM",
                    "cs.NA",
                    "physics.ao-ph",
                    "01-08, 65K10, 65D10, 15A29"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02300v1/1.0",
                "title": "Robust Physics Informed Neural Networks",
                "year": 2024,
                "abstract": "We introduce a Robust version of the Physics-Informed Neural Networks\n(RPINNs) to approximate the Partial Differential Equations (PDEs) solution.\nStandard Physics Informed Neural Networks (PINN) takes into account the\ngoverning physical laws described by PDE during the learning process. The\nnetwork is trained on a data set that consists of randomly selected points in\nthe physical domain and its boundary. PINNs have been successfully applied to\nsolve various problems described by PDEs with boundary conditions. The loss\nfunction in traditional PINNs is based on the strong residuals of the PDEs.\nThis loss function in PINNs is generally not robust with respect to the true\nerror. The loss function in PINNs can be far from the true error, which makes\nthe training process more difficult. In particular, we do not know if the\ntraining process has already converged to the solution with the required\naccuracy. This is especially true if we do not know the exact solution, so we\ncannot estimate the true error during the training. This paper introduces a\ndifferent way of defining the loss function. It incorporates the residual and\nthe inverse of the Gram matrix, computed using the energy norm. We test our\nRPINN algorithm on two Laplace problems and one advection-diffusion problem in\ntwo spatial dimensions. We conclude that RPINN is a robust method. The proposed\nloss coincides well with the true error of the solution, as measured in the\nenergy norm. Thus, we know if our training process goes well, and we know when\nto stop the training to obtain the neural network approximation of the solution\nof the PDE with the true error of required accuracy.",
                "authors": [
                    "Marcin \u0141o\u015b",
                    "Maciej Paszy\u0144ski"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02300v1",
                    "http://arxiv.org/pdf/2401.02300v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NA",
                    "math.NA",
                    "65M99, 68T07",
                    "G.1.8; I.2; I.m; G.1.10; J.2"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02298v1/1.0",
                "title": "Optimal shape design of printing nozzles for extrusion-based additive\n  manufacturing",
                "year": 2024,
                "abstract": "The optimal design seeks the best possible solution(s) for a mechanical\nstructure, device, or system, satisfying a series of requirements and leading\nto the best performance. In this work, optimized nozzle shapes have been\ndesigned for a wide range of polymer melts to be used in extrusion-based\nadditive manufacturing, which aims to minimize pressure drop and allow greater\nflow control at large extrusion velocities. This is achieved with a twofold\napproach, combining a global optimization algorithm with computational fluid\ndynamics for optimizing a contraction geometry for viscoelastic fluids and\nvalidating these geometries experimentally. In the optimization process,\nvariable coordinates for the nozzle's contraction section are defined, the\nobjective function is selected, and the optimization algorithm is guided within\nmanufacturing constraints. Comparisons of flow-type and streamline plots reveal\nthat the nozzle shape significantly influences flow patterns. Depending on the\nrheological properties, the optimized solution either promotes shear or\nextensional flow, enhancing the material flow rate. Finally, experimental\nvalidation of the nozzle performance assessed the actual printing flow, the\nextrusion force and the overall print control. It is shown that optimizing the\nnozzle can significantly reduce backflow-related pressure drop, positively\nimpacting total pressure drop (up to 41%) and reducing backflow effects. This\nwork has real-world implications for the additive manufacturing industry,\noffering opportunities for increased printing speeds, enhanced productivity,\nand improved printing quality and reliability. Our research contributes to\nadvancing extrusion-based printing processes technology, addressing industry\ndemands and enhancing the field of additive manufacturing.",
                "authors": [
                    "Tomas Schuller",
                    "Maziyar Jalaal",
                    "Paola Fanzio",
                    "Francisco J. Galindo-Rosales"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02298v1",
                    "http://arxiv.org/pdf/2401.02298v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "physics.app-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02297v1/1.0",
                "title": "Are LLMs Robust for Spoken Dialogues?",
                "year": 2024,
                "abstract": "Large Pre-Trained Language Models have demonstrated state-of-the-art\nperformance in different downstream tasks, including dialogue state tracking\nand end-to-end response generation. Nevertheless, most of the publicly\navailable datasets and benchmarks on task-oriented dialogues focus on written\nconversations. Consequently, the robustness of the developed models to spoken\ninteractions is unknown. In this work, we have evaluated the performance of\nLLMs for spoken task-oriented dialogues on the DSTC11 test sets. Due to the\nlack of proper spoken dialogue datasets, we have automatically transcribed a\ndevelopment set of spoken dialogues with a state-of-the-art ASR engine. We have\ncharacterized the ASR-error types and their distributions and simulated these\nerrors in a large dataset of dialogues. We report the intrinsic (perplexity)\nand extrinsic (human evaluation) performance of fine-tuned GPT-2 and T5 models\nin two subtasks of response generation and dialogue state tracking,\nrespectively. The results show that LLMs are not robust to spoken noise by\ndefault, however, fine-tuning/training such models on a proper dataset of\nspoken TODs can result in a more robust performance.",
                "authors": [
                    "Seyed Mahed Mousavi",
                    "Gabriel Roccabruna",
                    "Simone Alghisi",
                    "Massimo Rizzoli",
                    "Mirco Ravanelli",
                    "Giuseppe Riccardi"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02297v1",
                    "http://arxiv.org/pdf/2401.02297v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02295v1/1.0",
                "title": "Tunning the number of chiral edge channels in a fixed quantum anomalous\n  Hall system",
                "year": 2024,
                "abstract": "Quantum anomalous Hall (QAH) insulators exhibit chiral edge channels\ncharacterized by vanishing longitudinal conductance and quantized Hall\nconductance of Ce2/h, wherein the Chern number C is an integer equal to the\nnumber of the parallel chiral edge channels. These chiral edge channels conduct\ndissipationless transport in QAH insulators, making them pivotal for\napplications in low-consumption electronics and topological quantum computing.\nWhile the QAH effect with multiple chiral edge channels (i.e., C >1) has been\ndemonstrated in multilayers consisting of magnetic topological insulators and\nnormal insulators, the channel number remains fixed for a given sample. Here,\nwe unveil the tunability of the number of chiral edge channels within a single\nQAH insulator device. By tuning the magnetization of individual layers within\nthe multilayer system, Chern insulating states with different Chern numbers are\nunveiled. The tunable Chern number was corroborated by our theoretical\ncalculations. Furthermore, we conducted layer-dependent calculations to\nelucidate the contribution of the Chern number from different layers in the\nmultilayer. Our findings demonstrate an extra degree of freedom in manipulating\nthe chiral edge channels in QAH insulators. This newfound tunability offers\nextra dimension for the implementation of the QAH-based multi-channel\ndissipationless transport.",
                "authors": [
                    "Peng Deng",
                    "Yulei Han",
                    "Peng Zhang",
                    "Su Kong Chong",
                    "Zhenhua Qiao",
                    "Kang L. Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02295v1",
                    "http://arxiv.org/pdf/2401.02295v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "cond-mat.mtrl-sci"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02292v1/1.0",
                "title": "GridFormer: Point-Grid Transformer for Surface Reconstruction",
                "year": 2024,
                "abstract": "Implicit neural networks have emerged as a crucial technology in 3D surface\nreconstruction. To reconstruct continuous surfaces from discrete point clouds,\nencoding the input points into regular grid features (plane or volume) has been\ncommonly employed in existing approaches. However, these methods typically use\nthe grid as an index for uniformly scattering point features. Compared with the\nirregular point features, the regular grid features may sacrifice some\nreconstruction details but improve efficiency. To take full advantage of these\ntwo types of features, we introduce a novel and high-efficiency attention\nmechanism between the grid and point features named Point-Grid Transformer\n(GridFormer). This mechanism treats the grid as a transfer point connecting the\nspace and point cloud. Our method maximizes the spatial expressiveness of grid\nfeatures and maintains computational efficiency. Furthermore, optimizing\npredictions over the entire space could potentially result in blurred\nboundaries. To address this issue, we further propose a boundary optimization\nstrategy incorporating margin binary cross-entropy loss and boundary sampling.\nThis approach enables us to achieve a more precise representation of the object\nstructure. Our experiments validate that our method is effective and\noutperforms the state-of-the-art approaches under widely used benchmarks by\nproducing more precise geometry reconstructions. The code is available at\nhttps://github.com/list17/GridFormer.",
                "authors": [
                    "Shengtao Li",
                    "Ge Gao",
                    "Yudong Liu",
                    "Yu-Shen Liu",
                    "Ming Gu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02292v1",
                    "http://arxiv.org/pdf/2401.02292v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02287v1/1.0",
                "title": "Distillation-based fabric anomaly detection",
                "year": 2024,
                "abstract": "Unsupervised texture anomaly detection has been a concerning topic in a vast\namount of industrial processes. Patterned textures inspection, particularly in\nthe context of fabric defect detection, is indeed a widely encountered use\ncase. This task involves handling a diverse spectrum of colors and textile\ntypes, encompassing a wide range of fabrics. Given the extensive variability in\ncolors, textures, and defect types, fabric defect detection poses a complex and\nchallenging problem in the field of patterned textures inspection. In this\narticle, we propose a knowledge distillation-based approach tailored\nspecifically for addressing the challenge of unsupervised anomaly detection in\ntextures resembling fabrics. Our method aims to redefine the recently\nintroduced reverse distillation approach, which advocates for an\nencoder-decoder design to mitigate classifier bias and to prevent the student\nfrom reconstructing anomalies. In this study, we present a new reverse\ndistillation technique for the specific task of fabric defect detection. Our\napproach involves a meticulous design selection that strategically highlights\nhigh-level features. To demonstrate the capabilities of our approach both in\nterms of performance and inference speed, we conducted a series of experiments\non multiple texture datasets, including MVTEC AD, AITEX, and TILDA, alongside\nconducting experiments on a dataset acquired from a textile manufacturing\nfacility. The main contributions of this paper are the following: a robust\ntexture anomaly detector utilizing a reverse knowledge-distillation technique\nsuitable for both anomaly detection and domain generalization and a novel\ndataset encompassing a diverse range of fabrics and defects.",
                "authors": [
                    "Simon Thomine",
                    "Hichem Snoussi"
                ],
                "url": [
                    "http://dx.doi.org/10.1177/00405175231206820",
                    "http://arxiv.org/abs/2401.02287v1",
                    "http://arxiv.org/pdf/2401.02287v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02281v1/1.0",
                "title": "PEGASUS: Physically Enhanced Gaussian Splatting Simulation System for\n  6DOF Object Pose Dataset Generation",
                "year": 2024,
                "abstract": "We introduce Physically Enhanced Gaussian Splatting Simulation System\n(PEGASUS) for 6DOF object pose dataset generation, a versatile dataset\ngenerator based on 3D Gaussian Splatting. Environment and object\nrepresentations can be easily obtained using commodity cameras to reconstruct\nwith Gaussian Splatting. PEGASUS allows the composition of new scenes by\nmerging the respective underlying Gaussian Splatting point cloud of an\nenvironment with one or multiple objects. Leveraging a physics engine enables\nthe simulation of natural object placement within a scene through interaction\nbetween meshes extracted for the objects and the environment. Consequently, an\nextensive amount of new scenes - static or dynamic - can be created by\ncombining different environments and objects. By rendering scenes from various\nperspectives, diverse data points such as RGB images, depth maps, semantic\nmasks, and 6DoF object poses can be extracted. Our study demonstrates that\ntraining on data generated by PEGASUS enables pose estimation networks to\nsuccessfully transfer from synthetic data to real-world data. Moreover, we\nintroduce the Ramen dataset, comprising 30 Japanese cup noodle items. This\ndataset includes spherical scans that captures images from both object\nhemisphere and the Gaussian Splatting reconstruction, making them compatible\nwith PEGASUS.",
                "authors": [
                    "Lukas Meyer",
                    "Floris Erich",
                    "Yusuke Yoshiyasu",
                    "Marc Stamminger",
                    "Noriaki Ando",
                    "Yukiyasu Domae"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02281v1",
                    "http://arxiv.org/pdf/2401.02281v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02278v1/1.0",
                "title": "Lightweight Fish Classification Model for Sustainable Marine Management:\n  Indonesian Case",
                "year": 2024,
                "abstract": "The enormous demand for seafood products has led to exploitation of marine\nresources and near-extinction of some species. In particular, overfishing is\none the main issues in sustainable marine development. In alignment with the\nprotection of marine resources and sustainable fishing, this study proposes to\nadvance fish classification techniques that support identifying protected fish\nspecies using state-of-the-art machine learning. We use a custom modification\nof the MobileNet model to design a lightweight classifier called M-MobileNet\nthat is capable of running on limited hardware. As part of the study, we\ncompiled a labeled dataset of 37,462 images of fish found in the waters of the\nIndonesian archipelago. The proposed model is trained on the dataset to\nclassify images of the captured fish into their species and give\nrecommendations on whether they are consumable or not. Our modified MobileNet\nmodel uses only 50\\% of the top layer parameters with about 42% GTX 860M\nutility and achieves up to 97% accuracy in fish classification and determining\nits consumability. Given the limited computing capacity available on many\nfishing vessels, the proposed model provides a practical solution to on-site\nfish classification. In addition, synchronized implementation of the proposed\nmodel on multiple vessels can supply valuable information about the movement\nand location of different species of fish.",
                "authors": [
                    "Febrian Kurniawan",
                    "Gandeva Bayu Satrya",
                    "Firuz Kamalov"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02278v1",
                    "http://arxiv.org/pdf/2401.02278v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02277v1/1.0",
                "title": "Universal Approximation Theorem for Vector- and Hypercomplex-Valued\n  Neural Networks",
                "year": 2024,
                "abstract": "The universal approximation theorem states that a neural network with one\nhidden layer can approximate continuous functions on compact sets with any\ndesired precision. This theorem supports using neural networks for various\napplications, including regression and classification tasks. Furthermore, it is\nvalid for real-valued neural networks and some hypercomplex-valued neural\nnetworks such as complex-, quaternion-, tessarine-, and Clifford-valued neural\nnetworks. However, hypercomplex-valued neural networks are a type of\nvector-valued neural network defined on an algebra with additional algebraic or\ngeometric properties. This paper extends the universal approximation theorem\nfor a wide range of vector-valued neural networks, including\nhypercomplex-valued models as particular instances. Precisely, we introduce the\nconcept of non-degenerate algebra and state the universal approximation theorem\nfor neural networks defined on such algebras.",
                "authors": [
                    "Marcos Eduardo Valle",
                    "Wington L. Vital",
                    "Guilherme Vieira"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02277v1",
                    "http://arxiv.org/pdf/2401.02277v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NE"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02274v1/1.0",
                "title": "ShapeAug: Occlusion Augmentation for Event Camera Data",
                "year": 2024,
                "abstract": "Recently, Dynamic Vision Sensors (DVSs) sparked a lot of interest due to\ntheir inherent advantages over conventional RGB cameras. These advantages\ninclude a low latency, a high dynamic range and a low energy consumption.\nNevertheless, the processing of DVS data using Deep Learning (DL) methods\nremains a challenge, particularly since the availability of event training data\nis still limited. This leads to a need for event data augmentation techniques\nin order to improve accuracy as well as to avoid over-fitting on the training\ndata. Another challenge especially in real world automotive applications is\nocclusion, meaning one object is hindering the view onto the object behind it.\nIn this paper, we present a novel event data augmentation approach, which\naddresses this problem by introducing synthetic events for randomly moving\nobjects in a scene. We test our method on multiple DVS classification datasets,\nresulting in an relative improvement of up to 6.5 % in top1-accuracy. Moreover,\nwe apply our augmentation technique on the real world Gen1 Automotive Event\nDataset for object detection, where we especially improve the detection of\npedestrians by up to 5 %.",
                "authors": [
                    "Katharina Bendig",
                    "Ren\u00e9 Schuster",
                    "Didier Stricker"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02274v1",
                    "http://arxiv.org/pdf/2401.02274v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02271v1/1.0",
                "title": "Towards Seamless Serverless Computing Across an Edge-Cloud Continuum",
                "year": 2024,
                "abstract": "Serverless computing has emerged as an attractive paradigm due to the\nefficiency of development and the ease of deployment without managing any\nunderlying infrastructure. Nevertheless, serverless computing approaches face\nnumerous challenges to unlock their full potential in hybrid environments. To\ngain a deeper understanding and firsthand knowledge of serverless computing in\nedge-cloud deployments, we review the current state of open-source serverless\nplatforms and compare them based on predefined requirements. We then design and\nimplement a serverless computing platform with a novel edge orchestration\ntechnique that seamlessly deploys serverless functions across the edge and\ncloud environments on top of the Knative serverless platform. Moreover, we\npropose an offloading strategy for edge environments and four different\nfunctions for experimentation and showcase the performance benefits of our\nsolution. Our results demonstrate that such an approach can efficiently utilize\nboth cloud and edge resources by dynamically offloading functions from the edge\nto the cloud during high activity, while reducing the overall application\nlatency and increasing request throughput compared to an edge-only deployment.",
                "authors": [
                    "Emilian Simion",
                    "Yuandou Wang",
                    "Hsiang-ling Tai",
                    "Uraz Odyurt",
                    "Zhiming Zhao"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02271v1",
                    "http://arxiv.org/pdf/2401.02271v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02268v1/1.0",
                "title": "Beyond Self-Promotion: How Software Engineering Research Is Discussed on\n  LinkedIn",
                "year": 2024,
                "abstract": "LinkedIn is the largest professional network in the world. As such, it can\nserve to build bridges between practitioners, whose daily work is software\nengineering (SE), and researchers, who work to advance the field of software\nengineering. We know that such a metaphorical bridge exists: SE research\nfindings are sometimes shared on LinkedIn and commented on by software\npractitioners. Yet, we do not know what state the bridge is in. Therefore, we\nquantitatively and qualitatively investigate how SE practitioners and\nresearchers approach each other via public LinkedIn discussions and what both\nsides can contribute to effective science communication. We found that a\nconsiderable proportion of LinkedIn posts on SE research are written by people\nwho are not the paper authors (39%). Further, 71% of all comments in our\ndataset are from people in the industry, but only every second post receives at\nleast one comment at all. Based on our findings, we formulate concrete advice\nfor researchers and practitioners to make sharing new research findings on\nLinkedIn more fruitful.",
                "authors": [
                    "Marvin Wyrich",
                    "Justus Bogner"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02268v1",
                    "http://arxiv.org/pdf/2401.02268v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.CY"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02264v1/1.0",
                "title": "Globalizing and stabilizing global $\\infty$-categories",
                "year": 2024,
                "abstract": "We consider the question of cocompleting partially presentable parametrized\n$\\infty$-categories in the sense of arXiv:2307.11001. As our main result we\nshow that in certain cases one may compute such relative cocompletions via a\nvery explicit formula given in terms of partially lax limits. We then apply\nthis to equivariant homotopy theory, building on the work of op. cit. and\narXiv:2301.08240, to conclude that the global $\\infty$-category of globally\nequivariant spectra is the relative cocompletion of the global\n$\\infty$-category of equivariant spectra. Evaluating at a group $G$ we obtain a\ndescription of the $\\infty$-category of $G$-global spectra as a partially lax\nlimit, extending the main result of arXiv:2206.01556 for finite groups to\n$G$-global homotopy theory. Finally we investigate the question of stabilizing\nglobal $\\infty$-categories by inverting the action of representation spheres,\nand deduce a second universal property for the global $\\infty$-category of\nglobally equivariant spectra, similar to that of arXiv:2302.06207.",
                "authors": [
                    "Sil Linskens"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02264v1",
                    "http://arxiv.org/pdf/2401.02264v1"
                ],
                "primary_category": "math.AT",
                "categories": [
                    "math.AT",
                    "math.CT"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02262v1/1.0",
                "title": "The Effects of Generative AI on Computing Students' Help-Seeking\n  Preferences",
                "year": 2024,
                "abstract": "Help-seeking is a critical way for students to learn new concepts, acquire\nnew skills, and get unstuck when problem-solving in their computing courses.\nThe recent proliferation of generative AI tools, such as ChatGPT, offers\nstudents a new source of help that is always available on-demand. However, it\nis unclear how this new resource compares to existing help-seeking resources\nalong dimensions of perceived quality, latency, and trustworthiness. In this\npaper, we investigate the help-seeking preferences and experiences of computing\nstudents now that generative AI tools are available to them. We collected\nsurvey data (n=47) and conducted interviews (n=8) with computing students. Our\nresults suggest that although these models are being rapidly adopted, they have\nnot yet fully eclipsed traditional help resources. The help-seeking resources\nthat students rely on continue to vary depending on the task and other factors.\nFinally, we observed preliminary evidence about how help-seeking with\ngenerative AI is a skill that needs to be developed, with disproportionate\nbenefits for those who are better able to harness the capabilities of LLMs. We\ndiscuss potential implications for integrating generative AI into computing\nclassrooms and the future of help-seeking in the era of generative AI.",
                "authors": [
                    "Irene Hou",
                    "Sophia Metille",
                    "Zhuo Li",
                    "Owen Man",
                    "Cynthia Zastudil",
                    "Stephen MacNeil"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02262v1",
                    "http://arxiv.org/pdf/2401.02262v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02259v1/1.0",
                "title": "Nearest-Neighboring Pairing of Monolayer NbSe2 Facilitates the Emergence\n  of Topological Superconducting States",
                "year": 2024,
                "abstract": "NbSe2, which simultaneously exhibits superconductivity and spin-orbit\ncoupling, is anticipated to pave the way for topological superconductivity and\nunconventional electron pairing. In this paper, we systematically study\ntopological superconducting (TSC) phases in monolayer NbSe2 through mixing\non-site s-wave pairing (ps) with nearest-neighbor pairing (psA1) based on a\ntight-binding model. We observe rich phases with both fixed and sensitive Chern\nnumbers (CNs) depending on the chemical potential ({\\mu}) and out-of-plane\nmagnetic field (Vz). As the psA1 increases, the TSC phase manifests matching\nand mismatching features according to whether there is a bulk-boundary\ncorrespondence (BBC). Strikingly, the introduction of mixed wave pairing\nsignificantly reduces the critical Vz to form TSC phases compared with the pure\ns-wave paring. Moreover, the TSC phase can be modulated even at Vz=0 under\nappropriate {\\mu} and psA1, which is identified by the robust topological edge\nstates (TESs) of ribbons. Additionally, the mixed pairing influences the\nhybridization of bulk and edge states, resulting in a matching/mismatching BBC\nwith localized/oscillating TESs on the ribbon. Our finding is helpful for the\nrealization of TSC states in experiment, as well as designing and regulating\nTSC materials.",
                "authors": [
                    "Yizhi Li",
                    "Quan Gao",
                    "Yanru Li",
                    "Jianxin Zhong",
                    "Lijun Meng"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02259v1",
                    "http://arxiv.org/pdf/2401.02259v1"
                ],
                "primary_category": "cond-mat.supr-con",
                "categories": [
                    "cond-mat.supr-con",
                    "physics.comp-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02258v1/1.0",
                "title": "Uncertainty-Aware Deep Attention Recurrent Neural Network for\n  Heterogeneous Time Series Imputation",
                "year": 2024,
                "abstract": "Missingness is ubiquitous in multivariate time series and poses an obstacle\nto reliable downstream analysis. Although recurrent network imputation achieved\nthe SOTA, existing models do not scale to deep architectures that can\npotentially alleviate issues arising in complex data. Moreover, imputation\ncarries the risk of biased estimations of the ground truth. Yet, confidence in\nthe imputed values is always unmeasured or computed post hoc from model output.\nWe propose DEep Attention Recurrent Imputation (DEARI), which jointly estimates\nmissing values and their associated uncertainty in heterogeneous multivariate\ntime series. By jointly representing feature-wise correlations and temporal\ndynamics, we adopt a self attention mechanism, along with an effective residual\ncomponent, to achieve a deep recurrent neural network with good imputation\nperformance and stable convergence. We also leverage self-supervised metric\nlearning to boost performance by optimizing sample similarity. Finally, we\ntransform DEARI into a Bayesian neural network through a novel Bayesian\nmarginalization strategy to produce stochastic DEARI, which outperforms its\ndeterministic equivalent. Experiments show that DEARI surpasses the SOTA in\ndiverse imputation tasks using real-world datasets, namely air quality control,\nhealthcare and traffic.",
                "authors": [
                    "Linglong Qian",
                    "Zina Ibrahim",
                    "Richard Dobson"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02258v1",
                    "http://arxiv.org/pdf/2401.02258v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02256v1/1.0",
                "title": "Rethinking Response Evaluation from Interlocutor's Eye for Open-Domain\n  Dialogue Systems",
                "year": 2024,
                "abstract": "Open-domain dialogue systems have started to engage in continuous\nconversations with humans. Those dialogue systems are required to be adjusted\nto the human interlocutor and evaluated in terms of their perspective. However,\nit is questionable whether the current automatic evaluation methods can\napproximate the interlocutor's judgments. In this study, we analyzed and\nexamined what features are needed in an automatic response evaluator from the\ninterlocutor's perspective. The first experiment on the Hazumi dataset revealed\nthat interlocutor awareness plays a critical role in making automatic response\nevaluation correlate with the interlocutor's judgments. The second experiment\nusing massive conversations on X (formerly Twitter) confirmed that dialogue\ncontinuity prediction can train an interlocutor-aware response evaluator\nwithout human feedback while revealing the difficulty in evaluating generated\nresponses compared to human responses.",
                "authors": [
                    "Yuma Tsuta",
                    "Naoki Yoshinaga",
                    "Shoetsu Sato",
                    "Masashi Toyoda"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02256v1",
                    "http://arxiv.org/pdf/2401.02256v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02254v1/1.0",
                "title": "L3Cube-IndicNews: News-based Short Text and Long Document Classification\n  Datasets in Indic Languages",
                "year": 2024,
                "abstract": "In this work, we introduce L3Cube-IndicNews, a multilingual text\nclassification corpus aimed at curating a high-quality dataset for Indian\nregional languages, with a specific focus on news headlines and articles. We\nhave centered our work on 10 prominent Indic languages, including Hindi,\nBengali, Marathi, Telugu, Tamil, Gujarati, Kannada, Odia, Malayalam, and\nPunjabi. Each of these news datasets comprises 10 or more classes of news\narticles. L3Cube-IndicNews offers 3 distinct datasets tailored to handle\ndifferent document lengths that are classified as: Short Headlines\nClassification (SHC) dataset containing the news headline and news category,\nLong Document Classification (LDC) dataset containing the whole news article\nand the news category, and Long Paragraph Classification (LPC) containing\nsub-articles of the news and the news category. We maintain consistent labeling\nacross all 3 datasets for in-depth length-based analysis. We evaluate each of\nthese Indic language datasets using 4 different models including monolingual\nBERT, multilingual Indic Sentence BERT (IndicSBERT), and IndicBERT. This\nresearch contributes significantly to expanding the pool of available text\nclassification datasets and also makes it possible to develop topic\nclassification models for Indian regional languages. This also serves as an\nexcellent resource for cross-lingual analysis owing to the high overlap of\nlabels among languages. The datasets and models are shared publicly at\nhttps://github.com/l3cube-pune/indic-nlp",
                "authors": [
                    "Aishwarya Mirashi",
                    "Srushti Sonavane",
                    "Purva Lingayat",
                    "Tejas Padhiyar",
                    "Raviraj Joshi"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02254v1",
                    "http://arxiv.org/pdf/2401.02254v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02244v1/1.0",
                "title": "Policy-regularized Offline Multi-objective Reinforcement Learning",
                "year": 2024,
                "abstract": "In this paper, we aim to utilize only offline trajectory data to train a\npolicy for multi-objective RL. We extend the offline policy-regularized method,\na widely-adopted approach for single-objective offline RL problems, into the\nmulti-objective setting in order to achieve the above goal. However, such\nmethods face a new challenge in offline MORL settings, namely the\npreference-inconsistent demonstration problem. We propose two solutions to this\nproblem: 1) filtering out preference-inconsistent demonstrations via\napproximating behavior preferences, and 2) adopting regularization techniques\nwith high policy expressiveness. Moreover, we integrate the\npreference-conditioned scalarized update method into policy-regularized offline\nRL, in order to simultaneously learn a set of policies using a single policy\nnetwork, thus reducing the computational cost induced by the training of a\nlarge number of individual policies for various preferences. Finally, we\nintroduce Regularization Weight Adaptation to dynamically determine appropriate\nregularization weights for arbitrary target preferences during deployment.\nEmpirical results on various multi-objective datasets demonstrate the\ncapability of our approach in solving offline MORL problems.",
                "authors": [
                    "Qian Lin",
                    "Chao Yu",
                    "Zongkai Liu",
                    "Zifan Wu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02244v1",
                    "http://arxiv.org/pdf/2401.02244v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02241v1/1.0",
                "title": "Slot-guided Volumetric Object Radiance Fields",
                "year": 2024,
                "abstract": "We present a novel framework for 3D object-centric representation learning.\nOur approach effectively decomposes complex scenes into individual objects from\na single image in an unsupervised fashion. This method, called slot-guided\nVolumetric Object Radiance Fields (sVORF), composes volumetric object radiance\nfields with object slots as a guidance to implement unsupervised 3D scene\ndecomposition. Specifically, sVORF obtains object slots from a single image via\na transformer module, maps these slots to volumetric object radiance fields\nwith a hypernetwork and composes object radiance fields with the guidance of\nobject slots at a 3D location. Moreover, sVORF significantly reduces memory\nrequirement due to small-sized pixel rendering during training. We demonstrate\nthe effectiveness of our approach by showing top results in scene decomposition\nand generation tasks of complex synthetic datasets (e.g., Room-Diverse).\nFurthermore, we also confirm the potential of sVORF to segment objects in\nreal-world scenes (e.g., the LLFF dataset). We hope our approach can provide\npreliminary understanding of the physical world and help ease future research\nin 3D object-centric representation learning.",
                "authors": [
                    "Di Qi",
                    "Tong Yang",
                    "Xiangyu Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02241v1",
                    "http://arxiv.org/pdf/2401.02241v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02239v1/1.0",
                "title": "A Decision Method for Elementary Stream Calculus",
                "year": 2024,
                "abstract": "The main result is a doubly exponential decision procedure for the\nfirst-order equality theory of streams with both arithmetic and\ncontrol-oriented stream operations. This stream logic is expressive for\nelementary problems of stream calculus.",
                "authors": [
                    "Harald Ruess"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02239v1",
                    "http://arxiv.org/pdf/2401.02239v1"
                ],
                "primary_category": "cs.LO",
                "categories": [
                    "cs.LO",
                    "I.1, J.6, F.4"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02235v1/1.0",
                "title": "Reconstruction of curves from their theta hyperplanes in genera $6$ and\n  $7$",
                "year": 2024,
                "abstract": "We derive a formula for reconstructing a generic complex canonical curve $C$\nof genus 6 and 7 in terms of the theta hyperplanes of $C$. Hence, we get a\ngeneric inverse to the Torelli map, as well as a complete description of the\nSchottky locus in these genera. The computational part of the proof relies on a\ncertified numerical argument.",
                "authors": [
                    "T\u00fcrk\u00fc \u00d6zl\u00fcm \u00c7elik",
                    "David Lehavi"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02235v1",
                    "http://arxiv.org/pdf/2401.02235v1"
                ],
                "primary_category": "math.AG",
                "categories": [
                    "math.AG",
                    "Primary: 14H40, 14H42, 65G40, Secondary: 14H45, 14Q05, 14Q04"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02234v1/1.0",
                "title": "One-step implementation of nonadiabatic holonomic fSim gate in\n  superconducting circuits",
                "year": 2024,
                "abstract": "Due to its significant application in reducing algorithm depth, fSim gates\nhave attracted a lot of attention, while one-step implementation of fSim gates\nremains an unresolved issue. In this manuscript, we propose a one-step\nimplementation of holonomic fSim gates in a tunable superconducting circuit\nbased on the three lowest energy levels. Numerical simulations demonstrate the\nfeasibility of our scheme. This scheme may provide a promising path toward\nquantum computation and simulation.",
                "authors": [
                    "M. -R. Yun",
                    "Zheng Shan",
                    "L. -L. Yan",
                    "Yu Jia S. -L. Su",
                    "G. Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02234v1",
                    "http://arxiv.org/pdf/2401.02234v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02231v1/1.0",
                "title": "On the computation of coarse cohomology",
                "year": 2024,
                "abstract": "The purpose of this article is to relate coarse cohomology of metric spaces\nwith a more computable cohomology. We introduce a notion of boundedly supported\ncohomology and prove that coarse cohomology of many spaces are isomorphic to\nthe boundedly supported cohomology. Boundedly supported cohomology coincides\nwith compactly supported Alexander--Spanier cohomology if the space is proper\nand contractible. Our work generalizes an earlier result of Roe which says that\nthe coarse cohomology is isomorphic to the compactly supported\nAlexander-Spanier cohomology if the space is uniformly contractible. As an\napplication of our main theorem, we obtain that coarse cohomology of the\ncomplement can be computed in terms of Alexander-Spanier cohomology for many\nspaces.",
                "authors": [
                    "Arka Banerjee"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02231v1",
                    "http://arxiv.org/pdf/2401.02231v1"
                ],
                "primary_category": "math.MG",
                "categories": [
                    "math.MG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02223v1/1.0",
                "title": "A BDI Agent-Based Task Scheduling Framework for Cloud Computing",
                "year": 2024,
                "abstract": "Cloud computing is an attractive technology for providing computing resources\nover the Internet. Task scheduling is a critical issue in cloud computing,\nwhere an efficient task scheduling method can improve overall cloud\nperformance. Since cloud computing is a large-scale and geographically\ndistributed environment, traditional scheduling methods that allocate resources\nin a centralized manner are ineffective. Besides, traditional methods are\ndifficult to make rational decisions timely when the external environment\nchanges. This paper proposes a decentralized BDI (belief-desire-intention)\nagent-based scheduling framework for cloud computing. BDI agents have\nadvantages in modelling dynamic environments because BDI agents can update\ntheir beliefs, change desires, and trigger behaviours based on environmental\nchanges. Besides, to avoid communication stuck caused by environmental\nuncertainties, the asynchronous communication mode with a notify listener is\nemployed. The proposed framework covers both the task scheduling and\nrescheduling stages with the consideration of uncertain events that can\ninterrupt task executions. Two agent-based algorithms are proposed to implement\nthe task scheduling and rescheduling processes, and a novel recommendation\nmechanism is presented in the scheduling stage to reduce the impact of\ninformation synchronization delays. The proposed framework is implemented by\nJADEX and tested on CloudSim. The experimental results show that our framework\ncan minimize the task makespan, balance the resource utilization in a\nlarge-scale environment, and maximize the task success rate when uncertain\nevents occur.",
                "authors": [
                    "Yikun Yang",
                    "Fenghui Ren",
                    "Minjie Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02223v1",
                    "http://arxiv.org/pdf/2401.02223v1"
                ],
                "primary_category": "cs.MA",
                "categories": [
                    "cs.MA"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02219v1/1.0",
                "title": "A Decentralized Multiagent-Based Task Scheduling Framework for Handling\n  Uncertain Events in Fog Computing",
                "year": 2024,
                "abstract": "Fog computing has become an attractive research topic in recent years. As an\nextension of the cloud, fog computing provides computing resources for Internet\nof Things (IoT) applications through communicative fog nodes located at the\nnetwork edge. Fog nodes assist cloud services in handling real-time and mobile\napplications by bringing the processing capability to where the data is\ngenerated. However, the introduction of fog nodes can increase scheduling\nopenness and uncertainty. The scheduling issues in fog computing need to\nconsider the geography, load balancing, and network latency between IoT\ndevices, fog nodes, as well as the parent cloud. Besides, the scheduling\nmethods also need to deal with the occurrence of uncertain events in real-time\nso as to ensure service reliability. This paper proposes an agent-based\nframework with a decentralized structure to construct the architecture of fog\ncomputing, while three agent-based algorithms are proposed to implement the\nscheduling, load balance, and rescheduling processes. The proposed framework is\nimplemented by JADE and evaluated on the iFogSim toolkit. Experimental results\nshow that the proposed scheduling framework can adaptively schedule tasks and\nresources for different service requests in fog computing and can also improve\nthe task success rate when uncertain events occur.",
                "authors": [
                    "Yikun Yang",
                    "Fenghui Ren",
                    "Minjie Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02219v1",
                    "http://arxiv.org/pdf/2401.02219v1"
                ],
                "primary_category": "cs.MA",
                "categories": [
                    "cs.MA"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02218v1/1.0",
                "title": "Optimizing Information Freshness in Uplink Multiuser MIMO Networks with\n  Partial Observations",
                "year": 2024,
                "abstract": "This paper investigates a multiuser scheduling problem within an uplink\nmultiple-input multi-output (MIMO) status update network, consisting of a\nmulti-antenna base station (BS) and multiple single-antenna devices. The\npresence of multiple antennas at the BS introduces spatial degrees-of-freedom,\nenabling concurrent transmission of status updates from multiple devices in\neach time slot. Our objective is to optimize network-wide information\nfreshness, quantified by the age of information (AoI) metric, by determining\nhow the BS can best schedule device transmissions, while taking into account\nthe random arrival of status updates at the device side.To address this\ndecision-making problem, we model it as a partially observable Markov decision\nprocess (POMDP) and establish that the evolution of belief states for different\ndevices is independent.We also prove that feasible belief states can be\ndescribed by finite-dimensional vectors. Building on these observations, we\ndevelop a dynamic scheduling (DS) policy to solve the POMDP, and then derive an\nupper bound of its AoI performance, which is used to optimize the parameter\nconfiguration. To gain more design insights, we investigate a symmetric\nnetwork, and put forth a fixed scheduling (FS) policy with lower computational\ncomplexity. An action space reduction strategy is applied to further reduce the\ncomputational complexity of both DS and FS policies. Our numerical results\nvalidate our analyses and indicate that the DS policy with the reduced action\nspace performs almost identically to the original DS policy, and both\noutperform the baseline policies.",
                "authors": [
                    "Jingwei Liu",
                    "Qian Wang",
                    "He Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02218v1",
                    "http://arxiv.org/pdf/2401.02218v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "cs.NI",
                    "math.IT"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02212v1/1.0",
                "title": "Joint Multi-Facts Reasoning Network For Complex Temporal Question\n  Answering Over Knowledge Graph",
                "year": 2024,
                "abstract": "Temporal Knowledge Graph (TKG) is an extension of regular knowledge graph by\nattaching the time scope. Existing temporal knowledge graph question answering\n(TKGQA) models solely approach simple questions, owing to the prior assumption\nthat each question only contains a single temporal fact with explicit/implicit\ntemporal constraints. Hence, they perform poorly on questions which own\nmultiple temporal facts. In this paper, we propose \\textbf{\\underline{J}}oint\n\\textbf{\\underline{M}}ulti \\textbf{\\underline{F}}acts\n\\textbf{\\underline{R}}easoning \\textbf{\\underline{N}}etwork (JMFRN), to jointly\nreasoning multiple temporal facts for accurately answering \\emph{complex}\ntemporal questions. Specifically, JMFRN first retrieves question-related\ntemporal facts from TKG for each entity of the given complex question. For\njoint reasoning, we design two different attention (\\ie entity-aware and\ntime-aware) modules, which are suitable for universal settings, to aggregate\nentities and timestamps information of retrieved facts. Moreover, to filter\nincorrect type answers, we introduce an additional answer type discrimination\ntask. Extensive experiments demonstrate our proposed method significantly\noutperforms the state-of-art on the well-known complex temporal question\nbenchmark TimeQuestions.",
                "authors": [
                    "Rikui Huang",
                    "Wei Wei",
                    "Xiaoye Qu",
                    "Wenfeng Xie",
                    "Xianling Mao",
                    "Dangyang Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02212v1",
                    "http://arxiv.org/pdf/2401.02212v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02208v1/1.0",
                "title": "DIALIGHT: Lightweight Multilingual Development and Evaluation of\n  Task-Oriented Dialogue Systems with Large Language Models",
                "year": 2024,
                "abstract": "We present DIALIGHT, a toolkit for developing and evaluating multilingual\nTask-Oriented Dialogue (ToD) systems which facilitates systematic evaluations\nand comparisons between ToD systems using fine-tuning of Pretrained Language\nModels (PLMs) and those utilising the zero-shot and in-context learning\ncapabilities of Large Language Models (LLMs). In addition to automatic\nevaluation, this toolkit features (i) a secure, user-friendly web interface for\nfine-grained human evaluation at both local utterance level and global dialogue\nlevel, and (ii) a microservice-based backend, improving efficiency and\nscalability. Our evaluations reveal that while PLM fine-tuning leads to higher\naccuracy and coherence, LLM-based systems excel in producing diverse and\nlikeable responses. However, we also identify significant challenges of LLMs in\nadherence to task-specific instructions and generating outputs in multiple\nlanguages, highlighting areas for future research. We hope this open-sourced\ntoolkit will serve as a valuable resource for researchers aiming to develop and\nproperly evaluate multilingual ToD systems and will lower, currently still\nhigh, entry barriers in the field.",
                "authors": [
                    "Songbo Hu",
                    "Xiaobin Wang",
                    "Zhangdie Yuan",
                    "Anna Korhonen",
                    "Ivan Vuli\u0107"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02208v1",
                    "http://arxiv.org/pdf/2401.02208v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02207v1/1.0",
                "title": "A noise-limiting quantum algorithm using mid-circuit measurements for\n  dynamical correlations at infinite temperature",
                "year": 2024,
                "abstract": "It is generally considered that the signal output by a quantum circuit is\nattenuated exponentially fast in the number of gates. This letter explores how\nalgorithms using mid-circuit measurements and classical conditioning as\ncomputational tools (and not as error mitigation or correction subroutines) can\nbe naturally resilient to complete decoherence, and maintain quantum states\nwith useful properties even for infinitely deep noisy circuits. Specifically,\nwe introduce a quantum channel built out of mid-circuit measurements and\nfeed-forward, that can be used to compute dynamical correlations at infinite\ntemperature and canonical ensemble expectation values for any Hamiltonian. The\nunusual property of this algorithm is that in the presence of a depolarizing\nchannel it still displays a meaningful, non-zero signal in the large depth\nlimit. We showcase the noise resilience of this quantum channel on Quantinuum's\nH1-1 ion-trap quantum computer.",
                "authors": [
                    "Etienne Granet",
                    "Henrik Dreyer"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02207v1",
                    "http://arxiv.org/pdf/2401.02207v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02205v1/1.0",
                "title": "Dust growth and pebble formation in the initial stages of protoplanetary\n  disk evolution",
                "year": 2024,
                "abstract": "Aims. The initial stages of planet formation may start concurrently with the\nformation of a gas-dust protoplanetary disk. This makes the study of the\nearliest stages of protoplanetary disk formation crucially important. Here we\nfocus on dust growth and pebble formation in a protoplanetary disk that is\nstill accreting from a parental cloud core. Methods. We have developed an\noriginal three-dimensional numerical hydrodynamics code, which computes the\ncollapse of rotating clouds and disk formation on nested meshes using a novel\nhybrid Coarray Fortran-OpenMP approach for distributed and shared memory\nparallelization. Dust dynamics and growth are also included in the simulations.\nResults. We found that the dust growth from $\\sim 1~\\mu$m to 1-10~mm already\noccurs in the initial few thousand years of disk evolution but the Stokes\nnumber hardly exceeds 0.1 because of higher disk densities and temperatures\ncompared to the minimum mass Solar nebular. The ratio of the dust-to-gas\nvertical scale heights remains rather modest, 0.2--0.5, which may be explained\nby the perturbing action of spiral arms that develop in the disk soon after its\nformation. The dust-to-gas mass ratio in the disk midplane is highly\nnonhomogeneous throughout the disk extent and is in general enhanced by a\nfactor of several compared to the fiducial 1:100 value. Low St hinders strong\ndust accumulation in the spiral arms compared to the rest of the disk and the\nnonsteady nature of the spirals is also an obstacle. The spatial distribution\nof pebbles in the disk midplane exhibits a highly nonhomogeneous and patchy\ncharacter. The total mass of pebbles in the disk increases with time and\nreaches a few tens of Earth masses after a few tens of thousand years of disk\nevolution. Abridged.",
                "authors": [
                    "Eduard Vorobyov",
                    "Igor Kulikov",
                    "Vardan Elbakyan",
                    "James McKevitt",
                    "Manuel Guedel"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02205v1",
                    "http://arxiv.org/pdf/2401.02205v1"
                ],
                "primary_category": "astro-ph.EP",
                "categories": [
                    "astro-ph.EP",
                    "astro-ph.SR"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02200v1/1.0",
                "title": "Compositing with 2D Vector Fields by using Shape Maps that can represent\n  Inconsistent, Impossible, and Incoherent Shapes",
                "year": 2024,
                "abstract": "In this paper, we present a new compositing approach to obtain stylized\nreflections and refractions with a simple control. Our approach does not\nrequire any mask or separate 3D rendering. Moreover, only one additional image\nis sufficient to obtain a composited image with convincing qualitative\nreflection and refraction effects. We have also developed linearized methods\nthat are easy to compute. Although these methods do not directly correspond to\nthe underlying physical phenomena of reflection and refraction, they can\nprovide results that are visually similar to realistic 3D rendering. The main\nadvantage of this approach is the ability to treat images as ``mock-3D'' shapes\nthat can be inserted into any digital paint system without any significant\nstructural change. The core of our approach is the shape map, which encodes 2D\nshape and thickness information for all visible points of an image of a shape.\nThis information does not have to be complete or consistent to obtain\ninteresting composites. In particular, the shape maps allow us to represent\nimpossible and incoherent shapes with 2D non-conservative vector fields.",
                "authors": [
                    "Ergun Akleman",
                    "Youyou Wang",
                    "Ozgur Gonen"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02200v1",
                    "http://arxiv.org/pdf/2401.02200v1"
                ],
                "primary_category": "cs.GR",
                "categories": [
                    "cs.GR"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02194v1/1.0",
                "title": "Inherently robust suboptimal MPC for autonomous racing with anytime\n  feasible SQP",
                "year": 2024,
                "abstract": "In recent years, the increasing need for high-performance controllers in\napplications like autonomous driving has motivated the development of\noptimization routines tailored to specific control problems. In this paper, we\npropose an efficient inexact model predictive control (MPC) strategy for\nautonomous miniature racing with inherent robustness properties. We rely on a\nfeasible sequential quadratic programming (SQP) algorithm capable of generating\nfeasible intermediate iterates such that the solver can be stopped after any\nnumber of iterations, without jeopardizing recursive feasibility. In this way,\nwe provide a strategy that computes suboptimal and yet feasible solutions with\na computational footprint that is much lower than state-of-the-art methods\nbased on the computation of locally optimal solutions. Under suitable\nassumptions on the terminal set and on the controllability properties of the\nsystem, we can state that, for any sufficiently small disturbance affecting the\nsystem's dynamics, recursive feasibility can be guaranteed. We validate the\neffectiveness of the proposed strategy in simulation and by deploying it onto a\nphysical experiment with autonomous miniature race cars. Both the simulation\nand experimental results demonstrate that, using the feasible SQP method, a\nfeasible solution can be obtained with moderate additional computational effort\ncompared to strategies that resort to early termination without providing a\nfeasible solution. At the same time, the proposed method is significantly\nfaster than the state-of-the-art solver Ipopt.",
                "authors": [
                    "Logan Numerow",
                    "Andrea Zanelli",
                    "Andrea Carron",
                    "Melanie N. Zeilinger"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02194v1",
                    "http://arxiv.org/pdf/2401.02194v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC",
                    "cs.RO"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02192v1/1.0",
                "title": "Nodule detection and generation on chest X-rays: NODE21 Challenge",
                "year": 2024,
                "abstract": "Pulmonary nodules may be an early manifestation of lung cancer, the leading\ncause of cancer-related deaths among both men and women. Numerous studies have\nestablished that deep learning methods can yield high-performance levels in the\ndetection of lung nodules in chest X-rays. However, the lack of gold-standard\npublic datasets slows down the progression of the research and prevents\nbenchmarking of methods for this task. To address this, we organized a public\nresearch challenge, NODE21, aimed at the detection and generation of lung\nnodules in chest X-rays. While the detection track assesses state-of-the-art\nnodule detection systems, the generation track determines the utility of nodule\ngeneration algorithms to augment training data and hence improve the\nperformance of the detection systems. This paper summarizes the results of the\nNODE21 challenge and performs extensive additional experiments to examine the\nimpact of the synthetically generated nodule training images on the detection\nalgorithm performance.",
                "authors": [
                    "Ecem Sogancioglu",
                    "Bram van Ginneken",
                    "Finn Behrendt",
                    "Marcel Bengs",
                    "Alexander Schlaefer",
                    "Miron Radu",
                    "Di Xu",
                    "Ke Sheng",
                    "Fabien Scalzo",
                    "Eric Marcus",
                    "Samuele Papa",
                    "Jonas Teuwen",
                    "Ernst Th. Scholten",
                    "Steven Schalekamp",
                    "Nils Hendrix",
                    "Colin Jacobs",
                    "Ward Hendrix",
                    "Clara I S\u00e1nchez",
                    "Keelin Murphy"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02192v1",
                    "http://arxiv.org/pdf/2401.02192v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02191v1/1.0",
                "title": "Characterizing Fake News Targeting Corporations",
                "year": 2024,
                "abstract": "Misinformation proliferates in the online sphere, with evident impacts on the\npolitical and social realms, influencing democratic discourse and posing risks\nto public health and safety. The corporate world is also a prime target for\nfake news dissemination. While recent studies have attempted to characterize\ncorporate misinformation and its effects on companies, their findings often\nsuffer from limitations due to qualitative or narrative approaches and a narrow\nfocus on specific industries. To address this gap, we conducted an analysis\nutilizing social media quantitative methods and crowd-sourcing studies to\ninvestigate corporate misinformation across a diverse array of industries\nwithin the S\\&P 500 companies. Our study reveals that corporate misinformation\nencompasses topics such as products, politics, and societal issues. We\ndiscovered companies affected by fake news also get reputable news coverage but\nless social media attention, leading to heightened negativity in social media\ncomments, diminished stock growth, and increased stress mentions among employee\nreviews. Additionally, we observe that a company is not targeted by fake news\nall the time, but there are particular times when a critical mass of fake news\nemerges. These findings hold significant implications for regulators, business\nleaders, and investors, emphasizing the necessity to vigilantly monitor the\nescalating phenomenon of corporate misinformation.",
                "authors": [
                    "Ke Zhou",
                    "Sanja Scepanovic",
                    "Daniele Quercia"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02191v1",
                    "http://arxiv.org/pdf/2401.02191v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02188v1/1.0",
                "title": "A quantum chemistry approach to linear vibro-polaritonic IR spectra with\n  perturbative electron-photon correlation",
                "year": 2024,
                "abstract": "In the vibrational strong coupling (VSC) regime, molecular vibrations and\nresonant low-frequency cavity modes form light-matter hybrid states, named\nvibrational polaritons, with characteristic IR spectroscopic signatures. Here,\nwe introduce a quantum chemistry based computational scheme for linear IR\nspectra of vibrational polaritons in polyatomic molecules, which perturbatively\naccounts for nonresonant electron-photon interactions under VSC. Specifically,\nwe formulate a cavity Born- Oppenheimer perturbation theory (CBO-PT) linear\nresponse approach, which provides an approximate but systematic description of\nsuch electron-photon correlation effects in VSC scenarios, while relying on\nmolecular ab initio quantum chemistry methods. We identify relevant\nelectron-photon correlation effects at second-order of CBO-PT, which manifest\nas static polarizability-dependent Hessian corrections and an emerging\npolarizability-dependent cavity intensity component providing access to\ntransmission spectra commonly measured in vibro-polaritonic chemistry.\nIllustratively, we address electron-photon correlation effects perturbatively\nin IR spectra of CO$_2$ and Fe(CO)$_5$ vibropolaritonic models qualitatively in\nsound agreement with non-perturbative CBO linear response theory.",
                "authors": [
                    "Eric W. Fischer",
                    "Jan A. Syska",
                    "Peter Saalfrank"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02188v1",
                    "http://arxiv.org/pdf/2401.02188v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02187v1/1.0",
                "title": "Location Aware Modular Biencoder for Tourism Question Answering",
                "year": 2024,
                "abstract": "Answering real-world tourism questions that seek Point-of-Interest (POI)\nrecommendations is challenging, as it requires both spatial and non-spatial\nreasoning, over a large candidate pool. The traditional method of encoding each\npair of question and POI becomes inefficient when the number of candidates\nincreases, making it infeasible for real-world applications. To overcome this,\nwe propose treating the QA task as a dense vector retrieval problem, where we\nencode questions and POIs separately and retrieve the most relevant POIs for a\nquestion by utilizing embedding space similarity. We use pretrained language\nmodels (PLMs) to encode textual information, and train a location encoder to\ncapture spatial information of POIs. Experiments on a real-world tourism QA\ndataset demonstrate that our approach is effective, efficient, and outperforms\nprevious methods across all metrics. Enabled by the dense retrieval\narchitecture, we further build a global evaluation baseline, expanding the\nsearch space by 20 times compared to previous work. We also explore several\nfactors that impact on the model's performance through follow-up experiments.\nOur code and model are publicly available at https://github.com/haonan-li/LAMB.",
                "authors": [
                    "Haonan Li",
                    "Martin Tomko",
                    "Timothy Baldwin"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02187v1",
                    "http://arxiv.org/pdf/2401.02187v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02183v1/1.0",
                "title": "FairGridSearch: A Framework to Compare Fairness-Enhancing Models",
                "year": 2024,
                "abstract": "Machine learning models are increasingly used in critical decision-making\napplications. However, these models are susceptible to replicating or even\namplifying bias present in real-world data. While there are various bias\nmitigation methods and base estimators in the literature, selecting the optimal\nmodel for a specific application remains challenging.\n  This paper focuses on binary classification and proposes FairGridSearch, a\nnovel framework for comparing fairness-enhancing models. FairGridSearch enables\nexperimentation with different model parameter combinations and recommends the\nbest one. The study applies FairGridSearch to three popular datasets (Adult,\nCOMPAS, and German Credit) and analyzes the impacts of metric selection, base\nestimator choice, and classification threshold on model fairness.\n  The results highlight the significance of selecting appropriate accuracy and\nfairness metrics for model evaluation. Additionally, different base estimators\nand classification threshold values affect the effectiveness of bias mitigation\nmethods and fairness stability respectively, but the effects are not consistent\nacross all datasets. Based on these findings, future research on fairness in\nmachine learning should consider a broader range of factors when building fair\nmodels, going beyond bias mitigation methods alone.",
                "authors": [
                    "Shih-Chi Ma",
                    "Tatiana Ermakova",
                    "Benjamin Fabian"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/WI-IAT59888.2023.00064",
                    "http://arxiv.org/abs/2401.02183v1",
                    "http://arxiv.org/pdf/2401.02183v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CY"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02180v1/1.0",
                "title": "Proven Distributed Memory Parallelization of Particle Methods",
                "year": 2024,
                "abstract": "We provide a mathematically proven parallelization scheme for particle\nmethods on distributed-memory computer systems. Particle methods are a\nversatile and widely used class of algorithms for computer simulations and\nnumerical predictions in various applications, ranging from continuum fluid\ndynamics and granular flows, using methods such as Smoothed Particle\nHydrodynamics (SPH) and Discrete Element Methods (DEM) to Molecular Dynamics\n(MD) simulations in molecular modeling. Particle methods naturally lend\nthemselves to implementation on parallel-computing hardware. So far, however, a\nmathematical proof of correctness and equivalence to sequential implementations\nwas only available for shared-memory parallelism. Here, we leverage a formal\ndefinition of the algorithmic class of particle methods to provide a proven\nparallelization scheme for distributed-memory computers. We prove that these\nparallelized particle methods on distributed memory computers are formally\nequivalent to their sequential counterpart for a well-defined class of particle\nmethods. Notably, the here analyzed parallelization scheme is well-known and\ncommonly used. Our analysis is, therefore, of immediate practical relevance to\nexisting and new parallel software implementations of particle methods and\nplaces them on solid theoretical grounds.",
                "authors": [
                    "Johannes Pahlke",
                    "Ivo F. Sbalzarini"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02180v1",
                    "http://arxiv.org/pdf/2401.02180v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC",
                    "cs.DS",
                    "cs.SE"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02173v1/1.0",
                "title": "Prompt Decoupling for Text-to-Image Person Re-identification",
                "year": 2024,
                "abstract": "Text-to-image person re-identification (TIReID) aims to retrieve the target\nperson from an image gallery via a textual description query. Recently,\npre-trained vision-language models like CLIP have attracted significant\nattention and have been widely utilized for this task due to their robust\ncapacity for semantic concept learning and rich multi-modal knowledge. However,\nrecent CLIP-based TIReID methods commonly rely on direct fine-tuning of the\nentire network to adapt the CLIP model for the TIReID task. Although these\nmethods show competitive performance on this topic, they are suboptimal as they\nnecessitate simultaneous domain adaptation and task adaptation. To address this\nissue, we attempt to decouple these two processes during the training stage.\nSpecifically, we introduce the prompt tuning strategy to enable domain\nadaptation and propose a two-stage training approach to disentangle domain\nadaptation from task adaptation. In the first stage, we freeze the two encoders\nfrom CLIP and solely focus on optimizing the prompts to alleviate domain gap\nbetween the original training data of CLIP and downstream tasks. In the second\nstage, we maintain the fixed prompts and fine-tune the CLIP model to prioritize\ncapturing fine-grained information, which is more suitable for TIReID task.\nFinally, we evaluate the effectiveness of our method on three widely used\ndatasets. Compared to the directly fine-tuned approach, our method achieves\nsignificant improvements.",
                "authors": [
                    "Weihao Li",
                    "Lei Tan",
                    "Pingyang Dai",
                    "Yan Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02173v1",
                    "http://arxiv.org/pdf/2401.02173v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02172v1/1.0",
                "title": "Recognition of Unit Segment and Polyline Graphs is\n  $\\exists\\mathbb{R}$-Complete",
                "year": 2024,
                "abstract": "Given a set of objects O in the plane, the corresponding intersection graph\nis defined as follows. A vertex is created for each object and an edge joins\ntwo vertices whenever the corresponding objects intersect. We study here the\ncase of unit segments and polylines with exactly k bends. In the recognition\nproblem, we are given a graph and want to decide whether the graph can be\nrepresented as the intersection graph of certain geometric objects. In previous\nwork it was shown that various recognition problems are\n$\\exists\\mathbb{R}$-complete, leaving unit segments and polylines as few\nremaining natural cases. We show that recognition for both families of objects\nis $\\exists\\mathbb{R}$-complete.",
                "authors": [
                    "Michael Hoffmann",
                    "Tillmann Miltzow",
                    "Simon Weber",
                    "Lasse Wulf"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02172v1",
                    "http://arxiv.org/pdf/2401.02172v1"
                ],
                "primary_category": "cs.CG",
                "categories": [
                    "cs.CG"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02165v1/1.0",
                "title": "Optimization of ionic configurations in battery materials by quantum\n  annealing",
                "year": 2024,
                "abstract": "Energy materials with disorder in site occupation are challenging for\ncomputational studies due to an exponential scaling of the configuration space.\nWe herein present a grand-canonical optimization method that enables the use of\nquantum annealing (QA) for sampling the ionic ground state. The method relies\non a Legendre transformation of the Coulomb energy cost function that strongly\nreduces the effective coupling strengths of the fully connected problem, which\nis essential for effectiveness of QA. The approach is expected to be applicable\nto a variety of materials optimization problems.",
                "authors": [
                    "Tobias Binninger",
                    "Yin-Ying Ting",
                    "Piotr M. Kowalski",
                    "Michael H. Eikerling"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02165v1",
                    "http://arxiv.org/pdf/2401.02165v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02162v1/1.0",
                "title": "Frequency Domain Nuances Mining for Visible-Infrared Person\n  Re-identification",
                "year": 2024,
                "abstract": "The key of visible-infrared person re-identification (VIReID) lies in how to\nminimize the modality discrepancy between visible and infrared images. Existing\nmethods mainly exploit the spatial information while ignoring the\ndiscriminative frequency information. To address this issue, this paper aims to\nreduce the modality discrepancy from the frequency domain perspective.\nSpecifically, we propose a novel Frequency Domain Nuances Mining (FDNM) method\nto explore the cross-modality frequency domain information, which mainly\nincludes an amplitude guided phase (AGP) module and an amplitude nuances mining\n(ANM) module. These two modules are mutually beneficial to jointly explore\nfrequency domain visible-infrared nuances, thereby effectively reducing the\nmodality discrepancy in the frequency domain. Besides, we propose a\ncenter-guided nuances mining loss to encourage the ANM module to preserve\ndiscriminative identity information while discovering diverse cross-modality\nnuances. To the best of our knowledge, this is the first work that explores the\npotential frequency information for VIReID research. Extensive experiments show\nthat the proposed FDNM has significant advantages in improving the performance\nof VIReID. Specifically, our method outperforms the second-best method by 5.2\\%\nin Rank-1 accuracy and 5.8\\% in mAP on the SYSU-MM01 dataset under the indoor\nsearch mode, respectively. Besides, we also validate the effectiveness and\ngeneralization of our method on the challenging visible-infrared face\nrecognition task. \\textcolor{magenta}{The code will be available.}",
                "authors": [
                    "Yukang Zhang",
                    "Yang Lu",
                    "Yan Yan",
                    "Hanzi Wang",
                    "Xuelong Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02162v1",
                    "http://arxiv.org/pdf/2401.02162v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02161v1/1.0",
                "title": "Enhancing RAW-to-sRGB with Decoupled Style Structure in Fourier Domain",
                "year": 2024,
                "abstract": "RAW to sRGB mapping, which aims to convert RAW images from smartphones into\nRGB form equivalent to that of Digital Single-Lens Reflex (DSLR) cameras, has\nbecome an important area of research. However, current methods often ignore the\ndifference between cell phone RAW images and DSLR camera RGB images, a\ndifference that goes beyond the color matrix and extends to spatial structure\ndue to resolution variations. Recent methods directly rebuild color mapping and\nspatial structure via shared deep representation, limiting optimal performance.\nInspired by Image Signal Processing (ISP) pipeline, which distinguishes image\nrestoration and enhancement, we present a novel Neural ISP framework, named\nFourierISP. This approach breaks the image down into style and structure within\nthe frequency domain, allowing for independent optimization. FourierISP is\ncomprised of three subnetworks: Phase Enhance Subnet for structural refinement,\nAmplitude Refine Subnet for color learning, and Color Adaptation Subnet for\nblending them in a smooth manner. This approach sharpens both color and\nstructure, and extensive evaluations across varied datasets confirm that our\napproach realizes state-of-the-art results. Code will be available at\n~\\url{https://github.com/alexhe101/FourierISP}.",
                "authors": [
                    "Xuanhua He",
                    "Tao Hu",
                    "Guoli Wang",
                    "Zejin Wang",
                    "Run Wang",
                    "Qian Zhang",
                    "Keyu Yan",
                    "Ziyi Chen",
                    "Rui Li",
                    "Chenjun Xie",
                    "Jie Zhang",
                    "Man Zhou"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02161v1",
                    "http://arxiv.org/pdf/2401.02161v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02160v1/1.0",
                "title": "Human-in-the-Loop Policy Optimization for Preference-Based\n  Multi-Objective Reinforcement Learning",
                "year": 2024,
                "abstract": "Multi-objective reinforcement learning (MORL) aims to find a set of\nhigh-performing and diverse policies that address trade-offs between multiple\nconflicting objectives. However, in practice, decision makers (DMs) often\ndeploy only one or a limited number of trade-off policies. Providing too many\ndiversified trade-off policies to the DM not only significantly increases their\nworkload but also introduces noise in multi-criterion decision-making. With\nthis in mind, we propose a human-in-the-loop policy optimization framework for\npreference-based MORL that interactively identifies policies of interest. Our\nmethod proactively learns the DM's implicit preference information without\nrequiring any a priori knowledge, which is often unavailable in real-world\nblack-box decision scenarios. The learned preference information is used to\nprogressively guide policy optimization towards policies of interest. We\nevaluate our approach against three conventional MORL algorithms that do not\nconsider preference information and four state-of-the-art preference-based MORL\nalgorithms on two MORL environments for robot control and smart grid\nmanagement. Experimental results fully demonstrate the effectiveness of our\nproposed method in comparison to the other peer algorithms.",
                "authors": [
                    "Ke Li",
                    "Han Guo"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02160v1",
                    "http://arxiv.org/pdf/2401.02160v1"
                ],
                "primary_category": "cs.NE",
                "categories": [
                    "cs.NE"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02158v1/1.0",
                "title": "Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and\n  LightGBM models",
                "year": 2024,
                "abstract": "This paper describes approaches and results for shared Task 1 and 4 of\nSMMH4-23 by Team Shayona. Shared Task-1 was binary classification of english\ntweets self-reporting a COVID-19 diagnosis, and Shared Task-4 was Binary\nclassification of English Reddit posts self-reporting a social anxiety disorder\ndiagnosis. Our team has achieved the highest f1-score 0.94 in Task-1 among all\nparticipants. We have leveraged the Transformer model (BERT) in combination\nwith the LightGBM model for both tasks.",
                "authors": [
                    "Rushi Chavda",
                    "Darshan Makwana",
                    "Vraj Patel",
                    "Anupam Shukla"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02158v1",
                    "http://arxiv.org/pdf/2401.02158v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02157v1/1.0",
                "title": "High-order compact gas-kinetic scheme in arbitrary Lagrangian-Eulerian\n  formulation",
                "year": 2024,
                "abstract": "This study proposes an extension of the high-order compact gas-kinetic scheme\n(CGKS) to compressible flow simulation in an arbitrary Lagrangian-Eulerian\n(ALE) formulation in unstructured mesh. The ALE method is achieved by\nsubdividing arbitrary mesh into tetrahedrons and integrating flux function in a\nlocal coordinate system at the cell interface to ensure geometric conservation\nlaw. The scheme incorporates a compact reconstruction with third-order accuracy\nfor updating both cell-averaged conservative flow variables and their\ngradients. HWENO-type nonlinear reconstruction and gradient compression factors\nare adopted to improve the accuracy and robustness of the scheme. A multi-stage\nmulti-derivative (MSMD) time-stepping method is also implemented to achieve\nhigh-order time accuracy with fewer middle stages. The scheme is used to study\nproblems involving moving boundaries. The numerical experiments demonstrate the\neffectiveness of the scheme in capturing the accurate solutions of both\nlow-speed smooth flow and highly compressible ones with strong shock waves.",
                "authors": [
                    "Yue Zhang",
                    "Kun Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02157v1",
                    "http://arxiv.org/pdf/2401.02157v1"
                ],
                "primary_category": "physics.comp-ph",
                "categories": [
                    "physics.comp-ph"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02153v1/1.0",
                "title": "Unit Testing in ASP Revisited: Language and Test-Driven Development\n  Environment",
                "year": 2024,
                "abstract": "Unit testing frameworks are nowadays considered a best practice, included in\nalmost all modern software development processes, to achieve rapid development\nof correct specifications. Knowledge representation and reasoning paradigms\nsuch as Answer Set Programming (ASP), that have been used in industry-level\napplications, are not an exception. Indeed, the first unit testing\nspecification language for ASP was proposed in 2011 as a feature of the ASPIDE\ndevelopment environment. Later, a more portable unit testing language was\nincluded in the LANA annotation language. In this paper we revisit both\nlanguages and tools for unit testing in ASP. We propose a new unit test\nspecification language that allows one to inline tests within ASP programs, and\nwe identify the computational complexity of the tasks associated with checking\nthe various program-correctness assertions. Test-case specifications are\ntransparent to the traditional evaluation, but can be interpreted by a specific\ntesting tool. Thus, we present a novel environment supporting test driven\ndevelopment of ASP programs.",
                "authors": [
                    "Giovanni Amendola",
                    "Tobias Berei",
                    "Giuseppe Mazzotta",
                    "Francesco Ricca"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02153v1",
                    "http://arxiv.org/pdf/2401.02153v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.AI"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02152v1/1.0",
                "title": "Estimating continuous data of wrist joint angles using ultrasound images",
                "year": 2024,
                "abstract": "Ultrasound imaging has recently been introduced as a sensing interface for\njoint motion estimation. The use of ultrasound images as an estimation method\nis expected to improve the control performance of assistive devices and\nhuman--machine interfaces. This study aimed to estimate continuous wrist joint\nangles using ultrasound images. Specifically, in an experiment, joint angle\ninformation was obtained during extension--flexion movements, and ultrasound\nimages of the associated muscles were acquired. Using the features obtained\nfrom ultrasound images, a multivariate linear regression model was used to\nestimate the joint angles. The coordinates of the feature points obtained using\noptical flow from the ultrasound images were used as explanatory variables of\nthe multivariate linear regression model. The model was trained and tested for\neach trial by each participant to verify the estimation accuracy. The results\nshow that the mean and standard deviation of the estimation accuracy for all\ntrials were root mean square error (RMSE)=1.82 $\\pm$ 0.54 deg and coefficient\nof determination (R2)=0.985 $\\pm$ 0.009. Our method achieves a highly accurate\nestimation of joint angles compared with previous studies using other signals,\nsuch as surface electromyography, while the multivariate linear regression\nmodel is simple and both computational and model training costs are low.",
                "authors": [
                    "Yo Kobayashi",
                    "Yoshihiro Katagi"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02152v1",
                    "http://arxiv.org/pdf/2401.02152v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC",
                    "cs.RO",
                    "eess.SP"
                ]
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02151v1/1.0",
                "title": "Frequency-Adaptive Pan-Sharpening with Mixture of Experts",
                "year": 2024,
                "abstract": "Pan-sharpening involves reconstructing missing high-frequency information in\nmulti-spectral images with low spatial resolution, using a higher-resolution\npanchromatic image as guidance. Although the inborn connection with frequency\ndomain, existing pan-sharpening research has not almost investigated the\npotential solution upon frequency domain. To this end, we propose a novel\nFrequency Adaptive Mixture of Experts (FAME) learning framework for\npan-sharpening, which consists of three key components: the Adaptive Frequency\nSeparation Prediction Module, the Sub-Frequency Learning Expert Module, and the\nExpert Mixture Module. In detail, the first leverages the discrete cosine\ntransform to perform frequency separation by predicting the frequency mask. On\nthe basis of generated mask, the second with low-frequency MOE and\nhigh-frequency MOE takes account for enabling the effective low-frequency and\nhigh-frequency information reconstruction. Followed by, the final fusion module\ndynamically weights high-frequency and low-frequency MOE knowledge to adapt to\nremote sensing images with significant content variations. Quantitative and\nqualitative experiments over multiple datasets demonstrate that our method\nperforms the best against other state-of-the-art ones and comprises a strong\ngeneralization ability for real-world scenes. Code will be made publicly at\n\\url{https://github.com/alexhe101/FAME-Net}.",
                "authors": [
                    "Xuanhua He",
                    "Keyu Yan",
                    "Rui Li",
                    "Chengjun Xie",
                    "Jie Zhang",
                    "Man Zhou"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02151v1",
                    "http://arxiv.org/pdf/2401.02151v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ]
            }
        ]
    }
]