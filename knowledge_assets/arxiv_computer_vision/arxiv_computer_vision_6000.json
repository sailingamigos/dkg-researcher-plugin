[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07766v1",
            "title": "Vision-Language Integration in Multimodal Video Transformers (Partially)\n  Aligns with the Brain",
            "updated": "2023-11-13T21:32:37Z",
            "published": "2023-11-13T21:32:37Z",
            "summary": "Integrating information from multiple modalities is arguably one of the\nessential prerequisites for grounding artificial intelligence systems with an\nunderstanding of the real world. Recent advances in video transformers that\njointly learn from vision, text, and sound over time have made some progress\ntoward this goal, but the degree to which these models integrate information\nfrom modalities still remains unclear. In this work, we present a promising\napproach for probing a pre-trained multimodal video transformer model by\nleveraging neuroscientific evidence of multimodal information processing in the\nbrain. Using brain recordings of participants watching a popular TV show, we\nanalyze the effects of multi-modal connections and interactions in a\npre-trained multi-modal video transformer on the alignment with uni- and\nmulti-modal brain regions. We find evidence that vision enhances masked\nprediction performance during language processing, providing support that\ncross-modal representations in models can benefit individual modalities.\nHowever, we don't find evidence of brain-relevant information captured by the\njoint multi-modal transformer representations beyond that captured by all of\nthe individual modalities. We finally show that the brain alignment of the\npre-trained joint representation can be improved by fine-tuning using a task\nthat requires vision-language inferences. Overall, our results paint an\noptimistic picture of the ability of multi-modal transformers to integrate\nvision and language in partially brain-relevant ways but also show that\nimproving the brain alignment of these models may require new approaches.",
            "author": [
                "Dota Tianai Dong",
                "Mariya Toneva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07766v1",
                "http://arxiv.org/pdf/2311.07766v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07765v1",
            "title": "FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based\n  Human Activity Recognition",
            "updated": "2023-11-13T21:31:07Z",
            "published": "2023-11-13T21:31:07Z",
            "summary": "Motion sensors integrated into wearable and mobile devices provide valuable\ninformation about the device users. Machine learning and, recently, deep\nlearning techniques have been used to characterize sensor data. Mostly, a\nsingle task, such as recognition of activities, is targeted, and the data is\nprocessed centrally at a server or in a cloud environment. However, the same\nsensor data can be utilized for multiple tasks and distributed machine-learning\ntechniques can be used without the requirement of the transmission of data to a\ncentre. This paper explores Federated Transfer Learning in a Multi-Task manner\nfor both sensor-based human activity recognition and device position\nidentification tasks. The OpenHAR framework is used to train the models, which\ncontains ten smaller datasets. The aim is to obtain model(s) applicable for\nboth tasks in different datasets, which may include only some label types.\nMultiple experiments are carried in the Flower federated learning environment\nusing the DeepConvLSTM architecture. Results are presented for federated and\ncentralized versions under different parameters and restrictions. By utilizing\ntransfer learning and training a task-specific and personalized federated\nmodel, we obtained a similar accuracy with training each client individually\nand higher accuracy than a fully centralized approach.",
            "author": [
                "Egemen \u0130\u015fg\u00fcder",
                "\u00d6zlem Durmaz \u0130ncel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07765v1",
                "http://arxiv.org/pdf/2311.07765v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07762v1",
            "title": "Finite Mixtures of Multivariate Poisson-Log Normal Factor Analyzers for\n  Clustering Count Data",
            "updated": "2023-11-13T21:23:15Z",
            "published": "2023-11-13T21:23:15Z",
            "summary": "A mixture of multivariate Poisson-log normal factor analyzers is introduced\nby imposing constraints on the covariance matrix, which resulted in flexible\nmodels for clustering purposes. In particular, a class of eight parsimonious\nmixture models based on the mixtures of factor analyzers model are introduced.\nVariational Gaussian approximation is used for parameter estimation, and\ninformation criteria are used for model selection. The proposed models are\nexplored in the context of clustering discrete data arising from RNA sequencing\nstudies. Using real and simulated data, the models are shown to give favourable\nclustering performance. The GitHub R package for this work is available at\nhttps://github.com/anjalisilva/mixMPLNFA and is released under the open-source\nMIT license.",
            "author": [
                "Andrea Payne",
                "Anjali Silva",
                "Steven J. Rothstein",
                "Paul D. McNicholas",
                "Sanjeena Subedi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07762v1",
                "http://arxiv.org/pdf/2311.07762v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62H30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07761v1",
            "title": "Amodal Optical Flow",
            "updated": "2023-11-13T21:21:43Z",
            "published": "2023-11-13T21:21:43Z",
            "summary": "Optical flow estimation is very challenging in situations with transparent or\noccluded objects. In this work, we address these challenges at the task level\nby introducing Amodal Optical Flow, which integrates optical flow with amodal\nperception. Instead of only representing the visible regions, we define amodal\noptical flow as a multi-layered pixel-level motion field that encompasses both\nvisible and occluded regions of the scene. To facilitate research on this new\ntask, we extend the AmodalSynthDrive dataset to include pixel-level labels for\namodal optical flow estimation. We present several strong baselines, along with\nthe Amodal Flow Quality metric to quantify the performance in an interpretable\nmanner. Furthermore, we propose the novel AmodalFlowNet as an initial step\ntoward addressing this task. AmodalFlowNet consists of a transformer-based\ncost-volume encoder paired with a recurrent transformer decoder which\nfacilitates recurrent hierarchical feature propagation and amodal semantic\ngrounding. We demonstrate the tractability of amodal optical flow in extensive\nexperiments and show its utility for downstream tasks such as panoptic\ntracking. We make the dataset, code, and trained models publicly available at\nhttp://amodal-flow.cs.uni-freiburg.de.",
            "author": [
                "Maximilian Luz",
                "Rohit Mohan",
                "Ahmed Rida Sekkat",
                "Oliver Sawade",
                "Elmar Matthes",
                "Thomas Brox",
                "Abhinav Valada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07761v1",
                "http://arxiv.org/pdf/2311.07761v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07758v1",
            "title": "Synchrophasor Data Anomaly Detection on Grid Edge by 5G Communication\n  and Adjacent Compute",
            "updated": "2023-11-13T21:16:49Z",
            "published": "2023-11-13T21:16:49Z",
            "summary": "The fifth-generation mobile communication (5G) technology offers\nopportunities to enhance the real-time monitoring of grids. The 5G-enabled\nphasor measurement units (PMUs) feature flexible positioning and cost-effective\nlong-term maintenance without the constraints of fixing wires. This paper is\nthe first to demonstrate the applicability of 5G in PMU communication, and the\nexperiment was carried out at Verizon non-standalone test-bed at Pacific\nNorthwest National Laboratory (PNNL) Advanced Wireless Communication lab. The\nperformance of the 5G-enabled PMU communication setup is reviewed and discussed\nin this paper, and a generalized dynamic linear model (GDLM) based real-time\nsynchrophasor data anomaly detection use-case is presented. Last but not least,\nthe practicability of implementing 5G for wide-area protection strategies is\nexplored and discussed by analyzing the experimental results.",
            "author": [
                "Chuan Qin",
                "Dexin Wang",
                "Kishan Prudhvi Guddanti",
                "Xiaoyuan Fan",
                "Zhangshuan Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07758v1",
                "http://arxiv.org/pdf/2311.07758v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07756v1",
            "title": "Quantized tensor networks for solving the Vlasov-Maxwell equations",
            "updated": "2023-11-13T21:15:13Z",
            "published": "2023-11-13T21:15:13Z",
            "summary": "While the Vlasov-Maxwell equations provide an \\textit{ab-initio} description\nof collisionless plasmas, solving them is often impractical due to high\ncomputational costs. In this work, we implement a semi-implicit Vlasov-Maxwell\nsolver utilizing the quantized tensor network (QTN) framework. This framework\nallows one to efficiently represent and manipulate low-rank approximations of\nhigh-dimensional data sets. As a result, the cost of the solver scales\npolynomially with parameter $D$ (the so-called bond dimension), which is\ndirectly related to the error associated with the low-rank approximation. By\nincreasing $D$, convergence to the dynamics that the solver would obtain\nwithout any low-rank approximation is guaranteed. We find that for the 2D3V\ntest problems considered here, a modest $D=64$ appears to be sufficient for\ncapturing the expected physics, despite the simulations using a total of\n$2^{36}$ grid points and thus requiring $D=2^{18}$ for exact calculations.\nAdditionally, we utilize a QTN time evolution scheme based on the Dirac-Frenkel\nvariational principle, which allows us to use larger time steps than that\nprescribed by the Courant-Friedrichs-Lewy (CFL) constraint. As such, the QTN\nformat appears to be a promising means of approximately solving the\nVlasov-Maxwell equations with significantly reduced cost.",
            "author": [
                "Erika Ye",
                "Nuno Loureiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07756v1",
                "http://arxiv.org/pdf/2311.07756v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.plasm-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07755v1",
            "title": "Feasibility and Performance of the Staged Z-Pinch: A One-dimensional\n  Study with FLASH and MACH2",
            "updated": "2023-11-13T21:14:14Z",
            "published": "2023-11-13T21:14:14Z",
            "summary": "Z-pinch platforms constitute a promising pathway to fusion energy research.\nHere, we present a one-dimensional numerical study of the staged Z-pinch (SZP)\nconcept using the FLASH and MACH2 codes. We discuss the verification of the\ncodes using two analytical benchmarks that include Z-pinch-relevant physics,\nbuilding confidence on the codes' ability to model such experiments. Then,\nFLASH is used to simulate two different SZP configurations: a xenon gas-puff\nliner (SZP1*) and a silver solid liner (SZP2). The SZP2 results are compared\nagainst previously published MACH2 results, and a new code-to-code comparison\non SZP1* is presented. Using an ideal equation of state and analytical\ntransport coefficients, FLASH yields a fuel convergence ratio (CR) of\napproximately 39 and a mass-averaged fuel ion temperature slightly below 1 keV\nfor the SZP2 scheme, significantly lower than the full-physics MACH2\nprediction. For the new SZP1* configuration, full-physics FLASH simulations\nfurnish large and inherently unstable CRs (> 300), but achieve fuel ion\ntemperatures of many keV. While MACH2 also predicts high temperatures, the fuel\nstagnates at a smaller CR. The integrated code-to-code comparison reveals how\nmagnetic insulation, heat conduction, and radiation transport affect platform\nperformance and the feasibility of the SZP concept.",
            "author": [
                "Edward C. Hansen",
                "Fernando Garcia-Rubio",
                "Marissa B. P. Adams",
                "Milad Fatenejad",
                "Kasper Moczulski",
                "Paul Ney",
                "Hafiz U. Rahman",
                "Adam C. Reyes",
                "Emil Ruskov",
                "Victor Tranchant",
                "Petros Tzeferacos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07755v1",
                "http://arxiv.org/pdf/2311.07755v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07754v1",
            "title": "Efficient Prior-Free Mechanisms for No-Regret Agents",
            "updated": "2023-11-13T21:13:42Z",
            "published": "2023-11-13T21:13:42Z",
            "summary": "We study a repeated Principal Agent problem between a long lived Principal\nand Agent pair in a prior free setting. In our setting, the sequence of\nrealized states of nature may be adversarially chosen, the Agent is non-myopic,\nand the Principal aims for a strong form of policy regret. Following Camara,\nHartline, and Johnson, we model the Agent's long-run behavior with behavioral\nassumptions that relax the common prior assumption (for example, that the Agent\nhas no swap regret). Within this framework, we revisit the mechanism proposed\nby Camara et al., which informally uses calibrated forecasts of the unknown\nstates of nature in place of a common prior. We give two main improvements.\nFirst, we give a mechanism that has an exponentially improved dependence (in\nterms of both running time and regret bounds) on the number of distinct states\nof nature. To do this, we show that our mechanism does not require truly\ncalibrated forecasts, but rather forecasts that are unbiased subject to only a\npolynomially sized collection of events -- which can be produced with\npolynomial overhead. Second, in several important special cases -- including\nthe focal linear contracting setting -- we show how to remove strong\n``Alignment'' assumptions (which informally require that near-ties are always\nbroken in favor of the Principal) by specifically deploying ``stable'' policies\nthat do not have any near ties that are payoff relevant to the Principal. Taken\ntogether, our new mechanism makes the compelling framework proposed by Camara\net al. much more powerful, now able to be realized over polynomially sized\nstate spaces, and while requiring only mild assumptions on Agent behavior.",
            "author": [
                "Natalie Collina",
                "Aaron Roth",
                "Han Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07754v1",
                "http://arxiv.org/pdf/2311.07754v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.DS",
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07751v1",
            "title": "Strong exponential stability of switched impulsive systems with\n  mode-constrained switching",
            "updated": "2023-11-13T21:07:46Z",
            "published": "2023-11-13T21:07:46Z",
            "summary": "Strong stability, defined by bounds that decay not only over time but also\nwith the number of impulses, has been established as a requirement to ensure\nrobustness properties for impulsive systems with respect to inputs or\ndisturbances. Most existing results, however, only consider weak stability. In\nthis paper, we provide a method for calculating the maximum overshoot and the\ndecay rate for strong (and weak) global uniform exponential stability bounds\nfor non-linear switched impulsive systems. We consider the scenario of\nmode-constrained switching where not all transitions between subsystems are\nallowed, and where subsystems may exhibit unstable dynamics in the flow and\njump maps. Based on direct and reverse mode-dependent average dwell-time and\nactivation-time constraints, we derive stability bounds that can be improved by\nconsidering longer switching sequences for computation. We provide numerical\nexamples that illustrate the weak and strong exponential stability bounds and\nalso how the results can be employed to ensure the stability robustness of\nnonlinear systems that admit a global state weak linearization.",
            "author": [
                "Alexis J. Vallarella",
                "Jos\u00e9 Luis Mancilla-Aguilar",
                "Hernan Haimovich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07751v1",
                "http://arxiv.org/pdf/2311.07751v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07750v2",
            "title": "SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models\n  for Multi-Label Chest X-Ray Classification",
            "updated": "2023-11-20T15:01:19Z",
            "published": "2023-11-13T21:07:07Z",
            "summary": "Chest X-rays are widely used to diagnose thoracic diseases, but the lack of\ndetailed information about these abnormalities makes it challenging to develop\naccurate automated diagnosis systems, which is crucial for early detection and\neffective treatment. To address this challenge, we employed deep learning\ntechniques to identify patterns in chest X-rays that correspond to different\ndiseases. We conducted experiments on the \"ChestX-ray14\" dataset using various\npre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical\nmodels. The best individual model was the CoAtNet, which achieved an area under\nthe receiver operating characteristic curve (AUROC) of 84.2%. By combining the\npredictions of all trained models using a weighted average ensemble where the\nweight of each model was determined using differential evolution, we further\nimproved the AUROC to 85.4%, outperforming other state-of-the-art methods in\nthis field. Our findings demonstrate the potential of deep learning techniques,\nparticularly ensemble deep learning, for improving the accuracy of automatic\ndiagnosis of thoracic diseases from chest X-rays.",
            "author": [
                "S. M. Nabil Ashraf",
                "Md. Adyelullahil Mamun",
                "Hasnat Md. Abdullah",
                "Md. Golam Rabiul Alam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07750v2",
                "http://arxiv.org/pdf/2311.07750v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.4; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07744v1",
            "title": "Dynamic Local Attention with Hierarchical Patching for Irregular\n  Clinical Time Series",
            "updated": "2023-11-13T20:54:52Z",
            "published": "2023-11-13T20:54:52Z",
            "summary": "Irregular multivariate time series data is prevalent in the clinical and\nhealthcare domains. It is characterized by time-wise and feature-wise\nirregularities, making it challenging for machine learning methods to work\nwith. To solve this, we introduce a new model architecture composed of two\nmodules: (1) DLA, a Dynamic Local Attention mechanism that uses learnable\nqueries and feature-specific local windows when computing the self-attention\noperation. This results in aggregating irregular time steps raw input within\neach window to a harmonized regular latent space representation while taking\ninto account the different features' sampling rates. (2) A hierarchical MLP\nmixer that processes the output of DLA through multi-scale patching to leverage\ninformation at various scales for the downstream tasks. Our approach\noutperforms state-of-the-art methods on three real-world datasets, including\nthe latest clinical MIMIC IV dataset.",
            "author": [
                "Xingyu Chen",
                "Xiaochen Zheng",
                "Amina Mollaysa",
                "Manuel Sch\u00fcrch",
                "Ahmed Allam",
                "Michael Krauthammer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07744v1",
                "http://arxiv.org/pdf/2311.07744v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07740v1",
            "title": "Towards a Classification of Isolated $j$-invariants",
            "updated": "2023-11-13T20:44:09Z",
            "published": "2023-11-13T20:44:09Z",
            "summary": "We develop an algorithm to test whether a non-CM elliptic curve\n$E/\\mathbb{Q}$ gives rise to an isolated point of any degree on any modular\ncurve of the form $X_1(N)$. This builds on prior work of Zywina which gives a\nmethod for computing the image of the adelic Galois representation associated\nto $E$. Running this algorithm on all elliptic curves presently in the\n$L$-functions and Modular Forms Database and the Stein-Watkins Database gives\nstrong evidence for the conjecture that $E$ gives rise to an isolated point on\n$X_1(N)$ if and only if $j(E)=-140625/8, -9317,$ $351/4$, or\n$-162677523113838677$.",
            "author": [
                "Abbey Bourdon",
                "Sachi Hashimoto",
                "Timo Keller",
                "Zev Klagsbrun",
                "David Lowry-Duda",
                "Travis Morrison",
                "Filip Najman",
                "Himanshu Shukla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07740v1",
                "http://arxiv.org/pdf/2311.07740v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07738v1",
            "title": "Revisiting Stylized Facts for Modern Stock Markets",
            "updated": "2023-11-13T20:43:20Z",
            "published": "2023-11-13T20:43:20Z",
            "summary": "In 2001, Rama Cont introduced a now-widely used set of 'stylized facts' to\nsynthesize empirical studies of financial time series, resulting in 11\nqualitative properties presumed to be universal to all financial markets. Here,\nwe replicate Cont's analyses for a convenience sample of stocks drawn from the\nU.S. stock market following a fundamental shift in market regulation. Our study\nrelies on the same authoritative data as that used by the U.S. regulator. We\nfind conclusive evidence in the modern market for eight of Cont's original\nfacts, while we find weak support for one additional fact and no support for\nthe remaining two. Our study represents the first test of the original set of\n11 stylized facts against the same stocks, therefore providing insight into how\nCont's stylized facts should be viewed in the context of modern stock markets.",
            "author": [
                "Ethan Ratliff-Crain",
                "Colin M. Van Oort",
                "James Bagrow",
                "Matthew T. K. Koehler",
                "Brian F. Tivnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07738v1",
                "http://arxiv.org/pdf/2311.07738v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07737v1",
            "title": "Nonreciprocal phase shifts in a nonlinear periodic waveguide",
            "updated": "2023-11-13T20:43:19Z",
            "published": "2023-11-13T20:43:19Z",
            "summary": "We explore nonreciprocal vibration transmission in a nonlinear periodic\nwaveguide. Nonlinearity and asymmetry, the two necessary requirements for\nnonreciprocity, are both introduced within the unit cell of the periodic\nwaveguide. We focus primarily on the contribution of phase to the nonreciprocal\nsteady-state response of the system. To highlight the phase effects, which are\nrarely discussed in the literature, we investigate response regimes in which\nnonreciprocity is solely due to nonreciprocal phase shifts: when the locations\nof the source and receiver are interchanged, the amplitude of transmitted\nvibrations remains unchanged but the transmitted phases are not equal. We\npresent a computational analysis of this state of phase nonreciprocity in the\nweakly nonlinear frequency-preserving response regime, where we characterize\nthe response using its nonreciprocal phase shift. This allows us to\nsystematically find a set of system parameters (including two symmetry-breaking\nparameters) that lead to reciprocal nonlinear response in a system with broken\nmirror symmetry. In other words, we show that breaking the mirror symmetry of a\npassive nonlinear waveguide is a necessary but insufficient condition for\nnonreciprocal dynamics to exist. Our findings highlight the important role of\nphase in nonlinear nonreciprocity and showcase the potential of asymmetry to\nserve as an additional design parameter.",
            "author": [
                "Ali Kogani",
                "Behrooz Yousefzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07737v1",
                "http://arxiv.org/pdf/2311.07737v1"
            ],
            "primary_category": "nlin.PS",
            "category": [
                "nlin.PS",
                "math.DS",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07734v1",
            "title": "Quality-Aware Prototype Memory for Face Representation Learning",
            "updated": "2023-11-13T20:36:54Z",
            "published": "2023-11-13T20:36:54Z",
            "summary": "Prototype Memory is a powerful model for face representation learning. It\nenables the training of face recognition models using datasets of any size,\nwith on-the-fly generation of prototypes (classifier weights) and efficient\nways of their utilization. Prototype Memory demonstrated strong results in many\nface recognition benchmarks. However, the algorithm of prototype generation,\nused in it, is prone to the problems of imperfectly calculated prototypes in\ncase of low-quality or poorly recognizable faces in the images, selected for\nthe prototype creation. All images of the same person, presented in the\nmini-batch, used with equal weights, and the resulting averaged prototype could\nbe contaminated with imperfect embeddings of such face images. It can lead to\nmisdirected training signals and impair the performance of the trained face\nrecognition models. In this paper, we propose a simple and effective way to\nimprove Prototype Memory with quality-aware prototype generation. Quality-Aware\nPrototype Memory uses different weights for images of different quality in the\nprocess of prototype generation. With this improvement, prototypes get more\nvaluable information from high-quality images and less hurt by low-quality\nones. We propose and compare several methods of quality estimation and usage,\nperform extensive experiments on the different face recognition benchmarks and\ndemonstrate the advantages of the proposed model compared to the basic version\nof Prototype Memory.",
            "author": [
                "Evgeny Smirnov",
                "Vasiliy Galyuk",
                "Evgeny Lukyanets"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07734v1",
                "http://arxiv.org/pdf/2311.07734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07729v1",
            "title": "Distributed pressure matching strategy using diffusion adaptation",
            "updated": "2023-11-13T20:24:13Z",
            "published": "2023-11-13T20:24:13Z",
            "summary": "Personal sound zone (PSZ) systems, which aim to create listening (bright) and\nsilent (dark) zones in neighboring regions of space, are often based on\ntime-varying acoustics. Conventional adaptive-based methods for handling PSZ\ntasks suffer from the collection and processing of acoustic transfer\nfunctions~(ATFs) between all the matching microphones and all the loudspeakers\nin a centralized manner, resulting in high calculation complexity and costly\naccuracy requirements. This paper presents a distributed pressure-matching (PM)\nmethod relying on diffusion adaptation (DPM-D) to spread the computational load\namongst nodes in order to overcome these issues. The global PM problem is\ndefined as a sum of local costs, and the diffusion adaption approach is then\nused to create a distributed solution that just needs local information\nexchanges. Simulations over multi-frequency bins and a computational complexity\nanalysis are conducted to evaluate the properties of the algorithm and to\ncompare it with centralized counterparts.",
            "author": [
                "Mengfei Zhang",
                "Junqing Zhang",
                "Jie Chen",
                "C\u00e9dric Richard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07729v1",
                "http://arxiv.org/pdf/2311.07729v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07727v1",
            "title": "Computing the homotopy type and homological invariants of the\n  independence complex of ternary graphs",
            "updated": "2023-11-13T20:12:46Z",
            "published": "2023-11-13T20:12:46Z",
            "summary": "In 2022, Jinha Kim proved a conjecture by Engstr\\\"om that states the\nindependence complex of a graph with no induced cycle of length divisible by 3\nis either contractible or homotopy equivalent to a sphere. We give criteria for\nwhen the independence complex of a ternary graph is contractible, and describe\nthe dimension of the sphere when it is not. We then apply our results to\ndescribe the multigraded betti numbers of the edge ideal of a ternary graph. In\nparticular, we show that the regularity and depth of edge ideals of a ternary\ngraph $G$ are equal if and only if the independence complex of $G$ is not\ncontractible. Finally, we apply our results to partially recover and generalize\nrecent results on the depth of edge ideals of some unicyclic graphs.",
            "author": [
                "Sara Faridi",
                "Thiago Holleben"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07727v1",
                "http://arxiv.org/pdf/2311.07727v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.AT",
                "math.CO",
                "13F55, 05E40, 05E45, 55U10, 55P15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07726v1",
            "title": "A Simple Quantum Blockmodeling with Qubits and Permutations",
            "updated": "2023-11-13T20:10:53Z",
            "published": "2023-11-13T20:10:53Z",
            "summary": "Blockmodeling of a given problem represented by an $N\\times N$ adjacency\nmatrix can be found by swapping rows and columns of the matrix (i.e.\nmultiplying matrix from left and right by a permutation matrix). In general,\nthrough performing this task, row and column permutations affect the fitness\nvalue in optimization: For an $N\\times N$ matrix, it requires $O(N)$\ncomputations to find (or update) the fitness value of a candidate solution.\n  On quantum computers, permutations can be applied in parallel and\nefficiently, and their implementations can be as simple as a single qubit\noperation (a NOT gate on a qubit) which takes an $O(1)$ time algorithmic step.\nIn this paper, using permutation matrices, we describe a quantum blockmodeling\nfor data analysis tasks. In the model, the measurement outcome of a small group\nof qubits are mapped to indicate the fitness value. Therefore, we show that it\nis possible to find or update the fitness value in $O(log(N))$ time. This lead\nus to show that when the number of iterations are less than $log(N)$ time, it\nmay be possible to reach the same solution exponentially faster on quantum\ncomputers in comparison to classical computers. In addition, since on quantum\ncircuits the different sequence of permutations can be applied in parallel\n(superpositon), the machine learning task in this model can be implemented more\nefficiently on quantum computers.",
            "author": [
                "Ammar Daskin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07726v1",
                "http://arxiv.org/pdf/2311.07726v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07723v2",
            "title": "Generalization Analogies: A Testbed for Generalizing AI Oversight to\n  Hard-To-Measure Domains",
            "updated": "2023-11-19T01:33:53Z",
            "published": "2023-11-13T20:07:36Z",
            "summary": "As AI systems become more intelligent and their behavior becomes more\nchallenging to assess, they may learn to game the flaws of human feedback\ninstead of genuinely striving to follow instructions; however, this risk can be\nmitigated by controlling how LLMs generalize human feedback to situations where\nit is unreliable. To better understand how reward models generalize, we craft\n69 distribution shifts spanning 8 categories. We find that reward models do not\nlearn to evaluate `instruction-following' by default and instead favor personas\nthat resemble internet text. Techniques for interpreting reward models'\ninternal representations achieve better generalization than standard\nfine-tuning, but still frequently fail to distinguish instruction-following\nfrom conflated behaviors. We consolidate the 15 most challenging distribution\nshifts into the GENeralization analogIES (GENIES) benchmark, which we hope will\nenable progress toward controlling reward model generalization.",
            "author": [
                "Joshua Clymer",
                "Garrett Baker",
                "Rohan Subramani",
                "Sam Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07723v2",
                "http://arxiv.org/pdf/2311.07723v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07719v1",
            "title": "TokaMaker: An open-source time-dependent Grad-Shafranov tool for the\n  design and modeling of axisymmetric fusion devices",
            "updated": "2023-11-13T19:58:47Z",
            "published": "2023-11-13T19:58:47Z",
            "summary": "In this paper, we present a new static and time-dependent MagnetoHydroDynamic\n(MHD) equilibrium code, TokaMaker, for axisymmetric configurations of\nmagnetized plasmas, based on the well-known Grad-Shafranov equation. This code\nutilizes finite element methods on an unstructured triangular grid to enable\ncapturing accurate machine geometry and simple mesh generation from\nengineering-like descriptions of present and future devices. The new code is\ndesigned for ease of use without sacrificing capability and speed through a\ncombination of Python, Fortran, and C/C++ components. A detailed description of\nthe numerical methods of the code, including a novel formulation of the\nboundary conditions for free-boundary equilibria, and validation of the\nimplementation of those methods using both analytic test cases and cross-code\nvalidation is shown. Results show expected convergence across tested polynomial\norders for analytic and cross-code test cases.",
            "author": [
                "C. Hansen",
                "I. G. Stewart",
                "D. Burgess",
                "M. Pharr",
                "S. Guizzo",
                "F. Logak",
                "A. O. Nelson",
                "C. Paz-Soldan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07719v1",
                "http://arxiv.org/pdf/2311.07719v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07715v1",
            "title": "PolyIE: A Dataset of Information Extraction from Polymer Material\n  Scientific Literature",
            "updated": "2023-11-13T19:56:18Z",
            "published": "2023-11-13T19:56:18Z",
            "summary": "Scientific information extraction (SciIE), which aims to automatically\nextract information from scientific literature, is becoming more important than\never. However, there are no existing SciIE datasets for polymer materials,\nwhich is an important class of materials used ubiquitously in our daily lives.\nTo bridge this gap, we introduce POLYIE, a new SciIE dataset for polymer\nmaterials. POLYIE is curated from 146 full-length polymer scholarly articles,\nwhich are annotated with different named entities (i.e., materials, properties,\nvalues, conditions) as well as their N-ary relations by domain experts. POLYIE\npresents several unique challenges due to diverse lexical formats of entities,\nambiguity between entities, and variable-length relations. We evaluate\nstate-of-the-art named entity extraction and relation extraction models on\nPOLYIE, analyze their strengths and weaknesses, and highlight some difficult\ncases for these models. To the best of our knowledge, POLYIE is the first SciIE\nbenchmark for polymer materials, and we hope it will lead to more research\nefforts from the community on this challenging task. Our code and data are\navailable on: https://github.com/jerry3027/PolyIE.",
            "author": [
                "Jerry Junyang Cheung",
                "Yuchen Zhuang",
                "Yinghao Li",
                "Pranav Shetty",
                "Wantian Zhao",
                "Sanjeev Grampurohit",
                "Rampi Ramprasad",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07715v1",
                "http://arxiv.org/pdf/2311.07715v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07712v1",
            "title": "Low-Cost Architecture for an Advanced Smart Shower System Using Internet\n  of Things Platform",
            "updated": "2023-11-13T19:55:01Z",
            "published": "2023-11-13T19:55:01Z",
            "summary": "Wastage of water is a critical issue amongst the various global crises. This\npaper proposes an architecture model for a low-cost, energy efficient SMART\nShower system that is ideal for efficient water management and be able to\npredict reliably any accidental fall in the shower space. The sensors in this\nprototype can document the surrounding temperature and humidity in real time\nand thereby circulate the ideal temperature of water for its patron, rather\nthan its reliance on predictive values . Three different scenarios are\ndiscussed that can allow reliably predicting any accidental fall in the shower\nvicinity. Motion sensors, sound sensors and gesture sensors can be used to\ncompliment prediction of possible injuries in the shower. The integration with\nthe Internet of Things (IoT) platform will allow caretakers to monitor the\nactivities in the shower space especially in the case of elderly individuals as\nthere have been reported cases of casualties in the slippery shower space. The\nproposed proof-of-concept prototype is cost effective and can be incorporated\ninto an existing system for the added precedence of safety and convenience. The\nintelligent system is conserving water by optimizing its flow temperature and\nthe IoT platform allows real time monitoring for safety.",
            "author": [
                "Shadeeb Hossain",
                "Ahmed Abdelgawad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07712v1",
                "http://arxiv.org/pdf/2311.07712v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07711v1",
            "title": "Histopathologic Cancer Detection",
            "updated": "2023-11-13T19:51:46Z",
            "published": "2023-11-13T19:51:46Z",
            "summary": "Early diagnosis of the cancer cells is necessary for making an effective\ntreatment plan and for the health and safety of a patient. Nowadays, doctors\nusually use a histological grade that pathologists determine by performing a\nsemi-quantitative analysis of the histopathological and cytological features of\nhematoxylin-eosin (HE) stained histopathological images. This research\ncontributes a potential classification model for cancer prognosis to\nefficiently utilize the valuable information underlying the HE-stained\nhistopathological images. This work uses the PatchCamelyon benchmark datasets\nand trains them in a multi-layer perceptron and convolution model to observe\nthe model's performance in terms of precision, Recall, F1 Score, Accuracy, and\nAUC Score. The evaluation result shows that the baseline convolution model\noutperforms the baseline MLP model. Also, this paper introduced ResNet50 and\nInceptionNet models with data augmentation, where ResNet50 is able to beat the\nstate-of-the-art model. Furthermore, the majority vote and concatenation\nensemble were evaluated and provided the future direction of using transfer\nlearning and segmentation to understand the specific features.",
            "author": [
                "Varan Singh Rohila",
                "Neeraj Lalwani",
                "Lochan Basyal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07711v1",
                "http://arxiv.org/pdf/2311.07711v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07710v1",
            "title": "A Practical and Optimal First-Order Method for Large-Scale Convex\n  Quadratic Programming",
            "updated": "2023-11-13T19:50:03Z",
            "published": "2023-11-13T19:50:03Z",
            "summary": "Convex quadratic programming (QP) is an important class of optimization\nproblem with wide applications in practice. The classic QP solvers are based on\neither simplex or barrier method, both of which suffer from the scalability\nissue because their computational bottleneck is solving linear equations. In\nthis paper, we design and analyze a first-order method called the restarted\naccelerated primal-dual hybrid gradient method for QP, whose computational\nbottleneck is matrix-vector multiplication. We show that the proposed algorithm\nhas a linear convergence rate when solving generic QP, and the obtained linear\nrate is optimal among a wide class of primal-dual methods. Furthermore, we\nconnect the linear rate with a sharpness constant of the KKT system of QP,\nwhich is a standard quantity to measure the hardness of a continuous\noptimization problem. Numerical experiments on a standard QP benchmark set\nshowcase the advantage of the proposed algorithm compared to its first-order\ncounterparts.",
            "author": [
                "Haihao Lu",
                "Jinwen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07710v1",
                "http://arxiv.org/pdf/2311.07710v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07708v1",
            "title": "Reinforcement Learning for Solving Stochastic Vehicle Routing Problem",
            "updated": "2023-11-13T19:46:22Z",
            "published": "2023-11-13T19:46:22Z",
            "summary": "This study addresses a gap in the utilization of Reinforcement Learning (RL)\nand Machine Learning (ML) techniques in solving the Stochastic Vehicle Routing\nProblem (SVRP) that involves the challenging task of optimizing vehicle routes\nunder uncertain conditions. We propose a novel end-to-end framework that\ncomprehensively addresses the key sources of stochasticity in SVRP and utilizes\nan RL agent with a simple yet effective architecture and a tailored training\nmethod. Through comparative analysis, our proposed model demonstrates superior\nperformance compared to a widely adopted state-of-the-art metaheuristic,\nachieving a significant 3.43% reduction in travel costs. Furthermore, the model\nexhibits robustness across diverse SVRP settings, highlighting its adaptability\nand ability to learn optimal routing strategies in varying environments. The\npublicly available implementation of our framework serves as a valuable\nresource for future research endeavors aimed at advancing RL-based solutions\nfor SVRP.",
            "author": [
                "Zangir Iklassov",
                "Ikboljon Sobirov",
                "Ruben Solozabal",
                "Martin Takac"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07708v1",
                "http://arxiv.org/pdf/2311.07708v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07705v1",
            "title": "Robust and Scalable Hyperdimensional Computing With Brain-Like Neural\n  Adaptations",
            "updated": "2023-11-13T19:42:33Z",
            "published": "2023-11-13T19:42:33Z",
            "summary": "The Internet of Things (IoT) has facilitated many applications utilizing\nedge-based machine learning (ML) methods to analyze locally collected data.\nUnfortunately, popular ML algorithms often require intensive computations\nbeyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional\ncomputing (HDC) has been introduced to address this issue. However, existing\nHDCs use static encoders, requiring extremely high dimensionality and hundreds\nof training iterations to achieve reasonable accuracy. This results in a huge\nefficiency loss, severely impeding the application of HDCs in IoT systems. We\nobserved that a main cause is that the encoding module of existing HDCs lacks\nthe capability to utilize and adapt to information learned during training. In\ncontrast, neurons in human brains dynamically regenerate all the time and\nprovide more useful functionalities when learning new information. While the\ngoal of HDC is to exploit the high-dimensionality of randomly generated base\nhypervectors to represent the information as a pattern of neural activity, it\nremains challenging for existing HDCs to support a similar behavior as brain\nneural regeneration. In this work, we present dynamic HDC learning frameworks\nthat identify and regenerate undesired dimensions to provide adequate accuracy\nwith significantly lowered dimensionalities, thereby accelerating both the\ntraining and inference.",
            "author": [
                "Junyao Wang",
                "Mohammad Abdullah Al Faruque"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07705v1",
                "http://arxiv.org/pdf/2311.07705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07703v1",
            "title": "Measuring Entrainment in Spontaneous Code-switched Speech",
            "updated": "2023-11-13T19:41:34Z",
            "published": "2023-11-13T19:41:34Z",
            "summary": "It is well-known that interlocutors who entrain to one another have more\nsuccessful conversations than those who do not. Previous research has shown\nthat interlocutors entrain on linguistic features in both written and spoken\nmonolingual domains. More recent work on code-switched communication has also\nshown preliminary evidence of entrainment on certain aspects of code-switching\n(CSW). However, such studies of entrainment in code-switched domains have been\nextremely few and restricted to human-machine textual interactions. Our work\nstudies code-switched spontaneous speech between humans by answering the\nfollowing questions: 1) Do patterns of written and spoken entrainment in\nmonolingual settings generalize to code-switched settings? 2) Do patterns of\nentrainment on code-switching in generated text generalize to spontaneous\ncode-switched speech? We find evidence of affirmative answers to both of these\nquestions, with important implications for the potentially \"universal\" nature\nof entrainment as a communication phenomenon, and potential applications in\ninclusive and interactive speech technology.",
            "author": [
                "Debasmita Bhattacharya",
                "Siying Ding",
                "Alayna Nguyen",
                "Julia Hirschberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07703v1",
                "http://arxiv.org/pdf/2311.07703v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07702v1",
            "title": "On a conjecture of Ghorpade, Datta and Beelen for the number of points\n  of varities over finite fields",
            "updated": "2023-11-13T19:39:58Z",
            "published": "2023-11-13T19:39:58Z",
            "summary": "Consider a finite field $\\mathbb{F}_q$ and positive integers $d,m,r$ with\n$1\\leq r\\leq \\binom{m+d}{d}$. Let $S_d(m)$ be the $\\mathbb{F}_q$ vector space\nof all homogeneous polynomials of degree $d$ in $X_0,\\dots,X_m$. Let $e_r(d,m)$\nbe the maximum number of $\\mathbb{F}_q$-rational points in the vanishing set of\n$W$ as $W$ varies through all subspaces of $S_d(m)$ of dimension $r$. Ghorpade,\nDatta and Beelen had conjectured an exact formula of $e_r(d,m)$ when $q\\geq\nd+1$. We prove that their conjectured formula is true when $q$ is sufficiently\nlarge in terms of $m,d,r$. The problem of determining $e_r(d,m)$ is equivalent\nto the problem of computing the $r^{th}$ generalized hamming weights of\nprojective the Reed Muller code $PRM_q(d,m)$. It is also equivalent to the\nproblem of determining the maximum number of points on sections of Veronese\nvarieties by linear subvarieties of codimension $r$.",
            "author": [
                "Deepesh Singhal",
                "Yuxin Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07702v1",
                "http://arxiv.org/pdf/2311.07702v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07700v1",
            "title": "AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language\n  Models Denoising",
            "updated": "2023-11-13T19:36:54Z",
            "published": "2023-11-13T19:36:54Z",
            "summary": "Large language models (LLMs) have opened up enormous opportunities while\nsimultaneously posing ethical dilemmas. One of the major concerns is their\nability to create text that closely mimics human writing, which can lead to\npotential misuse, such as academic misconduct, disinformation, and fraud. To\naddress this problem, we present AuthentiGPT, an efficient classifier that\ndistinguishes between machine-generated and human-written texts. Under the\nassumption that human-written text resides outside the distribution of\nmachine-generated text, AuthentiGPT leverages a black-box LLM to denoise input\ntext with artificially added noise, and then semantically compares the denoised\ntext with the original to determine if the content is machine-generated. With\nonly one trainable parameter, AuthentiGPT eliminates the need for a large\ntraining dataset, watermarking the LLM's output, or computing the\nlog-likelihood. Importantly, the detection capability of AuthentiGPT can be\neasily adapted to any generative language model. With a 0.918 AUROC score on a\ndomain-specific dataset, AuthentiGPT demonstrates its effectiveness over other\ncommercial algorithms, highlighting its potential for detecting\nmachine-generated text in academic settings.",
            "author": [
                "Zhen Guo",
                "Shangdi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07700v1",
                "http://arxiv.org/pdf/2311.07700v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07692v1",
            "title": "On The Truthfulness of 'Surprisingly Likely' Responses of Large Language\n  Models",
            "updated": "2023-11-13T19:21:25Z",
            "published": "2023-11-13T19:21:25Z",
            "summary": "The surprisingly likely criterion in the seminal work of Prelec (the Bayesian\nTruth Serum) guarantees truthfulness in a game-theoretic multi-agent setting,\nby rewarding rational agents to maximise the expected information gain with\ntheir answers w.r.t. their probabilistic beliefs. We investigate the relevance\nof a similar criterion for responses of LLMs. We hypothesize that if the\nsurprisingly likely criterion works in LLMs, under certain conditions, the\nresponses that maximize the reward under this criterion should be more accurate\nthan the responses that only maximize the posterior probability. Using\nbenchmarks including the TruthfulQA benchmark and using openly available LLMs:\nGPT-2 and LLaMA-2, we show that the method indeed improves the accuracy\nsignificantly (for example, upto 24 percentage points aggregate improvement on\nTruthfulQA and upto 70 percentage points improvement on individual categories\nof questions).",
            "author": [
                "Naman Goel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07692v1",
                "http://arxiv.org/pdf/2311.07692v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07690v1",
            "title": "Correlated volumes for extended wavefunctions on a random-regular graph",
            "updated": "2023-11-13T19:15:18Z",
            "published": "2023-11-13T19:15:18Z",
            "summary": "We analyze the ergodic properties of a metallic wavefunction for the Anderson\nmodel in a disordered random-regular graph with branching number $k=2.$ A few\nq-moments $I_q$ associated with the zero energy eigenvector are numerically\ncomputed up to sizes $N=4\\times 10^6.$ We extract their corresponding fractal\ndimensions $D_q$ in the thermodynamic limit together with correlated volumes\n$N_q$ that control finite-size effects. At intermediate values of disorder $W,$\nwe obtain ergodicity $D_q=1$ for $q=1,2$ and correlation volumes that increase\nfast upon approaching the Anderson transition $\\log(\\log(N_q))\\sim W.$ We then\nfocus on the extraction of the volume $N_0$ associated with the typical value\nof the wavefunction $e^{<\\log|\\psi|^2>},$ which follows a similar tendency as\nthe ones for $N_1$ or $N_2.$ Its value at intermediate disorders is close, but\nsmaller, to the so-called ergodic volume previously found via the\nsuper-symmetric formalism and belief propagator algorithms. None of the\ncomputed correlated volumes shows a tendency to diverge up to disorders\n$W\\approx 15$, specifically none with exponent $\\nu=1/2$. Deeper in the metal,\nwe characterize the crossover to system sizes much smaller than the first\ncorrelated volume $N_1\\gg N.$ Once this crossover has taken place, we obtain\nevidence of a scaling in which the derivative of the first fractal dimension\n$D_1$ behaves critically with an exponent $\\nu=1.$",
            "author": [
                "Manuel Pino",
                "Jose E. Roman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07690v1",
                "http://arxiv.org/pdf/2311.07690v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07689v1",
            "title": "MART: Improving LLM Safety with Multi-round Automatic Red-Teaming",
            "updated": "2023-11-13T19:13:29Z",
            "published": "2023-11-13T19:13:29Z",
            "summary": "Red-teaming is a common practice for mitigating unsafe behaviors in Large\nLanguage Models (LLMs), which involves thoroughly assessing LLMs to identify\npotential flaws and addressing them with responsible and accurate responses.\nWhile effective, manual red-teaming is costly, and existing automatic\nred-teaming typically discovers safety risks without addressing them. In this\npaper, we propose a Multi-round Automatic Red-Teaming (MART) method, which\nincorporates both automatic adversarial prompt writing and safe response\ngeneration, significantly increasing red-teaming scalability and the safety of\nthe target LLM. Specifically, an adversarial LLM and a target LLM interplay\nwith each other in an iterative manner, where the adversarial LLM aims to\ngenerate challenging prompts that elicit unsafe responses from the target LLM,\nwhile the target LLM is fine-tuned with safety aligned data on these\nadversarial prompts. In each round, the adversarial LLM crafts better attacks\non the updated target LLM, while the target LLM also improves itself through\nsafety fine-tuning. On adversarial prompt benchmarks, the violation rate of an\nLLM with limited safety alignment reduces up to 84.7% after 4 rounds of MART,\nachieving comparable performance to LLMs with extensive adversarial prompt\nwriting. Notably, model helpfulness on non-adversarial prompts remains stable\nthroughout iterations, indicating the target LLM maintains strong performance\non instruction following.",
            "author": [
                "Suyu Ge",
                "Chunting Zhou",
                "Rui Hou",
                "Madian Khabsa",
                "Yi-Chia Wang",
                "Qifan Wang",
                "Jiawei Han",
                "Yuning Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07689v1",
                "http://arxiv.org/pdf/2311.07689v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07687v1",
            "title": "Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend\n  Actions in Text Games",
            "updated": "2023-11-13T19:12:49Z",
            "published": "2023-11-13T19:12:49Z",
            "summary": "Large Language Models (LLMs) have demonstrated superior performance in\nlanguage understanding benchmarks. CALM, a popular approach, leverages\nlinguistic priors of LLMs -- GPT-2 -- for action candidate recommendations to\nimprove the performance in text games in Jericho without environment-provided\nactions. However, CALM adapts GPT-2 with annotated human gameplays and keeps\nthe LLM fixed during the learning of the text based games. In this work, we\nexplore and evaluate updating LLM used for candidate recommendation during the\nlearning of the text based game as well to mitigate the reliance on the human\nannotated gameplays, which are costly to acquire. We observe that by updating\nthe LLM during learning using carefully selected in-game transitions, we can\nreduce the dependency on using human annotated game plays for fine-tuning the\nLLMs. We conducted further analysis to study the transferability of the updated\nLLMs and observed that transferring in-game trained models to other games did\nnot result in a consistent transfer.",
            "author": [
                "Arjun Vaithilingam Sudhakar",
                "Prasanna Parthasarathi",
                "Janarthanan Rajendran",
                "Sarath Chandar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07687v1",
                "http://arxiv.org/pdf/2311.07687v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07686v1",
            "title": "Achieving Optimum Received Power with Elementwise Updates in the Least\n  Number of Steps for Discrete-Phase RISs",
            "updated": "2023-11-13T19:09:42Z",
            "published": "2023-11-13T19:09:42Z",
            "summary": "The problem of optimizing discrete phases in a reconfigurable intelligent\nsurface (RIS) to maximize the received power at a user equipment is addressed.\nNecessary and sufficient conditions to achieve this maximization are given.\nThese conditions are employed in an algorithm to achieve the maximization. New\nversions of the algorithm are given that are proven to achieve convergence in N\nor fewer steps whether the direct link is completely blocked or not, where N is\nthe number of the RIS elements, whereas previously published results achieve\nthis in KN or 2N number of steps where K is the number of discrete phases,\ne.g., [1], [2]. Thus, for a discrete-phase RIS, the techniques presented in\nthis paper achieve the optimum received power in the smallest number of steps\npublished in the literature. In addition, in each of those N steps, the\ntechniques presented in this paper determine only one or a small number of\nphase shifts with a simple elementwise update rule, which result in a\nsubstantial reduction of computation time, as compared to the algorithms in the\nliterature, e.g., [2], [3].",
            "author": [
                "Dogan Kutay Pekcan",
                "Ender Ayanoglu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07686v1",
                "http://arxiv.org/pdf/2311.07686v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.ET",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07682v1",
            "title": "Fuse to Forget: Bias Reduction and Selective Memorization through Model\n  Fusion",
            "updated": "2023-11-13T19:02:56Z",
            "published": "2023-11-13T19:02:56Z",
            "summary": "Model fusion research aims to aggregate the knowledge of multiple models to\nenhance performance by combining their weights. In this work, we study the\ninverse, investigating whether and how can model fusion interfere and reduce\nunwanted knowledge. We delve into the effects of model fusion on the evolution\nof learned shortcuts, social biases, and memorization capabilities in\nfine-tuned language models. Through several experiments covering text\nclassification and generation tasks, our analysis highlights that shared\nknowledge among models is usually enhanced during model fusion, while unshared\nknowledge is usually lost or forgotten. Based on this observation, we\ndemonstrate the potential of model fusion as a debiasing tool and showcase its\nefficacy in addressing privacy concerns associated with language models.",
            "author": [
                "Kerem Zaman",
                "Leshem Choshen",
                "Shashank Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07682v1",
                "http://arxiv.org/pdf/2311.07682v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07678v1",
            "title": "Computing Implicitizations of Multi-Graded Polynomial Maps",
            "updated": "2023-11-13T19:01:48Z",
            "published": "2023-11-13T19:01:48Z",
            "summary": "In this paper, we focus on computing the kernel of a map of polynomial rings\n$\\varphi$. This core problem in symbolic computation is known as\nimplicitization. While there are extremely effective Gr\\\"obner basis methods\nused to solve this problem, these methods can become infeasible as the number\nof variables increases. In the case when the map $\\varphi$ is multigraded, we\nconsider an alternative approach. We demonstrate how to quickly compute a\nmatrix of maximal rank for which $\\varphi$ has a positive multigrading. Then in\neach graded component we compute the minimal generators of the kernel in that\nmultidegree with linear algebra. We have implemented our techniques in\nMacaulay2 and show that our implementation can compute many generators of low\ndegree in examples where Gr\\\"obner techniques have failed. This includes\nseveral examples coming from phylogenetics where even a complete list of\nquadrics and cubics were unknown. When the multigrading refines total degree,\nour algorithm is \\emph{embarassingly parallel} and a fully parallelized version\nof our algorithm will be forthcoming in OSCAR.",
            "author": [
                "Joseph Cummings",
                "Benjamin Hollering"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07678v1",
                "http://arxiv.org/pdf/2311.07678v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "cs.SC",
                "math.AC",
                "math.ST",
                "stat.TH",
                "68W3068W30 68W30 68W30 68W30, 13P25, 62R01"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07677v1",
            "title": "Estimating the matrix $p \\rightarrow q$ norm",
            "updated": "2023-11-13T19:01:41Z",
            "published": "2023-11-13T19:01:41Z",
            "summary": "The matrix $p \\rightarrow q$ norm is a fundamental quantity appearing in a\nvariety of areas of mathematics. This quantity is known to be efficiently\ncomputable in only a few special cases. The best known algorithms for\napproximately computing this quantity with theoretical guarantees essentially\nconsist of computing the $p\\to q$ norm for $p,q$ where this quantity can be\ncomputed exactly or up to a constant, and applying interpolation. We analyze\nthe matrix $2 \\to q$ norm problem and provide an improved approximation\nalgorithm via a simple argument involving the rows of a given matrix. For\nexample, we improve the best-known $2\\to 4$ norm approximation from $m^{1/8}$\nto $m^{1/12}$. This insight for the $2\\to q$ norm improves the best known $p\n\\to q$ approximation algorithm for the region $p \\le 2 \\le q$, and leads to an\noverall improvement in the best-known approximation for $p \\to q$ norms from\n$m^{25/128}$ to $m^{3 - 2 \\sqrt{2}}$.",
            "author": [
                "Larry Guth",
                "Dominique Maldague",
                "John Urschel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07677v1",
                "http://arxiv.org/pdf/2311.07677v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.FA",
                "15A60, 65F35, 68W25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07676v1",
            "title": "Centralized calibration of power system dynamic models using variational\n  data assimilation",
            "updated": "2023-11-13T19:01:40Z",
            "published": "2023-11-13T19:01:40Z",
            "summary": "This paper presents a novel centralized, variational data assimilation\napproach for calibrating transient dynamic models in electrical power systems,\nfocusing on load model parameters. With the increasing importance of\ninverter-based resources, assessing power systems' dynamic performance under\ndisturbances has become challenging, necessitating robust model calibration\nmethods. The proposed approach expands on previous Bayesian frameworks by\nestablishing a posterior distribution of parameters using an approximation\naround the maximum a posteriori value. We illustrate the efficacy of our method\nby generating events of varying intensity, highlighting its ability to capture\nthe systems' evolution accurately and with associated uncertainty estimates.\nThis research improves the precision of dynamic performance assessments in\nmodern power systems, with potential applications in managing uncertainties and\noptimizing system operations.",
            "author": [
                "Ahmed Attia",
                "D. Adrian Maldonado",
                "Emil Constantinescu",
                "Mihai Anitescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07676v1",
                "http://arxiv.org/pdf/2311.07676v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07672v1",
            "title": "Dynamical friction in dark matter superfluids: The evolution of black\n  hole binaries",
            "updated": "2023-11-13T19:01:03Z",
            "published": "2023-11-13T19:01:03Z",
            "summary": "The theory of superfluid dark matter is characterized by self-interacting\nsub-eV particles that thermalize and condense to form a superfluid core in\ngalaxies. Massive black holes at the center of galaxies, however, modify the\ndark matter distribution and result in a density enhancement in their vicinity\nknown as dark matter spikes. The presence of these spikes affects the evolution\nof binary systems by modifying their gravitational wave emission and inducing\ndynamical friction effects on the orbiting bodies. In this work, we assess the\nrole of dynamical friction for bodies moving through a superfluid core enhanced\nby a central massive black hole. As a first step, we compute the dynamical\nfriction force experienced by bodies moving in a circular orbit. Then, we\nestimate the gravitational wave dephasing of the binary, showing that the\neffect of the superfluid drag force is beyond the reach of space-based\nexperiments like LISA, contrarily to collisionless dark matter, therefore\nproviding an opportunity to distinguish these dark matter models.",
            "author": [
                "Lasha Berezhiani",
                "Giordano Cintia",
                "Valerio De Luca",
                "Justin Khoury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07672v1",
                "http://arxiv.org/pdf/2311.07672v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA",
                "gr-qc",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07666v2",
            "title": "Efficient MPS representations and quantum circuits from the Fourier\n  modes of classical image data",
            "updated": "2023-12-01T14:42:23Z",
            "published": "2023-11-13T19:00:33Z",
            "summary": "Machine learning tasks are an exciting application for quantum computers, as\nit has been proven that they can learn certain problems more efficiently than\nclassical ones. Applying quantum machine learning algorithms to classical data\ncan have many important applications, as qubits allow for dealing with\nexponentially more data than classical bits. However, preparing the\ncorresponding quantum states usually requires an exponential number of gates\nand therefore may ruin any potential quantum speedups. Here, we show that\nclassical data with a sufficiently quickly decaying Fourier spectrum after\nbeing mapped to a quantum state can be well-approximated by states with a small\nSchmidt rank (i.e., matrix product states) and we derive explicit error bounds.\nThese approximated states can, in turn, be prepared on a quantum computer with\na linear number of nearest-neighbor two-qubit gates. We confirm our results\nnumerically on a set of $1024\\times1024$-pixel images taken from the\n'Imagenette' dataset. Additionally, we consider different variational circuit\nans\\\"atze and demonstrate numerically that one-dimensional sequential circuits\nachieve the same compression quality as more powerful ans\\\"atze.",
            "author": [
                "Bernhard Jobst",
                "Kevin Shen",
                "Carlos A. Riofr\u00edo",
                "Elvira Shishenina",
                "Frank Pollmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07666v2",
                "http://arxiv.org/pdf/2311.07666v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07657v1",
            "title": "The Riemann zeta function and exact exponential sum identities of\n  divisor functions",
            "updated": "2023-11-13T19:00:04Z",
            "published": "2023-11-13T19:00:04Z",
            "summary": "We prove an explicit integral formula for computing the product of two\nshifted Riemann zeta functions everywhere in the complex plane. We show that\nthis formula implies the existence of infinite families of exact exponential\nsum identities involving the divisor functions, and we provide examples of\nthese identities. We conjecturally propose a method to compute divisor\nfunctions by matrix inversion, without employing arithmetic techniques.",
            "author": [
                "Maria Nastasescu",
                "Nicolas Robles",
                "Bogdan Stoica",
                "Alexandru Zaharescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07657v1",
                "http://arxiv.org/pdf/2311.07657v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07640v1",
            "title": "Origin of reduced dynamical friction by dark matter halos with net\n  prograde rotation",
            "updated": "2023-11-13T19:00:01Z",
            "published": "2023-11-13T19:00:01Z",
            "summary": "We provide an explanation for the reduced dynamical friction on galactic bars\nin spinning dark matter halos. Earlier work based on linear theory predicted an\nincrease in dynamical friction when dark halos have a net forward rotation,\nbecause prograde orbits couple to bars more strongly than retrograde orbits.\nSubsequent numerical studies, however, found the opposite trend: dynamical\nfriction weakens with increasing spin of the halo. We revisit this problem and\ndemonstrate that linear theory in fact correctly predicts a reduced torque in\nforward-rotating halos. We show that shifting the halo mass from retrograde to\nprograde phase space generates a positive gradient in the distribution function\nnear the origin of the z-angular momentum (Lz=0), which results in a resonant\ntransfer of Lz to the bar, making the net dynamical friction weaker. While this\neffect is subdominant for the major resonances, including the corotation\nresonance, it leads to a significant positive torque on the bar for the series\nof direct radial resonances, as these resonances are strongest at Lz=0. The\noverall dynamical friction from spinning halos is shown to decrease with the\nhalo's spin, in agreement with the secular behavior of N-body simulations. We\nvalidate our linear calculation by computing the nonlinear torque from\nindividual resonances using the angle-averaged Hamiltonian.",
            "author": [
                "Rimpei Chiba",
                "Sandeep Kumar Kataria"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07640v1",
                "http://arxiv.org/pdf/2311.07640v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07575v1",
            "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for\n  Multi-modal Large Language Models",
            "updated": "2023-11-13T18:59:47Z",
            "published": "2023-11-13T18:59:47Z",
            "summary": "We present SPHINX, a versatile multi-modal large language model (MLLM) with a\njoint mixing of model weights, tuning tasks, and visual embeddings. First, for\nstronger vision-language alignment, we unfreeze the large language model (LLM)\nduring pre-training, and introduce a weight mix strategy between LLMs trained\nby real-world and synthetic data. By directly integrating the weights from two\ndomains, the mixed LLM can efficiently incorporate diverse semantics with\nfavorable robustness. Then, to enable multi-purpose capabilities, we mix a\nvariety of tasks for joint visual instruction tuning, and design task-specific\ninstructions to avoid inter-task conflict. In addition to the basic visual\nquestion answering, we include more challenging tasks such as region-level\nunderstanding, caption grounding, document layout detection, and human pose\nestimation, contributing to mutual enhancement over different scenarios.\nAdditionally, we propose to extract comprehensive visual embeddings from\nvarious network architectures, pre-training paradigms, and information\ngranularity, providing language models with more robust image representations.\nBased on our proposed joint mixing, SPHINX exhibits superior multi-modal\nunderstanding capabilities on a wide range of applications. On top of this, we\nfurther propose an efficient strategy aiming to better capture fine-grained\nappearances of high-resolution images. With a mixing of different scales and\nhigh-resolution sub-images, SPHINX attains exceptional visual parsing and\nreasoning performance on existing evaluation benchmarks. We hope our work may\ncast a light on the exploration of joint mixing in future MLLM research. Code\nis released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.",
            "author": [
                "Ziyi Lin",
                "Chris Liu",
                "Renrui Zhang",
                "Peng Gao",
                "Longtian Qiu",
                "Han Xiao",
                "Han Qiu",
                "Chen Lin",
                "Wenqi Shao",
                "Keqin Chen",
                "Jiaming Han",
                "Siyuan Huang",
                "Yichi Zhang",
                "Xuming He",
                "Hongsheng Li",
                "Yu Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07575v1",
                "http://arxiv.org/pdf/2311.07575v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07574v2",
            "title": "To See is to Believe: Prompting GPT-4V for Better Visual Instruction\n  Tuning",
            "updated": "2023-11-29T15:37:24Z",
            "published": "2023-11-13T18:59:31Z",
            "summary": "Existing visual instruction tuning methods typically prompt large language\nmodels with textual descriptions to generate instruction-following data.\nDespite the promising performance achieved, these descriptions are derived from\nimage annotations, which are oftentimes coarse-grained. Furthermore, the\ninstructions might even contradict the visual content without observing the\nentire visual context. To address this challenge, we introduce a fine-grained\nvisual instruction dataset, LVIS-Instruct4V, which contains 220K visually\naligned and context-aware instructions produced by prompting the powerful\nGPT-4V with images from LVIS. Through experimental validation and case studies,\nwe demonstrate that high-quality visual instructional data could improve the\nperformance of LLaVA-1.5, a state-of-the-art large multimodal model, across a\nwide spectrum of benchmarks by clear margins. Notably, by simply replacing the\nLLaVA-Instruct with our LVIS-Instruct4V, we achieve better results than LLaVA\non most challenging LMM benchmarks, e.g., LLaVA$^w$ (76.7 vs. 70.7) and MM-Vet\n(40.2 vs. 35.4). We release our data and model at\nhttps://github.com/X2FD/LVIS-INSTRUCT4V.",
            "author": [
                "Junke Wang",
                "Lingchen Meng",
                "Zejia Weng",
                "Bo He",
                "Zuxuan Wu",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07574v2",
                "http://arxiv.org/pdf/2311.07574v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07573v1",
            "title": "Realizability of Free Spaces of Curves",
            "updated": "2023-11-13T18:59:07Z",
            "published": "2023-11-13T18:59:07Z",
            "summary": "The free space diagram is a popular tool to compute the well-known Fr\\'echet\ndistance. As the Fr\\'echet distance is used in many different fields, many\nvariants have been established to cover the specific needs of these\napplications. Often, the question arises whether a certain pattern in the free\nspace diagram is \"realizable\", i.e., whether there exists a pair of polygonal\nchains whose free space diagram corresponds to it. The answer to this question\nmay help in deciding the computational complexity of these distance measures,\nas well as allowing to design more efficient algorithms for restricted input\nclasses that avoid certain free space patterns. Therefore, we study the inverse\nproblem: Given a potential free space diagram, do there exist curves that\ngenerate this diagram?\n  Our problem of interest is closely tied to the classic Distance Geometry\nproblem. We settle the complexity of Distance Geometry in $\\mathbb{R}^{> 2}$,\nshowing $\\exists\\mathbb{R}$-hardness. We use this to show that for curves in\n$\\mathbb{R}^{\\ge 2}$, the realizability problem is\n$\\exists\\mathbb{R}$-complete, both for continuous and for discrete Fr\\'echet\ndistance. We prove that the continuous case in $\\mathbb{R}^1$ is only weakly\nNP-hard, and we provide a pseudo-polynomial time algorithm and show that it is\nfixed-parameter tractable. Interestingly, for the discrete case in\n$\\mathbb{R}^1$, we show that the problem becomes solvable in polynomial time.",
            "author": [
                "Hugo A. Akitaya",
                "Maike Buchin",
                "Majid Mirzanezhad",
                "Leonie Ryvkin",
                "Carola Wenk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07573v1",
                "http://arxiv.org/pdf/2311.07573v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07571v1",
            "title": "Universal signatures of Majorana zero modes in critical Kitaev chains",
            "updated": "2023-11-13T18:58:48Z",
            "published": "2023-11-13T18:58:48Z",
            "summary": "Many topological or critical aspects of the Kitaev chain are well known, with\nseveral classic results. In contrast, the study of the critical behavior of the\nstrong Majorana zero modes (MZM) has been overlooked. Here we introduce two\ntopological markers which, surprisingly, exhibit non-trivial signatures over\nthe entire (1+1) Ising critical line. We first analytically compute the MZM\nfidelity ${\\cal{F}}_{\\rm MZM}$--a measure of the MZM mapping between parity\nsectors. It takes a universal value along the (1+1) Ising critical line,\n${\\cal{F}}_{\\rm MZM}=\\sqrt{8}/\\pi$, independent of the energy. We also obtain\nan exact analytical result for the critical MZM occupation number ${{\\cal\nN}}_{\\rm MZM}$ which depends on the Catalan's constant ${\\cal G}\\approx\n0.91596559$, for both the ground-state (${{\\cal N}}_{\\rm\nMZM}=1/2-4{\\cal{G}}/\\pi^2\\approx 0.12877$) and the first excited state (${{\\cal\nN}}_{\\rm MZM}=1/2+(8-4{\\cal{G}})/\\pi^2\\approx 0.93934$). We further compute\nfinite-size corrections which identically vanish for the special ratio\n$\\Delta/t=\\sqrt{2}-1$ between pairing and hopping in the critical Kitaev chain.",
            "author": [
                "Nicolas Laflorencie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07571v1",
                "http://arxiv.org/pdf/2311.07571v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.stat-mech",
                "cond-mat.supr-con",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07568v1",
            "title": "Feature emergence via margin maximization: case studies in algebraic\n  tasks",
            "updated": "2023-11-13T18:56:33Z",
            "published": "2023-11-13T18:56:33Z",
            "summary": "Understanding the internal representations learned by neural networks is a\ncornerstone challenge in the science of machine learning. While there have been\nsignificant recent strides in some cases towards understanding how neural\nnetworks implement specific target functions, this paper explores a\ncomplementary question -- why do networks arrive at particular computational\nstrategies? Our inquiry focuses on the algebraic learning tasks of modular\naddition, sparse parities, and finite group operations. Our primary theoretical\nfindings analytically characterize the features learned by stylized neural\nnetworks for these algebraic tasks. Notably, our main technique demonstrates\nhow the principle of margin maximization alone can be used to fully specify the\nfeatures learned by the network. Specifically, we prove that the trained\nnetworks utilize Fourier features to perform modular addition and employ\nfeatures corresponding to irreducible group-theoretic representations to\nperform compositions in general groups, aligning closely with the empirical\nobservations of Nanda et al. and Chughtai et al. More generally, we hope our\ntechniques can help to foster a deeper understanding of why neural networks\nadopt specific computational strategies.",
            "author": [
                "Depen Morwani",
                "Benjamin L. Edelman",
                "Costin-Andrei Oncescu",
                "Rosie Zhao",
                "Sham Kakade"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07568v1",
                "http://arxiv.org/pdf/2311.07568v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.5.1; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07564v1",
            "title": "Can Authorship Attribution Models Distinguish Speakers in Speech\n  Transcripts?",
            "updated": "2023-11-13T18:54:17Z",
            "published": "2023-11-13T18:54:17Z",
            "summary": "Authorship verification is the problem of determining if two distinct writing\nsamples share the same author and is typically concerned with the attribution\nof written text. In this paper, we explore the attribution of transcribed\nspeech, which poses novel challenges. The main challenge is that many stylistic\nfeatures, such as punctuation and capitalization, are not available or\nreliable. Therefore, we expect a priori that transcribed speech is a more\nchallenging domain for attribution. On the other hand, other stylistic\nfeatures, such as speech disfluencies, may enable more successful attribution\nbut, being specific to speech, require special purpose models. To better\nunderstand the challenges of this setting, we contribute the first systematic\nstudy of speaker attribution based solely on transcribed speech. Specifically,\nwe propose a new benchmark for speaker attribution focused on conversational\nspeech transcripts. To control for spurious associations of speakers with\ntopic, we employ both conversation prompts and speakers' participating in the\nsame conversation to construct challenging verification trials of varying\ndifficulties. We establish the state of the art on this new benchmark by\ncomparing a suite of neural and non-neural baselines, finding that although\nwritten text attribution models achieve surprisingly good performance in\ncertain settings, they struggle in the hardest settings we consider.",
            "author": [
                "Cristina Aggazzotti",
                "Nicholas Andrews",
                "Elizabeth Allyn Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07564v1",
                "http://arxiv.org/pdf/2311.07564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07562v1",
            "title": "GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone\n  GUI Navigation",
            "updated": "2023-11-13T18:53:37Z",
            "published": "2023-11-13T18:53:37Z",
            "summary": "We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical\nuser interface (GUI) navigation task. MM-Navigator can interact with a\nsmartphone screen as human users, and determine subsequent actions to fulfill\ngiven instructions. Our findings demonstrate that large multimodal models\n(LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its\nadvanced screen interpretation, action reasoning, and precise action\nlocalization capabilities. We first benchmark MM-Navigator on our collected iOS\nscreen dataset. According to human assessments, the system exhibited a 91\\%\naccuracy rate in generating reasonable action descriptions and a 75\\% accuracy\nrate in executing the correct actions for single-step instructions on iOS.\nAdditionally, we evaluate the model on a subset of an Android screen navigation\ndataset, where the model outperforms previous GUI navigators in a zero-shot\nfashion. Our benchmark and detailed analyses aim to lay a robust groundwork for\nfuture research into the GUI navigation task. The project page is at\nhttps://github.com/zzxslp/MM-Navigator.",
            "author": [
                "An Yan",
                "Zhengyuan Yang",
                "Wanrong Zhu",
                "Kevin Lin",
                "Linjie Li",
                "Jianfeng Wang",
                "Jianwei Yang",
                "Yiwu Zhong",
                "Julian McAuley",
                "Jianfeng Gao",
                "Zicheng Liu",
                "Lijuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07562v1",
                "http://arxiv.org/pdf/2311.07562v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07561v1",
            "title": "Fast Normalized Cross-Correlation for Template Matching with Rotations",
            "updated": "2023-11-13T18:53:30Z",
            "published": "2023-11-13T18:53:30Z",
            "summary": "Normalized cross-correlation is the reference approach to carry out template\nmatching on images. When it is computed in Fourier space, it can handle\nefficiently template translations but it cannot do so with template rotations.\nIncluding rotations requires sampling the whole space of rotations, repeating\nthe computation of the correlation each time.\n  This article develops an alternative mathematical theory to handle\nefficiently, at the same time, rotations and translations. Our proposal has a\nreduced computational complexity because it does not require to repeatedly\nsample the space of rotations. To do so, we integrate the information relative\nto all rotated versions of the template into a unique symmetric tensor template\n-which is computed only once per template-. Afterward, we demonstrate that the\ncorrelation between the image to be processed with the independent tensor\ncomponents of the tensorial template contains enough information to recover\ntemplate instance positions and rotations.\n  Our proposed method has the potential to speed up conventional template\nmatching computations by a factor of several magnitude orders for the case of\n3D images.",
            "author": [
                "Jos\u00e9 Mar\u00eda Almira",
                "Harold Phelippeau",
                "Antonio Martinez-Sanchez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07561v1",
                "http://arxiv.org/pdf/2311.07561v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "math.GM",
                "68U10",
                "I.4.7; I.4.8; I.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07560v1",
            "title": "Scanning the moduli of smooth hypersurfaces",
            "updated": "2023-11-13T18:53:09Z",
            "published": "2023-11-13T18:53:09Z",
            "summary": "We study the locus of smooth hypersurfaces inside the Hilbert scheme of a\nsmooth projective complex variety. In the spirit of scanning, we construct a\nmap to a continuous section space of a projective bundle, and show that it\ninduces an isomorphism in integral homology in a range of degrees growing with\nthe ampleness of the hypersurfaces. When the ambient variety is a curve, this\nrecovers a result of McDuff about configuration spaces. We compute the rational\ncohomology of the section space and exhibit a phenomenon of homological\nstability for hypersurfaces with first Chern class going to infinity. For\nsimply connected varieties, the rational cohomology is shown to agree with the\nstable cohomology of a moduli space of hypersurfaces, with a peculiar\ntangential structure, as studied by Galatius and Randal-Williams.",
            "author": [
                "Alexis Aumonier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07560v1",
                "http://arxiv.org/pdf/2311.07560v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.AT",
                "55R80, 14J70 (Primary), 14C05, 14M12, 57R15 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07557v1",
            "title": "Backreaction of axion-SU(2) dynamics during inflation",
            "updated": "2023-11-13T18:50:53Z",
            "published": "2023-11-13T18:50:53Z",
            "summary": "We consider the effects of backreaction on axion-SU(2) dynamics during\ninflation. We use the linear evolution equations for the gauge field modes and\ncompute their backreaction on the background quantities numerically using the\nHartree approximation. We find a new dynamical attractor solution for the axion\nfield and the vacuum expectation value of the gauge field, where the latter has\nan opposite sign with respect to the chromo-natural inflation solution. Our\nfindings are of particular interest to the phenomenology of axion-SU(2)\ninflation, redefining parts of the viable parameter space. In addition, the\nbackreaction effects lead to characteristic oscillatory features in the\nprimordial gravitational wave background that are potentially detectable with\nupcoming gravitational wave detectors.",
            "author": [
                "Oksana Iarygina",
                "Evangelos I. Sfakianakis",
                "Ramkishor Sharma",
                "Axel Brandenburg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07557v1",
                "http://arxiv.org/pdf/2311.07557v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07556v1",
            "title": "Using Natural Language Explanations to Improve Robustness of In-context\n  Learning for Natural Language Inference",
            "updated": "2023-11-13T18:49:13Z",
            "published": "2023-11-13T18:49:13Z",
            "summary": "Recent studies have demonstrated that large language models (LLMs) excel in\ndiverse tasks through in-context learning (ICL) facilitated by task-specific\nprompts and examples. However, the existing literature shows that ICL\nencounters performance deterioration when exposed to adversarial inputs.\nEnhanced performance has been observed when ICL is augmented with natural\nlanguage explanations (NLEs) (we refer to it as X-ICL). Thus, this work\ninvestigates whether X-ICL can improve the robustness of LLMs on a suite of\nseven adversarial and challenging natural language inference datasets.\nMoreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT in\nour case) with few human-generated NLEs to produce further NLEs (we call it\nChatGPT few-shot), which we show superior to both ChatGPT zero-shot and\nhuman-generated NLEs alone. We evaluate five popular LLMs (GPT3.5-turbo,\nLLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shot\nyields over 6% improvement over ICL. Furthermore, while prompt selection\nstrategies were previously shown to significantly improve ICL on\nin-distribution test sets, we show that these strategies do not match the\nefficacy of the X-ICL paradigm in robustness-oriented evaluations.",
            "author": [
                "Xuanli He",
                "Yuxiang Wu",
                "Oana-Maria Camburu",
                "Pasquale Minervini",
                "Pontus Stenetorp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07556v1",
                "http://arxiv.org/pdf/2311.07556v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07554v1",
            "title": "Fast and Space-Efficient Parallel Algorithms for Influence Maximization",
            "updated": "2023-11-13T18:48:57Z",
            "published": "2023-11-13T18:48:57Z",
            "summary": "Influence Maximization (IM) is a crucial problem in data science. The goal is\nto find a fixed-size set of highly-influential seed vertices on a network to\nmaximize the influence spread along the edges. While IM is NP-hard on\ncommonly-used diffusion models, a greedy algorithm can achieve\n$(1-1/e)$-approximation, repeatedly selecting the vertex with the highest\nmarginal gain in influence as the seed. Due to theoretical guarantees, rich\nliterature focuses on improving the performance of the greedy algorithm. To\nestimate the marginal gain, existing work either runs Monte Carlo (MC)\nsimulations of influence spread or pre-stores hundreds of sketches (usually\nper-vertex information). However, these approaches can be inefficient in time\n(MC simulation) or space (storing sketches), preventing the ideas from scaling\nto today's large-scale graphs.\n  This paper significantly improves the scalability of IM using two key\ntechniques. The first is a sketch-compression technique for the independent\ncascading model on undirected graphs. It allows combining the simulation and\nsketching approaches to achieve a time-space tradeoff. The second technique\nincludes new data structures for parallel seed selection. Using our new\napproaches, we implemented PaC-IM: Parallel and Compressed IM.\n  We compare PaC-IM with state-of-the-art parallel IM systems on a 96-core\nmachine with 1.5TB memory. PaC-IM can process large-scale graphs with up to\n900M vertices and 74B edges in about 2 hours. On average across all tested\ngraphs, our uncompressed version is 5--18$\\times$ faster and about 1.4$\\times$\nmore space-efficient than existing parallel IM systems. Using compression\nfurther saves 3.8$\\times$ space with only 70% overhead in time on average.",
            "author": [
                "Letong Wang",
                "Xiangyun Ding",
                "Yan Gu",
                "Yihan Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07554v1",
                "http://arxiv.org/pdf/2311.07554v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07548v1",
            "title": "Interpretable Fine-Tuning for Graph Neural Network Surrogate Models",
            "updated": "2023-11-13T18:37:07Z",
            "published": "2023-11-13T18:37:07Z",
            "summary": "Data-based surrogate modeling has surged in capability in recent years with\nthe emergence of graph neural networks (GNNs), which can operate directly on\nmesh-based representations of data. The goal of this work is to introduce an\ninterpretable fine-tuning strategy for GNNs, with application to unstructured\nmesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that\nadds interpretability to a pre-trained baseline GNN through an adaptive\nsub-graph sampling strategy that isolates regions in physical space\nintrinsically linked to the forecasting task, while retaining the predictive\ncapability of the baseline. The structures identified by the fine-tuned GNNs,\nwhich are adaptively produced in the forward pass as explicit functions of the\ninput, serve as an accessible link between the baseline model architecture, the\noptimization goal, and known problem-specific physics. Additionally, through a\nregularization procedure, the fine-tuned GNNs can also be used to identify,\nduring inference, graph nodes that correspond to a majority of the anticipated\nforecasting error, adding a novel interpretable error-tagging capability to\nbaseline models. Demonstrations are performed using unstructured flow data\nsourced from flow over a backward-facing step at high Reynolds numbers.",
            "author": [
                "Shivam Barwey",
                "Romit Maulik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07548v1",
                "http://arxiv.org/pdf/2311.07548v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07547v1",
            "title": "GPT-4V(ision) as A Social Media Analysis Engine",
            "updated": "2023-11-13T18:36:50Z",
            "published": "2023-11-13T18:36:50Z",
            "summary": "Recent research has offered insights into the extraordinary capabilities of\nLarge Multimodal Models (LMMs) in various general vision and language tasks.\nThere is growing interest in how LMMs perform in more specialized domains.\nSocial media content, inherently multimodal, blends text, images, videos, and\nsometimes audio. Understanding social multimedia content remains a challenging\nproblem for contemporary machine learning frameworks. In this paper, we explore\nGPT-4V(ision)'s capabilities for social multimedia analysis. We select five\nrepresentative tasks, including sentiment analysis, hate speech detection, fake\nnews identification, demographic inference, and political ideology detection,\nto evaluate GPT-4V. Our investigation begins with a preliminary quantitative\nanalysis for each task using existing benchmark datasets, followed by a careful\nreview of the results and a selection of qualitative samples that illustrate\nGPT-4V's potential in understanding multimodal social media content. GPT-4V\ndemonstrates remarkable efficacy in these tasks, showcasing strengths such as\njoint understanding of image-text pairs, contextual and cultural awareness, and\nextensive commonsense knowledge. Despite the overall impressive capacity of\nGPT-4V in the social media domain, there remain notable challenges. GPT-4V\nstruggles with tasks involving multilingual social multimedia comprehension and\nhas difficulties in generalizing to the latest trends in social media.\nAdditionally, it exhibits a tendency to generate erroneous information in the\ncontext of evolving celebrity and politician knowledge, reflecting the known\nhallucination problem. The insights gleaned from our findings underscore a\npromising future for LMMs in enhancing our comprehension of social media\ncontent and its users through the analysis of multimodal information.",
            "author": [
                "Hanjia Lyu",
                "Jinfa Huang",
                "Daoan Zhang",
                "Yongsheng Yu",
                "Xinyi Mou",
                "Jinsheng Pan",
                "Zhengyuan Yang",
                "Zhongyu Wei",
                "Jiebo Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07547v1",
                "http://arxiv.org/pdf/2311.07547v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07540v1",
            "title": "Finding planted cliques using Markov chain Monte Carlo",
            "updated": "2023-11-13T18:31:42Z",
            "published": "2023-11-13T18:31:42Z",
            "summary": "The planted clique problem is a paradigmatic model of\nstatistical-to-computational gaps: the planted clique is\ninformation-theoretically detectable if its size $k\\ge 2\\log_2 n$ but\npolynomial-time algorithms only exist for the recovery task when $k=\n\\Omega(\\sqrt{n})$. By now, there are many simple and fast algorithms that\nsucceed as soon as $k = \\Omega(\\sqrt{n})$. Glaringly, however, no MCMC approach\nto the problem had been shown to work, including the Metropolis process on\ncliques studied by Jerrum since 1992. In fact, Chen, Mossel, and Zadik recently\nshowed that any Metropolis process whose state space is the set of cliques\nfails to find any sub-linear sized planted clique in polynomial time if\ninitialized naturally from the empty set. Here, we redeem MCMC performance for\nthe planted clique problem by relaxing the state space to all vertex subsets\nand adding a corresponding energy penalty for missing edges. With that, we\nprove that energy-minimizing Markov chains (gradient descent and a\nlow-temperature relaxation of it) succeed at recovering planted cliques of size\n$k = \\Omega(\\sqrt{n})$ if initialized from the full graph. Importantly,\ninitialized from the empty set, the relaxation still does not help the gradient\ndescent find sub-linear planted cliques. We also demonstrate robustness of\nthese Markov chain approaches under a natural contamination model.",
            "author": [
                "Reza Gheissari",
                "Aukosh Jagannath",
                "Yiming Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07540v1",
                "http://arxiv.org/pdf/2311.07540v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "math.PR",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07538v1",
            "title": "Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided\n  Classifiers",
            "updated": "2023-11-13T18:28:25Z",
            "published": "2023-11-13T18:28:25Z",
            "summary": "Recent approaches have explored language-guided classifiers capable of\nclassifying examples from novel tasks when provided with task-specific natural\nlanguage explanations, instructions or prompts (Sanh et al., 2022; R. Menon et\nal., 2022). While these classifiers can generalize in zero-shot settings, their\ntask performance often varies substantially between different language\nexplanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also,\ncurrent approaches fail to leverage unlabeled examples that may be available in\nmany scenarios. Here, we introduce TALC, a framework that uses data programming\nto adapt a language-guided classifier for a new task during inference when\nprovided with explanations from multiple teachers and unlabeled test examples.\nOur results show that TALC consistently outperforms a competitive baseline from\nprior work by an impressive 9.3% (relative improvement). Further, we\ndemonstrate the robustness of TALC to variations in the quality and quantity of\nprovided explanations, highlighting its potential in scenarios where learning\nfrom multiple teachers or a crowd is involved. Our code is available at:\nhttps://github.com/WeiKangda/TALC.git.",
            "author": [
                "Kangda Wei",
                "Sayan Ghosh",
                "Rakesh R. Menon",
                "Shashank Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07538v1",
                "http://arxiv.org/pdf/2311.07538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10757v1",
            "title": "How Contentious Terms About People and Cultures are Used in Linked Open\n  Data",
            "updated": "2023-11-13T18:25:20Z",
            "published": "2023-11-13T18:25:20Z",
            "summary": "Web resources in linked open data (LOD) are comprehensible to humans through\nliteral textual values attached to them, such as labels, notes, or comments.\nWord choices in literals may not always be neutral. When outdated and\nculturally stereotyping terminology is used in literals, they may appear as\noffensive to users in interfaces and propagate stereotypes to algorithms\ntrained on them. We study how frequently and in which literals contentious\nterms about people and cultures occur in LOD and whether there are attempts to\nmark the usage of such terms. For our analysis, we reuse English and Dutch\nterms from a knowledge graph that provides opinions of experts from the\ncultural heritage domain about terms' contentiousness. We inspect occurrences\nof these terms in four widely used datasets: Wikidata, The Getty Art &\nArchitecture Thesaurus, Princeton WordNet, and Open Dutch WordNet. Some terms\nare ambiguous and contentious only in particular senses. Applying word sense\ndisambiguation, we generate a set of literals relevant to our analysis. We\nfound that outdated, derogatory, stereotyping terms frequently appear in\ndescriptive and labelling literals, such as preferred labels that are usually\ndisplayed in interfaces and used for indexing. In some cases, LOD contributors\nmark contentious terms with words and phrases in literals (implicit markers) or\nproperties linked to resources (explicit markers). However, such marking is\nrare and non-consistent in all datasets. Our quantitative and qualitative\ninsights could be helpful in developing more systematic approaches to address\nthe propagation of stereotypes via LOD.",
            "author": [
                "Andrei Nesterov",
                "Laura Hollink",
                "Jacco van Ossenbruggen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10757v1",
                "http://arxiv.org/pdf/2311.10757v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07536v1",
            "title": "A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual\n  Question Answering",
            "updated": "2023-11-13T18:22:32Z",
            "published": "2023-11-13T18:22:32Z",
            "summary": "The emergence of multimodal large models (MLMs) has significantly advanced\nthe field of visual understanding, offering remarkable capabilities in the\nrealm of visual question answering (VQA). Yet, the true challenge lies in the\ndomain of knowledge-intensive VQA tasks, which necessitate not just recognition\nof visual elements, but also a deep comprehension of the visual information in\nconjunction with a vast repository of learned knowledge. To uncover such\ncapabilities of MLMs, particularly the newly introduced GPT-4V, we provide an\nin-depth evaluation from three perspectives: 1) Commonsense Knowledge, which\nassesses how well models can understand visual cues and connect to general\nknowledge; 2) Fine-grained World Knowledge, which tests the model's skill in\nreasoning out specific knowledge from images, showcasing their proficiency\nacross various specialized fields; 3) Comprehensive Knowledge with\nDecision-making Rationales, which examines model's capability to provide\nlogical explanations for its inference, facilitating a deeper analysis from the\ninterpretability perspective. Extensive experiments indicate that GPT-4V\nachieves SOTA performance on above three tasks. Interestingly, we find that: a)\nGPT-4V demonstrates enhanced reasoning and explanation when using composite\nimages as few-shot; b) GPT-4V produces severe hallucinations when dealing with\nworld knowledge, highlighting the future need for advancements in this research\ndirection.",
            "author": [
                "Yunxin Li",
                "Longyue Wang",
                "Baotian Hu",
                "Xinyu Chen",
                "Wanqi Zhong",
                "Chenyang Lyu",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07536v1",
                "http://arxiv.org/pdf/2311.07536v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07535v1",
            "title": "Causality Diagrams using Hybrid Vector Clocks",
            "updated": "2023-11-13T18:22:16Z",
            "published": "2023-11-13T18:22:16Z",
            "summary": "Causality in distributed systems is a concept that has long been explored and\nnumerous approaches have been made to use causality as a way to trace\ndistributed system execution. Traditional approaches usually used system\nprofiling and newer approaches profiled clocks of systems to detect failures\nand construct timelines that caused those failures. Since the advent of logical\nclocks, these profiles have become more and more accurate with ways to\ncharacterize concurrency and distributions, with accurate diagrams for message\npassing. Vector clocks addressed the shortcomings of using traditional logical\nclocks, by storing information about other processes in the system as well.\nHybrid vector clocks are a novel approach to this concept where clocks need not\nstore all the process information. Rather, we store information of processes\nwithin an acceptable skew of the focused process. This gives us an efficient\nway of profiling with substantially reduced costs to the system. Building on\nthis idea, we propose the idea of building causal traces using information\ngenerated from the hybrid vector clock. The hybrid vector clock would provide\nus with a strong sense of concurrency and distribution, and we theorize that\nall the information generated from the clock is sufficient to develop a causal\ntrace for debugging. We post-process and parse the clocks generated from an\nexecution trace to develop a swimlane on a web interface, that traces the\npoints of failure of a distributed system. We also provide an API to reuse this\nconcept for any generic distributed system framework.",
            "author": [
                "Ishaan Lagwankar",
                "Kanishka Wijewardena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07535v1",
                "http://arxiv.org/pdf/2311.07535v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07534v2",
            "title": "Unsupervised Musical Object Discovery from Audio",
            "updated": "2023-11-14T08:15:25Z",
            "published": "2023-11-13T18:21:33Z",
            "summary": "Current object-centric learning models such as the popular SlotAttention\narchitecture allow for unsupervised visual scene decomposition. Our novel\nMusicSlots method adapts SlotAttention to the audio domain, to achieve\nunsupervised music decomposition. Since concepts of opacity and occlusion in\nvision have no auditory analogues, the softmax normalization of alpha masks in\nthe decoders of visual object-centric models is not well-suited for decomposing\naudio objects. MusicSlots overcomes this problem. We introduce a\nspectrogram-based multi-object music dataset tailored to evaluate\nobject-centric learning on western tonal music. MusicSlots achieves good\nperformance on unsupervised note discovery and outperforms several established\nbaselines on supervised note property prediction tasks.",
            "author": [
                "Joonsu Gha",
                "Vincent Herrmann",
                "Benjamin Grewe",
                "J\u00fcrgen Schmidhuber",
                "Anand Gopalakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07534v2",
                "http://arxiv.org/pdf/2311.07534v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07532v1",
            "title": "It's Not Easy Being Wrong: Evaluating Process of Elimination Reasoning\n  in Large Language Models",
            "updated": "2023-11-13T18:18:22Z",
            "published": "2023-11-13T18:18:22Z",
            "summary": "Chain-of-thought (COT) prompting can help large language models (LLMs) reason\ntoward correct answers, but its efficacy in reasoning toward incorrect answers\nis unexplored. This strategy of process of elimination (PoE), when used with\nCOT, has the potential to enhance interpretability in tasks like medical\ndiagnoses of exclusion. Thus, we propose PoE with COT, a new task where LLMs\nmust reason toward incorrect options on multiple-choice questions. We evaluate\nthe ability of GPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on 2-choice\ncommonsense and scientific reasoning datasets. We show that PoE consistently\nunderperforms directly choosing the correct answer. The agreement of these\nstrategies is also lower than the self-consistency of each strategy. To study\nthese issues further, we conduct an error analysis and give suggestions for\nfuture work.",
            "author": [
                "Nishant Balepur",
                "Shramay Palta",
                "Rachel Rudinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07532v1",
                "http://arxiv.org/pdf/2311.07532v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07520v1",
            "title": "Dynamic mode decomposition of nonequilibrium electron-phonon dynamics:\n  accelerating the first-principles real-time Boltzmann equation",
            "updated": "2023-11-13T18:00:30Z",
            "published": "2023-11-13T18:00:30Z",
            "summary": "Nonequilibrium dynamics governed by electron-phonon (e-ph) interactions plays\na key role in electronic devices and spectroscopies and is central to\nunderstanding electronic excitations in materials. The real-time Boltzmann\ntransport equation (rt-BTE) with collision processes computed from first\nprinciples can describe the coupled dynamics of electrons and atomic vibrations\n(phonons). Yet, a bottleneck of these simulations is the calculation of e-ph\nscattering integrals on dense momentum grids at each time step. Here we show a\ndata-driven approach based on dynamic mode decomposition (DMD) that can\naccelerate the time propagation of the rt-BTE and identify dominant electronic\nprocesses. We apply this approach to two case studies, high-field charge\ntransport and ultrafast excited electron relaxation. In both cases, simulating\nonly a short time window of ~10% of the dynamics suffices to predict the\ndynamics from initial excitation to steady state using DMD extrapolation.\nAnalysis of the momentum-space modes extracted from DMD sheds light on the\nmicroscopic mechanisms governing electron relaxation to steady state or\nequilibrium. The combination of accuracy and efficiency makes our DMD-based\nmethod a valuable tool for investigating ultrafast dynamics in a wide range of\nmaterials.",
            "author": [
                "Ivan Maliyov",
                "Jia Yin",
                "Jia Yao",
                "Chao Yang",
                "Marco Bernardi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07520v1",
                "http://arxiv.org/pdf/2311.07520v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07514v1",
            "title": "VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search",
            "updated": "2023-11-13T17:56:54Z",
            "published": "2023-11-13T17:56:54Z",
            "summary": "Text-based Person Search (TBPS) aims to retrieve images of target pedestrian\nindicated by textual descriptions. It is essential for TBPS to extract\nfine-grained local features and align them crossing modality. Existing methods\nutilize external tools or heavy cross-modal interaction to achieve explicit\nalignment of cross-modal fine-grained features, which is inefficient and\ntime-consuming. In this work, we propose a Vision-Guided Semantic-Group Network\n(VGSG) for text-based person search to extract well-aligned fine-grained visual\nand textual features. In the proposed VGSG, we develop a Semantic-Group Textual\nLearning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to\nextract textual local features under the guidance of visual local clues. In\nSGTL, in order to obtain the local textual representation, we group textual\nfeatures from the channel dimension based on the semantic cues of language\nexpression, which encourages similar semantic patterns to be grouped implicitly\nwithout external tools. In VGKT, a vision-guided attention is employed to\nextract visual-related textual features, which are inherently aligned with\nvisual cues and termed vision-guided textual features. Furthermore, we design a\nrelational knowledge transfer, including a vision-language similarity transfer\nand a class probability transfer, to adaptively propagate information of the\nvision-guided textual features to semantic-group textual features. With the\nhelp of relational knowledge transfer, VGKT is capable of aligning\nsemantic-group textual features with corresponding visual features without\nexternal tools and complex pairwise interaction. Experimental results on two\nchallenging benchmarks demonstrate its superiority over state-of-the-art\nmethods.",
            "author": [
                "Shuting He",
                "Hao Luo",
                "Wei Jiang",
                "Xudong Jiang",
                "Henghui Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07514v1",
                "http://arxiv.org/pdf/2311.07514v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07513v1",
            "title": "A Hypothesis on Good Practices for AI-based Systems for Financial Time\n  Series Forecasting: Towards Domain-Driven XAI Methods",
            "updated": "2023-11-13T17:56:45Z",
            "published": "2023-11-13T17:56:45Z",
            "summary": "Machine learning and deep learning have become increasingly prevalent in\nfinancial prediction and forecasting tasks, offering advantages such as\nenhanced customer experience, democratising financial services, improving\nconsumer protection, and enhancing risk management. However, these complex\nmodels often lack transparency and interpretability, making them challenging to\nuse in sensitive domains like finance. This has led to the rise of eXplainable\nArtificial Intelligence (XAI) methods aimed at creating models that are easily\nunderstood by humans. Classical XAI methods, such as LIME and SHAP, have been\ndeveloped to provide explanations for complex models. While these methods have\nmade significant contributions, they also have limitations, including\ncomputational complexity, inherent model bias, sensitivity to data sampling,\nand challenges in dealing with feature dependence. In this context, this paper\nexplores good practices for deploying explainability in AI-based systems for\nfinance, emphasising the importance of data quality, audience-specific methods,\nconsideration of data properties, and the stability of explanations. These\npractices aim to address the unique challenges and requirements of the\nfinancial industry and guide the development of effective XAI tools.",
            "author": [
                "Branka Hadji Misheva",
                "Joerg Osterrieder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07513v1",
                "http://arxiv.org/pdf/2311.07513v1"
            ],
            "primary_category": "q-fin.GN",
            "category": [
                "q-fin.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07509v1",
            "title": "A Benchmark to Understand the Role of Knowledge Graphs on Large Language\n  Model's Accuracy for Question Answering on Enterprise SQL Databases",
            "updated": "2023-11-13T17:54:50Z",
            "published": "2023-11-13T17:54:50Z",
            "summary": "Enterprise applications of Large Language Models (LLMs) hold promise for\nquestion answering on enterprise SQL databases. However, the extent to which\nLLMs can accurately respond to enterprise questions in such databases remains\nunclear, given the absence of suitable Text-to-SQL benchmarks tailored to\nenterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to\nenhance LLM-based question answering by providing business context is not well\nunderstood. This study aims to evaluate the accuracy of LLM-powered question\nanswering systems in the context of enterprise questions and SQL databases,\nwhile also exploring the role of knowledge graphs in improving accuracy. To\nachieve this, we introduce a benchmark comprising an enterprise SQL schema in\nthe insurance domain, a range of enterprise queries encompassing reporting to\nmetrics, and a contextual layer incorporating an ontology and mappings that\ndefine a knowledge graph. Our primary finding reveals that question answering\nusing GPT-4, with zero-shot prompts directly on SQL databases, achieves an\naccuracy of 16%. Notably, this accuracy increases to 54% when questions are\nposed over a Knowledge Graph representation of the enterprise SQL database.\nTherefore, investing in Knowledge Graph provides higher accuracy for LLM\npowered question answering systems.",
            "author": [
                "Juan Sequeda",
                "Dean Allemang",
                "Bryon Jacob"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07509v1",
                "http://arxiv.org/pdf/2311.07509v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07508v1",
            "title": "Limiting Current on Periodic Electron Sheets in a Planar Diode",
            "updated": "2023-11-13T17:54:00Z",
            "published": "2023-11-13T17:54:00Z",
            "summary": "We consider the steady state limiting current that can be carried by an\ninfinite periodic array of thin electron sheets spaced by period p in a planar\ndiode of gap voltage V and gap separation d. Our primary assumptions are (1)\nelectron motion is restricted by an infinite magnetic field to the direction\nnormal to the electrode surfaces, (2) all electrons are emitted from the\ncathode with initial kinetic energy Ein, and (3) electron motion is\nnon-relativistic. The limiting current density, averaged over a period and\nnormalized to the classical 1D Child-Langmuir (CL) current density (including a\nfactor that accounts for non-zero Ein), is found to depend only on the two\ndimensionless parameters p/d and Ein/eV. This average limiting current density\nis computed from the maximum current density for which the iterative solution\nof a non-linear integral equation converges. Numerical results and empirical\ncurve fits for the limiting current are presented, together with an analysis as\np/d and Ein/eV approach zero or infinity, in which cases previously published\nresults are recovered. Our main finding is that, while the local anode current\ndensity within each electron sheet is infinite in our model (that is, it\nexceeds the classical 1D CL value by an 'infinite' factor), the period average\nanode current density is in fact still bounded by the classical 1D CL value.\nThis study therefore provides further evidence that the classical 1D\nChild-Langmuir current density is truly a fundamental limit that cannot be\ncircumvented.",
            "author": [
                "David Chernin",
                "Dion Li",
                "Y. Y. Lau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07508v1",
                "http://arxiv.org/pdf/2311.07508v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07507v2",
            "title": "Scalar curvature for metric spaces: Defining curvature for Quantum\n  Gravity without coordinates",
            "updated": "2023-11-14T14:43:31Z",
            "published": "2023-11-13T17:53:26Z",
            "summary": "Geometrical properties of spacetime are difficult to study in nonperturbative\napproaches to quantum gravity like Causal Dynamical Triangulations (CDT), where\none uses simplicial manifolds to define the gravitational path integral,\ninstead of Riemannian manifolds. In particular, in CDT one only relies on two\nmathematical tools, a distance measure and a volume measure. In this paper, we\ndefine a notion of scalar curvature, for metric spaces endowed with a volume\nmeasure or a random walk, without assuming nor using notions of tensor\ncalculus. Furthermore, we directly define the Ricci scalar, without the need of\ndefining and computing the Riemann or the Ricci tensor a priori. For this, we\nmake use of quantities, like the surface of a geodesic sphere, or the return\nprobability of scalar diffusion processes, that can be computed in these metric\nspaces, as in a Riemannian manifold, where they receive scalar curvature\ncontributions. Our definitions recover the classical results of scalar\ncurvature when the sets are Riemannian manifolds. We propose seven methods to\ncompute the scalar curvature in these spaces, and we compare their features in\nnatural implementations in discrete spaces. The defined generalized scalar\ncurvatures are easily implemented on discrete spaces, like graphs. We present\nthe results of our definitions on random triangulations of a 2D sphere and\nplane. Additionally, we show the results of our generalized scalar curvatures\non the quantum geometries of 2D CDT, where we find that all our definitions\nindicate a flat ground state of the gravitational path integral.",
            "author": [
                "Agust\u00edn Silva",
                "Jesse van der Duin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07507v2",
                "http://arxiv.org/pdf/2311.07507v2"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02984v1",
            "title": "Diff-GO: Diffusion Goal-Oriented Communications to Achieve Ultra-High\n  Spectrum Efficiency",
            "updated": "2023-11-13T17:52:44Z",
            "published": "2023-11-13T17:52:44Z",
            "summary": "The latest advances in artificial intelligence (AI) present many\nunprecedented opportunities to achieve much improved bandwidth saving in\ncommunications. Unlike conventional communication systems focusing on packet\ntransport, rich datasets and AI makes it possible to efficiently transfer only\nthe information most critical to the goals of message recipients. One of the\nmost exciting advances in generative AI known as diffusion model presents a\nunique opportunity for designing ultra-fast communication systems well beyond\nlanguage-based messages. This work presents an ultra-efficient communication\ndesign by utilizing generative AI-based on diffusion models as a specific\nexample of the general goal-oriented communication framework. To better control\nthe regenerated message at the receiver output, our diffusion system design\nincludes a local regeneration module with finite dimensional noise latent. The\ncritical significance of noise latent control and sharing residing on our\nDiff-GO is the ability to introduce the concept of \"local generative feedback\"\n(Local-GF), which enables the transmitter to monitor the quality and gauge the\nquality or accuracy of the message recovery at the semantic system receiver. To\nthis end, we propose a new low-dimensional noise space for the training of\ndiffusion models, which significantly reduces the communication overhead and\nachieves satisfactory message recovery performance. Our experimental results\ndemonstrate that the proposed noise space and the diffusion-based generative\nmodel achieve ultra-high spectrum efficiency and accurate recovery of\ntransmitted image signals. By trading off computation for bandwidth efficiency\n(C4BE), this new framework provides an important avenue to achieve exceptional\ncomputation-bandwidth tradeoff.",
            "author": [
                "Achintha Wijesinghe",
                "Songyang Zhang",
                "Suchinthaka Wanninayaka",
                "Weiwei Wang",
                "Zhi Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02984v1",
                "http://arxiv.org/pdf/2312.02984v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.MM",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07506v1",
            "title": "Provably Efficient Learning of Phases of Matter via Dissipative\n  Evolutions",
            "updated": "2023-11-13T17:50:18Z",
            "published": "2023-11-13T17:50:18Z",
            "summary": "The combination of quantum many-body and machine learning techniques has\nrecently proved to be a fertile ground for new developments in quantum\ncomputing. Several works have shown that it is possible to classically\nefficiently predict the expectation values of local observables on all states\nwithin a phase of matter using a machine learning algorithm after learning from\ndata obtained from other states in the same phase. However, existing results\nare restricted to phases of matter such as ground states of gapped Hamiltonians\nand Gibbs states that exhibit exponential decay of correlations. In this work,\nwe drop this requirement and show how it is possible to learn local expectation\nvalues for all states in a phase, where we adopt the Lindbladian phase\ndefinition by Coser \\& P\\'erez-Garc\\'ia [Coser \\& P\\'erez-Garc\\'ia, Quantum 3,\n174 (2019)], which defines states to be in the same phase if we can drive one\nto other rapidly with a local Lindbladian. This definition encompasses the\nbetter-known Hamiltonian definition of phase of matter for gapped ground state\nphases, and further applies to any family of states connected by short unitary\ncircuits, as well as non-equilibrium phases of matter, and those stable under\nexternal dissipative interactions. Under this definition, we show that $N =\nO(\\log(n/\\delta)2^{polylog(1/\\epsilon)})$ samples suffice to learn local\nexpectation values within a phase for a system with $n$ qubits, to error\n$\\epsilon$ with failure probability $\\delta$. This sample complexity is\ncomparable to previous results on learning gapped and thermal phases, and it\nencompasses previous results of this nature in a unified way. Furthermore, we\nalso show that we can learn families of states which go beyond the Lindbladian\ndefinition of phase, and we derive bounds on the sample complexity which are\ndependent on the mixing time between states under a Lindbladian evolution.",
            "author": [
                "Emilio Onorati",
                "Cambyse Rouz\u00e9",
                "Daniel Stilck Fran\u00e7a",
                "James D. Watson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07506v1",
                "http://arxiv.org/pdf/2311.07506v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07504v1",
            "title": "STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using\n  SMOTE, Edited Nearest Neighbour, and Mixup",
            "updated": "2023-11-13T17:45:28Z",
            "published": "2023-11-13T17:45:28Z",
            "summary": "Imbalanced datasets in medical imaging are characterized by skewed class\nproportions and scarcity of abnormal cases. When trained using such data,\nmodels tend to assign higher probabilities to normal cases, leading to biased\nperformance. Common oversampling techniques such as SMOTE rely on local\ninformation and can introduce marginalization issues. This paper investigates\nthe potential of using Mixup augmentation that combines two training examples\nalong with their corresponding labels to generate new data points as a generic\nvicinal distribution. To this end, we propose STEM, which combines SMOTE-ENN\nand Mixup at the instance level. This integration enables us to effectively\nleverage the entire distribution of minority classes, thereby mitigating both\nbetween-class and within-class imbalances. We focus on the breast cancer\nproblem, where imbalanced datasets are prevalent. The results demonstrate the\neffectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the\nDigital Database for Screening Mammography and Wisconsin Breast Cancer\n(Diagnostics) datasets, respectively. Moreover, this method shows promising\npotential when applied with an ensemble of machine learning (ML) classifiers.",
            "author": [
                "Yumnah Hasan",
                "Fatemeh Amerehi",
                "Patrick Healy",
                "Conor Ryan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07504v1",
                "http://arxiv.org/pdf/2311.07504v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07498v1",
            "title": "Reducing the Need for Backpropagation and Discovering Better Optima With\n  Explicit Optimizations of Neural Networks",
            "updated": "2023-11-13T17:38:07Z",
            "published": "2023-11-13T17:38:07Z",
            "summary": "Iterative differential approximation methods that rely upon backpropagation\nhave enabled the optimization of neural networks; however, at present, they\nremain computationally expensive, especially when training models at scale. In\nthis paper, we propose a computationally efficient alternative for optimizing\nneural networks that can both reduce the costs of scaling neural networks and\nprovide high-efficiency optimizations for low-resource applications. We derive\nan explicit solution to a simple feed-forward language model (LM) by\nmathematically analyzing its gradients. This solution generalizes from\nsingle-layer LMs to the class of all single-layer feed-forward\nsoftmax-activated neural models trained on positive-valued features, as is\ndemonstrated by our extension of this solution application to MNIST digit\nclassification. For both LM and digit classifiers, we find computationally that\nexplicit solutions perform near-optimality in experiments showing that 1)\niterative optimization only marginally improves the explicit solution\nparameters and 2) randomly initialized parameters iteratively optimize towards\nthe explicit solution. We also preliminarily apply the explicit solution\nlocally by layer in multi-layer networks and discuss how the solution's\ncomputational savings increase with model complexity -- for both single- and\nmult-layer applications of the explicit solution, we emphasize that the optima\nachieved cannot be reached by backpropagation alone, i.e., better optima appear\ndiscoverable only after explicit solutions are applied. Finally, we discuss the\nsolution's computational savings alongside its impact on model interpretability\nand suggest future directions for the derivation of explicit solutions to\ncomplex- and multi-layer architectures.",
            "author": [
                "Jake Ryland Williams",
                "Haoran Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07498v1",
                "http://arxiv.org/pdf/2311.07498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "physics.data-an",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07497v1",
            "title": "Multilingual Nonce Dependency Treebanks: Understanding how LLMs\n  represent and process syntactic structure",
            "updated": "2023-11-13T17:36:58Z",
            "published": "2023-11-13T17:36:58Z",
            "summary": "We introduce SPUD (Semantically Perturbed Universal Dependencies), a\nframework for creating nonce treebanks for the multilingual Universal\nDependencies (UD) corpora. SPUD data satisfies syntactic argument structure,\nprovides syntactic annotations, and ensures grammaticality via\nlanguage-specific rules. We create nonce data in Arabic, English, French,\nGerman, and Russian, and demonstrate two use cases of SPUD treebanks. First, we\ninvestigate the effect of nonce data on word co-occurrence statistics, as\nmeasured by perplexity scores of autoregressive (ALM) and masked language\nmodels (MLM). We find that ALM scores are significantly more affected by nonce\ndata than MLM scores. Second, we show how nonce data affects the performance of\nsyntactic dependency probes. We replicate the findings of M\\\"uller-Eberstein et\nal. (2022) on nonce test data and show that the performance declines on both\nMLMs and ALMs wrt. original test data. However, a majority of the performance\nis kept, suggesting that the probe indeed learns syntax independently from\nsemantics.",
            "author": [
                "David Arps",
                "Laura Kallmeyer",
                "Younes Samih",
                "Hassan Sajjad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07497v1",
                "http://arxiv.org/pdf/2311.07497v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07492v1",
            "title": "How Physicality Enables Trust: A New Era of Trust-Centered Cyberphysical\n  Systems",
            "updated": "2023-11-13T17:28:57Z",
            "published": "2023-11-13T17:28:57Z",
            "summary": "Multi-agent cyberphysical systems enable new capabilities in efficiency,\nresilience, and security. The unique characteristics of these systems prompt a\nreevaluation of their security concepts, including their vulnerabilities, and\nmechanisms to mitigate these vulnerabilities. This survey paper examines how\nadvancement in wireless networking, coupled with the sensing and computing in\ncyberphysical systems, can foster novel security capabilities. This study\ndelves into three main themes related to securing multi-agent cyberphysical\nsystems. First, we discuss the threats that are particularly relevant to\nmulti-agent cyberphysical systems given the potential lack of trust between\nagents. Second, we present prospects for sensing, contextual awareness, and\nauthentication, enabling the inference and measurement of ``inter-agent trust\"\nfor these systems. Third, we elaborate on the application of quantifiable trust\nnotions to enable ``resilient coordination,\" where ``resilient\" signifies\nsustained functionality amid attacks on multiagent cyberphysical systems. We\nrefer to the capability of cyberphysical systems to self-organize, and\ncoordinate to achieve a task as autonomy. This survey unveils the cyberphysical\ncharacter of future interconnected systems as a pivotal catalyst for realizing\nrobust, trust-centered autonomy in tomorrow's world.",
            "author": [
                "Stephanie Gil",
                "Michal Yemini",
                "Arsenia Chorti",
                "Angelia Nedi\u0107",
                "H. Vincent Poor",
                "Andrea J. Goldsmith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07492v1",
                "http://arxiv.org/pdf/2311.07492v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA",
                "cs.NI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07491v1",
            "title": "A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question\n  Decomposition with Large Language Models",
            "updated": "2023-11-13T17:28:03Z",
            "published": "2023-11-13T17:28:03Z",
            "summary": "While large language models exhibit remarkable performance in the Question\nAnswering task, they are susceptible to hallucinations. Challenges arise when\nthese models grapple with understanding multi-hop relations in complex\nquestions or lack the necessary knowledge for a comprehensive response. To\naddress this issue, we introduce the \"Decompose-and-Query\" framework (D&Q).\nThis framework guides the model to think and utilize external knowledge similar\nto ReAct, while also restricting its thinking to reliable information,\neffectively mitigating the risk of hallucinations. Experiments confirm the\neffectiveness of D&Q: On our ChitChatQA dataset, D&Q does not lose to ChatGPT\nin 67% of cases; on the HotPotQA question-only setting, D&Q achieved an F1\nscore of 59.6%. Our code is available at\nhttps://github.com/alkaidpku/DQ-ToolQA.",
            "author": [
                "Hejing Cao",
                "Zhenwei An",
                "Jiazhan Feng",
                "Kun Xu",
                "Liwei Chen",
                "Dongyan Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07491v1",
                "http://arxiv.org/pdf/2311.07491v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07490v1",
            "title": "A Guide to Evaluating the Experience of Media and Arts Technology",
            "updated": "2023-11-13T17:28:01Z",
            "published": "2023-11-13T17:28:01Z",
            "summary": "Evaluation is essential to understanding the value that digital creativity\nbrings to people's experience, for example in terms of their enjoyment,\ncreativity, and engagement. There is a substantial body of research on how to\ndesign and evaluate interactive arts and digital creativity applications. There\nis also extensive Human-Computer Interaction (HCI) literature on how to\nevaluate user interfaces and user experiences. However, it can be difficult for\nartists, practitioners, and researchers to navigate such a broad and disparate\ncollection of materials when considering how to evaluate technology they create\nthat is at the intersection of art and interaction. This chapter provides a\nguide to designing robust user studies of creative applications at the\nintersection of art, technology and interaction, which we refer to as Media and\nArts Technology (MAT). We break MAT studies down into two main kinds:\nproof-of-concept and comparative studies. As MAT studies are exploratory in\nnature, their evaluation requires the collection and analysis of both\nqualitative data such as free text questionnaire responses, interviews, and\nobservations, and also quantitative data such as questionnaires, number of\ninteractions, and length of time spent interacting. This chapter draws on over\n15 years of experience of designing and evaluating novel interactive systems to\nprovide a concrete template on how to structure a study to evaluate MATs that\nis both rigorous and repeatable, and how to report study results that are\npublishable and accessible to a wide readership in art and science communities\nalike.",
            "author": [
                "Nick Bryan-Kinns",
                "Courtney N. Reed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07490v1",
                "http://arxiv.org/pdf/2311.07490v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07485v1",
            "title": "EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient\n  Federated Learning",
            "updated": "2023-11-13T17:25:06Z",
            "published": "2023-11-13T17:25:06Z",
            "summary": "Federated Learning (FL) is a decentralized machine learning paradigm that\nenables collaborative model training across dispersed nodes without having to\nforce individual nodes to share data. However, its broad adoption is hindered\nby the high communication costs of transmitting a large number of model\nparameters. This paper presents EvoFed, a novel approach that integrates\nEvolutionary Strategies (ES) with FL to address these challenges. EvoFed\nemploys a concept of 'fitness-based information sharing', deviating\nsignificantly from the conventional model-based FL. Rather than exchanging the\nactual updated model parameters, each node transmits a distance-based\nsimilarity measure between the locally updated model and each member of the\nnoise-perturbed model population. Each node, as well as the server, generates\nan identical population set of perturbed models in a completely synchronized\nfashion using the same random seeds. With properly chosen noise variance and\npopulation size, perturbed models can be combined to closely reflect the actual\nmodel updated using the local dataset, allowing the transmitted similarity\nmeasures (or fitness values) to carry nearly the complete information about the\nmodel parameters. As the population size is typically much smaller than the\nnumber of model parameters, the savings in communication load is large. The\nserver aggregates these fitness values and is able to update the global model.\nThis global fitness vector is then disseminated back to the nodes, each of\nwhich applies the same update to be synchronized to the global model. Our\nanalysis shows that EvoFed converges, and our experimental results validate\nthat at the cost of increased local processing loads, EvoFed achieves\nperformance comparable to FedAvg while reducing overall communication\nrequirements drastically in various practical settings.",
            "author": [
                "Mohammad Mahdi Rahimi",
                "Hasnain Irshad Bhatti",
                "Younghyun Park",
                "Humaira Kousar",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07485v1",
                "http://arxiv.org/pdf/2311.07485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07484v1",
            "title": "Psychometric Predictive Power of Large Language Models",
            "updated": "2023-11-13T17:19:14Z",
            "published": "2023-11-13T17:19:14Z",
            "summary": "Next-word probabilities from language models have been shown to successfully\nsimulate human reading behavior. Building on this, we show that, interestingly,\ninstruction-tuned large language models (LLMs) yield worse psychometric\npredictive power (PPP) for human reading behavior than base LLMs with\nequivalent perplexities. In other words, instruction tuning, which helps LLMs\nprovide human-preferred responses, does not always make them human-like from\nthe computational psycholinguistics perspective. In addition, we explore\nprompting methodologies in simulating human reading behavior with LLMs, showing\nthat prompts reflecting a particular linguistic hypothesis lead LLMs to exhibit\nbetter PPP but are still worse than base LLMs. These highlight that recent\ninstruction tuning and prompting do not offer better estimates than direct\nprobability measurements from base LLMs in cognitive modeling.",
            "author": [
                "Tatsuki Kuribayashi",
                "Yohei Oseki",
                "Timothy Baldwin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07484v1",
                "http://arxiv.org/pdf/2311.07484v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07477v1",
            "title": "Temporal Performance Prediction for Deep Convolutional Long Short-Term\n  Memory Networks",
            "updated": "2023-11-13T17:11:35Z",
            "published": "2023-11-13T17:11:35Z",
            "summary": "Quantifying predictive uncertainty of deep semantic segmentation networks is\nessential in safety-critical tasks. In applications like autonomous driving,\nwhere video data is available, convolutional long short-term memory networks\nare capable of not only providing semantic segmentations but also predicting\nthe segmentations of the next timesteps. These models use cell states to\nbroadcast information from previous data by taking a time series of inputs to\npredict one or even further steps into the future. We present a temporal\npostprocessing method which estimates the prediction performance of\nconvolutional long short-term memory networks by either predicting the\nintersection over union of predicted and ground truth segments or classifying\nbetween intersection over union being equal to zero or greater than zero. To\nthis end, we create temporal cell state-based input metrics per segment and\ninvestigate different models for the estimation of the predictive quality based\non these metrics. We further study the influence of the number of considered\ncell states for the proposed metrics.",
            "author": [
                "Laura Fieback",
                "Bidya Dash",
                "Jakob Spiegelberg",
                "Hanno Gottschalk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07477v1",
                "http://arxiv.org/pdf/2311.07477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07475v1",
            "title": "Masked Face Dataset Generation and Masked Face Recognition",
            "updated": "2023-11-13T17:09:57Z",
            "published": "2023-11-13T17:09:57Z",
            "summary": "In the post-pandemic era, wearing face masks has posed great challenge to the\nordinary face recognition. In the previous study, researchers has applied\npretrained VGG16, and ResNet50 to extract features on the elaborate curated\nexisting masked face recognition (MFR) datasets, RMFRD and SMFRD. To make the\nmodel more adaptable to the real world situation where the sample size is\nsmaller and the camera environment has greater changes, we created a more\nchallenging masked face dataset ourselves, by selecting 50 identities with 1702\nimages from Labelled Faces in the Wild (LFW) Dataset, and simulated face masks\nthrough key point detection. The another part of our study is to solve the\nmasked face recognition problem, and we chose models by referring to the former\nstate of the art results, instead of directly using pretrained models, we fine\ntuned the model on our new dataset and use the last linear layer to do the\nclassification directly. Furthermore, we proposed using data augmentation\nstrategy to further increase the test accuracy, and fine tuned a new networks\nbeyond the former study, one of the most SOTA networks, Inception ResNet v1.\nThe best test accuracy on 50 identity MFR has achieved 95%.",
            "author": [
                "Rui Cai",
                "Xuying Ning",
                "Peter N. Belhumeur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07475v1",
                "http://arxiv.org/pdf/2311.07475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07473v1",
            "title": "Temperature effects in topological insulators of transition metal\n  dichalcogenide monolayers",
            "updated": "2023-11-13T17:08:26Z",
            "published": "2023-11-13T17:08:26Z",
            "summary": "We investigate the role of temperature on the topological insulating state of\nmetal dichalcogenide monolayers, 1T$^\\prime$-MX$_2$ (M=W, Mo and X=S, Se).\nUsing first principles calculations based on density functional theory, we\nconsider three temperature-related contributions to the topological band gap:\nelectrons coupling with short-wavelength phonons, with long-wavelength phonons\n\\textit{via} Fr\\\"ohlich coupling, and thermal expansion. We find that\nelectron-phonon coupling promotes the topology of the electronic structures of\nall 1T$^\\prime$-MX$_2$ monolayers, while thermal expansion acts as a\ncounteracting effect. Additionally, we derive the band renormalization from\nFr\\\"ohlich coupling in the two-dimensional context and observe its relatively\nmodest contribution to 1T$^\\prime$-MX$_2$ monolayers. Finally, we present a\nsimplified physical picture to understand the \"inverse Varshni\" effect driven\nby band inversion in topological insulators. Our work reveals that, among the\nfour 1T$^\\prime$-MX$_2$ studied monolayers, MoSe$_2$ is a promising candidate\nfor room temperature applications as its band gap displays remarkable\nresilience against thermal expansion, while the topological order of WS$_2$ can\nbe tuned under the combined influence of strain and temperature. Both materials\nrepresent novel examples of temperature promoted topological insulators.",
            "author": [
                "Siyu Chen",
                "Isaac J. Parker",
                "Bartomeu Monserrat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07473v1",
                "http://arxiv.org/pdf/2311.07473v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "cond-mat.other",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07470v1",
            "title": "Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer",
            "updated": "2023-11-13T17:03:02Z",
            "published": "2023-11-13T17:03:02Z",
            "summary": "Multi-modal large language models (LLM) have achieved powerful capabilities\nfor visual semantic understanding in recent years. However, little is known\nabout how LLMs comprehend visual information and interpret different modalities\nof features. In this paper, we propose a new method for identifying multi-modal\nneurons in transformer-based multi-modal LLMs. Through a series of experiments,\nWe highlight three critical properties of multi-modal neurons by four\nwell-designed quantitative evaluation metrics. Furthermore, we introduce a\nknowledge editing method based on the identified multi-modal neurons, for\nmodifying a specific token to another designative token. We hope our findings\ncan inspire further explanatory researches on understanding mechanisms of\nmulti-modal LLMs.",
            "author": [
                "Haowen Pan",
                "Yixin Cao",
                "Xiaozhi Wang",
                "Xun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07470v1",
                "http://arxiv.org/pdf/2311.07470v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07469v2",
            "title": "InCA: Rethinking In-Car Conversational System Assessment Leveraging\n  Large Language Models",
            "updated": "2023-11-15T22:10:34Z",
            "published": "2023-11-13T17:02:06Z",
            "summary": "The assessment of advanced generative large language models (LLMs) poses a\nsignificant challenge, given their heightened complexity in recent\ndevelopments. Furthermore, evaluating the performance of LLM-based applications\nin various industries, as indicated by Key Performance Indicators (KPIs), is a\ncomplex undertaking. This task necessitates a profound understanding of\nindustry use cases and the anticipated system behavior. Within the context of\nthe automotive industry, existing evaluation metrics prove inadequate for\nassessing in-car conversational question answering (ConvQA) systems. The unique\ndemands of these systems, where answers may relate to driver or car safety and\nare confined within the car domain, highlight the limitations of current\nmetrics. To address these challenges, this paper introduces a set of KPIs\ntailored for evaluating the performance of in-car ConvQA systems, along with\ndatasets specifically designed for these KPIs. A preliminary and comprehensive\nempirical evaluation substantiates the efficacy of our proposed approach.\nFurthermore, we investigate the impact of employing varied personas in prompts\nand found that it enhances the model's capacity to simulate diverse viewpoints\nin assessments, mirroring how individuals with different backgrounds perceive a\ntopic.",
            "author": [
                "Ken E. Friedl",
                "Abbas Goher Khan",
                "Soumya Ranjan Sahoo",
                "Md Rashad Al Hasan Rony",
                "Jana Germies",
                "Christian S\u00fc\u00df"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07469v2",
                "http://arxiv.org/pdf/2311.07469v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07468v2",
            "title": "Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation\n  of the Reversal Curse",
            "updated": "2023-11-16T08:35:05Z",
            "published": "2023-11-13T17:01:12Z",
            "summary": "Recent studies have highlighted a phenomenon in large language models (LLMs)\nknown as \"the reversal curse,\" in which the order of knowledge entities in the\ntraining data biases the models' comprehension. For example, if a model is\ntrained on sentences where entity A consistently appears before entity B, it\ncan respond to queries about A by providing B as the answer. However, it may\nencounter confusion when presented with questions concerning B. We contend that\nthe reversal curse is partially a result of specific model training objectives,\nparticularly evident in the prevalent use of the next-token prediction within\nmost causal language models. For the next-token prediction, models solely focus\non a token's preceding context, resulting in a restricted comprehension of the\ninput. In contrast, we illustrate that the GLM, trained using the\nautoregressive blank infilling objective where tokens to be predicted have\naccess to the entire context, exhibits better resilience against the reversal\ncurse. We propose a novel training method, BIdirectional Casual language\nmodeling Optimization (BICO), designed to mitigate the reversal curse when\nfine-tuning pretrained causal language models on new data. BICO modifies the\ncausal attention mechanism to function bidirectionally and employs a mask\ndenoising optimization. In the task designed to assess the reversal curse, our\napproach improves Llama's accuracy from the original 0% to around 70%. We hope\nthat more attention can be focused on exploring and addressing these inherent\nweaknesses of the current LLMs, in order to achieve a higher level of\nintelligence.",
            "author": [
                "Ang Lv",
                "Kaiyi Zhang",
                "Shufang Xie",
                "Quan Tu",
                "Yuhan Chen",
                "Ji-Rong Wen",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07468v2",
                "http://arxiv.org/pdf/2311.07468v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07467v1",
            "title": "Energetic Particle Tracing in Optimized Quasisymmetric Stellarator\n  Equilibria",
            "updated": "2023-11-13T16:54:20Z",
            "published": "2023-11-13T16:54:20Z",
            "summary": "Recent developments in the design of magnetic confinement fusion devices have\nallowed the construction of exceptionally optimized stellarator configurations.\nThe near-axis expansion in particular has proven to enable the construction of\nmagnetic configurations with good confinement properties while taking only a\nfraction of the usual computation time to generate optimized magnetic\nequilibria. However, not much is known about the overall features of\nfast-particle orbits computed in such analytical, yet simplified, equilibria\nwhen compared to those originating from accurate equilibrium solutions. This\nwork aims to assess and demonstrate the potential of the near-axis expansion to\nprovide accurate information on particle orbits and to compute loss fractions\nin moderate to high aspect ratios. The configurations used here are all scaled\nto fusion-relevant parameters and approximate quasisymmetry in various degrees.\nThis allows us to understand how deviations from quasisymmetry affect particle\norbits and what are their effects on the estimation of the loss fraction.\nGuiding-center trajectories of fusion-born alpha particles are traced using\ngyronimo and SIMPLE codes under the NEAT framework, showing good numerical\nagreement. Discrepancies between near-axis and MHD fields have minor effects on\npassing particles but significant effects on trapped particles, especially in\nquasihelically symmetric magnetic fields. Effective expressions were found for\nestimating orbit widths and passing-trapped separatrix in quasisymmetric\nnear-axis fields. Loss fractions agree in the prompt losses regime but diverge\nafterward.",
            "author": [
                "P. A. Figueiredo",
                "R. Jorge",
                "J. Ferreira",
                "P. Rodrigues"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07467v1",
                "http://arxiv.org/pdf/2311.07467v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07466v1",
            "title": "On Measuring Faithfulness of Natural Language Explanations",
            "updated": "2023-11-13T16:53:51Z",
            "published": "2023-11-13T16:53:51Z",
            "summary": "Large language models (LLMs) can explain their own predictions, through\npost-hoc or Chain-of-Thought (CoT) explanations. However the LLM could make up\nreasonably sounding explanations that are unfaithful to its underlying\nreasoning. Recent work has designed tests that aim to judge the faithfulness of\neither post-hoc or CoT explanations. In this paper we argue that existing\nfaithfulness tests are not actually measuring faithfulness in terms of the\nmodels' inner workings, but only evaluate their self-consistency on the output\nlevel. The aims of our work are two-fold. i) We aim to clarify the status of\nexisting faithfulness tests in terms of model explainability, characterising\nthem as self-consistency tests instead. This assessment we underline by\nconstructing a Comparative Consistency Bank for self-consistency tests that for\nthe first time compares existing tests on a common suite of 11 open-source LLMs\nand 5 datasets -- including ii) our own proposed self-consistency measure\nCC-SHAP. CC-SHAP is a new fine-grained measure (not test) of LLM\nself-consistency that compares a model's input contributions to answer\nprediction and generated explanation. With CC-SHAP, we aim to take a step\nfurther towards measuring faithfulness with a more interpretable and\nfine-grained method. Code available at\n\\url{https://github.com/Heidelberg-NLP/CC-SHAP}",
            "author": [
                "Letitia Parcalabescu",
                "Anette Frank"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07466v1",
                "http://arxiv.org/pdf/2311.07466v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68Txx",
                "I.2.7; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07465v1",
            "title": "Computerized Tomography and Reproducing Kernels",
            "updated": "2023-11-13T16:53:38Z",
            "published": "2023-11-13T16:53:38Z",
            "summary": "The X-ray transform is one of the most fundamental integral operators in\nimage processing and reconstruction. In this article, we revisit its\nmathematical formalism, and propose an innovative approach making use of\nReproducing Kernel Hilbert Spaces (RKHS). Within this framework, the X-ray\ntransform can be considered as a natural analogue of Euclidean projections. The\nRKHS framework considerably simplifies projection image interpolation, and\nleads to an analogue of the celebrated representer theorem for the problem of\ntomographic reconstruction. It leads to methodology that is dimension-free and\nstands apart from conventional filtered back-projection techniques, as it does\nnot hinge on the Fourier transform. It also allows us to establish sharp\nstability results at a genuinely functional level, but in the realistic setting\nwhere the data are discrete and noisy. The RKHS framework is amenable to any\nreproducing kernel on a unit ball, affording a high level of generality. When\nthe kernel is chosen to be rotation-invariant, one can obtain explicit spectral\nrepresentations which elucidate the regularity structure of the associated\nHilbert spaces, and one can also solve the reconstruction problem at the same\ncomputational cost as filtered back-projection.",
            "author": [
                "Ho Yun",
                "Victor M. Panaretos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07465v1",
                "http://arxiv.org/pdf/2311.07465v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "math.ST",
                "stat.ML",
                "stat.TH",
                "44A12 (Primary), 46E22 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07463v1",
            "title": "MEGAVERSE: Benchmarking Large Language Models Across Languages,\n  Modalities, Models and Tasks",
            "updated": "2023-11-13T16:45:37Z",
            "published": "2023-11-13T16:45:37Z",
            "summary": "Recently, there has been a rapid advancement in research on Large Language\nModels (LLMs), resulting in significant progress in several Natural Language\nProcessing (NLP) tasks. Consequently, there has been a surge in LLM evaluation\nresearch to comprehend the models' capabilities and limitations. However, much\nof this research has been confined to the English language, leaving LLM\nbuilding and evaluation for non-English languages relatively unexplored. There\nhas been an introduction of several new LLMs, necessitating their evaluation on\nnon-English languages. This study aims to expand our MEGA benchmarking suite by\nincluding six new datasets to form the MEGAVERSE benchmark. The benchmark\ncomprises 22 datasets covering 81 languages, including low-resource African\nlanguages. We evaluate several state-of-the-art LLMs like GPT-3.5-Turbo, GPT4,\nPaLM2, and Llama2 on the MEGAVERSE datasets. Additionally, we include two\nmultimodal datasets in the benchmark and assess the performance of the\nLLaVa-v1.5 model. Our experiments suggest that GPT4 and PaLM2 outperform the\nLlama models on various tasks, notably on low-resource languages, with GPT4\noutperforming PaLM2 on more datasets than vice versa. However, issues such as\ndata contamination must be addressed to obtain an accurate assessment of LLM\nperformance on non-English languages.",
            "author": [
                "Sanchit Ahuja",
                "Divyanshu Aggarwal",
                "Varun Gumma",
                "Ishaan Watts",
                "Ashutosh Sathe",
                "Millicent Ochieng",
                "Rishav Hada",
                "Prachi Jain",
                "Maxamed Axmed",
                "Kalika Bali",
                "Sunayana Sitaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07463v1",
                "http://arxiv.org/pdf/2311.07463v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07462v1",
            "title": "Investigating Robustness in Cyber-Physical Systems:\n  Specification-Centric Analysis in the face of System Deviations",
            "updated": "2023-11-13T16:44:43Z",
            "published": "2023-11-13T16:44:43Z",
            "summary": "The adoption of cyber-physical systems (CPS) is on the rise in complex\nphysical environments, encompassing domains such as autonomous vehicles, the\nInternet of Things (IoT), and smart cities. A critical attribute of CPS is\nrobustness, denoting its capacity to operate safely despite potential\ndisruptions and uncertainties in the operating environment. This paper proposes\na novel specification-based robustness, which characterizes the effectiveness\nof a controller in meeting a specified system requirement, articulated through\nSignal Temporal Logic (STL) while accounting for possible deviations in the\nsystem. This paper also proposes the robustness falsification problem based on\nthe definition, which involves identifying minor deviations capable of\nviolating the specified requirement. We present an innovative two-layer\nsimulation-based analysis framework designed to identify subtle robustness\nviolations. To assess our methodology, we devise a series of benchmark problems\nwherein system parameters can be adjusted to emulate various forms of\nuncertainties and disturbances. Initial evaluations indicate that our\nfalsification approach proficiently identifies robustness violations, providing\nvaluable insights for comparing robustness between conventional and\nreinforcement learning (RL)-based controllers",
            "author": [
                "Changjian Zhang",
                "Parv Kapoor",
                "Romulo Meira-Goes",
                "David Garlan",
                "Eunsuk Kang",
                "Akila Ganlath",
                "Shatadal Mishra",
                "Nejib Ammar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07462v1",
                "http://arxiv.org/pdf/2311.07462v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LO",
                "cs.SE",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07458v1",
            "title": "Trust in Queer Human-Robot Interaction",
            "updated": "2023-11-13T16:42:21Z",
            "published": "2023-11-13T16:42:21Z",
            "summary": "Human-robot interaction (HRI) systems need to build trust with people of\ndiverse identities. This position paper argues that queer (LGBTQIA+) people\nmust be included in the design and evaluation of HRI systems to ensure their\ntrust in and acceptance of robots. Queer people have faced discrimination and\nharm from artificial intelligence and robotic systems. Despite calls for\nincreased diversity and inclusion, HRI has not systemically addressed queer\nissues. This paper suggests three approaches to address trust in queer HRI:\ndiversifying human-subject pools, centering queer people in HRI studies, and\ncontextualizing measures of trust.",
            "author": [
                "Raj Korpan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07458v1",
                "http://arxiv.org/pdf/2311.07458v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07454v1",
            "title": "Causal Discovery under Latent Class Confounding",
            "updated": "2023-11-13T16:35:34Z",
            "published": "2023-11-13T16:35:34Z",
            "summary": "Directed acyclic graphs are used to model the causal structure of a system.\n``Causal discovery'' describes the problem of learning this structure from\ndata. When data is an aggregate from multiple sources (populations or\nenvironments), global confounding obscures conditional independence properties\nthat drive many causal discovery algorithms. For this reason, existing causal\ndiscovery algorithms are not suitable for the multiple-source setting. We\ndemonstrate that, if the confounding is of bounded cardinality (i.e. the data\ncomes from a limited number of sources), causal discovery can still be\nachieved. The feasibility of this problem is governed by a trade-off between\nthe cardinality of the global confounder, the cardinalities of the observed\nvariables, and the sparsity of the causal structure.",
            "author": [
                "Bijan Mazaheri",
                "Spencer Gordon",
                "Yuval Rabani",
                "Leonard Schulman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07454v1",
                "http://arxiv.org/pdf/2311.07454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07453v1",
            "title": "ChartCheck: An Evidence-Based Fact-Checking Dataset over Real-World\n  Chart Images",
            "updated": "2023-11-13T16:35:29Z",
            "published": "2023-11-13T16:35:29Z",
            "summary": "Data visualizations are common in the real-world. We often use them in data\nsources such as scientific documents, news articles, textbooks, and social\nmedia to summarize key information in a visual form. Charts can also mislead\nits audience by communicating false information or biasing them towards a\nspecific agenda. Verifying claims against charts is not a straightforward\nprocess. It requires analyzing both the text and visual components of the\nchart, considering characteristics such as colors, positions, and orientations.\nMoreover, to determine if a claim is supported by the chart content often\nrequires different types of reasoning. To address this challenge, we introduce\nChartCheck, a novel dataset for fact-checking against chart images. ChartCheck\nis the first large-scale dataset with 1.7k real-world charts and 10.5k\nhuman-written claims and explanations. We evaluated the dataset on\nstate-of-the-art models and achieved an accuracy of 73.9 in the finetuned\nsetting. Additionally, we identified chart characteristics and reasoning types\nthat challenge the models.",
            "author": [
                "Mubashara Akhtar",
                "Nikesh Subedi",
                "Vivek Gupta",
                "Sahar Tahmasebi",
                "Oana Cocarascu",
                "Elena Simperl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07453v1",
                "http://arxiv.org/pdf/2311.07453v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07449v1",
            "title": "Language Grounded QFormer for Efficient Vision Language Understanding",
            "updated": "2023-11-13T16:30:49Z",
            "published": "2023-11-13T16:30:49Z",
            "summary": "Large-scale pretraining and instruction tuning have been successful for\ntraining general-purpose language models with broad competencies. However,\nextending to general-purpose vision-language models is challenging due to the\ndistributional diversity in visual inputs. A recent line of work explores\nvision-language instruction tuning, taking inspiration from the Query\nTransformer (QFormer) approach proposed in BLIP-2 models for bridging frozen\nmodalities. However, these approaches rely heavily on large-scale multi-modal\npretraining for representation learning before eventual finetuning, incurring a\nhuge computational overhead, poor scaling, and limited accessibility. To that\nend, we propose a more efficient method for QFormer-based vision-language\nalignment and demonstrate the effectiveness of our strategy compared to\nexisting baselines in improving the efficiency of vision-language pretraining.",
            "author": [
                "Moulik Choraria",
                "Nitesh Sekhar",
                "Yue Wu",
                "Xu Zhang",
                "Prateek Singhal",
                "Lav R. Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07449v1",
                "http://arxiv.org/pdf/2311.07449v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07448v1",
            "title": "Evolution of SLiM-mediated hijack functions in intrinsically disordered\n  viral proteins",
            "updated": "2023-11-13T16:29:22Z",
            "published": "2023-11-13T16:29:22Z",
            "summary": "Viruses and their hosts are involved in an 'arms race' where they continually\nevolve mechanisms to overcome each other. It has long been proposed that\nintrinsic disorder provides a substrate for the evolution of viral hijack\nfunctions and that short linear motifs (SLiMs) are important players in this\nprocess. Here, we review evidence in support of this tenet from two model\nsystems: the papillomavirus E7 protein and the adenovirus E1A protein.\nPhylogenetic reconstructions reveal that SLiMs appear and disappear multiple\ntimes across evolution, providing evidence of convergent evolution within\nindividual viral phylogenies. Multiple functionally related SLiMs show strong\nco-evolution signals that persist across long distances in the primary sequence\nand occur in unrelated viral proteins. Moreover, changes in SLiMs are\nassociated with changes in phenotypic traits such as host range and tropism.\nTracking viral evolutionary events reveals that host switch events are\nassociated with the loss of several SLiMs, suggesting that SLiMs are under\nfunctional selection and that changes in SLiMs support viral adaptation.\nFine-tuning of viral SLiM sequences can improve affinity, allowing them to\noutcompete host counterparts. However, viral SLiMs are not always competitive\nby themselves, and tethering of two suboptimal SLiMs by a disordered linker may\ninstead enable viral hijack. Coevolution between the SLiMs and the linker\nindicates that the evolution of disordered regions may be more constrained than\npreviously thought. In summary, experimental and computational studies support\na role for SLiMs and intrinsic disorder in viral hijack functions and in viral\nadaptive evolution.",
            "author": [
                "Juliana Glavina",
                "Nicolas Palopoli",
                "Luc\u00eda B Chemes"
            ],
            "link": [
                "http://dx.doi.org/10.1042/EBC20220059",
                "http://arxiv.org/abs/2311.07448v1",
                "http://arxiv.org/pdf/2311.07448v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14707v1",
            "title": "Knowledge Tracing Challenge: Optimal Activity Sequencing for Students",
            "updated": "2023-11-13T16:28:34Z",
            "published": "2023-11-13T16:28:34Z",
            "summary": "Knowledge tracing is a method used in education to assess and track the\nacquisition of knowledge by individual learners. It involves using a variety of\ntechniques, such as quizzes, tests, and other forms of assessment, to determine\nwhat a learner knows and does not know about a particular subject. The goal of\nknowledge tracing is to identify gaps in understanding and provide targeted\ninstruction to help learners improve their understanding and retention of\nmaterial. This can be particularly useful in situations where learners are\nworking at their own pace, such as in online learning environments. By\nproviding regular feedback and adjusting instruction based on individual needs,\nknowledge tracing can help learners make more efficient progress and achieve\nbetter outcomes. Effectively solving the KT problem would unlock the potential\nof computer-aided education applications such as intelligent tutoring systems,\ncurriculum learning, and learning materials recommendations. In this paper, we\nwill present the results of the implementation of two Knowledge Tracing\nalgorithms on a newly released dataset as part of the AAAI2023 Global Knowledge\nTracing Challenge.",
            "author": [
                "Yann Hicke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14707v1",
                "http://arxiv.org/pdf/2311.14707v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07446v1",
            "title": "Story-to-Motion: Synthesizing Infinite and Controllable Character\n  Animation from Long Text",
            "updated": "2023-11-13T16:22:38Z",
            "published": "2023-11-13T16:22:38Z",
            "summary": "Generating natural human motion from a story has the potential to transform\nthe landscape of animation, gaming, and film industries. A new and challenging\ntask, Story-to-Motion, arises when characters are required to move to various\nlocations and perform specific motions based on a long text description. This\ntask demands a fusion of low-level control (trajectories) and high-level\ncontrol (motion semantics). Previous works in character control and\ntext-to-motion have addressed related aspects, yet a comprehensive solution\nremains elusive: character control methods do not handle text description,\nwhereas text-to-motion methods lack position constraints and often produce\nunstable motions. In light of these limitations, we propose a novel system that\ngenerates controllable, infinitely long motions and trajectories aligned with\nthe input text. (1) We leverage contemporary Large Language Models to act as a\ntext-driven motion scheduler to extract a series of (text, position, duration)\npairs from long text. (2) We develop a text-driven motion retrieval scheme that\nincorporates motion matching with motion semantic and trajectory constraints.\n(3) We design a progressive mask transformer that addresses common artifacts in\nthe transition motion such as unnatural pose and foot sliding. Beyond its\npioneering role as the first comprehensive solution for Story-to-Motion, our\nsystem undergoes evaluation across three distinct sub-tasks: trajectory\nfollowing, temporal action composition, and motion blending, where it\noutperforms previous state-of-the-art motion synthesis methods across the\nboard. Homepage: https://story2motion.github.io/.",
            "author": [
                "Zhongfei Qing",
                "Zhongang Cai",
                "Zhitao Yang",
                "Lei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07446v1",
                "http://arxiv.org/pdf/2311.07446v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07445v1",
            "title": "Think Before You Speak: Cultivating Communication Skills of Large\n  Language Models via Inner Monologue",
            "updated": "2023-11-13T16:19:42Z",
            "published": "2023-11-13T16:19:42Z",
            "summary": "The emergence of large language models (LLMs) further improves the\ncapabilities of open-domain dialogue systems and can generate fluent, coherent,\nand diverse responses. However, LLMs still lack an important ability:\ncommunication skills, which makes them more like information seeking tools than\nanthropomorphic chatbots. To make LLMs more anthropomorphic and proactive\nduring the conversation, we add five communication skills to the response\ngeneration process: topic transition, proactively asking questions, concept\nguidance, empathy, and summarising often. The addition of communication skills\nincreases the interest of users in the conversation and attracts them to chat\nfor longer. To enable LLMs better understand and use communication skills, we\ndesign and add the inner monologue to LLMs. The complete process is achieved\nthrough prompt engineering and in-context learning. To evaluate communication\nskills, we construct a benchmark named Cskills for evaluating various\ncommunication skills, which can also more comprehensively evaluate the dialogue\ngeneration ability of the model. Experimental results show that the proposed\nCSIM strategy improves the backbone models and outperforms the baselines in\nboth automatic and human evaluations.",
            "author": [
                "Junkai Zhou",
                "Liang Pang",
                "Huawei Shen",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07445v1",
                "http://arxiv.org/pdf/2311.07445v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07439v2",
            "title": "Investigating Multi-Pivot Ensembling with Massively Multilingual Machine\n  Translation Models",
            "updated": "2023-11-14T14:01:46Z",
            "published": "2023-11-13T16:15:20Z",
            "summary": "Massively multilingual machine translation models allow for the translation\nof a large number of languages with a single model, but have limited\nperformance on low- and very-low-resource translation directions. Pivoting via\nhigh-resource languages remains a strong strategy for low-resource directions,\nand in this paper we revisit ways of pivoting through multiple languages.\nPrevious work has used a simple averaging of probability distributions from\nmultiple paths, but we find that this performs worse than using a single pivot,\nand exacerbates the hallucination problem because the same hallucinations can\nbe probable across different paths. As an alternative, we propose MaxEns, a\ncombination strategy that is biased towards the most confident predictions,\nhypothesising that confident predictions are less prone to be hallucinations.\nWe evaluate different strategies on the FLORES benchmark for 20 low-resource\nlanguage directions, demonstrating that MaxEns improves translation quality for\nlow-resource languages while reducing hallucination in translations, compared\nto both direct translation and an averaging approach. On average, multi-pivot\nstrategies still lag behind using English as a single pivot language, raising\nthe question of how to identify the best pivoting strategy for a given\ntranslation direction.",
            "author": [
                "Alireza Mohammadshahi",
                "Jannis Vamvas",
                "Rico Sennrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07439v2",
                "http://arxiv.org/pdf/2311.07439v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07438v1",
            "title": "Hardest Monotone Functions for Evolutionary Algorithms",
            "updated": "2023-11-13T16:13:30Z",
            "published": "2023-11-13T16:13:30Z",
            "summary": "The study of hardest and easiest fitness landscapes is an active area of\nresearch. Recently, Kaufmann, Larcher, Lengler and Zou conjectured that for the\nself-adjusting $(1,\\lambda)$-EA, Adversarial Dynamic BinVal (ADBV) is the\nhardest dynamic monotone function to optimize. We introduce the function\nSwitching Dynamic BinVal (SDBV) which coincides with ADBV whenever the number\nof remaining zeros in the search point is strictly less than $n/2$, where $n$\ndenotes the dimension of the search space. We show, using a combinatorial\nargument, that for the $(1+1)$-EA with any mutation rate $p \\in [0,1]$, SDBV is\ndrift-minimizing among the class of dynamic monotone functions. Our\nconstruction provides the first explicit example of an instance of the\npartially-ordered evolutionary algorithm (PO-EA) model with parameterized\npessimism introduced by Colin, Doerr and F\\'erey, building on work of Jansen.\nWe further show that the $(1+1)$-EA optimizes SDBV in $\\Theta(n^{3/2})$\ngenerations. Our simulations demonstrate matching runtimes for both static and\nself-adjusting $(1,\\lambda)$ and $(1+\\lambda)$-EA. We further show, using an\nexample of fixed dimension, that drift-minimization does not equal maximal\nruntime.",
            "author": [
                "Marc Kaufmann",
                "Maxime Larcher",
                "Johannes Lengler",
                "Oliver Sieberling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07438v1",
                "http://arxiv.org/pdf/2311.07438v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "math.PR",
                "68W50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07432v1",
            "title": "Supersampling of Data from Structured-light Scanner with Deep Learning",
            "updated": "2023-11-13T16:04:41Z",
            "published": "2023-11-13T16:04:41Z",
            "summary": "This paper focuses on increasing the resolution of depth maps obtained from\n3D cameras using structured light technology. Two deep learning models FDSR and\nDKN are modified to work with high-resolution data, and data pre-processing\ntechniques are implemented for stable training. The models are trained on our\ncustom dataset of 1200 3D scans. The resulting high-resolution depth maps are\nevaluated using qualitative and quantitative metrics. The approach for depth\nmap upsampling offers benefits such as reducing the processing time of a\npipeline by first downsampling a high-resolution depth map, performing various\nprocessing steps at the lower resolution and upsampling the resulting depth map\nor increasing the resolution of a point cloud captured in lower resolution by a\ncheaper device. The experiments demonstrate that the FDSR model excels in terms\nof faster processing time, making it a suitable choice for applications where\nspeed is crucial. On the other hand, the DKN model provides results with higher\nprecision, making it more suitable for applications that prioritize accuracy.",
            "author": [
                "Martin Melicher\u010d\u00edk",
                "Luk\u00e1\u0161 Gajdo\u0161ech",
                "Viktor Kocur",
                "Martin Madaras"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DISA59116.2023.10308923",
                "http://arxiv.org/abs/2311.07432v1",
                "http://arxiv.org/pdf/2311.07432v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07430v1",
            "title": "Controlled Text Generation for Black-box Language Models via Score-based\n  Progressive Editor",
            "updated": "2023-11-13T16:03:23Z",
            "published": "2023-11-13T16:03:23Z",
            "summary": "Despite recent progress in language models, generating constrained text for\nspecific domains remains a challenge, particularly when utilizing black-box\nmodels that lack domain-specific knowledge. In this paper, we introduce ScoPE\n(Score-based Progressive Editor) generation, a novel approach for controlled\ntext generation for black-box language models. We employ ScoPE to facilitate\ntext generation in the target domain by integrating it with language models\nthrough a cascading approach. Trained to enhance the target domain score of the\nedited text, ScoPE progressively edits intermediate output discrete tokens to\nalign with the target attributes throughout the auto-regressive generation\nprocess of the language model. This iterative process guides subsequent steps\nto produce desired output texts for the target domain. Our experimental results\non diverse controlled generations demonstrate that ScoPE effectively\nfacilitates controlled text generation for black-box language models in both\nin-domain and out-of-domain conditions, which is challenging for existing\nmethods.",
            "author": [
                "Sangwon Yu",
                "Changmin Lee",
                "Hojin Lee",
                "Sungroh Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07430v1",
                "http://arxiv.org/pdf/2311.07430v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07427v1",
            "title": "Boolean Variation and Boolean Logic BackPropagation",
            "updated": "2023-11-13T16:01:43Z",
            "published": "2023-11-13T16:01:43Z",
            "summary": "The notion of variation is introduced for the Boolean set and based on which\nBoolean logic backpropagation principle is developed. Using this concept, deep\nmodels can be built with weights and activations being Boolean numbers and\noperated with Boolean logic instead of real arithmetic. In particular, Boolean\ndeep models can be trained directly in the Boolean domain without latent\nweights. No gradient but logic is synthesized and backpropagated through\nlayers.",
            "author": [
                "Van Minh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07427v1",
                "http://arxiv.org/pdf/2311.07427v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM",
                "cs.LO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07426v1",
            "title": "Optimising Human-AI Collaboration by Learning Convincing Explanations",
            "updated": "2023-11-13T16:00:16Z",
            "published": "2023-11-13T16:00:16Z",
            "summary": "Machine learning models are being increasingly deployed to take, or assist in\ntaking, complicated and high-impact decisions, from quasi-autonomous vehicles\nto clinical decision support systems. This poses challenges, particularly when\nmodels have hard-to-detect failure modes and are able to take actions without\noversight. In order to handle this challenge, we propose a method for a\ncollaborative system that remains safe by having a human ultimately making\ndecisions, while giving the model the best opportunity to convince and debate\nthem with interpretable explanations. However, the most helpful explanation\nvaries among individuals and may be inconsistent across stated preferences. To\nthis end we develop an algorithm, Ardent, to efficiently learn a ranking\nthrough interaction and best assist humans complete a task. By utilising a\ncollaborative approach, we can ensure safety and improve performance while\naddressing transparency and accountability concerns. Ardent enables efficient\nand effective decision-making by adapting to individual preferences for\nexplanations, which we validate through extensive simulations alongside a user\nstudy involving a challenging image classification task, demonstrating\nconsistent improvement over competing systems.",
            "author": [
                "Alex J. Chan",
                "Alihan Huyuk",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07426v1",
                "http://arxiv.org/pdf/2311.07426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07424v1",
            "title": "Hallucination Augmented Recitations for Language Models",
            "updated": "2023-11-13T15:58:18Z",
            "published": "2023-11-13T15:58:18Z",
            "summary": "Attribution is a key concept in large language models (LLMs) as it enables\ncontrol over information sources and enhances the factuality of LLMs. While\nexisting approaches utilize open book question answering to improve\nattribution, factual datasets may reward language models to recall facts that\nthey already know from their pretraining data, not attribution. In contrast,\ncounterfactual open book QA datasets would further improve attribution because\nthe answer could only be grounded in the given text. We propose Hallucination\nAugmented Recitations (HAR) for creating counterfactual datasets by utilizing\nhallucination in LLMs to improve attribution. For open book QA as a case study,\nwe demonstrate that models finetuned with our counterfactual datasets improve\ntext grounding, leading to better open book QA performance, with up to an 8.0%\nincrease in F1 score. Our counterfactual dataset leads to significantly better\nperformance than using humanannotated factual datasets, even with 4x smaller\ndatasets and 4x smaller models. We observe that improvements are consistent\nacross various model sizes and datasets, including multi-hop, biomedical, and\nadversarial QA datasets.",
            "author": [
                "Abdullatif K\u00f6ksal",
                "Renat Aksitov",
                "Chung-Ching Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07424v1",
                "http://arxiv.org/pdf/2311.07424v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07421v1",
            "title": "Robust semi-supervised segmentation with timestep ensembling diffusion\n  models",
            "updated": "2023-11-13T15:57:17Z",
            "published": "2023-11-13T15:57:17Z",
            "summary": "Medical image segmentation is a challenging task, made more difficult by many\ndatasets' limited size and annotations. Denoising diffusion probabilistic\nmodels (DDPM) have recently shown promise in modelling the distribution of\nnatural images and were successfully applied to various medical imaging tasks.\nThis work focuses on semi-supervised image segmentation using diffusion models,\nparticularly addressing domain generalisation. Firstly, we demonstrate that\nsmaller diffusion steps generate latent representations that are more robust\nfor downstream tasks than larger steps. Secondly, we use this insight to\npropose an improved esembling scheme that leverages information-dense small\nsteps and the regularising effect of larger steps to generate predictions. Our\nmodel shows significantly better performance in domain-shifted settings while\nretaining competitive performance in-domain. Overall, this work highlights the\npotential of DDPMs for semi-supervised medical image segmentation and provides\ninsights into optimising their performance under domain shift.",
            "author": [
                "Margherita Rosnati",
                "Melanie Roschewitz",
                "Ben Glocker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07421v1",
                "http://arxiv.org/pdf/2311.07421v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07419v1",
            "title": "Diaconis-Ylvisaker prior penalized likelihood for $p/n \\to \u03ba\\in\n  (0,1)$ logistic regression",
            "updated": "2023-11-13T15:55:41Z",
            "published": "2023-11-13T15:55:41Z",
            "summary": "We characterise the behaviour of the maximum Diaconis-Ylvisaker prior\npenalized likelihood estimator in high-dimensional logistic regression, where\nthe number of covariates is a fraction $\\kappa \\in (0,1)$ of the number of\nobservations $n$, as $n \\to \\infty$. We derive the estimator's aggregate\nasymptotic behaviour when covariates are independent normal random variables\nwith mean zero and variance $1/n$, and the vector of regression coefficients\nhas length $\\gamma \\sqrt{n}$, asymptotically. From this foundation, we devise\nadjusted $Z$-statistics, penalized likelihood ratio statistics, and aggregate\nasymptotic results with arbitrary covariate covariance. In the process, we fill\nin gaps in previous literature by formulating a Lipschitz-smooth approximate\nmessage passing recursion, to formally transfer the asymptotic results from\napproximate message passing to logistic regression. While the maximum\nlikelihood estimate asymptotically exists only for a narrow range of $(\\kappa,\n\\gamma)$ values, the maximum Diaconis-Ylvisaker prior penalized likelihood\nestimate not only exists always but is also directly computable using maximum\nlikelihood routines. Thus, our asymptotic results also hold for $(\\kappa,\n\\gamma)$ values where results for maximum likelihood are not attainable, with\nno overhead in implementation or computation. We study the estimator's\nshrinkage properties and compare it to logistic ridge regression and\ndemonstrate our theoretical findings with simulations.",
            "author": [
                "Philipp Sterzinger",
                "Ioannis Kosmidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07419v1",
                "http://arxiv.org/pdf/2311.07419v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH",
                "62J12, 62F12, 62F05, 62J07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07418v1",
            "title": "Speech-based Slot Filling using Large Language Models",
            "updated": "2023-11-13T15:54:30Z",
            "published": "2023-11-13T15:54:30Z",
            "summary": "Recently, advancements in large language models (LLMs) have shown an\nunprecedented ability across various language tasks. This paper investigates\nthe potential application of LLMs to slot filling with noisy ASR\ntranscriptions, via both in-context learning and task-specific fine-tuning.\nDedicated prompt designs and fine-tuning approaches are proposed to improve the\nrobustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a\nlinearised knowledge injection (LKI) scheme is also proposed to integrate\ndynamic external knowledge into LLMs. Experiments were performed on SLURP to\nquantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and\nVicuna-13B (v1.1 and v1.5) with different ASR error rates. The use of the\nproposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an\n8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline\nsystem on a limited data setup.",
            "author": [
                "Guangzhi Sun",
                "Shutong Feng",
                "Dongcheng Jiang",
                "Chao Zhang",
                "Milica Ga\u0161i\u0107",
                "Philip C. Woodland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07418v1",
                "http://arxiv.org/pdf/2311.07418v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07417v1",
            "title": "Mitigating Backdoors within Deep Neural Networks in Data-limited\n  Configuration",
            "updated": "2023-11-13T15:54:27Z",
            "published": "2023-11-13T15:54:27Z",
            "summary": "As the capacity of deep neural networks (DNNs) increases, their need for huge\namounts of data significantly grows. A common practice is to outsource the\ntraining process or collect more data over the Internet, which introduces the\nrisks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data\nwhile behaving maliciously once a trigger is injected into a sample at the test\ntime. In such cases, the defender faces multiple difficulties. First, the\navailable clean dataset may not be sufficient for fine-tuning and recovering\nthe backdoored DNN. Second, it is impossible to recover the trigger in many\nreal-world applications without information about it. In this paper, we\nformulate some characteristics of poisoned neurons. This backdoor\nsuspiciousness score can rank network neurons according to their activation\nvalues, weights, and their relationship with other neurons in the same layer.\nOur experiments indicate the proposed method decreases the chance of attacks\nbeing successful by more than 50% with a tiny clean dataset, i.e., ten clean\nsamples for the CIFAR-10 dataset, without significantly deteriorating the\nmodel's performance. Moreover, the proposed method runs three times as fast as\nbaselines.",
            "author": [
                "Soroush Hashemifar",
                "Saeed Parsa",
                "Morteza Zakeri-Nasrabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07417v1",
                "http://arxiv.org/pdf/2311.07417v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07416v1",
            "title": "Three-dimensional granular flow simulation using graph neural\n  network-based learned simulator",
            "updated": "2023-11-13T15:54:09Z",
            "published": "2023-11-13T15:54:09Z",
            "summary": "Reliable evaluations of geotechnical hazards like landslides and debris flow\nrequire accurate simulation of granular flow dynamics. Traditional numerical\nmethods can simulate the complex behaviors of such flows that involve\nsolid-like to fluid-like transitions, but they are computationally intractable\nwhen simulating large-scale systems. Surrogate models based on statistical or\nmachine learning methods are a viable alternative, but they are typically\nempirical and rely on a confined set of parameters in evaluating associated\nrisks. Due to their permutation-dependent learning, conventional machine\nlearning models require an unreasonably large amount of training data for\nbuilding generalizable surrogate models. We employ a graph neural network\n(GNN), a novel deep learning technique, to develop a GNN-based simulator (GNS)\nfor granular flows to address these issues. Graphs represent the state of\ngranular flows and interactions, like the exchange of energy and momentum\nbetween grains, and GNN learns the local interaction law. GNS takes the current\nstate of the granular flow and estimates the next state using Euler explicit\nintegration. We train GNS on a limited set of granular flow trajectories and\nevaluate its performance in a three-dimensional granular column collapse\ndomain. GNS successfully reproduces the overall behaviors of column collapses\nwith various aspect ratios that were not encountered during training. The\ncomputation speed of GNS outperforms high-fidelity numerical simulators by 300\ntimes.",
            "author": [
                "Yongjin Choi",
                "Krishna Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07416v1",
                "http://arxiv.org/pdf/2311.07416v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG",
                "I.6.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07414v1",
            "title": "FIRST: A Million-Entry Dataset for Text-Driven Fashion Synthesis and\n  Design",
            "updated": "2023-11-13T15:50:25Z",
            "published": "2023-11-13T15:50:25Z",
            "summary": "Text-driven fashion synthesis and design is an extremely valuable part of\nartificial intelligence generative content(AIGC), which has the potential to\npropel a tremendous revolution in the traditional fashion industry. To advance\nthe research on text-driven fashion synthesis and design, we introduce a new\ndataset comprising a million high-resolution fashion images with rich\nstructured textual(FIRST) descriptions. In the FIRST, there is a wide range of\nattire categories and each image-paired textual description is organized at\nmultiple hierarchical levels. Experiments on prevalent generative models\ntrained over FISRT show the necessity of FIRST. We invite the community to\nfurther develop more intelligent fashion synthesis and design systems that make\nfashion design more creative and imaginative based on our dataset. The dataset\nwill be released soon.",
            "author": [
                "Zhen Huang",
                "Yihao Li",
                "Dong Pei",
                "Jiapeng Zhou",
                "Xuliang Ning",
                "Jianlin Han",
                "Xiaoguang Han",
                "Xuejun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07414v1",
                "http://arxiv.org/pdf/2311.07414v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07407v1",
            "title": "Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking\n  Re-Identification",
            "updated": "2023-11-13T15:41:25Z",
            "published": "2023-11-13T15:41:25Z",
            "summary": "In this paper, we show that paint markings are a feasible approach to\nautomatize the analysis of behavioral assays involving honey bees in the field\nwhere marking has to be as lightweight as possible. We contribute a novel\ndataset for bees re-identification with paint-markings with 4392 images and 27\nidentities. Contrastive learning with a ResNet backbone and triplet loss led to\nidentity representation features with almost perfect recognition in closed\nsetting where identities are known in advance. Diverse experiments evaluate the\ncapability to generalize to separate IDs, and show the impact of using\ndifferent body parts for identification, such as using the unmarked abdomen\nonly. In addition, we show the potential to fully automate the visit detection\nand provide preliminary results of compute time for future real-time deployment\nin the field on an edge device.",
            "author": [
                "Luke Meyers",
                "Josu\u00e9 Rodr\u00edguez Cordero",
                "Carlos Corrada Bravo",
                "Fanfan Noel",
                "Jos\u00e9 Agosto-Rivera",
                "Tugrul Giray",
                "R\u00e9mi M\u00e9gret"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07407v1",
                "http://arxiv.org/pdf/2311.07407v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.8; I.4.9; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07399v1",
            "title": "Context-Aware Adaptive Prefetching for DASH Streaming over 5G Networks",
            "updated": "2023-11-13T15:27:23Z",
            "published": "2023-11-13T15:27:23Z",
            "summary": "The increasing consumption of video streams and the demand for higher-quality\ncontent drive the evolution of telecommunication networks and the development\nof new network accelerators to boost media delivery while optimizing network\nusage. Multi-access Edge Computing (MEC) enables the possibility to enforce\nmedia delivery by deploying caching instances at the network edge, close to the\nRadio Access Network (RAN). Thus, the content can be prefetched and served from\nthe MEC host, reducing network traffic and increasing the Quality of Service\n(QoS) and the Quality of Experience (QoE). This paper proposes a novel\nmechanism to prefetch Dynamic Adaptive Streaming over HTTP (DASH) streams at\nthe MEC, employing a Machine Learning (ML) classification model to select the\nmedia segments to prefetch. The model is trained with media session metrics to\nimprove the forecasts with application layer information. The proposal is\ntested with Mobile Network Operators (MNOs)' 5G MEC and RAN and compared with\nother strategies by assessing cache and player's performance metrics.",
            "author": [
                "Juncal Uriol",
                "Inhar Yeregui",
                "Alvaro Gabilondo",
                "Roberto Viola",
                "Pablo Angueira",
                "Jon Montalban"
            ],
            "link": [
                "http://dx.doi.org/10.1109/BMSB58369.2023.10211275",
                "http://arxiv.org/abs/2311.07399v1",
                "http://arxiv.org/pdf/2311.07399v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07398v1",
            "title": "Processing and Segmentation of Human Teeth from 2D Images using Weakly\n  Supervised Learning",
            "updated": "2023-11-13T15:25:55Z",
            "published": "2023-11-13T15:25:55Z",
            "summary": "Teeth segmentation is an essential task in dental image analysis for accurate\ndiagnosis and treatment planning. While supervised deep learning methods can be\nutilized for teeth segmentation, they often require extensive manual annotation\nof segmentation masks, which is time-consuming and costly. In this research, we\npropose a weakly supervised approach for teeth segmentation that reduces the\nneed for manual annotation. Our method utilizes the output heatmaps and\nintermediate feature maps from a keypoint detection network to guide the\nsegmentation process. We introduce the TriDental dataset, consisting of 3000\noral cavity images annotated with teeth keypoints, to train a teeth keypoint\ndetection network. We combine feature maps from different layers of the\nkeypoint detection network, enabling accurate teeth segmentation without\nexplicit segmentation annotations. The detected keypoints are also used for\nfurther refinement of the segmentation masks. Experimental results on the\nTriDental dataset demonstrate the superiority of our approach in terms of\naccuracy and robustness compared to state-of-the-art segmentation methods. Our\nmethod offers a cost-effective and efficient solution for teeth segmentation in\nreal-world dental applications, eliminating the need for extensive manual\nannotation efforts.",
            "author": [
                "Tom\u00e1\u0161 Kunzo",
                "Viktor Kocur",
                "Luk\u00e1\u0161 Gajdo\u0161ech",
                "Martin Madaras"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DISA59116.2023.10308924",
                "http://arxiv.org/abs/2311.07398v1",
                "http://arxiv.org/pdf/2311.07398v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07397v1",
            "title": "An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination\n  Evaluation",
            "updated": "2023-11-13T15:25:42Z",
            "published": "2023-11-13T15:25:42Z",
            "summary": "Despite making significant progress in multi-modal tasks, current Multi-modal\nLarge Language Models (MLLMs) encounter the significant challenge of\nhallucination, which may lead to harmful consequences. Therefore, evaluating\nMLLMs' hallucinations is becoming increasingly important in model improvement\nand practical application deployment. Previous works are limited in high\nevaluation costs (e.g., relying on humans or advanced LLMs) and insufficient\nevaluation dimensions (e.g., types of hallucination and task). In this paper,\nwe propose an LLM-free multi-dimensional benchmark AMBER, which can be used to\nevaluate both generative task and discriminative task including object\nexistence, object attribute and object relation hallucination. Based on AMBER,\nwe design a low-cost and efficient evaluation pipeline. Additionally, we\nconduct a comprehensive evaluation and detailed analysis of mainstream MLLMs\nincluding GPT-4V(ision), and also give guideline suggestions for mitigating\nhallucinations. The data and code of AMBER are available at\nhttps://github.com/junyangwang0410/AMBER.",
            "author": [
                "Junyang Wang",
                "Yuhang Wang",
                "Guohai Xu",
                "Jing Zhang",
                "Yukai Gu",
                "Haitao Jia",
                "Ming Yan",
                "Ji Zhang",
                "Jitao Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07397v1",
                "http://arxiv.org/pdf/2311.07397v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07396v1",
            "title": "Exploring Values in Museum Artifacts in the SPICE project: a Preliminary\n  Study",
            "updated": "2023-11-13T15:24:55Z",
            "published": "2023-11-13T15:24:55Z",
            "summary": "This document describes the rationale, the implementation and a preliminary\nevaluation of a semantic reasoning tool developed in the EU H2020 SPICE project\nto enhance the diversity of perspectives experienced by museum visitors. The\ntool, called DEGARI 2.0 for values, relies on the commonsense reasoning\nframework TCL, and exploits an ontological model formalizingthe Haidt's theory\nof moral values to associate museum items with combined values and emotions.\nWithin a museum exhibition, this tool can suggest cultural items that are\nassociated not only with the values of already experienced or preferred\nobjects, but also with novel items with different value stances, opening the\nvisit experience to more inclusive interpretations of cultural content. The\nsystem has been preliminarily tested, in the context of the SPICE project, on\nthe collection of the Hecht Museum of Haifa.",
            "author": [
                "Nele Kadastik",
                "Thomas A. Pederson",
                "Luis Emilio Bruni",
                "Rossana Damiano",
                "Antonio Lieto",
                "Manuel Striani",
                "Tsvi Kuflik",
                "Alan Wecker"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3511047.3537662",
                "http://arxiv.org/abs/2311.07396v1",
                "http://arxiv.org/pdf/2311.07396v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "Human-Computer Interaction"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07391v1",
            "title": "Multi-Layer Monitoring at the Edge for Vehicular Video Streaming: Field\n  Trials",
            "updated": "2023-11-13T15:15:05Z",
            "published": "2023-11-13T15:15:05Z",
            "summary": "In an increasingly connected world, wireless networks' monitoring and\ncharacterization are of vital importance. Service and application providers\nneed to have a detailed understanding of network performance to offer new\nsolutions tailored to the needs of today's society. In the context of mobility,\nin-vehicle infotainment services are expected to stand out among other popular\nconnected vehicle services, so it is essential that communication networks are\nable to satisfy the Quality of Service (QoS) and Quality of Experience (QoE)\nrequirements needed for these type of services. This paper investigates a\nmulti-layer network performance monitoring architecture at the edge providing\nQoS, QoE, and localization information for vehicular video streaming\napplications in real-time over 5G networks. In order to conduct field trials\nand show test results, Mobile Network Operators (MNOs)' 5G Standalone (SA)\nnetwork and Multi-access Edge Computing (MEC) infrastructure are used to\nprovide connectivity and edge computing resources to a vehicle equipped with a\n5G modem.",
            "author": [
                "Inhar Yeregui",
                "Juncal Uriol",
                "Roberto Viola",
                "Pablo Angueira",
                "Jasone Astorga",
                "Jon Montalban"
            ],
            "link": [
                "http://dx.doi.org/10.1109/BMSB58369.2023.10211216",
                "http://arxiv.org/abs/2311.07391v1",
                "http://arxiv.org/pdf/2311.07391v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07390v1",
            "title": "Evaluating the Significance of Outdoor Advertising from Driver's\n  Perspective Using Computer Vision",
            "updated": "2023-11-13T15:14:53Z",
            "published": "2023-11-13T15:14:53Z",
            "summary": "Outdoor advertising, such as roadside billboards, plays a significant role in\nmarketing campaigns but can also be a distraction for drivers, potentially\nleading to accidents. In this study, we propose a pipeline for evaluating the\nsignificance of roadside billboards in videos captured from a driver's\nperspective. We have collected and annotated a new BillboardLamac dataset,\ncomprising eight videos captured by drivers driving through a predefined path\nwearing eye-tracking devices. The dataset includes annotations of billboards,\nincluding 154 unique IDs and 155 thousand bounding boxes, as well as eye\nfixation data. We evaluate various object tracking methods in combination with\na YOLOv8 detector to identify billboard advertisements with the best approach\nachieving 38.5 HOTA on BillboardLamac. Additionally, we train a random forest\nclassifier to classify billboards into three classes based on the length of\ndriver fixations achieving 75.8% test accuracy. An analysis of the trained\nclassifier reveals that the duration of billboard visibility, its saliency, and\nsize are the most influential features when assessing billboard significance.",
            "author": [
                "Zuzana \u010cernekov\u00e1",
                "Zuzana Berger Haladov\u00e1",
                "J\u00e1n \u0160pirka",
                "Viktor Kocur"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DISA59116.2023.10308914",
                "http://arxiv.org/abs/2311.07390v1",
                "http://arxiv.org/pdf/2311.07390v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07387v1",
            "title": "Assessing Logical Puzzle Solving in Large Language Models: Insights from\n  a Minesweeper Case Study",
            "updated": "2023-11-13T15:11:26Z",
            "published": "2023-11-13T15:11:26Z",
            "summary": "Large Language Models (LLMs) have shown remarkable proficiency in language\nunderstanding and have been successfully applied to a variety of real-world\ntasks through task-specific fine-tuning or prompt engineering. Despite these\nadvancements, it remains an open question whether LLMs are fundamentally\ncapable of reasoning and planning, or if they primarily rely on recalling and\nsynthesizing information from their training data. In our research, we\nintroduce a novel task -- Minesweeper -- specifically designed in a format\nunfamiliar to LLMs and absent from their training datasets. This task\nchallenges LLMs to identify the locations of mines based on numerical clues\nprovided by adjacent opened cells. Successfully completing this task requires\nan understanding of each cell's state, discerning spatial relationships between\nthe clues and mines, and strategizing actions based on logical deductions drawn\nfrom the arrangement of the cells. Our experiments, including trials with the\nadvanced GPT-4 model, indicate that while LLMs possess the foundational\nabilities required for this task, they struggle to integrate these into a\ncoherent, multi-step logical reasoning process needed to solve Minesweeper.\nThese findings highlight the need for further research to understand and nature\nof reasoning capabilities in LLMs under similar circumstances, and to explore\npathways towards more sophisticated AI reasoning and planning models.",
            "author": [
                "Yinghao Li",
                "Haorui Wang",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07387v1",
                "http://arxiv.org/pdf/2311.07387v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07383v1",
            "title": "LM-Polygraph: Uncertainty Estimation for Language Models",
            "updated": "2023-11-13T15:08:59Z",
            "published": "2023-11-13T15:08:59Z",
            "summary": "Recent advancements in the capabilities of large language models (LLMs) have\npaved the way for a myriad of groundbreaking applications in various fields.\nHowever, a significant challenge arises as these models often \"hallucinate\",\ni.e., fabricate facts without providing users an apparent means to discern the\nveracity of their statements. Uncertainty estimation (UE) methods are one path\nto safer, more responsible, and more effective use of LLMs. However, to date,\nresearch on UE methods for LLMs has been focused primarily on theoretical\nrather than engineering contributions. In this work, we tackle this issue by\nintroducing LM-Polygraph, a framework with implementations of a battery of\nstate-of-the-art UE methods for LLMs in text generation tasks, with unified\nprogram interfaces in Python. Additionally, it introduces an extendable\nbenchmark for consistent evaluation of UE techniques by researchers, and a demo\nweb application that enriches the standard chat dialog with confidence scores,\nempowering end-users to discern unreliable responses. LM-Polygraph is\ncompatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and\nGPT-4, and is designed to support future releases of similarly-styled LMs.",
            "author": [
                "Ekaterina Fadeeva",
                "Roman Vashurin",
                "Akim Tsvigun",
                "Artem Vazhentsev",
                "Sergey Petrakov",
                "Kirill Fedyanin",
                "Daniil Vasilev",
                "Elizaveta Goncharova",
                "Alexander Panchenko",
                "Maxim Panov",
                "Timothy Baldwin",
                "Artem Shelmanov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07383v1",
                "http://arxiv.org/pdf/2311.07383v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07378v1",
            "title": "Unusual chemical bond and spectrum of beryllium dimer in ground\n  $X^1\u03a3_g^+$ state",
            "updated": "2023-11-13T14:57:04Z",
            "published": "2023-11-13T14:57:04Z",
            "summary": "This review outlines the main results which show the dual nature of the\nchemical bond in diatomic beryllium molecule in the ground $X^1\\Sigma_g^+$\nstate. It has been shown that the beryllium atoms are covalently bound at\nlow-lying vibrational energy levels ({\\nu}=0-4), while at higher ones\n({\\nu}=5-11) they are bound by van der Waals forces near the right turning\npoints. High precision ab initio quantum calculations of Be$_2$ resulted in the\ndevelopment of the modified expanded Morse oscillator potential function which\ncontains all twelve vibrational energy levels [A.V. Mitin, Chem. Phys. Lett.\n682, 30 (2017)]. The dual nature of chemical bond in Be$_2$ is evidenced as a\nsharp corner on the attractive branch of the ground state potential curve.\nMoreover, it has been found that the Douglas-Kroll-Hess relativistic\ncorrections also show a sharp corner when presented in dependence on the\ninternuclear separation. The difference in energy between the extrapolated and\ncalculated multi-reference configuration interaction energies in dependence on\nthe internuclear separation also exhibits singular point in the same region.\nThe other problems of ab initio quantum calculations of the beryllium dimer are\nalso discussed. Calculated spectrum of vibrational-rotational bound states and\nnew metastable states of the beryllium dimer in the ground state important for\nlaser spectroscopy are presented. The vibration problem was solved for the\nmodified expanded Morse oscillator potential function and for the potential\nfunction obtained with Slater-type orbitals [M. Lesiuk et al, Chem. Theory\nComput. 15, 2470 (2019)]. The theoretical upper and lower estimates of the\nspectrum of vibrational-rotational bound states and the spectrum of\nrotational-vibrational metastable states with complex-valued energy eigenvalues\nand the scattering length in the beryllium dimer are presented.",
            "author": [
                "A. V. Mitin",
                "A. A. Gusev",
                "O. Chuluunbaatar",
                "S. I. Vinitsky",
                "V. L. Derbov",
                "Luong Le Hai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07378v1",
                "http://arxiv.org/pdf/2311.07378v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07377v1",
            "title": "Testing learning-enabled cyber-physical systems with Large-Language\n  Models: A Formal Approach",
            "updated": "2023-11-13T14:56:14Z",
            "published": "2023-11-13T14:56:14Z",
            "summary": "The integration of machine learning (ML) into cyber-physical systems (CPS)\noffers significant benefits, including enhanced efficiency, predictive\ncapabilities, real-time responsiveness, and the enabling of autonomous\noperations. This convergence has accelerated the development and deployment of\na range of real-world applications, such as autonomous vehicles, delivery\ndrones, service robots, and telemedicine procedures. However, the software\ndevelopment life cycle (SDLC) for AI-infused CPS diverges significantly from\ntraditional approaches, featuring data and learning as two critical components.\nExisting verification and validation techniques are often inadequate for these\nnew paradigms. In this study, we pinpoint the main challenges in ensuring\nformal safety for learningenabled CPS.We begin by examining testing as the most\npragmatic method for verification and validation, summarizing the current\nstate-of-the-art methodologies. Recognizing the limitations in current testing\napproaches to provide formal safety guarantees, we propose a roadmap to\ntransition from foundational probabilistic testing to a more rigorous approach\ncapable of delivering formal assurance.",
            "author": [
                "Xi Zheng",
                "Aloysius K. Mok",
                "Ruzica Piskac",
                "Yong Jae Lee",
                "Bhaskar Krishnamachari",
                "Dakai Zhu",
                "Oleg Sokolsky",
                "Insup Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07377v1",
                "http://arxiv.org/pdf/2311.07377v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.DC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07635v1",
            "title": "Past as a Guide: Leveraging Retrospective Learning for Python Code\n  Completion",
            "updated": "2023-11-13T14:40:33Z",
            "published": "2023-11-13T14:40:33Z",
            "summary": "This work presents Past as a Guide (PaG), a simple approach for Large\nLanguage Models (LLMs) to improve the coding capabilities by integrating the\npast history with interactive and iterative code refinements. To be specific,\ninspired by human cognitive processes, the proposed method enables LLMs to\nutilize previous programming and debugging experiences to enhance the Python\ncode completion tasks. The framework facilitates LLMs to iteratively refine the\nPython code based on previous execution and debugging results and optimize\nlearning and reasoning capabilities. The proposed methodology achieved a 92\\%\npass@1 on HumanEval, demonstrating the potential to advance the field by\nleveraging retrospection from past experiences and interactive and iterative\nrefinement processes without external correctness indicators.",
            "author": [
                "Seunggyoon Shin",
                "Seunggyu Chang",
                "Sungjoon Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07635v1",
                "http://arxiv.org/pdf/2311.07635v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07371v1",
            "title": "Scalable Estimation for Structured Additive Distributional Regression\n  Through Variational Inference",
            "updated": "2023-11-13T14:37:48Z",
            "published": "2023-11-13T14:37:48Z",
            "summary": "Structured additive distributional regression models offer a versatile\nframework for estimating complete conditional distributions by relating all\nparameters of a parametric distribution to covariates. Although these models\nefficiently leverage information in vast and intricate data sets, they often\nresult in highly-parameterized models with many unknowns. Standard estimation\nmethods, like Bayesian approaches based on Markov chain Monte Carlo methods,\nface challenges in estimating these models due to their complexity and\ncostliness. To overcome these issues, we suggest a fast and scalable\nalternative based on variational inference. Our approach combines a\nparsimonious parametric approximation for the posteriors of regression\ncoefficients, with the exact conditional posterior for hyperparameters. For\noptimization, we use a stochastic gradient ascent method combined with an\nefficient strategy to reduce the variance of estimators. We provide theoretical\nproperties and investigate global and local annealing to enhance robustness,\nparticularly against data outliers. Our implementation is very general,\nallowing us to include various functional effects like penalized splines or\ncomplex tensor product interactions. In a simulation study, we demonstrate the\nefficacy of our approach in terms of accuracy and computation time. Lastly, we\npresent two real examples illustrating the modeling of infectious COVID-19\noutbreaks and outlier detection in brain activity.",
            "author": [
                "Jana Kleinemeier",
                "Nadja Klein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07371v1",
                "http://arxiv.org/pdf/2311.07371v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07370v2",
            "title": "Classification of developmental and brain disorders via graph\n  convolutional aggregation",
            "updated": "2023-11-16T14:55:15Z",
            "published": "2023-11-13T14:36:29Z",
            "summary": "While graph convolution based methods have become the de-facto standard for\ngraph representation learning, their applications to disease prediction tasks\nremain quite limited, particularly in the classification of neurodevelopmental\nand neurodegenerative brain disorders. In this paper, we introduce an\naggregator normalization graph convolutional network by leveraging aggregation\nin graph sampling, as well as skip connections and identity mapping. The\nproposed model learns discriminative graph node representations by\nincorporating both imaging and non-imaging features into the graph nodes and\nedges, respectively, with the aim of augmenting predictive capabilities and\nproviding a holistic perspective on the underlying mechanisms of brain\ndisorders. Skip connections enable the direct flow of information from the\ninput features to later layers of the network, while identity mapping helps\nmaintain the structural information of the graph during feature learning. We\nbenchmark our model against several recent baseline methods on two large\ndatasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease\nNeuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder\nand Alzheimer's disease, respectively. Experimental results demonstrate the\ncompetitive performance of our approach in comparison with recent baselines in\nterms of several evaluation metrics, achieving relative improvements of 50% and\n13.56% in classification accuracy over graph convolutional networks on ABIDE\nand ADNI, respectively.",
            "author": [
                "Ibrahim Salim",
                "A. Ben Hamza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07370v2",
                "http://arxiv.org/pdf/2311.07370v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07634v2",
            "title": "ActiveDC: Distribution Calibration for Active Finetuning",
            "updated": "2023-11-15T09:32:05Z",
            "published": "2023-11-13T14:35:18Z",
            "summary": "The pretraining-finetuning paradigm has gained popularity in various computer\nvision tasks. In this paradigm, the emergence of active finetuning arises due\nto the abundance of large-scale data and costly annotation requirements. Active\nfinetuning involves selecting a subset of data from an unlabeled pool for\nannotation, facilitating subsequent finetuning. However, the use of a limited\nnumber of training samples can lead to a biased distribution, potentially\nresulting in model overfitting. In this paper, we propose a new method called\nActiveDC for the active finetuning tasks. Firstly, we select samples for\nannotation by optimizing the distribution similarity between the subset to be\nselected and the entire unlabeled pool in continuous space. Secondly, we\ncalibrate the distribution of the selected samples by exploiting implicit\ncategory information in the unlabeled pool. The feature visualization provides\nan intuitive sense of the effectiveness of our approach to distribution\ncalibration. We conducted extensive experiments on three image classification\ndatasets with different sampling ratios. The results indicate that ActiveDC\nconsistently outperforms the baseline performance in all image classification\ntasks. The improvement is particularly significant when the sampling ratio is\nlow, with performance gains of up to 10%. Our code will be released.",
            "author": [
                "Wenshuai Xu",
                "Zhenhui Hu",
                "Yu Lu",
                "Jinzhou Meng",
                "Qingjie Liu",
                "Yunhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07634v2",
                "http://arxiv.org/pdf/2311.07634v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07367v1",
            "title": "SL(2, $\\mathbb C$) quartic vertex for closed string field theory",
            "updated": "2023-11-13T14:31:31Z",
            "published": "2023-11-13T14:31:31Z",
            "summary": "We construct the $\\mathrm{SL}(2, \\mathbb C)$ quartic vertex with a generic\nstub parameter for the bosonic closed string field theory by characterizing the\nvertex region in the moduli space of 4-punctured sphere, and providing the\nnecessary and sufficient constraints for the local coordinate maps. While\n$\\mathrm{SL}(2, \\mathbb C)$ vertices are not known to have a nice geometric\nrecursive construction like the minimal area or hyperbolic vertices, they can\nbe studied analytically which makes them more convenient for simple\ncomputations. In particular, we obtain exact formulas for the parametrization\nand volume of the vertex region as a function of the stub parameter. The main\nobjective of having an explicit quartic vertex is to later study its\ndecomposition using auxiliary fields.",
            "author": [
                "Harold Erbin",
                "Suvajit Majumder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07367v1",
                "http://arxiv.org/pdf/2311.07367v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07366v1",
            "title": "arfpy: A python package for density estimation and generative modeling\n  with adversarial random forests",
            "updated": "2023-11-13T14:28:21Z",
            "published": "2023-11-13T14:28:21Z",
            "summary": "This paper introduces $\\textit{arfpy}$, a python implementation of\nAdversarial Random Forests (ARF) (Watson et al., 2023), which is a lightweight\nprocedure for synthesizing new data that resembles some given data. The\nsoftware $\\textit{arfpy}$ equips practitioners with straightforward\nfunctionalities for both density estimation and generative modeling. The method\nis particularly useful for tabular data and its competitive performance is\ndemonstrated in previous literature. As a major advantage over the mostly deep\nlearning based alternatives, $\\textit{arfpy}$ combines the method's reduced\nrequirements in tuning efforts and computational resources with a user-friendly\npython interface. This supplies audiences across scientific fields with\nsoftware to generate data effortlessly.",
            "author": [
                "Kristin Blesch",
                "Marvin N. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07366v1",
                "http://arxiv.org/pdf/2311.07366v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07363v3",
            "title": "Efficient bandwidth extension of musical signals using a differentiable\n  harmonic plus noise model",
            "updated": "2023-11-27T11:36:06Z",
            "published": "2023-11-13T14:26:32Z",
            "summary": "The task of bandwidth extension addresses the generation of missing high\nfrequencies of audio signals based on knowledge of the low-frequency part of\nthe sound. This task applies to various problems, such as audio coding or audio\nrestoration. In this article, we focus on efficient bandwidth extension of\nmonophonic and polyphonic musical signals using a differentiable digital signal\nprocessing (DDSP) model. Such a model is composed of a neural network part with\nrelatively few parameters trained to infer the parameters of a differentiable\ndigital signal processing model, which efficiently generates the output\nfull-band audio signal.\n  We first address bandwidth extension of monophonic signals, and then propose\ntwo methods to explicitely handle polyphonic signals. The benefits of the\nproposed models are first demonstrated on monophonic and polyphonic synthetic\ndata against a baseline and a deep-learning-based resnet model. The models are\nnext evaluated on recorded monophonic and polyphonic data, for a wide variety\nof instruments and musical genres. We show that all proposed models surpass a\nhigher complexity deep learning model for an objective metric computed in the\nfrequency domain. A MUSHRA listening test confirms the superiority of the\nproposed approach in terms of perceptual quality.",
            "author": [
                "Pierre-Amaury Grumiaux",
                "Mathieu Lagrange"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07363v3",
                "http://arxiv.org/pdf/2311.07363v3"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07362v2",
            "title": "Volcano: Mitigating Multimodal Hallucination through Self-Feedback\n  Guided Revision",
            "updated": "2023-11-14T06:04:31Z",
            "published": "2023-11-13T14:26:24Z",
            "summary": "Large multimodal models (LMMs) suffer from multimodal hallucination, where\nthey provide incorrect responses misaligned with the given visual information.\nRecent works have conjectured that one of the reasons behind multimodal\nhallucination might be due to the vision encoder failing to ground on the image\nproperly. To mitigate this issue, we propose a novel approach that leverages\nself-feedback as visual cues. Building on this approach, we introduce Volcano,\na multimodal self-feedback guided revision model. Volcano generates natural\nlanguage feedback to its initial response based on the provided visual\ninformation and utilizes this feedback to self-revise its initial response.\nVolcano effectively reduces multimodal hallucination and achieves\nstate-of-the-art on MMHal-Bench, POPE, and GAVIE. It also improves on general\nmultimodal abilities and outperforms previous models on MM-Vet and MMBench.\nThrough a qualitative analysis, we show that Volcano's feedback is properly\ngrounded on the image than the initial response. This indicates that Volcano\ncan provide itself with richer visual information, helping alleviate multimodal\nhallucination. We publicly release Volcano models of 7B and 13B sizes along\nwith the data and code at https://github.com/kaistAI/Volcano.",
            "author": [
                "Seongyun Lee",
                "Sue Hyun Park",
                "Yongrae Jo",
                "Minjoon Seo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07362v2",
                "http://arxiv.org/pdf/2311.07362v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07361v1",
            "title": "The Impact of Large Language Models on Scientific Discovery: a\n  Preliminary Study using GPT-4",
            "updated": "2023-11-13T14:26:12Z",
            "published": "2023-11-13T14:26:12Z",
            "summary": "In recent years, groundbreaking advancements in natural language processing\nhave culminated in the emergence of powerful large language models (LLMs),\nwhich have showcased remarkable capabilities across a vast array of domains,\nincluding the understanding, generation, and translation of natural language,\nand even tasks that extend beyond language processing. In this report, we delve\ninto the performance of LLMs within the context of scientific discovery,\nfocusing on GPT-4, the state-of-the-art language model. Our investigation spans\na diverse range of scientific areas encompassing drug discovery, biology,\ncomputational chemistry (density functional theory (DFT) and molecular dynamics\n(MD)), materials design, and partial differential equations (PDE). Evaluating\nGPT-4 on scientific tasks is crucial for uncovering its potential across\nvarious research domains, validating its domain-specific expertise,\naccelerating scientific progress, optimizing resource allocation, guiding\nfuture model development, and fostering interdisciplinary research. Our\nexploration methodology primarily consists of expert-driven case assessments,\nwhich offer qualitative insights into the model's comprehension of intricate\nscientific concepts and relationships, and occasionally benchmark testing,\nwhich quantitatively evaluates the model's capacity to solve well-defined\ndomain-specific problems. Our preliminary exploration indicates that GPT-4\nexhibits promising potential for a variety of scientific applications,\ndemonstrating its aptitude for handling complex problem-solving and knowledge\nintegration tasks. Broadly speaking, we evaluate GPT-4's knowledge base,\nscientific understanding, scientific numerical calculation abilities, and\nvarious scientific prediction capabilities.",
            "author": [
                "Microsoft Research AI4Science",
                "Microsoft Azure Quantum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07361v1",
                "http://arxiv.org/pdf/2311.07361v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07357v1",
            "title": "Registered and Segmented Deformable Object Reconstruction from a Single\n  View Point Cloud",
            "updated": "2023-11-13T14:21:55Z",
            "published": "2023-11-13T14:21:55Z",
            "summary": "In deformable object manipulation, we often want to interact with specific\nsegments of an object that are only defined in non-deformed models of the\nobject. We thus require a system that can recognize and locate these segments\nin sensor data of deformed real world objects. This is normally done using\ndeformable object registration, which is problem specific and complex to tune.\nRecent methods utilize neural occupancy functions to improve deformable object\nregistration by registering to an object reconstruction. Going one step\nfurther, we propose a system that in addition to reconstruction learns\nsegmentation of the reconstructed object. As the resulting output already\ncontains the information about the segments, we can skip the registration\nprocess. Tested on a variety of deformable objects in simulation and the real\nworld, we demonstrate that our method learns to robustly find these segments.\nWe also introduce a simple sampling algorithm to generate better training data\nfor occupancy learning.",
            "author": [
                "Pit Henrich",
                "Bal\u00e1zs Gyenes",
                "Paul Maria Scheikl",
                "Gerhard Neumann",
                "Franziska Mathis-Ullrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07357v1",
                "http://arxiv.org/pdf/2311.07357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09245v1",
            "title": "Affine Invariance in Continuous-Domain Convolutional Neural Networks",
            "updated": "2023-11-13T14:17:57Z",
            "published": "2023-11-13T14:17:57Z",
            "summary": "The notion of group invariance helps neural networks in recognizing patterns\nand features under geometric transformations. Indeed, it has been shown that\ngroup invariance can largely improve deep learning performances in practice,\nwhere such transformations are very common. This research studies affine\ninvariance on continuous-domain convolutional neural networks. Despite other\nresearch considering isometric invariance or similarity invariance, we focus on\nthe full structure of affine transforms generated by the generalized linear\ngroup $\\mathrm{GL}_2(\\mathbb{R})$. We introduce a new criterion to assess the\nsimilarity of two input signals under affine transformations. Then, unlike\nconventional methods that involve solving complex optimization problems on the\nLie group $G_2$, we analyze the convolution of lifted signals and compute the\ncorresponding integration over $G_2$. In sum, our research could eventually\nextend the scope of geometrical transformations that practical deep-learning\npipelines can handle.",
            "author": [
                "Ali Mohaddes",
                "Johannes Lederer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09245v1",
                "http://arxiv.org/pdf/2311.09245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07350v1",
            "title": "Magnetoresistive detection of perpendicular switching in a magnetic\n  insulator",
            "updated": "2023-11-13T14:10:56Z",
            "published": "2023-11-13T14:10:56Z",
            "summary": "Spintronics offers promising routes for efficient memory, logic, and\ncomputing technologies. The central challenge in spintronics is electrically\nmanipulating and detecting magnetic states in devices. The electrical control\nof magnetization via spin-orbit torques is effective in both conducting and\ninsulating magnetic layers. However, the electrical readout of magnetization in\nthe latter is inherently difficult, limiting its use in practical applications.\nHere, we demonstrate magnetoresistive detection of perpendicular magnetization\nreversal in an electrically insulating ferrimagnet, terbium iron garnet (TbIG).\nTo do so, we use TbIG|Cu|TbCo, where TbCo is a conducting ferrimagnet and\nserves as the reference layer, and Cu is a nonmagnetic spacer. Current\ninjection through Cu|TbCo allows us to detect the magnetization reversal of\nTbIG with a simple resistance readout during an external magnetic field sweep.\nBy examining the effect of measurement temperature, TbCo composition, and Cu\nthickness on the sign and amplitude of the magnetoresistance, we conclude that\nthe spin-dependent electron scattering at the TbIG|Cu interface is the\nunderlying cause. Technologically-feasible magnetoresistive detection of\nperpendicular switching in a ferrimagnetic garnet is a breakthrough, as it\nopens broad avenues for novel insulating spintronic devices and concepts.",
            "author": [
                "Silvia Damerio",
                "Achintya Sunil",
                "M. Mehraeen",
                "Steven S. -L. Zhang",
                "Can O. Avci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07350v1",
                "http://arxiv.org/pdf/2311.07350v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07349v1",
            "title": "Vehicle-to-grid for car sharing -- A simulation study for 2030",
            "updated": "2023-11-13T14:08:39Z",
            "published": "2023-11-13T14:08:39Z",
            "summary": "The proliferation of car sharing services in recent years presents a\npromising avenue for advancing sustainable transportation. Beyond merely\nreducing car ownership rates, these systems can play a pivotal role in\nbolstering grid stability through the provision of ancillary services via\nvehicle-to-grid (V2G) technologies - a facet that has received limited\nattention in previous research. In this study, we analyze the potential of V2G\nin car sharing by designing future scenarios for a national-scale service in\nSwitzerland. We propose an agent-based simulation pipeline that considers\npopulation changes as well as different business strategies of the car sharing\nservice, and we demonstrate its successful application for simulating scenarios\nfor 2030. To imitate car sharing user behavior, we develop a data-driven mode\nchoice model. Our analysis reveals important differences in the examined\nscenarios, such as higher vehicle utilization rates for a reduced fleet size as\nwell as in a scenario featuring new car sharing stations. These disparities\ntranslate into variations in the power flexibility of the fleet available for\nancillary services, ranging from 12 to 50 MW, depending on the scenario and the\ntime of the day. Furthermore, we conduct a case study involving a subset of the\ncar sharing fleet, incorporating real-world electricity pricing data. The case\nstudy substantiates the existence of a sweet spot involving monetary gains for\nboth power grid operators and fleet owners. Our findings provide guidelines to\ndecision makers and underscore the pressing need for regulatory enhancements\nconcerning power trading within the realm of car sharing.",
            "author": [
                "Nina Wiedemann",
                "Yanan Xin",
                "Vasco Medici",
                "Lorenzo Nespoli",
                "Esra Suel",
                "Martin Raubal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07349v1",
                "http://arxiv.org/pdf/2311.07349v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07348v1",
            "title": "Deformable Groupwise Registration Using a Locally Low-Rank Dissimilarity\n  Metric for Myocardial Strain Estimation from Cardiac Cine MRI Images",
            "updated": "2023-11-13T14:06:44Z",
            "published": "2023-11-13T14:06:44Z",
            "summary": "Objective: Cardiovascular magnetic resonance-feature tracking (CMR-FT)\nrepresents a group of methods for myocardial strain estimation from cardiac\ncine MRI images. Established CMR-FT methods are mainly based on optical flow or\npairwise registration. However, these methods suffer from either inaccurate\nestimation of large motion or drift effect caused by accumulative tracking\nerrors. In this work, we propose a deformable groupwise registration method\nusing a locally low-rank (LLR) dissimilarity metric for CMR-FT. Methods: The\nproposed method (Groupwise-LLR) tracks the feature points by a groupwise\nregistration-based two-step strategy. Unlike the globally low-rank (GLR)\ndissimilarity metric, the proposed LLR metric imposes low-rankness on local\nimage patches rather than the whole image. We quantitatively compared\nGroupwise-LLR with the Farneback optical flow, a pairwise registration method,\nand a GLR-based groupwise registration method on simulated and in vivo\ndatasets. Results: Results from the simulated dataset showed that Groupwise-LLR\nachieved more accurate tracking and strain estimation compared with the other\nmethods. Results from the in vivo dataset showed that Groupwise-LLR achieved\nmore accurate tracking and elimination of the drift effect in late-diastole.\nInter-observer reproducibility of strain estimates was similar between all\nstudied methods. Conclusion: The proposed method estimates myocardial strains\nmore accurately due to the application of a groupwise registration-based\ntracking strategy and an LLR-based dissimilarity metric. Significance: The\nproposed CMR-FT method may facilitate more accurate estimation of myocardial\nstrains, especially in diastole, for clinical assessments of cardiac\ndysfunction.",
            "author": [
                "Haiyang Chen",
                "Juan Gao",
                "Chenxi Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07348v1",
                "http://arxiv.org/pdf/2311.07348v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07339v1",
            "title": "Pseudo-Anosov autoquivalances arising from Symplectic topology and their\n  hyperbolic actions on stability conditions",
            "updated": "2023-11-13T13:49:50Z",
            "published": "2023-11-13T13:49:50Z",
            "summary": "Within $N$-Calabi-Yau categories associated with quivers whose base graphs\nform trees, we delve into the study of the asymptotic behaviors of\nautoequivalences of a specific type. These autoequivalences, which we call\n\"Penner type,\" exhibit straightforward asymptotic characteristics, making them\nnoteworthy exemplars of \"pseudo-Anosov\" autoequivalences in the sense of\n\\cite{Fan-Filip-Haiden-Katzarkov-Liu21}, and also in a stronger sense that we\ndefine in the present paper.\n  In addition, we provide a practical methodology for calculating the\nstretching factors of Penner type autoequivalences. We expect that this\ncomputational approach can have applications. As an example, we establish a\npositive lower bound on the translation length of the induced action these\nautoequivalences have on the space of stability conditions. Our anticipation is\nthat this lower bound is, in fact, exact. Notably, we have observed instances\nof Penner type $\\Phi$ where the induced actions align precisely with this lower\nbound. In other words, these examples induce hyperbolic actions on the space of\nstability conditions.",
            "author": [
                "Hanwool Bae",
                "Sangjin Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07339v1",
                "http://arxiv.org/pdf/2311.07339v1"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "math.CT",
                "math.DS",
                "math.RT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07335v1",
            "title": "Throughput Maximization in Multi-Band Optical Networks with Column\n  Generation",
            "updated": "2023-11-13T13:43:52Z",
            "published": "2023-11-13T13:43:52Z",
            "summary": "Multi-band transmission is a promising technical direction for spectrum and\ncapacity expansion of existing optical networks. Due to the increase in the\nnumber of usable wavelengths in multi-band optical networks, the complexity of\nresource allocation problems becomes a major concern. Moreover, the\ntransmission performance, spectrum width, and cost constraint across optical\nbands may be heterogeneous. Assuming a worst-case transmission margin in U, L,\nand C-bands, this paper investigates the problem of throughput maximization in\nmulti-band optical networks, including the optimization of route, wavelength,\nand band assignment. We propose a low-complexity decomposition approach based\non Column Generation (CG) to address the scalability issue faced by traditional\nmethodologies. We numerically compare the results obtained by our CG-based\napproach to an integer linear programming model, confirming the near-optimal\nnetwork throughput. Our results also demonstrate the scalability of the\nCG-based approach when the number of wavelengths increases, with the\ncomputation time in the magnitude order of 10 s for cases varying from 75 to\n1200 wavelength channels per link in a 14-node network.",
            "author": [
                "Cao Chen",
                "Shilin Xiao",
                "Fen Zhou",
                "Massimo Tornatore"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07335v1",
                "http://arxiv.org/pdf/2311.07335v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07334v1",
            "title": "The topology and isochronicity on complex Hamiltonian systems with\n  homogeneous nonlinearities",
            "updated": "2023-11-13T13:42:57Z",
            "published": "2023-11-13T13:42:57Z",
            "summary": "In this paper, we study the Hamiltonian differential systems with a\nhomogeneous nonlinearity part on $\\mathbb{C}^2$. Firstly, we give a series of\ntopological properties of the polynomial Hamiltonian function, especially the\ninformation on the singular points and the non-trivial cycles vanishing at\ninfinity. Secondly, by using those topological properties, we successfully\nprovide a complete set of the necessary and sufficient conditions of\nisochronous centers for such systems with any degree. Our method avoids tedious\ncomputation of the coefficients of normalization occurring in the usual tools\nto deal with the isochronicity problem.",
            "author": [
                "Guangfeng Dong",
                "Jiazhong Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07334v1",
                "http://arxiv.org/pdf/2311.07334v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "34C05, 34M04"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07330v1",
            "title": "Status update: $\u03c0^0\\to \u03b3^\\ast \u03b3^\\ast$ transition form factor\n  on CLS ensembles",
            "updated": "2023-11-13T13:33:02Z",
            "published": "2023-11-13T13:33:02Z",
            "summary": "In this report we present the status of the Mainz group's lattice QCD\ncalculation of the pion transition form factor, which describes the interaction\nof an on-shell pion with two off-shell photons. This form factor is the main\ningredient in the calculation of the pion-pole contribution to hadronic\nlight-by-light scattering in the muon $g-2$. We use the $N_f = 2 + 1$ CLS gauge\nensembles, and we update our previous work by including a physical pion mass\nensemble (E250). We compute the transition form factor in a moving frame as\nwell as in the pion rest frame in order to have access to a wider range of\nphoton virtualities. In addition to the quark-line connected correlator we also\ncompute the quark-line disconnected diagrams that contribute to the form\nfactor. At the final stage of the analysis, the result on E250 will be combined\nwith the previous work published in 2019 to extrapolate the form factor to the\ncontinuum and to physical quark masses.",
            "author": [
                "Jonna Koponen",
                "Antoine G\u00e9rardin",
                "Harvey B. Meyer",
                "Konstantin Ottnad",
                "Georg von Hippel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07330v1",
                "http://arxiv.org/pdf/2311.07330v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07324v1",
            "title": "DAGC: Data-Volume-Aware Adaptive Sparsification Gradient Compression for\n  Distributed Machine Learning in Mobile Computing",
            "updated": "2023-11-13T13:24:09Z",
            "published": "2023-11-13T13:24:09Z",
            "summary": "Distributed machine learning (DML) in mobile environments faces significant\ncommunication bottlenecks. Gradient compression has emerged as an effective\nsolution to this issue, offering substantial benefits in environments with\nlimited bandwidth and metered data. Yet, they encounter severe performance drop\nin non-IID environments due to a one-size-fits-all compression approach, which\ndoes not account for the varying data volumes across workers. Assigning varying\ncompression ratios to workers with distinct data distributions and volumes is\nthus a promising solution. This study introduces an analysis of distributed SGD\nwith non-uniform compression, which reveals that the convergence rate\n(indicative of the iterations needed to achieve a certain accuracy) is\ninfluenced by compression ratios applied to workers with differing volumes.\nAccordingly, we frame relative compression ratio assignment as an $n$-variables\nchi-square nonlinear optimization problem, constrained by a fixed and limited\ncommunication budget. We propose DAGC-R, which assigns the worker handling\nlarger data volumes the conservative compression. Recognizing the computational\nlimitations of mobile devices, we DAGC-A, which are computationally less\ndemanding and enhances the robustness of the absolute gradient compressor in\nnon-IID scenarios. Our experiments confirm that both the DAGC-A and DAGC-R can\nachieve better performance when dealing with highly imbalanced data volume\ndistribution and restricted communication.",
            "author": [
                "Rongwei Lu",
                "Yutong Jiang",
                "Yinan Mao",
                "Chen Tang",
                "Bin Chen",
                "Laizhong Cui",
                "Zhi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07324v1",
                "http://arxiv.org/pdf/2311.07324v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07321v1",
            "title": "Connecting the Dots: Graph Neural Network Powered Ensemble and\n  Classification of Medical Images",
            "updated": "2023-11-13T13:20:54Z",
            "published": "2023-11-13T13:20:54Z",
            "summary": "Deep learning models have demonstrated remarkable results for various\ncomputer vision tasks, including the realm of medical imaging. However, their\napplication in the medical domain is limited due to the requirement for large\namounts of training data, which can be both challenging and expensive to\nobtain. To mitigate this, pre-trained models have been fine-tuned on\ndomain-specific data, but such an approach can suffer from inductive biases.\nFurthermore, deep learning models struggle to learn the relationship between\nspatially distant features and their importance, as convolution operations\ntreat all pixels equally. Pioneering a novel solution to this challenge, we\nemploy the Image Foresting Transform to optimally segment images into\nsuperpixels. These superpixels are subsequently transformed into\ngraph-structured data, enabling the proficient extraction of features and\nmodeling of relationships using Graph Neural Networks (GNNs). Our method\nharnesses an ensemble of three distinct GNN architectures to boost its\nrobustness. In our evaluations targeting pneumonia classification, our\nmethodology surpassed prevailing Deep Neural Networks (DNNs) in performance,\nall while drastically cutting down on the parameter count. This not only trims\ndown the expenses tied to data but also accelerates training and minimizes\nbias. Consequently, our proposition offers a sturdy, economically viable, and\nscalable strategy for medical image classification, significantly diminishing\ndependency on extensive training data sets.",
            "author": [
                "Aryan Singh",
                "Pepijn Van de Ven",
                "Ciar\u00e1n Eising",
                "Patrick Denny"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07321v1",
                "http://arxiv.org/pdf/2311.07321v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07314v1",
            "title": "Semi-automatic Data Enhancement for Document-Level Relation Extraction\n  with Distant Supervision from Large Language Models",
            "updated": "2023-11-13T13:10:44Z",
            "published": "2023-11-13T13:10:44Z",
            "summary": "Document-level Relation Extraction (DocRE), which aims to extract relations\nfrom a long context, is a critical challenge in achieving fine-grained\nstructural comprehension and generating interpretable document representations.\nInspired by recent advances in in-context learning capabilities emergent from\nlarge language models (LLMs), such as ChatGPT, we aim to design an automated\nannotation method for DocRE with minimum human effort. Unfortunately, vanilla\nin-context learning is infeasible for document-level relation extraction due to\nthe plenty of predefined fine-grained relation types and the uncontrolled\ngenerations of LLMs. To tackle this issue, we propose a method integrating a\nlarge language model (LLM) and a natural language inference (NLI) module to\ngenerate relation triples, thereby augmenting document-level relation datasets.\nWe demonstrate the effectiveness of our approach by introducing an enhanced\ndataset known as DocGNRE, which excels in re-annotating numerous long-tail\nrelation types. We are confident that our method holds the potential for\nbroader applications in domain-specific relation type definitions and offers\ntangible benefits in advancing generalized language semantic comprehension.",
            "author": [
                "Junpeng Li",
                "Zixia Jia",
                "Zilong Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07314v1",
                "http://arxiv.org/pdf/2311.07314v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07312v1",
            "title": "C-Procgen: Empowering Procgen with Controllable Contexts",
            "updated": "2023-11-13T13:07:48Z",
            "published": "2023-11-13T13:07:48Z",
            "summary": "We present C-Procgen, an enhanced suite of environments on top of the Procgen\nbenchmark. C-Procgen provides access to over 200 unique game contexts across 16\ngames. It allows for detailed configuration of environments, ranging from game\nmechanics to agent attributes. This makes the procedural generation process,\npreviously a black-box in Procgen, more transparent and adaptable for various\nresearch needs.The upgrade enhances dynamic context management and\nindividualized assignments, while maintaining computational efficiency.\nC-Procgen's controllable contexts make it applicable in diverse reinforcement\nlearning research areas, such as learning dynamics analysis, curriculum\nlearning, and transfer learning. We believe that C-Procgen will fill a gap in\nthe current literature and offer a valuable toolkit for future works.",
            "author": [
                "Zhenxiong Tan",
                "Kaixin Wang",
                "Xinchao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07312v1",
                "http://arxiv.org/pdf/2311.07312v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07311v1",
            "title": "Do large language models and humans have similar behaviors in causal\n  inference with script knowledge?",
            "updated": "2023-11-13T13:05:15Z",
            "published": "2023-11-13T13:05:15Z",
            "summary": "Recently, large pre-trained language models (LLMs) have demonstrated superior\nlanguage understanding abilities, including zero-shot causal reasoning.\nHowever, it is unclear to what extent their capabilities are similar to human\nones. We here study the processing of an event $B$ in a script-based story,\nwhich causally depends on a previous event $A$. In our manipulation, event $A$\nis stated, negated, or omitted in an earlier section of the text. We first\nconducted a self-paced reading experiment, which showed that humans exhibit\nsignificantly longer reading times when causal conflicts exist ($\\neg A\n\\rightarrow B$) than under logical conditions ($A \\rightarrow B$). However,\nreading times remain similar when cause A is not explicitly mentioned,\nindicating that humans can easily infer event B from their script knowledge. We\nthen tested a variety of LLMs on the same data to check to what extent the\nmodels replicate human behavior. Our experiments show that 1) only recent LLMs,\nlike GPT-3 or Vicuna, correlate with human behavior in the $\\neg A \\rightarrow\nB$ condition. 2) Despite this correlation, all models still fail to predict\nthat $nil \\rightarrow B$ is less surprising than $\\neg A \\rightarrow B$,\nindicating that LLMs still have difficulties integrating script knowledge. Our\ncode and collected data set are available at\nhttps://github.com/tony-hong/causal-script.",
            "author": [
                "Xudong Hong",
                "Margarita Ryzhova",
                "Daniel Adrian Biondi",
                "Vera Demberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07311v1",
                "http://arxiv.org/pdf/2311.07311v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7; I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07310v2",
            "title": "Dynamic Optimization on Quantum Hardware: Feasibility for a Process\n  Industry Use Case",
            "updated": "2023-11-15T14:50:04Z",
            "published": "2023-11-13T13:03:37Z",
            "summary": "The quest for real-time dynamic optimization solutions in the process\nindustry represents a formidable computational challenge, particularly within\nthe realm of applications like model predictive control where rapid and\nreliable computations are critical. Conventional methods can struggle to\nsurmount the complexities of such tasks. Quantum computing and quantum\nannealing emerge as avant-garde contenders to transcend conventional\ncomputational constraints. We convert a dynamic optimization problem,\ncharacterized by a system of differential equations, into a Quadratic\nUnconstrained Binary Optimization problem, enabling quantum computational\napproaches. The empirical findings synthesized from classical methods,\nsimulated annealing, quantum annealing via D-Wave's quantum annealer, and\nhybrid solver methodologies, illuminate the intricate landscape of\ncomputational prowess essential for tackling complex and high-dimensional\ndynamic optimization problems. Our findings suggest that while quantum\nannealing is a maturing technology that currently does not outperform\nstate-of-the-art classical solvers, continuous improvements could eventually\naid in increasing efficiency within the chemical process industry.",
            "author": [
                "Dennis Michael Nenno",
                "Adrian Caspari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07310v2",
                "http://arxiv.org/pdf/2311.07310v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07306v1",
            "title": "What Large Language Models Bring to Text-rich VQA?",
            "updated": "2023-11-13T12:52:29Z",
            "published": "2023-11-13T12:52:29Z",
            "summary": "Text-rich VQA, namely Visual Question Answering based on text recognition in\nthe images, is a cross-modal task that requires both image comprehension and\ntext recognition. In this work, we focus on investigating the advantages and\nbottlenecks of LLM-based approaches in addressing this problem. To address the\nabove concern, we separate the vision and language modules, where we leverage\nexternal OCR models to recognize texts in the image and Large Language Models\n(LLMs) to answer the question given texts. The whole framework is training-free\nbenefiting from the in-context ability of LLMs. This pipeline achieved superior\nperformance compared to the majority of existing Multimodal Large Language\nModels (MLLM) on four text-rich VQA datasets. Besides, based on the ablation\nstudy, we find that LLM brings stronger comprehension ability and may introduce\nhelpful knowledge for the VQA problem. The bottleneck for LLM to address\ntext-rich VQA problems may primarily lie in visual part. We also combine the\nOCR module with MLLMs and pleasantly find that the combination of OCR module\nwith MLLM also works. It's worth noting that not all MLLMs can comprehend the\nOCR information, which provides insights into how to train an MLLM that\npreserves the abilities of LLM.",
            "author": [
                "Xuejing Liu",
                "Wei Tang",
                "Xinzhe Ni",
                "Jinghui Lu",
                "Rui Zhao",
                "Zechao Li",
                "Fei Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07306v1",
                "http://arxiv.org/pdf/2311.07306v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07302v1",
            "title": "Continuous Coherent Quantum Feedback with Time Delays: Tensor Network\n  Solution",
            "updated": "2023-11-13T12:46:58Z",
            "published": "2023-11-13T12:46:58Z",
            "summary": "In this paper we develop a novel method to solve problems involving quantum\noptical systems coupled to coherent quantum feedback loops featuring time\ndelays. Our method is based on exact mappings of such non-Markovian problems to\nequivalent Markovian driven dissipative quantum many-body problems. In this\nwork we show that the resulting Markovian quantum many-body problems can be\nsolved (numerically) exactly and efficiently using tensor network methods for a\nseries of paradigmatic examples, consisting of driven quantum systems coupled\nto waveguides at several distant points. In particular, we show that our method\nallows solving problems in so far inaccessible regimes, including problems with\narbitrary long time delays and arbitrary numbers of excitations in the delay\nlines. We obtain solutions for the full real-time dynamics as well as the\nsteady state in all these regimes. Finally, motivated by our results, we\ndevelop a novel mean-field approach, which allows us to find the solution\nsemi-analytically and identify parameter regimes where this approximation is in\nexcellent agreement with our exact tensor network results.",
            "author": [
                "Kseniia Vodenkova",
                "Hannes Pichler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07302v1",
                "http://arxiv.org/pdf/2311.07302v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07301v1",
            "title": "Dynamically Weighted Factor-Graph for Feature-based Geo-localization",
            "updated": "2023-11-13T12:44:14Z",
            "published": "2023-11-13T12:44:14Z",
            "summary": "Feature-based geo-localization relies on associating features extracted from\naerial imagery with those detected by the vehicle's sensors. This requires that\nthe type of landmarks must be observable from both sources. This no-variety of\nfeature types generates poor representations that lead to outliers and\ndeviations, produced by ambiguities and lack of detections respectively. To\nmitigate these drawbacks, in this paper, we present a dynamically weighted\nfactor graph model for the vehicle's trajectory estimation. The weight\nadjustment in this implementation depends on information quantification in the\ndetections performed using a LiDAR sensor. Also, a prior (GNSS-based) error\nestimation is included in the model. Then, when the representation becomes\nambiguous or sparse, the weights are dynamically adjusted to rely on the\ncorrected prior trajectory, mitigating in this way outliers and deviations. We\ncompare our method against state-of-the-art geo-localization ones in a\nchallenging ambiguous environment, where we also cause detection losses. We\ndemonstrate mitigation of the mentioned drawbacks where the other methods fail.",
            "author": [
                "Miguel \u00c1ngel Mu\u00f1oz-Ba\u00f1\u00f3n",
                "Alejandro Olivas",
                "Edison Velasco-S\u00e1nchez",
                "Francisco A. Candelas",
                "Fernando Torres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07301v1",
                "http://arxiv.org/pdf/2311.07301v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07296v1",
            "title": "BIDRN: A Method of Bidirectional Recurrent Neural Network for Sentiment\n  Analysis",
            "updated": "2023-11-13T12:36:53Z",
            "published": "2023-11-13T12:36:53Z",
            "summary": "Text mining research has grown in importance in recent years due to the\ntremendous increase in the volume of unstructured textual data. This has\nresulted in immense potential as well as obstacles in the sector, which may be\nefficiently addressed with adequate analytical and study methods. Deep\nBidirectional Recurrent Neural Networks are used in this study to analyze\nsentiment. The method is categorized as sentiment polarity analysis because it\nmay generate a dataset with sentiment labels. This dataset can be used to train\nand evaluate sentiment analysis models capable of extracting impartial\nopinions. This paper describes the Sentiment Analysis-Deep Bidirectional\nRecurrent Neural Networks (SA-BDRNN) Scheme, which seeks to overcome the\nchallenges and maximize the potential of text mining in the context of Big\nData. The current study proposes a SA-DBRNN Scheme that attempts to give a\nsystematic framework for sentiment analysis in the context of student input on\ninstitution choice. The purpose of this study is to compare the effectiveness\nof the proposed SA- DBRNN Scheme to existing frameworks to establish a robust\ndeep neural network that might serve as an adequate classification model in the\nfield of sentiment analysis.",
            "author": [
                "Dr. D Muthusankar",
                "Dr. P Kaladevi",
                "Dr. V R Sadasivam",
                "R Praveen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07296v1",
                "http://arxiv.org/pdf/2311.07296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07293v1",
            "title": "Microwave-to-Optical Quantum Transduction Utilizing the Topological\n  Faraday Effect of Topological Insulator Heterostructures",
            "updated": "2023-11-13T12:35:33Z",
            "published": "2023-11-13T12:35:33Z",
            "summary": "The quantum transduction between microwave and optical photons is essential\nfor realizing scalable quantum computers with superconducting qubits. Due to\nthe large frequency difference between microwave and optical ranges, the\ntransduction needs to be done via intermediate bosonic modes or nonlinear\nprocesses. So far, the transduction efficiency $\\eta$ via the magneto-optic\nFaraday effect (i.e., the light-magnon interaction) in the ferromagnet YIG has\nbeen demonstrated to be small as $\\eta\\sim 10^{-8} \\mathrm{-} 10^{-15}$ due to\nthe sample size limitation inside the cavity. Here, we take advantage of the\nfact that three-dimensional topological insulator thin films exhibit a\ntopological Faraday effect that is independent of the sample thickness. This\nleads to a large Faraday rotation angle and therefore enhanced light-magnon\ninteraction in the thin film limit. We show theoretically that the transduction\nefficiency can be greatly improved to $\\eta\\sim10^{-4}$ by utilizing the\nheterostructures consisting of topological insulator thin films such as\nBi$_2$Se$_3$ and ferromagnetic insulator thin films such as YIG.",
            "author": [
                "Akihiko Sekine",
                "Mari Ohfuchi",
                "Yoshiyasu Doi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07293v1",
                "http://arxiv.org/pdf/2311.07293v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.str-el",
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07291v1",
            "title": "LiLO: Lightweight and low-bias LiDAR Odometry method based on spherical\n  range image filtering",
            "updated": "2023-11-13T12:34:43Z",
            "published": "2023-11-13T12:34:43Z",
            "summary": "In unstructured outdoor environments, robotics requires accurate and\nefficient odometry with low computational time. Existing low-bias LiDAR\nodometry methods are often computationally expensive. To address this problem,\nwe present a lightweight LiDAR odometry method that converts unorganized point\ncloud data into a spherical range image (SRI) and filters out surface, edge,\nand ground features in the image plane. This substantially reduces computation\ntime and the required features for odometry estimation in LOAM-based\nalgorithms. Our odometry estimation method does not rely on global maps or loop\nclosure algorithms, which further reduces computational costs. Experimental\nresults generate a translation and rotation error of 0.86\\% and 0.0036{\\deg}/m\non the KITTI dataset with an average runtime of 78ms. In addition, we tested\nthe method with our data, obtaining an average closed-loop error of 0.8m and a\nruntime of 27ms over eight loops covering 3.5Km.",
            "author": [
                "Edison P. Velasco-S\u00e1nchez",
                "Miguel \u00c1ngel Mu\u00f1oz-Ba\u00f1\u00f3n",
                "Francisco A. Candelas",
                "Santiago T. Puente",
                "Fernando Torres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07291v1",
                "http://arxiv.org/pdf/2311.07291v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07285v1",
            "title": "Multi Sentence Description of Complex Manipulation Action Videos",
            "updated": "2023-11-13T12:27:06Z",
            "published": "2023-11-13T12:27:06Z",
            "summary": "Automatic video description requires the generation of natural language\nstatements about the actions, events, and objects in the video. An important\nhuman trait, when we describe a video, is that we are able to do this with\nvariable levels of detail. Different from this, existing approaches for\nautomatic video descriptions are mostly focused on single sentence generation\nat a fixed level of detail. Instead, here we address video description of\nmanipulation actions where different levels of detail are required for being\nable to convey information about the hierarchical structure of these actions\nrelevant also for modern approaches of robot learning. We propose one hybrid\nstatistical and one end-to-end framework to address this problem. The hybrid\nmethod needs much less data for training, because it models statistically\nuncertainties within the video clips, while in the end-to-end method, which is\nmore data-heavy, we are directly connecting the visual encoder to the language\ndecoder without any intermediate (statistical) processing step. Both frameworks\nuse LSTM stacks to allow for different levels of description granularity and\nvideos can be described by simple single-sentences or complex multiple-sentence\ndescriptions. In addition, quantitative results demonstrate that these methods\nproduce more realistic descriptions than other competing approaches.",
            "author": [
                "Fatemeh Ziaeetabar",
                "Reza Safabakhsh",
                "Saeedeh Momtazi",
                "Minija Tamosiunaite",
                "Florentin W\u00f6rg\u00f6tter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07285v1",
                "http://arxiv.org/pdf/2311.07285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07284v1",
            "title": "Learning Arithmetic Formulas in the Presence of Noise: A General\n  Framework and Applications to Unsupervised Learning",
            "updated": "2023-11-13T12:26:25Z",
            "published": "2023-11-13T12:26:25Z",
            "summary": "We present a general framework for designing efficient algorithms for\nunsupervised learning problems, such as mixtures of Gaussians and subspace\nclustering. Our framework is based on a meta algorithm that learns arithmetic\ncircuits in the presence of noise, using lower bounds. This builds upon the\nrecent work of Garg, Kayal and Saha (FOCS 20), who designed such a framework\nfor learning arithmetic circuits without any noise. A key ingredient of our\nmeta algorithm is an efficient algorithm for a novel problem called Robust\nVector Space Decomposition. We show that our meta algorithm works well when\ncertain matrices have sufficiently large smallest non-zero singular values. We\nconjecture that this condition holds for smoothed instances of our problems,\nand thus our framework would yield efficient algorithms for these problems in\nthe smoothed setting.",
            "author": [
                "Pritam Chandra",
                "Ankit Garg",
                "Neeraj Kayal",
                "Kunal Mittal",
                "Tanmay Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07284v1",
                "http://arxiv.org/pdf/2311.07284v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07279v2",
            "title": "Gravitational waves from extreme-mass-ratio inspirals in the\n  semiclassical gravity spacetime",
            "updated": "2023-11-29T06:54:54Z",
            "published": "2023-11-13T12:23:02Z",
            "summary": "More recently, Fernandes \\cite{Fernandes:2023vux} discovered analytic\nstationary and axially-symmetric black hole solutions within semiclassical\ngravity, driven by the trace anomaly. The study unveils some distinctive\nfeatures of these solutions. In this paper, we compute the gravitational waves\nemitted from the \\ac{EMRI} around these quantum-corrected rotating black holes\nusing the kludge approximate method. Firstly, we derive the orbital energy,\nangular momentum and fundamental frequencies for orbits on the equatorial\nplane. We find that, for the gravitational radiation described by quadrupole\nformulas, the contribution from the trace anomaly only appears at higher-order\nterms in the energy flux when compared with the standard Kerr case. Therefore,\nwe can compute the EMRI waveforms from the quantum-corrected rotating black\nhole using the Kerr fluxes. We assess the differences between the EMRI\nwaveforms from rotating black holes with and without the trace anomaly by\ncalculating the dephasing and mismatch. Our results demonstrate that\nspace-borne gravitational wave detectors can distinguish the EMRI waveform from\nthe quantum-corrected black holes with a fractional coupling constant of $\\sim\n10^{-3}$ within one year observation. Finally, we compute the constraint on the\ncoupling constant using the Fisher information matrix method and find that the\npotential constraint on the coupling constant by LISA can be within the error\n$\\sim 10^{-4}$ in suitable scenarios.",
            "author": [
                "Tieguang Zi",
                "Peng-Cheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07279v2",
                "http://arxiv.org/pdf/2311.07279v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07277v1",
            "title": "AdaCCD: Adaptive Semantic Contrasts Discovery based Cross Lingual\n  Adaptation for Code Clone Detection",
            "updated": "2023-11-13T12:20:48Z",
            "published": "2023-11-13T12:20:48Z",
            "summary": "Code Clone Detection, which aims to retrieve functionally similar programs\nfrom large code bases, has been attracting increasing attention. Modern\nsoftware often involves a diverse range of programming languages. However,\ncurrent code clone detection methods are generally limited to only a few\npopular programming languages due to insufficient annotated data as well as\ntheir own model design constraints. To address these issues, we present AdaCCD,\na novel cross-lingual adaptation method that can detect cloned codes in a new\nlanguage without any annotations in that language. AdaCCD leverages\nlanguage-agnostic code representations from pre-trained programming language\nmodels and propose an Adaptively Refined Contrastive Learning framework to\ntransfer knowledge from resource-rich languages to resource-poor languages. We\nevaluate the cross-lingual adaptation results of AdaCCD by constructing a\nmultilingual code clone detection benchmark consisting of 5 programming\nlanguages. AdaCCD achieves significant improvements over other baselines, and\nit is even comparable to supervised fine-tuning.",
            "author": [
                "Yangkai Du",
                "Tengfei Ma",
                "Lingfei Wu",
                "Xuhong Zhang",
                "Shouling Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07277v1",
                "http://arxiv.org/pdf/2311.07277v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07273v1",
            "title": "Sumanene monolayer of pure carbon: a two-dimensional Kagome-analogy\n  lattice with desirable band gap, ultrahigh carrier mobility and strong\n  exciton binding energy",
            "updated": "2023-11-13T12:13:48Z",
            "published": "2023-11-13T12:13:48Z",
            "summary": "Design and synthesis of novel two-dimensional (2D) materials that possess\nrobust structural stability and unusual physical properties may open up\nenormous opportunities for device and engineering applications. Herein we\npropose a 2D sumanene lattice that be regarded as a derivative of the\nconventional Kagome lattice. Our tight-binding analysis demonstrates sumanene\nlattice contains two sets of Dirac cones and two sets of flat bands near the\nFermi surface, distinctively different from the Kagome lattice. Using\nfirst-principles calculations, we theoretically suggest two possible routines\nfor realization of stable 2D sumanene monolayers (named as a phase and b\nphase), and a-sumanene monolayer can be experimentally synthesized with\nchemical vapor deposition using C21H12 as a precursor. Small binding energies\non Au(111) surface signify the possibility of their peel-off after grown on the\nnoble metal substrate. Importantly, our GW plus Bethe-Salpeter equation\ncalculations demonstrate both monolayers have moderate band gaps (1.94 eV for\na) and ultrahigh carrier mobilities (3.4*104 cm2/Vs for a). In particular,\na-sumanene monolayer possesses a strong exciton binding energy of 0.73 eV,\nsuggesting potential applications in optics.",
            "author": [
                "Xiaoran Shi",
                "Weiwei Gao",
                "Hongsheng Liu",
                "Zhen-Guo Fu",
                "Gang Zhang",
                "Yong-Wei Zhang",
                "Junfeng Gao",
                "Jijun Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1002/smll.202203274",
                "http://arxiv.org/abs/2311.07273v1",
                "http://arxiv.org/pdf/2311.07273v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07631v1",
            "title": "The 4+1 Model of Data Science",
            "updated": "2023-11-13T12:12:32Z",
            "published": "2023-11-13T12:12:32Z",
            "summary": "Data Science is a complex and evolving field, but most agree that it can be\ndefined as a combination of expertise drawn from three broad areascomputer\nscience and technology, math and statistics, and domain knowledge -- with the\npurpose of extracting knowledge and value from data. Beyond this, the field is\noften defined as a series of practical activities ranging from the cleaning and\nwrangling of data, to its analysis and use to infer models, to the visual and\nrhetorical representation of results to stakeholders and decision-makers. This\nessay proposes a model of data science that goes beyond laundry-list\ndefinitions to get at the specific nature of data science and help distinguish\nit from adjacent fields such as computer science and statistics. We define data\nscience as an interdisciplinary field comprising four broad areas of expertise:\nvalue, design, systems, and analytics. A fifth area, practice, integrates the\nother four in specific contexts of domain knowledge. We call this the 4+1 model\nof data science. Together, these areas belong to every data science project,\neven if they are often unconnected and siloed in the academy.",
            "author": [
                "Rafael C. Alvarado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07631v1",
                "http://arxiv.org/pdf/2311.07631v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.GL",
                "E.m; K.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07272v1",
            "title": "Hydrodynamic theories for a system of weakly self-interacting classical\n  ultra-relativistic scalar particles: causality and stability",
            "updated": "2023-11-13T12:11:25Z",
            "published": "2023-11-13T12:11:25Z",
            "summary": "We investigate the causality and stability of three different relativistic\ndissipative fluid-dynamical formulations emerging from a system of classical,\nultra-relativistic scalar particles self-interacting via a quartic potential.\nFor this particular interaction, all transport coefficients of Navier-Stokes,\nBemfica-Disconzi-Noronha-Kovtun and second-order transient theories can be\ncomputed in analytical form. We first show that Navier-Stokes theory is acausal\nand unstable regardless of the matching conditions. On the other hand, BDNK\ntheory can be linearly causal and stable for a particular set of matching\nchoices that does not contain the so-called exotic Eckart prescription. In\nparticular, using the Li\\'enard-Chipart criterion, we obtain a set of\nsufficient conditions that guarantee the stability of the theory. Last,\nsecond-order transient hydrodynamic theory in Landau matching is shown to be\nlinearly causal and stable.",
            "author": [
                "Caio V. P. de Brito",
                "Gabriel S. Rocha",
                "Gabriel S. Denicol"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07272v1",
                "http://arxiv.org/pdf/2311.07272v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07265v3",
            "title": "Quotient Space Quantum Codes",
            "updated": "2023-12-04T14:53:36Z",
            "published": "2023-11-13T12:03:59Z",
            "summary": "Quantum error-correcting codes are crucial for quantum computing and\ncommunication. Currently, these codes are mainly categorized into additive,\nnon-additive, and surface codes. Additive and non-additive codes utilize one or\nmore invariant subspaces of the stabilizer G to construct quantum codes.\nTherefore, the selection of these invariant subspaces is a key issue. In this\npaper, we propose a solution to this problem by introducing quotient space\ncodes and a construction method for quotient space quantum codes. This new\nframework unifies additive and non-additive quantum codes. We demonstrate the\ncodeword stabilizer codes as a special case within this framework and\nsupplement its error-correction distance. Furthermore, we provide a simple\nproof of the Singleton bound for this quantum code by establishing the code\nbound of quotient space codes and discuss the code bounds for pure and impure\ncodes. The quotient space approach offers a concise and clear mathematical form\nfor the study of quantum codes.",
            "author": [
                "Jing-Lei Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07265v3",
                "http://arxiv.org/pdf/2311.07265v3"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07264v1",
            "title": "Danish Foundation Models",
            "updated": "2023-11-13T12:03:52Z",
            "published": "2023-11-13T12:03:52Z",
            "summary": "Large language models, sometimes referred to as foundation models, have\ntransformed multiple fields of research. However, smaller languages risk\nfalling behind due to high training costs and small incentives for large\ncompanies to train these models. To combat this, the Danish Foundation Models\nproject seeks to provide and maintain open, well-documented, and high-quality\nfoundation models for the Danish language. This is achieved through broad\ncooperation with public and private institutions, to ensure high data quality\nand applicability of the trained models. We present the motivation of the\nproject, the current status, and future perspectives.",
            "author": [
                "Kenneth Enevoldsen",
                "Lasse Hansen",
                "Dan S. Nielsen",
                "Rasmus A. F. Egeb\u00e6k",
                "S\u00f8ren V. Holm",
                "Martin C. Nielsen",
                "Martin Bernstorff",
                "Rasmus Larsen",
                "Peter B. J\u00f8rgensen",
                "Malte H\u00f8jmark-Bertelsen",
                "Peter B. Vahlstrup",
                "Per M\u00f8ldrup-Dalum",
                "Kristoffer Nielbo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07264v1",
                "http://arxiv.org/pdf/2311.07264v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07263v1",
            "title": "LT-ViT: A Vision Transformer for multi-label Chest X-ray classification",
            "updated": "2023-11-13T12:02:46Z",
            "published": "2023-11-13T12:02:46Z",
            "summary": "Vision Transformers (ViTs) are widely adopted in medical imaging tasks, and\nsome existing efforts have been directed towards vision-language training for\nChest X-rays (CXRs). However, we envision that there still exists a potential\nfor improvement in vision-only training for CXRs using ViTs, by aggregating\ninformation from multiple scales, which has been proven beneficial for\nnon-transformer networks. Hence, we have developed LT-ViT, a transformer that\nutilizes combined attention between image tokens and randomly initialized\nauxiliary tokens that represent labels. Our experiments demonstrate that LT-ViT\n(1) surpasses the state-of-the-art performance using pure ViTs on two publicly\navailable CXR datasets, (2) is generalizable to other pre-training methods and\ntherefore is agnostic to model initialization, and (3) enables model\ninterpretability without grad-cam and its variants.",
            "author": [
                "Umar Marikkar",
                "Sara Atito",
                "Muhammad Awais",
                "Adam Mahdi"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICIP49359.2023.10222175",
                "http://arxiv.org/abs/2311.07263v1",
                "http://arxiv.org/pdf/2311.07263v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07261v1",
            "title": "Sketch-based Video Object Segmentation: Benchmark and Analysis",
            "updated": "2023-11-13T11:53:49Z",
            "published": "2023-11-13T11:53:49Z",
            "summary": "Reference-based video object segmentation is an emerging topic which aims to\nsegment the corresponding target object in each video frame referred by a given\nreference, such as a language expression or a photo mask. However, language\nexpressions can sometimes be vague in conveying an intended concept and\nambiguous when similar objects in one frame are hard to distinguish by\nlanguage. Meanwhile, photo masks are costly to annotate and less practical to\nprovide in a real application. This paper introduces a new task of sketch-based\nvideo object segmentation, an associated benchmark, and a strong baseline. Our\nbenchmark includes three datasets, Sketch-DAVIS16, Sketch-DAVIS17 and\nSketch-YouTube-VOS, which exploit human-drawn sketches as an informative yet\nlow-cost reference for video object segmentation. We take advantage of STCN, a\npopular baseline of semi-supervised VOS task, and evaluate what the most\neffective design for incorporating a sketch reference is. Experimental results\nshow sketch is more effective yet annotation-efficient than other references,\nsuch as photo masks, language and scribble.",
            "author": [
                "Ruolin Yang",
                "Da Li",
                "Conghui Hu",
                "Timothy Hospedales",
                "Honggang Zhang",
                "Yi-Zhe Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07261v1",
                "http://arxiv.org/pdf/2311.07261v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07259v1",
            "title": "Towards Bounding Causal Effects under Markov Equivalence",
            "updated": "2023-11-13T11:49:55Z",
            "published": "2023-11-13T11:49:55Z",
            "summary": "Predicting the effect of unseen interventions is a fundamental research\nquestion across the data sciences. It is well established that, in general,\nsuch questions cannot be answered definitively from observational data, e.g.,\nas a consequence of unobserved confounding. A generalization of this task is to\ndetermine non-trivial bounds on causal effects induced by the data, also known\nas the task of partial causal identification. In the literature, several\nalgorithms have been developed for solving this problem. Most, however, require\na known parametric form or a fully specified causal diagram as input, which is\nusually not available in practical applications. In this paper, we assume as\ninput a less informative structure known as a Partial Ancestral Graph, which\nrepresents a Markov equivalence class of causal diagrams and is learnable from\nobservational data. In this more \"data-driven\" setting, we provide a systematic\nalgorithm to derive bounds on causal effects that can be computed analytically.",
            "author": [
                "Alexis Bellot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07259v1",
                "http://arxiv.org/pdf/2311.07259v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07251v1",
            "title": "The Dynamics of a Bicycle on a Pump Track -- First Results on Modeling\n  and Optimal Control",
            "updated": "2023-11-13T11:36:03Z",
            "published": "2023-11-13T11:36:03Z",
            "summary": "We investigate the dynamics of a bicycle on an uneven mountain bike track\nsplit into straight sections with small jumps (kickers) and banked corners. A\nbasic bike-rider model is proposed and used to derive equations of motion,\nwhich capture the possibilities to accelerate the bicycle without pedaling.\nSince this is a first approach to the problem, only corners connected by\nstraight lines are considered to compute optimal riding strategies. The\nsimulation is validated with experimental data obtained on a real pump track.\nIt is demonstrated that the model effectively captures the longitudinal bike\nacceleration resulting from the relative vertical motion between the rider's\nupper body and the bicycle. Our numerical results are in good analogy with real\nrider's actions on similar tracks.",
            "author": [
                "Julian Golembiewski",
                "Marcus Schmidt",
                "Benedikt Terschluse",
                "Thomas Jaitner",
                "Thomas Liebig",
                "Timm Faulwasser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07251v1",
                "http://arxiv.org/pdf/2311.07251v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07247v2",
            "title": "Simultaneous Clutter Detection and Semantic Segmentation of Moving\n  Objects for Automotive Radar Data",
            "updated": "2023-11-14T07:36:39Z",
            "published": "2023-11-13T11:29:38Z",
            "summary": "The unique properties of radar sensors, such as their robustness to adverse\nweather conditions, make them an important part of the environment perception\nsystem of autonomous vehicles. One of the first steps during the processing of\nradar point clouds is often the detection of clutter, i.e. erroneous points\nthat do not correspond to real objects. Another common objective is the\nsemantic segmentation of moving road users. These two problems are handled\nstrictly separate from each other in literature. The employed neural networks\nare always focused entirely on only one of the tasks. In contrast to this, we\nexamine ways to solve both tasks at the same time with a single jointly used\nmodel. In addition to a new augmented multi-head architecture, we also devise a\nmethod to represent a network's predictions for the two tasks with only one\noutput value. This novel approach allows us to solve the tasks simultaneously\nwith the same inference time as a conventional task-specific model. In an\nextensive evaluation, we show that our setup is highly effective and\noutperforms every existing network for semantic segmentation on the RadarScenes\ndataset.",
            "author": [
                "Johannes Kopp",
                "Dominik Kellner",
                "Aldi Piroli",
                "Vinzenz Dallabetta",
                "Klaus Dietmayer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07247v2",
                "http://arxiv.org/pdf/2311.07247v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07239v1",
            "title": "RESenv: A Realistic Earthquake Simulation Environment based on Unreal\n  Engine",
            "updated": "2023-11-13T11:08:10Z",
            "published": "2023-11-13T11:08:10Z",
            "summary": "Earthquakes have a significant impact on societies and economies, driving the\nneed for effective search and rescue strategies. With the growing role of AI\nand robotics in these operations, high-quality synthetic visual data becomes\ncrucial. Current simulation methods, mostly focusing on single building\ndamages, often fail to provide realistic visuals for complex urban settings. To\nbridge this gap, we introduce an innovative earthquake simulation system using\nthe Chaos Physics System in Unreal Engine. Our approach aims to offer detailed\nand realistic visual simulations essential for AI and robotic training in\nrescue missions. By integrating real seismic waveform data, we enhance the\nauthenticity and relevance of our simulations, ensuring they closely mirror\nreal-world earthquake scenarios. Leveraging the advanced capabilities of Unreal\nEngine, our system delivers not only high-quality visualisations but also\nreal-time dynamic interactions, making the simulated environments more\nimmersive and responsive. By providing advanced renderings, accurate physical\ninteractions, and comprehensive geological movements, our solution outperforms\ntraditional methods in efficiency and user experience. Our simulation\nenvironment stands out in its detail and realism, making it a valuable tool for\nAI tasks such as path planning and image recognition related to earthquake\nresponses. We validate our approach through three AI-based tasks: similarity\ndetection, path planning, and image segmentation.",
            "author": [
                "Yitong Sun",
                "Hanchun Wang",
                "Zhejun Zhang",
                "Cyriel Diels",
                "Ali Asadipour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07239v1",
                "http://arxiv.org/pdf/2311.07239v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07237v1",
            "title": "In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge\n  via Logical Rule Guided Search",
            "updated": "2023-11-13T10:56:59Z",
            "published": "2023-11-13T10:56:59Z",
            "summary": "Since large language models have approached human-level performance on many\ntasks, it has become increasingly harder for researchers to find tasks that are\nstill challenging to the models. Failure cases usually come from the long-tail\ndistribution - data that an oracle language model could assign a probability on\nthe lower end of its distribution. Current methodology such as prompt\nengineering or crowdsourcing are insufficient for creating long-tail examples\nbecause humans are constrained by cognitive bias. We propose a\nLogic-Induced-Knowledge-Search (LINK) framework for systematically generating\nlong-tail knowledge statements. Grounded by a symbolic rule, we search for\nlong-tail values for each variable of the rule by first prompting a LLM, then\nverifying the correctness of the values with a critic, and lastly pushing for\nthe long-tail distribution with a reranker. With this framework we construct a\ndataset, Logic-Induced-Long-Tail (LINT), consisting of 200 symbolic rules and\n50K knowledge statements spanning across four domains. Human annotations find\nthat 84% of the statements in LINT are factually correct. In contrast, ChatGPT\nand GPT4 struggle with directly generating long-tail statements under the\nguidance of logic rules, each only getting 56% and 78% of their statements\ncorrect. Moreover, their \"long-tail\" generations in fact fall into the higher\nlikelihood range, and thus are not really long-tail. Our findings suggest that\nLINK is effective for generating data in the long-tail distribution while\nenforcing quality. LINT can be useful for systematically evaluating LLMs'\ncapabilities in the long-tail distribution. We challenge the models with a\nsimple entailment classification task using samples from LINT. We find that\nChatGPT and GPT4's capability in identifying incorrect knowledge drop by ~3% in\nthe long-tail distribution compared to head distribution.",
            "author": [
                "Huihan Li",
                "Yuting Ning",
                "Zeyi Liao",
                "Siyuan Wang",
                "Xiang Lorraine Li",
                "Ximing Lu",
                "Faeze Brahman",
                "Wenting Zhao",
                "Yejin Choi",
                "Xiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07237v1",
                "http://arxiv.org/pdf/2311.07237v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07236v1",
            "title": "A micro-mechanics based extension of the GTN continuum model accounting\n  for random void distributions",
            "updated": "2023-11-13T10:56:10Z",
            "published": "2023-11-13T10:56:10Z",
            "summary": "Randomness in the void distribution within a ductile metal complicates\nquantitative modeling of damage following the void growth to coalescence\nfailure process. Though the sequence of micro-mechanisms leading to ductile\nfailure is known from unit cell models, often based on assumptions of a regular\ndistribution of voids, the effect of randomness remains a challenge. In the\npresent work, mesoscale unit cell models, each containing an ensemble of four\nvoids of equal size that are randomly distributed, are used to find statistical\neffects on the yield surface of the homogenized material. A yield locus is\nfound based on a mean yield surface and a standard deviation of yield points\nobtained from 15 realizations of the four-void unit cells. It is found that the\nclassical GTN model very closely agrees with the mean of the yield points\nextracted from the unit cell calculations with random void distributions, while\nthe standard deviation $\\textbf{S}$ varies with the imposed stress state. It is\nshown that the standard deviation is nearly zero for stress triaxialities\n$T\\leq1/3$, while it rapidly increases for triaxialities above $T\\approx 1$,\nreaching maximum values of about $\\textbf{S}/\\sigma_0\\approx0.1$ at $T \\approx\n4$. At even higher triaxialities it decreases slightly. The results indicate\nthat the dependence of the standard deviation on the stress state follows from\nvariations in the deformation mechanism since a well-correlated variation is\nfound for the volume fraction of the unit cell that deforms plastically at\nyield. Thus, the random void distribution activates different complex\nlocalization mechanisms at high stress triaxialities that differ from the\nligament thinning mechanism forming the basis for the classical GTN model. A\nmethod for introducing the effect of randomness into the GTN continuum model is\npresented, and an excellent comparison to the unit cell yield locus is\nachieved.",
            "author": [
                "I. Holte",
                "K. L. Nielsen",
                "E. Mart\u00ednez-Pa\u00f1eda",
                "C. F. Niordson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07236v1",
                "http://arxiv.org/pdf/2311.07236v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07235v1",
            "title": "DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery",
            "updated": "2023-11-13T10:55:05Z",
            "published": "2023-11-13T10:55:05Z",
            "summary": "Despite the enhanced realism and immersion provided by VR headsets, users\nfrequently encounter adverse effects such as digital eye strain (DES), dry eye,\nand potential long-term visual impairment due to excessive eye stimulation from\nVR displays and pressure from the mask. Recent VR headsets are increasingly\nequipped with eye-oriented monocular cameras to segment ocular feature maps.\nYet, to compute the incident light stimulus and observe periocular condition\nalterations, it is imperative to transform these relative measurements into\nmetric dimensions. To bridge this gap, we propose a lightweight framework\nderived from the U-Net 3+ deep learning backbone that we re-optimised, to\nestimate measurable periocular depth maps. Compatible with any VR headset\nequipped with an eye-oriented monocular camera, our method reconstructs\nthree-dimensional periocular regions, providing a metric basis for related\nlight stimulus calculation protocols and medical guidelines. Navigating the\ncomplexities of data collection, we introduce a Dynamic Periocular Data\nGeneration (DPDG) environment based on UE MetaHuman, which synthesises\nthousands of training images from a small quantity of human facial scan data.\nEvaluated on a sample of 36 participants, our method exhibited notable efficacy\nin the periocular global precision evaluation experiment, and the pupil\ndiameter measurement.",
            "author": [
                "Yitong Sun",
                "Zijian Zhou",
                "Cyriel Diels",
                "Ali Asadipour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07235v1",
                "http://arxiv.org/pdf/2311.07235v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07234v1",
            "title": "Multi-task learning for joint weakly-supervised segmentation and aortic\n  arch anomaly classification in fetal cardiac MRI",
            "updated": "2023-11-13T10:54:53Z",
            "published": "2023-11-13T10:54:53Z",
            "summary": "Congenital Heart Disease (CHD) is a group of cardiac malformations present\nalready during fetal life, representing the prevailing category of birth\ndefects globally. Our aim in this study is to aid 3D fetal vessel topology\nvisualisation in aortic arch anomalies, a group which encompasses a range of\nconditions with significant anatomical heterogeneity. We present a multi-task\nframework for automated multi-class fetal vessel segmentation from 3D black\nblood T2w MRI and anomaly classification. Our training data consists of binary\nmanual segmentation masks of the cardiac vessels' region in individual subjects\nand fully-labelled anomaly-specific population atlases. Our framework combines\ndeep learning label propagation using VoxelMorph with 3D Attention U-Net\nsegmentation and DenseNet121 anomaly classification. We target 11 cardiac\nvessels and three distinct aortic arch anomalies, including double aortic arch,\nright aortic arch, and suspected coarctation of the aorta. We incorporate an\nanomaly classifier into our segmentation pipeline, delivering a multi-task\nframework with the primary motivation of correcting topological inaccuracies of\nthe segmentation. The hypothesis is that the multi-task approach will encourage\nthe segmenter network to learn anomaly-specific features. As a secondary\nmotivation, an automated diagnosis tool may have the potential to enhance\ndiagnostic confidence in a decision support setting. Our results showcase that\nour proposed training strategy significantly outperforms label propagation and\na network trained exclusively on propagated labels. Our classifier outperforms\na classifier trained exclusively on T2w volume images, with an average balanced\naccuracy of 0.99 (0.01) after joint training. Adding a classifier improves the\nanatomical and topological accuracy of all correctly classified double aortic\narch subjects.",
            "author": [
                "Paula Ramirez",
                "Alena Uus",
                "Milou P. M. van Poppel",
                "Irina Grigorescu",
                "Johannes K. Steinweg",
                "David F. A. Lloyd",
                "Kuberan Pushparajah",
                "Andrew P. King",
                "Maria Deprez"
            ],
            "link": [
                "http://dx.doi.org/10.59275/j.melba.2023-b7bc",
                "http://arxiv.org/abs/2311.07234v1",
                "http://arxiv.org/pdf/2311.07234v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07233v1",
            "title": "IASCAR: Incremental Answer Set Counting by Anytime Refinement",
            "updated": "2023-11-13T10:53:48Z",
            "published": "2023-11-13T10:53:48Z",
            "summary": "Answer set programming (ASP) is a popular declarative programming paradigm\nwith various applications. Programs can easily have many answer sets that\ncannot be enumerated in practice, but counting still allows quantifying\nsolution spaces. If one counts under assumptions on literals, one obtains a\ntool to comprehend parts of the solution space, so-called answer set\nnavigation. However, navigating through parts of the solution space requires\ncounting many times, which is expensive in theory. Knowledge compilation\ncompiles instances into representations on which counting works in polynomial\ntime. However, these techniques exist only for CNF formulas, and compiling ASP\nprograms into CNF formulas can introduce an exponential overhead. This paper\nintroduces a technique to iteratively count answer sets under assumptions on\nknowledge compilations of CNFs that encode supported models. Our anytime\ntechnique uses the inclusion-exclusion principle to improve bounds by over- and\nundercounting systematically. In a preliminary empirical analysis, we\ndemonstrate promising results. After compiling the input (offline phase), our\napproach quickly (re)counts.",
            "author": [
                "Johannes K. Fichte",
                "Sarah Alice Gaggl",
                "Markus Hecher",
                "Dominik Rusovac"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07233v1",
                "http://arxiv.org/pdf/2311.07233v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07231v1",
            "title": "Error Analysis of Option Pricing via Deep PDE Solvers: Empirical Study",
            "updated": "2023-11-13T10:52:44Z",
            "published": "2023-11-13T10:52:44Z",
            "summary": "Option pricing, a fundamental problem in finance, often requires solving\nnon-linear partial differential equations (PDEs). When dealing with multi-asset\noptions, such as rainbow options, these PDEs become high-dimensional, leading\nto challenges posed by the curse of dimensionality. While deep learning-based\nPDE solvers have recently emerged as scalable solutions to this\nhigh-dimensional problem, their empirical and quantitative accuracy remains not\nwell-understood, hindering their real-world applicability. In this study, we\naimed to offer actionable insights into the utility of Deep PDE solvers for\npractical option pricing implementation. Through comparative experiments, we\nassessed the empirical performance of these solvers in high-dimensional\ncontexts. Our investigation identified three primary sources of errors in Deep\nPDE solvers: (i) errors inherent in the specifications of the target option and\nunderlying assets, (ii) errors originating from the asset model simulation\nmethods, and (iii) errors stemming from the neural network training. Through\nablation studies, we evaluated the individual impact of each error source. Our\nresults indicate that the Deep BSDE method (DBSDE) is superior in performance\nand exhibits robustness against variations in option specifications. In\ncontrast, some other methods are overly sensitive to option specifications,\nsuch as time to expiration. We also find that the performance of these methods\nimproves inversely proportional to the square root of batch size and the number\nof time steps. This observation can aid in estimating computational resources\nfor achieving desired accuracies with Deep PDE solvers.",
            "author": [
                "Rawin Assabumrungrat",
                "Kentaro Minami",
                "Masanori Hirano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07231v1",
                "http://arxiv.org/pdf/2311.07231v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07230v1",
            "title": "How are Prompts Different in Terms of Sensitivity?",
            "updated": "2023-11-13T10:52:01Z",
            "published": "2023-11-13T10:52:01Z",
            "summary": "In-context learning (ICL) has become one of the most popular learning\nparadigms. While there is a growing body of literature focusing on prompt\nengineering, there is a lack of systematic analysis comparing the effects of\nprompts across different models and tasks. To address this gap, we present a\ncomprehensive prompt analysis based on the sensitivity of a function. Our\nanalysis reveals that sensitivity is an unsupervised proxy for model\nperformance, as it exhibits a strong negative correlation with accuracy. We use\ngradient-based saliency scores to empirically demonstrate how different prompts\naffect the relevance of input tokens to the output, resulting in different\nlevels of sensitivity. Furthermore, we introduce sensitivity-aware decoding\nwhich incorporates sensitivity estimation as a penalty term in the standard\ngreedy decoding. We show that this approach is particularly helpful when\ninformation in the input is scarce. Our work provides a fresh perspective on\nthe analysis of prompts, and contributes to a better understanding of the\nmechanism of ICL.",
            "author": [
                "Sheng Lu",
                "Hendrik Schuff",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07230v1",
                "http://arxiv.org/pdf/2311.07230v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07227v1",
            "title": "CARTOS: A Charging-Aware Real-Time Operating System for Intermittent\n  Batteryless Devices",
            "updated": "2023-11-13T10:48:36Z",
            "published": "2023-11-13T10:48:36Z",
            "summary": "This paper presents CARTOS, a charging-aware real-time operating system\ndesigned to enhance the functionality of intermittently-powered batteryless\ndevices (IPDs) for various Internet of Things (IoT) applications. While IPDs\noffer significant advantages such as extended lifespan and operability in\nextreme environments, they pose unique challenges, including the need to ensure\nforward progress of program execution amidst variable energy availability and\nmaintaining reliable real-time time behavior during power disruptions. To\naddress these challenges, CARTOS introduces a mixed-preemption scheduling model\nthat classifies tasks into computational and peripheral tasks, and ensures\ntheir efficient and timely execution by adopting just-in-time checkpointing for\ndivisible computation tasks and uninterrupted execution for indivisible\nperipheral tasks. CARTOS also supports processing chains of tasks with\nprecedence constraints and adapts its scheduling in response to environmental\nchanges to offer continuous execution under diverse conditions. CARTOS is\nimplemented with new APIs and components added to FreeRTOS but is designed for\nportability to other embedded RTOSs. Through real hardware experiments and\nsimulations, CARTOS exhibits superior performance over state-of-the-art\nmethods, demonstrating that it can serve as a practical platform for developing\nresilient, real-time sensing applications on IPDs.",
            "author": [
                "Mohsen Karimi",
                "Yidi Wang",
                "Youngbin Kim",
                "Yoojin Lim",
                "Hyoseung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07227v1",
                "http://arxiv.org/pdf/2311.07227v1"
            ],
            "primary_category": "cs.OS",
            "category": [
                "cs.OS",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07225v1",
            "title": "Modelling turbulence in axisymmetric wakes: an application to wind\n  turbine wakes",
            "updated": "2023-11-13T10:44:51Z",
            "published": "2023-11-13T10:44:51Z",
            "summary": "A novel fast-running model is developed to predict the three-dimensional (3D)\ndistribution of turbulent kinetic energy (TKE) in axisymmetric wake flows. This\nis achieved by mathematically solving the partial differential equation of the\nTKE transport using the Green's function method. The developed solution reduces\nto a double integral that can be computed numerically for a wake prescribed by\nany arbitrary velocity profile. It is shown that the solution can be further\nsimplified to a single integral for wakes with Gaussian-like velocity-deficit\nprofiles. Model results are compared and validated against detailed 3D laser\nDoppler anemometry data measured within the wake flow of a model wind turbine\nin a laboratory environment. This shows a remarkably good agreement in both the\nmagnitude and shape of the radial TKE profiles at the turbine hub height. The\nwind-tunnel data also provide insights into the evolution of important\nturbulent flow quantities such as turbulent viscosity, mixing length, and the\nTKE dissipation rate within a wind turbine wake.",
            "author": [
                "Majid Bastankhah",
                "Peter Hydon",
                "Jenna K. Zunder",
                "Charles Deebank",
                "Marco Placidi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07225v1",
                "http://arxiv.org/pdf/2311.07225v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07222v2",
            "title": "Neural General Circulation Models",
            "updated": "2023-11-28T05:29:19Z",
            "published": "2023-11-13T10:40:17Z",
            "summary": "General circulation models (GCMs) are the foundation of weather and climate\nprediction. GCMs are physics-based simulators which combine a numerical solver\nfor large-scale dynamics with tuned representations for small-scale processes\nsuch as cloud formation. Recently, machine learning (ML) models trained on\nreanalysis data achieved comparable or better skill than GCMs for deterministic\nweather forecasting. However, these models have not demonstrated improved\nensemble forecasts, or shown sufficient stability for long-term weather and\nclimate simulations. Here we present the first GCM that combines a\ndifferentiable solver for atmospheric dynamics with ML components, and show\nthat it can generate forecasts of deterministic weather, ensemble weather and\nclimate on par with the best ML and physics-based methods. NeuralGCM is\ncompetitive with ML models for 1-10 day forecasts, and with the European Centre\nfor Medium-Range Weather Forecasts ensemble prediction for 1-15 day forecasts.\nWith prescribed sea surface temperature, NeuralGCM can accurately track climate\nmetrics such as global mean temperature for multiple decades, and climate\nforecasts with 140 km resolution exhibit emergent phenomena such as realistic\nfrequency and trajectories of tropical cyclones. For both weather and climate,\nour approach offers orders of magnitude computational savings over conventional\nGCMs. Our results show that end-to-end deep learning is compatible with tasks\nperformed by conventional GCMs, and can enhance the large-scale physical\nsimulations that are essential for understanding and predicting the Earth\nsystem.",
            "author": [
                "Dmitrii Kochkov",
                "Janni Yuval",
                "Ian Langmore",
                "Peter Norgaard",
                "Jamie Smith",
                "Griffin Mooers",
                "James Lottes",
                "Stephan Rasp",
                "Peter D\u00fcben",
                "Milan Kl\u00f6wer",
                "Sam Hatfield",
                "Peter Battaglia",
                "Alvaro Sanchez-Gonzalez",
                "Matthew Willson",
                "Michael P. Brenner",
                "Stephan Hoyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07222v2",
                "http://arxiv.org/pdf/2311.07222v2"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07219v1",
            "title": "On Blockers and Transversals of Maximum Independent Sets in\n  Co-Comparability Graphs",
            "updated": "2023-11-13T10:29:22Z",
            "published": "2023-11-13T10:29:22Z",
            "summary": "In this paper, we consider the following two problems: (i) Deletion\nBlocker($\\alpha$) where we are given an undirected graph $G=(V,E)$ and two\nintegers $k,d\\geq 1$ and ask whether there exists a subset of vertices\n$S\\subseteq V$ with $|S|\\leq k$ such that $\\alpha(G-S) \\leq \\alpha(G)-d$, that\nis the independence number of $G$ decreases by at least $d$ after having\nremoved the vertices from $S$; (ii) Transversal($\\alpha$) where we are given an\nundirected graph $G=(V,E)$ and two integers $k,d\\geq 1$ and ask whether there\nexists a subset of vertices $S\\subseteq V$ with $|S|\\leq k$ such that for every\nmaximum independent set $I$ we have $|I\\cap S| \\geq d$. We show that both\nproblems are polynomial-time solvable in the class of co-comparability graphs\nby reducing them to the well-known Vertex Cut problem. Our results generalize a\nresult of [Chang et al., Maximum clique transversals, Lecture Notes in Computer\nScience 2204, pp. 32-43, WG 2001] and a recent result of [Hoang et al.,\nAssistance and interdiction problems on interval graphs, Discrete Applied\nMathematics 340, pp. 153-170, 2023].",
            "author": [
                "Felicia Lucke",
                "Bernard Ries"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07219v1",
                "http://arxiv.org/pdf/2311.07219v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08426v1",
            "title": "Non-Contact Breathing Rate Detection Using Optical Flow",
            "updated": "2023-11-13T10:26:18Z",
            "published": "2023-11-13T10:26:18Z",
            "summary": "Breathing rate is a vital health metric that is an invaluable indicator of\nthe overall health of a person. In recent years, the non-contact measurement of\nhealth signals such as breathing rate has been a huge area of development, with\na wide range of applications from telemedicine to driver monitoring systems.\nThis paper presents an investigation into a method of non-contact breathing\nrate detection using a motion detection algorithm, optical flow. Optical flow\nis used to successfully measure breathing rate by tracking the motion of\nspecific points on the body. In this study, the success of optical flow when\nusing different sets of points is evaluated. Testing shows that both chest and\nfacial movement can be used to determine breathing rate but to different\ndegrees of success. The chest generates very accurate signals, with an RMSE of\n0.63 on the tested videos. Facial points can also generate reliable signals\nwhen there is minimal head movement but are much more vulnerable to noise\ncaused by head/body movements. These findings highlight the potential of\noptical flow as a non-invasive method for breathing rate detection and\nemphasize the importance of selecting appropriate points to optimize accuracy.",
            "author": [
                "Robyn Maxwell",
                "Timothy Hanley",
                "Dara Golden",
                "Adara Andonie",
                "Joseph Lemley",
                "Ashkan Parsi"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.8238518",
                "http://arxiv.org/abs/2311.08426v1",
                "http://arxiv.org/pdf/2311.08426v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07217v1",
            "title": "Troubles and Failures in Interactional Language. Towards a\n  Linguistically Informed Taxonomy",
            "updated": "2023-11-13T10:24:51Z",
            "published": "2023-11-13T10:24:51Z",
            "summary": "The goal of this talk is to introduce a systematic research agenda which aims\nto understand the nature of interaction between humans and artificial\nconversational agents (CA) (henceforth humanmachine interaction, HMI).\nSpecifically, we shall take an explicit linguistic perspective focusing on\nlinguistically defined variables that are known to influence the flow of\nconversations among humans (henceforth human-human interaction, HHI).",
            "author": [
                "Martina Wiltschko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07217v1",
                "http://arxiv.org/pdf/2311.07217v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07216v1",
            "title": "Few Shot Learning for the Classification of Confocal Laser\n  Endomicroscopy Images of Head and Neck Tumors",
            "updated": "2023-11-13T10:17:00Z",
            "published": "2023-11-13T10:17:00Z",
            "summary": "The surgical removal of head and neck tumors requires safe margins, which are\nusually confirmed intraoperatively by means of frozen sections. This method is,\nin itself, an oversampling procedure, which has a relatively low sensitivity\ncompared to the definitive tissue analysis on paraffin-embedded sections.\nConfocal laser endomicroscopy (CLE) is an in-vivo imaging technique that has\nshown its potential in the live optical biopsy of tissue. An automated analysis\nof this notoriously difficult to interpret modality would help surgeons.\nHowever, the images of CLE show a wide variability of patterns, caused both by\nindividual factors but also, and most strongly, by the anatomical structures of\nthe imaged tissue, making it a challenging pattern recognition task. In this\nwork, we evaluate four popular few shot learning (FSL) methods towards their\ncapability of generalizing to unseen anatomical domains in CLE images. We\nevaluate this on images of sinunasal tumors (SNT) from five patients and on\nimages of the vocal folds (VF) from 11 patients using a cross-validation\nscheme. The best respective approach reached a median accuracy of 79.6% on the\nrather homogeneous VF dataset, but only of 61.6% for the highly diverse SNT\ndataset. Our results indicate that FSL on CLE images is viable, but strongly\naffected by the number of patients, as well as the diversity of anatomical\npatterns.",
            "author": [
                "Marc Aubreville",
                "Zhaoya Pan",
                "Matti Sievert",
                "Jonas Ammeling",
                "Jonathan Ganz",
                "Nicolai Oetter",
                "Florian Stelzle",
                "Ann-Kathrin Frenken",
                "Katharina Breininger",
                "Miguel Goncalves"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07216v1",
                "http://arxiv.org/pdf/2311.07216v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07215v1",
            "title": "Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback",
            "updated": "2023-11-13T10:15:19Z",
            "published": "2023-11-13T10:15:19Z",
            "summary": "Code editing is an essential step towards reliable program synthesis to\nautomatically correct critical errors generated from code LLMs. Recent studies\nhave demonstrated that closed-source LLMs (i.e., ChatGPT and GPT-4) are capable\nof generating corrective feedback to edit erroneous inputs. However, it remains\nchallenging for open-source code LLMs to generate feedback for code editing,\nsince these models tend to adhere to the superficial formats of feedback and\nprovide feedback with misleading information. Hence, the focus of our work is\nto leverage open-source code LLMs to generate helpful feedback with correct\nguidance for code editing. To this end, we present Coffee, a collected dataset\nspecifically designed for code fixing with feedback. Using this dataset, we\nconstruct CoffeePots, a framework for COde Fixing with FEEdback via\nPreference-Optimized Tuning and Selection. The proposed framework aims to\nautomatically generate helpful feedback for code editing while minimizing the\npotential risk of superficial feedback. The combination of Coffee and\nCoffeePots marks a significant advancement, achieving state-of-the-art\nperformance on HumanEvalFix benchmark. Codes and model checkpoints are publicly\navailable at https://github.com/Lune-Blue/COFFEE.",
            "author": [
                "Seungjun Moon",
                "Yongho Song",
                "Hyungjoo Chae",
                "Dongjin Kang",
                "Taeyoon Kwon",
                "Kai Tzu-iunn Ong",
                "Seung-won Hwang",
                "Jinyoung Yeo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07215v1",
                "http://arxiv.org/pdf/2311.07215v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07213v1",
            "title": "A method for quantifying sectoral optic disc pallor in fundus\n  photographs and its association with peripapillary RNFL thickness",
            "updated": "2023-11-13T10:13:59Z",
            "published": "2023-11-13T10:13:59Z",
            "summary": "Purpose: To develop an automatic method of quantifying optic disc pallor in\nfundus photographs and determine associations with peripapillary retinal nerve\nfibre layer (pRNFL) thickness.\n  Methods: We used deep learning to segment the optic disc, fovea, and vessels\nin fundus photographs, and measured pallor. We assessed the relationship\nbetween pallor and pRNFL thickness derived from optical coherence tomography\nscans in 118 participants. Separately, we used images diagnosed by clinical\ninspection as pale (N=45) and assessed how measurements compared to healthy\ncontrols (N=46). We also developed automatic rejection thresholds, and tested\nthe software for robustness to camera type, image format, and resolution.\n  Results: We developed software that automatically quantified disc pallor\nacross several zones in fundus photographs. Pallor was associated with pRNFL\nthickness globally (\\b{eta} = -9.81 (SE = 3.16), p < 0.05), in the temporal\ninferior zone (\\b{eta} = -29.78 (SE = 8.32), p < 0.01), with the nasal/temporal\nratio (\\b{eta} = 0.88 (SE = 0.34), p < 0.05), and in the whole disc (\\b{eta} =\n-8.22 (SE = 2.92), p < 0.05). Furthermore, pallor was significantly higher in\nthe patient group. Lastly, we demonstrate the analysis to be robust to camera\ntype, image format, and resolution.\n  Conclusions: We developed software that automatically locates and quantifies\ndisc pallor in fundus photographs and found associations between pallor\nmeasurements and pRNFL thickness.\n  Translational relevance: We think our method will be useful for the\nidentification, monitoring and progression of diseases characterized by disc\npallor/optic atrophy, including glaucoma, compression, and potentially in\nneurodegenerative disorders.",
            "author": [
                "Samuel Gibbon",
                "Graciela Muniz-Terrera",
                "Fabian SL Yii",
                "Charlene Hamid",
                "Simon Cox",
                "Ian JC Maccormick",
                "Andrew J Tatham",
                "Craig Ritchie",
                "Emanuele Trucco",
                "Baljean Dhillon",
                "Thomas J MacGillivray"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07213v1",
                "http://arxiv.org/pdf/2311.07213v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07211v2",
            "title": "A Gaussian Process Based Method with Deep Kernel Learning for Pricing\n  High-dimensional American Options",
            "updated": "2023-11-22T05:48:06Z",
            "published": "2023-11-13T10:13:50Z",
            "summary": "Machine learning methods, such as Gaussian process regression (GPR), have\nbeen widely used in recent years for pricing American options. GPR is\nconsidered as a potential method for estimating the continuation value of an\noption in the regression-based Monte Carlo method. However, it has some\ndrawbacks, such as the unreliability in high-dimensional cases and the high\ncomputational cost when the number of simulated paths is large. In this paper,\nwe apply the deep kernel learning and variational inference to GPR in order to\novercome these drawbacks, and test its performance under geometric Brownian\nmotion and Merton's jump diffusion models. The experiments show that the\nproposed method outperforms the Least Square Monte Carlo method in\nhigh-dimensional cases, especially with jump diffusion models.",
            "author": [
                "Jirong Zhuang",
                "Deng Ding",
                "Weiguo Lu",
                "Xuan Wu",
                "Gangnan Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07211v2",
                "http://arxiv.org/pdf/2311.07211v2"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07206v1",
            "title": "Efficient adaptivity for simulating cardiac electrophysiology with\n  spectral deferred correction methods",
            "updated": "2023-11-13T10:03:16Z",
            "published": "2023-11-13T10:03:16Z",
            "summary": "The locality of solution features in cardiac electrophysiology simulations\ncalls for adaptive methods. Due to the overhead incurred by established mesh\nrefinement and coarsening, however, such approaches failed in accelerating the\ncomputations. Here we investigate a different route to spatial adaptivity that\nis based on nested subset selection for algebraic degrees of freedom in\nspectral deferred correction methods. This combination of algebraic adaptivity\nand iterative solvers for higher order collocation time stepping realizes a\nmultirate integration with minimal overhead. This leads to moderate but\nsignificant speedups in both monodomain and cell-by-cell models of cardiac\nexcitation, as demonstrated at four numerical examples.",
            "author": [
                "Fatemeh Chegini",
                "Thomas Steinke",
                "Martin Weiser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07206v1",
                "http://arxiv.org/pdf/2311.07206v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65M60, 65M70, 65M50, 92C30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07204v1",
            "title": "On Elastic Language Models",
            "updated": "2023-11-13T09:55:52Z",
            "published": "2023-11-13T09:55:52Z",
            "summary": "Large-scale pretrained language models have achieved compelling performance\nin a wide range of language understanding and information retrieval tasks.\nKnowledge distillation offers an opportunity to compress a large language model\nto a small one, in order to reach a reasonable latency-performance tradeoff.\nHowever, for scenarios where the number of requests (e.g., queries submitted to\na search engine) is highly variant, the static tradeoff attained by the\ncompressed language model might not always fit. Once a model is assigned with a\nstatic tradeoff, it could be inadequate in that the latency is too high when\nthe number of requests is large or the performance is too low when the number\nof requests is small. To this end, we propose an elastic language model\n(ElasticLM) that elastically adjusts the tradeoff according to the request\nstream. The basic idea is to introduce a compute elasticity to the compressed\nlanguage model, so that the tradeoff could vary on-the-fly along scalable and\ncontrollable compute. Specifically, we impose an elastic structure to enable\nElasticLM with compute elasticity and design an elastic optimization to learn\nElasticLM under compute elasticity. To serve ElasticLM, we apply an elastic\nschedule. Considering the specificity of information retrieval, we adapt\nElasticLM to dense retrieval and reranking and present ElasticDenser and\nElasticRanker respectively. Offline evaluation is conducted on a language\nunderstanding benchmark GLUE; and several information retrieval tasks including\nNatural Question, Trivia QA, and MS MARCO. The results show that ElasticLM\nalong with ElasticDenser and ElasticRanker can perform correctly and\ncompetitively compared with an array of static baselines. Furthermore, online\nsimulation with concurrency is also carried out. The results demonstrate that\nElasticLM can provide elastic tradeoffs with respect to varying request stream.",
            "author": [
                "Chen Zhang",
                "Benyou Wang",
                "Dawei Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07204v1",
                "http://arxiv.org/pdf/2311.07204v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07630v1",
            "title": "Cross-modal Generative Model for Visual-Guided Binaural Stereo\n  Generation",
            "updated": "2023-11-13T09:53:14Z",
            "published": "2023-11-13T09:53:14Z",
            "summary": "Binaural stereo audio is recorded by imitating the way the human ear receives\nsound, which provides people with an immersive listening experience. Existing\napproaches leverage autoencoders and directly exploit visual spatial\ninformation to synthesize binaural stereo, resulting in a limited\nrepresentation of visual guidance. For the first time, we propose a visually\nguided generative adversarial approach for generating binaural stereo audio\nfrom mono audio. Specifically, we develop a Stereo Audio Generation Model\n(SAGM), which utilizes shared spatio-temporal visual information to guide the\ngenerator and the discriminator to work separately. The shared visual\ninformation is updated alternately in the generative adversarial stage,\nallowing the generator and discriminator to deliver their respective guided\nknowledge while visually sharing. The proposed method learns bidirectional\ncomplementary visual information, which facilitates the expression of visual\nguidance in generation. In addition, spatial perception is a crucial attribute\nof binaural stereo audio, and thus the evaluation of stereo spatial perception\nis essential. However, previous metrics failed to measure the spatial\nperception of audio. To this end, a metric to measure the spatial perception of\naudio is proposed for the first time. The proposed metric is capable of\nmeasuring the magnitude and direction of spatial perception in the temporal\ndimension. Further, considering its function, it is feasible to utilize it\ninstead of demanding user studies to some extent. The proposed method achieves\nstate-of-the-art performance on 2 datasets and 5 evaluation metrics.\nQualitative experiments and user studies demonstrate that the method generates\nspace-realistic stereo audio.",
            "author": [
                "Zhaojian Li",
                "Bin Zhao",
                "Yuan Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07630v1",
                "http://arxiv.org/pdf/2311.07630v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07202v1",
            "title": "Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model\n  Predictive Control",
            "updated": "2023-11-13T09:41:32Z",
            "published": "2023-11-13T09:41:32Z",
            "summary": "Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive\nControl (MPC) successfully attains globally optimal solutions by upholding\nconvexity within the MPC framework. However, current ICNN architectures\nencounter the issue of vanishing gradients, which limits their ability to serve\nas deep neural networks for complex tasks. Additionally, the current neural\nnetwork-based MPC, including conventional neural network-based MPC and\nICNN-based MPC, faces slower convergence speed when compared to MPC based on\nfirst-principles models. In this study, we leverage the principles of ICNNs to\npropose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific\ngoal of reducing convergence time and mitigating the vanishing gradient problem\nwhile ensuring closed-loop stability. From a simulation study of a nonlinear\nchemical reactor, we observed a mitigation of vanishing gradient problem and a\nreduction in convergence time, with a percentage decrease of 46.7%, 31.3%, and\n20.2% compared to baseline plain RNN, plain LSTM, and Input Convex Recurrent\nNeural Network, respectively.",
            "author": [
                "Zihao Wang",
                "Zhe Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07202v1",
                "http://arxiv.org/pdf/2311.07202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07201v1",
            "title": "Multiple topological phase transitions in magnetic systems: role of\n  anisotropic Dzyaloshinskii-Moriya interaction",
            "updated": "2023-11-13T09:40:54Z",
            "published": "2023-11-13T09:40:54Z",
            "summary": "In this work we study the topological properties of magnons in both\nferromagnetically and antiferromagnetically ordered systems on a\ntwo-dimensional square lattice. While topological features emerge owing to the\nviolation of time reversal symmetry induced by the Dzyaloshinskii-Moriya\ninteraction (DMI), here we consider an anisotropic DMI and ascertain the role\nof the anisotropy parameter on the topological phase transitions. In\nparticular, our phase plot for the ferromagnetic case demonstrates multiple\ntopological phase transitions, that is, from a topological phase to another\ntopological phase, and as well, from a topological phase to a trivial phase. In\nthe former, the topological invariant, namely the Chern number, discontinuously\nchanges from one finite value to another ($-1 \\rightarrow +1$), while it\nvanishes ($1 \\rightarrow 0$) in the latter. Further, an extended trivial region\nis observed where the DMI is non-zero, which is surprising since DMI is the\norigin of the topological gap. The nature of the phases and the phase\ntransitions, therein are characterized by their band structure, presence (or\nabsence) of the chiral edge modes, computation of the topological Hall effect,\netc. In contrast, the antiferromagnetic case presents a more predictable\nscenario, in the sense, it behaves as a trivial insulator in the absence of\nDMI, although demonstrate a topological to trivial phase transition.",
            "author": [
                "Shreya Debnath",
                "Saurabh Basu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07201v1",
                "http://arxiv.org/pdf/2311.07201v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07200v2",
            "title": "Normalising Flows for Bayesian Gravity Inversion",
            "updated": "2023-11-28T12:07:09Z",
            "published": "2023-11-13T09:40:53Z",
            "summary": "Gravity inversion is a commonly applied data analysis technique in the field\nof geophysics. While machine learning methods have previously been explored for\nthe problem of gravity inversion, these are deterministic approaches returning\na single solution deemed most appropriate by the algorithm. The method\npresented here takes a different approach, where gravity inversion is\nreformulated as a Bayesian parameter inference problem. Samples from the\nposterior probability distribution of source model parameters are obtained via\nthe implementation of a generative neural network architecture known as\nNormalising Flows. Due to its probabilistic nature, this framework provides the\nuser with a range of source parameters and uncertainties instead of a single\nsolution, and is inherently robust against instrumental noise. The performance\nof the Normalising Flow is compared to that of an established Bayesian method\ncalled Nested Sampling. It is shown that the new method returns results with\ncomparable accuracy 200 times faster than standard sampling methods, which\nmakes Normalising Flows a suitable method for real-time inversion in the field.\nWhen applied to data sets with high dimensionality, standard sampling methods\ncan become impractical due to long computation times. It is shown that\ninversion using Normalising Flows remains tractable even at 512 dimensions and\nonce the network is trained, the results can be obtained in $O(10)$ seconds.",
            "author": [
                "Henrietta Rakoczi",
                "Abhinav Prasad",
                "Karl Toland",
                "Christopher Messenger",
                "Giles Hammond"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07200v2",
                "http://arxiv.org/pdf/2311.07200v2"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07199v1",
            "title": "Joint Computation and Communication Resource Optimization for Beyond\n  Diagonal UAV-IRS Empowered MEC Networks",
            "updated": "2023-11-13T09:39:53Z",
            "published": "2023-11-13T09:39:53Z",
            "summary": "Intelligent Reconfigurable Surfaces (IRS) are crucial for overcoming\nchallenges in coverage, capacity, and energy efficiency beyond 5G (B5G). The\nclassical IRS architecture, employing a diagonal phase shift matrix, hampers\neffective passive beamforming manipulation. To unlock its full potential,\nBeyond Diagonal IRS (BD-IRS or IRS 2.0) emerges as a revolutionary member,\ntranscending limitations of the diagonal IRS. This paper introduces BD-IRS\ndeployed on unmanned aerial vehicles (BD-IRS-UAV) in Mobile Edge Computing\n(MEC) networks. Here, users offload tasks to the MEC server due to limited\nresources and finite battery life. The objective is to minimize worst-case\nsystem latency by optimizing BD-IRS-UAV deployment, local and edge\ncomputational resource allocation, task segmentation, power allocation, and\nreceived beamforming vector. The resulting non-convex/non-linear NP-hard\noptimization problem is intricate, prompting division into two subproblems: 1)\nBD-IRS-UAV deployment, local and edge computational resources, and task\nsegmentation, and 2) power allocation, received beamforming, and phase shift\ndesign. Standard optimization methods efficiently solve each subproblem. Monte\nCarlo simulations provide numerical results, comparing the proposed\nBD-IRS-UAV-enabled MEC optimization framework with various benchmarks.\nPerformance evaluations include comparisons with fully-connected and\ngroup-connected architectures, single-connected diagonal IRS, and binary\noffloading, edge computation, fixed computation, and local computation\nframeworks. Results show a 7.25% lower latency and a 17.77% improvement in data\nrate with BD-IRS compared to conventional diagonal IRS systems, demonstrating\nthe effectiveness of the proposed optimization framework.",
            "author": [
                "Asad Mahmood",
                "Thang X. Vu",
                "Wali Ullah Khan",
                "Symeon Chatzinotas",
                "Bj\u00f6rn Ottersten"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07199v1",
                "http://arxiv.org/pdf/2311.07199v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07198v1",
            "title": "MonoDiffusion: Self-Supervised Monocular Depth Estimation Using\n  Diffusion Model",
            "updated": "2023-11-13T09:38:30Z",
            "published": "2023-11-13T09:38:30Z",
            "summary": "Over the past few years, self-supervised monocular depth estimation that does\nnot depend on ground-truth during the training phase has received widespread\nattention. Most efforts focus on designing different types of network\narchitectures and loss functions or handling edge cases, e.g., occlusion and\ndynamic objects. In this work, we introduce a novel self-supervised depth\nestimation framework, dubbed MonoDiffusion, by formulating it as an iterative\ndenoising process. Because the depth ground-truth is unavailable in the\ntraining phase, we develop a pseudo ground-truth diffusion process to assist\nthe diffusion in MonoDiffusion. The pseudo ground-truth diffusion gradually\nadds noise to the depth map generated by a pre-trained teacher model.\nMoreover,the teacher model allows applying a distillation loss to guide the\ndenoised depth. Further, we develop a masked visual condition mechanism to\nenhance the denoising ability of model. Extensive experiments are conducted on\nthe KITTI and Make3D datasets and the proposed MonoDiffusion outperforms prior\nstate-of-the-art competitors. The source code will be available at\nhttps://github.com/ShuweiShao/MonoDiffusion.",
            "author": [
                "Shuwei Shao",
                "Zhongcai Pei",
                "Weihai Chen",
                "Dingchi Sun",
                "Peter C. Y. Chen",
                "Zhengguo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07198v1",
                "http://arxiv.org/pdf/2311.07198v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07194v2",
            "title": "Exploring the Dialogue Comprehension Ability of Large Language Models",
            "updated": "2023-11-16T11:56:12Z",
            "published": "2023-11-13T09:32:12Z",
            "summary": "LLMs may interact with users in the form of dialogue and generate responses\nfollowing their instructions, which naturally require dialogue comprehension\nabilities. However, dialogue comprehension is a general language ability which\nis hard to be evaluated directly. In this work, we propose to perform the\nevaluation with the help of the dialogue summarization task. Beside evaluating\nand analyzing the dialogue summarization performance (DIAC-Sum) of different\nLLMs, we also derive factual questions from the generated summaries and use\nthem as a more flexible measurement of dialogue comprehension (DIAC-FactQA).\nOur evaluation shows that, on average, 27% of the summaries generated by LLMs\ncontain factual inconsistency. Even ChatGPT, the strongest model evaluated, has\nsuch errors in 16% of its summaries. For answering the factual questions, which\nis more challenging, the average error rate of all evaluated LLMs is 37.2%.\nBoth results indicate serious deficiencies. Detailed analysis shows that the\nunderstanding of subject/object of the conversation is still the most\nchallenging problem for LLMs. Furthermore, to stimulate and enhance the\ndialogue comprehension ability of LLMs, we propose a fine-tuning paradigm with\nauto-constructed multi-task data. The experimental results demonstrate that our\nmethod achieved an error rate improvement of 10.9% on DIAC-FactQA.",
            "author": [
                "Shuaijie She",
                "Shujian Huang",
                "Xingyun Wang",
                "Yanke Zhou",
                "Jiajun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07194v2",
                "http://arxiv.org/pdf/2311.07194v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07189v1",
            "title": "$\u03a0_{2}$-Rule Systems and Inductive Classes of G\u00f6del Algebras",
            "updated": "2023-11-13T09:29:00Z",
            "published": "2023-11-13T09:29:00Z",
            "summary": "In this paper we present a general theory of $\\Pi_{2}$-rules for systems of\nintuitionistic and modal logic. We introduce the notions of $\\Pi_{2}$-rule\nsystem and of an Inductive Class, and provide model-theoretic and algebraic\ncompleteness theorems, which serve as our basic tools. As an illustration of\nthe general theory, we analyse the structure of inductive classes of G\\\"{o}del\nalgebras, from a structure theoretic and logical point of view. We show that\nunlike other well-studied settings (such as logics, or single-conclusion rule\nsystems), there are continuum many $\\Pi_{2}$-rule systems extending\n$\\mathsf{LC}=\\mathsf{IPC}+(p\\rightarrow q)\\vee (q\\rightarrow p)$, and show how\nour methods allow easy proofs of the admissibility of the well-known\nTakeuti-Titani rule. Our final results concern general questions admissibility\nin $\\mathsf{LC}$: (1) we present a full classification of those inductive\nclasses which are inductively complete, i.e., where all $\\Pi_{2}$-rules which\nare admissible are derivable, and (2) show that the problem of admissibility of\n$\\Pi_{2}$-rules over $\\mathsf{LC}$ is decidable.",
            "author": [
                "Rodrigo Nicolau Almeida"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07189v1",
                "http://arxiv.org/pdf/2311.07189v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07188v1",
            "title": "Fitting tree model with CNN and geodesics to track vesselsand\n  application to Ultrasound Localization Microscopy data",
            "updated": "2023-11-13T09:25:03Z",
            "published": "2023-11-13T09:25:03Z",
            "summary": "Segmentation of tubular structures in vascular imaging is a well studied\ntask, although it is rare that we try to infuse knowledge of the tree-like\nstructure of the regions to be detected. Our work focuses on detecting the\nimportant landmarks in the vascular network (via CNN performing both\nlocalization and classification of the points of interest) and representing\nvessels as the edges in some minimal distance tree graph. We leverage geodesic\nmethods relevant to the detection of vessels and their geometry, making use of\nthe space of positions and orientations so that 2D vessels can be accurately\nrepresented as trees. We build our model to carry tracking on Ultrasound\nLocalization Microscopy (ULM) data, proposing to build a good cost function for\ntracking on this type of data. We also test our framework on synthetic and eye\nfundus data. Results show that scarcity of well annotated ULM data is an\nobstacle to localization of vascular landmarks but the Orientation Score built\nfrom ULM data yields good geodesics for tracking blood vessels.",
            "author": [
                "Th\u00e9o Bertrand",
                "Laurent D. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07188v1",
                "http://arxiv.org/pdf/2311.07188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07187v1",
            "title": "Solving Inverse Obstacle Scattering Problem with Latent Surface\n  Representations",
            "updated": "2023-11-13T09:24:06Z",
            "published": "2023-11-13T09:24:06Z",
            "summary": "We propose a novel iterative numerical method to solve the three-dimensional\ninverse obstacle scattering problem of recovering the shape of the obstacle\nfrom far-field measurements. To address the inherent ill-posed nature of the\ninverse problem, we advocate the use of a trained latent representation of\nsurfaces as the generative prior. This prior enjoys excellent expressivity\nwithin the given class of shapes, and meanwhile, the latent dimensionality is\nlow, which greatly facilitates the computation. Thus, the admissible manifold\nof surfaces is realistic and the resulting optimization problem is less\nill-posed. We employ the shape derivative to evolve the latent surface\nrepresentation, by minimizing the loss, and we provide a local convergence\nanalysis of a gradient descent type algorithm to a stationary point of the\nloss. We present several numerical examples, including also backscattered and\nphaseless data, to showcase the effectiveness of the proposed algorithm.",
            "author": [
                "Junqing Chen",
                "Bangti Jin",
                "Haibo Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07187v1",
                "http://arxiv.org/pdf/2311.07187v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07185v1",
            "title": "Dedukti: a Logical Framework based on the $\u03bb$$\u03a0$-Calculus Modulo\n  Theory",
            "updated": "2023-11-13T09:22:36Z",
            "published": "2023-11-13T09:22:36Z",
            "summary": "Dedukti is a Logical Framework based on the $\\lambda$$\\Pi$-Calculus Modulo\nTheory. We show that many theories can be expressed in Dedukti: constructive\nand classical predicate logic, Simple type theory, programming languages, Pure\ntype systems, the Calculus of inductive constructions with universes, etc. and\nthat permits to used it to check large libraries of proofs developed in other\nproof systems: Zenon, iProver, FoCaLiZe, HOL Light, and Matita.",
            "author": [
                "Ali Assaf",
                "Guillaume Burel",
                "Rapha\u00ebl Cauderlier",
                "David Delahaye",
                "Gilles Dowek",
                "Catherine Dubois",
                "Fr\u00e9d\u00e9ric Gilbert",
                "Pierre Halmagrand",
                "Olivier Hermant",
                "Ronan Saillard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07185v1",
                "http://arxiv.org/pdf/2311.07185v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07184v2",
            "title": "Cross-Axis Transformer with 2D Rotary Embeddings",
            "updated": "2023-11-29T17:01:00Z",
            "published": "2023-11-13T09:19:14Z",
            "summary": "Despite lagging behind their modal cousins in many respects, Vision\nTransformers have provided an interesting opportunity to bridge the gap between\nsequence modeling and image modeling. Up until now however, vision transformers\nhave largely been held back, due to both computational inefficiency, and lack\nof proper handling of spatial dimensions. In this paper, we introduce the\nCross-Axis Transformer. CAT is a model inspired by both Axial Transformers, and\nMicrosoft's recent Retentive Network, that drastically reduces the required\nnumber of floating point operations required to process an image, while\nsimultaneously converging faster and more accurately than the Vision\nTransformers it replaces.",
            "author": [
                "Lily Erickson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07184v2",
                "http://arxiv.org/pdf/2311.07184v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07178v1",
            "title": "Game Solving with Online Fine-Tuning",
            "updated": "2023-11-13T09:09:52Z",
            "published": "2023-11-13T09:09:52Z",
            "summary": "Game solving is a similar, yet more difficult task than mastering a game.\nSolving a game typically means to find the game-theoretic value (outcome given\noptimal play), and optionally a full strategy to follow in order to achieve\nthat outcome. The AlphaZero algorithm has demonstrated super-human level play,\nand its powerful policy and value predictions have also served as heuristics in\ngame solving. However, to solve a game and obtain a full strategy, a winning\nresponse must be found for all possible moves by the losing player. This\nincludes very poor lines of play from the losing side, for which the AlphaZero\nself-play process will not encounter. AlphaZero-based heuristics can be highly\ninaccurate when evaluating these out-of-distribution positions, which occur\nthroughout the entire search. To address this issue, this paper investigates\napplying online fine-tuning while searching and proposes two methods to learn\ntailor-designed heuristics for game solving. Our experiments show that using\nonline fine-tuning can solve a series of challenging 7x7 Killall-Go problems,\nusing only 23.54% of computation time compared to the baseline without online\nfine-tuning. Results suggest that the savings scale with problem size. Our\nmethod can further be extended to any tree search algorithm for problem\nsolving. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver.",
            "author": [
                "Ti-Rong Wu",
                "Hung Guei",
                "Ting Han Wei",
                "Chung-Chin Shih",
                "Jui-Te Chin",
                "I-Chen Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07178v1",
                "http://arxiv.org/pdf/2311.07178v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07174v1",
            "title": "The High-dimensional Phase Diagram and the Large CALPHAD Model",
            "updated": "2023-11-13T09:07:17Z",
            "published": "2023-11-13T09:07:17Z",
            "summary": "When alloy systems comprise more than three elements, the visualization of\nthe entire phase space becomes not only daunting but is also accompanied by a\ndata surge. Addressing this complexity, we delve into the FeNiCrMn alloy system\nand introduce the Large CALPHAD Model (LCM). The LCM acts as a computational\nconduit, capturing the entire phase space. Subsequently, this enormous data is\nsystematically structured using a high-dimensional phase diagram, aided by hash\ntables and Depth-first Search (DFS), rendering it both digestible and\nprogrammatically accessible. Remarkably, the LCM boasts a 97% classification\naccuracy and a mean square error of 4.80*10-5 in phase volume prediction. Our\nmethodology successfully delineates 51 unique phase spaces in the FeNiCrMn\nsystem, exemplifying its efficacy with the design of all 439 eutectic alloys.\nThis pioneering methodology signifies a monumental shift in alloy design\ntechniques or even multi-variable problems.",
            "author": [
                "Zhengdi Liu",
                "Xulong An",
                "Wenwen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07174v1",
                "http://arxiv.org/pdf/2311.07174v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07172v1",
            "title": "VerityMath: Advancing Mathematical Reasoning by Self-Verification\n  Through Unit Consistency",
            "updated": "2023-11-13T09:06:58Z",
            "published": "2023-11-13T09:06:58Z",
            "summary": "Large Language Models (LLMs) combined with program-based solving techniques\nare increasingly demonstrating proficiency in mathematical reasoning. However,\nsuch progress is mostly demonstrated in closed-source models such as\nOpenAI-GPT4 and Claude. In this paper, we seek to study the performance of\nstrong open-source LLMs. Specifically, we analyze the outputs of Code Llama\n(7B) when applied to math word problems. We identify a category of problems\nthat pose a challenge for the model, particularly those involving quantities\nthat span multiple types or units. To address this issue, we propose a\nsystematic approach by defining units for each quantity and ensuring the\nconsistency of these units during mathematical operations. We developed Unit\nConsistency Programs (UCPs), an annotated dataset of math word problems, each\npaired with programs that contain unit specifications and unit verification\nroutines. Finally, we finetune the Code Llama (7B) model with UCPs to produce\nVerityMath and present our preliminary findings.",
            "author": [
                "Vernon Toh",
                "Ratish Puduppully",
                "Nancy F. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07172v1",
                "http://arxiv.org/pdf/2311.07172v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07171v1",
            "title": "calamanCy: A Tagalog Natural Language Processing Toolkit",
            "updated": "2023-11-13T09:06:43Z",
            "published": "2023-11-13T09:06:43Z",
            "summary": "We introduce calamanCy, an open-source toolkit for constructing natural\nlanguage processing (NLP) pipelines for Tagalog. It is built on top of spaCy,\nenabling easy experimentation and integration with other frameworks. calamanCy\naddresses the development gap by providing a consistent API for building NLP\napplications and offering general-purpose multitask models with out-of-the-box\nsupport for dependency parsing, parts-of-speech (POS) tagging, and named entity\nrecognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by\nconsolidating disjointed resources in a unified framework. The calamanCy\ntoolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.",
            "author": [
                "Lester James V. Miranda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07171v1",
                "http://arxiv.org/pdf/2311.07171v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07170v1",
            "title": "Regenerating Arbitrary Video Sequences with Distillation Path-Finding",
            "updated": "2023-11-13T09:05:30Z",
            "published": "2023-11-13T09:05:30Z",
            "summary": "If the video has long been mentioned as a widespread visualization form, the\nanimation sequence in the video is mentioned as storytelling for people.\nProducing an animation requires intensive human labor from skilled professional\nartists to obtain plausible animation in both content and motion direction,\nincredibly for animations with complex content, multiple moving objects, and\ndense movement. This paper presents an interactive framework to generate new\nsequences according to the users' preference on the starting frame. The\ncritical contrast of our approach versus prior work and existing commercial\napplications is that novel sequences with arbitrary starting frame are produced\nby our system with a consistent degree in both content and motion direction. To\nachieve this effectively, we first learn the feature correlation on the\nframeset of the given video through a proposed network called RSFNet. Then, we\ndevelop a novel path-finding algorithm, SDPF, which formulates the knowledge of\nmotion directions of the source video to estimate the smooth and plausible\nsequences. The extensive experiments show that our framework can produce new\nanimations on the cartoon and natural scenes and advance prior works and\ncommercial applications to enable users to obtain more predictable results.",
            "author": [
                "Thi-Ngoc-Hanh Le",
                "Sheng-Yi Yao",
                "Chun-Te Wu",
                "Tong-Yee Lee"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TVCG.2023.3237739",
                "http://arxiv.org/abs/2311.07170v1",
                "http://arxiv.org/pdf/2311.07170v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07169v1",
            "title": "CASTER: A Computer-Vision-Assisted Wireless Channel Simulator for\n  Gesture Recognition",
            "updated": "2023-11-13T09:04:37Z",
            "published": "2023-11-13T09:04:37Z",
            "summary": "In this paper, a computer-vision-assisted simulation method is proposed to\naddress the issue of training dataset acquisition for wireless hand gesture\nrecognition. In the existing literature, in order to classify gestures via the\nwireless channel estimation, massive training samples should be measured in a\nconsistent environment, consuming significant efforts. In the proposed CASTER\nsimulator, however, the training dataset can be simulated via existing videos.\nParticularly, a gesture is represented by a sequence of snapshots, and the\nchannel impulse response of each snapshot is calculated via tracing the rays\nscattered off a primitive-based hand model. Moreover, CASTER simulator relies\non the existing videos to extract the motion data of gestures. Thus, the\nmassive measurements of wireless channel can be eliminated. The experiments\ndemonstrate a 90.8% average classification accuracy of simulation-to-reality\ninference.",
            "author": [
                "Zhenyu Ren",
                "Guoliang Li",
                "Chenqing Ji",
                "Chao Yu",
                "Shuai Wang",
                "Rui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07169v1",
                "http://arxiv.org/pdf/2311.07169v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07167v1",
            "title": "STEER: Unified Style Transfer with Expert Reinforcement",
            "updated": "2023-11-13T09:02:30Z",
            "published": "2023-11-13T09:02:30Z",
            "summary": "While text style transfer has many applications across natural language\nprocessing, the core premise of transferring from a single source style is\nunrealistic in a real-world setting. In this work, we focus on arbitrary style\ntransfer: rewriting a text from an arbitrary, unknown style to a target style.\n  We propose STEER: Unified Style Transfer with Expert Reinforcement, a unified\nframe-work developed to overcome the challenge of limited parallel data for\nstyle transfer. STEER involves automatically generating a corpus of\nstyle-transfer pairs using a product of experts during decoding. The generated\noffline data is then used to pre-train an initial policy before switching to\nonline, off-policy reinforcement learning for further improvements via\nfine-grained reward signals. STEER is unified and can transfer to multiple\ntarget styles from an arbitrary, unknown source style, making it particularly\nflexible and efficient.\n  Experimental results on a challenging dataset with text from a diverse set of\nstyles demonstrate state-of-the-art results compared to competitive baselines.\nRemarkably, STEER outperforms the 175B parameter instruction-tuned GPT-3 on\noverall style transfer quality, despite being 226 times smaller in size. We\nalso show STEER is robust, maintaining its style transfer capabilities on\nout-of-domain data, and surpassing nearly all baselines across various styles.\nThe success of our method highlights the potential of RL algorithms when\naugmented with controllable decoding to overcome the challenge of limited data\nsupervision.",
            "author": [
                "Skyler Hallinan",
                "Faeze Brahman",
                "Ximing Lu",
                "Jaehun Jung",
                "Sean Welleck",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07167v1",
                "http://arxiv.org/pdf/2311.07167v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07166v1",
            "title": "NDDepth: Normal-Distance Assisted Monocular Depth Estimation and\n  Completion",
            "updated": "2023-11-13T09:01:50Z",
            "published": "2023-11-13T09:01:50Z",
            "summary": "Over the past few years, monocular depth estimation and completion have been\npaid more and more attention from the computer vision community because of\ntheir widespread applications. In this paper, we introduce novel physics\n(geometry)-driven deep learning frameworks for these two tasks by assuming that\n3D scenes are constituted with piece-wise planes. Instead of directly\nestimating the depth map or completing the sparse depth map, we propose to\nestimate the surface normal and plane-to-origin distance maps or complete the\nsparse surface normal and distance maps as intermediate outputs. To this end,\nwe develop a normal-distance head that outputs pixel-level surface normal and\ndistance. Meanwhile, the surface normal and distance maps are regularized by a\ndeveloped plane-aware consistency constraint, which are then transformed into\ndepth maps. Furthermore, we integrate an additional depth head to strengthen\nthe robustness of the proposed frameworks. Extensive experiments on the\nNYU-Depth-v2, KITTI and SUN RGB-D datasets demonstrate that our method exceeds\nin performance prior state-of-the-art monocular depth estimation and completion\ncompetitors. The source code will be available at\nhttps://github.com/ShuweiShao/NDDepth.",
            "author": [
                "Shuwei Shao",
                "Zhongcai Pei",
                "Weihai Chen",
                "Peter C. Y. Chen",
                "Zhengguo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07166v1",
                "http://arxiv.org/pdf/2311.07166v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07164v1",
            "title": "Pruning random resistive memory for optimizing analogue AI",
            "updated": "2023-11-13T08:59:01Z",
            "published": "2023-11-13T08:59:01Z",
            "summary": "The rapid advancement of artificial intelligence (AI) has been marked by the\nlarge language models exhibiting human-like intelligence. However, these models\nalso present unprecedented challenges to energy consumption and environmental\nsustainability. One promising solution is to revisit analogue computing, a\ntechnique that predates digital computing and exploits emerging analogue\nelectronic devices, such as resistive memory, which features in-memory\ncomputing, high scalability, and nonvolatility. However, analogue computing\nstill faces the same challenges as before: programming nonidealities and\nexpensive programming due to the underlying devices physics. Here, we report a\nuniversal solution, software-hardware co-design using structural\nplasticity-inspired edge pruning to optimize the topology of a randomly\nweighted analogue resistive memory neural network. Software-wise, the topology\nof a randomly weighted neural network is optimized by pruning connections\nrather than precisely tuning resistive memory weights. Hardware-wise, we reveal\nthe physical origin of the programming stochasticity using transmission\nelectron microscopy, which is leveraged for large-scale and low-cost\nimplementation of an overparameterized random neural network containing\nhigh-performance sub-networks. We implemented the co-design on a 40nm 256K\nresistive memory macro, observing 17.3% and 19.9% accuracy improvements in\nimage and audio classification on FashionMNIST and Spoken digits datasets, as\nwell as 9.8% (2%) improvement in PR (ROC) in image segmentation on DRIVE\ndatasets, respectively. This is accompanied by 82.1%, 51.2%, and 99.8%\nimprovement in energy efficiency thanks to analogue in-memory computing. By\nembracing the intrinsic stochasticity and in-memory computing, this work may\nsolve the biggest obstacle of analogue computing systems and thus unleash their\nimmense potential for next-generation AI hardware.",
            "author": [
                "Yi Li",
                "Songqi Wang",
                "Yaping Zhao",
                "Shaocong Wang",
                "Woyu Zhang",
                "Yangu He",
                "Ning Lin",
                "Binbin Cui",
                "Xi Chen",
                "Shiming Zhang",
                "Hao Jiang",
                "Peng Lin",
                "Xumeng Zhang",
                "Xiaojuan Qi",
                "Zhongrui Wang",
                "Xiaoxin Xu",
                "Dashan Shang",
                "Qi Liu",
                "Kwang-Ting Cheng",
                "Ming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07164v1",
                "http://arxiv.org/pdf/2311.07164v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07163v1",
            "title": "Enhancing Lightweight Neural Networks for Small Object Detection in IoT\n  Applications",
            "updated": "2023-11-13T08:58:34Z",
            "published": "2023-11-13T08:58:34Z",
            "summary": "Advances in lightweight neural networks have revolutionized computer vision\nin a broad range of IoT applications, encompassing remote monitoring and\nprocess automation. However, the detection of small objects, which is crucial\nfor many of these applications, remains an underexplored area in current\ncomputer vision research, particularly for embedded devices. To address this\ngap, the paper proposes a novel adaptive tiling method that can be used on top\nof any existing object detector including the popular FOMO network for object\ndetection on microcontrollers. Our experimental results show that the proposed\ntiling method can boost the F1-score by up to 225% while reducing the average\nobject count error by up to 76%. Furthermore, the findings of this work suggest\nthat using a soft F1 loss over the popular binary cross-entropy loss can\nsignificantly reduce the negative impact of imbalanced data. Finally, we\nvalidate our approach by conducting experiments on the Sony Spresense\nmicrocontroller, showcasing the proposed method's ability to strike a balance\nbetween detection performance, low latency, and minimal memory consumption.",
            "author": [
                "Liam Boyle",
                "Nicolas Baumann",
                "Seonyeong Heo",
                "Michele Magno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07163v1",
                "http://arxiv.org/pdf/2311.07163v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07162v1",
            "title": "CycleGANAS: Differentiable Neural Architecture Search for CycleGAN",
            "updated": "2023-11-13T08:56:56Z",
            "published": "2023-11-13T08:56:56Z",
            "summary": "We develop a Neural Architecture Search (NAS) framework for CycleGAN that\ncarries out unpaired image-to-image translation task. Extending previous NAS\ntechniques for Generative Adversarial Networks (GANs) to CycleGAN is not\nstraightforward due to the task difference and greater search space. We design\narchitectures that consist of a stack of simple ResNet-based cells and develop\na search method that effectively explore the large search space. We show that\nour framework, called CycleGANAS, not only effectively discovers\nhigh-performance architectures that either match or surpass the performance of\nthe original CycleGAN, but also successfully address the data imbalance by\nindividual architecture search for each translation direction. To our best\nknowledge, it is the first NAS result for CycleGAN and shed light on NAS for\nmore complex structures.",
            "author": [
                "Taegun An",
                "Changhee Joo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07162v1",
                "http://arxiv.org/pdf/2311.07162v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07161v1",
            "title": "Developing a Named Entity Recognition Dataset for Tagalog",
            "updated": "2023-11-13T08:56:47Z",
            "published": "2023-11-13T08:56:47Z",
            "summary": "We present the development of a Named Entity Recognition (NER) dataset for\nTagalog. This corpus helps fill the resource gap present in Philippine\nlanguages today, where NER resources are scarce. The texts were obtained from a\npretraining corpora containing news reports, and were labeled by native\nspeakers in an iterative fashion. The resulting dataset contains ~7.8k\ndocuments across three entity types: Person, Organization, and Location. The\ninter-annotator agreement, as measured by Cohen's $\\kappa$, is 0.81. We also\nconducted extensive empirical evaluation of state-of-the-art methods across\nsupervised and transfer learning settings. Finally, we released the data and\nprocessing code publicly to inspire future work on Tagalog NLP.",
            "author": [
                "Lester James V. Miranda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07161v1",
                "http://arxiv.org/pdf/2311.07161v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07159v1",
            "title": "A new quasilinear model for turbulent momentum transport in tokamaks\n  with flow shear and plasma shaping",
            "updated": "2023-11-13T08:54:01Z",
            "published": "2023-11-13T08:54:01Z",
            "summary": "Sufficiently strong flow shear reduces turbulent transport in tokamak\nplasmas, thereby improving the prospects for fusion power plants. It is\ntherefore of great importance to efficiently explore parameter space to find\nwhere strong plasma flow can be achieved. To this end, we propose a new,\nphysically motivated quasi-linear model for estimating momentum transport from\nturbulence in the presence of toroidal flow shear and plasma shaping. The\nmethod gives good estimates of momentum transport for up-down asymmetric\ngeometries as well as low magnetic shear and tight aspect ratio. The results\nare benchmarked with high-fidelity nonlinear GENE simulations, demonstrating\nthat it provides a fast and accurate estimate of momentum transport.",
            "author": [
                "Haomin Sun",
                "Justin Ball",
                "Stephan Brunner",
                "Arnas Volcokas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07159v1",
                "http://arxiv.org/pdf/2311.07159v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07156v1",
            "title": "Deep mixture of linear mixed models for complex longitudinal data",
            "updated": "2023-11-13T08:50:48Z",
            "published": "2023-11-13T08:50:48Z",
            "summary": "Mixtures of linear mixed models are widely used for modelling longitudinal\ndata for which observation times differ between subjects. In typical\napplications, temporal trends are described using a basis expansion, with basis\ncoefficients treated as random effects varying by subject. Additional random\neffects can describe variation between mixture components, or other known\nsources of variation in complex experimental designs. A key advantage of these\nmodels is that they provide a natural mechanism for clustering, which can be\nhelpful for interpretation in many applications. Current versions of mixtures\nof linear mixed models are not specifically designed for the case where there\nare many observations per subject and a complex temporal trend, which requires\na large number of basis functions to capture. In this case, the\nsubject-specific basis coefficients are a high-dimensional random effects\nvector, for which the covariance matrix is hard to specify and estimate,\nespecially if it varies between mixture components. To address this issue, we\nconsider the use of recently-developed deep mixture of factor analyzers models\nas the prior for the random effects. The resulting deep mixture of linear mixed\nmodels is well-suited to high-dimensional settings, and we describe an\nefficient variational inference approach to posterior computation. The efficacy\nof the method is demonstrated on both real and simulated data.",
            "author": [
                "Lucas Kock",
                "Nadja Klein",
                "David J. Nott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07156v1",
                "http://arxiv.org/pdf/2311.07156v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07155v1",
            "title": "Sync Pure Counterfactual Regret Minimization in Incomplete Information\n  Extensive Form Games",
            "updated": "2023-11-13T08:50:37Z",
            "published": "2023-11-13T08:50:37Z",
            "summary": "Counterfactual Regret Minimization (CFR) and its variants developed based\nupon Regret Matching (RM) have been considered to be the best method to solve\nincomplete information extensive form games. In addition to RM and CFR,\nFictitious Play (FP) is another equilibrium computation algorithm in normal\nform games. Previous experience has shown that the convergence rate of FP is\nslower than RM and FP is difficult to use in extensive form games. However,\nrecent research has made improvements in both issues. Firstly, Abernethy\nproposed a new FP variant sync FP, which has faster convergence rate than RM+.\nSecondly, Qi introduced FP into extensive form games and proposed Pure CFR\n(PCFR). This paper combines these two improvements, resulting in a new\nalgorithm sync PCFR. In our experiment, the convergence rate of sync PCFR is\napproximately an order of magnitude faster than CFR+ (state-of-the-art\nalgorithm for equilibrium computation in incomplete information extensive form\ngames), while requiring less memory in an iteration.",
            "author": [
                "Qi Ju"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07155v1",
                "http://arxiv.org/pdf/2311.07155v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07154v1",
            "title": "On the instability of threshold solutions of reaction-diffusion\n  equations, and applications to optimization problems",
            "updated": "2023-11-13T08:50:34Z",
            "published": "2023-11-13T08:50:34Z",
            "summary": "The first part of this paper is devoted to the derivation of a technical\nresult, related to the stability of the solution of a reaction-diffusion\nequation $u_t-\\Delta u = f(x,u)$ on $(0,\\infty)\\times \\mathbb{R}^N$, where the\ninitial datum $u(0,x)=u_0(x)$ is such that $\\lim_{t\\to +\\infty} u(t,x)=W(x)$\nfor all $x$, with $W$ a steady state in $H^1(\\mathbb{R}^N)$. We characterize\nthe perturbations $h$ such that, if $u^h$ is the solution associated with the\ninitial datum $u_0+h$, then, if $h$ is small enough in a sense, one has\n$u^h(t,x)>W(x)$ (resp. $u(t,x)<W(x)$) for $t$ large. This condition depends on\nthe sign of $\\int_{\\mathbb{R}^N} h(x)p(0,x)dx$, where $p$ is an adjoint\nsolution, which satisfies a backward parabolic equation on $(0,\\infty)$ and is\nuniquely defined [7]. We then provide two applications of our result. We first\naddress an open problem stated in [8] when $N=1$ and $f$ is a bistable\nnonlinearity independent of $x$. Namely, we compute the derivative of the\ncritical length $L^*(r)$ associated with the initial datum\n$\\mathbf{I}_{(-L-r,-r)\\cup (r,L+r)}$, that is the length $L$ above (resp.\nbelow) which $u(t,x)$ converges to $1$ (resp. $0$) as $t\\to +\\infty$. Lastly,\nagain when $N=1$ and $f$ is a bistable nonlinearity independent of $x$, we\nprove the existence and characterize with a bathtub principle the initial datum\n$\\underline{u}_0$ minimizing some cost function $\\int_\\mathbb{R} j(u_0)$ and\nguaranteeing at the same time that $\\liminf_{t\\to +\\infty} u(t,x)>0$ for all\n$x$.",
            "author": [
                "Gr\u00e9goire Nadin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07154v1",
                "http://arxiv.org/pdf/2311.07154v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07152v1",
            "title": "Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object\n  Detection",
            "updated": "2023-11-13T08:47:09Z",
            "published": "2023-11-13T08:47:09Z",
            "summary": "3D object Detection with LiDAR-camera encounters overfitting in algorithm\ndevelopment which is derived from the violation of some fundamental rules. We\nrefer to the data annotation in dataset construction for theory complementing\nand argue that the regression task prediction should not involve the feature\nfrom the camera branch. By following the cutting-edge perspective of 'Detecting\nAs Labeling', we propose a novel paradigm dubbed DAL. With the most classical\nelementary algorithms, a simple predicting pipeline is constructed by imitating\nthe data annotation process. Then we train it in the simplest way to minimize\nits dependency and strengthen its portability. Though simple in construction\nand training, the proposed DAL paradigm not only substantially pushes the\nperformance boundary but also provides a superior trade-off between speed and\naccuracy among all existing methods. With comprehensive superiority, DAL is an\nideal baseline for both future work development and practical deployment. The\ncode has been released to facilitate future work on\nhttps://github.com/HuangJunJie2017/BEVDet.",
            "author": [
                "Junjie Huang",
                "Yun Ye",
                "Zhujin Liang",
                "Yi Shan",
                "Dalong Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07152v1",
                "http://arxiv.org/pdf/2311.07152v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07150v1",
            "title": "Interaction is all You Need? A Study of Robots Ability to Understand and\n  Execute",
            "updated": "2023-11-13T08:39:06Z",
            "published": "2023-11-13T08:39:06Z",
            "summary": "This paper aims to address a critical challenge in robotics, which is\nenabling them to operate seamlessly in human environments through natural\nlanguage interactions. Our primary focus is to equip robots with the ability to\nunderstand and execute complex instructions in coherent dialogs to facilitate\nintricate task-solving scenarios. To explore this, we build upon the Execution\nfrom Dialog History (EDH) task from the Teach benchmark. We employ a\nmulti-transformer model with BART LM. We observe that our best configuration\noutperforms the baseline with a success rate score of 8.85 and a\ngoal-conditioned success rate score of 14.02. In addition, we suggest an\nalternative methodology for completing this task. Moreover, we introduce a new\ntask by expanding the EDH task and making predictions about game plans instead\nof individual actions. We have evaluated multiple BART models and an LLaMA2\nLLM, which has achieved a ROGUE-L score of 46.77 for this task.",
            "author": [
                "Kushal Koshti",
                "Nidhir Bhavsar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07150v1",
                "http://arxiv.org/pdf/2311.07150v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07626v1",
            "title": "Quantum Machine Learning for Remote Sensing: Exploring potential and\n  challenges",
            "updated": "2023-11-13T08:38:44Z",
            "published": "2023-11-13T08:38:44Z",
            "summary": "The industry of quantum technologies is rapidly expanding, offering promising\nopportunities for various scientific domains. Among these emerging\ntechnologies, Quantum Machine Learning (QML) has attracted considerable\nattention due to its potential to revolutionize data processing and analysis.\nIn this paper, we investigate the application of QML in the field of remote\nsensing. It is believed that QML can provide valuable insights for analysis of\ndata from space. We delve into the common beliefs surrounding the quantum\nadvantage in QML for remote sensing and highlight the open challenges that need\nto be addressed. To shed light on the challenges, we conduct a study focused on\nthe problem of kernel value concentration, a phenomenon that adversely affects\nthe runtime of quantum computers. Our findings indicate that while this issue\nnegatively impacts quantum computer performance, it does not entirely negate\nthe potential quantum advantage in QML for remote sensing.",
            "author": [
                "Artur Miroszewski",
                "Jakub Nalepa",
                "Bertrand Le Saux",
                "Jakub Mielczarek"
            ],
            "link": [
                "http://dx.doi.org/10.2760/46796",
                "http://arxiv.org/abs/2311.07626v1",
                "http://arxiv.org/pdf/2311.07626v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07148v1",
            "title": "Variation of the electron flux spectrum along a solar flare loop as\n  inferred from STIX hard X-ray observations",
            "updated": "2023-11-13T08:36:36Z",
            "published": "2023-11-13T08:36:36Z",
            "summary": "Regularized imaging spectroscopy was introduced for the construction of\nelectron flux images at different energies from count visibilities recorded by\nthe Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI). In this work\nwe seek to extend this approach to data from the Spectrometer/Telescope for\nImaging X-rays (STIX) on-board the Solar Orbiter mission. Our aims are to\ndemonstrate the feasibility of regularized imaging spectroscopy as a method for\nanalysis of STIX data, and also to show how such analysis can lead to insights\ninto the physical processes affecting the nonthermal electrons responsible for\nthe hard X-ray emission observed by STIX. STIX records imaging data in an\nintrinsically different manner from RHESSI. Rather than sweeping the angular\nfrequency plane in a set of concentric circles (one circle per detector), STIX\nuses $30$ collimators, each corresponding to a specific angular frequency. In\nthis paper we derive an appropriate modification of the previous computational\napproach for the analysis of the visibilities observed by STIX. This approach\nalso allows for the observed count data to be placed into non-uniformly-spaced\nenergy bins. We show that the regularized imaging spectroscopy approach is not\nonly feasible for analysis of the visibilities observed by STIX, but also more\nreliable. Application of the regularized imaging spectroscopy technique to\nseveral well-observed flares reveals details of the variation of the electron\nflux spectrum throughout the flare sources. We conclude that the\nvisibility-based regularized imaging spectroscopy approach is well-suited to\nanalysis of STIX data. We also use STIX electron flux spectral images to track,\nfor the first time, the behavior of the accelerated electrons during their path\nfrom the acceleration site in the solar corona toward the chromosphere",
            "author": [
                "Anna Volpara",
                "Paolo Massa",
                "Sam Krucker",
                "A Gordon Emslie",
                "Michele Piana",
                "Anna Maria Massone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07148v1",
                "http://arxiv.org/pdf/2311.07148v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "cs.NA",
                "math.NA",
                "physics.space-ph",
                "85-08, 45Q05, 65F22"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07625v2",
            "title": "Activity Sparsity Complements Weight Sparsity for Efficient RNN\n  Inference",
            "updated": "2023-12-07T07:59:58Z",
            "published": "2023-11-13T08:18:44Z",
            "summary": "Artificial neural networks open up unprecedented machine learning\ncapabilities at the cost of ever growing computational requirements.\nSparsifying the parameters, often achieved through weight pruning, has been\nidentified as a powerful technique to compress the number of model parameters\nand reduce the computational operations of neural networks. Yet, sparse\nactivations, while omnipresent in both biological neural networks and deep\nlearning systems, have not been fully utilized as a compression technique in\ndeep learning. Moreover, the interaction between sparse activations and weight\npruning is not fully understood. In this work, we demonstrate that activity\nsparsity can compose multiplicatively with parameter sparsity in a recurrent\nneural network model based on the GRU that is designed to be activity sparse.\nWe achieve up to $20\\times$ reduction of computation while maintaining\nperplexities below $60$ on the Penn Treebank language modeling task. This\nmagnitude of reduction has not been achieved previously with solely sparsely\nconnected LSTMs, and the language modeling performance of our model has not\nbeen achieved previously with any sparsely activated recurrent neural networks\nor spiking neural networks. Neuromorphic computing devices are especially good\nat taking advantage of the dynamic activity sparsity, and our results provide\nstrong evidence that making deep learning models activity sparse and porting\nthem to neuromorphic devices can be a viable strategy that does not compromise\non task performance. Our results also drive further convergence of methods from\ndeep learning and neuromorphic computing for efficient machine learning.",
            "author": [
                "Rishav Mukherji",
                "Mark Sch\u00f6ne",
                "Khaleelulla Khan Nazeer",
                "Christian Mayr",
                "Anand Subramoney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07625v2",
                "http://arxiv.org/pdf/2311.07625v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07143v1",
            "title": "Learning Symmetrization for Equivariance with Orbit Distance\n  Minimization",
            "updated": "2023-11-13T08:14:29Z",
            "published": "2023-11-13T08:14:29Z",
            "summary": "We present a general framework for symmetrizing an arbitrary neural-network\narchitecture and making it equivariant with respect to a given group. We build\nupon the proposals of Kim et al. (2023); Kaba et al. (2023) for symmetrization,\nand improve them by replacing their conversion of neural features into group\nrepresentations, with an optimization whose loss intuitively measures the\ndistance between group orbits. This change makes our approach applicable to a\nbroader range of matrix groups, such as the Lorentz group O(1, 3), than these\ntwo proposals. We experimentally show our method's competitiveness on the SO(2)\nimage classification task, and also its increased generality on the task with\nO(1, 3). Our implementation will be made accessible at\nhttps://github.com/tiendatnguyen-vision/Orbit-symmetrize.",
            "author": [
                "Tien Dat Nguyen",
                "Jinwoo Kim",
                "Hongseok Yang",
                "Seunghoon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07143v1",
                "http://arxiv.org/pdf/2311.07143v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07141v2",
            "title": "SABAF: Removing Strong Attribute Bias from Neural Networks with\n  Adversarial Filtering",
            "updated": "2023-11-16T07:23:17Z",
            "published": "2023-11-13T08:13:55Z",
            "summary": "Ensuring a neural network is not relying on protected attributes (e.g., race,\nsex, age) for prediction is crucial in advancing fair and trustworthy AI. While\nseveral promising methods for removing attribute bias in neural networks have\nbeen proposed, their limitations remain under-explored. To that end, in this\nwork, we mathematically and empirically reveal the limitation of existing\nattribute bias removal methods in presence of strong bias and propose a new\nmethod that can mitigate this limitation. Specifically, we first derive a\ngeneral non-vacuous information-theoretical upper bound on the performance of\nany attribute bias removal method in terms of the bias strength, revealing that\nthey are effective only when the inherent bias in the dataset is relatively\nweak. Next, we derive a necessary condition for the existence of any method\nthat can remove attribute bias regardless of the bias strength. Inspired by\nthis condition, we then propose a new method using an adversarial objective\nthat directly filters out protected attributes in the input space while\nmaximally preserving all other attributes, without requiring any specific\ntarget label. The proposed method achieves state-of-the-art performance in both\nstrong and moderate bias settings. We provide extensive experiments on\nsynthetic, image, and census datasets, to verify the derived theoretical bound\nand its consequences in practice, and evaluate the effectiveness of the\nproposed method in removing strong attribute bias.",
            "author": [
                "Jiazhi Li",
                "Mahyar Khayatkhoei",
                "Jiageng Zhu",
                "Hanchen Xie",
                "Mohamed E. Hussein",
                "Wael AbdAlmageed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07141v2",
                "http://arxiv.org/pdf/2311.07141v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07140v1",
            "title": "A Linear Parameter-Varying Approach to Data Predictive Control",
            "updated": "2023-11-13T08:12:28Z",
            "published": "2023-11-13T08:12:28Z",
            "summary": "By means of the linear parameter-varying (LPV) Fundamental Lemma, we derive\nnovel data-driven predictive control (DPC) methods for LPV systems. In\nparticular, we present output-feedback and state-feedback-based LPV-DPC methods\nwith terminal ingredients, which guarantee exponential stability and recursive\nfeasibility. We provide methods for the data-based computation of these\nterminal ingredients. Furthermore, an in-depth analysis of the properties and\nimplementation aspects of the LPV-DPC schemes is given, including alternative\nrecursive formulations, application for nonlinear systems and handling\nnoise-disturbed data. We demonstrate the performance of the proposed methods on\na simulation example involving a nonlinear unbalanced disc system.",
            "author": [
                "Chris Verhoek",
                "Julian Berberich",
                "Sofie Haesaert",
                "Roland T\u00f3th",
                "Hossam S. Abbas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07140v1",
                "http://arxiv.org/pdf/2311.07140v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07138v1",
            "title": "WaterBench: Towards Holistic Evaluation of Watermarks for Large Language\n  Models",
            "updated": "2023-11-13T08:09:01Z",
            "published": "2023-11-13T08:09:01Z",
            "summary": "To mitigate the potential misuse of large language models (LLMs), recent\nresearch has developed watermarking algorithms, which restrict the generation\nprocess to leave an invisible trace for watermark detection. Due to the\ntwo-stage nature of the task, most studies evaluate the generation and\ndetection separately, thereby presenting a challenge in unbiased, thorough, and\napplicable evaluations. In this paper, we introduce WaterBench, the first\ncomprehensive benchmark for LLM watermarks, in which we design three crucial\nfactors: (1) For \\textbf{benchmarking procedure}, to ensure an apples-to-apples\ncomparison, we first adjust each watermarking method's hyper-parameter to reach\nthe same watermarking strength, then jointly evaluate their generation and\ndetection performance. (2) For \\textbf{task selection}, we diversify the input\nand output length to form a five-category taxonomy, covering $9$ tasks. (3) For\n\\textbf{evaluation metric}, we adopt the GPT4-Judge for automatically\nevaluating the decline of instruction-following abilities after watermarking.\nWe evaluate $4$ open-source watermarks on $2$ LLMs under $2$ watermarking\nstrengths and observe the common struggles for current methods on maintaining\nthe generation quality. The code and data are available at\n\\url{https://github.com/THU-KEG/WaterBench}.",
            "author": [
                "Shangqing Tu",
                "Yuliang Sun",
                "Yushi Bai",
                "Jifan Yu",
                "Lei Hou",
                "Juanzi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07138v1",
                "http://arxiv.org/pdf/2311.07138v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07137v1",
            "title": "Galactoseismology in cosmological simulations: Vertical perturbations by\n  dark matter, satellite galaxies and gas",
            "updated": "2023-11-13T08:07:23Z",
            "published": "2023-11-13T08:07:23Z",
            "summary": "Only recently, complex models that include the global dynamics from dwarf\nsatellite galaxies, dark matter halo structure, gas infalls, and stellar disk\nin a cosmological context became available to study the dynamics of disk\ngalaxies such as the Milky Way (MW). We use a MW model from a high-resolution\nhydrodynamical cosmological simulation named GARROTXA to establish the\nrelationship between the vertical disturbances seen in its galactic disk and\nmultiple perturbations, from the dark matter halo, satellites and gas.\n  We calculate the bending modes in the galactic disk in the last 6 Gyr of\nevolution. To quantify the impact of dark matter and gas we compute the\nvertical acceleration exerted by these components onto the disk and compare\nthem with the bending behavior with Fourier analysis. We find complex bending\npatterns at different radii and times, such as an inner retrograde mode with\nhigh frequency, as well as an outer slower retrograde mode excited at different\ntimes. The amplitudes of these bending modes are highest during the early\nstages of the thin disk formation and reach up to 8.5 km s-1 in the late disk\nevolution. We find that the infall of satellite galaxies leads to a tilt of the\ndisk, and produces anisotropic gas accretion with subsequent star formation\nevents, and supernovae, creating significant vertical accelerations onto the\ndisk plane. The misalignment between the disk and the inner stellar/dark matter\ntriaxial structure, formed during the ancient assembly of the galaxy, creates a\nstrong vertical acceleration on the stars.\n  We conclude that several agents trigger the bending of the stellar disk and\nits phase spirals in this simulation, including satellite galaxies, dark\nsub-halos, misaligned gaseous structures, and the inner dark matter profile,\nwhich coexist and influence each other, making it challenging to establish\ndirect causality.",
            "author": [
                "B. Garc\u00eda-Conde",
                "T. Antoja",
                "S. Roca-F\u00e0brega",
                "F. G\u00f3mez",
                "P. Ramos",
                "N. Garavito-Camargo",
                "MA. G\u00f3mez-Flechoso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07137v1",
                "http://arxiv.org/pdf/2311.07137v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07136v1",
            "title": "Superconducting pairing symmetry in MoTe$_{2}$",
            "updated": "2023-11-13T08:06:33Z",
            "published": "2023-11-13T08:06:33Z",
            "summary": "Topological superconductors have long been sought for their potential use in\nquantum computing. The type-II Weyl semimetal MoTe$_{2}$ is an obvious\ncandidate, exhibiting a superconducting state below 500 mK at ambient pressure,\nbut the question remains whether the pairing is conventional $s^{++}$ or\ntopological $s^{+-}$. The application of external pressure favors the\nsuperconducting state in MoTe$_{2}$ and suppresses the structural transition\nfrom $1T'$ to $T_{d}$. The competition between the two structures leads to a\nmixed phase that strongly enhances the disorder present in the system,\nremarkably without affecting the superconducting transition temperature, in\ncontrast to the expectation of $s^{+-}$ pairing superconductivity. Our thorough\nanalysis of the electrical and Hall resistivities as a function of pressure\nyields the most accurate temperature-pressure phase diagram available to date\nfor MoTe$_{2}$ and a detailed view of the relationship between disorder and\nsuperconductivity, supporting a conventional $s^{++}$ pairing symmetry.",
            "author": [
                "M. M. Piva",
                "L. O. Kutelak",
                "R. Borth",
                "Y. Liu",
                "C. Petrovic",
                "R. D. dos Reis",
                "M. Nicklas"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevMaterials.7.L111801",
                "http://arxiv.org/abs/2311.07136v1",
                "http://arxiv.org/pdf/2311.07136v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07130v1",
            "title": "Reconfiguration of basis pairs in regular matroids",
            "updated": "2023-11-13T07:53:53Z",
            "published": "2023-11-13T07:53:53Z",
            "summary": "In recent years, combinatorial reconfiguration problems have attracted great\nattention due to their connection to various topics such as optimization,\ncounting, enumeration, or sampling. One of the most intriguing open questions\nconcerns the exchange distance of two matroid basis sequences, a problem that\nappears in several areas of computer science and mathematics. In 1980, White\nproposed a conjecture for the characterization of two basis sequences being\nreachable from each other by symmetric exchanges, which received a significant\ninterest also in algebra due to its connection to toric ideals and Gr\\\"obner\nbases. In this work, we verify White's conjecture for basis sequences of length\ntwo in regular matroids, a problem that was formulated as a separate question\nby Farber, Richter, and Shan and Andres, Hochst\\\"attler, and Merkel. Most of\nprevious work on White's conjecture has not considered the question from an\nalgorithmic perspective. We study the problem from an optimization point of\nview: our proof implies a polynomial algorithm for determining a sequence of\nsymmetric exchanges that transforms a basis pair into another, thus providing\nthe first polynomial upper bound on the exchange distance of basis pairs in\nregular matroids. As a byproduct, we verify a conjecture of Gabow from 1976 on\nthe serial symmetric exchange property of matroids for the regular case.",
            "author": [
                "Krist\u00f3f B\u00e9rczi",
                "Bence M\u00e1trav\u00f6lgyi",
                "Tam\u00e1s Schwarcz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07130v1",
                "http://arxiv.org/pdf/2311.07130v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07623v2",
            "title": "PadChannel: Improving CNN Performance through Explicit Padding Encoding",
            "updated": "2023-11-16T17:17:40Z",
            "published": "2023-11-13T07:44:56Z",
            "summary": "In convolutional neural networks (CNNs), padding plays a pivotal role in\npreserving spatial dimensions throughout the layers. Traditional padding\ntechniques do not explicitly distinguish between the actual image content and\nthe padded regions, potentially causing CNNs to incorrectly interpret the\nboundary pixels or regions that resemble boundaries. This ambiguity can lead to\nsuboptimal feature extraction. To address this, we propose PadChannel, a novel\npadding method that encodes padding statuses as an additional input channel,\nenabling CNNs to easily distinguish genuine pixels from padded ones. By\nincorporating PadChannel into several prominent CNN architectures, we observed\nsmall performance improvements and notable reductions in the variances on the\nImageNet-1K image classification task at marginal increases in the\ncomputational cost. The source code is available at\nhttps://github.com/AussieSeaweed/pad-channel",
            "author": [
                "Juho Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07623v2",
                "http://arxiv.org/pdf/2311.07623v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07126v1",
            "title": "How to Do Machine Learning with Small Data? -- A Review from an\n  Industrial Perspective",
            "updated": "2023-11-13T07:39:13Z",
            "published": "2023-11-13T07:39:13Z",
            "summary": "Artificial intelligence experienced a technological breakthrough in science,\nindustry, and everyday life in the recent few decades. The advancements can be\ncredited to the ever-increasing availability and miniaturization of\ncomputational resources that resulted in exponential data growth. However,\nbecause of the insufficient amount of data in some cases, employing machine\nlearning in solving complex tasks is not straightforward or even possible. As a\nresult, machine learning with small data experiences rising importance in data\nscience and application in several fields. The authors focus on interpreting\nthe general term of \"small data\" and their engineering and industrial\napplication role. They give a brief overview of the most important industrial\napplications of machine learning and small data. Small data is defined in terms\nof various characteristics compared to big data, and a machine learning\nformalism was introduced. Five critical challenges of machine learning with\nsmall data in industrial applications are presented: unlabeled data, imbalanced\ndata, missing data, insufficient data, and rare events. Based on those\ndefinitions, an overview of the considerations in domain representation and\ndata acquisition is given along with a taxonomy of machine learning approaches\nin the context of small data.",
            "author": [
                "Ivan Kraljevski",
                "Yong Chul Ju",
                "Dmitrij Ivanov",
                "Constanze Tsch\u00f6pe",
                "Matthias Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07126v1",
                "http://arxiv.org/pdf/2311.07126v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07125v1",
            "title": "Attention-Challenging Multiple Instance Learning for Whole Slide Image\n  Classification",
            "updated": "2023-11-13T07:34:53Z",
            "published": "2023-11-13T07:34:53Z",
            "summary": "Overfitting remains a significant challenge in the application of Multiple\nInstance Learning (MIL) methods for Whole Slide Image (WSI) analysis.\nVisualizing heatmaps reveals that current MIL methods focus on a subset of\npredictive instances, hindering effective model generalization. To tackle this,\nwe propose Attention-Challenging MIL (ACMIL), aimed at forcing the attention\nmechanism to capture more challenging predictive instances. ACMIL incorporates\ntwo techniques, Multiple Branch Attention (MBA) to capture richer predictive\ninstances and Stochastic Top-K Instance Masking (STKIM) to suppress simple\npredictive instances. Evaluation on three WSI datasets outperforms\nstate-of-the-art methods. Additionally, through heatmap visualization, UMAP\nvisualization, and attention value statistics, this paper comprehensively\nillustrates ACMIL's effectiveness in overcoming the overfitting challenge. The\nsource code is available at \\url{https://github.com/dazhangyu123/ACMIL}.",
            "author": [
                "Yunlong Zhang",
                "Honglin Li",
                "Yuxuan Sun",
                "Sunyi Zheng",
                "Chenglu Zhu",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07125v1",
                "http://arxiv.org/pdf/2311.07125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07121v1",
            "title": "Control Requirements and Benchmarks for Quantum Error Correction",
            "updated": "2023-11-13T07:29:28Z",
            "published": "2023-11-13T07:29:28Z",
            "summary": "Reaching useful fault-tolerant quantum computation relies on successfully\nimplementing quantum error correction (QEC). In QEC, quantum gates and\nmeasurements are performed to stabilize the computational qubits, and classical\nprocessing is used to convert the measurements into estimated logical Pauli\nframe updates or logical measurement results. While QEC research has\nconcentrated on developing and evaluating QEC codes and decoding algorithms,\nspecification and clarification of the requirements for the classical control\nsystem running QEC codes are lacking. Here, we elucidate the roles of the QEC\ncontrol system, the necessity to implement low latency feed-forward quantum\noperations, and suggest near-term benchmarks that confront the classical\nbottlenecks for QEC quantum computation. These benchmarks are based on the\nlatency between a measurement and the operation that depends on it and\nincorporate the different control aspects such as quantum-classical\nparallelization capabilities and decoding throughput. Using a dynamical system\nanalysis, we show how the QEC control system latency performance determines the\noperation regime of a QEC circuit: latency divergence, where quantum\ncalculations are unfeasible, classical-controller limited runtime, or\nquantum-operation limited runtime where the classical operations do not delay\nthe quantum circuit. This analysis and the proposed benchmarks aim to allow the\nevaluation and development of QEC control systems toward their realization as a\nmain component in fault-tolerant quantum computation.",
            "author": [
                "Yaniv Kurman",
                "Lior Ella",
                "Ramon Szmuk",
                "Oded Wertheim",
                "Benedikt Dorschner",
                "Sam Stanwyck",
                "Yonatan Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07121v1",
                "http://arxiv.org/pdf/2311.07121v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07117v1",
            "title": "Olfactory learning alters navigation strategies and behavioral\n  variability in C. elegans",
            "updated": "2023-11-13T07:21:22Z",
            "published": "2023-11-13T07:21:22Z",
            "summary": "Animals adjust their behavioral response to sensory input adaptively\ndepending on past experiences. The flexible brain computation is crucial for\nsurvival and is of great interest in neuroscience. The nematode C. elegans\nmodulates its navigation behavior depending on the association of odor butanone\nwith food (appetitive training) or starvation (aversive training), and will\nthen climb up the butanone gradient or ignore it, respectively. However, the\nexact change in navigation strategy in response to learning is still unknown.\nHere we study the learned odor navigation in worms by combining precise\nexperimental measurement and a novel descriptive model of navigation. Our model\nconsists of two known navigation strategies in worms: biased random walk and\nweathervaning. We infer weights on these strategies by applying the model to\nworm navigation trajectories and the exact odor concentration it experiences.\nCompared to naive worms, appetitive trained worms up-regulate the biased random\nwalk strategy, and aversive trained worms down-regulate the weathervaning\nstrategy. The statistical model provides prediction with $>90 \\%$ accuracy of\nthe past training condition given navigation data, which outperforms the\nclassical chemotaxis metric. We find that the behavioral variability is altered\nby learning, such that worms are less variable after training compared to naive\nones. The model further predicts the learning-dependent response and\nvariability under optogenetic perturbation of the olfactory neuron\nAWC$^\\mathrm{ON}$. Lastly, we investigate neural circuits downstream from\nAWC$^\\mathrm{ON}$ that are differentially recruited for learned odor-guided\nnavigation. Together, we provide a new paradigm to quantify flexible navigation\nalgorithms and pinpoint the underlying neural substrates.",
            "author": [
                "Kevin S. Chen",
                "Jonathan W. Pillow",
                "Andrew M. Leifer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07117v1",
                "http://arxiv.org/pdf/2311.07117v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07115v1",
            "title": "Gen-Z: Generative Zero-Shot Text Classification with Contextualized\n  Label Descriptions",
            "updated": "2023-11-13T07:12:57Z",
            "published": "2023-11-13T07:12:57Z",
            "summary": "Language model (LM) prompting--a popular paradigm for solving NLP tasks--has\nbeen shown to be susceptible to miscalibration and brittleness to slight prompt\nvariations, caused by its discriminative prompting approach, i.e., predicting\nthe label given the input. To address these issues, we propose Gen-Z--a\ngenerative prompting framework for zero-shot text classification. GEN-Z is\ngenerative, as it measures the LM likelihood of input text, conditioned on\nnatural language descriptions of labels. The framework is multivariate, as\nlabel descriptions allow us to seamlessly integrate additional contextual\ninformation about the labels to improve task performance. On various standard\nclassification benchmarks, with six open-source LM families, we show that\nzero-shot classification with simple contextualization of the data source of\nthe evaluation set consistently outperforms both zero-shot and few-shot\nbaselines while improving robustness to prompt variations. Further, our\napproach enables personalizing classification in a zero-shot manner by\nincorporating author, subject, or reader information in the label descriptions.",
            "author": [
                "Sachin Kumar",
                "Chan Young Park",
                "Yulia Tsvetkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07115v1",
                "http://arxiv.org/pdf/2311.07115v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07113v2",
            "title": "SpectralGPT: Spectral Foundation Model",
            "updated": "2023-11-25T09:11:50Z",
            "published": "2023-11-13T07:09:30Z",
            "summary": "The foundation model has recently garnered significant attention due to its\npotential to revolutionize the field of visual representation learning in a\nself-supervised manner. While most foundation models are tailored to\neffectively process RGB images for various visual tasks, there is a noticeable\ngap in research focused on spectral data, which offers valuable information for\nscene understanding, especially in remote sensing (RS) applications. To fill\nthis gap, we created for the first time a universal RS foundation model, named\nSpectralGPT, which is purpose-built to handle spectral RS images using a novel\n3D generative pretrained transformer (GPT). Compared to existing foundation\nmodels, SpectralGPT 1) accommodates input images with varying sizes,\nresolutions, time series, and regions in a progressive training fashion,\nenabling full utilization of extensive RS big data; 2) leverages 3D token\ngeneration for spatial-spectral coupling; 3) captures spectrally sequential\npatterns via multi-target reconstruction; 4) trains on one million spectral RS\nimages, yielding models with over 600 million parameters. Our evaluation\nhighlights significant performance improvements with pretrained SpectralGPT\nmodels, signifying substantial potential in advancing spectral RS big data\napplications within the field of geoscience across four downstream tasks:\nsingle/multi-label scene classification, semantic segmentation, and change\ndetection.",
            "author": [
                "Danfeng Hong",
                "Bing Zhang",
                "Xuyang Li",
                "Yuxuan Li",
                "Chenyu Li",
                "Jing Yao",
                "Naoto Yokoya",
                "Hao Li",
                "Pedram Ghamisi",
                "Xiuping Jia",
                "Antonio Plaza",
                "Gamba Paolo",
                "Jon Atli Benediktsson",
                "Jocelyn Chanussot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07113v2",
                "http://arxiv.org/pdf/2311.07113v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07110v1",
            "title": "Adversarial Purification for Data-Driven Power System Event Classifiers\n  with Diffusion Models",
            "updated": "2023-11-13T06:52:56Z",
            "published": "2023-11-13T06:52:56Z",
            "summary": "The global deployment of the phasor measurement units (PMUs) enables\nreal-time monitoring of the power system, which has stimulated considerable\nresearch into machine learning-based models for event detection and\nclassification. However, recent studies reveal that machine learning-based\nmethods are vulnerable to adversarial attacks, which can fool the event\nclassifiers by adding small perturbations to the raw PMU data. To mitigate the\nthreats posed by adversarial attacks, research on defense strategies is\nurgently needed. This paper proposes an effective adversarial purification\nmethod based on the diffusion model to counter adversarial attacks on the\nmachine learning-based power system event classifier. The proposed method\nincludes two steps: injecting noise into the PMU data; and utilizing a\npre-trained neural network to eliminate the added noise while simultaneously\nremoving perturbations introduced by the adversarial attacks. The proposed\nadversarial purification method significantly increases the accuracy of the\nevent classifier under adversarial attacks while satisfying the requirements of\nreal-time operations. In addition, the theoretical analysis reveals that the\nproposed diffusion model-based adversarial purification method decreases the\ndistance between the original and compromised PMU data, which reduces the\nimpacts of adversarial attacks. The empirical results on a large-scale\nreal-world PMU dataset validate the effectiveness and computational efficiency\nof the proposed adversarial purification method.",
            "author": [
                "Yuanbin Cheng",
                "Koji Yamashita",
                "Jim Follum",
                "Nanpeng Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07110v1",
                "http://arxiv.org/pdf/2311.07110v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.CR",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07102v1",
            "title": "Fovea Transformer: Efficient Long-Context Modeling with Structured\n  Fine-to-Coarse Attention",
            "updated": "2023-11-13T06:24:27Z",
            "published": "2023-11-13T06:24:27Z",
            "summary": "The quadratic complexity of self-attention in Transformers has hindered the\nprocessing of long text. To alleviate this problem, previous works have\nproposed to sparsify the attention matrix, taking advantage of the observation\nthat crucial information about a token can be derived from its neighbors. These\nmethods typically combine one or another form of local attention and global\nattention. Such combinations introduce abrupt changes in contextual granularity\nwhen going from local to global, which may be undesirable. We believe that a\nsmoother transition could potentially enhance model's ability to capture\nlong-context dependencies. In this study, we introduce Fovea Transformer, a\nlong-context focused transformer that addresses the challenges of capturing\nglobal dependencies while maintaining computational efficiency. To achieve\nthis, we construct a multi-scale tree from the input sequence, and use\nrepresentations of context tokens with a progressively coarser granularity in\nthe tree, as their distance to the query token increases. We evaluate our model\non three long-context summarization tasks\\footnote{Our code is publicly\navailable at: \\textit{https://github.com/ZiweiHe/Fovea-Transformer}}. It\nachieves state-of-the-art performance on two of them, and competitive results\non the third with mixed improvement and setback of the evaluation metrics.",
            "author": [
                "Ziwei He",
                "Jian Yuan",
                "Le Zhou",
                "Jingwen Leng",
                "Bo Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07102v1",
                "http://arxiv.org/pdf/2311.07102v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07099v1",
            "title": "Explanation-aware Soft Ensemble Empowers Large Language Model In-context\n  Learning",
            "updated": "2023-11-13T06:13:38Z",
            "published": "2023-11-13T06:13:38Z",
            "summary": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language understanding tasks. With only a few demonstration examples,\nthese LLMs can quickly adapt to target tasks without expensive gradient\nupdates. Common strategies to boost such 'in-context' learning ability are to\nensemble multiple model decoded results and require the model to generate an\nexplanation along with the prediction. However, these models often treat\ndifferent class predictions equally and neglect the potential discrepancy\nbetween the explanations and predictions. To fully unleash the power of\nexplanations, we propose EASE, an Explanation-Aware Soft Ensemble framework to\nempower in-context learning with LLMs. We design two techniques,\nexplanation-guided ensemble, and soft probability aggregation, to mitigate the\neffect of unreliable explanations and improve the consistency between\nexplanations and final predictions. Experiments on seven natural language\nunderstanding tasks and four varying-size LLMs demonstrate the effectiveness of\nour proposed framework.",
            "author": [
                "Yue Yu",
                "Jiaming Shen",
                "Tianqi Liu",
                "Zhen Qin",
                "Jing Nathan Yan",
                "Jialu Liu",
                "Chao Zhang",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07099v1",
                "http://arxiv.org/pdf/2311.07099v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07094v1",
            "title": "Trustworthy Quantum Computation through Quantum Physical Unclonable\n  Functions",
            "updated": "2023-11-13T05:47:33Z",
            "published": "2023-11-13T05:47:33Z",
            "summary": "Quantum computing is under rapid development, and today there are several\ncloud-based, quantum computers (QCs) of modest size (>100s of physical qubits).\nAlthough these QCs, along with their highly-specialized classical support\ninfrastructure, are in limited supply, they are readily available for remote\naccess and programming. This work shows the viability of using intrinsic\nquantum hardware properties for fingerprinting cloud-based QCs that exist\ntoday. We demonstrate the reliability of intrinsic fingerprinting with real QC\ncharacterization data, as well as simulated QC data, and we detail a quantum\nphysically unclonable function (Q-PUF) scheme for secure key generation using\nunique fingerprint data combined with fuzzy extraction. We use fixed-frequency\ntransmon qubits for prototyping our methods.",
            "author": [
                "Kaitlin N. Smith",
                "Pranav Gokhale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07094v1",
                "http://arxiv.org/pdf/2311.07094v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07093v2",
            "title": "On the Effectiveness of ASR Representations in Real-world Noisy Speech\n  Emotion Recognition",
            "updated": "2023-11-14T13:09:51Z",
            "published": "2023-11-13T05:45:55Z",
            "summary": "This paper proposes an efficient attempt to noisy speech emotion recognition\n(NSER). Conventional NSER approaches have proven effective in mitigating the\nimpact of artificial noise sources, such as white Gaussian noise, but are\nlimited to non-stationary noises in real-world environments due to their\ncomplexity and uncertainty. To overcome this limitation, we introduce a new\nmethod for NSER by adopting the automatic speech recognition (ASR) model as a\nnoise-robust feature extractor to eliminate non-vocal information in noisy\nspeech. We first obtain intermediate layer information from the ASR model as a\nfeature representation for emotional speech and then apply this representation\nfor the downstream NSER task. Our experimental results show that 1) the\nproposed method achieves better NSER performance compared with the conventional\nnoise reduction method, 2) outperforms self-supervised learning approaches, and\n3) even outperforms text-based approaches using ASR transcription or the ground\ntruth transcription of noisy speech.",
            "author": [
                "Xiaohan Shi",
                "Jiajun He",
                "Xingfeng Li",
                "Tomoki Toda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07093v2",
                "http://arxiv.org/pdf/2311.07093v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07092v1",
            "title": "To Tell The Truth: Language of Deception and Language Models",
            "updated": "2023-11-13T05:40:11Z",
            "published": "2023-11-13T05:40:11Z",
            "summary": "Text-based misinformation permeates online discourses, yet evidence of\npeople's ability to discern truth from such deceptive textual content is\nscarce. We analyze a novel TV game show data where conversations in a\nhigh-stake environment between individuals with conflicting objectives result\nin lies. We investigate the manifestation of potentially verifiable language\ncues of deception in the presence of objective truth, a distinguishing feature\nabsent in previous text-based deception datasets. We show that there exists a\nclass of detectors (algorithms) that have similar truth detection performance\ncompared to human subjects, even when the former accesses only the language\ncues while the latter engages in conversations with complete access to all\npotential sources of cues (language and audio-visual). Our model, built on a\nlarge language model, employs a bottleneck framework to learn discernible cues\nto determine truth, an act of reasoning in which human subjects often perform\npoorly, even with incentives. Our model detects novel but accurate language\ncues in many cases where humans failed to detect deception, opening up the\npossibility of humans collaborating with algorithms and ameliorating their\nability to detect the truth.",
            "author": [
                "Bodhisattwa Prasad Majumder",
                "Sanchaita Hazra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07092v1",
                "http://arxiv.org/pdf/2311.07092v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07091v1",
            "title": "Code-Aided Channel Estimation in LDPC-Coded MIMO Systems",
            "updated": "2023-11-13T05:39:35Z",
            "published": "2023-11-13T05:39:35Z",
            "summary": "For a multiple-input multiple-output (MIMO) system with unknown channel state\ninformation (CSI), a novel low-density parity check (LDPC)-coded transmission\n(LCT) scheme with joint pilot and data channel estimation is proposed. To\nfine-tune the CSI, a method based on the constraints introduced by the coded\ndata from an LDPC code is designed such that the MIMO detector exploits the\nfine-tuned CSI. For reducing the computational burden, a coordinate ascent\nalgorithm is employed along with several approximation methods, effectively\nreducing the required times of MIMO detection and computational complexity to\nachieve a satisfying performance. Simulation results utilizing WiMAX standard\nLDPC codes and quadrature phase-shift keying (QPSK) modulation demonstrate\ngains of up to 1.3 dB at a frame error rate (FER) of $10^{-4}$ compared to\npilot-assisted transmission (PAT) over Rayleigh block-fading channels.",
            "author": [
                "Binghui Shi",
                "Yongpeng Wu",
                "Peihong Yuan",
                "Derrick Wing Kwan Ng",
                "Xiang-Gen Xia",
                "Wenjun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07091v1",
                "http://arxiv.org/pdf/2311.07091v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07090v1",
            "title": "CLiF-VQA: Enhancing Video Quality Assessment by Incorporating High-Level\n  Semantic Information related to Human Feelings",
            "updated": "2023-11-13T05:38:44Z",
            "published": "2023-11-13T05:38:44Z",
            "summary": "Video Quality Assessment (VQA) aims to simulate the process of perceiving\nvideo quality by the human visual system (HVS). The judgments made by HVS are\nalways influenced by human subjective feelings. However, most of the current\nVQA research focuses on capturing various distortions in the spatial and\ntemporal domains of videos, while ignoring the impact of human feelings. In\nthis paper, we propose CLiF-VQA, which considers both features related to human\nfeelings and spatial features of videos. In order to effectively extract\nfeatures related to human feelings from videos, we explore the consistency\nbetween CLIP and human feelings in video perception for the first time.\nSpecifically, we design multiple objective and subjective descriptions closely\nrelated to human feelings as prompts. Further we propose a novel CLIP-based\nsemantic feature extractor (SFE) which extracts features related to human\nfeelings by sliding over multiple regions of the video frame. In addition, we\nfurther capture the low-level-aware features of the video through a spatial\nfeature extraction module. The two different features are then aggregated\nthereby obtaining the quality score of the video. Extensive experiments show\nthat the proposed CLiF-VQA exhibits excellent performance on several VQA\ndatasets.",
            "author": [
                "Yachun Mi",
                "Yu Li",
                "Yan Shu",
                "Chen Hui",
                "Puchao Zhou",
                "Shaohui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07090v1",
                "http://arxiv.org/pdf/2311.07090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07089v3",
            "title": "Recursive and non-recursive filters for sequential smoothing and\n  prediction with instantaneous phase and frequency estimation applications\n  (extended version)",
            "updated": "2023-11-28T06:31:04Z",
            "published": "2023-11-13T05:37:03Z",
            "summary": "A simple procedure for the design of recursive digital filters with an\ninfinite impulse response (IIR) and non-recursive digital filters with a finite\nimpulse response (FIR) is described. The fixed-lag smoothing filters are\ndesigned to track an approximately polynomial signal of specified degree\nwithout bias at steady state, while minimizing the gain of high-frequency\n(coloured) noise with a specified power spectral density. For the IIR variant,\nthe procedure determines the optimal lag (i.e. the passband group delay)\nyielding a recursive low-complexity smoother of low order, with a specified\nbandwidth, and excellent passband phase linearity. The filters are applied to\nthe problem of instantaneous frequency estimation, e.g. for Doppler-shift\nmeasurement, for a complex exponential with polynomial phase progression in\nadditive white noise. For this classical problem, simulations show that the\nincorporation of a prediction filter (with a one-sample lead) reduces the\nincidence of (phase or frequency) angle unwrapping errors, particularly for\nsignals with high rates of angle change, which are known to limit the\nperformance of standard FIR estimators at low SNR. This improvement allows the\ninstantaneous phase of low-frequency signals to be estimated, e.g. for\ntime-delay measurement, and/or the instantaneous frequency of\nfrequency-modulated signals, down to a lower SNR. In the absence of unwrapping\nerrors, the error variance of the IIR estimators (with the optimal phase lag)\nreaches the FIR lower bound, at a significantly lower computational cost.\nGuidelines for configuring and tuning both FIR and IIR filters are provided.",
            "author": [
                "Hugh Lachlan Kennedy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07089v3",
                "http://arxiv.org/pdf/2311.07089v3"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07079v2",
            "title": "Sample Dominance Aware Framework via Non-Parametric Estimation for\n  Spontaneous Brain-Computer Interface",
            "updated": "2023-11-15T02:51:08Z",
            "published": "2023-11-13T05:08:26Z",
            "summary": "Deep learning has shown promise in decoding brain signals, such as\nelectroencephalogram (EEG), in the field of brain-computer interfaces (BCIs).\nHowever, the non-stationary characteristics of EEG signals pose challenges for\ntraining neural networks to acquire appropriate knowledge. Inconsistent EEG\nsignals resulting from these non-stationary characteristics can lead to poor\nperformance. Therefore, it is crucial to investigate and address sample\ninconsistency to ensure robust performance in spontaneous BCIs. In this study,\nwe introduce the concept of sample dominance as a measure of EEG signal\ninconsistency and propose a method to modulate its effect on network training.\nWe present a two-stage dominance score estimation technique that compensates\nfor performance degradation caused by sample inconsistencies. Our proposed\nmethod utilizes non-parametric estimation to infer sample inconsistency and\nassigns each sample a dominance score. This score is then aggregated with the\nloss function during training to modulate the impact of sample inconsistency.\nFurthermore, we design a curriculum learning approach that gradually increases\nthe influence of inconsistent signals during training to improve overall\nperformance. We evaluate our proposed method using public spontaneous BCI\ndataset. The experimental results confirm that our findings highlight the\nimportance of addressing sample dominance for achieving robust performance in\nspontaneous BCIs.",
            "author": [
                "Byeong-Hoo Lee",
                "Byoung-Hee Kwon",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07079v2",
                "http://arxiv.org/pdf/2311.07079v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07078v1",
            "title": "The Distribution of Sandpile Groups of Random Graphs with their Pairings",
            "updated": "2023-11-13T05:02:42Z",
            "published": "2023-11-13T05:02:42Z",
            "summary": "We determine the distribution of the sandpile group (also known as the\nJacobian) of the Erd\\H{o}s-R\\'{e}nyi random graph $G(n,q)$ along with its\ncanonical duality pairing as $n$ tends to infinity, fully resolving a\nconjecture from 2015 due to Clancy, Leake, and Payne and generalizing the\nresult by Wood on the groups. In particular, we show that a finite abelian\n$p$-group $G$ equipped with a perfect symmetric pairing $\\delta$ appears as the\nSylow $p$-part of the sandpile group and its pairing with frequency inversely\nproportional to $|G||\\mathrm{Aut}(G,\\delta)|$, where $\\mathrm{Aut}(G,\\delta)$\nis the set of automorphisms of $G$ preserving the pairing $\\delta$. While this\ndistribution is related to the Cohen-Lenstra distribution, the two\ndistributions are not the same on account of the additional algebraic data of\nthe pairing. The proof utilizes the moment method: we first compute a complete\nset of moments for our random variable (the average number of epimorphisms from\nour random object to a fixed object in the category of interest) and then show\nthe moments determine the distribution. To obtain the moments, we prove a\nuniversality result for the moments of cokernels of random symmetric integral\nmatrices whose dual groups are equipped with symmetric pairings that is strong\nenough to handle both the dependence in the diagonal entries and the additional\ndata of the pairing. We then apply results due to Sawin and Wood to show that\nthese moments determine a unique distribution.",
            "author": [
                "Eliot Hodges"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07078v1",
                "http://arxiv.org/pdf/2311.07078v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.NT",
                "math.PR",
                "05C80, 15B52, 60B20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07076v1",
            "title": "On the Discussion of Large Language Models: Symmetry of Agents and\n  Interplay with Prompts",
            "updated": "2023-11-13T04:56:48Z",
            "published": "2023-11-13T04:56:48Z",
            "summary": "Two ways has been discussed to unlock the reasoning capability of a large\nlanguage model. The first one is prompt engineering and the second one is to\ncombine the multiple inferences of large language models, or the multi-agent\ndiscussion. Theoretically, this paper justifies the multi-agent discussion\nmechanisms from the symmetry of agents. Empirically, this paper reports the\nempirical results of the interplay of prompts and discussion mechanisms,\nrevealing the empirical state-of-the-art performance of complex multi-agent\nmechanisms can be approached by carefully developed prompt engineering. This\npaper also proposes a scalable discussion mechanism based on conquer and merge,\nproviding a simple multi-agent discussion solution with simple prompts but\nstate-of-the-art performance.",
            "author": [
                "Qineng Wang",
                "Zihao Wang",
                "Ying Su",
                "Yangqiu Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07076v1",
                "http://arxiv.org/pdf/2311.07076v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07075v2",
            "title": "GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency\n  Learning",
            "updated": "2023-11-22T23:49:58Z",
            "published": "2023-11-13T04:48:33Z",
            "summary": "DeepFake detection is pivotal in personal privacy and public safety. With the\niterative advancement of DeepFake techniques, high-quality forged videos and\nimages are becoming increasingly deceptive. Prior research has seen numerous\nattempts by scholars to incorporate biometric features into the field of\nDeepFake detection. However, traditional biometric-based approaches tend to\nsegregate biometric features from general ones and freeze the biometric feature\nextractor. These approaches resulted in the exclusion of valuable general\nfeatures, potentially leading to a performance decline and, consequently, a\nfailure to fully exploit the potential of biometric information in assisting\nDeepFake detection. Moreover, insufficient attention has been dedicated to\nscrutinizing gaze authenticity within the realm of DeepFake detection in recent\nyears. In this paper, we introduce GazeForensics, an innovative DeepFake\ndetection method that utilizes gaze representation obtained from a 3D gaze\nestimation model to regularize the corresponding representation within our\nDeepFake detection model, while concurrently integrating general features to\nfurther enhance the performance of our model. Experiment results reveal that\nour proposed GazeForensics outperforms the current state-of-the-art methods.",
            "author": [
                "Qinlin He",
                "Chunlei Peng",
                "Decheng Liu",
                "Nannan Wang",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07075v2",
                "http://arxiv.org/pdf/2311.07075v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07073v2",
            "title": "Exposition on over-squashing problem on GNNs: Current Methods,\n  Benchmarks and Challenges",
            "updated": "2023-11-17T22:51:23Z",
            "published": "2023-11-13T04:40:13Z",
            "summary": "Graph-based message-passing neural networks (MPNNs) have achieved remarkable\nsuccess in both node and graph-level learning tasks. However, several\nidentified problems, including over-smoothing (OSM), limited expressive power,\nand over-squashing (OSQ), still limit the performance of MPNNs. In particular,\nOSQ serves as the latest identified problem, where MPNNs gradually lose their\nlearning accuracy when long-range dependencies between graph nodes are\nrequired. In this work, we provide an exposition on the OSQ problem by\nsummarizing different formulations of OSQ from current literature, as well as\nthe three different categories of approaches for addressing the OSQ problem. In\naddition, we also discuss the alignment between OSQ and expressive power and\nthe trade-off between OSQ and OSM. Furthermore, we summarize the empirical\nmethods leveraged from existing works to verify the efficiency of OSQ\nmitigation approaches, with illustrations of their computational complexities.\nLastly, we list some open questions that are of interest for further\nexploration of the OSQ problem along with potential directions from the best of\nour knowledge.",
            "author": [
                "Dai Shi",
                "Andi Han",
                "Lequan Lin",
                "Yi Guo",
                "Junbin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07073v2",
                "http://arxiv.org/pdf/2311.07073v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07070v1",
            "title": "Explain-then-Translate: An Analysis on Improving Program Translation\n  with Self-generated Explanations",
            "updated": "2023-11-13T04:28:49Z",
            "published": "2023-11-13T04:28:49Z",
            "summary": "This work explores the use of self-generated natural language explanations as\nan intermediate step for code-to-code translation with language models. Across\nthree types of explanations and 19 programming languages constructed from the\nMultiPL-E dataset, we find the explanations to be particularly effective in the\nzero-shot case, improving performance by 12% on average. Improvements with\nnatural language explanations are particularly pronounced on difficult\nprograms. We release our dataset, code, and canonical solutions in all 19\nlanguages.",
            "author": [
                "Zilu Tang",
                "Mayank Agarwal",
                "Alex Shypula",
                "Bailin Wang",
                "Derry Wijaya",
                "Jie Chen",
                "Yoon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07070v1",
                "http://arxiv.org/pdf/2311.07070v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07066v1",
            "title": "Context Consistency between Training and Testing in Simultaneous Machine\n  Translation",
            "updated": "2023-11-13T04:11:32Z",
            "published": "2023-11-13T04:11:32Z",
            "summary": "Simultaneous Machine Translation (SiMT) aims to yield a real-time partial\ntranslation with a monotonically growing the source-side context. However,\nthere is a counterintuitive phenomenon about the context usage between training\nand testing: e.g., the wait-k testing model consistently trained with wait-k is\nmuch worse than that model inconsistently trained with wait-k' (k' is not equal\nto k) in terms of translation quality. To this end, we first investigate the\nunderlying reasons behind this phenomenon and uncover the following two\nfactors: 1) the limited correlation between translation quality and training\n(cross-entropy) loss; 2) exposure bias between training and testing. Based on\nboth reasons, we then propose an effective training approach called context\nconsistency training accordingly, which makes consistent the context usage\nbetween training and testing by optimizing translation quality and latency as\nbi-objectives and exposing the predictions to the model during the training.\nThe experiments on three language pairs demonstrate our intuition: our system\nencouraging context consistency outperforms that existing systems with context\ninconsistency for the first time, with the help of our context consistency\ntraining approach.",
            "author": [
                "Meizhi Zhong",
                "Lemao Liu",
                "Kehai Chen",
                "Mingming Yang",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07066v1",
                "http://arxiv.org/pdf/2311.07066v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07064v1",
            "title": "PROPANE: Prompt design as an inverse problem",
            "updated": "2023-11-13T04:08:49Z",
            "published": "2023-11-13T04:08:49Z",
            "summary": "Carefully-designed prompts are key to inducing desired behavior in Large\nLanguage Models (LLMs). As a result, great effort has been dedicated to\nengineering prompts that guide LLMs toward particular behaviors. In this work,\nwe propose an automatic prompt optimization framework, PROPANE, which aims to\nfind a prompt that induces semantically similar outputs to a fixed set of\nexamples without user intervention. We further demonstrate that PROPANE can be\nused to (a) improve existing prompts, and (b) discover semantically obfuscated\nprompts that transfer between models.",
            "author": [
                "Rimon Melamed",
                "Lucas H. McCabe",
                "Tanay Wakhare",
                "Yejin Kim",
                "H. Howie Huang",
                "Enric Boix-Adsera"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07064v1",
                "http://arxiv.org/pdf/2311.07064v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07059v1",
            "title": "Application of deep learning methods to the study of magnetic phenomena",
            "updated": "2023-11-13T03:53:09Z",
            "published": "2023-11-13T03:53:09Z",
            "summary": "Nowadays, methods and techniques of Machine Learning and Deep Learning are\nbeing used in various scientific areas. They help to automatize calculations\nwithout losing in quality. In this paper the applying of convolutional neural\nnetwork was considered in frame of problems from statistical physics and\ncomputer simulation of magnetic films. In a frame of the first task, CNN was\nused to determine critical Curie point for Ising model on 2D square lattice.\nObtained results were compared with classical Monte-Carlo methods and exact\nsolution. Systems of various lattice sizes and the influence of the size effect\non the results' accuracy were considered. Also, authors considered the\nclassical two-dimensional Heisenberg model, a spin system with direct\nshort-range exchange, and studied of its competition with the\nDzyaloshinskii-Moriya interaction. A neural network was applied to the\nrecognition of Spiral (Sp), Spiral-skyrmion (SpSk) Skyrmion (Sk),\nSkyrmion-ferromagnetic (SkF) and Ferromagnetic (FM) phases of the Heisenberg\nspin system with magnetic skyrmions. The advantage of CNN's application over\nconventional methods for determination of skyrmion's phases was revealed.",
            "author": [
                "E. V. Vasiliev",
                "D. Yu. Kapitan",
                "A. O. Korol",
                "A. E. Rybin",
                "P. A. Ovchinnikov",
                "K. S. Soldatov",
                "Yu. A. Shevchenko",
                "A. G. Makarov",
                "V. Yu. Kapitan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07059v1",
                "http://arxiv.org/pdf/2311.07059v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "60-04",
                "F.1.1; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07052v1",
            "title": "Towards the Law of Capacity Gap in Distilling Language Models",
            "updated": "2023-11-13T03:36:18Z",
            "published": "2023-11-13T03:36:18Z",
            "summary": "Language model (LM) distillation is a trending area that aims to distil the\nknowledge resided in a large teacher LM to a small student one. While various\nmethods have been proposed to push the distillation to its limits, it is still\na pain distilling LMs when a large capacity gap is exhibited between the\nteacher and the student LMs. The pain is mainly resulted by the curse of\ncapacity gap, which describes that a larger teacher LM cannot always lead to a\nbetter student LM than one distilled from a smaller teacher LM due to the\naffect of capacity gap increment. That is, there is likely an optimal point\nyielding the best student LM along the scaling course of the teacher LM. Even\nworse, the curse of capacity gap can be only partly yet not fully lifted as\nindicated in previous studies.\n  However, the tale is not ever one-sided. Although a larger teacher LM has\nbetter performance than a smaller teacher LM, it is much more\nresource-demanding especially in the context of recent large LMs (LLMs).\nConsequently, instead of sticking to lifting the curse, leaving the curse as is\nshould be arguably fine. Even better, in this paper, we reveal that the optimal\ncapacity gap is almost consistent across different student scales and\narchitectures, fortunately turning the curse into the law of capacity gap. The\nlaw later guides us to distil a 3B student LM (termed MiniMA) from a 7B teacher\nLM (adapted LLaMA2-7B). MiniMA is demonstrated to yield a new\ncompute-performance pareto frontier among existing 3B LMs on commonly used\nbenchmarks, and its instruction-tuned version (termed MiniChat) outperforms a\nwide range of 3B competitors in GPT4 evaluation and could even compete with\nseveral 7B chat models.",
            "author": [
                "Chen Zhang",
                "Dawei Song",
                "Zheyu Ye",
                "Yan Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07052v1",
                "http://arxiv.org/pdf/2311.07052v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07044v1",
            "title": "$L_0$-Sampler: An $L_{0}$ Model Guided Volume Sampling for NeRF",
            "updated": "2023-11-13T03:05:16Z",
            "published": "2023-11-13T03:05:16Z",
            "summary": "Since being proposed, Neural Radiance Fields (NeRF) have achieved great\nsuccess in related tasks, mainly adopting the hierarchical volume sampling\n(HVS) strategy for volume rendering. However, the HVS of NeRF approximates\ndistributions using piecewise constant functions, which provides a relatively\nrough estimation. Based on the observation that a well-trained weight function\n$w(t)$ and the $L_0$ distance between points and the surface have very high\nsimilarity, we propose $L_0$-Sampler by incorporating the $L_0$ model into\n$w(t)$ to guide the sampling process. Specifically, we propose to use piecewise\nexponential functions rather than piecewise constant functions for\ninterpolation, which can not only approximate quasi-$L_0$ weight distributions\nalong rays quite well but also can be easily implemented with few lines of code\nwithout additional computational burden. Stable performance improvements can be\nachieved by applying $L_0$-Sampler to NeRF and its related tasks like 3D\nreconstruction. Code is available at https://ustc3dv.github.io/L0-Sampler/ .",
            "author": [
                "Liangchen Li",
                "Juyong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07044v1",
                "http://arxiv.org/pdf/2311.07044v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07042v2",
            "title": "Open-Vocabulary Video Anomaly Detection",
            "updated": "2023-11-15T02:17:52Z",
            "published": "2023-11-13T02:54:17Z",
            "summary": "Video anomaly detection (VAD) with weak supervision has achieved remarkable\nperformance in utilizing video-level labels to discriminate whether a video\nframe is normal or abnormal. However, current approaches are inherently limited\nto a closed-set setting and may struggle in open-world applications where there\ncan be anomaly categories in the test data unseen during training. A few recent\nstudies attempt to tackle a more realistic setting, open-set VAD, which aims to\ndetect unseen anomalies given seen anomalies and normal videos. However, such a\nsetting focuses on predicting frame anomaly scores, having no ability to\nrecognize the specific categories of anomalies, despite the fact that this\nability is essential for building more informed video surveillance systems.\nThis paper takes a step further and explores open-vocabulary video anomaly\ndetection (OVVAD), in which we aim to leverage pre-trained large models to\ndetect and categorize seen and unseen anomalies. To this end, we propose a\nmodel that decouples OVVAD into two mutually complementary tasks --\nclass-agnostic detection and class-specific classification -- and jointly\noptimizes both tasks. Particularly, we devise a semantic knowledge injection\nmodule to introduce semantic knowledge from large language models for the\ndetection task, and design a novel anomaly synthesis module to generate pseudo\nunseen anomaly videos with the help of large vision generation models for the\nclassification task. These semantic knowledge and synthesis anomalies\nsubstantially extend our model's capability in detecting and categorizing a\nvariety of seen and unseen anomalies. Extensive experiments on three\nwidely-used benchmarks demonstrate our model achieves state-of-the-art\nperformance on OVVAD task.",
            "author": [
                "Peng Wu",
                "Xuerong Zhou",
                "Guansong Pang",
                "Yujia Sun",
                "Jing Liu",
                "Peng Wang",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07042v2",
                "http://arxiv.org/pdf/2311.07042v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07622v2",
            "title": "Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed\n  Image Retrieval",
            "updated": "2023-11-15T04:13:37Z",
            "published": "2023-11-13T02:49:57Z",
            "summary": "Zero-shot composed image retrieval (ZS-CIR), which aims to retrieve a target\nimage based on textual modifications to a reference image without triplet\nlabeling, has gained more and more attention. Current ZS-CIR research mainly\nrelies on two unlabeled pre-trained models: the vision-language model, e.g.,\nCLIP, and the Pic2Word/textual inversion model. However, the pre-trained models\nand CIR tasks have substantial discrepancies, where the pre-trained models\nlearn the similarities between vision and language but CIR aims to learn the\nmodifications of the image guided by text. In this paper, we introduce a novel\nunlabeled and pre-trained masked tuning approach to reduce the gap between the\npre-trained model and the downstream CIR task. We first reformulate the\npre-trained vision-language contrastive learning as the CIR task, where we\nrandomly mask input image patches to generate $\\langle$masked image, text,\nimage$\\rangle$ triple from an image-text pair. Then, we propose a masked\ntuning, which uses the text and the masked image to learn the modifications of\nthe original image. With such a simple design, it can learn to capture\nfine-grained text-guided modifications. Extensive experimental results\ndemonstrate the significant superiority of our approach over the baseline\nmodels on three ZS-CIR datasets, including FashionIQ, CIRR, and CIRCO.",
            "author": [
                "Junyang Chen",
                "Hanjiang Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07622v2",
                "http://arxiv.org/pdf/2311.07622v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07039v1",
            "title": "Time-Optimal Control for High-Order Chain-of-Integrators Systems with\n  Full State Constraints and Arbitrary Terminal States",
            "updated": "2023-11-13T02:42:43Z",
            "published": "2023-11-13T02:42:43Z",
            "summary": "Time-optimal control for high-order chain-of-integrators systems with full\nstate constraints and arbitrary given terminal states remains a challenging\nproblem in the optimal control theory domain, yet to be resolved. To enhance\nfurther comprehension of the problem, this paper establishes a novel notation\nsystem and theoretical framework, successfully providing the switching manifold\nfor high-order problems in the form of switching law. Through deriving\nproperties of switching laws on signs and dimension, this paper proposes a\ndefinite condition for time-optimal control. Guided by the developed theory, a\ntrajectory planning method named the manifold-intercept method (MIM) is\ndeveloped. The proposed MIM can plan time-optimal jerk-limited trajectories\nwith full state constraints, and can also plan near-optimal higher-order\ntrajectories with negligible extra motion time. Numerical results indicate that\nthe proposed MIM outperforms all baselines in computational time, computational\naccuracy, and trajectory quality by a large gap.",
            "author": [
                "Yunan Wang",
                "Chuxiong Hu",
                "Zeyang Li",
                "Shize Lin",
                "Suqin He",
                "Ze Wang",
                "Yu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07039v1",
                "http://arxiv.org/pdf/2311.07039v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07037v1",
            "title": "Phonological Level wav2vec2-based Mispronunciation Detection and\n  Diagnosis Method",
            "updated": "2023-11-13T02:41:41Z",
            "published": "2023-11-13T02:41:41Z",
            "summary": "The automatic identification and analysis of pronunciation errors, known as\nMispronunciation Detection and Diagnosis (MDD) plays a crucial role in Computer\nAided Pronunciation Learning (CAPL) tools such as Second-Language (L2) learning\nor speech therapy applications. Existing MDD methods relying on analysing\nphonemes can only detect categorical errors of phonemes that have an adequate\namount of training data to be modelled. With the unpredictable nature of the\npronunciation errors of non-native or disordered speakers and the scarcity of\ntraining datasets, it is unfeasible to model all types of mispronunciations.\nMoreover, phoneme-level MDD approaches have a limited ability to provide\ndetailed diagnostic information about the error made. In this paper, we propose\na low-level MDD approach based on the detection of speech attribute features.\nSpeech attribute features break down phoneme production into elementary\ncomponents that are directly related to the articulatory system leading to more\nformative feedback to the learner. We further propose a multi-label variant of\nthe Connectionist Temporal Classification (CTC) approach to jointly model the\nnon-mutually exclusive speech attributes using a single model. The pre-trained\nwav2vec2 model was employed as a core model for the speech attribute detector.\nThe proposed method was applied to L2 speech corpora collected from English\nlearners from different native languages. The proposed speech attribute MDD\nmethod was further compared to the traditional phoneme-level MDD and achieved a\nsignificantly lower False Acceptance Rate (FAR), False Rejection Rate (FRR),\nand Diagnostic Error Rate (DER) over all speech attributes compared to the\nphoneme-level equivalent.",
            "author": [
                "Mostafa Shahin",
                "Julien Epps",
                "Beena Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07037v1",
                "http://arxiv.org/pdf/2311.07037v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07035v1",
            "title": "ContHutch++: Stochastic trace estimation for implicit integral operators",
            "updated": "2023-11-13T02:36:41Z",
            "published": "2023-11-13T02:36:41Z",
            "summary": "Hutchinson's estimator is a randomized algorithm that computes an\n$\\epsilon$-approximation to the trace of any positive semidefinite matrix using\n$\\mathcal{O}(1/\\epsilon^2)$ matrix-vector products. An improvement of\nHutchinson's estimator, known as Hutch++, only requires\n$\\mathcal{O}(1/\\epsilon)$ matrix-vector products. In this paper, we propose a\ngeneralization of Hutch++, which we call ContHutch++, that uses\noperator-function products to efficiently estimate the trace of any trace-class\nintegral operator. Our ContHutch++ estimates avoid spectral artifacts\nintroduced by discretization and are accompanied by rigorous high-probability\nerror bounds. We use ContHutch++ to derive a new high-order accurate algorithm\nfor quantum density-of-states and also show how it can estimate electromagnetic\nfields induced by incoherent sources.",
            "author": [
                "Jennifer Zvonek",
                "Andrew Horning",
                "Alex Townsend"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07035v1",
                "http://arxiv.org/pdf/2311.07035v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07033v1",
            "title": "TTMFN: Two-stream Transformer-based Multimodal Fusion Network for\n  Survival Prediction",
            "updated": "2023-11-13T02:31:20Z",
            "published": "2023-11-13T02:31:20Z",
            "summary": "Survival prediction plays a crucial role in assisting clinicians with the\ndevelopment of cancer treatment protocols. Recent evidence shows that\nmultimodal data can help in the diagnosis of cancer disease and improve\nsurvival prediction. Currently, deep learning-based approaches have experienced\nincreasing success in survival prediction by integrating pathological images\nand gene expression data. However, most existing approaches overlook the\nintra-modality latent information and the complex inter-modality correlations.\nFurthermore, existing modalities do not fully exploit the immense\nrepresentational capabilities of neural networks for feature aggregation and\ndisregard the importance of relationships between features. Therefore, it is\nhighly recommended to address these issues in order to enhance the prediction\nperformance by proposing a novel deep learning-based method. We propose a novel\nframework named Two-stream Transformer-based Multimodal Fusion Network for\nsurvival prediction (TTMFN), which integrates pathological images and gene\nexpression data. In TTMFN, we present a two-stream multimodal co-attention\ntransformer module to take full advantage of the complex relationships between\ndifferent modalities and the potential connections within the modalities.\nAdditionally, we develop a multi-head attention pooling approach to effectively\naggregate the feature representations of the two modalities. The experiment\nresults on four datasets from The Cancer Genome Atlas demonstrate that TTMFN\ncan achieve the best performance or competitive results compared to the\nstate-of-the-art methods in predicting the overall survival of patients.",
            "author": [
                "Ruiquan Ge",
                "Xiangyang Hu",
                "Rungen Huang",
                "Gangyong Jia",
                "Yaqi Wang",
                "Renshu Gu",
                "Changmiao Wang",
                "Elazab Ahmed",
                "Linyan Wang",
                "Juan Ye",
                "Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07033v1",
                "http://arxiv.org/pdf/2311.07033v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07032v1",
            "title": "ExpNote: Black-box Large Language Models are Better Task Solvers with\n  Experience Notebook",
            "updated": "2023-11-13T02:31:16Z",
            "published": "2023-11-13T02:31:16Z",
            "summary": "Black-box Large Language Models (LLMs) have shown great power in solving\nvarious tasks and are considered general problem solvers. However, LLMs still\nfail in many specific tasks although understand the task instruction. In this\npaper, we focus on the problem of boosting the ability of black-box LLMs to\nsolve downstream tasks. We propose ExpNote, an automated framework to help LLMs\nbetter adapt to unfamiliar tasks through reflecting and noting experiences from\ntraining data and retrieving them from external memory during testing. We\nevaluate ExpNote on multiple tasks and the experimental results demonstrate\nthat the proposed method significantly improves the performance of black-box\nLLMs. The data and code are available at\nhttps://github.com/forangel2014/ExpNote",
            "author": [
                "Wangtao Sun",
                "Xuanqing Yu",
                "Shizhu He",
                "Jun Zhao",
                "Kang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07032v1",
                "http://arxiv.org/pdf/2311.07032v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07027v1",
            "title": "Robust softmax aggregation on blockchain based federated learning with\n  convergence guarantee",
            "updated": "2023-11-13T02:25:52Z",
            "published": "2023-11-13T02:25:52Z",
            "summary": "Blockchain based federated learning is a distributed learning scheme that\nallows model training without participants sharing their local data sets, where\nthe blockchain components eliminate the need for a trusted central server\ncompared to traditional Federated Learning algorithms. In this paper we propose\na softmax aggregation blockchain based federated learning framework. First, we\npropose a new blockchain based federated learning architecture that utilizes\nthe well-tested proof-of-stake consensus mechanism on an existing blockchain\nnetwork to select validators and miners to aggregate the participants' updates\nand compute the blocks. Second, to ensure the robustness of the aggregation\nprocess, we design a novel softmax aggregation method based on approximated\npopulation loss values that relies on our specific blockchain architecture.\nAdditionally, we show our softmax aggregation technique converges to the global\nminimum in the convex setting with non-restricting assumptions. Our\ncomprehensive experiments show that our framework outperforms existing robust\naggregation algorithms in various settings by large margins.",
            "author": [
                "Huiyu Wu",
                "Diego Klabjan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07027v1",
                "http://arxiv.org/pdf/2311.07027v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07025v1",
            "title": "Embarassingly Simple Dataset Distillation",
            "updated": "2023-11-13T02:14:54Z",
            "published": "2023-11-13T02:14:54Z",
            "summary": "Dataset distillation extracts a small set of synthetic training samples from\na large dataset with the goal of achieving competitive performance on test data\nwhen trained on this sample. In this work, we tackle dataset distillation at\nits core by treating it directly as a bilevel optimization problem.\nRe-examining the foundational back-propagation through time method, we study\nthe pronounced variance in the gradients, computational burden, and long-term\ndependencies. We introduce an improved method: Random Truncated Backpropagation\nThrough Time (RaT-BPTT) to address them. RaT-BPTT incorporates a truncation\ncoupled with a random window, effectively stabilizing the gradients and\nspeeding up the optimization while covering long dependencies. This allows us\nto establish new state-of-the-art for a variety of standard dataset benchmarks.\nA deeper dive into the nature of distilled data unveils pronounced\nintercorrelation. In particular, subsets of distilled datasets tend to exhibit\nmuch worse performance than directly distilled smaller datasets of the same\nsize. Leveraging RaT-BPTT, we devise a boosting mechanism that generates\ndistilled datasets that contain subsets with near optimal performance across\ndifferent data budgets.",
            "author": [
                "Yunzhen Feng",
                "Ramakrishna Vedantam",
                "Julia Kempe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07025v1",
                "http://arxiv.org/pdf/2311.07025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07621v1",
            "title": "To Transformers and Beyond: Large Language Models for the Genome",
            "updated": "2023-11-13T02:13:58Z",
            "published": "2023-11-13T02:13:58Z",
            "summary": "In the rapidly evolving landscape of genomics, deep learning has emerged as a\nuseful tool for tackling complex computational challenges. This review focuses\non the transformative role of Large Language Models (LLMs), which are mostly\nbased on the transformer architecture, in genomics. Building on the foundation\nof traditional convolutional neural networks and recurrent neural networks, we\nexplore both the strengths and limitations of transformers and other LLMs for\ngenomics. Additionally, we contemplate the future of genomic modeling beyond\nthe transformer architecture based on current trends in research. The paper\naims to serve as a guide for computational biologists and computer scientists\ninterested in LLMs for genomic data. We hope the paper can also serve as an\neducational introduction and discussion for biologists to a fundamental shift\nin how we will be analyzing genomic data in the future.",
            "author": [
                "Micaela E. Consens",
                "Cameron Dufault",
                "Michael Wainberg",
                "Duncan Forster",
                "Mehran Karimzadeh",
                "Hani Goodarzi",
                "Fabian J. Theis",
                "Alan Moses",
                "Bo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07621v1",
                "http://arxiv.org/pdf/2311.07621v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07022v1",
            "title": "ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in\n  Video-Language Models",
            "updated": "2023-11-13T02:13:13Z",
            "published": "2023-11-13T02:13:13Z",
            "summary": "With the ever-increasing popularity of pretrained Video-Language Models\n(VidLMs), there is a pressing need to develop robust evaluation methodologies\nthat delve deeper into their visio-linguistic capabilities. To address this\nchallenge, we present ViLMA (Video Language Model Assessment), a task-agnostic\nbenchmark that places the assessment of fine-grained capabilities of these\nmodels on a firm footing. Task-based evaluations, while valuable, fail to\ncapture the complexities and specific temporal aspects of moving images that\nVidLMs need to process. Through carefully curated counterfactuals, ViLMA offers\na controlled evaluation suite that sheds light on the true potential of these\nmodels, as well as their performance gaps compared to human-level\nunderstanding. ViLMA also includes proficiency tests, which assess basic\ncapabilities deemed essential to solving the main counterfactual tests. We show\nthat current VidLMs' grounding abilities are no better than those of\nvision-language models which use static images. This is especially striking\nonce the performance on proficiency tests is factored in. Our benchmark serves\nas a catalyst for future research on VidLMs, helping to highlight areas that\nstill need to be explored.",
            "author": [
                "Ilker Kesen",
                "Andrea Pedrotti",
                "Mustafa Dogan",
                "Michele Cafagna",
                "Emre Can Acikgoz",
                "Letitia Parcalabescu",
                "Iacer Calixto",
                "Anette Frank",
                "Albert Gatt",
                "Aykut Erdem",
                "Erkut Erdem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07022v1",
                "http://arxiv.org/pdf/2311.07022v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07017v1",
            "title": "Topologically Protected Metastable States in Classical Dynamics",
            "updated": "2023-11-13T02:01:41Z",
            "published": "2023-11-13T02:01:41Z",
            "summary": "We propose that the domain walls formed in a classical Ginzburg-Landau model\ncan exhibit topologically stable but thermodynamically metastable states. This\nproposal relies on Allen-Cahn's assertion that the velocity of domain wall at\nsome point is proportional to the mean curvature at that point. From this\nassertion we speculate that domain wall resembles a rubber band that can winds\nthe background geometry in a nontrivial way and can exist permanently. We\nnumerically verify our proposal in two and three spatial dimensions by using\nperiodic boundary conditions as well as Neumann boundary conditions. We find\nthat there are always possibilities to form topologically stable domain walls\nin the final equilibrium states. However, from the aspects of thermodynamics\nthese topologically nontrivial domain walls have higher free energies and are\nthermodynamically metastable. These metastable states that are protected by\ntopology could potentially serve as storage media in the computer and\ninformation technology industry.",
            "author": [
                "Han-Qing Shi",
                "Tian-Chi Ma",
                "Hai-Qing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07017v1",
                "http://arxiv.org/pdf/2311.07017v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07016v1",
            "title": "Maximum Flow on Highly Dynamic Graphs",
            "updated": "2023-11-13T02:00:22Z",
            "published": "2023-11-13T02:00:22Z",
            "summary": "Recent advances in dynamic graph processing have enabled the analysis of\nhighly dynamic graphs with change at rates as high as millions of edge changes\nper second. Solutions in this domain, however, have been demonstrated only for\nrelatively simple algorithms like PageRank, breadth-first search, and connected\ncomponents. Expanding beyond this, we explore the maximum flow problem, a\nfundamental, yet more complex problem, in graph analytics. We propose a novel,\ndistributed algorithm for max-flow on dynamic graphs, and implement it on top\nof an asynchronous vertex-centric abstraction. We show that our algorithm can\nprocess both additions and deletions of vertices and edges efficiently at scale\non fast-evolving graphs, and provide a comprehensive analysis by evaluating, in\naddition to throughput, two criteria that are important when applied to\nreal-world problems: result latency and solution stability.",
            "author": [
                "Juntong Luo",
                "Scott Sallinen",
                "Matei Ripeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07016v1",
                "http://arxiv.org/pdf/2311.07016v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07015v1",
            "title": "QudCom: Towards Quantum Compilation for Qudit Systems",
            "updated": "2023-11-13T01:58:48Z",
            "published": "2023-11-13T01:58:48Z",
            "summary": "Qudit-based quantum computation offers unique advantages over qubit-based\nsystems in terms of noise mitigation capabilities as well as algorithmic\ncomplexity improvements. However, the software ecosystem for multi-state\nquantum systems is severely limited. In this paper, we highlight a quantum\nworkflow for describing and compiling qudit systems. We investigate the design\nand implementation of a quantum compiler for qudit systems. We also explore\nseveral key theoretical properties of qudit computing as well as efficient\noptimization techniques. Finally, we provide demonstrations using physical\nquantum computers as well as simulations of the proposed quantum toolchain.",
            "author": [
                "Daniel Volya",
                "Prabhat Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07015v1",
                "http://arxiv.org/pdf/2311.07015v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07014v1",
            "title": "Teach me with a Whisper: Enhancing Large Language Models for Analyzing\n  Spoken Transcripts using Speech Embeddings",
            "updated": "2023-11-13T01:53:12Z",
            "published": "2023-11-13T01:53:12Z",
            "summary": "Speech data has rich acoustic and paralinguistic information with important\ncues for understanding a speaker's tone, emotion, and intent, yet traditional\nlarge language models such as BERT do not incorporate this information. There\nhas been an increased interest in multi-modal language models leveraging audio\nand/or visual information and text. However, current multi-modal language\nmodels require both text and audio/visual data streams during inference/test\ntime. In this work, we propose a methodology for training language models\nleveraging spoken language audio data but without requiring the audio stream\nduring prediction time. This leads to an improved language model for analyzing\nspoken transcripts while avoiding an audio processing overhead at test time. We\nachieve this via an audio-language knowledge distillation framework, where we\ntransfer acoustic and paralinguistic information from a pre-trained speech\nembedding (OpenAI Whisper) teacher model to help train a student language model\non an audio-text dataset. In our experiments, the student model achieves\nconsistent improvement over traditional language models on tasks analyzing\nspoken transcripts.",
            "author": [
                "Fatema Hasan",
                "Yulong Li",
                "James Foulds",
                "Shimei Pan",
                "Bishwaranjan Bhattacharjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07014v1",
                "http://arxiv.org/pdf/2311.07014v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07006v1",
            "title": "Context-dependent Instruction Tuning for Dialogue Response Generation",
            "updated": "2023-11-13T01:25:30Z",
            "published": "2023-11-13T01:25:30Z",
            "summary": "Recent language models have achieved impressive performance in natural\nlanguage tasks by incorporating instructions with task input during\nfine-tuning. Since all samples in the same natural language task can be\nexplained with the same task instructions, many instruction datasets only\nprovide a few instructions for the entire task, without considering the input\nof each example in the task. However, this approach becomes ineffective in\ncomplex multi-turn dialogue generation tasks, where the input varies highly\nwith each turn as the dialogue context changes, so that simple task\ninstructions cannot improve the generation performance. To address this\nlimitation, we introduce a context-based instruction fine-tuning framework for\neach multi-turn dialogue which generates both responses and instructions based\non the previous context as input. During the evaluation, the model generates\ninstructions based on the previous context to self-guide the response. The\nproposed framework produces comparable or even outstanding results compared to\nthe baselines by aligning instructions to the input during fine-tuning with the\ninstructions in quantitative evaluations on dialogue benchmark datasets with\nreduced computation budget.",
            "author": [
                "Jin Myung Kwak",
                "Minseon Kim",
                "Sung Ju Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07006v1",
                "http://arxiv.org/pdf/2311.07006v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07004v1",
            "title": "Improved Task Scheduling for Virtual Machines in the Cloud based on the\n  Gravitational Search Algorithm",
            "updated": "2023-11-13T01:13:21Z",
            "published": "2023-11-13T01:13:21Z",
            "summary": "The rapid and convenient provision of the available computing resources is a\ncrucial requirement in modern cloud computing environments. However, if only\nthe execution time is taken into account when the resources are scheduled, it\ncould lead to imbalanced workloads as well as to significant under-utilisation\nof the involved Virtual Machines (VMs). In the present work a novel task\nscheduling scheme is introduced, which is based on the proper adaptation of a\nmodern and quite effective evolutionary optimization method, the Gravitational\nSearch Algorithm (GSA). The proposed scheme aims at optimizing the entire\nscheduling procedure, in terms of both the tasks execution time and the system\n(VMs) resource utilisation. Moreover, the fitness function was properly\nselected considering both the above factors in an appropriately weighted\nfunction in order to obtain better results for large inputs. Sufficient\nsimulation experiments show the efficiency of the proposed scheme, as well as\nits excellence over related approaches of the bibliography, with similar\nobjectives.",
            "author": [
                "Basilis Mamalis",
                "Marios Perlitis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07004v1",
                "http://arxiv.org/pdf/2311.07004v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07002v1",
            "title": "PICS in Pics: Physics Informed Contour Selection for Rapid Image\n  Segmentation",
            "updated": "2023-11-13T01:03:19Z",
            "published": "2023-11-13T01:03:19Z",
            "summary": "Effective training of deep image segmentation models is challenging due to\nthe need for abundant, high-quality annotations. Generating annotations is\nlaborious and time-consuming for human experts, especially in medical image\nsegmentation. To facilitate image annotation, we introduce Physics Informed\nContour Selection (PICS) - an interpretable, physics-informed algorithm for\nrapid image segmentation without relying on labeled data. PICS draws\ninspiration from physics-informed neural networks (PINNs) and an active contour\nmodel called snake. It is fast and computationally lightweight because it\nemploys cubic splines instead of a deep neural network as a basis function. Its\ntraining parameters are physically interpretable because they directly\nrepresent control knots of the segmentation curve. Traditional snakes involve\nminimization of the edge-based loss functionals by deriving the Euler-Lagrange\nequation followed by its numerical solution. However, PICS directly minimizes\nthe loss functional, bypassing the Euler Lagrange equations. It is the first\nsnake variant to minimize a region-based loss function instead of traditional\nedge-based loss functions. PICS uniquely models the three-dimensional (3D)\nsegmentation process with an unsteady partial differential equation (PDE),\nwhich allows accelerated segmentation via transfer learning. To demonstrate its\neffectiveness, we apply PICS for 3D segmentation of the left ventricle on a\npublicly available cardiac dataset. While doing so, we also introduce a new\nconvexity-preserving loss term that encodes the shape information of the left\nventricle to enhance PICS's segmentation quality. Overall, PICS presents\nseveral novelties in network architecture, transfer learning, and\nphysics-inspired losses for image segmentation, thereby showing promising\noutcomes and potential for further refinement.",
            "author": [
                "Vikas Dwivedi",
                "Balaji Srinivasan",
                "Ganapathy Krishnamurthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07002v1",
                "http://arxiv.org/pdf/2311.07002v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06999v1",
            "title": "Quantum and classical query complexities of functions of matrices",
            "updated": "2023-11-13T00:45:41Z",
            "published": "2023-11-13T00:45:41Z",
            "summary": "Let $A$ be a sparse Hermitian matrix, $f(x)$ be a univariate function, and\n$i, j$ be two indices. In this work, we investigate the query complexity of\napproximating $\\bra{i} f(A) \\ket{j}$. We show that for any continuous function\n$f(x):[-1,1]\\rightarrow [-1,1]$, the quantum query complexity of computing\n$\\bra{i} f(A) \\ket{j}\\pm \\varepsilon/4$ is lower bounded by\n$\\Omega(\\widetilde{\\deg}_\\varepsilon(f))$. The upper bound is at most quadratic\nin $\\widetilde{\\deg}_\\varepsilon(f)$ and is linear in\n$\\widetilde{\\deg}_\\varepsilon(f)$ under certain mild assumptions on $A$. Here\nthe approximate degree $\\widetilde{\\deg}_\\varepsilon(f)$ is the minimum degree\nsuch that there is a polynomial of that degree approximating $f$ up to additive\nerror $\\varepsilon$ in the interval $[-1,1]$. We also show that the classical\nquery complexity is lower bounded by\n$\\widetilde{\\Omega}(2^{\\widetilde{\\deg}_{2\\varepsilon}(f)/6})$. Our results\nshow that the quantum and classical separation is exponential for any\ncontinuous function of sparse Hermitian matrices, and also imply the optimality\nof implementing smooth functions of sparse Hermitian matrices by quantum\nsingular value transformation. The main techniques we used are the dual\npolynomial method for functions over the reals, linear semi-infinite\nprogramming, and tridiagonal matrices.",
            "author": [
                "Ashley Montanaro",
                "Changpeng Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06999v1",
                "http://arxiv.org/pdf/2311.06999v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06995v1",
            "title": "Scalable Delivery of Scalable Libraries and Tools: How ECP Delivered a\n  Software Ecosystem for Exascale and Beyond",
            "updated": "2023-11-13T00:30:43Z",
            "published": "2023-11-13T00:30:43Z",
            "summary": "The Exascale Computing Project (ECP) was one of the largest open-source\nscientific software development projects ever. It supported approximately 1,000\nstaff from US Department of Energy laboratories, and university and industry\npartners. About 250 staff contributed to 70 scientific libraries and tools to\nsupport applications on multiple exascale computing systems that were also\nunder development.\n  Funded as a construction project, ECP adopted an earned-value management\nsystem, based on milestones. and a key performance parameter system based, in\npart, on integrations. With accelerated delivery schedules and significant\nproject risk, we also emphasized software quality using community policies,\nautomated testing, and continuous integration. Software Development Kit teams\nprovided cross-team collaboration. Products were delivered via E4S, a curated\nportfolio of libraries and tools.\n  In this paper, we discuss the organizational and management elements that\nenabled the efficient and effective delivery of ECP libraries and tools,\nlessons learned and next steps.",
            "author": [
                "Michael A. Heroux"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06995v1",
                "http://arxiv.org/pdf/2311.06995v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06990v1",
            "title": "Red Giant Rotational Inversion Kernels Need Nonlinear Surface\n  Corrections",
            "updated": "2023-11-13T00:03:57Z",
            "published": "2023-11-13T00:03:57Z",
            "summary": "Asteroseismology is our only means of measuring stellar rotation in their\ninteriors, rather than at their surfaces. Some techniques for measurements of\nthis kind -- \"rotational inversions\" -- require the shapes of linear response\nkernels computed from reference stellar models to be representative of those in\nthe stars they are intended to match. This is not the case in evolved stars\nexhibiting gravitoacoustic mixed modes: we show that the action of the\nasteroseismic surface term -- systematic errors in the modelling of\nnear-surface layers -- changes the shapes of their inversion kernels.\nCorrections for the surface term are not ordinarily considered necessary for\nrotational inversions. We show how this may have caused previous estimates of\nred-giant envelope rotation rates from mixed-mode asteroseismic inversions to\nhave been unintentionally contaminated by core rotation as a result, with\nerrors comparable to the entire reported estimates. We derive a mitigation\nprocedure for this hitherto unaccounted systematic error, and demonstrate its\nviability and effectiveness. We recommend this mitigation be applied when\nrevising existing rotational inversions. Finally, we discuss both the prospects\nfor applying such mitigation to the harder problem of inversions for stellar\nstructure (rather than rotation), as well as the broader implications of this\nsystematic error with regards to the longstanding problem of internal angular\nmomentum transport.",
            "author": [
                "J. M. Joel Ong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06990v1",
                "http://arxiv.org/pdf/2311.06990v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06985v1",
            "title": "SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions\n  by Themselves",
            "updated": "2023-11-12T23:14:43Z",
            "published": "2023-11-12T23:14:43Z",
            "summary": "Large language models (LLMs) can generate intermediate reasoning steps. To\nelicit the reliable reasoning, the common practice is to employ few-shot\nchain-of-thought prompting, where several in-context demonstrations for\nreasoning are prepended to the question. However, such chain-of-thought\nexamples are expensive to craft, especially for professional domains, and can\nhave high variance depending on human annotators. Therefore, this work\ninvestigates whether LLMs can teach themselves to reason without human-crafted\ndemonstrations. We propose SELF-EXPLAIN to generate CoT examples by LLMs\ninspired by \"encoding specificity\" in human memory retrieval. We find using\nself-explanations makes LLMs more confident, more calibrated and less biased\nwhen answering complex questions. Moreover, we find prompting with\nself-explanations can even significantly outperform using human-crafted CoTs on\nseveral complex question answering dataset.",
            "author": [
                "Jiachen Zhao",
                "Zonghai Yao",
                "Zhichao Yang",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06985v1",
                "http://arxiv.org/pdf/2311.06985v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06978v1",
            "title": "Augmented Bridge Matching",
            "updated": "2023-11-12T22:42:34Z",
            "published": "2023-11-12T22:42:34Z",
            "summary": "Flow and bridge matching are a novel class of processes which encompass\ndiffusion models. One of the main aspect of their increased flexibility is that\nthese models can interpolate between arbitrary data distributions i.e. they\ngeneralize beyond generative modeling and can be applied to learning stochastic\n(and deterministic) processes of arbitrary transfer tasks between two given\ndistributions. In this paper, we highlight that while flow and bridge matching\nprocesses preserve the information of the marginal distributions, they do\n\\emph{not} necessarily preserve the coupling information unless additional,\nstronger optimality conditions are met. This can be problematic if one aims at\npreserving the original empirical pairing. We show that a simple modification\nof the matching process recovers this coupling by augmenting the velocity field\n(or drift) with the information of the initial sample point. Doing so, we lose\nthe Markovian property of the process but preserve the coupling information\nbetween distributions. We illustrate the efficiency of our augmentation in\nlearning mixture of image translation tasks.",
            "author": [
                "Valentin De Bortoli",
                "Guan-Horng Liu",
                "Tianrong Chen",
                "Evangelos A. Theodorou",
                "Weilie Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06978v1",
                "http://arxiv.org/pdf/2311.06978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06977v1",
            "title": "High-precision scattering amplitudes for LHC phenomenology",
            "updated": "2023-11-12T22:37:18Z",
            "published": "2023-11-12T22:37:18Z",
            "summary": "In this work, we consider scattering amplitudes relevant for high-precision\nLarge Hadron Collider (LHC) phenomenology. We analyse the general structure of\namplitudes, and we review state-of-the-art methods for computing them. We\ndiscuss advantages and shortcomings of these methods, and we point out the\nbottlenecks in modern amplitude computations. As a practical illustration, we\npresent frontier applications relevant for multi-loop multi-scale processes. We\ncompute the helicity amplitudes for diphoton production in gluon fusion and\nphoton+jet production in proton scattering in three-loop massless Quantum\nChromodynamics (QCD). We have adopted a new projector-based prescription to\ncompute helicity amplitudes in the 't Hooft-Veltman scheme. We also rederived\nthe minimal set of independent Feynman integrals for this problem using the\ndifferential equations method, and we confirmed their intricate analytic\nproperties. By employing modern methods for integral reduction, we provide the\nfinal results in a compact form, which is appropriate for efficient numerical\nevaluation. Beyond QCD, we have computed the two-loop mixed QCD-electroweak\namplitudes for Z+jet production in proton scattering in light-quark-initiated\nchannels, without closed fermion loops. This process provides important insight\ninto the high-precision studies of the Standard Model, as well as into Dark\nMatter searches at the LHC. We have employed a numerical approach based on\nhigh-precision evaluation of Feynman integrals with the modern Auxiliary Mass\nFlow method. The obtained numerical results in all relevant partonic channels\nare evaluated on a two-dimensional grid appropriate for further\nphenomenological applications.",
            "author": [
                "Piotr Bargiela"
            ],
            "link": [
                "http://dx.doi.org/10.5287/ora-5rqgkyeje",
                "http://arxiv.org/abs/2311.06977v1",
                "http://arxiv.org/pdf/2311.06977v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06976v1",
            "title": "CD-COCO: A Versatile Complex Distorted COCO Database for\n  Scene-Context-Aware Computer Vision",
            "updated": "2023-11-12T22:28:19Z",
            "published": "2023-11-12T22:28:19Z",
            "summary": "The recent development of deep learning methods applied to vision has enabled\ntheir increasing integration into real-world applications to perform complex\nComputer Vision (CV) tasks. However, image acquisition conditions have a major\nimpact on the performance of high-level image processing. A possible solution\nto overcome these limitations is to artificially augment the training databases\nor to design deep learning models that are robust to signal distortions. We opt\nhere for the first solution by enriching the database with complex and\nrealistic distortions which were ignored until now in the existing databases.\nTo this end, we built a new versatile database derived from the well-known\nMS-COCO database to which we applied local and global photo-realistic\ndistortions. These new local distortions are generated by considering the scene\ncontext of the images that guarantees a high level of photo-realism.\nDistortions are generated by exploiting the depth information of the objects in\nthe scene as well as their semantics. This guarantees a high level of\nphoto-realism and allows to explore real scenarios ignored in conventional\ndatabases dedicated to various CV applications. Our versatile database offers\nan efficient solution to improve the robustness of various CV tasks such as\nObject Detection (OD), scene segmentation, and distortion-type classification\nmethods. The image database, scene classification index, and distortion\ngeneration codes are publicly available\n\\footnote{\\url{https://github.com/Aymanbegh/CD-COCO}}",
            "author": [
                "Ayman Beghdadi",
                "Azeddine Beghdadi",
                "Malik Mallem",
                "Lotfi Beji",
                "Faouzi Alaya Cheikh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06976v1",
                "http://arxiv.org/pdf/2311.06976v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06964v1",
            "title": "Adaptive recurrent vision performs zero-shot computation scaling to\n  unseen difficulty levels",
            "updated": "2023-11-12T21:07:04Z",
            "published": "2023-11-12T21:07:04Z",
            "summary": "Humans solving algorithmic (or) reasoning problems typically exhibit solution\ntimes that grow as a function of problem difficulty. Adaptive recurrent neural\nnetworks have been shown to exhibit this property for various\nlanguage-processing tasks. However, little work has been performed to assess\nwhether such adaptive computation can also enable vision models to extrapolate\nsolutions beyond their training distribution's difficulty level, with prior\nwork focusing on very simple tasks. In this study, we investigate a critical\nfunctional role of such adaptive processing using recurrent neural networks: to\ndynamically scale computational resources conditional on input requirements\nthat allow for zero-shot generalization to novel difficulty levels not seen\nduring training using two challenging visual reasoning tasks: PathFinder and\nMazes. We combine convolutional recurrent neural networks (ConvRNNs) with a\nlearnable halting mechanism based on Graves (2016). We explore various\nimplementations of such adaptive ConvRNNs (AdRNNs) ranging from tying weights\nacross layers to more sophisticated biologically inspired recurrent networks\nthat possess lateral connections and gating. We show that 1) AdRNNs learn to\ndynamically halt processing early (or late) to solve easier (or harder)\nproblems, 2) these RNNs zero-shot generalize to more difficult problem settings\nnot shown during training by dynamically increasing the number of recurrent\niterations at test time. Our study provides modeling evidence supporting the\nhypothesis that recurrent processing enables the functional advantage of\nadaptively allocating compute resources conditional on input requirements and\nhence allowing generalization to harder difficulty levels of a visual reasoning\nproblem without training.",
            "author": [
                "Vijay Veerabadran",
                "Srinivas Ravishankar",
                "Yuan Tang",
                "Ritik Raina",
                "Virginia R. de Sa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06964v1",
                "http://arxiv.org/pdf/2311.06964v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06962v1",
            "title": "Atlas: Hybrid Cloud Migration Advisor for Interactive Microservices",
            "updated": "2023-11-12T21:01:42Z",
            "published": "2023-11-12T21:01:42Z",
            "summary": "Hybrid cloud provides an attractive solution to microservices for better\nresource elasticity. A subset of application components can be offloaded from\nthe on-premises cluster to the cloud, where they can readily access additional\nresources. However, the selection of this subset is challenging because of the\nlarge number of possible combinations. A poor choice degrades the application\nperformance, disrupts the critical services, and increases the cost to the\nextent of making the use of hybrid cloud unviable. This paper presents Atlas, a\nhybrid cloud migration advisor. Atlas uses a data-driven approach to learn how\neach user-facing API utilizes different components and their network footprints\nto drive the migration decision. It learns to accelerate the discovery of\nhigh-quality migration plans from millions and offers recommendations with\ncustomizable trade-offs among three quality indicators: end-to-end latency of\nuser-facing APIs representing application performance, service availability,\nand cloud hosting costs. Atlas continuously monitors the application even after\nthe migration for proactive recommendations. Our evaluation shows that Atlas\ncan achieve 21% better API performance (latency) and 11% cheaper cost with less\nservice disruption than widely used solutions.",
            "author": [
                "Ka-Ho Chow",
                "Umesh Deshpande",
                "Veera Deenadhayalan",
                "Sangeetha Seshadri",
                "Ling Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06962v1",
                "http://arxiv.org/pdf/2311.06962v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06961v1",
            "title": "Empowering Learning: Standalone, Browser-Only Courses for Seamless\n  Education",
            "updated": "2023-11-12T20:59:52Z",
            "published": "2023-11-12T20:59:52Z",
            "summary": "Massive Open Online Courses (MOOCs) have transformed the educational\nlandscape, offering scalable and flexible learning opportunities, particularly\nin data-centric fields like data science and artificial intelligence.\nIncorporating AI and data science into MOOCs is a potential means of enhancing\nthe learning experience through adaptive learning approaches. In this context,\nwe introduce PyGlide, a proof-of-concept open-source MOOC delivery system that\nunderscores autonomy, transparency, and collaboration in maintaining course\ncontent. We provide a user-friendly, step-by-step guide for PyGlide,\nemphasizing its distinct advantage of not requiring any local software\ninstallation for students. Highlighting its potential to enhance accessibility,\ninclusivity, and the manageability of course materials, we showcase PyGlide's\npractical application in a continuous integration pipeline on GitHub. We\nbelieve that PyGlide charts a promising course for the future of open-source\nMOOCs, effectively addressing crucial challenges in online education.",
            "author": [
                "Babak Moghadas",
                "Brian S. Caffo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06961v1",
                "http://arxiv.org/pdf/2311.06961v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06957v1",
            "title": "Simulating Public Administration Crisis: A Novel Generative Agent-Based\n  Simulation System to Lower Technology Barriers in Social Science Research",
            "updated": "2023-11-12T20:48:01Z",
            "published": "2023-11-12T20:48:01Z",
            "summary": "This article proposes a social simulation paradigm based on the GPT-3.5 large\nlanguage model. It involves constructing Generative Agents that emulate human\ncognition, memory, and decision-making frameworks, along with establishing a\nvirtual social system capable of stable operation and an insertion mechanism\nfor standardized public events. The project focuses on simulating a township\nwater pollution incident, enabling the comprehensive examination of a virtual\ngovernment's response to a specific public administration event. Controlled\nvariable experiments demonstrate that the stored memory in generative agents\nsignificantly influences both individual decision-making and social networks.\n  The Generative Agent-Based Simulation System introduces a novel approach to\nsocial science and public administration research. Agents exhibit personalized\ncustomization, and public events are seamlessly incorporated through natural\nlanguage processing. Its high flexibility and extensive social interaction\nrender it highly applicable in social science investigations. The system\neffectively reduces the complexity associated with building intricate social\nsimulations while enhancing its interpretability.",
            "author": [
                "Bushi Xiao",
                "Ziyuan Yin",
                "Zixuan Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06957v1",
                "http://arxiv.org/pdf/2311.06957v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06956v1",
            "title": "SegReg: Segmenting OARs by Registering MR Images and CT Annotations",
            "updated": "2023-11-12T20:46:54Z",
            "published": "2023-11-12T20:46:54Z",
            "summary": "Organ at risk (OAR) segmentation is a critical process in radiotherapy\ntreatment planning such as head and neck tumors. Nevertheless, in clinical\npractice, radiation oncologists predominantly perform OAR segmentations\nmanually on CT scans. This manual process is highly time-consuming and\nexpensive, limiting the number of patients who can receive timely radiotherapy.\nAdditionally, CT scans offer lower soft-tissue contrast compared to MRI.\nDespite MRI providing superior soft-tissue visualization, its time-consuming\nnature makes it infeasible for real-time treatment planning. To address these\nchallenges, we propose a method called SegReg, which utilizes Elastic Symmetric\nNormalization for registering MRI to perform OAR segmentation. SegReg\noutperforms the CT-only baseline by 16.78% in mDSC and 18.77% in mIoU, showing\nthat it effectively combines the geometric accuracy of CT with the superior\nsoft-tissue contrast of MRI, making accurate automated OAR segmentation for\nclinical practice become possible.",
            "author": [
                "Zeyu Zhang",
                "Xuyin Qi",
                "Bowen Zhang",
                "Biao Wu",
                "Hien Le",
                "Bora Jeong",
                "Minh-Son To",
                "Richard Hartley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06956v1",
                "http://arxiv.org/pdf/2311.06956v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06952v1",
            "title": "A GPU-Accelerated Moving-Horizon Algorithm for Training Deep\n  Classification Trees on Large Datasets",
            "updated": "2023-11-12T20:34:00Z",
            "published": "2023-11-12T20:34:00Z",
            "summary": "Decision trees are essential yet NP-complete to train, prompting the\nwidespread use of heuristic methods such as CART, which suffers from\nsub-optimal performance due to its greedy nature. Recently, breakthroughs in\nfinding optimal decision trees have emerged; however, these methods still face\nsignificant computational costs and struggle with continuous features in\nlarge-scale datasets and deep trees. To address these limitations, we introduce\na moving-horizon differential evolution algorithm for classification trees with\ncontinuous features (MH-DEOCT). Our approach consists of a discrete tree\ndecoding method that eliminates duplicated searches between adjacent samples, a\nGPU-accelerated implementation that significantly reduces running time, and a\nmoving-horizon strategy that iteratively trains shallow subtrees at each node\nto balance the vision and optimizer capability. Comprehensive studies on 68 UCI\ndatasets demonstrate that our approach outperforms the heuristic method CART on\ntraining and testing accuracy by an average of 3.44% and 1.71%, respectively.\nMoreover, these numerical studies empirically demonstrate that MH-DEOCT\nachieves near-optimal performance (only 0.38% and 0.06% worse than the global\noptimal method on training and testing, respectively), while it offers\nremarkable scalability for deep trees (e.g., depth=8) and large-scale datasets\n(e.g., ten million samples).",
            "author": [
                "Jiayang Ren",
                "Valent\u00edn Osuna-Enciso",
                "Morimasa Okamoto",
                "Qiangqiang Mao",
                "Chaojie Ji",
                "Liang Cao",
                "Kaixun Hua",
                "Yankai Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06952v1",
                "http://arxiv.org/pdf/2311.06952v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06951v1",
            "title": "Virtual Photons Shed Light on the Early Temperature of Dense QCD Matter",
            "updated": "2023-11-12T20:29:58Z",
            "published": "2023-11-12T20:29:58Z",
            "summary": "Dileptons produced during heavy-ion collisions represent a unique probe of\nthe QCD phase diagram, and convey information about the state of the strongly\ninteracting system at the moment their preceding off-shell photon is created.\nIn this study, we compute thermal dilepton yields from Au+Au collisions\nperformed at different beam energies, employing a (3+1)-dimensional dynamic\nframework combined with emission rates accurate at next-to-leading order in\nperturbation theory and which include baryon chemical potential dependencies.\nBy comparing the effective temperature extracted from the thermal dilepton\ninvariant mass spectrum with the average temperature of the fluid, we offer a\nrobust quantitative validation of dileptons as effective probe of the early\nquark-gluon plasma stage.",
            "author": [
                "Jessica Churchill",
                "Lipei Du",
                "Charles Gale",
                "Greg Jackson",
                "Sangyong Jeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06951v1",
                "http://arxiv.org/pdf/2311.06951v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ex",
                "hep-ph",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06946v3",
            "title": "Performance of a Large Multimodal Model-based chatbot on the Test of\n  Understanding Graphs in Kinematics",
            "updated": "2023-11-22T13:40:44Z",
            "published": "2023-11-12T20:15:13Z",
            "summary": "The well-known artificial intelligence-based chatbot ChatGPT has recently\nbecome able to process image data as input. We investigated its performance on\nthe Test of Understanding Graphs in Kinematics (TUG-K) with the purpose of\ninforming the physics education community of the current potential of using\nChatGPT in the education process, particularly on tasks that involve graphical\ninterpretation. We used Robert Taylor's three-roles framework to guide our\nanalysis and frame our findings in terms of their educational implications. We\nfound that ChatGPT, on average, performed similarly to students at the high\nschool level, but with significant differences in the distribution of the\ncorrectness of its responses, as well as in terms of the displayed \"reasoning\"\nand \"visual\" abilities. While ChatGPT was very successful at proposing\nproductive strategies for solving the tasks on the test and expressed correct\n\"reasoning\" in most of its responses, it had difficulties correctly \"seeing\"\ngraphs. We suggest that, based on its performance, it would not be advisable to\nuse it in the role of a tutor, a model of a student, or a tool for assisting\nvision-impaired persons in the context of kinematics graphs.",
            "author": [
                "Giulia Polverini",
                "Bor Gregorcic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06946v3",
                "http://arxiv.org/pdf/2311.06946v3"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06937v1",
            "title": "Kleene Algebra with Dynamic Tests: Completeness and Complexity",
            "updated": "2023-11-12T19:49:41Z",
            "published": "2023-11-12T19:49:41Z",
            "summary": "We study versions of Kleene algebra with dynamic tests, that is, extensions\nof Kleene algebra with domain and antidomain operators. We show that Kleene\nalgebras with tests and Propositional dynamic logic correspond to special cases\nof the dynamic test framework. In particular, we establish completeness results\nwith respect to relational models and guarded-language models, and we show that\ntwo prominent classes of Kleene algebras with dynamic tests have an\nEXPTIME-complete equational theory.",
            "author": [
                "Igor Sedl\u00e1r"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06937v1",
                "http://arxiv.org/pdf/2311.06937v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06935v1",
            "title": "A method to estimate the rectangular orthotropic plate elastic constants\n  using least-squares and Chladni patterns",
            "updated": "2023-11-12T19:33:00Z",
            "published": "2023-11-12T19:33:00Z",
            "summary": "A method to retrieve the elastic constants of rectangular wooden plates is\npresented, relying on the measurement of a set of eigenfrequencies and the\nidentification of the corresponding mode shapes, and belonging to the more\ngeneral category of non-destructive inverse parameter estimation methods.\nCompared to previous works, the current method is effective with any choice of\nboundary conditions. Furthermore, the error function is linear in the elastic\nconstants, which are computed via a matrix inversion. This framework lends\nitself naturally to a physical interpretation of the results in terms of linear\ncombinations of eigenmodes, yielding new sets of modes and associated combined\nmode shapes in which the elastic constants are completely uncoupled. A number\nof numerical benchmark tests and experimental cases are treated in detail,\nhighlighting the reliability of the proposed methodology in cases of interest\nin acoustics and musical acoustics.",
            "author": [
                "Michele Ducceschi",
                "Sebastian Duran",
                "Henna Tahvanainen",
                "Ludovico Ausiello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06935v1",
                "http://arxiv.org/pdf/2311.06935v1"
            ],
            "primary_category": "physics.class-ph",
            "category": [
                "physics.class-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06930v1",
            "title": "Video-based sympathetic arousal assessment via peripheral blood flow\n  estimation",
            "updated": "2023-11-12T19:06:33Z",
            "published": "2023-11-12T19:06:33Z",
            "summary": "Electrodermal activity (EDA) is considered a standard marker of sympathetic\nactivity. However, traditional EDA measurement requires electrodes in steady\ncontact with the skin. Can sympathetic arousal be measured using only an\noptical sensor, such as an RGB camera? This paper presents a novel approach to\ninfer sympathetic arousal by measuring the peripheral blood flow on the face or\nhand optically. We contribute a self-recorded dataset of 21 participants,\ncomprising synchronized videos of participants' faces and palms and\ngold-standard EDA and photoplethysmography (PPG) signals. Our results show that\nwe can measure peripheral sympathetic responses that closely correlate with the\nground truth EDA. We obtain median correlations of 0.57 to 0.63 between our\ninferred signals and the ground truth EDA using only videos of the\nparticipants' palms or foreheads or PPG signals from the foreheads or fingers.\nWe also show that sympathetic arousal is best inferred from the forehead,\nfinger, or palm.",
            "author": [
                "Bjoern Braun",
                "Daniel McDuff",
                "Tadas Baltrusaitis",
                "Christian Holz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06930v1",
                "http://arxiv.org/pdf/2311.06930v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06926v1",
            "title": "Matrix-free polynomial preconditioning of saddle point systems using the\n  hyper-power method",
            "updated": "2023-11-12T18:55:53Z",
            "published": "2023-11-12T18:55:53Z",
            "summary": "This study explores the integration of the hyper-power sequence, a method\ncommonly employed for approximating the Moore-Penrose inverse, to enhance the\neffectiveness of an existing preconditioner. The approach is closely related to\npolynomial preconditioning based on Neumann series. We commence with a\nstate-of-the-art matrix-free preconditioner designed for the saddle point\nsystem derived from isogeometric structure-preserving discretization of the\nStokes equations. Our results demonstrate that incorporating multiple\niterations of the hyper-power method enhances the effectiveness of the\npreconditioner, leading to a substantial reduction in both iteration counts and\noverall solution time for simulating Stokes flow within a 3D lid-driven cavity.\nThrough a comprehensive analysis, we assess the stability, accuracy, and\nnumerical cost associated with the proposed scheme.",
            "author": [
                "Micha\u0142 \u0141ukasz Mika",
                "Marco ten Eikelder",
                "Dominik Schillinger",
                "Ren\u00e9 Rinke Hiemstra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06926v1",
                "http://arxiv.org/pdf/2311.06926v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "65N30, 65F08, 65F10, 65F30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06925v1",
            "title": "Microwave Quantum Memristors",
            "updated": "2023-11-12T18:51:52Z",
            "published": "2023-11-12T18:51:52Z",
            "summary": "We propose a design of a superconducting quantum memristive device in the\nmicrowave regime, that is, a microwave quantum memristor. It comprises two\nlinked resonators, where the primary one is coupled to a superconducting\nquantum interference device (SQUID), allowing the adjustment of the resonator\nproperties with an external magnetic flux. The auxiliary resonator is operated\nthrough weak measurements, providing feedback to the primary resonator via the\nSQUID and establishing stable memristive behavior via the external magnetic\nflux. The device operates with a classical input signal in one cavity while\nreading the response in the other, serving as a fundamental building block for\narrays of microwave quantum memristors. In this sense, we observe that a\nbipartite setup can retain its memristive behavior while gaining entanglement\nand quantum correlations. Our findings open the door to the experimental\nimplementation of memristive superconducting quantum devices and arrays of\nmicrowave quantum memristors on the path to neuromorphic quantum computing.",
            "author": [
                "X. -Y. Qiu",
                "S. Kumar",
                "F. A. C\u00e1rdenas-L\u00f3pez",
                "G. Alvarado Barrios",
                "E. Solano",
                "F. Albarr\u00e1n-Arriagada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06925v1",
                "http://arxiv.org/pdf/2311.06925v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06923v1",
            "title": "Optimal mean first-passage time of a run-and-tumble particle in a\n  one-dimensional confining potential",
            "updated": "2023-11-12T18:44:03Z",
            "published": "2023-11-12T18:44:03Z",
            "summary": "We consider a run-and-tumble particle (RTP), subjected to a telegraphic noise\nwith a constant rate $\\gamma$, and in the presence of an external confining\npotential $V(x) = \\alpha |x|^p$ with $p \\geq 1$. We compute the mean\nfirst-passage time (MFPT) at the origin $\\tau_\\gamma(x_0)$ for an RTP starting\nat $x_0$. We obtain a closed form expression for $\\tau_\\gamma(x_0)$ for all $p\n\\geq 1$, which becomes fully explicit in the case $p=1$, $p=2$ and in the limit\n$p \\to \\infty$. For generic $p>1$ we find that there exists an optimal rate\n$\\gamma_{\\rm opt}$ that minimizes the MFPT and we characterize in detail its\ndependence on $x_0$. We find that $\\gamma_{\\rm opt} \\propto 1/x_0$ as $x_0 \\to\n0$, while $\\gamma_{\\rm opt}$ converges to a nontrivial constant as $x_0 \\to\n\\infty$. In contrast, for $p=1$, there is no finite optimum and $\\gamma_{\\rm\nopt} \\to \\infty$ in this case. These analytical results are confirmed by our\nnumerical simulations.",
            "author": [
                "Mathis Gueneau",
                "Satya N. Majumdar",
                "Gregory Schehr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06923v1",
                "http://arxiv.org/pdf/2311.06923v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06921v1",
            "title": "Concept Matching: Clustering-based Federated Continual Learning",
            "updated": "2023-11-12T18:31:20Z",
            "published": "2023-11-12T18:31:20Z",
            "summary": "Federated Continual Learning (FCL) has emerged as a promising paradigm that\ncombines Federated Learning (FL) and Continual Learning (CL). To achieve good\nmodel accuracy, FCL needs to tackle catastrophic forgetting due to concept\ndrift over time in CL, and to overcome the potential interference among clients\nin FL. We propose Concept Matching (CM), a clustering-based framework for FCL\nto address these challenges. The CM framework groups the client models into\nconcept model clusters, and then builds different global models to capture\ndifferent concepts in FL over time. In each round, the server sends the global\nconcept models to the clients. To avoid catastrophic forgetting, each client\nselects the concept model best-matching the concept of the current data for\nfurther fine-tuning. To avoid interference among client models with different\nconcepts, the server clusters the models representing the same concept,\naggregates the model weights in each cluster, and updates the global concept\nmodel with the cluster model of the same concept. Since the server does not\nknow the concepts captured by the aggregated cluster models, we propose a novel\nserver concept matching algorithm that effectively updates a global concept\nmodel with a matching cluster model. The CM framework provides flexibility to\nuse different clustering, aggregation, and concept matching algorithms. The\nevaluation demonstrates that CM outperforms state-of-the-art systems and scales\nwell with the number of clients and the model size.",
            "author": [
                "Xiaopeng Jiang",
                "Cristian Borcea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06921v1",
                "http://arxiv.org/pdf/2311.06921v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06917v1",
            "title": "FLASH-RL: Federated Learning Addressing System and Static Heterogeneity\n  using Reinforcement Learning",
            "updated": "2023-11-12T18:21:00Z",
            "published": "2023-11-12T18:21:00Z",
            "summary": "Federated Learning (FL) has emerged as a promising Machine Learning paradigm,\nenabling multiple users to collaboratively train a shared model while\npreserving their local data. To minimize computing and communication costs\nassociated with parameter transfer, it is common practice in FL to select a\nsubset of clients in each training round. This selection must consider both\nsystem and static heterogeneity. Therefore, we propose FLASH-RL, a framework\nthat utilizes Double Deep QLearning (DDQL) to address both system and static\nheterogeneity in FL. FLASH-RL introduces a new reputation-based utility\nfunction to evaluate client contributions based on their current and past\nperformances. Additionally, an adapted DDQL algorithm is proposed to expedite\nthe learning process. Experimental results on MNIST and CIFAR-10 datasets have\nshown FLASH-RL's effectiveness in achieving a balanced trade-off between model\nperformance and end-to-end latency against existing solutions. Indeed, FLASH-RL\nreduces latency by up to 24.83% compared to FedAVG and 24.67% compared to\nFAVOR. It also reduces the training rounds by up to 60.44% compared to FedAVG\nand +76% compared to FAVOR. In fall detection using the MobiAct dataset,\nFLASH-RL outperforms FedAVG by up to 2.82% in model's performance and reduces\nlatency by up to 34.75%. Additionally, FLASH-RL achieves the target performance\nfaster, with up to a 45.32% reduction in training rounds compared to FedAVG.",
            "author": [
                "Sofiane Bouaziz",
                "Hadjer Benmeziane",
                "Youcef Imine",
                "Leila Hamdad",
                "Smail Niar",
                "Hamza Ouarnoughi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06917v1",
                "http://arxiv.org/pdf/2311.06917v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06916v1",
            "title": "TSViT: A Time Series Vision Transformer for Fault Diagnosis",
            "updated": "2023-11-12T18:16:48Z",
            "published": "2023-11-12T18:16:48Z",
            "summary": "Traditional fault diagnosis methods using Convolutional Neural Networks\n(CNNs) face limitations in capturing temporal features (i.e., the variation of\nvibration signals over time). To address this issue, this paper introduces a\nnovel model, the Time Series Vision Transformer (TSViT), specifically designed\nfor fault diagnosis. On one hand, TSViT model integrates a convolutional layer\nto segment vibration signals and capture local features. On the other hand, it\nemploys a transformer encoder to learn long-term temporal information. The\nexperimental results with other methods on two distinct datasets validate the\neffectiveness and generalizability of TSViT with a comparative analysis of its\nhyperparameters' impact on model performance, computational complexity, and\noverall parameter quantity. TSViT reaches average accuracies of 100% and 99.99%\non two test sets, correspondingly.",
            "author": [
                "Shouhua Zhang",
                "Jiehan Zhou",
                "Xue Ma",
                "Chenglin Wen",
                "Susanna Pirttikangas",
                "Chen Yu",
                "Weishan Zhang",
                "Chunsheng Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06916v1",
                "http://arxiv.org/pdf/2311.06916v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06914v1",
            "title": "Model-assisted Reinforcement Learning of a Quadrotor",
            "updated": "2023-11-12T18:05:56Z",
            "published": "2023-11-12T18:05:56Z",
            "summary": "In recent times, reinforcement learning has produced baffling results when it\ncomes to performing control tasks with highly non-linear systems. The\nimpressive results always outweigh the potential vulnerabilities or\nuncertainties associated with the agents when deployed in the real-world. While\nthe performance is remarkable compared to the classical control algorithms, the\nreinforcement learning-based methods suffer from two flaws, robustness and\ninterpretability, which are vital for contemporary real-world applications. The\npaper attempts to alleviate such problems with reinforcement learning and\nproposes the concept of model-assisted reinforcement learning to induce a\nnotion of conservativeness in the agents. The control task considered for the\nexperiment involves navigating a CrazyFlie quadrotor. The paper also describes\na way of reformulating the task to have the flexibility of tuning the level of\nconservativeness via multi-objective reinforcement learning. The results\ninclude a comparison of the vanilla reinforcement learning approaches and the\nproposed approach. The metrics are evaluated by systematically injecting\ndisturbances to classify the inherent robustness and conservativeness of the\nagents. More concrete arguments are made by computing and comparing the\nbackward reachability tubes of the RL policies by solving the\nHamilton-Jacobi-Bellman partial differential equation (HJ PDE).",
            "author": [
                "Arshad Javeed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06914v1",
                "http://arxiv.org/pdf/2311.06914v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07620v1",
            "title": "EPIM: Efficient Processing-In-Memory Accelerators based on Epitome",
            "updated": "2023-11-12T17:56:39Z",
            "published": "2023-11-12T17:56:39Z",
            "summary": "The exploration of Processing-In-Memory (PIM) accelerators has garnered\nsignificant attention within the research community. However, the utilization\nof large-scale neural networks on Processing-In-Memory (PIM) accelerators\nencounters challenges due to constrained on-chip memory capacity. To tackle\nthis issue, current works explore model compression algorithms to reduce the\nsize of Convolutional Neural Networks (CNNs). Most of these algorithms either\naim to represent neural operators with reduced-size parameters (e.g.,\nquantization) or search for the best combinations of neural operators (e.g.,\nneural architecture search). Designing neural operators to align with PIM\naccelerators' specifications is an area that warrants further study. In this\npaper, we introduce the Epitome, a lightweight neural operator offering\nconvolution-like functionality, to craft memory-efficient CNN operators for PIM\naccelerators (EPIM). On the software side, we evaluate epitomes' latency and\nenergy on PIM accelerators and introduce a PIM-aware layer-wise design method\nto enhance their hardware efficiency. We apply epitome-aware quantization to\nfurther reduce the size of epitomes. On the hardware side, we modify the\ndatapath of current PIM accelerators to accommodate epitomes and implement a\nfeature map reuse technique to reduce computation cost. Experimental results\nreveal that our 3-bit quantized EPIM-ResNet50 attains 71.59% top-1 accuracy on\nImageNet, reducing crossbar areas by 30.65 times. EPIM surpasses the\nstate-of-the-art pruning methods on PIM.",
            "author": [
                "Chenyu Wang",
                "Zhen Dong",
                "Daquan Zhou",
                "Zhenhua Zhu",
                "Yu Wang",
                "Jiashi Feng",
                "Kurt Keutzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07620v1",
                "http://arxiv.org/pdf/2311.07620v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06910v1",
            "title": "Zooming in on the Universe: In Search of Quantum Spacetime",
            "updated": "2023-11-12T17:54:31Z",
            "published": "2023-11-12T17:54:31Z",
            "summary": "This thesis investigates low-dimensional models of nonperturbative quantum\ngravity, with a special focus on Causal Dynamical Triangulations (CDT). We\ndefine the so-called curvature profile, a new quantum gravitational observable\nbased on the quantum Ricci curvature. We subsequently study its coarse-graining\ncapabilities on a class of regular, two-dimensional polygons with isolated\ncurvature singularities, and we determine the curvature profile of\n(1+1)-dimensional CDT with toroidal topology. Next, we focus on CDT in 2+1\ndimensions, intvestigating the behavior of the two-dimensional spatial slice\ngeometries. We then turn our attention to matrix models, exploring a\ndifferential reformulation of the integrals over one- and two-matrix ensembles.\nFinally, we provide a hands-on introduction to computer simulations of CDT\nquantum gravity.",
            "author": [
                "Joren Brunekreef"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06910v1",
                "http://arxiv.org/pdf/2311.06910v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-lat",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06908v1",
            "title": "Computing the F-pure Threshold of Flag Varieties",
            "updated": "2023-11-12T17:50:43Z",
            "published": "2023-11-12T17:50:43Z",
            "summary": "We compute the $F$-pure threshold of the natural cone over flag varieties in\ncharacteristic $p>0$. Our calculations are mainly focused on flag varieties\nthat are arithmetically Gorenstein, but we offer some results in the\nnon-Gorenstein case. Our goal is to determine the $a$-invariant of the cone. As\na result, the $F$-pure thresholds we find are independent of the characteristic\n$p$, hence one immediately gets the value of the log canonical threshold of\nflags in characteristic 0 as well.",
            "author": [
                "Justin Fong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06908v1",
                "http://arxiv.org/pdf/2311.06908v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.AC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06906v2",
            "title": "Particle-based algorithm for stochastic optimal control",
            "updated": "2023-12-03T12:45:47Z",
            "published": "2023-11-12T17:50:27Z",
            "summary": "The solution to a stochastic optimal control problem can be determined by\ncomputing the value function from a discretisation of the associated\nHamilton-Jacobi-Bellman equation. Alternatively, the problem can be\nreformulated in terms of a pair of forward-backward SDEs, which makes\nMonte-Carlo techniques applicable. More recently, the problem has also been\nviewed from the perspective of forward and reverse time SDEs and their\nassociated Fokker-Planck equations. This approach is closely related to\ntechniques used in score generative models. Forward and reverse time\nformulations express the value function as the ratio of two probability density\nfunctions; one stemming from a forward McKean-Vlasov SDE and another one from a\nreverse McKean-Vlasov SDE. In this note, we extend this approach to a more\ngeneral class of stochastic optimal control problems and combine it with\nensemble Kalman filter type and diffusion map approximation techniques in order\nto obtain efficient and robust particle-based algorithms.",
            "author": [
                "Sebastian Reich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06906v2",
                "http://arxiv.org/pdf/2311.06906v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.NA",
                "math.NA",
                "93E20, 49L12, 65C35, 65M75"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06899v1",
            "title": "Flames: Benchmarking Value Alignment of Chinese Large Language Models",
            "updated": "2023-11-12T17:18:21Z",
            "published": "2023-11-12T17:18:21Z",
            "summary": "The widespread adoption of large language models (LLMs) across various\nregions underscores the urgent need to evaluate their alignment with human\nvalues. Current benchmarks, however, fall short of effectively uncovering\nsafety vulnerabilities in LLMs. Despite numerous models achieving high scores\nand 'topping the chart' in these evaluations, there is still a significant gap\nin LLMs' deeper alignment with human values and achieving genuine harmlessness.\nTo this end, this paper proposes the first highly adversarial benchmark named\nFlames, consisting of 2,251 manually crafted prompts, ~18.7K model responses\nwith fine-grained annotations, and a specified scorer. Our framework\nencompasses both common harmlessness principles, such as fairness, safety,\nlegality, and data protection, and a unique morality dimension that integrates\nspecific Chinese values such as harmony. Based on the framework, we carefully\ndesign adversarial prompts that incorporate complex scenarios and jailbreaking\nmethods, mostly with implicit malice. By prompting mainstream LLMs with such\nadversarially constructed prompts, we obtain model responses, which are then\nrigorously annotated for evaluation. Our findings indicate that all the\nevaluated LLMs demonstrate relatively poor performance on Flames, particularly\nin the safety and fairness dimensions. Claude emerges as the best-performing\nmodel overall, but with its harmless rate being only 63.08% while GPT-4 only\nscores 39.04%. The complexity of Flames has far exceeded existing benchmarks,\nsetting a new challenge for contemporary LLMs and highlighting the need for\nfurther alignment of LLMs. To efficiently evaluate new models on the benchmark,\nwe develop a specified scorer capable of scoring LLMs across multiple\ndimensions, achieving an accuracy of 77.4%. The Flames Benchmark is publicly\navailable on https://github.com/AIFlames/Flames.",
            "author": [
                "Kexin Huang",
                "Xiangyang Liu",
                "Qianyu Guo",
                "Tianxiang Sun",
                "Jiawei Sun",
                "Yaru Wang",
                "Zeyang Zhou",
                "Yixu Wang",
                "Yan Teng",
                "Xipeng Qiu",
                "Yingchun Wang",
                "Dahua Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06899v1",
                "http://arxiv.org/pdf/2311.06899v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06898v1",
            "title": "Retrieval and Generative Approaches for a Pregnancy Chatbot in Nepali\n  with Stemmed and Non-Stemmed Data : A Comparative Study",
            "updated": "2023-11-12T17:16:46Z",
            "published": "2023-11-12T17:16:46Z",
            "summary": "The field of Natural Language Processing which involves the use of artificial\nintelligence to support human languages has seen tremendous growth due to its\nhigh-quality features. Its applications such as language translation, chatbots,\nvirtual assistants, search autocomplete, and autocorrect are widely used in\nvarious domains including healthcare, advertising, customer service, and target\nadvertising. To provide pregnancy-related information a health domain chatbot\nhas been proposed and this work explores two different NLP-based approaches for\ndeveloping the chatbot. The first approach is a multiclass classification-based\nretrieval approach using BERTbased multilingual BERT and multilingual\nDistilBERT while the other approach employs a transformer-based generative\nchatbot for pregnancy-related information. The performance of both stemmed and\nnon-stemmed datasets in Nepali language has been analyzed for each approach.\nThe experimented results indicate that BERT-based pre-trained models perform\nwell on non-stemmed data whereas scratch transformer models have better\nperformance on stemmed data. Among the models tested the DistilBERT model\nachieved the highest training and validation accuracy and testing accuracy of\n0.9165 on the retrieval-based model architecture implementation on the\nnon-stemmed dataset. Similarly, in the generative approach architecture\nimplementation with transformer 1 gram BLEU and 2 gram BLEU scores of 0.3570\nand 0.1413 respectively were achieved.",
            "author": [
                "Sujan Poudel",
                "Nabin Ghimire",
                "Bipesh Subedi",
                "Saugat Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06898v1",
                "http://arxiv.org/pdf/2311.06898v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06894v1",
            "title": "An Application of Vector Autoregressive Model for Analyzing the Impact\n  of Weather And Nearby Traffic Flow On The Traffic Volume",
            "updated": "2023-11-12T16:45:29Z",
            "published": "2023-11-12T16:45:29Z",
            "summary": "This paper aims to predict the traffic flow at one road segment based on\nnearby traffic volume and weather conditions. Our team also discover the impact\nof weather conditions and nearby traffic volume on the traffic flow at a target\npoint. The analysis results will help solve the problem of traffic flow\nprediction and develop an optimal transport network with efficient traffic\nmovement and minimal traffic congestion. Hourly historical weather and traffic\nflow data are selected to solve this problem. This paper uses model VAR(36)\nwith time trend and constant to train the dataset and forecast. With an RMSE of\n565.0768111 on average, the model is considered appropriate although some\nstatistical tests implies that the residuals are unstable and non-normal. Also,\nthis paper points out some variables that are not useful in forecasting, which\nhelps simplify the data-collecting process when building the forecasting\nsystem.",
            "author": [
                "Anh Thi-Hoang Nguyen",
                "Dung Ha Nguyen",
                "Trong-Hop Do"
            ],
            "link": [
                "http://dx.doi.org/10.1109/RIVF55975.2022.10013894",
                "http://arxiv.org/abs/2311.06894v1",
                "http://arxiv.org/pdf/2311.06894v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14706v2",
            "title": "Social AI Improves Well-Being Among Female Young Adults",
            "updated": "2023-11-29T01:11:00Z",
            "published": "2023-11-12T16:44:43Z",
            "summary": "The rise of language models like ChatGPT has introduced Social AI as a new\nform of entertainment, particularly among young adults who engage with\nAI-powered agents. This paper investigates the effects of these interactions on\nusers' social and mental well-being, a subject that has incited extensive\ndebate among both the public and scholars. Our study involved a survey of 5,260\nusers of Chai, a Social AI Platform. The findings indicate significant\nbenefits, with notable variations across demographics. Female users, in\nparticular, reported the most substantial improvements: 43.4% strongly agreed\nthat Social AI positively impacted their mental health, exceeding male users by\n10.5%. In managing social anxieties, 38.9% of females strongly agreed on a\npositive impact, compared to 30.0% for males and 27.1% for other genders.\nHistorically, new media and technology have often been met with groundless\nmoral panic, with societal figures raising concerns without substantial\nevidence of harm. Our research indicates the importance of approaching such\nclaims with caution and emphasizes the necessity of an evidence-based\nperspective in discussions about the behavioral effects of emerging\ntechnologies.",
            "author": [
                "Ebony Zhang",
                "Xiaoding Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14706v2",
                "http://arxiv.org/pdf/2311.14706v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06892v1",
            "title": "Setting a Baseline for long-shot real-time Player and Ball detection in\n  Soccer Videos",
            "updated": "2023-11-12T16:39:02Z",
            "published": "2023-11-12T16:39:02Z",
            "summary": "Players and ball detection are among the first required steps on a football\nanalytics platform. Until recently, the existing open datasets on which the\nevaluations of most models were based, were not sufficient. In this work, we\npoint out their weaknesses, and with the advent of the SoccerNet v3, we propose\nand deliver to the community an edited part of its dataset, in YOLO normalized\nannotation format for training and evaluation. The code of the methods and\nmetrics are provided so that they can be used as a benchmark in future\ncomparisons. The recent YOLO8n model proves better than FootAndBall in\nlong-shot real-time detection of the ball and players on football fields.",
            "author": [
                "Konstantinos Moutselos",
                "Ilias Maglogiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06892v1",
                "http://arxiv.org/pdf/2311.06892v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06889v2",
            "title": "Programmatic Strategy Synthesis: Resolving Nondeterminism in\n  Probabilistic Programs",
            "updated": "2023-11-14T17:02:43Z",
            "published": "2023-11-12T16:26:34Z",
            "summary": "We consider imperative programs that involve both randomization and pure\nnondeterminism. The central question is how to find a strategy resolving the\npure nondeterminism such that the so-obtained determinized program satisfies a\ngiven quantitative specification, i.e., bounds on expected outcomes such as the\nexpected final value of a program variable or the probability to terminate in a\ngiven set of states. We show how memoryless and deterministic (MD) strategies\ncan be obtained in a semi-automatic fashion using deductive verification\ntechniques. For loop-free programs, the MD strategies resulting from our\nweakest precondition-style framework are correct by construction. This extends\nto loopy programs, provided the loops are equipped with suitable loop\ninvariants - just like in program verification. We show how our technique\nrelates to the well-studied problem of obtaining strategies in countably\ninfinite Markov decision processes with reachability-reward objectives.\nFinally, we apply our technique to several case studies.",
            "author": [
                "Kevin Batz",
                "Tom Jannik Biskup",
                "Joost-Pieter Katoen",
                "Tobias Winkler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06889v2",
                "http://arxiv.org/pdf/2311.06889v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06887v1",
            "title": "Anticipating User Needs: Insights from Design Fiction on Conversational\n  Agents for Computational Thinking",
            "updated": "2023-11-12T16:19:03Z",
            "published": "2023-11-12T16:19:03Z",
            "summary": "Computational thinking, and by extension, computer programming, is\nnotoriously challenging to learn. Conversational agents and generative\nartificial intelligence (genAI) have the potential to facilitate this learning\nprocess by offering personalized guidance, interactive learning experiences,\nand code generation. However, current genAI-based chatbots focus on\nprofessional developers and may not adequately consider educational needs.\nInvolving educators in conceiving educational tools is critical for ensuring\nusefulness and usability. We enlisted \\numParticipants{} instructors to engage\nin design fiction sessions in which we elicited abilities such a conversational\nagent supported by genAI should display. Participants envisioned a\nconversational agent that guides students stepwise through exercises, tuning\nits method of guidance with an awareness of the educational background, skills\nand deficits, and learning preferences. The insights obtained in this paper can\nguide future implementations of tutoring conversational agents oriented toward\nteaching computational thinking and computer programming.",
            "author": [
                "Jacob Penney",
                "Jo\u00e3o Felipe Pimentel",
                "Igor Steinmacher",
                "Marco A. Gerosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06887v1",
                "http://arxiv.org/pdf/2311.06887v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06880v1",
            "title": "Deadbeat Robust Model Predictive Control: Robustness without Computing\n  Robust Invariant Sets",
            "updated": "2023-11-12T15:55:32Z",
            "published": "2023-11-12T15:55:32Z",
            "summary": "Deadbeat Robust Model Predictive Control (DRMPC) is introduced as a new\napproach of Robust Model Predictive Control (RMPC) for linear systems with\nadditive disturbances. Its main idea is to completely extinguish the effect of\nthe disturbances in the predictions within a small number of time steps, called\nthe deadbeat horizon. To this end, explicit deadbeat input sequences are\ncalculated for the vertices of the disturbance set. They generalize to a\nnonlinear disturbance feedback policy for all disturbances by means of a\nbarycentric function. Similar to previous approaches, this disturbance feedback\npolicy can be either part of the online optimization (Online DRMPC) or\npre-calculated during the design phase of the controller (Offline DRMPC). The\nmain advantage over all other RMPC approaches is that no Robust Positive\nInvariant (RPI) set has to be calculated, which is often intractable for\nsystems with higher dimensions. Nonetheless, for Online DRMPC and Offline DRMPC\nrecursive feasibility and input-to-state stability can be guaranteed. A small\nnumerical example compares the two versions of DRMPC and demonstrates that the\nperformance of DRMPC is competitive with other state-of-the-art RMPC\napproaches. Its main advantage is its easy extension to linear time-varying\n(LTV) and linear parameter-varying (LPV) systems.",
            "author": [
                "G. Schildbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06880v1",
                "http://arxiv.org/pdf/2311.06880v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06879v1",
            "title": "pFedES: Model Heterogeneous Personalized Federated Learning with Feature\n  Extractor Sharing",
            "updated": "2023-11-12T15:43:39Z",
            "published": "2023-11-12T15:43:39Z",
            "summary": "As a privacy-preserving collaborative machine learning paradigm, federated\nlearning (FL) has attracted significant interest from academia and the industry\nalike. To allow each data owner (a.k.a., FL clients) to train a heterogeneous\nand personalized local model based on its local data distribution, system\nresources and requirements on model structure, the field of model-heterogeneous\npersonalized federated learning (MHPFL) has emerged. Existing MHPFL approaches\neither rely on the availability of a public dataset with special\ncharacteristics to facilitate knowledge transfer, incur high computation and\ncommunication costs, or face potential model leakage risks. To address these\nlimitations, we propose a model-heterogeneous personalized Federated learning\napproach based on feature Extractor Sharing (pFedES). It incorporates a small\nhomogeneous feature extractor into each client's heterogeneous local model.\nClients train them via the proposed iterative learning method to enable the\nexchange of global generalized knowledge and local personalized knowledge. The\nsmall local homogeneous extractors produced after local training are uploaded\nto the FL server and for aggregation to facilitate easy knowledge sharing among\nclients. We theoretically prove that pFedES can converge over wall-to-wall\ntime. Extensive experiments on two real-world datasets against six\nstate-of-the-art methods demonstrate that pFedES builds the most accurate\nmodel, while incurring low communication and computation costs. Compared with\nthe best-performing baseline, it achieves 1.61% higher test accuracy, while\nreducing communication and computation costs by 99.6% and 82.9%, respectively.",
            "author": [
                "Liping Yi",
                "Han Yu",
                "Gang Wang",
                "Xiaoguang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06879v1",
                "http://arxiv.org/pdf/2311.06879v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06874v1",
            "title": "Distributed Charging Coordination of Electric Trucks with Limited\n  Charging Resources",
            "updated": "2023-11-12T15:24:18Z",
            "published": "2023-11-12T15:24:18Z",
            "summary": "Electric trucks usually need to charge their batteries during long-range\ndelivery missions, and the charging times are often nontrivial. As charging\nresources are limited, waiting times for some trucks can be prolonged at\ncertain stations. To facilitate the efficient operation of electric trucks, we\npropose a distributed charging coordination framework. Within the scheme, the\ncharging stations provide waiting estimates to incoming trucks upon request and\nassign charging ports according to the first-come, first-served rule. Based on\nthe updated information, the individual trucks compute where and how long to\ncharge whenever approaching a charging station in order to complete their\ndelivery missions timely and cost-effectively. We perform empirical studies for\ntrucks traveling over the Swedish road network and compare our scheme with the\none where charging plans are computed offline, assuming unlimited charging\nfacilities. It is shown that the proposed scheme outperforms the offline\napproach at the expense of little communication overhead.",
            "author": [
                "Ting Bai",
                "Yuchao Li",
                "Karl Henrik Johansson",
                "Jonas M\u00e5rtensson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06874v1",
                "http://arxiv.org/pdf/2311.06874v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06868v1",
            "title": "Concept-wise Fine-tuning Matters in Preventing Negative Transfer",
            "updated": "2023-11-12T14:58:11Z",
            "published": "2023-11-12T14:58:11Z",
            "summary": "A multitude of prevalent pre-trained models mark a major milestone in the\ndevelopment of artificial intelligence, while fine-tuning has been a common\npractice that enables pretrained models to figure prominently in a wide array\nof target datasets. Our empirical results reveal that off-the-shelf finetuning\ntechniques are far from adequate to mitigate negative transfer caused by two\ntypes of underperforming features in a pre-trained model, including rare\nfeatures and spuriously correlated features. Rooted in structural causal models\nof predictions after fine-tuning, we propose a Concept-wise fine-tuning\n(Concept-Tuning) approach which refines feature representations in the level of\npatches with each patch encoding a concept. Concept-Tuning minimizes the\nnegative impacts of rare features and spuriously correlated features by (1)\nmaximizing the mutual information between examples in the same category with\nregard to a slice of rare features (a patch) and (2) applying front-door\nadjustment via attention neural networks in channels and feature slices\n(patches). The proposed Concept-Tuning consistently and significantly (by up to\n4.76%) improves prior state-of-the-art fine-tuning methods on eleven datasets,\ndiverse pre-training strategies (supervised and self-supervised ones), various\nnetwork architectures, and sample sizes in a target dataset.",
            "author": [
                "Yunqiao Yang",
                "Long-Kai Huang",
                "Ying Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06868v1",
                "http://arxiv.org/pdf/2311.06868v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06864v2",
            "title": "Understanding Practices around Computational News Discovery Tools in the\n  Domain of Science Journalism",
            "updated": "2023-11-28T16:47:49Z",
            "published": "2023-11-12T14:47:50Z",
            "summary": "Science and technology journalists today face challenges in finding\nnewsworthy leads due to increased workloads, reduced resources, and expanding\nscientific publishing ecosystems. Given this context, we explore computational\nmethods to aid these journalists' news discovery in terms of time-efficiency\nand agency. In particular, we prototyped three computational information\nsubsidies into an interactive tool that we used as a probe to better understand\nhow such a tool may offer utility or more broadly shape the practices of\nprofessional science journalists. Our findings highlight central considerations\naround science journalists' agency, context, and responsibilities that such\ntools can influence and could account for in design. Based on this, we suggest\ndesign opportunities for greater and longer-term user agency; incorporating\ncontextual, personal and collaborative notions of newsworthiness; and\nleveraging flexible interfaces and generative models. Overall, our findings\ncontribute a richer view of the sociotechnical system around computational news\ndiscovery tools, and suggest ways to improve such tools to better support the\npractices of science journalists.",
            "author": [
                "Sachita Nishal",
                "Jasmine Sinchai",
                "Nicholas Diakopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06864v2",
                "http://arxiv.org/pdf/2311.06864v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CY",
                "H.5; I.7; J.4; K.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06859v1",
            "title": "Benchmarking the optimization optical machines with the planted\n  solutions",
            "updated": "2023-11-12T14:28:56Z",
            "published": "2023-11-12T14:28:56Z",
            "summary": "We introduce universal, easy-to-reproduce generative models for the QUBO\ninstances to differentiate the performance of the hardware/solvers effectively.\nOur benchmark process extends the well-known Hebb's rule of associative memory\nwith the asymmetric pattern weights. We provide a comprehensive overview of\ncalculations conducted across various scales and using different classes of\ndynamical equations. Our aim is to analyze their results, including factors\nsuch as the probability of encountering the ground state, planted state,\nspurious state, or states falling outside the predetermined energy range.\nMoreover, the generated problems show additional properties, such as the\neasy-hard-easy complexity transition and complicated cluster structures of\nplanted solutions. Our method establishes a prospective platform to potentially\naddress other questions related to the fundamental principles behind device\nphysics and algorithms for novel computing machines.",
            "author": [
                "Nikita Stroev",
                "Natalia G. Berloff",
                "Nir Davidson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06859v1",
                "http://arxiv.org/pdf/2311.06859v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "cond-mat.stat-mech",
                "physics.comp-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06858v1",
            "title": "Can Large Language Models Augment a Biomedical Ontology with missing\n  Concepts and Relations?",
            "updated": "2023-11-12T14:20:55Z",
            "published": "2023-11-12T14:20:55Z",
            "summary": "Ontologies play a crucial role in organizing and representing knowledge.\nHowever, even current ontologies do not encompass all relevant concepts and\nrelationships. Here, we explore the potential of large language models (LLM) to\nexpand an existing ontology in a semi-automated fashion. We demonstrate our\napproach on the biomedical ontology SNOMED-CT utilizing semantic relation types\nfrom the widely used UMLS semantic network. We propose a method that uses\nconversational interactions with an LLM to analyze clinical practice guidelines\n(CPGs) and detect the relationships among the new medical concepts that are not\npresent in SNOMED-CT. Our initial experimentation with the conversational\nprompts yielded promising preliminary results given a manually generated gold\nstandard, directing our future potential improvements.",
            "author": [
                "Antonio Zaitoun",
                "Tomer Sagi",
                "Szymon Wilk",
                "Mor Peleg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06858v1",
                "http://arxiv.org/pdf/2311.06858v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06855v1",
            "title": "DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial\n  Training",
            "updated": "2023-11-12T14:12:19Z",
            "published": "2023-11-12T14:12:19Z",
            "summary": "This paper focuses on the DialFRED task, which is the task of embodied\ninstruction following in a setting where an agent can actively ask questions\nabout the task. To address this task, we propose DialMAT. DialMAT introduces\nMoment-based Adversarial Training, which incorporates adversarial perturbations\ninto the latent space of language, image, and action. Additionally, it\nintroduces a crossmodal parallel feature extraction mechanism that applies\nfoundation models to both language and image. We evaluated our model using a\ndataset constructed from the DialFRED dataset and demonstrated superior\nperformance compared to the baseline method in terms of success rate and path\nweighted success rate. The model secured the top position in the DialFRED\nChallenge, which took place at the CVPR 2023 Embodied AI workshop.",
            "author": [
                "Kanta Kaneda",
                "Ryosuke Korekata",
                "Yuiga Wada",
                "Shunya Nagashima",
                "Motonari Kambara",
                "Yui Iioka",
                "Haruka Matsuo",
                "Yuto Imai",
                "Takayuki Nishimura",
                "Komei Sugiura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06855v1",
                "http://arxiv.org/pdf/2311.06855v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06852v1",
            "title": "Contrastive Learning of View-Invariant Representations for Facial\n  Expressions Recognition",
            "updated": "2023-11-12T14:05:09Z",
            "published": "2023-11-12T14:05:09Z",
            "summary": "Although there has been much progress in the area of facial expression\nrecognition (FER), most existing methods suffer when presented with images that\nhave been captured from viewing angles that are non-frontal and substantially\ndifferent from those used in the training process. In this paper, we propose\nViewFX, a novel view-invariant FER framework based on contrastive learning,\ncapable of accurately classifying facial expressions regardless of the input\nviewing angles during inference. ViewFX learns view-invariant features of\nexpression using a proposed self-supervised contrastive loss which brings\ntogether different views of the same subject with a particular expression in\nthe embedding space. We also introduce a supervised contrastive loss to push\nthe learnt view-invariant features of each expression away from other\nexpressions. Since facial expressions are often distinguished with very subtle\ndifferences in the learned feature space, we incorporate the Barlow twins loss\nto reduce the redundancy and correlations of the representations in the learned\nrepresentations. The proposed method is a substantial extension of our\npreviously proposed CL-MEx, which only had a self-supervised loss. We test the\nproposed framework on two public multi-view facial expression recognition\ndatasets, KDEF and DDCF. The experiments demonstrate that our approach\noutperforms previous works in the area and sets a new state-of-the-art for both\ndatasets while showing considerably less sensitivity to challenging angles and\nthe number of output labels used for training. We also perform detailed\nsensitivity and ablation experiments to evaluate the impact of different\ncomponents of our model as well as its sensitivity to different parameters.",
            "author": [
                "Shuvendu Roy",
                "Ali Etemad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06852v1",
                "http://arxiv.org/pdf/2311.06852v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06851v3",
            "title": "Automatic Textual Normalization for Hate Speech Detection",
            "updated": "2023-12-04T15:34:29Z",
            "published": "2023-11-12T14:01:38Z",
            "summary": "Social media data is a valuable resource for research, yet it contains a wide\nrange of non-standard words (NSW). These irregularities hinder the effective\noperation of NLP tools. Current state-of-the-art methods for the Vietnamese\nlanguage address this issue as a problem of lexical normalization, involving\nthe creation of manual rules or the implementation of multi-staged deep\nlearning frameworks, which necessitate extensive efforts to craft intricate\nrules. In contrast, our approach is straightforward, employing solely a\nsequence-to-sequence (Seq2Seq) model. In this research, we provide a dataset\nfor textual normalization, comprising 2,181 human-annotated comments with an\ninter-annotator agreement of 0.9014. By leveraging the Seq2Seq model for\ntextual normalization, our results reveal that the accuracy achieved falls\nslightly short of 70%. Nevertheless, textual normalization enhances the\naccuracy of the Hate Speech Detection (HSD) task by approximately 2%,\ndemonstrating its potential to improve the performance of complex NLP tasks.\nOur dataset is accessible for research purposes.",
            "author": [
                "Anh Thi-Hoang Nguyen",
                "Dung Ha Nguyen",
                "Nguyet Thi Nguyen",
                "Khanh Thanh-Duy Ho",
                "Kiet Van Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06851v3",
                "http://arxiv.org/pdf/2311.06851v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06845v1",
            "title": "Sampler Scheduler for Diffusion Models",
            "updated": "2023-11-12T13:35:25Z",
            "published": "2023-11-12T13:35:25Z",
            "summary": "Diffusion modeling (DM) has high-quality generative performance, and the\nsampling problem is an important part of the DM performance. Thanks to\nefficient differential equation solvers, the sampling speed can be reduced\nwhile higher sampling quality is guaranteed. However, currently, there is a\ncontradiction in samplers for diffusion-based generative models: the mainstream\nsampler choices are diverse, each with its own characteristics in terms of\nperformance. However, only a single sampler algorithm can be specified on all\nsampling steps in the generative process. This often makes one torn between\nsampler choices; in other words, it makes it difficult to fully utilize the\nadvantages of each sampler. In this paper, we propose the feasibility of using\ndifferent samplers (ODE/SDE) on different sampling steps of the same sampling\nprocess based on analyzing and generalizing the updating formulas of each\nmainstream sampler, and experimentally demonstrate that such a multi-sampler\nscheduling improves the sampling results to some extent. In particular, we also\nverify that the combination of using SDE in the early sampling steps and ODE in\nthe later sampling steps solves the inherent problems previously caused by\nusing both singly. We show that our design changes improve the sampling\nefficiency and quality in previous work. For instance, when Number of Function\nEvaluations (NFE) = 24, the ODE Sampler Scheduler achieves a FID score of 1.91\non the CIFAR-10 dataset, compared to 2.02 for DPM++ 2M, 1.97 for DPM2, and\n11.90 for Heun for the same NFE. Meanwhile the Sampler Scheduler with the\ncombined scheduling of SDE and ODE reaches 1.899, compared to 18.63 for Euler\na, 3.14 for DPM2 a and 23.14 for DPM++ SDE.",
            "author": [
                "Zitong Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06845v1",
                "http://arxiv.org/pdf/2311.06845v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14705v1",
            "title": "Ethics and Responsible AI Deployment",
            "updated": "2023-11-12T13:32:46Z",
            "published": "2023-11-12T13:32:46Z",
            "summary": "As Artificial Intelligence (AI) becomes more prevalent, protecting personal\nprivacy is a critical ethical issue that must be addressed. This article\nexplores the need for ethical AI systems that safeguard individual privacy\nwhile complying with ethical standards. By taking a multidisciplinary approach,\nthe research examines innovative algorithmic techniques such as differential\nprivacy, homomorphic encryption, federated learning, international regulatory\nframeworks, and ethical guidelines. The study concludes that these algorithms\neffectively enhance privacy protection while balancing the utility of AI with\nthe need to protect personal data. The article emphasises the importance of a\ncomprehensive approach that combines technological innovation with ethical and\nregulatory strategies to harness the power of AI in a way that respects and\nprotects individual privacy.",
            "author": [
                "Petar Radanliev",
                "Omar Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14705v1",
                "http://arxiv.org/pdf/2311.14705v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC",
                "cs.SI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06838v1",
            "title": "GIELLM: Japanese General Information Extraction Large Language Model\n  Utilizing Mutual Reinforcement Effect",
            "updated": "2023-11-12T13:30:38Z",
            "published": "2023-11-12T13:30:38Z",
            "summary": "Information Extraction (IE) stands as a cornerstone in natural language\nprocessing, traditionally segmented into distinct sub-tasks. The advent of\nLarge Language Models (LLMs) heralds a paradigm shift, suggesting the\nfeasibility of a singular model addressing multiple IE subtasks. In this vein,\nwe introduce the General Information Extraction Large Language Model (GIELLM),\nwhich integrates text Classification, Sentiment Analysis, Named Entity\nRecognition, Relation Extraction, and Event Extraction using a uniform\ninput-output schema. This innovation marks the first instance of a model\nsimultaneously handling such a diverse array of IE subtasks. Notably, the\nGIELLM leverages the Mutual Reinforcement Effect (MRE), enhancing performance\nin integrated tasks compared to their isolated counterparts. Our experiments\ndemonstrate State-of-the-Art (SOTA) results in five out of six Japanese mixed\ndatasets, significantly surpassing GPT-3.5-Turbo. Further, an independent\nevaluation using the novel Text Classification Relation and Event\nExtraction(TCREE) dataset corroborates the synergistic advantages of MRE in\ntext and word classification. This breakthrough paves the way for most IE\nsubtasks to be subsumed under a singular LLM framework. Specialized fine-tune\ntask-specific models are no longer needed.",
            "author": [
                "Chengguang Gan",
                "Qinghao Zhang",
                "Tatsunori Mori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06838v1",
                "http://arxiv.org/pdf/2311.06838v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06837v1",
            "title": "GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs\n  on Large Clusters",
            "updated": "2023-11-12T13:30:31Z",
            "published": "2023-11-12T13:30:31Z",
            "summary": "Graph neural networks (GNNs) are one of the most rapidly growing fields\nwithin deep learning. According to the growth in the dataset and the model size\nused for GNNs, an important problem is that it becomes nearly impossible to\nkeep the whole network on GPU memory. Among numerous attempts, distributed\ntraining is one popular approach to address the problem. However, due to the\nnature of GNNs, existing distributed approaches suffer from poor scalability,\nmainly due to the slow external server communications.\n  In this paper, we propose GraNNDis, an efficient distributed GNN training\nframework for training GNNs on large graphs and deep layers. GraNNDis\nintroduces three new techniques. First, shared preloading provides a training\nstructure for a cluster of multi-GPU servers. We suggest server-wise preloading\nof essential vertex dependencies to reduce the low-bandwidth external server\ncommunications. Second, we present expansion-aware sampling. Because shared\npreloading alone has limitations because of the neighbor explosion,\nexpansion-aware sampling reduces vertex dependencies that span across server\nboundaries. Third, we propose cooperative batching to create a unified\nframework for full-graph and minibatch training. It significantly reduces\nredundant memory usage in mini-batch training. From this, GraNNDis enables a\nreasonable trade-off between full-graph and mini-batch training through\nunification especially when the entire graph does not fit into the GPU memory.\nWith experiments conducted on a multi-server/multi-GPU cluster, we show that\nGraNNDis provides superior speedup over the state-of-the-art distributed GNN\ntraining frameworks.",
            "author": [
                "Jaeyong Song",
                "Hongsun Jang",
                "Jaewon Jung",
                "Youngsok Kim",
                "Jinho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06837v1",
                "http://arxiv.org/pdf/2311.06837v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06834v1",
            "title": "Osteoporosis Prediction from Hand and Wrist X-rays using Image\n  Segmentation and Self-Supervised Learning",
            "updated": "2023-11-12T13:19:00Z",
            "published": "2023-11-12T13:19:00Z",
            "summary": "Osteoporosis is a widespread and chronic metabolic bone disease that often\nremains undiagnosed and untreated due to limited access to bone mineral density\n(BMD) tests like Dual-energy X-ray absorptiometry (DXA). In response to this\nchallenge, current advancements are pivoting towards detecting osteoporosis by\nexamining alternative indicators from peripheral bone areas, with the goal of\nincreasing screening rates without added expenses or time. In this paper, we\npresent a method to predict osteoporosis using hand and wrist X-ray images,\nwhich are both widely accessible and affordable, though their link to DXA-based\ndata is not thoroughly explored. Initially, our method segments the ulnar,\nradius, and metacarpal bones using a foundational model for image segmentation.\nThen, we use a self-supervised learning approach to extract meaningful\nrepresentations without the need for explicit labels, and move on to classify\nosteoporosis in a supervised manner. Our method is evaluated on a dataset with\n192 individuals, cross-referencing their verified osteoporosis conditions\nagainst the standard DXA test. With a notable classification score (AUC=0.83),\nour model represents a pioneering effort in leveraging vision-based techniques\nfor osteoporosis identification from the peripheral skeleton sites.",
            "author": [
                "Hyungeun Lee",
                "Ung Hwang",
                "Seungwon Yu",
                "Chang-Hun Lee",
                "Kijung Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06834v1",
                "http://arxiv.org/pdf/2311.06834v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06830v1",
            "title": "A 50-spin surface acoustic wave Ising machine",
            "updated": "2023-11-12T13:06:58Z",
            "published": "2023-11-12T13:06:58Z",
            "summary": "Time-multiplexed Spinwave Ising Machines (SWIMs) have unveiled a route\ntowards miniaturized, low-cost, and low-power solvers of combinatorial\noptimization problems. While the number of supported spins is limited by the\nnonlinearity of the spinwave dispersion, other collective excitations, such as\nsurface acoustic waves (SAWs), offer a linear dispersion. Here, we demonstrate\nan all-to-all, fully FPGA reprogrammable, 50-spin surface acoustic wave-based\nIsing machine (SAWIM), using a 50-mm-long Lithium Niobate SAW delay line,\noff-the-shelf microwave components, and a low-cost FPGA. The SAWIM can solve\nany 50-spin MAX-CUT problem, with arbitrary coupling matrices, in less than 340\n$\\mu$s consuming only 0.62 mJ, corresponding to close to 3000 solutions per\nsecond and a figure of merit of 1610 solutions/W/s. We compare the SAWIM\ncomputational results with those of a 100-spin optical Coherent Ising machine\nand find a higher probability of solution. Moreover, we demonstrate that there\nis an optimum overall coupling strength between spins at which the probability\nof the exact solution reaches 100%. The SAWIM illustrates the general merits of\nsolid state wave-based time-multiplexed Ising machines in the microwave domain\nas versatile platforms for commercially feasible high-performance solvers of\ncombinatorial optimization problems.",
            "author": [
                "Artem Litvinenko",
                "Roman Khymyn",
                "Roman Ovcharov",
                "Johan \u00c5kerman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06830v1",
                "http://arxiv.org/pdf/2311.06830v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "90C27"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06829v1",
            "title": "Joint Design of Coding and Modulation for Digital Over-the-Air\n  Computation",
            "updated": "2023-11-12T12:55:21Z",
            "published": "2023-11-12T12:55:21Z",
            "summary": "Due to its high communication efficiency, over-the-air computation (AirComp)\nhas been expected to carry out various computing tasks in the next-generation\nwireless networks. However, up to now, most applications of AirComp are\nexplored in the analog domain, which limits the capability of AirComp in\nresisting the complex wireless environment, not to mention to integrate the\nAirComp technique to the existing universal communication standards, most of\nwhich are based on the digital system. In this paper, we propose a joint design\nof channel coding and digital modulation for digital AirComp transmission to\nattempt to reinforce the foundation for the application of AirComp in the\ndigital system. Specifically, we first propose a non-binary LDPC-based channel\ncoding scheme to enhance the error-correction capability of AirComp. Then, a\ndigital modulation scheme is proposed to achieve the number summation from\nmultiple transmitters via the lattice coding technique. We also provide\nsimulation results to demonstrate the feasibility and the performance of the\nproposed design.",
            "author": [
                "Xin Xie",
                "Cunqinq Hua",
                "Jianan Hong",
                "Yuejun Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06829v1",
                "http://arxiv.org/pdf/2311.06829v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06826v1",
            "title": "Fairness Hacking: The Malicious Practice of Shrouding Unfairness in\n  Algorithms",
            "updated": "2023-11-12T12:48:28Z",
            "published": "2023-11-12T12:48:28Z",
            "summary": "Fairness in machine learning (ML) is an ever-growing field of research due to\nthe manifold potential for harm from algorithmic discrimination. To prevent\nsuch harm, a large body of literature develops new approaches to quantify\nfairness. Here, we investigate how one can divert the quantification of\nfairness by describing a practice we call \"fairness hacking\" for the purpose of\nshrouding unfairness in algorithms. This impacts end-users who rely on learning\nalgorithms, as well as the broader community interested in fair AI practices.\nWe introduce two different categories of fairness hacking in reference to the\nestablished concept of p-hacking. The first category, intra-metric fairness\nhacking, describes the misuse of a particular metric by adding or removing\nsensitive attributes from the analysis. In this context, countermeasures that\nhave been developed to prevent or reduce p-hacking can be applied to similarly\nprevent or reduce fairness hacking. The second category of fairness hacking is\ninter-metric fairness hacking. Inter-metric fairness hacking is the search for\na specific fair metric with given attributes. We argue that countermeasures to\nprevent or reduce inter-metric fairness hacking are still in their infancy.\nFinally, we demonstrate both types of fairness hacking using real datasets. Our\npaper intends to serve as a guidance for discussions within the fair ML\ncommunity to prevent or reduce the misuse of fairness metrics, and thus reduce\noverall harm from ML applications.",
            "author": [
                "Kristof Meding",
                "Thilo Hagendorff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06826v1",
                "http://arxiv.org/pdf/2311.06826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06822v1",
            "title": "Cluster properties of heavy nuclei predicted with the\n  Barcelona-Catania-Paris-Madrid energy density functional",
            "updated": "2023-11-12T12:12:13Z",
            "published": "2023-11-12T12:12:13Z",
            "summary": "We study the cluster emission properties of 224Ra and 238Pu employing the\nBarcelona-Catania-Paris-Madrid (BCPM) energy density functional (EDF). Starting\nfrom two-dimensional potential energy surfaces, coexisting fission paths are\nidentified. A fission valley located at large octupole deformations,\ncorresponding to a highly-asymmetric mass distribution, is found in both\nnuclei. As the corresponding fragments are dominated by the presence of 208Pb,\nwe can relate this fission path to the emergence of cluster emission. Using the\noctupole moment as collective degree of freedom, we compute the cluster decay\nhalf-lives and study the impact of collective inertias, pairing strength and\ncollective zero-point energy. The agreement with experimental data resembles\nthe results obtained for spontaneous fission half-lives, indicating the\ncapability of BCPM to consistently describe a large variety of fission\nphenomena, including cluster emission.",
            "author": [
                "Samuel A. Giuliani",
                "Luis M. Robledo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06822v1",
                "http://arxiv.org/pdf/2311.06822v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06818v1",
            "title": "Cricket Player Profiling: Unraveling Strengths and Weaknesses Using Text\n  Commentary Data",
            "updated": "2023-11-12T11:51:05Z",
            "published": "2023-11-12T11:51:05Z",
            "summary": "Devising player-specific strategies in cricket necessitates a meticulous\nunderstanding of each player's unique strengths and weaknesses. Nevertheless,\nthe absence of a definitive computational approach to extract such insights\nfrom cricket players poses a significant challenge. This paper seeks to address\nthis gap by establishing computational models designed to extract the rules\ngoverning player strengths and weaknesses, thereby facilitating the development\nof tailored strategies for individual players. The complexity of this endeavor\nlies in several key areas: the selection of a suitable dataset, the precise\ndefinition of strength and weakness rules, the identification of an appropriate\nlearning algorithm, and the validation of the derived rules. To tackle these\nchallenges, we propose the utilization of unstructured data, specifically\ncricket text commentary, as a valuable resource for constructing comprehensive\nstrength and weakness rules for cricket players. We also introduce\ncomputationally feasible definitions for the construction of these rules, and\npresent a dimensionality reduction technique for the rule-building process. In\norder to showcase the practicality of this approach, we conduct an in-depth\nanalysis of cricket player strengths and weaknesses using a vast corpus of more\nthan one million text commentaries. Furthermore, we validate the constructed\nrules through two distinct methodologies: intrinsic and extrinsic. The outcomes\nof this research are made openly accessible, including the collected data,\nsource code, and results for over 250 cricket players, which can be accessed at\nhttps://bit.ly/2PKuzx8.",
            "author": [
                "Swarup Ranjan Behera",
                "Vijaya V. Saradhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06818v1",
                "http://arxiv.org/pdf/2311.06818v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06816v1",
            "title": "On original and latent space connectivity in deep neural networks",
            "updated": "2023-11-12T11:41:07Z",
            "published": "2023-11-12T11:41:07Z",
            "summary": "We study whether inputs from the same class can be connected by a continuous\npath, in original or latent representation space, such that all points on the\npath are mapped by the neural network model to the same class. Understanding\nhow the neural network views its own input space and how the latent spaces are\nstructured has value for explainability and robustness. We show that paths,\nlinear or nonlinear, connecting same-class inputs exist in all cases studied.",
            "author": [
                "Boyang Gu",
                "Anastasia Borovykh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06816v1",
                "http://arxiv.org/pdf/2311.06816v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06815v1",
            "title": "Evaluation of GPT-4 for chest X-ray impression generation: A reader\n  study on performance and perception",
            "updated": "2023-11-12T11:40:57Z",
            "published": "2023-11-12T11:40:57Z",
            "summary": "The remarkable generative capabilities of multimodal foundation models are\ncurrently being explored for a variety of applications. Generating radiological\nimpressions is a challenging task that could significantly reduce the workload\nof radiologists. In our study we explored and analyzed the generative abilities\nof GPT-4 for Chest X-ray impression generation. To generate and evaluate\nimpressions of chest X-rays based on different input modalities (image, text,\ntext and image), a blinded radiological report was written for 25-cases of the\npublicly available NIH-dataset. GPT-4 was given image, finding section or both\nsequentially to generate an input dependent impression. In a blind randomized\nreading, 4-radiologists rated the impressions and were asked to classify the\nimpression origin (Human, AI), providing justification for their decision.\nLastly text model evaluation metrics and their correlation with the\nradiological score (summation of the 4 dimensions) was assessed. According to\nthe radiological score, the human-written impression was rated highest,\nalthough not significantly different to text-based impressions. The automated\nevaluation metrics showed moderate to substantial correlations to the\nradiological score for the image impressions, however individual scores were\nhighly divergent among inputs, indicating insufficient representation of\nradiological quality. Detection of AI-generated impressions varied by input and\nwas 61% for text-based impressions. Impressions classified as AI-generated had\nsignificantly worse radiological scores even when written by a radiologist,\nindicating potential bias. Our study revealed significant discrepancies between\na radiological assessment and common automatic evaluation metrics depending on\nthe model input. The detection of AI-generated findings is subject to bias that\nhighly rated impressions are perceived as human-written.",
            "author": [
                "Sebastian Ziegelmayer",
                "Alexander W. Marka",
                "Nicolas Lenhart",
                "Nadja Nehls",
                "Stefan Reischl",
                "Felix Harder",
                "Andreas Sauter",
                "Marcus Makowski",
                "Markus Graf",
                "Joshua Gawlitza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06815v1",
                "http://arxiv.org/pdf/2311.06815v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06814v1",
            "title": "Revealing the effects of laser beam shaping on melt pool behaviour in\n  conduction-mode laser melting",
            "updated": "2023-11-12T11:34:47Z",
            "published": "2023-11-12T11:34:47Z",
            "summary": "Laser beam shaping offers remarkable possibilities to control and optimise\nprocess stability and tailor material properties and structure in laser-based\nwelding and additive manufacturing. However, little is known about the\ninfluence of laser beam shaping on the complex melt-pool behaviour, solidified\nmelt-track bead profile and microstructural grain morphology in laser material\nprocessing. A simulation-based approach is utilised in the present work to\nstudy the effects of laser beam intensity profile and angle of incidence on the\nmelt-pool behaviour in conduction-mode laser melting of stainless steel 316L\nplates. The present high-fidelity physics-based computational model accounts\nfor crucial physical phenomena in laser material processing such as complex\nlaser-matter interaction, solidification and melting, heat and fluid flow\ndynamics, and free-surface oscillations. Experiments were carried out using\ndifferent laser beam shapes and the validity of the numerical predictions is\ndemonstrated. The results indicate that for identical processing parameters,\nreshaping the laser beam leads to notable changes in the thermal and fluid flow\nfields in the melt pool, affecting the melt-track bead profile and\nsolidification microstructure. The columnar-to-equiaxed transition is discussed\nfor different laser-intensity profiles.",
            "author": [
                "Amin Ebrahimi",
                "Mohammad Sattari",
                "Aravind Babu",
                "Arjun Sood",
                "Gert-willem R\u00f6mer",
                "Marcel Hermans"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jmrt.2023.11.046",
                "http://arxiv.org/abs/2311.06814v1",
                "http://arxiv.org/pdf/2311.06814v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06812v1",
            "title": "MANSY: Generalizing Neural Adaptive Immersive Video Streaming With\n  Ensemble and Representation Learning",
            "updated": "2023-11-12T11:20:25Z",
            "published": "2023-11-12T11:20:25Z",
            "summary": "The popularity of immersive videos has prompted extensive research into\nneural adaptive tile-based streaming to optimize video transmission over\nnetworks with limited bandwidth. However, the diversity of users' viewing\npatterns and Quality of Experience (QoE) preferences has not been fully\naddressed yet by existing neural adaptive approaches for viewport prediction\nand bitrate selection. Their performance can significantly deteriorate when\nusers' actual viewing patterns and QoE preferences differ considerably from\nthose observed during the training phase, resulting in poor generalization. In\nthis paper, we propose MANSY, a novel streaming system that embraces user\ndiversity to improve generalization. Specifically, to accommodate users'\ndiverse viewing patterns, we design a Transformer-based viewport prediction\nmodel with an efficient multi-viewport trajectory input output architecture\nbased on implicit ensemble learning. Besides, we for the first time combine the\nadvanced representation learning and deep reinforcement learning to train the\nbitrate selection model to maximize diverse QoE objectives, enabling the model\nto generalize across users with diverse preferences. Extensive experiments\ndemonstrate that MANSY outperforms state-of-the-art approaches in viewport\nprediction accuracy and QoE improvement on both trained and unseen viewing\npatterns and QoE preferences, achieving better generalization.",
            "author": [
                "Duo Wu",
                "Panlong Wu",
                "Miao Zhang",
                "Fangxin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06812v1",
                "http://arxiv.org/pdf/2311.06812v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06807v1",
            "title": "On the Robustness of Question Rewriting Systems to Questions of Varying\n  Hardness",
            "updated": "2023-11-12T11:09:30Z",
            "published": "2023-11-12T11:09:30Z",
            "summary": "In conversational question answering (CQA), the task of question\nrewriting~(QR) in context aims to rewrite a context-dependent question into an\nequivalent self-contained question that gives the same answer. In this paper,\nwe are interested in the robustness of a QR system to questions varying in\nrewriting hardness or difficulty. Since there is a lack of questions classified\nbased on their rewriting hardness, we first propose a heuristic method to\nautomatically classify questions into subsets of varying hardness, by measuring\nthe discrepancy between a question and its rewrite. To find out what makes\nquestions hard or easy for rewriting, we then conduct a human evaluation to\nannotate the rewriting hardness of questions. Finally, to enhance the\nrobustness of QR systems to questions of varying hardness, we propose a novel\nlearning framework for QR that first trains a QR model independently on each\nsubset of questions of a certain level of hardness, then combines these QR\nmodels as one joint model for inference. Experimental results on two datasets\nshow that our framework improves the overall performance compared to the\nbaselines.",
            "author": [
                "Hai Ye",
                "Hwee Tou Ng",
                "Wenjuan Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06807v1",
                "http://arxiv.org/pdf/2311.06807v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06805v1",
            "title": "Tunable Soft Prompts are Messengers in Federated Learning",
            "updated": "2023-11-12T11:01:10Z",
            "published": "2023-11-12T11:01:10Z",
            "summary": "Federated learning (FL) enables multiple participants to collaboratively\ntrain machine learning models using decentralized data sources, alleviating\nprivacy concerns that arise from directly sharing local data. However, the lack\nof model privacy protection in FL becomes an unneglectable challenge,\nespecially when people want to federally finetune models based on a proprietary\nlarge language model. In this study, we propose a novel FL training approach\nthat accomplishes information exchange among participants via tunable soft\nprompts. These soft prompts, updated and transmitted between the server and\nclients, assume the role of the global model parameters and serve as messengers\nto deliver useful knowledge from the local data and global model. As the global\nmodel itself is not required to be shared and the local training is conducted\nbased on an auxiliary model with fewer parameters than the global model, the\nproposed approach provides protection for the global model while reducing\ncommunication and computation costs in FL. Extensive experiments show the\neffectiveness of the proposed approach compared to several baselines. We have\nreleased the source code at\n\\url{https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp}.",
            "author": [
                "Chenhe Dong",
                "Yuexiang Xie",
                "Bolin Ding",
                "Ying Shen",
                "Yaliang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06805v1",
                "http://arxiv.org/pdf/2311.06805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06802v1",
            "title": "A hybrid discrete exterior calculus and finite difference method for\n  anelastic convection in spherical shells",
            "updated": "2023-11-12T10:45:49Z",
            "published": "2023-11-12T10:45:49Z",
            "summary": "The present work develops, verifies, and benchmarks a hybrid discrete\nexterior calculus and finite difference (DEC-FD) method for density-stratified\nthermal convection in spherical shells. Discrete exterior calculus (DEC) is\nnotable for its coordinate independence and structure preservation properties.\nThe hybrid DEC-FD method for Boussinesq convection has been developed by\nMantravadi et al. (Mantravadi, B., Jagad, P., & Samtaney, R. (2023). A hybrid\ndiscrete exterior calculus and finite difference method for Boussinesq\nconvection in spherical shells. Journal of Computational Physics, 491, 112397).\nMotivated by astrophysics problems, we extend this method assuming anelastic\nconvection, which retains density stratification; this has been widely used for\ndecades to understand thermal convection in stars and giant planets. In the\npresent work, the governing equations are splitted into surface and radial\ncomponents and discrete anelastic equations are derived by replacing spherical\nsurface operators with DEC and radial operators with FD operators. The novel\nfeature of this work is the discretization of anelastic equations with the\nDEC-FD method and the assessment of a hybrid solver for density-stratified\nthermal convection in spherical shells. The discretized anelastic equations are\nverified using the method of manufactured solution (MMS). We performed a series\nof three-dimensional convection simulations in a spherical shell geometry and\nexamined the effect of density ratio on convective flow structures and energy\ndynamics. The present observations are in agreement with the benchmark models.",
            "author": [
                "Hamid Hassan Khan",
                "Pankaj Jagad",
                "Matteo Parsani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06802v1",
                "http://arxiv.org/pdf/2311.06802v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06801v1",
            "title": "A Comprehensive Survey On Client Selections in Federated Learning",
            "updated": "2023-11-12T10:40:43Z",
            "published": "2023-11-12T10:40:43Z",
            "summary": "Federated Learning (FL) is a rapidly growing field in machine learning that\nallows data to be trained across multiple decentralized devices. The selection\nof clients to participate in the training process is a critical factor for the\nperformance of the overall system. In this survey, we provide a comprehensive\noverview of the state-of-the-art client selection techniques in FL, including\ntheir strengths and limitations, as well as the challenges and open issues that\nneed to be addressed. We cover conventional selection techniques such as random\nselection where all or partial random of clients is used for the trained. We\nalso cover performance-aware selections and as well as resource-aware\nselections for resource-constrained networks and heterogeneous networks. We\nalso discuss the usage of client selection in model security enhancement.\nLastly, we discuss open issues and challenges related to clients selection in\ndynamic constrained, and heterogeneous networks.",
            "author": [
                "Ala Gouissem",
                "Zina Chkirbene",
                "Ridha Hamila"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06801v1",
                "http://arxiv.org/pdf/2311.06801v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06799v1",
            "title": "Correlated disorder in entropic crystals",
            "updated": "2023-11-12T10:21:11Z",
            "published": "2023-11-12T10:21:11Z",
            "summary": "We report computational evidence of a new type of disordered phase in\ncrystals resulting from entropy driven self-assembly of hard convex polyhedra.\nThe disorder was reflected in the orientations of the anisotropic particles and\nnot in the positions of the centers of geometry. Despite the lack of order,\nparticle orientations were not random and exhibited strong correlations. The\ncorrelations were manifested in terms of ``quantized'' rotational motions in a\nfixed number of absolute orientations, while maintaining equal populations and\nspecific measure of pairwise angular differences among the discrete values.\nThis gave rise to a discretely mobile phase in the low density solid and a\nquenched disordered state at high pressure. This finding can be interpreted as\nthe simplest example of correlated disorder in crystalline materials.",
            "author": [
                "Sumitava Kundu",
                "Kaustav Chakraborty",
                "Avisek Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06799v1",
                "http://arxiv.org/pdf/2311.06799v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.mtrl-sci",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06798v1",
            "title": "MetaMix: Meta-state Precision Searcher for Mixed-precision Activation\n  Quantization",
            "updated": "2023-11-12T10:21:04Z",
            "published": "2023-11-12T10:21:04Z",
            "summary": "Mixed-precision quantization of efficient networks often suffer from\nactivation instability encountered in the exploration of bit selections. To\naddress this problem, we propose a novel method called MetaMix which consists\nof bit selection and weight training phases. The bit selection phase iterates\ntwo steps, (1) the mixed-precision-aware weight update, and (2) the bit-search\ntraining with the fixed mixed-precision-aware weights, both of which combined\nreduce activation instability in mixed-precision quantization and contribute to\nfast and high-quality bit selection. The weight training phase exploits the\nweights and step sizes trained in the bit selection phase and fine-tunes them\nthereby offering fast training. Our experiments with efficient and\nhard-to-quantize networks, i.e., MobileNet v2 and v3, and ResNet-18 on ImageNet\nshow that our proposed method pushes the boundary of mixed-precision\nquantization, in terms of accuracy vs. operations, by outperforming both mixed-\nand single-precision SOTA methods.",
            "author": [
                "Han-Byul Kim",
                "Joo Hyung Lee",
                "Sungjoo Yoo",
                "Hong-Seok Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06798v1",
                "http://arxiv.org/pdf/2311.06798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06797v1",
            "title": "Dual-Branch Reconstruction Network for Industrial Anomaly Detection with\n  RGB-D Data",
            "updated": "2023-11-12T10:19:14Z",
            "published": "2023-11-12T10:19:14Z",
            "summary": "Unsupervised anomaly detection methods are at the forefront of industrial\nanomaly detection efforts and have made notable progress. Previous work\nprimarily used 2D information as input, but multi-modal industrial anomaly\ndetection based on 3D point clouds and RGB images is just beginning to emerge.\nThe regular approach involves utilizing large pre-trained models for feature\nrepresentation and storing them in memory banks. However, the above methods\nrequire a longer inference time and higher memory usage, which cannot meet the\nreal-time requirements of the industry. To overcome these issues, we propose a\nlightweight dual-branch reconstruction network(DBRN) based on RGB-D input,\nlearning the decision boundary between normal and abnormal examples. The\nrequirement for alignment between the two modalities is eliminated by using\ndepth maps instead of point cloud input. Furthermore, we introduce an\nimportance scoring module in the discriminative network to assist in fusing\nfeatures from these two modalities, thereby obtaining a comprehensive\ndiscriminative result. DBRN achieves 92.8% AUROC with high inference efficiency\non the MVTec 3D-AD dataset without large pre-trained models and memory banks.",
            "author": [
                "Chenyang Bi",
                "Yueyang Li",
                "Haichi Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06797v1",
                "http://arxiv.org/pdf/2311.06797v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06796v1",
            "title": "Deep Perspective Transformation Based Vehicle Localization on Bird's Eye\n  View",
            "updated": "2023-11-12T10:16:42Z",
            "published": "2023-11-12T10:16:42Z",
            "summary": "An accurate understanding of a self-driving vehicle's surrounding environment\nis crucial for its navigation system. To enhance the effectiveness of existing\nalgorithms and facilitate further research, it is essential to provide\ncomprehensive data to the routing system. Traditional approaches rely on\ninstalling multiple sensors to simulate the environment, leading to high costs\nand complexity. In this paper, we propose an alternative solution by generating\na top-down representation of the scene, enabling the extraction of distances\nand directions of other cars relative to the ego vehicle. We introduce a new\nsynthesized dataset that offers extensive information about the ego vehicle and\nits environment in each frame, providing valuable resources for similar\ndownstream tasks. Additionally, we present an architecture that transforms\nperspective view RGB images into bird's-eye-view maps with segmented\nsurrounding vehicles. This approach offers an efficient and cost-effective\nmethod for capturing crucial environmental information for self-driving cars.\nCode and dataset are available at\nhttps://github.com/IPM-HPC/Perspective-BEV-Transformer.",
            "author": [
                "Abtin Mahyar",
                "Hossein Motamednia",
                "Dara Rahmati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06796v1",
                "http://arxiv.org/pdf/2311.06796v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06794v1",
            "title": "CL-Flow:Strengthening the Normalizing Flows by Contrastive Learning for\n  Better Anomaly Detection",
            "updated": "2023-11-12T10:07:03Z",
            "published": "2023-11-12T10:07:03Z",
            "summary": "In the anomaly detection field, the scarcity of anomalous samples has\ndirected the current research emphasis towards unsupervised anomaly detection.\nWhile these unsupervised anomaly detection methods offer convenience, they also\noverlook the crucial prior information embedded within anomalous samples.\nMoreover, among numerous deep learning methods, supervised methods generally\nexhibit superior performance compared to unsupervised methods. Considering the\nreasons mentioned above, we propose a self-supervised anomaly detection\napproach that combines contrastive learning with 2D-Flow to achieve more\nprecise detection outcomes and expedited inference processes. On one hand, we\nintroduce a novel approach to anomaly synthesis, yielding anomalous samples in\naccordance with authentic industrial scenarios, alongside their surrogate\nannotations. On the other hand, having obtained a substantial number of\nanomalous samples, we enhance the 2D-Flow framework by incorporating\ncontrastive learning, leveraging diverse proxy tasks to fine-tune the network.\nOur approach enables the network to learn more precise mapping relationships\nfrom self-generated labels while retaining the lightweight characteristics of\nthe 2D-Flow. Compared to mainstream unsupervised approaches, our\nself-supervised method demonstrates superior detection accuracy, fewer\nadditional model parameters, and faster inference speed. Furthermore, the\nentire training and inference process is end-to-end. Our approach showcases new\nstate-of-the-art results, achieving a performance of 99.6\\% in image-level\nAUROC on the MVTecAD dataset and 96.8\\% in image-level AUROC on the BTAD\ndataset.",
            "author": [
                "Shunfeng Wang",
                "Yueyang Li",
                "Haichi Luo",
                "Chenyang Bi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06794v1",
                "http://arxiv.org/pdf/2311.06794v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06792v1",
            "title": "IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion\n  Models",
            "updated": "2023-11-12T10:03:32Z",
            "published": "2023-11-12T10:03:32Z",
            "summary": "We present a diffusion-based image morphing approach with\nperceptually-uniform sampling (IMPUS) that produces smooth, direct, and\nrealistic interpolations given an image pair. A latent diffusion model has\ndistinct conditional distributions and data embeddings for each of the two\nimages, especially when they are from different classes. To bridge this gap, we\ninterpolate in the locally linear and continuous text embedding space and\nGaussian latent space. We first optimize the endpoint text embeddings and then\nmap the images to the latent space using a probability flow ODE. Unlike\nexisting work that takes an indirect morphing path, we show that the model\nadaptation yields a direct path and suppresses ghosting artifacts in the\ninterpolated images. To achieve this, we propose an adaptive bottleneck\nconstraint based on a novel relative perceptual path diversity score that\nautomatically controls the bottleneck size and balances the diversity along the\npath with its directness. We also propose a perceptually-uniform sampling\ntechnique that enables visually smooth changes between the interpolated images.\nExtensive experiments validate that our IMPUS can achieve smooth, direct, and\nrealistic image morphing and be applied to other image generation tasks.",
            "author": [
                "Zhaoyuan Yang",
                "Zhengyang Yu",
                "Zhiwei Xu",
                "Jaskirat Singh",
                "Jing Zhang",
                "Dylan Campbell",
                "Peter Tu",
                "Richard Hartley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06792v1",
                "http://arxiv.org/pdf/2311.06792v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06791v2",
            "title": "InfMLLM: A Unified Framework for Visual-Language Tasks",
            "updated": "2023-12-06T11:06:06Z",
            "published": "2023-11-12T09:58:16Z",
            "summary": "Large language models (LLMs) have proven their remarkable versatility in\nhandling a comprehensive range of language-centric applications. To expand\nLLMs' capabilities to a broader spectrum of modal inputs, multimodal large\nlanguage models (MLLMs) have attracted growing interest. This work delves into\nenabling LLMs to tackle more vision-language-related tasks, particularly image\ncaptioning, visual question answering (VQA,) and visual grounding. To this end,\nwe implemented a three-stage training scheme: starting with lightweight\nalignment pretraining, then moderate-weight multitask hybrid training, and\nfinally, LLM fine-tuning to improve instruction following capability.\nThroughout the training process, the requirements on GPU memory gradually\nincrease. To effectively manage the number of visual embeddings passed to the\nLLM while preserving their positional information, we introduce a\nstraightforward visual adapter module dubbed pool-adapter. Our experiments\ndemonstrate that preserving the positional information of visual embeddings\nthrough the pool-adapter is particularly beneficial for tasks like visual\ngrounding. We name our proposed approach InfMLLM and have evaluated it\nextensively on various benchmark datasets. Our results demonstrate that InfMLLM\nachieves either state-of-the-art (SOTA) performance or performance comparable\nto recent MLLMs. The code and model will be made open-source at:\n\\url{https://github.com/mightyzau/InfMLLM}.",
            "author": [
                "Qiang Zhou",
                "Zhibin Wang",
                "Wei Chu",
                "Yinghui Xu",
                "Hao Li",
                "Yuan Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06791v2",
                "http://arxiv.org/pdf/2311.06791v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06786v1",
            "title": "Explainability of Vision Transformers: A Comprehensive Review and New\n  Perspectives",
            "updated": "2023-11-12T09:23:40Z",
            "published": "2023-11-12T09:23:40Z",
            "summary": "Transformers have had a significant impact on natural language processing and\nhave recently demonstrated their potential in computer vision. They have shown\npromising results over convolution neural networks in fundamental computer\nvision tasks. However, the scientific community has not fully grasped the inner\nworkings of vision transformers, nor the basis for their decision-making, which\nunderscores the importance of explainability methods. Understanding how these\nmodels arrive at their decisions not only improves their performance but also\nbuilds trust in AI systems. This study explores different explainability\nmethods proposed for visual transformers and presents a taxonomy for organizing\nthem according to their motivations, structures, and application scenarios. In\naddition, it provides a comprehensive review of evaluation criteria that can be\nused for comparing explanation results, as well as explainability tools and\nframeworks. Finally, the paper highlights essential but unexplored aspects that\ncan enhance the explainability of visual transformers, and promising research\ndirections are suggested for future investment.",
            "author": [
                "Rojina Kashefi",
                "Leili Barekatain",
                "Mohammad Sabokrou",
                "Fatemeh Aghaeipoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06786v1",
                "http://arxiv.org/pdf/2311.06786v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06783v1",
            "title": "Q-Instruct: Improving Low-level Visual Abilities for Multi-modality\n  Foundation Models",
            "updated": "2023-11-12T09:10:51Z",
            "published": "2023-11-12T09:10:51Z",
            "summary": "Multi-modality foundation models, as represented by GPT-4V, have brought a\nnew paradigm for low-level visual perception and understanding tasks, that can\nrespond to a broad range of natural human instructions in a model. While\nexisting foundation models have shown exciting potentials on low-level visual\ntasks, their related abilities are still preliminary and need to be improved.\nIn order to enhance these models, we conduct a large-scale subjective\nexperiment collecting a vast number of real human feedbacks on low-level\nvision. Each feedback follows a pathway that starts with a detailed description\non the low-level visual appearance (*e.g. clarity, color, brightness* of an\nimage, and ends with an overall conclusion, with an average length of 45 words.\nThe constructed **Q-Pathway** dataset includes 58K detailed human feedbacks on\n18,973 images with diverse low-level appearance. Moreover, to enable foundation\nmodels to robustly respond to diverse types of questions, we design a\nGPT-participated conversion to process these feedbacks into diverse-format 200K\ninstruction-response pairs. Experimental results indicate that the\n**Q-Instruct** consistently elevates low-level perception and understanding\nabilities across several foundational models. We anticipate that our datasets\ncan pave the way for a future that general intelligence can perceive,\nunderstand low-level visual appearance and evaluate visual quality like a\nhuman. Our dataset, model zoo, and demo is published at:\nhttps://q-future.github.io/Q-Instruct.",
            "author": [
                "Haoning Wu",
                "Zicheng Zhang",
                "Erli Zhang",
                "Chaofeng Chen",
                "Liang Liao",
                "Annan Wang",
                "Kaixin Xu",
                "Chunyi Li",
                "Jingwen Hou",
                "Guangtao Zhai",
                "Geng Xue",
                "Wenxiu Sun",
                "Qiong Yan",
                "Weisi Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06783v1",
                "http://arxiv.org/pdf/2311.06783v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06780v1",
            "title": "A Strategyproof Mechanism for Ownership Restructuring in Privately Owned\n  Assets",
            "updated": "2023-11-12T08:56:47Z",
            "published": "2023-11-12T08:56:47Z",
            "summary": "It is unclear how to restructure ownership when an asset is privately held,\nand there is uncertainty about the owners' subjective valuations. When\nownership is divided equally between two owners, a commonly used mechanism is\ncalled a BMBY mechanism. This mechanism works as follows: each owner can\ninitiate a BMBY by naming her price. Once an owner declares a price, the other\nchooses to sell his holdings or buy the shares of the initiator at the given\nprice. This mechanism is simple and tractable; however, it does not elicit\nactual owner valuations, does not guarantee an efficient allocation, and, most\nimportantly, is limited to an equal partnership of two owners. In this paper,\nwe extend this rationale to a multi-owner setting. Our proposed mechanism\nelicits owner valuations truthfully. Additionally, our proposed mechanism\nexhibits several desirable traits: it is easy to implement, budget balanced,\nrobust to collusion (weakly group strategyproof), individually rational, and\nex-post efficient.",
            "author": [
                "Gal Danino",
                "Moran Koren",
                "Omer Madmon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06780v1",
                "http://arxiv.org/pdf/2311.06780v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06776v2",
            "title": "Galclaim: A tool to identify host galaxy of astrophysical transient\n  sources",
            "updated": "2023-11-14T08:25:29Z",
            "published": "2023-11-12T08:42:51Z",
            "summary": "The Galclaim software is designed to identify association between\nastrophysical transient sources and host galaxy by computing the probability of\nchance alignment. It is distributed as an open source Python software. It is\nalready used to identify, confirm or reject host galaxy candidates of GRBs and\nto validate or invalidate transient candidates in astrophysical observations.\nSuch tools are also very useful to characterise archived transient candidates\nin large sky survey telescopes.",
            "author": [
                "J. -G. Ducoin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06776v2",
                "http://arxiv.org/pdf/2311.06776v2"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06772v1",
            "title": "ChatAnything: Facetime Chat with LLM-Enhanced Personas",
            "updated": "2023-11-12T08:29:41Z",
            "published": "2023-11-12T08:29:41Z",
            "summary": "In this technical report, we target generating anthropomorphized personas for\nLLM-based characters in an online manner, including visual appearance,\npersonality and tones, with only text descriptions. To achieve this, we first\nleverage the in-context learning capability of LLMs for personality generation\nby carefully designing a set of system prompts. We then propose two novel\nconcepts: the mixture of voices (MoV) and the mixture of diffusers (MoD) for\ndiverse voice and appearance generation. For MoV, we utilize the text-to-speech\n(TTS) algorithms with a variety of pre-defined tones and select the most\nmatching one based on the user-provided text description automatically. For\nMoD, we combine the recent popular text-to-image generation techniques and\ntalking head algorithms to streamline the process of generating talking\nobjects. We termed the whole framework as ChatAnything. With it, users could be\nable to animate anything with any personas that are anthropomorphic using just\na few text inputs. However, we have observed that the anthropomorphic objects\nproduced by current generative models are often undetectable by pre-trained\nface landmark detectors, leading to failure of the face motion generation, even\nif these faces possess human-like appearances because those images are nearly\nseen during the training (e.g., OOD samples). To address this issue, we\nincorporate pixel-level guidance to infuse human face landmarks during the\nimage generation phase. To benchmark these metrics, we have built an evaluation\ndataset. Based on it, we verify that the detection rate of the face landmark is\nsignificantly increased from 57.0% to 92.5% thus allowing automatic face\nanimation based on generated speech content. The code and more results can be\nfound at https://chatanything.github.io/.",
            "author": [
                "Yilin Zhao",
                "Xinbin Yuan",
                "Shanghua Gao",
                "Zhijie Lin",
                "Qibin Hou",
                "Jiashi Feng",
                "Daquan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06772v1",
                "http://arxiv.org/pdf/2311.06772v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06771v1",
            "title": "Learning Globally Optimized Language Structure via Adversarial Training",
            "updated": "2023-11-12T08:21:43Z",
            "published": "2023-11-12T08:21:43Z",
            "summary": "Recent work has explored integrating autoregressive language models with\nenergy-based models (EBMs) to enhance text generation capabilities. However,\nlearning effective EBMs for text is challenged by the discrete nature of\nlanguage. This work proposes an adversarial training strategy to address\nlimitations in prior efforts. Specifically, an iterative adversarial attack\nalgorithm is presented to generate negative samples for training the EBM by\nperturbing text from the autoregressive model. This aims to enable the EBM to\nsuppress spurious modes outside the support of the data distribution.\nExperiments on an arithmetic sequence generation task demonstrate that the\nproposed adversarial training approach can substantially enhance the quality of\ngenerated sequences compared to prior methods. The results highlight the\npromise of adversarial techniques to improve discrete EBM training. Key\ncontributions include: (1) an adversarial attack strategy tailored to text to\ngenerate negative samples, circumventing MCMC limitations; (2) an adversarial\ntraining algorithm for EBMs leveraging these attacks; (3) empirical validation\nof performance improvements on a sequence generation task.",
            "author": [
                "Xuwang Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06771v1",
                "http://arxiv.org/pdf/2311.06771v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06770v1",
            "title": "Compressive Sensing-Based Grant-Free Massive Access for 6G Massive\n  Communication",
            "updated": "2023-11-12T08:20:21Z",
            "published": "2023-11-12T08:20:21Z",
            "summary": "The advent of the sixth-generation (6G) of wireless communications has given\nrise to the necessity to connect vast quantities of heterogeneous wireless\ndevices, which requires advanced system capabilities far beyond existing\nnetwork architectures. In particular, such massive communication has been\nrecognized as a prime driver that can empower the 6G vision of future\nubiquitous connectivity, supporting Internet of Human-Machine-Things for which\nmassive access is critical. This paper surveys the most recent advances toward\nmassive access in both academic and industry communities, focusing primarily on\nthe promising compressive sensing-based grant-free massive access paradigm. We\nfirst specify the limitations of existing random access schemes and reveal that\nthe practical implementation of massive communication relies on a dramatically\ndifferent random access paradigm from the current ones mainly designed for\nhuman-centric communications. Then, a compressive sensing-based grant-free\nmassive access roadmap is presented, where the evolutions from single-antenna\nto large-scale antenna array-based base stations, from single-station to\ncooperative massive multiple-input multiple-output systems, and from unsourced\nto sourced random access scenarios are detailed. Finally, we discuss the key\nchallenges and open issues to shed light on the potential future research\ndirections of grant-free massive access.",
            "author": [
                "Zhen Gao",
                "Malong Ke",
                "Yikun Mei",
                "Li Qiao",
                "Sheng Chen",
                "Derrick Wing Kwan Ng",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06770v1",
                "http://arxiv.org/pdf/2311.06770v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06769v1",
            "title": "Learning Predictive Safety Filter via Decomposition of Robust Invariant\n  Set",
            "updated": "2023-11-12T08:11:28Z",
            "published": "2023-11-12T08:11:28Z",
            "summary": "Ensuring safety of nonlinear systems under model uncertainty and external\ndisturbances is crucial, especially for real-world control tasks. Predictive\nmethods such as robust model predictive control (RMPC) require solving\nnonconvex optimization problems online, which leads to high computational\nburden and poor scalability. Reinforcement learning (RL) works well with\ncomplex systems, but pays the price of losing rigorous safety guarantee. This\npaper presents a theoretical framework that bridges the advantages of both RMPC\nand RL to synthesize safety filters for nonlinear systems with state- and\naction-dependent uncertainty. We decompose the robust invariant set (RIS) into\ntwo parts: a target set that aligns with terminal region design of RMPC, and a\nreach-avoid set that accounts for the rest of RIS. We propose a policy\niteration approach for robust reach-avoid problems and establish its monotone\nconvergence. This method sets the stage for an adversarial actor-critic deep RL\nalgorithm, which simultaneously synthesizes a reach-avoid policy network, a\ndisturbance policy network, and a reach-avoid value network. The learned\nreach-avoid policy network is utilized to generate nominal trajectories for\nonline verification, which filters potentially unsafe actions that may drive\nthe system into unsafe regions when worst-case disturbances are applied. We\nformulate a second-order cone programming (SOCP) approach for online\nverification using system level synthesis, which optimizes for the worst-case\nreach-avoid value of any possible trajectories. The proposed safety filter\nrequires much lower computational complexity than RMPC and still enjoys\npersistent robust safety guarantee. The effectiveness of our method is\nillustrated through a numerical example.",
            "author": [
                "Zeyang Li",
                "Chuxiong Hu",
                "Weiye Zhao",
                "Changliu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06769v1",
                "http://arxiv.org/pdf/2311.06769v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16164v1",
            "title": "Digital Transformation of High Voltage Isolation Control and Monitoring\n  System for HVE-400 Ion Implanter",
            "updated": "2023-11-12T08:07:55Z",
            "published": "2023-11-12T08:07:55Z",
            "summary": "HVE-400 ion implanter is special ion implantation equipment for semiconductor\nmaterials boron and phosphorus doping. The ion source and extraction deflection\nsystem are at high voltage platform, while the corresponding control system is\nat ground voltage position. The control signals and measurement signals of\nvarious parameters at the high-voltage end need to be transmitted between\nground voltage and high voltage through optical fibers to isolate high voltage.\nUpgrading is carried out due to the aging of the optical fiber transmission\ncontrol and monitoring system, which cannot work stably. The transformation\nreplaces the original distributed single-point control method with an advanced\ndistributed centralized control method, and integrates all control and\nmonitoring functions into an industrial control computer for digital operation\nand display. In the computer software, two kinds of automatic calculation of\nion mass number are designed. After upgrading, the implanter high-voltage\nplatform control and monitoring system features digitalization, centralized\ncontrol, high reliability, strong anti-interference, fast communication speed,\nand easy operation.",
            "author": [
                "Chengbo Li",
                "Xuepeng Sun",
                "Zhiguo Liu",
                "Chungang Guo",
                "Xiaoming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16164v1",
                "http://arxiv.org/pdf/2311.16164v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07618v1",
            "title": "Large Language Models' Understanding of Math: Source Criticism and\n  Extrapolation",
            "updated": "2023-11-12T07:52:32Z",
            "published": "2023-11-12T07:52:32Z",
            "summary": "It has been suggested that large language models such as GPT-4 have acquired\nsome form of understanding beyond the correlations among the words in text\nincluding some understanding of mathematics as well. Here, we perform a\ncritical inquiry into this claim by evaluating the mathematical understanding\nof the GPT-4 model. Considering that GPT-4's training set is a secret, it is\nnot straightforward to evaluate whether the model's correct answers are based\non a mathematical understanding or based on replication of proofs that the\nmodel has seen before. We specifically craft mathematical questions which their\nformal proofs are not readily available on the web, proofs that are more likely\nnot seen by the GPT-4. We see that GPT-4 is unable to solve those problems\ndespite their simplicity. It is hard to find scientific evidence suggesting\nthat GPT-4 has acquired an understanding of even basic mathematical concepts. A\nstraightforward way to find failure modes of GPT-4 in theorem proving is to\ncraft questions where their formal proofs are not available on the web. Our\nfinding suggests that GPT-4's ability is to reproduce, rephrase, and polish the\nmathematical proofs that it has seen before, and not in grasping mathematical\nconcepts. We also see that GPT-4's ability to prove mathematical theorems is\ncontinuously expanding over time despite the claim that it is a fixed model. We\nsuggest that the task of proving mathematical theorems in formal language is\ncomparable to the methods used in search engines such as Google while\npredicting the next word in a sentence may be a misguided approach, a recipe\nthat often leads to excessive extrapolation and eventual failures. Prompting\nthe GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question\nwhether it is valuable for machine learning or for theorem proving.",
            "author": [
                "Roozbeh Yousefzadeh",
                "Xuenan Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07618v1",
                "http://arxiv.org/pdf/2311.07618v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "math.HO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07617v1",
            "title": "CLAMP: A Contrastive Language And Molecule Pre-training Network",
            "updated": "2023-11-12T07:45:35Z",
            "published": "2023-11-12T07:45:35Z",
            "summary": "This paper highlights a shift in how to approach material generation. Instead\nof material-to-material, we propose a language-to-material generation\narchitecture that utilizes millions of untapped data points. Using a web\nscraper to collect crystal text pairs from open-source research papers, a\ncontrastive model can be trained using a convolutional graph neural network\nencoder and a language encoder. This would allow unsupervised zero-shot\nclassification which can be trained by taking advantage of linguistic\nstructure. Without any specific training data, an ~82\\% accuracy was achieved\nand ~75\\% accuracy for photocatalyst prediction with an extremely small\ndataset. This novel network could ideally be cross-applied to any reaction that\ncan be described via text, opening completely new methods to think about 3D\nchemical framework generation. In the full experiment diffusion models would\nlikely be incorporated to fully exploit the latent space.",
            "author": [
                "Neel Redkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07617v1",
                "http://arxiv.org/pdf/2311.07617v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "8.2.D.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06761v1",
            "title": "Learning Knowledge-Enhanced Contextual Language Representations for\n  Domain Natural Language Understanding",
            "updated": "2023-11-12T07:37:24Z",
            "published": "2023-11-12T07:37:24Z",
            "summary": "Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the\nperformance of various downstream NLP tasks by injecting knowledge facts from\nlarge-scale Knowledge Graphs (KGs). However, existing methods for pre-training\nKEPLMs with relational triples are difficult to be adapted to close domains due\nto the lack of sufficient domain graph semantics. In this paper, we propose a\nKnowledge-enhanced lANGuAge Representation learning framework for various\nclOsed dOmains (KANGAROO) via capturing the implicit graph structure among the\nentities. Specifically, since the entity coverage rates of closed-domain KGs\ncan be relatively low and may exhibit the global sparsity phenomenon for\nknowledge injection, we consider not only the shallow relational\nrepresentations of triples but also the hyperbolic embeddings of deep\nhierarchical entity-class structures for effective knowledge fusion.Moreover,\nas two closed-domain entities under the same entity-class often have locally\ndense neighbor subgraphs counted by max point biconnected component, we further\npropose a data augmentation strategy based on contrastive learning over\nsubgraphs to construct hard negative samples of higher quality. It makes the\nunderlying KELPMs better distinguish the semantics of these neighboring\nentities to further complement the global semantic sparsity. In the\nexperiments, we evaluate KANGAROO over various knowledge-aware and general NLP\ntasks in both full and few-shot learning settings, outperforming various KEPLM\ntraining paradigms performance in closed-domains significantly.",
            "author": [
                "Ruyao Xu",
                "Taolin Zhang",
                "Chengyu Wang",
                "Zhongjie Duan",
                "Cen Chen",
                "Minghui Qiu",
                "Dawei Cheng",
                "Xiaofeng He",
                "Weining Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06761v1",
                "http://arxiv.org/pdf/2311.06761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07616v1",
            "title": "ReIDTracker Sea: the technical report of BoaTrack and SeaDronesSee-MOT\n  challenge at MaCVi of WACV24",
            "updated": "2023-11-12T07:37:07Z",
            "published": "2023-11-12T07:37:07Z",
            "summary": "Multi-Object Tracking is one of the most important technologies in maritime\ncomputer vision. Our solution tries to explore Multi-Object Tracking in\nmaritime Unmanned Aerial vehicles (UAVs) and Unmanned Surface Vehicles (USVs)\nusage scenarios. Most of the current Multi-Object Tracking algorithms require\ncomplex association strategies and association information (2D location and\nmotion, 3D motion, 3D depth, 2D appearance) to achieve better performance,\nwhich makes the entire tracking system extremely complex and heavy. At the same\ntime, most of the current Multi-Object Tracking algorithms still require video\nannotation data which is costly to obtain for training. Our solution tries to\nexplore Multi-Object Tracking in a completely unsupervised way. The scheme\naccomplishes instance representation learning by using self-supervision on\nImageNet. Then, by cooperating with high-quality detectors, the multi-target\ntracking task can be completed simply and efficiently. The scheme achieved top\n3 performance on both UAV-based Multi-Object Tracking with Reidentification and\nUSV-based Multi-Object Tracking benchmarks and the solution won the\nchampionship in many multiple Multi-Object Tracking competitions. such as\nBDD100K MOT,MOTS, Waymo 2D MOT",
            "author": [
                "Kaer Huang",
                "Weitu Chong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07616v1",
                "http://arxiv.org/pdf/2311.07616v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07615v1",
            "title": "On Algorithmic Cache Optimization",
            "updated": "2023-11-12T07:31:39Z",
            "published": "2023-11-12T07:31:39Z",
            "summary": "We study matrix-matrix multiplication of two matrices, $A$ and $B$, each of\nsize $n \\times n$. This operation results in a matrix $C$ of size $n\\times n$.\nOur goal is to produce $C$ as efficiently as possible given a cache: a 1-D\nlimited set of data values that we can work with to perform elementary\noperations (additions, multiplications, etc.). That is, we attempt to reuse the\nmaximum amount of data from $A$, $B$ and $C$ during our computation (or\nequivalently, utilize data in the fast-access cache as often as possible).\nFirstly, we introduce the matrix-matrix multiplication algorithm. Secondly, we\npresent a standard two-memory model to simulate the architecture of a computer,\nand we explain the LRU (Least Recently Used) Cache policy (which is standard in\nmost computers). Thirdly, we introduce a basic model Cache Simulator, which\npossesses an $\\mathcal{O}(M)$ time complexity (meaning we are limited to small\n$M$ values). Then we discuss and model the LFU (Least Frequently Used) Cache\npolicy and the explicit control cache policy. Finally, we introduce the main\nresult of this paper, the $\\mathcal{O}(1)$ Cache Simulator, and use it to\ncompare, experimentally, the savings of time, energy, and communication\nincurred from the ideal cache-efficient algorithm for matrix-matrix\nmultiplication. The Cache Simulator simulates the amount of data movement that\noccurs between the main memory and the cache of the computer. One of the\nfindings of this project is that, in some cases, there is a significant\ndiscrepancy in communication values between an LRU cache algorithm and explicit\ncache control. We propose to alleviate this problem by ``tricking'' the LRU\ncache algorithm by updating the timestamp of the data we want to keep in cache\n(namely entries of matrix $C$). This enables us to have the benefits of an\nexplicit cache policy while being constrained by the LRU paradigm (realistic\npolicy on a CPU).",
            "author": [
                "Neil Bhavikatti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07615v1",
                "http://arxiv.org/pdf/2311.07615v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06760v1",
            "title": "GALA-n: Generic Architecture of Layout-Aware n-Bit Quantum Operators for\n  Cost-Effective Realization on IBM Quantum Computers",
            "updated": "2023-11-12T07:25:06Z",
            "published": "2023-11-12T07:25:06Z",
            "summary": "A generic architecture of n-bit quantum operators is proposed for\ncost-effective transpilation, based on the layouts and the number of n neighbor\nphysical qubits for IBM quantum computers, where n >= 3. This proposed\narchitecture is termed \"GALA-n quantum operator\". The GALA-n quantum operator\nis designed using the visual approach of the Bloch sphere, from the visual\nrepresentations of the rotational quantum operations for IBM native gates\n(square root of X, X, RZ, and CNOT). In this paper, we also proposed a new\nformula for the quantum cost, which calculates the total numbers of native\ngates, SWAP gates, and the depth of the final transpiled quantum circuits. This\nformula is termed the \"transpilation quantum cost\". After transpilation, our\nproposed GALA-n quantum operator always has a lower transpilation quantum cost\nthan that of conventional n-bit quantum operators, which are mainly constructed\nfrom costly n-bit Toffoli gates.",
            "author": [
                "A. Al-Bayaty",
                "M. Perkowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06760v1",
                "http://arxiv.org/pdf/2311.06760v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06758v1",
            "title": "Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for\n  Cross-Lingual Machine Reading Comprehension",
            "updated": "2023-11-12T07:20:37Z",
            "published": "2023-11-12T07:20:37Z",
            "summary": "In cross-lingual language understanding, machine translation is often\nutilized to enhance the transferability of models across languages, either by\ntranslating the training data from the source language to the target, or from\nthe target to the source to aid inference. However, in cross-lingual machine\nreading comprehension (MRC), it is difficult to perform a deep level of\nassistance to enhance cross-lingual transfer because of the variation of answer\nspan positions in different languages. In this paper, we propose X-STA, a new\napproach for cross-lingual MRC. Specifically, we leverage an attentive teacher\nto subtly transfer the answer spans of the source language to the answer output\nspace of the target. A Gradient-Disentangled Knowledge Sharing technique is\nproposed as an improved cross-attention block. In addition, we force the model\nto learn semantic alignments from multiple granularities and calibrate the\nmodel outputs with teacher guidance to enhance cross-lingual transferability.\nExperiments on three multi-lingual MRC datasets show the effectiveness of our\nmethod, outperforming state-of-the-art approaches.",
            "author": [
                "Tingfeng Cao",
                "Chengyu Wang",
                "Chuanqi Tan",
                "Jun Huang",
                "Jinhui Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06758v1",
                "http://arxiv.org/pdf/2311.06758v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06756v1",
            "title": "Personalized Federated Learning via ADMM with Moreau Envelope",
            "updated": "2023-11-12T07:13:37Z",
            "published": "2023-11-12T07:13:37Z",
            "summary": "Personalized federated learning (PFL) is an approach proposed to address the\nissue of poor convergence on heterogeneous data. However, most existing PFL\nframeworks require strong assumptions for convergence. In this paper, we\npropose an alternating direction method of multipliers (ADMM) for training PFL\nmodels with Moreau envelope (FLAME), which achieves a sublinear convergence\nrate, relying on the relatively weak assumption of gradient Lipschitz\ncontinuity. Moreover, due to the gradient-free nature of ADMM, FLAME alleviates\nthe need for hyperparameter tuning, particularly in avoiding the adjustment of\nthe learning rate when training the global model. In addition, we propose a\nbiased client selection strategy to expedite the convergence of training of PFL\nmodels. Our theoretical analysis establishes the global convergence under both\nunbiased and biased client selection strategies. Our experiments validate that\nFLAME, when trained on heterogeneous data, outperforms state-of-the-art methods\nin terms of model performance. Regarding communication efficiency, it exhibits\nan average speedup of 3.75x compared to the baselines. Furthermore,\nexperimental results validate that the biased client selection strategy speeds\nup the convergence of both personalized and global models.",
            "author": [
                "Shengkun Zhu",
                "Jinshan Zeng",
                "Sheng Wang",
                "Yuan Sun",
                "Zhiyong Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06756v1",
                "http://arxiv.org/pdf/2311.06756v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06754v1",
            "title": "From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with\n  Small Language Models",
            "updated": "2023-11-12T06:56:21Z",
            "published": "2023-11-12T06:56:21Z",
            "summary": "Reasoning is a distinctive human capacity, enabling us to address complex\nproblems by breaking them down into a series of manageable cognitive steps.\nYet, complex logical reasoning is still cumbersome for language models. Based\non the dual process theory in cognitive science, we are the first to unravel\nthe cognitive reasoning abilities of language models. Our framework employs an\niterative methodology to construct a Cognitive Tree (CogTree). The root node of\nthis tree represents the initial query, while the leaf nodes consist of\nstraightforward questions that can be answered directly. This construction\ninvolves two main components: the implicit extraction module (referred to as\nthe intuitive system) and the explicit reasoning module (referred to as the\nreflective system). The intuitive system rapidly generates multiple responses\nby utilizing in-context examples, while the reflective system scores these\nresponses using comparative learning. The scores guide the intuitive system in\nits subsequent generation step. Our experimental results on two popular and\nchallenging reasoning tasks indicate that it is possible to achieve a\nperformance level comparable to that of GPT-3.5 (with 175B parameters), using a\nsignificantly smaller language model that contains fewer parameters (<=7B) than\n5% of GPT-3.5.",
            "author": [
                "Junbing Yan",
                "Chengyu Wang",
                "Taolin Zhang",
                "Xiaofeng He",
                "Jun Huang",
                "Wei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06754v1",
                "http://arxiv.org/pdf/2311.06754v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06753v1",
            "title": "Towards General-Purpose Speech Abilities for Large Language Models Using\n  Unpaired Data",
            "updated": "2023-11-12T06:56:14Z",
            "published": "2023-11-12T06:56:14Z",
            "summary": "In this work, we extend the instruction-tuned Llama-2 model with end-to-end\ngeneral-purpose speech processing and reasoning abilities while maintaining the\nwide range of LLM capabilities, without using any carefully curated paired\ndata. The proposed model can utilize audio prompts as a replacement for text\nand sustain a conversation. Such a model also has extended cross-modal\ncapabilities such as being able to perform speech question answering, speech\ntranslation, and audio summarization amongst many other closed and open-domain\ntasks. This is unlike prior approaches in speech, in which LLMs are extended to\nhandle audio for a limited number of pre-designated tasks. Experiments show\nthat our end-to-end approach is on par with or outperforms a cascaded system\n(speech recognizer + LLM) in terms of modeling the response to a prompt.\nFurthermore, unlike a cascade, our approach shows the ability to interchange\ntext and audio modalities and utilize the prior context in a conversation to\nprovide better results.",
            "author": [
                "Yassir Fathullah",
                "Chunyang Wu",
                "Egor Lakomkin",
                "Junteng Jia",
                "Yuan Shangguan",
                "Jay Mahadeokar",
                "Ozlem Kalinli",
                "Christian Fuegen",
                "Mike Seltzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06753v1",
                "http://arxiv.org/pdf/2311.06753v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06752v1",
            "title": "BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image\n  Synthesis",
            "updated": "2023-11-12T06:39:00Z",
            "published": "2023-11-12T06:39:00Z",
            "summary": "Recently, diffusion-based deep generative models (e.g., Stable Diffusion)\nhave shown impressive results in text-to-image synthesis. However, current\ntext-to-image models often require multiple passes of prompt engineering by\nhumans in order to produce satisfactory results for real-world applications. We\npropose BeautifulPrompt, a deep generative model to produce high-quality\nprompts from very simple raw descriptions, which enables diffusion-based models\nto generate more beautiful images. In our work, we first fine-tuned the\nBeautifulPrompt model over low-quality and high-quality collecting prompt\npairs. Then, to ensure that our generated prompts can generate more beautiful\nimages, we further propose a Reinforcement Learning with Visual AI Feedback\ntechnique to fine-tune our model to maximize the reward values of the generated\nprompts, where the reward values are calculated based on the PickScore and the\nAesthetic Scores. Our results demonstrate that learning from visual AI feedback\npromises the potential to improve the quality of generated prompts and images\nsignificantly. We further showcase the integration of BeautifulPrompt to a\ncloud-native AI platform to provide better text-to-image generation service in\nthe cloud.",
            "author": [
                "Tingfeng Cao",
                "Chengyu Wang",
                "Bingyan Liu",
                "Ziheng Wu",
                "Jinhui Zhu",
                "Jun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06752v1",
                "http://arxiv.org/pdf/2311.06752v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06751v1",
            "title": "Coupled dynamics of steady jet flow control for flexible membrane wings",
            "updated": "2023-11-12T06:36:32Z",
            "published": "2023-11-12T06:36:32Z",
            "summary": "We present a steady jet flow-based flow control of flexible membrane wings\nfor an adaptive and efficient motion of bat-inspired drones in complex flight\nenvironments. A body-fitted variational computational aeroelastic framework is\nadopted for the modeling of fluid-structure interactions. High-momentum jet\nflows are injected from the leading edge and transported to the wake flows to\nalter the aerodynamic performance and the membrane vibration. The phase\ndiagrams of the coupled fluid-membrane dynamics are constructed in the\nparameter space of the angle of attack and the jet momentum coefficient. The\ncoupled dynamical effect of active jet flow control on the membrane performance\nis systematically explored. While the results indicate that the current active\nflow control strategy performs well at low angles of attack, the effectiveness\ndegrades at high angles of attack with large flow separation. To understand the\ncoupling mechanism, the variations of the vortex patterns at different jet\nmomentum coefficients are examined by the proper orthogonal decomposition modes\nin the Eulerian view and the fluid transport process is studied by the coherent\nflow structures in the Lagrange description. Two scaling relations that\nquantitatively connect the membrane deformation with the aerodynamic loads\npresented in our previous work are verified even when active jet flow control\nis applied. A unifying feedback loop that reveals the fluid-membrane coupling\nmechanism is proposed. This feedback loop provides useful guidance for\ndesigning optimal active flow control strategies and enhancing flight\ncapabilities. These findings can facilitate the development of next-generation\nbio-inspired drones that incorporate smart sensing and intelligent control.",
            "author": [
                "Guojun Li",
                "Rajeev Kumar Jaiman",
                "Hongzhong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06751v1",
                "http://arxiv.org/pdf/2311.06751v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06749v1",
            "title": "Aggregate, Decompose, and Fine-Tune: A Simple Yet Effective\n  Factor-Tuning Method for Vision Transformer",
            "updated": "2023-11-12T06:23:33Z",
            "published": "2023-11-12T06:23:33Z",
            "summary": "Recent advancements have illuminated the efficacy of some\ntensorization-decomposition Parameter-Efficient Fine-Tuning methods like LoRA\nand FacT in the context of Vision Transformers (ViT). However, these methods\ngrapple with the challenges of inadequately addressing inner- and cross-layer\nredundancy. To tackle this issue, we introduce EFfective Factor-Tuning (EFFT),\na simple yet effective fine-tuning method. Within the VTAB-1K dataset, our EFFT\nsurpasses all baselines, attaining state-of-the-art performance with a\ncategorical average of 75.9% in top-1 accuracy with only 0.28% of the\nparameters for full fine-tuning. Considering the simplicity and efficacy of\nEFFT, it holds the potential to serve as a foundational benchmark. The code and\nmodel are now available at\nhttps://github.com/Dongping-Chen/EFFT-EFfective-Factor-Tuning.",
            "author": [
                "Dongping Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06749v1",
                "http://arxiv.org/pdf/2311.06749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06746v1",
            "title": "Two Stream Scene Understanding on Graph Embedding",
            "updated": "2023-11-12T05:57:56Z",
            "published": "2023-11-12T05:57:56Z",
            "summary": "The paper presents a novel two-stream network architecture for enhancing\nscene understanding in computer vision. This architecture utilizes a graph\nfeature stream and an image feature stream, aiming to merge the strengths of\nboth modalities for improved performance in image classification and scene\ngraph generation tasks. The graph feature stream network comprises a\nsegmentation structure, scene graph generation, and a graph representation\nmodule. The segmentation structure employs the UPSNet architecture with a\nbackbone that can be a residual network, Vit, or Swin Transformer. The scene\ngraph generation component focuses on extracting object labels and neighborhood\nrelationships from the semantic map to create a scene graph. Graph\nConvolutional Networks (GCN), GraphSAGE, and Graph Attention Networks (GAT) are\nemployed for graph representation, with an emphasis on capturing node features\nand their interconnections. The image feature stream network, on the other\nhand, focuses on image classification through the use of Vision Transformer and\nSwin Transformer models. The two streams are fused using various data fusion\nmethods. This fusion is designed to leverage the complementary strengths of\ngraph-based and image-based features.Experiments conducted on the ADE20K\ndataset demonstrate the effectiveness of the proposed two-stream network in\nimproving image classification accuracy compared to conventional methods. This\nresearch provides a significant contribution to the field of computer vision,\nparticularly in the areas of scene understanding and image classification, by\neffectively combining graph-based and image-based approaches.",
            "author": [
                "Wenkai Yang",
                "Wenyuan Sun",
                "Runxaing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06746v1",
                "http://arxiv.org/pdf/2311.06746v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06738v1",
            "title": "A Robust Numerical Scheme for Solving Riesz-Tempered Fractional\n  Reaction-Diffusion Equations",
            "updated": "2023-11-12T05:22:28Z",
            "published": "2023-11-12T05:22:28Z",
            "summary": "The Fractional Diffusion Equation (FDE) is a mathematical model that\ndescribes anomalous transport phenomena characterized by non-local and\nlong-range dependencies which deviate from the traditional behavior of\ndiffusion. Solving this equation numerically is challenging due to the need to\ndiscretize complicated integral operators which increase the computational\ncosts. These complexities are exacerbated by nonlinear source terms, nonsmooth\ndata and irregular domains. In this study, we propose a second order\nExponential Time Differencing Finite Element Method (ETD-RDP-FEM) to\nefficiently solve nonlinear FDE, posed in irregular domains. This approach\ndiscretizes matrix exponentials using a rational function with real and\ndistinct poles, resulting in an L-stable scheme that damps spurious\noscillations caused by non-smooth initial data. The method is shown to\noutperform existing second-order methods for FDEs with a higher accuracy and\nfaster computational time.",
            "author": [
                "Mohammad Partohaghighi",
                "Emmanuel Asante-Asamani",
                "Olaniyi S. Iyiola"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06738v1",
                "http://arxiv.org/pdf/2311.06738v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06737v1",
            "title": "Detecting and Correcting Hate Speech in Multimodal Memes with Large\n  Visual Language Model",
            "updated": "2023-11-12T05:20:20Z",
            "published": "2023-11-12T05:20:20Z",
            "summary": "Recently, large language models (LLMs) have taken the spotlight in natural\nlanguage processing. Further, integrating LLMs with vision enables the users to\nexplore more emergent abilities in multimodality. Visual language models\n(VLMs), such as LLaVA, Flamingo, or GPT-4, have demonstrated impressive\nperformance on various visio-linguistic tasks. Consequently, there are enormous\napplications of large models that could be potentially used on social media\nplatforms. Despite that, there is a lack of related work on detecting or\ncorrecting hateful memes with VLMs. In this work, we study the ability of VLMs\non hateful meme detection and hateful meme correction tasks with zero-shot\nprompting. From our empirical experiments, we show the effectiveness of the\npretrained LLaVA model and discuss its strengths and weaknesses in these tasks.",
            "author": [
                "Minh-Hao Van",
                "Xintao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06737v1",
                "http://arxiv.org/pdf/2311.06737v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06736v1",
            "title": "Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof\n  Generation with Contrastive Stepwise Decoding",
            "updated": "2023-11-12T05:12:49Z",
            "published": "2023-11-12T05:12:49Z",
            "summary": "Logical reasoning remains a pivotal component within the realm of artificial\nintelligence. The recent evolution of large language models (LLMs) has marked\nsignificant progress in this domain. The adoption of strategies like\nchain-of-thought (CoT) has enhanced the performance of LLMs across diverse\nreasoning tasks. Nonetheless, logical reasoning that involves proof planning,\nspecifically those that necessitate the validation of explanation accuracy,\ncontinues to present stumbling blocks. In this study, we first evaluate the\nefficacy of LLMs with advanced CoT strategies concerning such tasks. Our\nanalysis reveals that LLMs still struggle to navigate complex reasoning chains,\nwhich demand the meticulous linkage of premises to derive a cogent conclusion.\nTo address this issue, we finetune a smaller-scale language model, equipping it\nto decompose proof objectives into more manageable subgoals. We also introduce\ncontrastive decoding to stepwise proof generation, making use of negative\nreasoning paths to strengthen the model's capacity for logical deduction.\nExperiments on EntailmentBank underscore the success of our method in\naugmenting the proof planning abilities of language models.",
            "author": [
                "Ying Su",
                "Xiaojin Fu",
                "Mingwen Liu",
                "Zhijiang Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06736v1",
                "http://arxiv.org/pdf/2311.06736v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06732v1",
            "title": "On explicit bounds of Fano threefolds",
            "updated": "2023-11-12T04:42:42Z",
            "published": "2023-11-12T04:42:42Z",
            "summary": "In this paper, we study the explicit geometry of threefolds, in particular,\nFano varieties. We find an explicitly computable positive integer $N$, such\nthat all but a bounded family of Fano threefolds have $N$-complements. This\nresult has many applications on finding explicit bounds of algebraic invariants\nfor threefolds. We provide explicit lower bounds for the first gap of the\n$\\mathbb R$-complementary thresholds for threefolds, the first gap of the\nglobal lc thresholds, the smallest minimal log discrepancy of exceptional\nthreefolds, and the volume of log threefolds with reduced boundary and ample\nlog canonical divisor. We also provide an explicit upper bound of the\nanti-canonical volume of exceptional threefolds. While the bounds in this paper\nmay not and are not expected to be optimal, they are the first explicit bounds\nof these invariants in dimension three.",
            "author": [
                "Caucher Birkar",
                "Jihao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06732v1",
                "http://arxiv.org/pdf/2311.06732v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "14J30, 14J45, 14E30, 14C20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06729v1",
            "title": "Comprehending Lexical and Affective Ontologies in the Demographically\n  Diverse Spatial Social Media Discourse",
            "updated": "2023-11-12T04:23:33Z",
            "published": "2023-11-12T04:23:33Z",
            "summary": "This study aims to comprehend linguistic and socio-demographic features,\nencompassing English language styles, conveyed sentiments, and lexical\ndiversity within spatial online social media review data. To this end, we\nundertake a case study that scrutinizes reviews composed by two distinct and\ndemographically diverse groups. Our analysis entails the extraction and\nexamination of various statistical, grammatical, and sentimental features from\nthese two groups. Subsequently, we leverage these features with machine\nlearning (ML) classifiers to discern their potential in effectively\ndifferentiating between the groups. Our investigation unveils substantial\ndisparities in certain linguistic attributes between the two groups. When\nintegrated into ML classifiers, these attributes exhibit a marked efficacy in\ndistinguishing the groups, yielding a macro F1 score of approximately 0.85.\nFurthermore, we conduct a comparative evaluation of these linguistic features\nwith word n-gram-based lexical features in discerning demographically diverse\nreview data. As expected, the n-gram lexical features, coupled with fine-tuned\ntransformer-based models, show superior performance, attaining accuracies\nsurpassing 95\\% and macro F1 scores exceeding 0.96. Our meticulous analysis and\ncomprehensive evaluations substantiate the efficacy of linguistic and\nsentimental features in effectively discerning demographically diverse review\ndata. The findings of this study provide valuable guidelines for future\nresearch endeavors concerning the analysis of demographic patterns in textual\ncontent across various social media platforms.",
            "author": [
                "Salim Sazzed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06729v1",
                "http://arxiv.org/pdf/2311.06729v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06726v1",
            "title": "The Distributed Complexity of Locally Checkable Labeling Problems Beyond\n  Paths and Trees",
            "updated": "2023-11-12T03:57:22Z",
            "published": "2023-11-12T03:57:22Z",
            "summary": "We consider locally checkable labeling LCL problems in the LOCAL model of\ndistributed computing. Since 2016, there has been a substantial body of work\nexamining the possible complexities of LCL problems. For example, it has been\nestablished that there are no LCL problems exhibiting deterministic\ncomplexities falling between $\\omega(\\log^* n)$ and $o(\\log n)$. This line of\ninquiry has yielded a wealth of algorithmic techniques and insights that are\nuseful for algorithm designers.\n  While the complexity landscape of LCL problems on general graphs, trees, and\npaths is now well understood, graph classes beyond these three cases remain\nlargely unexplored. Indeed, recent research trends have shifted towards a\nfine-grained study of special instances within the domains of paths and trees.\n  In this paper, we generalize the line of research on characterizing the\ncomplexity landscape of LCL problems to a much broader range of graph classes.\nWe propose a conjecture that characterizes the complexity landscape of LCL\nproblems for an arbitrary class of graphs that is closed under minors, and we\nprove a part of the conjecture.\n  Some highlights of our findings are as follows.\n  1. We establish a simple characterization of the minor-closed graph classes\nsharing the same deterministic complexity landscape as paths, where $O(1)$,\n$\\Theta(\\log^* n)$, and $\\Theta(n)$ are the only possible complexity classes.\n  2. It is natural to conjecture that any minor-closed graph class shares the\nsame complexity landscape as trees if and only if the graph class has bounded\ntreewidth and unbounded pathwidth. We prove the \"only if\" part of the\nconjecture.\n  3. In addition to the well-known complexity landscapes for paths, trees, and\ngeneral graphs, there are infinitely many different complexity landscapes among\nminor-closed graph classes.",
            "author": [
                "Yi-Jun Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06726v1",
                "http://arxiv.org/pdf/2311.06726v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06724v1",
            "title": "Controllable Topic-Focused Abstractive Summarization",
            "updated": "2023-11-12T03:51:38Z",
            "published": "2023-11-12T03:51:38Z",
            "summary": "Controlled abstractive summarization focuses on producing condensed versions\nof a source article to cover specific aspects by shifting the distribution of\ngenerated text towards a desired style, e.g., a set of topics. Subsequently,\nthe resulting summaries may be tailored to user-defined requirements. This\npaper presents a new Transformer-based architecture capable of producing\ntopic-focused summaries. The architecture modifies the cross-attention\nmechanism of the Transformer to bring topic-focus control to the generation\nprocess while not adding any further parameters to the model. We show that our\nmodel sets a new state of the art on the NEWTS dataset in terms of\ntopic-focused abstractive summarization as well as a topic-prevalence score.\nMoreover, we show via extensive experiments that our proposed topical\ncross-attention mechanism can be plugged into various Transformer models, such\nas BART and T5, improving their performance on the CNN/Dailymail and XSum\nbenchmark datasets for abstractive summarization. This is achieved via\nfine-tuning, without requiring training from scratch. Finally, we show through\nhuman evaluation that our model generates more faithful summaries outperforming\nthe state-of-the-art Frost model.",
            "author": [
                "Seyed Ali Bahrainian",
                "Martin Jaggi",
                "Carsten Eickhoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06724v1",
                "http://arxiv.org/pdf/2311.06724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06722v2",
            "title": "Schubert cells of mixed type in complex Lagrangian Grassmannians",
            "updated": "2023-11-26T19:09:40Z",
            "published": "2023-11-12T03:37:05Z",
            "summary": "We describe CW decompositions of complex Lagrangian Grassmannians, that\ncontain as subcomplexes, CW decompositions of real Lagrangian Grassmannians by\nSchubert-Arnol'd cells. The degrees of attaching maps are explicitly computed\nin terms of quantities that can be read off from the corresponding shifted\nYoung diagrams of mixed type. The signs are determined by a choice of\nlexicographical ordering on coordinates. As an immediate consequence, we obtain\nthe homotopy extension property for real and complex Lagrangian Grassmannians.\nWe also show some torsion classes in the integral homology of the real\nLagrangian Grassmannian are contractible inside the complex Lagrangian\nGrassmannian.",
            "author": [
                "Hyunmoon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06722v2",
                "http://arxiv.org/pdf/2311.06722v2"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "math.AT",
                "math.CO",
                "57T15 (Primary) 53D50, 53D12 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06720v1",
            "title": "Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small\n  Scorer",
            "updated": "2023-11-12T03:25:34Z",
            "published": "2023-11-12T03:25:34Z",
            "summary": "Large language models (LLMs) such as T0, FLAN, and OPT-IML, excel in\nmulti-tasking under a unified instruction-following paradigm, where they also\nexhibit remarkable generalization abilities to unseen tasks. Despite their\nimpressive performance, these LLMs, with sizes ranging from several billion to\nhundreds of billions of parameters, demand substantial computational resources,\nmaking their training and inference expensive and inefficient. Furthermore,\nadapting these models to downstream applications, particularly complex tasks,\nis often unfeasible due to the extensive hardware requirements for finetuning,\neven when utilizing parameter-efficient approaches such as prompt tuning.\nAdditionally, the most powerful multi-task LLMs, such as OPT-IML-175B and\nFLAN-PaLM-540B, are not publicly accessible, severely limiting their\ncustomization potential. To address these challenges, we introduce a pretrained\nsmall scorer, Cappy, designed to enhance the performance and efficiency of\nmulti-task LLMs. With merely 360 million parameters, Cappy functions either\nindependently on classification tasks or serve as an auxiliary component for\nLLMs, boosting their performance. Moreover, Cappy enables efficiently\nintegrating downstream supervision without requiring LLM finetuning nor the\naccess to their parameters. Our experiments demonstrate that, when working\nindependently on 11 language understanding tasks from PromptSource, Cappy\noutperforms LLMs that are several orders of magnitude larger. Besides, on 45\ncomplex tasks from BIG-Bench, Cappy boosts the performance of the advanced\nmulti-task LLM, FLAN-T5, by a large margin. Furthermore, Cappy is flexible to\ncooperate with other LLM adaptations, including finetuning and in-context\nlearning, offering additional performance enhancement.",
            "author": [
                "Bowen Tan",
                "Yun Zhu",
                "Lijuan Liu",
                "Eric Xing",
                "Zhiting Hu",
                "Jindong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06720v1",
                "http://arxiv.org/pdf/2311.06720v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06717v1",
            "title": "Whitehead Filtrations for Computations in Topological Hochschild\n  Homology",
            "updated": "2023-11-12T03:15:29Z",
            "published": "2023-11-12T03:15:29Z",
            "summary": "We discuss spectral sequences coming from Whitehead filtrations in the\ncomputation of topological Hochschild homology of ring spectra. Using cyclic\ninvariance, this makes for simple computations of $THH$ of connective rings $R$\nwith coefficients in discrete ring spectra. In particular, we show how to use\nthis to compute $THH(tmf,\\mathbb{F}_2)$, and $THH(tmf,\\mathbb{Z}_{(2)})$, where\n$tmf$ denotes the $\\mathbb{E}_\\infty$ ring spectrum of topological modular\nforms. Then, we obtain a description of $THH(\\ell/v_1^n)$ in terms of\n$THH(\\ell,\\ell/v_1^n)$, where the latter can be computed by results of\narXiv:0710.4368. We next explain how the methods of this computation generalize\nto give us information about $THH(cofib(x^k:\\Sigma^{k|x|}R\\to R))$ for $R$ and\n$cofib(x^k)$ suitably structured connective ring spectra, $k>1$, and $x\\in\n\\pi_{*}(R)$ an arbitrary element in positive degree. Finally, we examine the\ngeneral framework to describe the topological Hochschild homology of 2-local\nconnective self-conjugate K-theory, $ksc_2$.",
            "author": [
                "Logan Hyslop"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06717v1",
                "http://arxiv.org/pdf/2311.06717v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "math.KT",
                "55R20, 55T25 (Primary) 19D55 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06714v1",
            "title": "What factors influence the popularity of user-generated text in the\n  creative domain? A case study of book reviews",
            "updated": "2023-11-12T02:54:11Z",
            "published": "2023-11-12T02:54:11Z",
            "summary": "This study investigates a range of psychological, lexical, semantic, and\nreadability features of book reviews to elucidate the factors underlying their\nperceived popularity. To this end, we conduct statistical analyses of various\nfeatures, including the types and frequency of opinion and emotion-conveying\nterms, connectives, character mentions, word uniqueness, commonness, and\nsentence structure, among others. Additionally, we utilize two readability\ntests to explore whether reading ease is positively associated with review\npopularity. Finally, we employ traditional machine learning classifiers and\ntransformer-based fine-tuned language models with n-gram features to\nautomatically determine review popularity. Our findings indicate that, with the\nexception of a few features (e.g., review length, emotions, and word\nuniqueness), most attributes do not exhibit significant differences between\npopular and non-popular review groups. Furthermore, the poor performance of\nmachine learning classifiers using the word n-gram feature highlights the\nchallenges associated with determining popularity in creative domains. Overall,\nour study provides insights into the factors underlying review popularity and\nhighlights the need for further research in this area, particularly in the\ncreative realm.",
            "author": [
                "Salim Sazzed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06714v1",
                "http://arxiv.org/pdf/2311.06714v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06712v2",
            "title": "PuzzleTuning: Explicitly Bridge Pathological and Natural Image with\n  Puzzles",
            "updated": "2023-11-30T10:03:17Z",
            "published": "2023-11-12T02:43:22Z",
            "summary": "Pathological image analysis is a crucial field in computer vision. Due to the\nannotation scarcity in the pathological field, recently, most of the works\nleverage self-supervised learning (SSL) trained on unlabeled pathological\nimages, hoping to mine the main representation automatically. However, there\nare two core defects in SSL-based pathological pre-training: (1) they do not\nexplicitly explore the essential focuses of the pathological field, and (2)\nthey do not effectively bridge with and thus take advantage of the large\nnatural image domain. To explicitly address them, we propose our large-scale\nPuzzleTuning framework, containing the following innovations. Firstly, we\nidentify three task focuses that can effectively bridge pathological and\nnatural domains: appearance consistency, spatial consistency, and misalignment\nunderstanding. Secondly, we devise a multiple puzzle restoring task to\nexplicitly pre-train the model with these focuses. Thirdly, for the existing\nlarge domain gap between natural and pathological fields, we introduce an\nexplicit prompt-tuning process to incrementally integrate the domain-specific\nknowledge with the natural knowledge. Additionally, we design a\ncurriculum-learning training strategy that regulates the task difficulty,\nmaking the model fit the complex multiple puzzle restoring task adaptively.\nExperimental results show that our PuzzleTuning framework outperforms the\nprevious SOTA methods in various downstream tasks on multiple datasets. The\ncode, demo, and pre-trained weights are available at\nhttps://github.com/sagizty/PuzzleTuning.",
            "author": [
                "Tianyi Zhang",
                "Shangqing Lyu",
                "Yanli Lei",
                "Sicheng Chen",
                "Nan Ying",
                "Yufang He",
                "Yu Zhao",
                "Yunlu Feng",
                "Guanglei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06712v2",
                "http://arxiv.org/pdf/2311.06712v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06703v2",
            "title": "Enabling Human-Centered AI: A Methodological Perspective",
            "updated": "2023-11-14T17:32:07Z",
            "published": "2023-11-12T01:31:34Z",
            "summary": "Human-centered AI (HCAI) is a design philosophy that advocates prioritizing\nhumans in designing, developing, and deploying intelligent systems, aiming to\nmaximize the benefits of AI to humans and avoid potential adverse impacts.\nWhile HCAI continues to influence, the lack of guidance on methodology in\npractice makes its adoption challenging. This paper proposes a comprehensive\nHCAI framework based on our previous work with integrated components, including\ndesign goals, design principles, implementation approaches, interdisciplinary\nteams, HCAI methods, and HCAI processes. This paper also presents a\n\"three-layer\" approach to facilitate the implementation of the framework. We\nbelieve this systematic and executable framework can overcome the weaknesses in\ncurrent HCAI frameworks and the challenges currently faced in practice, putting\nit into action to enable HCAI further.",
            "author": [
                "Wei Xu",
                "Zaifeng Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06703v2",
                "http://arxiv.org/pdf/2311.06703v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06700v1",
            "title": "Deep JKO: time-implicit particle methods for general nonlinear gradient\n  flows",
            "updated": "2023-11-12T01:11:08Z",
            "published": "2023-11-12T01:11:08Z",
            "summary": "We develop novel neural network-based implicit particle methods to compute\nhigh-dimensional Wasserstein-type gradient flows with linear and nonlinear\nmobility functions. The main idea is to use the Lagrangian formulation in the\nJordan--Kinderlehrer--Otto (JKO) framework, where the velocity field is\napproximated using a neural network. We leverage the formulations from the\nneural ordinary differential equation (neural ODE) in the context of continuous\nnormalizing flow for efficient density computation. Additionally, we make use\nof an explicit recurrence relation for computing derivatives, which greatly\nstreamlines the backpropagation process. Our methodology demonstrates\nversatility in handling a wide range of gradient flows, accommodating various\npotential functions and nonlinear mobility scenarios. Extensive experiments\ndemonstrate the efficacy of our approach, including an illustrative example\nfrom Bayesian inverse problems. This underscores that our scheme provides a\nviable alternative solver for the Kalman-Wasserstein gradient flow.",
            "author": [
                "Wonjun Lee",
                "Li Wang",
                "Wuchen Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06700v1",
                "http://arxiv.org/pdf/2311.06700v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06697v1",
            "title": "Trusted Source Alignment in Large Language Models",
            "updated": "2023-11-12T00:25:25Z",
            "published": "2023-11-12T00:25:25Z",
            "summary": "Large language models (LLMs) are trained on web-scale corpora that inevitably\ninclude contradictory factual information from sources of varying reliability.\nIn this paper, we propose measuring an LLM property called trusted source\nalignment (TSA): the model's propensity to align with content produced by\ntrusted publishers in the face of uncertainty or controversy. We present\nFactCheckQA, a TSA evaluation dataset based on a corpus of fact checking\narticles. We describe a simple protocol for evaluating TSA and offer a detailed\nanalysis of design considerations including response extraction, claim\ncontextualization, and bias in prompt formulation. Applying the protocol to\nPaLM-2, we find that as we scale up the model size, the model performance on\nFactCheckQA improves from near-random to up to 80% balanced accuracy in\naligning with trusted sources.",
            "author": [
                "Vasilisa Bashlovkina",
                "Zhaobin Kuang",
                "Riley Matthews",
                "Edward Clifford",
                "Yennie Jun",
                "William W. Cohen",
                "Simon Baumgartner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06697v1",
                "http://arxiv.org/pdf/2311.06697v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06696v1",
            "title": "Simple and Effective Input Reformulations for Translation",
            "updated": "2023-11-12T00:23:37Z",
            "published": "2023-11-12T00:23:37Z",
            "summary": "Foundation language models learn from their finetuning input context in\ndifferent ways. In this paper, we reformulate inputs during finetuning for\nchallenging translation tasks, leveraging model strengths from pretraining in\nnovel ways to improve downstream performance. These reformulations are simple\ndata level modifications, require no additional collection of training data or\nmodification of data at inference time. They can be applied either on single\nlanguage pair translation tasks or massively multilingual translation tasks.\nExperiments with these techniques demonstrate significant performance\nimprovements up to $\\textbf{3.5 chrF++ on the Flores200 translation\nbenchmark}$. We hope our research accessibly improves finetuning data\nefficiency, enabling more effective training to scalably improve\nstate-of-the-art performance. Our code is released\n$\\href{https://github.com/bri25yu/LanguageModelExperimentation}{here}.$",
            "author": [
                "Brian Yu",
                "Hansen Lillemark",
                "Kurt Keutzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06696v1",
                "http://arxiv.org/pdf/2311.06696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06694v2",
            "title": "Comparative Multi-View Language Grounding",
            "updated": "2023-11-14T03:57:13Z",
            "published": "2023-11-12T00:21:58Z",
            "summary": "In this work, we consider the task of resolving object referents when given a\ncomparative language description. We present a Multi-view Approach to Grounding\nin Context (MAGiC) that leverages transformers to pragmatically reason over\nboth objects given multiple image views and a language description. In contrast\nto past efforts that attempt to connect vision and language for this task\nwithout fully considering the resulting referential context, MAGiC makes use of\nthe comparative information by jointly reasoning over multiple views of both\nobject referent candidates and the referring language expression. We present an\nanalysis demonstrating that comparative reasoning contributes to SOTA\nperformance on the SNARE object reference task.",
            "author": [
                "Chancharik Mitra",
                "Abrar Anwar",
                "Rodolfo Corona",
                "Dan Klein",
                "Trevor Darrell",
                "Jesse Thomason"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06694v2",
                "http://arxiv.org/pdf/2311.06694v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06693v1",
            "title": "Adaptive Mesh Refinement for Electromagnetic Simulation",
            "updated": "2023-11-12T00:11:23Z",
            "published": "2023-11-12T00:11:23Z",
            "summary": "We consider problems related to initial meshing and adaptive mesh refinement\nfor the electromagnetic simulation of various structures. The quality of the\ninitial mesh and the performance of the adaptive refinement are of great\nimportance for the finite element solution of the Maxwell equations, since they\ndirectly affect the accuracy and the computational time. In this paper, we\ndescribe the complete meshing workflow, which allows the simulation of\narbitrary structures. Test simulations confirm that the presented approach\nallows to reach the quality of the industrial simulation software.",
            "author": [
                "Alexey Belokrys-Fedotov",
                "Vladimir Garanzha",
                "Lennard Kamenski",
                "Alexandr Chikitkin",
                "Evgeniy Pesnya",
                "Nikita Aseev",
                "Andrey Vorobyev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06693v1",
                "http://arxiv.org/pdf/2311.06693v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65N50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06691v1",
            "title": "Automatized Self-Supervised Learning for Skin Lesion Screening",
            "updated": "2023-11-11T23:55:40Z",
            "published": "2023-11-11T23:55:40Z",
            "summary": "The incidence rates of melanoma, the deadliest form of skin cancer, have been\nincreasing steadily worldwide, presenting a significant challenge to\ndermatologists. Early detection of melanoma is crucial for improving patient\nsurvival rates, but identifying suspicious lesions through ugly duckling (UD)\nscreening, the current method used for skin cancer screening, can be\nchallenging and often requires expertise in pigmented lesions. To address these\nchallenges and improve patient outcomes, an artificial intelligence (AI)\ndecision support tool was developed to assist dermatologists in identifying UD\nfrom wide-field patient images. The tool uses a state-of-the-art object\ndetection algorithm to identify and extract all skin lesions from patient\nimages, which are then sorted by suspiciousness using a self-supervised AI\nalgorithm. A clinical validation study was conducted to evaluate the tool's\nperformance, which demonstrated an average sensitivity of 93% for the top-10\nAI-identified UDs on skin lesions selected by the majority of experts in\npigmented skin lesions. The study also found that dermatologists confidence\nincreased, and the average majority agreement with the top-10 AI-identified UDs\nimproved to 100% when assisted by AI. The development of this AI decision\nsupport tool aims to address the shortage of specialists, enable at-risk\npatients to receive faster consultations and understand the impact of\nAI-assisted screening. The tool's automation can assist dermatologists in\nidentifying suspicious lesions and provide a more objective assessment,\nreducing subjectivity in the screening process. The future steps for this\nproject include expanding the dataset to include histologically confirmed\nmelanoma cases and increasing the number of participants for clinical\nvalidation to strengthen the tool's reliability and adapt it for real-world\nconsultation.",
            "author": [
                "Vullnet Useini",
                "Stephanie Tanadini-Lang",
                "Quentin Lohmeyer",
                "Mirko Meboldt",
                "Nicolaus Andratschke",
                "Ralph P. Braun",
                "Javier Barranco Garc\u00eda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06691v1",
                "http://arxiv.org/pdf/2311.06691v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06690v1",
            "title": "Agnostic Membership Query Learning with Nontrivial Savings: New Results,\n  Techniques",
            "updated": "2023-11-11T23:46:48Z",
            "published": "2023-11-11T23:46:48Z",
            "summary": "(Abridged) Designing computationally efficient algorithms in the agnostic\nlearning model (Haussler, 1992; Kearns et al., 1994) is notoriously difficult.\nIn this work, we consider agnostic learning with membership queries for\ntouchstone classes at the frontier of agnostic learning, with a focus on how\nmuch computation can be saved over the trivial runtime of 2^n$. This approach\nis inspired by and continues the study of ``learning with nontrivial savings''\n(Servedio and Tan, 2017). To this end, we establish multiple agnostic learning\nalgorithms, highlighted by:\n  1. An agnostic learning algorithm for circuits consisting of a sublinear\nnumber of gates, which can each be any function computable by a sublogarithmic\ndegree k polynomial threshold function (the depth of the circuit is bounded\nonly by size). This algorithm runs in time 2^{n -s(n)} for s(n) \\approx\nn/(k+1), and learns over the uniform distribution over unlabelled examples on\n\\{0,1\\}^n.\n  2. An agnostic learning algorithm for circuits consisting of a sublinear\nnumber of gates, where each can be any function computable by a \\sym^+ circuit\nof subexponential size and sublogarithmic degree k. This algorithm runs in time\n2^{n-s(n)} for s(n) \\approx n/(k+1), and learns over distributions of\nunlabelled examples that are products of k+1 arbitrary and unknown\ndistributions, each over \\{0,1\\}^{n/(k+1)} (assume without loss of generality\nthat k+1 divides n).",
            "author": [
                "Ari Karchmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06690v1",
                "http://arxiv.org/pdf/2311.06690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06682v1",
            "title": "Single-Layer Digitized-Counterdiabatic Quantum Optimization for $p$-spin\n  Models",
            "updated": "2023-11-11T22:49:16Z",
            "published": "2023-11-11T22:49:16Z",
            "summary": "Quantum computing holds the potential for quantum advantage in optimization\nproblems, which requires advances in quantum algorithms and hardware\nspecifications. Adiabatic quantum optimization is conceptually a valid solution\nthat suffers from limited hardware coherence times. In this sense,\ncounterdiabatic quantum protocols provide a shortcut to this process, steering\nthe system along its ground state with fast-changing Hamiltonian. In this work,\nwe take full advantage of a digitized-counterdiabatic quantum optimization\n(DCQO) algorithm to find an optimal solution of the $p$-spin model up to\n4-local interactions. We choose a suitable scheduling function and initial\nHamiltonian such that a single-layer quantum circuit suffices to produce a good\nground-state overlap. By further optimizing parameters using variational\nmethods, we solve with unit accuracy 2-spin, 3-spin, and 4-spin problems for\n$100\\%$, $93\\%$, and $83\\%$ of instances, respectively. As a particular case of\nthe latter, we also solve factorization problems involving 5, 9, and 12 qubits.\nDue to the low computational overhead, our compact approach may become a\nvaluable tool towards quantum advantage in the NISQ era.",
            "author": [
                "Huijie Guan",
                "Fei Zhou",
                "Francisco Albarr\u00e1n-Arriagada",
                "Xi Chen",
                "Enrique Solano",
                "Narendra N. Hegade",
                "He-Liang Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06682v1",
                "http://arxiv.org/pdf/2311.06682v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06672v1",
            "title": "DUBLINE: A Deep Unfolding Network for B-line Detection in Lung\n  Ultrasound Images",
            "updated": "2023-11-11T22:00:35Z",
            "published": "2023-11-11T22:00:35Z",
            "summary": "In the context of lung ultrasound, the detection of B-lines, which are\nindicative of interstitial lung disease and pulmonary edema, plays a pivotal\nrole in clinical diagnosis. Current methods still rely on visual inspection by\nexperts. Vision-based automatic B-line detection methods have been developed,\nbut their performance has yet to improve in terms of both accuracy and\ncomputational speed. This paper presents a novel approach to posing B-line\ndetection as an inverse problem via deep unfolding of the Alternating Direction\nMethod of Multipliers (ADMM). It tackles the challenges of data labelling and\nmodel training in lung ultrasound image analysis by harnessing the capabilities\nof deep neural networks and model-based methods. Our objective is to\nsubstantially enhance diagnostic accuracy while ensuring efficient real-time\ncapabilities. The results show that the proposed method runs more than 90 times\nfaster than the traditional model-based method and achieves an F1 score that is\n10.6% higher.",
            "author": [
                "Tianqi Yang",
                "Nantheera Anantrasirichai",
                "Oktay Karaku\u015f",
                "Marco Allinovi",
                "Hatice Ceylan Koydemir",
                "Alin Achim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06672v1",
                "http://arxiv.org/pdf/2311.06672v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06671v1",
            "title": "Guideline for the Production of Digital Rights Management (DRM)",
            "updated": "2023-11-11T21:50:49Z",
            "published": "2023-11-11T21:50:49Z",
            "summary": "Multiple news sources over the years have reported on the problematic effects\nof Digital Rights Management, yet there are no reforms for DRM development,\nsimply removal. The issues are well-known to the public, frequently repeated\neven when addressed: impact on the software and to the devices that run them.\nYet few, if any, have discussed it in recent years, especially with the intent\nof eliminating the shown issues. This study reviews Digital Rights Management\nas a general topic, including the various forms it can take, the current laws\nthat affect DRM, and the current public reception and responses. This study\ndescribes the different types of DRM in general terms and then lists both\npositive and negative examples.",
            "author": [
                "Shannon Kathleen Coates",
                "Hossein Abroshan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06671v1",
                "http://arxiv.org/pdf/2311.06671v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06670v1",
            "title": "EPSAPG: A Pipeline Combining MMseqs2 and PSI-BLAST to Quickly Generate\n  Extensive Protein Sequence Alignment Profiles",
            "updated": "2023-11-11T21:40:00Z",
            "published": "2023-11-11T21:40:00Z",
            "summary": "Numerous machine learning (ML) models employed in protein function and\nstructure prediction depend on evolutionary information, which is captured\nthrough multiple-sequence alignments (MSA) or position-specific scoring\nmatrices (PSSM) as generated by PSI-BLAST. Consequently, these predictive\nmethods are burdened by substantial computational demands and prolonged\ncomputing time requirements. The principal challenge stems from the necessity\nimposed on the PSI-BLAST software to load large sequence databases sequentially\nin batches and then search for sequence alignments akin to a given query\nsequence. In the case of batch queries, the runtime scales even linearly. The\npredicament at hand is becoming more challenging as the size of bio-sequence\ndata repositories experiences exponential growth over time and as a\nconsequence, this upward trend exerts a proportional strain on the runtime of\nPSI-BLAST. To address this issue, an eminent resolution lies in leveraging the\nMMseqs2 method, capable of expediting the search process by a magnitude of 100.\nHowever, MMseqs2 cannot be directly employed to generate the final output in\nthe desired format of PSI-BLAST alignments and PSSM profiles. In this research\nwork, I developed a comprehensive pipeline that synergistically integrates both\nMMseqs2 and PSI-BLAST, resulting in the creation of a robust, optimized, and\nhighly efficient hybrid alignment pipeline. Notably, the hybrid tool exhibits a\nsignificant speed improvement, surpassing the runtime performance of PSI-BLAST\nin generating sequence alignment profiles by a factor of two orders of\nmagnitude. It is implemented in C++ and is freely available under the MIT\nlicense at https://github.com/issararab/EPSAPG.",
            "author": [
                "Issar Arab"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06670v1",
                "http://arxiv.org/pdf/2311.06670v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06668v2",
            "title": "In-context Vectors: Making In Context Learning More Effective and\n  Controllable Through Latent Space Steering",
            "updated": "2023-11-16T22:39:00Z",
            "published": "2023-11-11T21:19:44Z",
            "summary": "Large language models (LLMs) demonstrate emergent in-context learning\ncapabilities, where they adapt to new tasks based on example demonstrations.\nHowever, in-context learning has seen limited effectiveness in many settings,\nis difficult to quantitatively control and takes up context window space. To\novercome these limitations, we propose an alternative approach that recasts\nin-context learning as in-context vectors (ICV). Using ICV has two steps. We\nfirst use a forward pass on demonstration examples to create the in-context\nvector from the latent embedding of the LLM. This vector captures essential\ninformation about the intended task. On a new query, instead of adding\ndemonstrations to the prompt, we shift the latent states of the LLM using the\nICV. The ICV approach has several benefits: 1) it enables the LLM to more\neffectively follow the demonstration examples; 2) it's easy to control by\nadjusting the magnitude of the ICV; 3) it reduces the length of the prompt by\nremoving the in-context demonstrations; 4) ICV is computationally much more\nefficient than fine-tuning. We demonstrate that ICV achieves better performance\ncompared to standard in-context learning and fine-tuning on diverse tasks\nincluding safety, style transfer, role-playing and formatting. Moreover, we\nshow that we can flexibly teach LLM to simultaneously follow different types of\ninstructions by simple vector arithmetics on the corresponding ICVs.",
            "author": [
                "Sheng Liu",
                "Lei Xing",
                "James Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06668v2",
                "http://arxiv.org/pdf/2311.06668v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06667v1",
            "title": "Structured risk model",
            "updated": "2023-11-11T21:18:33Z",
            "published": "2023-11-11T21:18:33Z",
            "summary": "Income and risk coexist, yet investors are often so focused on chasing high\nreturns that they overlook the potential risks that can lead to high losses.\nTherefore, risk forecasting and risk control is the cornerstone of investment.\nTo address the challenge, we construct a multi-factor risk model on the basis\nof the classical multi-factor modeling framework. For the common factors,\ninspired by Barra Model's factor classification. we adjust the outliers and\nmissing values of factor exposure data, normalize and finally orthogonalize\nthem, before computing factor returns and making further analysis. Factor\nreturn covariance matrix and idiosyncratic return variance matrix are essential\ntools to express stock returns in the multi-factor risk model. Firstly, we\ncalculate the factor return covariance matrix with EWMA. To tackle the\ntime-series autocorrelation of factor returns, we apply Newey-West adjustment.\nThen we estimate the idiosyncratic return variance matrix in a similar way and\nmake Newey-West adjustment again to solve the time-series autocorrelation\nproblem. Since the return of a single share is sensitive to missing values and\noutliers, we introduce structural adjustment to improve the matrix.Eventually,\nwe obtain the return covariance matrix among stocks and compute the risk of\ninvestment portfolio based on it. Furthermore, we search for optimal portfolio\nwith respect to minimizing risk or maximizing risk-adjusted return with our\nmodel. They provide good Sharpe ratio and information ratio for considering\nboth absolute risk and active risk. Hence, the multi-factor risk model is\nefficient.",
            "author": [
                "Xinyuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06667v1",
                "http://arxiv.org/pdf/2311.06667v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06665v1",
            "title": "Withdrawal Success Optimization",
            "updated": "2023-11-11T21:10:04Z",
            "published": "2023-11-11T21:10:04Z",
            "summary": "For $n$ assets and discrete-time rebalancing, the probability to complete a\ngiven schedule of investments and withdrawals is maximized over progressively\nmeasurable portfolio weight functions. Applications consider two assets, namely\nthe S&P Composite Index and an inflation-protected bond. The maximum\nprobability and optimal portfolio weight functions are computed for annually\nrebalanced schedules involving an arbitrary initial investment and then equal\nannual withdrawals over the remainder of the time period. Applications also\nconsider annually rebalanced schedules that start with dollar cost averaging\n(equal annual investments) and then shift to equal annual withdrawals. Results\nindicate noticeable improvements in the probability to complete a given\nschedule when optimal portfolio weights are used instead of constant portfolio\nweights like the standard of keeping 90% in the S&P Composite Index and 10% in\ninflation-protected bonds.",
            "author": [
                "Hayden Brown"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06665v1",
                "http://arxiv.org/pdf/2311.06665v1"
            ],
            "primary_category": "q-fin.PM",
            "category": [
                "q-fin.PM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14704v1",
            "title": "An\u00e1lise e modelagem de jogos digitais: Relato de uma experi\u00eancia\n  educacional utlizando PBL em um grupo multidisciplinar",
            "updated": "2023-11-11T20:28:51Z",
            "published": "2023-11-11T20:28:51Z",
            "summary": "Traditional software engineering education generally emphasizes strict\ncollaboration and technical skills However active teaching strategies where\nstudents actively engage with the material transitioning from passive observers\nto active manipulators of realworld tools have shown effectiveness in software\nengineering The evolving market demands new skills in the context of digital\ntransformation presenting challenges such as modeling complex business\nscenarios and navigating the interconnections between people systems and\ntechnologies Shifting from conventional software engineering instruction to\nactive methodologies like ProblemBased Learning PBL has proven to bring\nrealworld market challenges and realities into the classroom This article\ndetails an experience from the Digital Games Analysis and Modeling course in\nthe Digital Games Masters program at Pontifical Catholic University of Sao\nPaulo It covers the discussed concepts case study rolebased work method and\nsteps of the meetings We also present examples of outcomes like requirement\ndiagrams context diagrams use case diagrams class diagrams interviews and\nothers that contributed to the Game Design Document GDD These were created by\neach group during the meetings alongside their game prototypes Additionally a\ndiscussion on the developed capabilities is included",
            "author": [
                "David de Oliveira Lemes",
                "Ezequiel Fran\u00e7a dos Santos",
                "Eduardo Romanek",
                "Celso Fujimoto",
                "Adriano Felix Valente"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14704v1",
                "http://arxiv.org/pdf/2311.14704v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06659v1",
            "title": "3DFusion, A real-time 3D object reconstruction pipeline based on\n  streamed instance segmented data",
            "updated": "2023-11-11T20:11:58Z",
            "published": "2023-11-11T20:11:58Z",
            "summary": "This paper presents a real-time segmentation and reconstruction system that\nutilizes RGB-D images to generate accurate and detailed individual 3D models of\nobjects within a captured scene. Leveraging state-of-the-art instance\nsegmentation techniques, the system performs pixel-level segmentation on RGB-D\ndata, effectively separating foreground objects from the background. The\nsegmented objects are then reconstructed into distinct 3D models in a\nhigh-performance computation platform. The real-time 3D modelling can be\napplied across various domains, including augmented/virtual reality, interior\ndesign, urban planning, road assistance, security systems, and more. To achieve\nreal-time performance, the paper proposes a method that effectively samples\nconsecutive frames to reduce network load while ensuring reconstruction\nquality. Additionally, a multi-process SLAM pipeline is adopted for parallel 3D\nreconstruction, enabling efficient cutting of the clustering objects into\nindividuals. This system employs the industry-leading framework YOLO for\ninstance segmentation. To improve YOLO's performance and accuracy,\nmodifications were made to resolve duplicated or false detection of similar\nobjects, ensuring the reconstructed models align with the targets. Overall,\nthis work establishes a robust real-time system with a significant enhancement\nfor object segmentation and reconstruction in the indoor environment. It can\npotentially be extended to the outdoor scenario, opening up numerous\nopportunities for real-world applications.",
            "author": [
                "Xi Sun",
                "Derek Jacoby",
                "Yvonne Coady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06659v1",
                "http://arxiv.org/pdf/2311.06659v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07611v1",
            "title": "Intentional Biases in LLM Responses",
            "updated": "2023-11-11T19:59:24Z",
            "published": "2023-11-11T19:59:24Z",
            "summary": "In this study we intentionally introduce biases into large language model\nresponses in an attempt to create specific personas for interactive media\npurposes. We explore the differences between open source models such as\nFalcon-7b and the GPT-4 model from Open AI, and we quantify some differences in\nresponses afforded by the two systems. We find that the guardrails in the GPT-4\nmixture of experts models with a supervisor, while useful in assuring AI\nalignment in general, are detrimental in trying to construct personas with a\nvariety of uncommon viewpoints. This study aims to set the groundwork for\nfuture exploration in intentional biases of large language models such that\nthese practices can be applied in the creative field, and new forms of media.",
            "author": [
                "Nicklaus Badyal",
                "Derek Jacoby",
                "Yvonne Coady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07611v1",
                "http://arxiv.org/pdf/2311.07611v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06655v1",
            "title": "Peculiarities of charged particle kinetics in spherical plasma",
            "updated": "2023-11-11T19:48:00Z",
            "published": "2023-11-11T19:48:00Z",
            "summary": "We describe kinetic simulations of transient problems in partially ionized\nweakly-collisional plasma around spherical bodies absorbing or emitting charged\nparticles. Numerical solutions of kinetic equations for electrons and ions in\n1D2V phase space are coupled to an electrostatic solver using the Poisson\nequation or quasineutrality condition for small Debye lengths. The formation of\nparticle groups and their contributions to electric current flow and screening\nof charged bodies by plasma are discussed for applications to Langmuir probes\nand solar wind.",
            "author": [
                "V I Kolobov",
                "R R Arslanbekov",
                "H Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06655v1",
                "http://arxiv.org/pdf/2311.06655v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06654v1",
            "title": "Unsupervised and semi-supervised co-salient object detection via\n  segmentation frequency statistics",
            "updated": "2023-11-11T19:47:16Z",
            "published": "2023-11-11T19:47:16Z",
            "summary": "In this paper, we address the detection of co-occurring salient objects\n(CoSOD) in an image group using frequency statistics in an unsupervised manner,\nwhich further enable us to develop a semi-supervised method. While previous\nworks have mostly focused on fully supervised CoSOD, less attention has been\nallocated to detecting co-salient objects when limited segmentation annotations\nare available for training. Our simple yet effective unsupervised method\nUS-CoSOD combines the object co-occurrence frequency statistics of unsupervised\nsingle-image semantic segmentations with salient foreground detections using\nself-supervised feature learning. For the first time, we show that a large\nunlabeled dataset e.g. ImageNet-1k can be effectively leveraged to\nsignificantly improve unsupervised CoSOD performance. Our unsupervised model is\na great pre-training initialization for our semi-supervised model SS-CoSOD,\nespecially when very limited labeled data is available for training. To avoid\npropagating erroneous signals from predictions on unlabeled data, we propose a\nconfidence estimation module to guide our semi-supervised training. Extensive\nexperiments on three CoSOD benchmark datasets show that both of our\nunsupervised and semi-supervised models outperform the corresponding\nstate-of-the-art models by a significant margin (e.g., on the Cosal2015\ndataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised\nco-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over\na SOTA semi-supervised CoSOD model).",
            "author": [
                "Souradeep Chakraborty",
                "Shujon Naha",
                "Muhammet Bastan",
                "Amit Kumar K C",
                "Dimitris Samaras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06654v1",
                "http://arxiv.org/pdf/2311.06654v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06651v1",
            "title": "Traffic Sign Recognition Using Local Vision Transformer",
            "updated": "2023-11-11T19:42:41Z",
            "published": "2023-11-11T19:42:41Z",
            "summary": "Recognition of traffic signs is a crucial aspect of self-driving cars and\ndriver assistance systems, and machine vision tasks such as traffic sign\nrecognition have gained significant attention. CNNs have been frequently used\nin machine vision, but introducing vision transformers has provided an\nalternative approach to global feature learning. This paper proposes a new\nnovel model that blends the advantages of both convolutional and\ntransformer-based networks for traffic sign recognition. The proposed model\nincludes convolutional blocks for capturing local correlations and\ntransformer-based blocks for learning global dependencies. Additionally, a\nlocality module is incorporated to enhance local perception. The performance of\nthe suggested model is evaluated on the Persian Traffic Sign Dataset and German\nTraffic Sign Recognition Benchmark and compared with SOTA convolutional and\ntransformer-based models. The experimental evaluations demonstrate that the\nhybrid network with the locality module outperforms pure transformer-based\nmodels and some of the best convolutional networks in accuracy. Specifically,\nour proposed final model reached 99.66% accuracy in the German traffic sign\nrecognition benchmark and 99.8% in the Persian traffic sign dataset, higher\nthan the best convolutional models. Moreover, it outperforms existing CNNs and\nViTs while maintaining fast inference speed. Consequently, the proposed model\nproves to be significantly faster and more suitable for real-world\napplications.",
            "author": [
                "Ali Farzipour",
                "Omid Nejati Manzari",
                "Shahriar B. Shokouhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06651v1",
                "http://arxiv.org/pdf/2311.06651v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06649v1",
            "title": "A Template Is All You Meme",
            "updated": "2023-11-11T19:38:14Z",
            "published": "2023-11-11T19:38:14Z",
            "summary": "Memes are a modern form of communication and meme templates possess a base\nsemantics that is customizable by whomever posts it on social media. Machine\nlearning systems struggle with memes, which is likely due to such systems\nhaving insufficient context to understand memes, as there is more to memes than\nthe obvious image and text. Here, to aid understanding of memes, we release a\nknowledge base of memes and information found on www.knowyourmeme.com, which we\ncall the Know Your Meme Knowledge Base (KYMKB), composed of more than 54,000\nimages. The KYMKB includes popular meme templates, examples of each template,\nand detailed information about the template. We hypothesize that meme templates\ncan be used to inject models with the context missing from previous approaches.\nTo test our hypothesis, we create a non-parametric majority-based classifier,\nwhich we call Template-Label Counter (TLC). We find TLC more effective than or\ncompetitive with fine-tuned baselines. To demonstrate the power of meme\ntemplates and the value of both our knowledge base and method, we conduct\nthorough classification experiments and exploratory data analysis in the\ncontext of five meme analysis tasks.",
            "author": [
                "Luke Bates",
                "Peter Ebert Christensen",
                "Preslav Nakov",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06649v1",
                "http://arxiv.org/pdf/2311.06649v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06647v1",
            "title": "Robust Text Classification: Analyzing Prototype-Based Networks",
            "updated": "2023-11-11T19:34:06Z",
            "published": "2023-11-11T19:34:06Z",
            "summary": "Downstream applications often require text classification models to be\naccurate, robust, and interpretable. While the accuracy of the stateof-the-art\nlanguage models approximates human performance, they are not designed to be\ninterpretable and often exhibit a drop in performance on noisy data. The family\nof PrototypeBased Networks (PBNs) that classify examples based on their\nsimilarity to prototypical examples of a class (prototypes) is natively\ninterpretable and shown to be robust to noise, which enabled its wide usage for\ncomputer vision tasks. In this paper, we study whether the robustness\nproperties of PBNs transfer to text classification tasks. We design a modular\nand comprehensive framework for studying PBNs, which includes different\nbackbone architectures, backbone sizes, and objective functions. Our evaluation\nprotocol assesses the robustness of models against character-, word-, and\nsentence-level perturbations. Our experiments on three benchmarks show that the\nrobustness of PBNs transfers to NLP classification tasks facing realistic\nperturbations. Moreover, the robustness of PBNs is supported mostly by the\nobjective function that keeps prototypes interpretable, while the robustness\nsuperiority of PBNs over vanilla models becomes more salient as datasets get\nmore complex.",
            "author": [
                "Zhivar Sourati",
                "Darshan Deshpande",
                "Filip Ilievski",
                "Kiril Gashteovski",
                "Sascha Saralajew"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06647v1",
                "http://arxiv.org/pdf/2311.06647v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    }
]