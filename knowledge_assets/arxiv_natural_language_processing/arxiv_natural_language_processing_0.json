[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04567v1",
            "title": "Scaling Laws of Synthetic Images for Model Training ... for Now",
            "updated": "2023-12-07T18:59:59Z",
            "published": "2023-12-07T18:59:59Z",
            "summary": "Recent significant advances in text-to-image models unlock the possibility of\ntraining vision systems using synthetic images, potentially overcoming the\ndifficulty of collecting curated data at scale. It is unclear, however, how\nthese models behave at scale, as more synthetic data is added to the training\nset. In this paper we study the scaling laws of synthetic images generated by\nstate of the art text-to-image models, for the training of supervised models:\nimage classifiers with label supervision, and CLIP with language supervision.\nWe identify several factors, including text prompts, classifier-free guidance\nscale, and types of text-to-image models, that significantly affect scaling\nbehavior. After tuning these factors, we observe that synthetic images\ndemonstrate a scaling trend similar to, but slightly less effective than, real\nimages in CLIP training, while they significantly underperform in scaling when\ntraining supervised image classifiers. Our analysis indicates that the main\nreason for this underperformance is the inability of off-the-shelf\ntext-to-image models to generate certain concepts, a limitation that\nsignificantly impairs the training of image classifiers. Our findings also\nsuggest that scaling synthetic data can be particularly effective in scenarios\nsuch as: (1) when there is a limited supply of real images for a supervised\nproblem (e.g., fewer than 0.5 million images in ImageNet), (2) when the\nevaluation dataset diverges significantly from the training data, indicating\nthe out-of-distribution scenario, or (3) when synthetic data is used in\nconjunction with real images, as demonstrated in the training of CLIP models.",
            "author": [
                "Lijie Fan",
                "Kaifeng Chen",
                "Dilip Krishnan",
                "Dina Katabi",
                "Phillip Isola",
                "Yonglong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04567v1",
                "http://arxiv.org/pdf/2312.04567v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04565v1",
            "title": "MuRF: Multi-Baseline Radiance Fields",
            "updated": "2023-12-07T18:59:56Z",
            "published": "2023-12-07T18:59:56Z",
            "summary": "We present Multi-Baseline Radiance Fields (MuRF), a general feed-forward\napproach to solving sparse view synthesis under multiple different baseline\nsettings (small and large baselines, and different number of input views). To\nrender a target novel view, we discretize the 3D space into planes parallel to\nthe target image plane, and accordingly construct a target view frustum volume.\nSuch a target volume representation is spatially aligned with the target view,\nwhich effectively aggregates relevant information from the input views for\nhigh-quality rendering. It also facilitates subsequent radiance field\nregression with a convolutional network thanks to its axis-aligned nature. The\n3D context modeled by the convolutional network enables our method to synthesis\nsharper scene structures than prior works. Our MuRF achieves state-of-the-art\nperformance across multiple different baseline settings and diverse scenarios\nranging from simple objects (DTU) to complex indoor and outdoor scenes\n(RealEstate10K and LLFF). We also show promising zero-shot generalization\nabilities on the Mip-NeRF 360 dataset, demonstrating the general applicability\nof MuRF.",
            "author": [
                "Haofei Xu",
                "Anpei Chen",
                "Yuedong Chen",
                "Christos Sakaridis",
                "Yulun Zhang",
                "Marc Pollefeys",
                "Andreas Geiger",
                "Fisher Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04565v1",
                "http://arxiv.org/pdf/2312.04565v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04561v1",
            "title": "GenDeF: Learning Generative Deformation Field for Video Generation",
            "updated": "2023-12-07T18:59:41Z",
            "published": "2023-12-07T18:59:41Z",
            "summary": "We offer a new perspective on approaching the task of video generation.\nInstead of directly synthesizing a sequence of frames, we propose to render a\nvideo by warping one static image with a generative deformation field (GenDeF).\nSuch a pipeline enjoys three appealing advantages. First, we can sufficiently\nreuse a well-trained image generator to synthesize the static image (also\ncalled canonical image), alleviating the difficulty in producing a video and\nthereby resulting in better visual quality. Second, we can easily convert a\ndeformation field to optical flows, making it possible to apply explicit\nstructural regularizations for motion modeling, leading to temporally\nconsistent results. Third, the disentanglement between content and motion\nallows users to process a synthesized video through processing its\ncorresponding static image without any tuning, facilitating many applications\nlike video editing, keypoint tracking, and video segmentation. Both qualitative\nand quantitative results on three common video generation benchmarks\ndemonstrate the superiority of our GenDeF method.",
            "author": [
                "Wen Wang",
                "Kecheng Zheng",
                "Qiuyu Wang",
                "Hao Chen",
                "Zifan Shi",
                "Ceyuan Yang",
                "Yujun Shen",
                "Chunhua Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04561v1",
                "http://arxiv.org/pdf/2312.04561v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04559v1",
            "title": "PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation",
            "updated": "2023-12-07T18:59:33Z",
            "published": "2023-12-07T18:59:33Z",
            "summary": "We present PrimDiffusion, the first diffusion-based framework for 3D human\ngeneration. Devising diffusion models for 3D human generation is difficult due\nto the intensive computational cost of 3D representations and the articulated\ntopology of 3D humans. To tackle these challenges, our key insight is operating\nthe denoising diffusion process directly on a set of volumetric primitives,\nwhich models the human body as a number of small volumes with radiance and\nkinematic information. This volumetric primitives representation marries the\ncapacity of volumetric representations with the efficiency of primitive-based\nrendering. Our PrimDiffusion framework has three appealing properties: 1)\ncompact and expressive parameter space for the diffusion model, 2) flexible 3D\nrepresentation that incorporates human prior, and 3) decoder-free rendering for\nefficient novel-view and novel-pose synthesis. Extensive experiments validate\nthat PrimDiffusion outperforms state-of-the-art methods in 3D human generation.\nNotably, compared to GAN-based methods, our PrimDiffusion supports real-time\nrendering of high-quality 3D humans at a resolution of $512\\times512$ once the\ndenoising process is done. We also demonstrate the flexibility of our framework\non training-free conditional generation such as texture transfer and 3D\ninpainting.",
            "author": [
                "Zhaoxi Chen",
                "Fangzhou Hong",
                "Haiyi Mei",
                "Guangcong Wang",
                "Lei Yang",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04559v1",
                "http://arxiv.org/pdf/2312.04559v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04557v1",
            "title": "GenTron: Delving Deep into Diffusion Transformers for Image and Video\n  Generation",
            "updated": "2023-12-07T18:59:30Z",
            "published": "2023-12-07T18:59:30Z",
            "summary": "In this study, we explore Transformer-based diffusion models for image and\nvideo generation. Despite the dominance of Transformer architectures in various\nfields due to their flexibility and scalability, the visual generative domain\nprimarily utilizes CNN-based U-Net architectures, particularly in\ndiffusion-based models. We introduce GenTron, a family of Generative models\nemploying Transformer-based diffusion, to address this gap. Our initial step\nwas to adapt Diffusion Transformers (DiTs) from class to text conditioning, a\nprocess involving thorough empirical exploration of the conditioning mechanism.\nWe then scale GenTron from approximately 900M to over 3B parameters, observing\nsignificant improvements in visual quality. Furthermore, we extend GenTron to\ntext-to-video generation, incorporating novel motion-free guidance to enhance\nvideo quality. In human evaluations against SDXL, GenTron achieves a 51.1% win\nrate in visual quality (with a 19.8% draw rate), and a 42.3% win rate in text\nalignment (with a 42.9% draw rate). GenTron also excels in the T2I-CompBench,\nunderscoring its strengths in compositional generation. We believe this work\nwill provide meaningful insights and serve as a valuable reference for future\nresearch.",
            "author": [
                "Shoufa Chen",
                "Mengmeng Xu",
                "Jiawei Ren",
                "Yuren Cong",
                "Sen He",
                "Yanping Xie",
                "Animesh Sinha",
                "Ping Luo",
                "Tao Xiang",
                "Juan-Manuel Perez-Rua"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04557v1",
                "http://arxiv.org/pdf/2312.04557v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04556v1",
            "title": "Large Language Models for Mathematicians",
            "updated": "2023-12-07T18:59:29Z",
            "published": "2023-12-07T18:59:29Z",
            "summary": "Large language models (LLMs) such as ChatGPT have received immense interest\nfor their general-purpose language understanding and, in particular, their\nability to generate high-quality text or computer code. For many professions,\nLLMs represent an invaluable tool that can speed up and improve the quality of\nwork. In this note, we discuss to what extent they can aid professional\nmathematicians. We first provide a mathematical description of the transformer\nmodel used in all modern language models. Based on recent studies, we then\noutline best practices and potential issues and report on the mathematical\nabilities of language models. Finally, we shed light on the potential of LMMs\nto change how mathematicians work.",
            "author": [
                "Simon Frieder",
                "Julius Berner",
                "Philipp Petersen",
                "Thomas Lukasiewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04556v1",
                "http://arxiv.org/pdf/2312.04556v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "math.HO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04554v1",
            "title": "Improved Visual Grounding through Self-Consistent Explanations",
            "updated": "2023-12-07T18:59:22Z",
            "published": "2023-12-07T18:59:22Z",
            "summary": "Vision-and-language models trained to match images with text can be combined\nwith visual explanation methods to point to the locations of specific objects\nin an image. Our work shows that the localization --\"grounding\"-- abilities of\nthese models can be further improved by finetuning for self-consistent visual\nexplanations. We propose a strategy for augmenting existing text-image datasets\nwith paraphrases using a large language model, and SelfEQ, a weakly-supervised\nstrategy on visual explanation maps for paraphrases that encourages\nself-consistency. Specifically, for an input textual phrase, we attempt to\ngenerate a paraphrase and finetune the model so that the phrase and paraphrase\nmap to the same region in the image. We posit that this both expands the\nvocabulary that the model is able to handle, and improves the quality of the\nobject locations highlighted by gradient-based visual explanation methods (e.g.\nGradCAM). We demonstrate that SelfEQ improves performance on Flickr30k,\nReferIt, and RefCOCO+ over a strong baseline method and several prior works.\nParticularly, comparing to other methods that do not use any type of box\nannotations, we obtain 84.07% on Flickr30k (an absolute improvement of 4.69%),\n67.40% on ReferIt (an absolute improvement of 7.68%), and 75.10%, 55.49% on\nRefCOCO+ test sets A and B respectively (an absolute improvement of 3.74% on\naverage).",
            "author": [
                "Ruozhen He",
                "Paola Cascante-Bonilla",
                "Ziyan Yang",
                "Alexander C. Berg",
                "Vicente Ordonez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04554v1",
                "http://arxiv.org/pdf/2312.04554v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04553v1",
            "title": "SPIDeRS: Structured Polarization for Invisible Depth and Reflectance\n  Sensing",
            "updated": "2023-12-07T18:59:21Z",
            "published": "2023-12-07T18:59:21Z",
            "summary": "Can we capture shape and reflectance in stealth? Such capability would be\nvaluable for many application domains in vision, xR, robotics, and HCI. We\nintroduce Structured Polarization, the first depth and reflectance sensing\nmethod using patterns of polarized light (SPIDeRS). The key idea is to modulate\nthe angle of linear polarization (AoLP) of projected light at each pixel. The\nuse of polarization makes it invisible and lets us recover not only depth but\nalso directly surface normals and even reflectance. We implement SPIDeRS with a\nliquid crystal spatial light modulator (SLM) and a polarimetric camera. We\nderive a novel method for robustly extracting the projected structured\npolarization pattern from the polarimetric object appearance. We evaluate the\neffectiveness of SPIDeRS by applying it to a number of real-world objects. The\nresults show that our method successfully reconstructs object shapes of various\nmaterials and is robust to diffuse reflection and ambient light. We also\ndemonstrate relighting using recovered surface normals and reflectance. We\nbelieve SPIDeRS opens a new avenue of polarization use in visual sensing.",
            "author": [
                "Tomoki Ichikawa",
                "Shohei Nobuhara",
                "Ko Nishino"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04553v1",
                "http://arxiv.org/pdf/2312.04553v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04552v1",
            "title": "Generating Illustrated Instructions",
            "updated": "2023-12-07T18:59:20Z",
            "published": "2023-12-07T18:59:20Z",
            "summary": "We introduce the new task of generating Illustrated Instructions, i.e.,\nvisual instructions customized to a user's needs. We identify desiderata unique\nto this task, and formalize it through a suite of automatic and human\nevaluation metrics, designed to measure the validity, consistency, and efficacy\nof the generations. We combine the power of large language models (LLMs)\ntogether with strong text-to-image generation diffusion models to propose a\nsimple approach called StackedDiffusion, which generates such illustrated\ninstructions given text as input. The resulting model strongly outperforms\nbaseline approaches and state-of-the-art multimodal LLMs; and in 30% of cases,\nusers even prefer it to human-generated articles. Most notably, it enables\nvarious new and exciting applications far beyond what static articles on the\nweb can provide, such as personalized instructions complete with intermediate\nsteps and pictures in response to a user's individual situation.",
            "author": [
                "Sachit Menon",
                "Ishan Misra",
                "Rohit Girdhar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04552v1",
                "http://arxiv.org/pdf/2312.04552v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04549v1",
            "title": "PlayFusion: Skill Acquisition via Diffusion from Language-Annotated Play",
            "updated": "2023-12-07T18:59:14Z",
            "published": "2023-12-07T18:59:14Z",
            "summary": "Learning from unstructured and uncurated data has become the dominant\nparadigm for generative approaches in language and vision. Such unstructured\nand unguided behavior data, commonly known as play, is also easier to collect\nin robotics but much more difficult to learn from due to its inherently\nmultimodal, noisy, and suboptimal nature. In this paper, we study this problem\nof learning goal-directed skill policies from unstructured play data which is\nlabeled with language in hindsight. Specifically, we leverage advances in\ndiffusion models to learn a multi-task diffusion model to extract robotic\nskills from play data. Using a conditional denoising diffusion process in the\nspace of states and actions, we can gracefully handle the complexity and\nmultimodality of play data and generate diverse and interesting robot\nbehaviors. To make diffusion models more useful for skill learning, we\nencourage robotic agents to acquire a vocabulary of skills by introducing\ndiscrete bottlenecks into the conditional behavior generation process. In our\nexperiments, we demonstrate the effectiveness of our approach across a wide\nvariety of environments in both simulation and the real world. Results\nvisualizations and videos at https://play-fusion.github.io",
            "author": [
                "Lili Chen",
                "Shikhar Bahl",
                "Deepak Pathak"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04549v1",
                "http://arxiv.org/pdf/2312.04549v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04547v1",
            "title": "Digital Life Project: Autonomous 3D Characters with Social Intelligence",
            "updated": "2023-12-07T18:58:59Z",
            "published": "2023-12-07T18:58:59Z",
            "summary": "In this work, we present Digital Life Project, a framework utilizing language\nas the universal medium to build autonomous 3D characters, who are capable of\nengaging in social interactions and expressing with articulated body motions,\nthereby simulating life in a digital environment. Our framework comprises two\nprimary components: 1) SocioMind: a meticulously crafted digital brain that\nmodels personalities with systematic few-shot exemplars, incorporates a\nreflection process based on psychology principles, and emulates autonomy by\ninitiating dialogue topics; 2) MoMat-MoGen: a text-driven motion synthesis\nparadigm for controlling the character's digital body. It integrates motion\nmatching, a proven industry technique to ensure motion quality, with\ncutting-edge advancements in motion generation for diversity. Extensive\nexperiments demonstrate that each module achieves state-of-the-art performance\nin its respective domain. Collectively, they enable virtual characters to\ninitiate and sustain dialogues autonomously, while evolving their\nsocio-psychological states. Concurrently, these characters can perform\ncontextually relevant bodily movements. Additionally, a motion captioning\nmodule further allows the virtual character to recognize and appropriately\nrespond to human players' actions. Homepage: https://digital-life-project.com/",
            "author": [
                "Zhongang Cai",
                "Jianping Jiang",
                "Zhongfei Qing",
                "Xinying Guo",
                "Mingyuan Zhang",
                "Zhengyu Lin",
                "Haiyi Mei",
                "Chen Wei",
                "Ruisi Wang",
                "Wanqi Yin",
                "Xiangyu Fan",
                "Han Du",
                "Liang Pan",
                "Peng Gao",
                "Zhitao Yang",
                "Yang Gao",
                "Jiaqi Li",
                "Tianxiang Ren",
                "Yukun Wei",
                "Xiaogang Wang",
                "Chen Change Loy",
                "Lei Yang",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04547v1",
                "http://arxiv.org/pdf/2312.04547v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04546v1",
            "title": "Adversarial Learning for Feature Shift Detection and Correction",
            "updated": "2023-12-07T18:58:40Z",
            "published": "2023-12-07T18:58:40Z",
            "summary": "Data shift is a phenomenon present in many real-world applications, and while\nthere are multiple methods attempting to detect shifts, the task of localizing\nand correcting the features originating such shifts has not been studied in\ndepth. Feature shifts can occur in many datasets, including in multi-sensor\ndata, where some sensors are malfunctioning, or in tabular and structured data,\nincluding biomedical, financial, and survey data, where faulty standardization\nand data processing pipelines can lead to erroneous features. In this work, we\nexplore using the principles of adversarial learning, where the information\nfrom several discriminators trained to distinguish between two distributions is\nused to both detect the corrupted features and fix them in order to remove the\ndistribution shift between datasets. We show that mainstream supervised\nclassifiers, such as random forest or gradient boosting trees, combined with\nsimple iterative heuristics, can localize and correct feature shifts,\noutperforming current statistical and neural network-based techniques. The code\nis available at https://github.com/AI-sandbox/DataFix.",
            "author": [
                "Miriam Barrabes",
                "Daniel Mas Montserrat",
                "Margarita Geleta",
                "Xavier Giro-i-Nieto",
                "Alexander G. Ioannidis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04546v1",
                "http://arxiv.org/pdf/2312.04546v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04539v1",
            "title": "Self-Guided Open-Vocabulary Semantic Segmentation",
            "updated": "2023-12-07T18:55:52Z",
            "published": "2023-12-07T18:55:52Z",
            "summary": "Vision-Language Models (VLMs) have emerged as promising tools for open-ended\nimage understanding tasks, including open vocabulary segmentation. Yet, direct\napplication of such VLMs to segmentation is non-trivial, since VLMs are trained\nwith image-text pairs and naturally lack pixel-level granularity. Recent works\nhave made advancements in bridging this gap, often by leveraging the shared\nimage-text space in which the image and a provided text prompt are represented.\nIn this paper, we challenge the capabilities of VLMs further and tackle\nopen-vocabulary segmentation without the need for any textual input. To this\nend, we propose a novel Self-Guided Semantic Segmentation (Self-Seg) framework.\nSelf-Seg is capable of automatically detecting relevant class names from\nclustered BLIP embeddings and using these for accurate semantic segmentation.\nIn addition, we propose an LLM-based Open-Vocabulary Evaluator (LOVE) to\neffectively assess predicted open-vocabulary class names. We achieve\nstate-of-the-art results on Pascal VOC, ADE20K and CityScapes for\nopen-vocabulary segmentation without given class names, as well as competitive\nperformance with methods where class names are given. All code and data will be\nreleased.",
            "author": [
                "Osman \u00dclger",
                "Maksymilian Kulicki",
                "Yuki Asano",
                "Martin R. Oswald"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04539v1",
                "http://arxiv.org/pdf/2312.04539v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04538v1",
            "title": "Direct and indirect spin current generation and spin-orbit torques in\n  ferromagnet/nonmagnet/ferromagnet trilayers",
            "updated": "2023-12-07T18:55:45Z",
            "published": "2023-12-07T18:55:45Z",
            "summary": "Spin-orbit torques in ferromagnet/nonmagnet/ferromagnet trilayers are studied\nusing a combination of symmetry analysis, circuit theory, semiclassical\nsimulations, and first-principles calculations using the non-equilibrium\nGreen's function method with supercell disorder averaging. We focus on\nunconventional processes involving the interplay between the two ferromagnetic\nlayers, which are classified into direct and indirect mechanisms. The direct\nmechanism involves spin current generation by one ferromagnetic layer and its\nsubsequent absorption by the other. In the indirect mechanism, the in-plane\nspin-polarized current from one ferromagnetic layer ``leaks'' into the other\nlayer, where it is converted into an out-of-plane spin current and reabsorbed\nby the original layer. The direct mechanism results in a predominantly\ndampinglike torque, which damps the magnetization towards a certain direction\n$\\mathbf{s}_d$. The indirect mechanism results in a predominantly fieldlike\ntorque with respect to a generally different direction $\\mathbf{s}_f$. Similar\nto the current-in-plane giant magnetoresistance, the indirect mechanism is only\nactive if the thickness of the nonmagnetic spacer is smaller than or comparable\nto the mean-free path. Numerical calculations for a semiclassical model based\non the Boltzmann equation confirm the presence of both direct and indirect\nmechanisms of spin current generation. First-principles calculations reveal\nsizeable unconventional spin-orbit torques in Co/Cu/Co, Py/Cu/Py, and Co/Pt/Co\ntrilayers and provide strong evidence of indirect spin current generation.",
            "author": [
                "V. P. Amin",
                "G. G. Baez Flores",
                "A. A. Kovalev",
                "K. D. Belashchenko"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04538v1",
                "http://arxiv.org/pdf/2312.04538v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04536v1",
            "title": "Invisibility of the integers for the discrete Gaussian chain via a\n  Caffarelli-Silvestre extension of the discrete fractional Laplacian",
            "updated": "2023-12-07T18:55:12Z",
            "published": "2023-12-07T18:55:12Z",
            "summary": "The Discrete Gaussian Chain is a model of interfaces $\\Psi : \\mathbf{Z} \\to\n\\mathbf{Z}$ governed by the Hamiltonian $$ H(\\Psi)= \\sum_{i\\neq j}\nJ_\\alpha(|i-j|) |\\Psi_i -\\Psi_j|^2 $$ with long-range coupling constants\n$J_\\alpha(k)\\asymp k^{-\\alpha}$. For any $\\alpha\\in [2,3)$ and at high enough\ntemperature, we prove an invariance principle for such an $\\alpha$-Discrete\nGaussian Chain towards a $H(\\alpha)$-fractional Gaussian process where the\nHurst index $H$ satisfies $H=H(\\alpha)=\\frac {\\alpha-2} 2$.\n  This result goes beyond a conjecture by Fr\\\"ohlich and Zegarlinski\n\\cite{frohlich1991phase} which conjectured fluctuations of order $n^{\\tfrac 1 2\n(\\alpha-2) \\wedge 1}$ for the Discrete Gaussian Chain.\n  More surprisingly, as opposed to the case of $2D$ Discrete Gaussian $\\Psi :\n\\mathbf{Z}^2 \\to \\mathbf{Z}$, we prove that the integers do not affect the {\\em\neffective temperature} of the discrete Gaussian Chain at large scales. Such an\n{\\em invisibility of the integers} had been predicted by Slurink and Hilhorst\nin the special case $\\alpha_c=2$ in \\cite{slurink1983roughening}.\n  Our proof relies on four main ingredients: (1) A Caffareli-Silvestre\nextension for the discrete fractional Laplacian (which may be of independent\ninterest) (2) A localisation of the chain in a smoother sub-domain (3) A\nCoulomb gas-type expansion in the spirit of Fr\\\"ohlich-Spencer \\cite{FS} (4)\nControlling the amount of Dirichlet Energy supported by a $1D$ band for the\nGreen functions of $\\mathbf{Z}^2$ Bessel type random walks\n  Our results also have implications for the so-called {\\em Boundary\nSine-Gordon field}. Finally, we analyse the (easier) regimes where\n$\\alpha\\in(1,2) \\cup (3,\\infty)$ as well as the $2D$ Discrete Gaussian with\nlong-range coupling constants (for any $\\alpha>\\alpha_c=4$).",
            "author": [
                "Christophe Garban"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04536v1",
                "http://arxiv.org/pdf/2312.04536v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04535v1",
            "title": "Trajeglish: Learning the Language of Driving Scenarios",
            "updated": "2023-12-07T18:53:27Z",
            "published": "2023-12-07T18:53:27Z",
            "summary": "A longstanding challenge for self-driving development is simulating dynamic\ndriving scenarios seeded from recorded driving logs. In pursuit of this\nfunctionality, we apply tools from discrete sequence modeling to model how\nvehicles, pedestrians and cyclists interact in driving scenarios. Using a\nsimple data-driven tokenization scheme, we discretize trajectories to\ncentimeter-level resolution using a small vocabulary. We then model the\nmulti-agent sequence of motion tokens with a GPT-like encoder-decoder that is\nautoregressive in time and takes into account intra-timestep interaction\nbetween agents. Scenarios sampled from our model exhibit state-of-the-art\nrealism; our model tops the Waymo Sim Agents Benchmark, surpassing prior work\nalong the realism meta metric by 3.3% and along the interaction metric by 9.9%.\nWe ablate our modeling choices in full autonomy and partial autonomy settings,\nand show that the representations learned by our model can quickly be adapted\nto improve performance on nuScenes. We additionally evaluate the scalability of\nour model with respect to parameter count and dataset size, and use density\nestimates from our model to quantify the saliency of context length and\nintra-timestep interaction for the traffic modeling task.",
            "author": [
                "Jonah Philion",
                "Xue Bin Peng",
                "Sanja Fidler"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04535v1",
                "http://arxiv.org/pdf/2312.04535v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04533v1",
            "title": "Dream2Real: Zero-Shot 3D Object Rearrangement with Vision-Language\n  Models",
            "updated": "2023-12-07T18:51:19Z",
            "published": "2023-12-07T18:51:19Z",
            "summary": "We introduce Dream2Real, a robotics framework which integrates\nvision-language models (VLMs) trained on 2D data into a 3D object rearrangement\npipeline. This is achieved by the robot autonomously constructing a 3D\nrepresentation of the scene, where objects can be rearranged virtually and an\nimage of the resulting arrangement rendered. These renders are evaluated by a\nVLM, so that the arrangement which best satisfies the user instruction is\nselected and recreated in the real world with pick-and-place. This enables\nlanguage-conditioned rearrangement to be performed zero-shot, without needing\nto collect a training dataset of example arrangements. Results on a series of\nreal-world tasks show that this framework is robust to distractors,\ncontrollable by language, capable of understanding complex multi-object\nrelations, and readily applicable to both tabletop and 6-DoF rearrangement\ntasks.",
            "author": [
                "Ivan Kapelyukh",
                "Yifei Ren",
                "Ignacio Alzugaray",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04533v1",
                "http://arxiv.org/pdf/2312.04533v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04529v1",
            "title": "Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of\n  Illumination and Reflectance",
            "updated": "2023-12-07T18:50:00Z",
            "published": "2023-12-07T18:50:00Z",
            "summary": "Reflectance bounds the frequency spectrum of illumination in the object\nappearance. In this paper, we introduce the first stochastic inverse rendering\nmethod, which recovers the full frequency spectrum of an illumination jointly\nwith the object reflectance from a single image. Our key idea is to solve this\nblind inverse problem in the reflectance map, an appearance representation\ninvariant to the underlying geometry, by learning to reverse the image\nformation with a novel diffusion model which we refer to as the Diffusion\nReflectance Map Network (DRMNet). Given an observed reflectance map converted\nand completed from the single input image, DRMNet generates a reflectance map\ncorresponding to a perfect mirror sphere while jointly estimating the\nreflectance. The forward process can be understood as gradually filtering a\nnatural illumination with lower and lower frequency reflectance and additive\nGaussian noise. DRMNet learns to invert this process with two subnetworks,\nIllNet and RefNet, which work in concert towards this joint estimation. The\nnetwork is trained on an extensive synthetic dataset and is demonstrated to\ngeneralize to real images, showing state-of-the-art accuracy on established\ndatasets.",
            "author": [
                "Yuto Enyo",
                "Ko Nishino"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04529v1",
                "http://arxiv.org/pdf/2312.04529v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04528v1",
            "title": "Using Large Language Models for Hyperparameter Optimization",
            "updated": "2023-12-07T18:46:50Z",
            "published": "2023-12-07T18:46:50Z",
            "summary": "This paper studies using foundational large language models (LLMs) to make\ndecisions during hyperparameter optimization (HPO). Empirical evaluations\ndemonstrate that in settings with constrained search budgets, LLMs can perform\ncomparably or better than traditional HPO methods like random search and\nBayesian optimization on standard benchmarks. Furthermore, we propose to treat\nthe code specifying our model as a hyperparameter, which the LLM outputs, going\nbeyond the capabilities of existing HPO approaches. Our findings suggest that\nLLMs are a promising tool for improving efficiency in the traditional\ndecision-making problem of hyperparameter optimization.",
            "author": [
                "Michael R. Zhang",
                "Nishkrit Desai",
                "Juhan Bae",
                "Jonathan Lorraine",
                "Jimmy Ba"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04528v1",
                "http://arxiv.org/pdf/2312.04528v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04523v1",
            "title": "Branched It\u00f4 Formula and natural It\u00f4-Stratonovich isomorphism",
            "updated": "2023-12-07T18:43:36Z",
            "published": "2023-12-07T18:43:36Z",
            "summary": "Branched rough paths define integration theories that may fail to satisfy the\nusual integration by parts identity. The intrinsically-defined projection of\nthe Connes-Kreimer Hopf algebra onto its primitive elements defined by\nBroadhurst and Kreimer, and further studied by Foissy, allows us to view it as\na commutative $\\mathbf{B}_\\infty$-algebra and thus to write an explicit\nchange-of-variable formula for solutions to rough differential equations. This\nformula, which is realised by means of an explicit morphism from the\nGrossman-Larson Hopf algebra to the Hopf algebra of differential operators,\nrestricts to the well-known It\\^o formula for semimartingales. We stablish an\nisomorphism with the shuffle algebra over primitives, extending Hoffman's\nexponential for the quasi shuffle algebra, and in particular the usual\nIt\\^o-Stratonovich correction formula for semimartingales. We place special\nemphasis on the one-dimensional case, in which certain rough path terms can be\nexpressed as polynomials in the extended trace path, which for semimartingales\nrestrict to the well-known Kailath-Segall polynomials. We end by describing an\nalgebraic framework for generating examples of branched rough paths, and,\nmotivated by the recent literature on stochastic processes, exhibit a few such\nexamples above scalar 1/4-fractional Brownian motion, two of which are \"truly\nbranched\", i.e. not quasi-geometric.",
            "author": [
                "Carlo Bellingeri",
                "Emilio Ferrucci",
                "Nikolas Tapia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04523v1",
                "http://arxiv.org/pdf/2312.04523v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CA",
                "math.RA",
                "60L20, 60L70, 16T30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04517v1",
            "title": "D-terms in Generalised Complex Geometry",
            "updated": "2023-12-07T18:37:02Z",
            "published": "2023-12-07T18:37:02Z",
            "summary": "Generalised Complex Geometry provides a natural interpretation of the\n$\\mathcal{N}=1$ supersymmetry conditions for warped solutions of type II\nsupergravity as differential equations on polyforms on the internal manifold.\nWritten in this language the supersymmetry conditions correspond to calibration\nconditions for probe D-branes: D-string, domain-wall or space-filling branes,\ndepending on the directions they span in the non-compact four-dimensional\nspace. The BPS condition corresponding to the calibration of space-filling\nD-branes has been reformulated by Tomasiello, eliminating the explicit\ndependence on the metric. We generalise this derivation to the case of\nnon-supersymmetric backgrounds violating the domain-wall and D-string\ncalibration conditions. We use this reformulation to derive constraints that\nthe ten-dimensional solutions with BPS space-filling sources must respect in\norder to dimensionally reduce to solutions of four-dimensional $\\mathcal{N}=1$\nsupergravity with non-vanishing F-terms and potentially non-vanishing D-terms.\nWe give the equations of motion for the class of type II vacua satisfying these\nconstraints in the language of pure spinors. We investigate how restrictive\nthese constraints are for the class of type IIB SU$(3)$ backgrounds with BPS\nspace-filling O5-planes.",
            "author": [
                "Vincent Menet"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04517v1",
                "http://arxiv.org/pdf/2312.04517v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04515v1",
            "title": "Efficient Monotonic Multihead Attention",
            "updated": "2023-12-07T18:34:57Z",
            "published": "2023-12-07T18:34:57Z",
            "summary": "We introduce the Efficient Monotonic Multihead Attention (EMMA), a\nstate-of-the-art simultaneous translation model with numerically-stable and\nunbiased monotonic alignment estimation. In addition, we present improved\ntraining and inference strategies, including simultaneous fine-tuning from an\noffline translation model and reduction of monotonic alignment variance. The\nexperimental results demonstrate that the proposed model attains\nstate-of-the-art performance in simultaneous speech-to-text translation on the\nSpanish and English translation task.",
            "author": [
                "Xutai Ma",
                "Anna Sun",
                "Siqi Ouyang",
                "Hirofumi Inaguma",
                "Paden Tomasello"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04515v1",
                "http://arxiv.org/pdf/2312.04515v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04514v1",
            "title": "Channel Charting for Streaming CSI Data",
            "updated": "2023-12-07T18:34:25Z",
            "published": "2023-12-07T18:34:25Z",
            "summary": "Channel charting (CC) applies dimensionality reduction to channel state\ninformation (CSI) data at the infrastructure basestation side with the goal of\nextracting pseudo-position information for each user. The self-supervised\nnature of CC enables predictive tasks that depend on user position without\nrequiring any ground-truth position information. In this work, we focus on the\npractically relevant streaming CSI data scenario, in which CSI is constantly\nestimated. To deal with storage limitations, we develop a novel streaming CC\narchitecture that maintains a small core CSI dataset from which the channel\ncharts are learned. Curation of the core CSI dataset is achieved using a\nmin-max-similarity criterion. Numerical validation with measured CSI data\ndemonstrates that our method approaches the accuracy obtained from the complete\nCSI dataset while using only a fraction of CSI storage and avoiding\ncatastrophic forgetting of old CSI data.",
            "author": [
                "Sueda Taner",
                "Maxime Guillaud",
                "Olav Tirkkonen",
                "Christoph Studer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04514v1",
                "http://arxiv.org/pdf/2312.04514v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04513v1",
            "title": "On-shell approach to (spinning) gravitational absorption processes",
            "updated": "2023-12-07T18:32:54Z",
            "published": "2023-12-07T18:32:54Z",
            "summary": "We utilize three point amplitudes with (spinning) particles of unequal mass\nand a graviton to capture the dynamics of absorption processes. We demonstrate\nthat the construction can represent the spheroidal harmonics appearing in the\nTeukolsky equations. The absolute square of the ``Wilson coefficients'' in this\neffective description can be fixed by matching to the known absorptive\ncross-sections. As an application, we compute corrections to the gravitational\nCompton amplitude from the exchange of states corresponding to such absorption\neffects. In the super-extremal limit, the corrections generate the non-analytic\n$|a|$-dependent contribution of the Compton amplitude found in\nref.\\cite{Bautista:2022wjf}.",
            "author": [
                "Yu-Jui Chen",
                "Tien Hsieh",
                "Yu-Tin Huang",
                "Jung-Wook Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04513v1",
                "http://arxiv.org/pdf/2312.04513v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04511v1",
            "title": "An LLM Compiler for Parallel Function Calling",
            "updated": "2023-12-07T18:32:04Z",
            "published": "2023-12-07T18:32:04Z",
            "summary": "Large Language Models (LLMs) have shown remarkable results on various complex\nreasoning benchmarks. The reasoning capabilities of LLMs enable them to execute\nfunction calls, using user-provided functions to overcome their inherent\nlimitations, such as knowledge cutoffs, poor arithmetic skills, or lack of\naccess to private data. This development has expanded LLMs' scope to include\nmulti-function calling, where LLMs are equipped with a variety of functions and\nselect the proper functions based on the context. Multi-function calling\nabilities of LLMs have catalyzed LLM-based software development, allowing them\nto tackle more complex problems. However, current methods for multi-function\ncalling often require sequential reasoning and acting for each function which\ncan result in high latency, cost, and sometimes inaccurate behavior. To address\nthis, we introduce LLMCompiler, which executes functions in parallel to\nefficiently orchestrate multi-function calling. Drawing from the principles of\nclassical compilers, LLMCompiler streamlines parallel function calling with\nthree components: (i) an LLM Planner, formulating execution strategies and\ndependencies; (ii) a Task Fetching Unit, dispatching function calling tasks;\nand (iii) an Executor, executing these tasks in parallel. LLMCompiler\nautomatically computes an optimized orchestration for the function calls and\ncan be used with open-source models such as LLaMA-2. We have benchmarked\nLLMCompiler on a range of tasks including cases with non-trivial\ninter-dependency between function calls, as well as cases that require dynamic\nreplanning based on intermediate results. We observe consistent latency speedup\nof up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to\n~9% as compared to ReAct. Additionally, LLMCompiler achieves up to 1.35x\nlatency gain over OpenAI's recent parallel function calling, while achieving\nsimilar accuracy.",
            "author": [
                "Sehoon Kim",
                "Suhong Moon",
                "Ryan Tabrizi",
                "Nicholas Lee",
                "Michael W. Mahoney",
                "Kurt Keutzer",
                "Amir Gholami"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04511v1",
                "http://arxiv.org/pdf/2312.04511v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04510v1",
            "title": "A Block Metropolis-Hastings Sampler for Controllable Energy-based Text\n  Generation",
            "updated": "2023-12-07T18:30:15Z",
            "published": "2023-12-07T18:30:15Z",
            "summary": "Recent work has shown that energy-based language modeling is an effective\nframework for controllable text generation because it enables flexible\nintegration of arbitrary discriminators. However, because energy-based LMs are\nglobally normalized, approximate techniques like Metropolis-Hastings (MH) are\nrequired for inference. Past work has largely explored simple proposal\ndistributions that modify a single token at a time, like in Gibbs sampling. In\nthis paper, we develop a novel MH sampler that, in contrast, proposes re-writes\nof the entire sequence in each step via iterative prompting of a large language\nmodel. Our new sampler (a) allows for more efficient and accurate sampling from\na target distribution and (b) allows generation length to be determined through\nthe sampling procedure rather than fixed in advance, as past work has required.\nWe perform experiments on two controlled generation tasks, showing both\ndownstream performance gains and more accurate target distribution sampling in\ncomparison with single-token proposal techniques.",
            "author": [
                "Jarad Forristal",
                "Niloofar Mireshghallah",
                "Greg Durrett",
                "Taylor Berg-Kirkpatrick"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04510v1",
                "http://arxiv.org/pdf/2312.04510v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04504v1",
            "title": "Coordination-free Decentralised Federated Learning on Complex Networks:\n  Overcoming Heterogeneity",
            "updated": "2023-12-07T18:24:19Z",
            "published": "2023-12-07T18:24:19Z",
            "summary": "Federated Learning (FL) is a well-known framework for successfully performing\na learning task in an edge computing scenario where the devices involved have\nlimited resources and incomplete data representation. The basic assumption of\nFL is that the devices communicate directly or indirectly with a parameter\nserver that centrally coordinates the whole process, overcoming several\nchallenges associated with it. However, in highly pervasive edge scenarios, the\npresence of a central controller that oversees the process cannot always be\nguaranteed, and the interactions (i.e., the connectivity graph) between devices\nmight not be predetermined, resulting in a complex network structure. Moreover,\nthe heterogeneity of data and devices further complicates the learning process.\nThis poses new challenges from a learning standpoint that we address by\nproposing a communication-efficient Decentralised Federated Learning (DFL)\nalgorithm able to cope with them. Our solution allows devices communicating\nonly with their direct neighbours to train an accurate model, overcoming the\nheterogeneity induced by data and different training histories. Our results\nshow that the resulting local models generalise better than those trained with\ncompeting approaches, and do so in a more communication-efficient way.",
            "author": [
                "Lorenzo Valerio",
                "Chiara Boldrini",
                "Andrea Passarella",
                "J\u00e1nos Kert\u00e9sz",
                "M\u00e1rton Karsai",
                "Gerardo I\u00f1iguez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04504v1",
                "http://arxiv.org/pdf/2312.04504v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "cs.MA",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04501v1",
            "title": "Graph Metanetworks for Processing Diverse Neural Architectures",
            "updated": "2023-12-07T18:21:52Z",
            "published": "2023-12-07T18:21:52Z",
            "summary": "Neural networks efficiently encode learned information within their\nparameters. Consequently, many tasks can be unified by treating neural networks\nthemselves as input data. When doing so, recent studies demonstrated the\nimportance of accounting for the symmetries and geometry of parameter spaces.\nHowever, those works developed architectures tailored to specific networks such\nas MLPs and CNNs without normalization layers, and generalizing such\narchitectures to other types of networks can be challenging. In this work, we\novercome these challenges by building new metanetworks - neural networks that\ntake weights from other neural networks as input. Put simply, we carefully\nbuild graphs representing the input neural networks and process the graphs\nusing graph neural networks. Our approach, Graph Metanetworks (GMNs),\ngeneralizes to neural architectures where competing methods struggle, such as\nmulti-head attention layers, normalization layers, convolutional layers, ResNet\nblocks, and group-equivariant linear layers. We prove that GMNs are expressive\nand equivariant to parameter permutation symmetries that leave the input neural\nnetwork functions unchanged. We validate the effectiveness of our method on\nseveral metanetwork tasks over diverse neural network architectures.",
            "author": [
                "Derek Lim",
                "Haggai Maron",
                "Marc T. Law",
                "Jonathan Lorraine",
                "James Lucas"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04501v1",
                "http://arxiv.org/pdf/2312.04501v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04500v1",
            "title": "Geometric phases in generalized radical Floquet dynamics",
            "updated": "2023-12-07T18:21:38Z",
            "published": "2023-12-07T18:21:38Z",
            "summary": "The Pancharatnam phase is a generalization of the Berry phase that applies to\ndiscrete sequences of quantum states. Here, we show that the Pancharatnam phase\nis a natural invariant for a wide class of quantum many-body dynamics involving\nmeasurements. We specifically investigate how a non-trivial Pancharatnam phase\narises in the trajectories of Floquet quantum error-correcting codes and show\nthat this phase can be extracted in a \"computationally-assisted\" interferometry\nprotocol, involving additional post-processing based on the measurement record\nthat defines a given quantum many-body trajectory. This Pancharatnam phase can\nalso be directly related to the Berry phase accrued by continuous unitary\nevolution within a gapped phase. For the $\\mathbb Z_2$ Floquet code of Hastings\nand Haah, we show that the associated family of unitary evolutions is the\nradical chiral Floquet phase. We demonstrate this correspondence explicitly by\nstudying an exactly-solvable model of interacting spins.",
            "author": [
                "Brenden Roberts",
                "Sagar Vijay",
                "Arpit Dua"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04500v1",
                "http://arxiv.org/pdf/2312.04500v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04498v1",
            "title": "Heating and cooling processes via phaseonium-driven dynamics of cascade\n  systems",
            "updated": "2023-12-07T18:21:22Z",
            "published": "2023-12-07T18:21:22Z",
            "summary": "The search for strategies to harness the temperature of quantum systems is\none of the main goals in quantum thermodynamics. Here we study the dynamics of\na system made of a pair of quantum harmonic oscillators, represented by\nsingle-mode cavity fields, interacting with a thermally excited beam of\nphaseonium atoms, which act as ancillas. The two cavities are arranged in a\ncascade configuration, so that the second cavity interacts with phaseonium\natoms only after their interaction with the first one. We provide exact closed\ndynamics of the first cavity for arbitrarily long interaction times. We\nhighlight the role played by the characteristic coherence phase of phaseonium\natoms in determining the steady states of the cavity fields as well as that of\nthe ancillas. Also, we show how the second cavity follows a non-Markovian\nevolution due to interactions with the \"used\" ancillary atoms, that enables\ninformation exchange with the first cavity. Adjusting the parameters of the\nphaseonium atoms, we can determine the final stable temperature reached by the\ncavities. In this way, the cavities can be heated up as well as cooled down.\nThese results provide useful insights towards the use of different types of\nancillas for thermodynamic cycles in cavity QED scenarios.",
            "author": [
                "Federico Amato",
                "Claudio Pellitteri",
                "G. Massimo Palma",
                "Salvatore Lorenzo",
                "Rosario Lo Franco"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04498v1",
                "http://arxiv.org/pdf/2312.04498v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04494v1",
            "title": "AVA: Towards Autonomous Visualization Agents through Visual\n  Perception-Driven Decision-Making",
            "updated": "2023-12-07T18:13:42Z",
            "published": "2023-12-07T18:13:42Z",
            "summary": "With recent advances in multi-modal foundation models, the previously\ntext-only large language models (LLM) have evolved to incorporate visual input,\nopening up unprecedented opportunities for various applications in\nvisualization. Our work explores the utilization of the visual perception\nability of multi-modal LLMs to develop Autonomous Visualization Agents (AVAs)\nthat can interpret and accomplish user-defined visualization objectives through\nnatural language. We propose the first framework for the design of AVAs and\npresent several usage scenarios intended to demonstrate the general\napplicability of the proposed paradigm. The addition of visual perception\nallows AVAs to act as the virtual visualization assistant for domain experts\nwho may lack the knowledge or expertise in fine-tuning visualization outputs.\nOur preliminary exploration and proof-of-concept agents suggest that this\napproach can be widely applicable whenever the choices of appropriate\nvisualization parameters require the interpretation of previous visual output.\nFeedback from unstructured interviews with experts in AI research, medical\nvisualization, and radiology has been incorporated, highlighting the\npracticality and potential of AVAs. Our study indicates that AVAs represent a\ngeneral paradigm for designing intelligent visualization systems that can\nachieve high-level visualization goals, which pave the way for developing\nexpert-level visualization agents in the future.",
            "author": [
                "Shusen Liu",
                "Haichao Miao",
                "Zhimin Li",
                "Matthew Olson",
                "Valerio Pascucci",
                "Peer-Timo Bremer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04494v1",
                "http://arxiv.org/pdf/2312.04494v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04493v1",
            "title": "Incoherent diffractive dijet production and gluon Bose enhancement in\n  the nuclear wave function",
            "updated": "2023-12-07T18:12:13Z",
            "published": "2023-12-07T18:12:13Z",
            "summary": "We investigate the effect of gluon Bose enhancement in the nuclear wave\nfunction on the dijet production in incoherent diffractive processes in DIS and\nultraperipheral collisions. We demonstrate that Bose enhancement leads to an\nenhancement of diffractive dijet production cross section when the transverse\nmomenta of the two jets are aligned at zero relative angle. This enhancement is\nmaximal when the magnitude of the transverse momenta of the two jets are equal,\nand disappears rather quickly as a function of the ratio of the two momenta. We\nstudy both the dilute limit and fully nonlinear dense regime where the nuclear\nwave function is evolved with the leading order JIMWLK equation. In both cases\nwe observe a visible effect, with it being enhanced by the evolution due to the\ndynamical generation of the color neutralization scale.",
            "author": [
                "Tiyasa Kar",
                "Alexander Kovner",
                "Ming Li",
                "Vladimir V. Skokov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04493v1",
                "http://arxiv.org/pdf/2312.04493v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04488v1",
            "title": "Transient effects in quantum dots contacted via topological\n  superconductor",
            "updated": "2023-12-07T18:05:16Z",
            "published": "2023-12-07T18:05:16Z",
            "summary": "We investigate gradual development of the quasiparticle states in two quantum\ndots attached to opposite sides of the topological superconducting nanowire,\nhosting the boundary modes. Specifically, we explore the non-equilibrium\ncross-correlations transmitted between these quantum dots via the zero-energy\nMajorana modes. From the analytical and numerical results we reveal nonlocal\nfeatures in the transient behavior of electron pairing, which subsequently\ncease while the hybrid structure evolves towards its asymptotic steady limit\nconfiguration. We estimate duration of these temporary nonlocal phenomena and\ninspect their possible manifestation in the quench-driven processes. Such\ndynamical effects might play an important role in braiding protocols of the\ntopological and/or conventional superconducting quantum bits using nanoscopic\nhybrid structures.",
            "author": [
                "R. Taranko",
                "K. Wrze\u015bniewski",
                "I. Weymann",
                "T. Doma\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04488v1",
                "http://arxiv.org/pdf/2312.04488v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04485v1",
            "title": "Relativistic quantum Otto engine: Instant work extraction from a quantum\n  field",
            "updated": "2023-12-07T18:00:01Z",
            "published": "2023-12-07T18:00:01Z",
            "summary": "In this study, we carry out a non-perturbative approach to a quantum Otto\nengine, employing an Unruh-DeWitt particle detector to extract work from a\nquantum Klein-Gordon field in an arbitrary globally hyperbolic curved\nspacetime. We broaden the scope by considering the field in any quasi-free\nstate, which includes vacuum, thermal, and squeezed states. A key aspect of our\nmethod is the instantaneous interaction between the detector and the field,\nwhich enables a thorough non-perturbative analysis. We demonstrate that the\ndetector can successfully extract positive work from the quantum Otto cycle,\neven when two isochoric processes occur instantaneously, provided the detector\nin the second isochoric process receives a signal from the first interaction.\nThis signaling allows the detector to release heat into the field, thereby the\nthermodynamic cycle is completed. As a demonstration, we consider a detector at\nrest in flat spacetime and compute the work extracted from the Minkowski vacuum\nstate.",
            "author": [
                "Kensuke Gallock-Yoshimura"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04485v1",
                "http://arxiv.org/pdf/2312.04485v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04484v1",
            "title": "FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation",
            "updated": "2023-12-07T17:59:53Z",
            "published": "2023-12-07T17:59:53Z",
            "summary": "LiDAR segmentation is crucial for autonomous driving systems. The recent\nrange-view approaches are promising for real-time processing. However, they\nsuffer inevitably from corrupted contextual information and rely heavily on\npost-processing techniques for prediction refinement. In this work, we propose\na simple yet powerful FRNet that restores the contextual information of the\nrange image pixels with corresponding frustum LiDAR points. Firstly, a frustum\nfeature encoder module is used to extract per-point features within the frustum\nregion, which preserves scene consistency and is crucial for point-level\npredictions. Next, a frustum-point fusion module is introduced to update\nper-point features hierarchically, which enables each point to extract more\nsurrounding information via the frustum features. Finally, a head fusion module\nis used to fuse features at different levels for final semantic prediction.\nExtensive experiments on four popular LiDAR segmentation benchmarks under\nvarious task setups demonstrate our superiority. FRNet achieves competitive\nperformance while maintaining high efficiency. The code is publicly available.",
            "author": [
                "Xiang Xu",
                "Lingdong Kong",
                "Hui Shuai",
                "Qingshan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04484v1",
                "http://arxiv.org/pdf/2312.04484v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04474v1",
            "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
            "updated": "2023-12-07T17:51:43Z",
            "published": "2023-12-07T17:51:43Z",
            "summary": "Code provides a general syntactic structure to build complex programs and\nperform precise computations when paired with a code interpreter -- we\nhypothesize that language models (LMs) can leverage code-writing to improve\nChain of Thought reasoning not only for logic and arithmetic tasks, but also\nfor linguistic ones (and in particular, those that are a mix of both). For\nexample, consider prompting an LM to write code that counts the number of times\nit detects sarcasm in an essay: the LM may struggle to write an implementation\nfor \"detect_sarcasm(string)\" that can be executed by the interpreter (handling\nthe edge cases would be insurmountable). However, LMs may still produce a valid\nsolution if they are used not only to write the code, but also to selectively\n\"emulate\" the interpreter by generating the expected output of\n\"detect_sarcasm(string)\" and other lines of code (e.g., that the interpreter\ncould not compile). In this work, we propose Chain of Code (CoT), a simple yet\nsurprisingly effective extension that improves LM code-driven reasoning. The\nkey idea is to encourage LMs to format linguistic sub-tasks in a program as\nflexible pseudocode that the compiler can explicitly catch undefined behaviors\nand hand off to simulate with an LM (as an \"LMulator\"). Experiments demonstrate\nthat Chain of Code outperforms Chain of Thought and other baselines across a\nvariety of benchmarks; on BIG-Bench Hard, Chain of Code achieves 84%, a gain of\n12% over Chain of Thought. CoT scales well with large and small models alike,\nand broadens the scope of reasoning questions that LMs can correctly answer by\n\"thinking in code\". Project webpage: https://chain-of-code.github.io/.",
            "author": [
                "Chengshu Li",
                "Jacky Liang",
                "Andy Zeng",
                "Xinyun Chen",
                "Karol Hausman",
                "Dorsa Sadigh",
                "Sergey Levine",
                "Li Fei-Fei",
                "Fei Xia",
                "Brian Ichter"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04474v1",
                "http://arxiv.org/pdf/2312.04474v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04472v1",
            "title": "Parking on trees with a (random) given degree sequence and the Frozen\n  configuration model",
            "updated": "2023-12-07T17:46:56Z",
            "published": "2023-12-07T17:46:56Z",
            "summary": "Consider a rooted tree on the top of which we let cars arrive on its\nvertices. Each car tries to park on its arriving vertex but if it is already\noccupied, it drives towards the root of the tree and parks as soon as possible.\nIn this article, we establish a natural coupling between the parking process on\ntrees with prescribed degrees and an oriented configuration model. As a\nconsequence, we recover the location of the phase transition for parking on\ncritical Bienaym\\'e--Galton--Watson trees already proven by Curien and\nH\\'enard, and Contat.",
            "author": [
                "Alice Contat"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04472v1",
                "http://arxiv.org/pdf/2312.04472v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04469v1",
            "title": "On the Learnability of Watermarks for Language Models",
            "updated": "2023-12-07T17:41:44Z",
            "published": "2023-12-07T17:41:44Z",
            "summary": "Watermarking of language model outputs enables statistical detection of\nmodel-generated text, which has many applications in the responsible deployment\nof language models. Existing watermarking strategies operate by altering the\ndecoder of an existing language model, and the ability for a language model to\ndirectly learn to generate the watermark would have significant implications\nfor the real-world deployment of watermarks. First, learned watermarks could be\nused to build open models that naturally generate watermarked text, allowing\nfor open models to benefit from watermarking. Second, if watermarking is used\nto determine the provenance of generated text, an adversary can hurt the\nreputation of a victim model by spoofing its watermark and generating damaging\nwatermarked text. To investigate the learnability of watermarks, we propose\nwatermark distillation, which trains a student model to behave like a teacher\nmodel that uses decoding-based watermarking. We test our approach on three\ndistinct decoding-based watermarking strategies and various hyperparameter\nsettings, finding that models can learn to generate watermarked text with high\ndetectability. We also find limitations to learnability, including the loss of\nwatermarking capabilities under fine-tuning on normal text and high sample\ncomplexity when learning low-distortion watermarks.",
            "author": [
                "Chenchen Gu",
                "Xiang Lisa Li",
                "Percy Liang",
                "Tatsunori Hashimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04469v1",
                "http://arxiv.org/pdf/2312.04469v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04465v1",
            "title": "FitDiff: Robust monocular 3D facial shape and reflectance estimation\n  using Diffusion Models",
            "updated": "2023-12-07T17:35:49Z",
            "published": "2023-12-07T17:35:49Z",
            "summary": "The remarkable progress in 3D face reconstruction has resulted in high-detail\nand photorealistic facial representations. Recently, Diffusion Models have\nrevolutionized the capabilities of generative methods by achieving far better\nperformance than GANs. In this work, we present FitDiff, a diffusion-based 3D\nfacial avatar generative model. This model accurately generates relightable\nfacial avatars, utilizing an identity embedding extracted from an \"in-the-wild\"\n2D facial image. Our multi-modal diffusion model concurrently outputs facial\nreflectance maps (diffuse and specular albedo and normals) and shapes,\nshowcasing great generalization capabilities. It is solely trained on an\nannotated subset of a public facial dataset, paired with 3D reconstructions. We\nrevisit the typical 3D facial fitting approach by guiding a reverse diffusion\nprocess using perceptual and face recognition losses. Being the first LDM\nconditioned on face recognition embeddings, FitDiff reconstructs relightable\nhuman avatars, that can be used as-is in common rendering engines, starting\nonly from an unconstrained facial image, and achieving state-of-the-art\nperformance.",
            "author": [
                "Stathis Galanakis",
                "Alexandros Lattas",
                "Stylianos Moschoglou",
                "Stefanos Zafeiriou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04465v1",
                "http://arxiv.org/pdf/2312.04465v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04463v1",
            "title": "Leveraging Transformer-based Language Models to Automate Requirements\n  Satisfaction Assessment",
            "updated": "2023-12-07T17:33:31Z",
            "published": "2023-12-07T17:33:31Z",
            "summary": "Requirements Satisfaction Assessment (RSA) evaluates whether the set of\ndesign elements linked to a single requirement provide sufficient coverage of\nthat requirement -- typically meaning that all concepts in the requirement are\naddressed by at least one of the design elements. RSA is an important software\nengineering activity for systems with any form of hierarchical decomposition --\nespecially safety or mission critical ones. In previous studies, researchers\nused basic Information Retrieval (IR) models to decompose requirements and\ndesign elements into chunks, and then evaluated the extent to which chunks of\ndesign elements covered all chunks in the requirement. However, results had low\naccuracy because many critical concepts that extend across the entirety of the\nsentence were not well represented when the sentence was parsed into\nindependent chunks. In this paper we leverage recent advances in natural\nlanguage processing to deliver significantly more accurate results. We propose\ntwo major architectures: Satisfaction BERT (Sat-BERT), and Dual-Satisfaction\nBERT (DSat-BERT), along with their multitask learning variants to improve\nsatisfaction assessments. We perform RSA on five different datasets and compare\nresults from our variants against the chunk-based legacy approach. All\nBERT-based models significantly outperformed the legacy baseline, and Sat-BERT\ndelivered the best results returning an average improvement of 124.75% in Mean\nAverage Precision.",
            "author": [
                "Amrit Poudel",
                "Jinfeng Lin",
                "Jane Cleland-Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04463v1",
                "http://arxiv.org/pdf/2312.04463v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04460v1",
            "title": "Probabilistic volumetric speckle suppression in OCT using deep learning",
            "updated": "2023-12-07T17:32:24Z",
            "published": "2023-12-07T17:32:24Z",
            "summary": "We present a deep learning framework for volumetric speckle reduction in\noptical coherence tomography (OCT) based on a conditional generative\nadversarial network (cGAN) that leverages the volumetric nature of OCT data. In\norder to utilize the volumetric nature of OCT data, our network takes partial\nOCT volumes as input, resulting in artifact-free despeckled volumes that\nexhibit excellent speckle reduction and resolution preservation in all three\ndimensions. Furthermore, we address the ongoing challenge of generating ground\ntruth data for supervised speckle suppression deep learning frameworks by using\nvolumetric non-local means despeckling-TNode to generate training data. We show\nthat, while TNode processing is computationally demanding, it serves as a\nconvenient, accessible gold-standard source for training data; our cGAN\nreplicates efficient suppression of speckle while preserving tissue structures\nwith dimensions approaching the system resolution of non-local means\ndespeckling while being two orders of magnitude faster than TNode. We\ndemonstrate fast, effective, and high-quality despeckling of the proposed\nnetwork in different tissue types acquired with three different OCT systems\ncompared to existing deep learning methods. The open-source nature of our work\nfacilitates re-training and deployment in any OCT system with an all-software\nimplementation, working around the challenge of generating high-quality,\nspeckle-free training data.",
            "author": [
                "Bhaskara Rao Chintada",
                "Sebasti\u00e1n Ruiz-Lopera",
                "Ren\u00e9 Restrepo",
                "Brett E. Bouma",
                "Martin Villiger",
                "N\u00e9stor Uribe-Patarroyo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04460v1",
                "http://arxiv.org/pdf/2312.04460v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.med-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04457v1",
            "title": "Guided simulation of conditioned chemical reaction networks",
            "updated": "2023-12-07T17:26:10Z",
            "published": "2023-12-07T17:26:10Z",
            "summary": "Let $X$ be a chemical reaction process, modeled as a multi-dimensional\ncontinuous-time jump process. Assume that at given times $0<t_1 < \\cdots <\nt_n$, linear combinations $v_i = L_i X(t_i),\\, i = 1,\\dots, n$ are observed for\ngiven matrices $L_i$. We show how to sample the process conditioned on hitting\nthe states $v_1,\\dots, v_n$ by a change of measure on the law of the\nunconditioned process. We derive sufficient conditions for this change of\nmeasure and complement our results using numerical illustrations.",
            "author": [
                "Marc Corstanje",
                "Frank van der Meulen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04457v1",
                "http://arxiv.org/pdf/2312.04457v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "stat.CO",
                "60J27, 60J28, 60J74"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04455v1",
            "title": "Fortify the Shortest Stave in Attention: Enhancing Context Awareness of\n  Large Language Models for Effective Tool Use",
            "updated": "2023-12-07T17:24:51Z",
            "published": "2023-12-07T17:24:51Z",
            "summary": "Recent advancements in large language models (LLMs) have significantly\nexpanded their functionality and skills as tool agents. In this paper, we argue\nthat a waveform pattern in the model's attention allocation has an impact on\nthe tool use performance, which degrades when the position of essential\ninformation hits the trough zone. To address this issue, we propose a novel\ninference method named Attention Buckets. This approach enables LLMs to handle\ncontext by conducting parallel processes, each featuring a unique RoPE angle\nbase that shapes the attention waveform. Attention Buckets ensures that an\nattention trough of a particular process can be compensated with an attention\npeak of another run, reducing the risk of the LLM missing essential information\nresiding within the attention trough. Our extensive experiments on the widely\nrecognized tool use benchmark demonstrate the efficacy of our approach, where a\n7B-parameter open-source model enhanced by Attention Buckets achieves SOTA\nperformance on par with GPT-4.",
            "author": [
                "Yuhan Chen",
                "Ang Lv",
                "Ting-En Lin",
                "Changyu Chen",
                "Yuchuan Wu",
                "Fei Huang",
                "Yongbin Li",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04455v1",
                "http://arxiv.org/pdf/2312.04455v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04448v1",
            "title": "Relativistic materials from an alternative viewpoint",
            "updated": "2023-12-07T17:16:58Z",
            "published": "2023-12-07T17:16:58Z",
            "summary": "Electrons in materials containing heavy elements are fundamentally\nrelativistic and should in principle be described using the Dirac equation.\nHowever, the current standard for treatment of electrons in such materials\ninvolves density functional theory methods originally formulated from the\nSchr\\\"{o}dinger equation. While some extensions of the Schr\\\"{o}dinger-based\nformulation have been explored, such as the scalar relativistic approximation\nwith or without spin-orbit coupling, these solutions do not provide a way to\nfully account for all relativistic effects of electrons, and the language used\nto describe such solutions are still based in the language of the\nSchr\\\"{o}dinger equation. In this article, we provide a different method for\ntranslating between the Dirac and Schr\\\"{o}dinger viewpoints in the context of\na Coulomb potential. By retaining the Dirac four-vector notation and\nterminology in taking the non-relativistic limit, we see a much deeper\nconnection between the Dirac and Schr\\\"{o}dinger equation solutions that allow\nus to more directly compare the effects of relativity in the angular and radial\nfunctions. Through this viewpoint, we introduce the concepts of densitals and\nDirac spherical harmonics that allow us to translate more easily between the\nDirac and Schr\\\"{o}dinger solutions. These concepts allow us to establish a\nuseful language for discussing relativistic effects in materials containing\nelements throughout the full periodic table and thereby enable a more\nfundamental understanding of the effects of relativity on electronic structure.",
            "author": [
                "Ann E. Mattsson",
                "Daniel A. Rehn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04448v1",
                "http://arxiv.org/pdf/2312.04448v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04445v1",
            "title": "Colossal orbital Zeeman effect driven by tunable spin-Berry curvature in\n  a kagome metal",
            "updated": "2023-12-07T17:10:13Z",
            "published": "2023-12-07T17:10:13Z",
            "summary": "Berry phase and the related concept of Berry curvature can give rise to many\nunconventional phenomena in solids. In this work, we discover colossal orbital\nZeeman effect of topological origin in a newly synthesized bilayer kagome metal\nTbV6Sn6. We use spectroscopic-imaging scanning tunneling microscopy to study\nthe magnetic field induced renormalization of the electronic band structure.\nThe nonmagnetic vanadium d-orbitals form Dirac crossings at the K point with a\nsmall mass gap and strong Berry curvature induced by the spin-orbit coupling.\nWe reveal that the magnetic field leads to the splitting of gapped Dirac\ndispersion into two branches with giant momentum-dependent g factors, resulting\nin the substantial renormalization of the Dirac band. These measurements\nprovide a direct observation of the magnetic field controlled orbital Zeeman\ncoupling to the enormous orbital magnetic moments of up to 200 Bohr magnetons\nnear the gapped Dirac points. Interestingly, the effect is increasingly\nnon-linear, and becomes gradually suppressed at higher magnetic fields.\nTheoretical modeling further confirms the existence of orbital magnetic moments\nin TbV6Sn6 produced by the non-trivial spin-Berry curvature of the Bloch wave\nfunctions. Our work provides the first direct insight into the\nmomentum-dependent nature of topological orbital moments and their tunability\nby magnetic field concomitant with the evolution of the spin-Berry curvature.\nSignificantly large orbital magnetic moments driven by the Berry curvature can\nalso be generated by other quantum numbers beyond spin, such as the valley in\ncertain graphene-based structures, which may be unveiled using the same tools\nhighlighted in our work.",
            "author": [
                "Hong Li",
                "Siyu Cheng",
                "Ganesh Pokharel",
                "Philipp Eck",
                "Chiara Bigi",
                "Federico Mazzola",
                "Giorgio Sangiovanni",
                "Stephen D. Wilson",
                "Domenico Di Sante",
                "Ziqiang Wang",
                "Ilija Zeljkovic"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04445v1",
                "http://arxiv.org/pdf/2312.04445v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.other",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04444v1",
            "title": "Parameter Inference for Hypo-Elliptic Diffusions under a Weak Design\n  Condition",
            "updated": "2023-12-07T17:08:35Z",
            "published": "2023-12-07T17:08:35Z",
            "summary": "We address the problem of parameter estimation for degenerate diffusion\nprocesses defined via the solution of Stochastic Differential Equations (SDEs)\nwith diffusion matrix that is not full-rank. For this class of hypo-elliptic\ndiffusions recent works have proposed contrast estimators that are\nasymptotically normal, provided that the step-size in-between observations\n$\\Delta=\\Delta_n$ and their total number $n$ satisfy $n \\to \\infty$, $n\n\\Delta_n \\to \\infty$, $\\Delta_n \\to 0$, and additionally $\\Delta_n = o\n(n^{-1/2})$. This latter restriction places a requirement for a so-called\n`rapidly increasing experimental design'. In this paper, we overcome this\nlimitation and develop a general contrast estimator satisfying asymptotic\nnormality under the weaker design condition $\\Delta_n = o(n^{-1/p})$ for\ngeneral $p \\ge 2$. Such a result has been obtained for elliptic SDEs in the\nliterature, but its derivation in a hypo-elliptic setting is highly\nnon-trivial. We provide numerical results to illustrate the advantages of the\ndeveloped theory.",
            "author": [
                "Yuga Iguchi",
                "Alexandros Beskos"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04444v1",
                "http://arxiv.org/pdf/2312.04444v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04443v1",
            "title": "Nonlinear aspects of stochastic particle acceleration",
            "updated": "2023-12-07T17:08:23Z",
            "published": "2023-12-07T17:08:23Z",
            "summary": "In turbulent magnetized plasmas, charged particles can be accelerated to high\nenergies through their interactions with the turbulent motions. As they do so,\nthey draw energy from the turbulence, possibly up to the point where they start\nmodifying the turbulent cascade. Stochastic acceleration then enters a\nnonlinear regime because turbulence damping back-reacts in turn on the\nacceleration process. This article develops a phenomenological model to explore\nthis phenomenon and its consequences on the particle and turbulent energy\nspectra. We determine a criterion that specifies the threshold of nonthermal\nparticle energy density and the characteristic momentum beyond which\nback-reaction becomes effective. Once the back-reaction sets in, the turbulence\ncascade becomes damped below a length scale that keeps increasing in time. The\naccelerated particle momentum distribution develops a near power-law of the\nform ${\\rm d}n/{\\rm d}p\\propto p^{-s}$ with $s\\sim2$ beyond the momentum at\nwhich back-reaction first sets in. At very high energies, where the gyroradius\nof accelerated particles becomes comparable to the outer scale of the\nturbulence, the energy spectrum can display an even harder spectrum with $s\\sim\n1.3-1.5$ over a short segment. The low-energy part of the spectrum, below the\ncritical momentum, is expected to be hard ($s\\sim 1$ or harder), and shaped by\nany residual acceleration process in the damped region of the turbulence\ncascade. This characteristic broken power-law shape with $s\\sim 2$ at high\nenergies may find phenomenological applications in various high-energy\nastrophysical contexts.",
            "author": [
                "M. Lemoine",
                "K. Murase",
                "F. Rieger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04443v1",
                "http://arxiv.org/pdf/2312.04443v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04441v1",
            "title": "Efficient Synthesis of Passively Loaded Finite Arrays for Tunable\n  Anomalous Reflection",
            "updated": "2023-12-07T17:07:32Z",
            "published": "2023-12-07T17:07:32Z",
            "summary": "A design methodology for planar loaded antenna arrays is proposed to\nsynthesize a perfect anomalous reflection into an arbitrary direction by\noptimizing the scattering characteristics of passively loaded array antennas.\nIt is based on efficient and accurate prediction of the induced current\ndistribution and the associated scattering for any given set of load\nimpedances. For a fixed array of finite dimensions, the deflection angles can\nbe continuously adjusted with proper tuning of each load. We study and develop\nanomalous reflectors as semi-finite (finite $\\times$ infinite) and finite\nplanar rectangular arrays comprising printed patches with a subwavelength\nspacing. Anomalous reflection into an arbitrary desired angle using purely\nreactive loads is numerically and experimentally validated. Owing to the\nalgebraic nature of load optimization, the design methodology may be applied to\nthe synthesis of large-scale reflectors of practical significance.",
            "author": [
                "Sravan K. R. Vuyyuru",
                "Risto Valkonen",
                "Sergei A. Tretyakov",
                "Do-Hoon Kwon"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04441v1",
                "http://arxiv.org/pdf/2312.04441v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04440v1",
            "title": "OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization",
            "updated": "2023-12-07T17:06:20Z",
            "published": "2023-12-07T17:06:20Z",
            "summary": "The performance of automatic summarization models has improved dramatically\nin recent years. Yet, there is still a gap in meeting specific information\nneeds of users in real-world scenarios, particularly when a targeted summary is\nsought, such as in the useful aspect-based summarization setting targeted in\nthis paper. Previous datasets and studies for this setting have predominantly\nconcentrated on a limited set of pre-defined aspects, focused solely on single\ndocument inputs, or relied on synthetic data. To advance research on more\nrealistic scenarios, we introduce OpenAsp, a benchmark for multi-document\n\\textit{open} aspect-based summarization. This benchmark is created using a\nnovel and cost-effective annotation protocol, by which an open aspect dataset\nis derived from existing generic multi-document summarization datasets. We\nanalyze the properties of OpenAsp showcasing its high-quality content. Further,\nwe show that the realistic open-aspect setting realized in OpenAsp poses a\nchallenge for current state-of-the-art summarization models, as well as for\nlarge language models.",
            "author": [
                "Shmuel Amar",
                "Liat Schiff",
                "Ori Ernst",
                "Asi Shefer",
                "Ori Shapira",
                "Ido Dagan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04440v1",
                "http://arxiv.org/pdf/2312.04440v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04438v1",
            "title": "Targeted Immunisation Thresholds for the Contact Process on Power-Law\n  Trees",
            "updated": "2023-12-07T17:05:06Z",
            "published": "2023-12-07T17:05:06Z",
            "summary": "The popular scale-free configuration model of a social network has a local\nlimit primarily a Galton-Watson tree with some power law offspring distribution\n$X$, having tail exponent parameter $\\tau>2$ such that $\\mathbb{P}(X>x) \\sim A\nx^{2-\\tau}$. It is known that contact process epidemics can propagate on these\ntrees and therefore these networks for arbitrarily small infection rates, and\nuniformly at random immunising a small positive proportion of vertices will\nhave no effect on this result. So, to reduce the possibility of survival of the\ncontact process on these trees we instead remove (immunise) those with largest\ndegree.\n  For small $\\lambda$ we find sharp thresholds in the maximum permissible\ndegree for the survival probability through three distinct $\\tau$ regimes,\nwhich by duality would correspond to a transition in the metastable density of\nthe associated network after this targeted removal. Above a threshold, we\nrecover the survival probabilities of Mountford, Valesin and Yao (2013) and\nthus the epidemic with immunisation is similar to without, but below a\nthreshold on the same order the survival probability is severely reduced or\nzero.",
            "author": [
                "John Fernley",
                "Emmanuel Jacob"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04438v1",
                "http://arxiv.org/pdf/2312.04438v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60K35 (primary), 60K37, 05C82 (secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04435v1",
            "title": "Deep3DSketch: 3D modeling from Free-hand Sketches with View- and\n  Structural-Aware Adversarial Training",
            "updated": "2023-12-07T16:57:38Z",
            "published": "2023-12-07T16:57:38Z",
            "summary": "This work aims to investigate the problem of 3D modeling using single\nfree-hand sketches, which is one of the most natural ways we humans express\nideas. Although sketch-based 3D modeling can drastically make the 3D modeling\nprocess more accessible, the sparsity and ambiguity of sketches bring\nsignificant challenges for creating high-fidelity 3D models that reflect the\ncreators' ideas. In this work, we propose a view- and structural-aware deep\nlearning approach, \\textit{Deep3DSketch}, which tackles the ambiguity and fully\nuses sparse information of sketches, emphasizing the structural information.\nSpecifically, we introduced random pose sampling on both 3D shapes and 2D\nsilhouettes, and an adversarial training scheme with an effective progressive\ndiscriminator to facilitate learning of the shape structures. Extensive\nexperiments demonstrated the effectiveness of our approach, which outperforms\nexisting methods -- with state-of-the-art (SOTA) performance on both synthetic\nand real datasets.",
            "author": [
                "Tianrun Chen",
                "Chenglong Fu",
                "Lanyun Zhu",
                "Papa Mao",
                "Jia Zhang",
                "Ying Zang",
                "Lingyun Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04435v1",
                "http://arxiv.org/pdf/2312.04435v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04432v1",
            "title": "FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning\n  Attacks in Federated Learning",
            "updated": "2023-12-07T16:56:24Z",
            "published": "2023-12-07T16:56:24Z",
            "summary": "Federated learning (FL) is a collaborative learning paradigm allowing\nmultiple clients to jointly train a model without sharing their training data.\nHowever, FL is susceptible to poisoning attacks, in which the adversary injects\nmanipulated model updates into the federated model aggregation process to\ncorrupt or destroy predictions (untargeted poisoning) or implant hidden\nfunctionalities (targeted poisoning or backdoors). Existing defenses against\npoisoning attacks in FL have several limitations, such as relying on specific\nassumptions about attack types and strategies or data distributions or not\nsufficiently robust against advanced injection techniques and strategies and\nsimultaneously maintaining the utility of the aggregated model. To address the\ndeficiencies of existing defenses, we take a generic and completely different\napproach to detect poisoning (targeted and untargeted) attacks. We present\nFreqFed, a novel aggregation mechanism that transforms the model updates (i.e.,\nweights) into the frequency domain, where we can identify the core frequency\ncomponents that inherit sufficient information about weights. This allows us to\neffectively filter out malicious updates during local training on the clients,\nregardless of attack types, strategies, and clients' data distributions. We\nextensively evaluate the efficiency and effectiveness of FreqFed in different\napplication domains, including image classification, word prediction, IoT\nintrusion detection, and speech recognition. We demonstrate that FreqFed can\nmitigate poisoning attacks effectively with a negligible impact on the utility\nof the aggregated model.",
            "author": [
                "Hossein Fereidooni",
                "Alessandro Pegoraro",
                "Phillip Rieger",
                "Alexandra Dmitrienko",
                "Ahmad-Reza Sadeghi"
            ],
            "link": [
                "http://dx.doi.org/10.14722/ndss.2024.23620",
                "http://arxiv.org/abs/2312.04432v1",
                "http://arxiv.org/pdf/2312.04432v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04428v1",
            "title": "A general framework for the generation of probabilistic socioeconomic\n  scenarios: Quantification of national food security risk with application to\n  the cases of Egypt and Ethiopia",
            "updated": "2023-12-07T16:54:46Z",
            "published": "2023-12-07T16:54:46Z",
            "summary": "In this work a general framework for providing detailed probabilistic\nsocioeconomic scenarios as well as estimates concerning country-level food\nsecurity risk is proposed. Our methodology builds on (a) the Bayesian\nprobabilistic version of the world population model and (b) on the\ninterdependencies of the minimum food requirements and the national food system\ncapacities on key drivers, such as: population, income, natural resources, and\nother socioeconomic and climate indicators. Model uncertainty plays an\nimportant role in such endeavours. In this perspective, the concept of the\nrecently developed convex risk measures which mitigate the model uncertainty\neffects, is employed for the development of a framework for assessment, in the\ncontext of food security. The proposed method provides predictions and\nevaluations for food security risk both within and across probabilistic\nscenarios at country level. Our methodology is illustrated through its\nimplementation for the cases of Egypt and Ethiopia, for the time period\n2019-2050, under the combined context of the Shared Socioeconomic Pathways\n(SSPs) and the Representative Concentration Pathways (RCPs).",
            "author": [
                "Phoebe Koundouri",
                "Georgios I. Papayiannis",
                "Achilleas Vassilopoulos",
                "Athanasios N. Yannacopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04428v1",
                "http://arxiv.org/pdf/2312.04428v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "stat.AP",
                "62P12, 62P20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04425v1",
            "title": "Confinement-Induced Isosymmetric Metal-Insulator Transition in Ultrathin\n  Epitaxial V2O3 Films",
            "updated": "2023-12-07T16:51:15Z",
            "published": "2023-12-07T16:51:15Z",
            "summary": "Dimensional confinement has shown to be an effective strategy to tune\ncompeting degrees of freedom in complex oxides. Here, we achieved atomic\nlayered growth of trigonal vanadium sesquioxide (V2O3) by means of\noxygen-assisted molecular beam epitaxy. This led to a series of high-quality\nepitaxial ultrathin V2O3 films down to unit cell thickness, enabling the study\nof the intrinsic electron correlations upon confinement. By electrical and\noptical measurements, we demonstrate a dimensional confinement-induced\nmetal-insulator transition in these ultrathin films. We shed light on the\nMott-Hubbard nature of this transition, revealing an abrupt vanishing of the\nquasiparticle weight as demonstrated by photoemission spectroscopy.\nFurthermore, we prove that dimensional confinement acts as an effective\nout-of-plane stress. This highlights the structural component of correlated\noxides in a confined architecture, while opening an avenue to control both\nin-plane and out-of-plane lattice components by epitaxial strain and\nconfinement, respectively.",
            "author": [
                "Simon Mellaerts",
                "Claudio Bellani",
                "Wei-Fan Hsu",
                "Alberto Binetti",
                "Koen Schouteden",
                "Maria Recaman-Payo",
                "Mariela Menghini",
                "Juan Rubio Zuazo",
                "Jes\u00fas L\u00f3pez S\u00e1nchez",
                "Jin Won Seo",
                "Michel Houssa",
                "Jean-Pierre Locquet"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04425v1",
                "http://arxiv.org/pdf/2312.04425v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04421v1",
            "title": "PWN-powered Galactic Center X-ray filament G0.13-0.11: Proof of the\n  synchrotron nature by IXPE",
            "updated": "2023-12-07T16:45:26Z",
            "published": "2023-12-07T16:45:26Z",
            "summary": "We report the discovery of X-ray polarization from the X-ray-bright\nthread/filament G0.13-0.11 in the Galactic Center region. This filament\nfeatures a bright hard X-ray source, most plausibly a Pulsar Wind Nebula (PWN),\nand an extended and structured diffuse component. Combining the polarization\nsignal from IXPE with the imaging/spectroscopic data from Chandra, we find that\nX-ray emission of G0.13-0.11 is highly polarized PD=$57(\\pm18)$\\% in the 3-6\nkeV band, while the polarization angle is PA=$21^\\circ(\\pm9^\\circ)$. This high\ndegree of polarization proves the synchrotron origin of the X-ray emission from\nG0.13-0.11. In turn, the measured polarization angle implies that the X-ray\nemission is polarized approximately perpendicular to a sequence of non-thermal\nradio filaments that may be part of the Galactic Center Radio Arc. The magnetic\nfield of the order of $100\\,{\\rm\\mu G}$ appears to be preferentially ordered\nalong the filaments. The above field strength is the fiducial value that makes\nour model self-consistent, while the other conclusions are largely\nmodel-independent.",
            "author": [
                "Eugene Churazov",
                "Ildar Khabibullin",
                "Thibault Barnouin",
                "Niccol\u00f2 Bucciantini",
                "Enrico Costa",
                "Laura Di Gesu",
                "Alessandro Di Marco",
                "Riccardo Ferrazzoli",
                "William Forman",
                "Philip Kaaret",
                "Dawoon E. Kim",
                "Jeffery J. Kolodziejczak",
                "Ralph Kraft",
                "Fr\u00e9d\u00e9ric Marin",
                "Giorgio Matt",
                "Michela Negro",
                "Roger W. Romani",
                "Stefano Silvestri",
                "Paolo Soffitta",
                "Rashid Sunyaev",
                "Jiri Svoboda",
                "Alexey Vikhlinin",
                "Martin C. Weisskopf",
                "Fei Xie",
                "Iv\u00e1n Agudo",
                "Lucio A. Antonelli",
                "Matteo Bachetti",
                "Luca Baldini",
                "Wayne H. Baumgartner",
                "Ronaldo Bellazzini",
                "Stefano Bianchi",
                "Stephen D. Bongiorno",
                "Raffaella Bonino",
                "Alessandro Brez",
                "Fiamma Capitanio",
                "Simone Castellano",
                "Elisabetta Cavazzuti",
                "Chien-Ting Chen",
                "Stefano Ciprini",
                "Alessandra De Rosa",
                "Ettore Del Monte",
                "Niccol\u00f2 Di Lalla",
                "Immacolata Donnarumma",
                "Victor Doroshenko",
                "Michal Dov\u010diak",
                "Steven R. Ehlert",
                "Teruaki Enoto",
                "Yuri Evangelista",
                "Sergio Fabiani",
                "Javier A. Garc\u00eda",
                "Shuichi Gunji",
                "Kiyoshi Hayashida",
                "Jeremy Heyl",
                "Wataru Iwakiri",
                "Svetlana G. Jorstad",
                "Vladimir Karas",
                "Fabian Kislat",
                "Takao Kitaguchi",
                "Henric Krawczynski",
                "Fabio La Monaca",
                "Luca Latronico",
                "Ioannis Liodakis",
                "Simone Maldera",
                "Alberto Manfreda",
                "Andrea Marinucci",
                "Alan P. Marscher",
                "Herman L. Marshall",
                "Francesco Massaro",
                "Ikuyuki Mitsuishi",
                "Tsunefumi Mizuno",
                "Fabio Muleri",
                "Chi-Yung Ng",
                "Stephen L. O'Dell",
                "Nicola Omodei",
                "Chiara Oppedisano",
                "Alessandro Papitto",
                "George G. Pavlov",
                "Abel L. Peirson",
                "Matteo Perri",
                "Melissa Pesce-Rollins",
                "Pierre-Olivier Petrucci",
                "Maura Pilia",
                "Andrea Possenti",
                "Juri Poutanen",
                "Simonetta Puccetti",
                "Brian D. Ramsey",
                "John Rankin",
                "Ajay Ratheesh",
                "Oliver J. Roberts",
                "Carmelo Sgr\u00f2",
                "Patrick Slane",
                "Gloria Spandre",
                "Douglas A. Swartz",
                "Toru Tamagawa",
                "Fabrizio Tavecchio",
                "Roberto Taverna",
                "Yuzuru Tawara",
                "Allyn F. Tennant",
                "Nicholas E. Thomas",
                "Francesco Tombesi",
                "Alessio Trois",
                "Sergey S. Tsygankov",
                "Roberto Turolla",
                "Jacco Vink",
                "Kinwah Wu",
                "Silvia Zane"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04421v1",
                "http://arxiv.org/pdf/2312.04421v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04418v1",
            "title": "MIST: An Efficient Approach for Software-Defined Multicast in Wireless\n  Mesh Networks",
            "updated": "2023-12-07T16:40:11Z",
            "published": "2023-12-07T16:40:11Z",
            "summary": "Multicasting is a vital information dissemination technique in\nSoftware-Defined Networking (SDN). With SDN, a multicast service can\nincorporate network functions implemented at different nodes, which is referred\nto as software-defined multicast. Emerging ubiquitous wireless networks for 5G\nand Beyond (B5G) inherently support multicast. However, the broadcast nature of\nwireless channels, especially in dense deployments, leads to neighborhood\ninterference as a primary system degradation factor, which introduces a new\nchallenge for software-defined multicast in wireless mesh networks. To tackle\nthis, this paper introduces a novel approach, based on the idea of minimizing\nboth the total length cost of the multicast tree and the interference at the\nsame time. Accordingly, a bicriteria optimization problem is formulated, which\nis called \\emph{Minimum Interference Steiner Tree (MIST)}. To solve the\nbicriteria problem, instead of resorting to heuristics, this paper employs an\ninnovative approach that is an approximate algorithm for MIST but with\nguaranteed performance. Specifically, the approach is a two-stage relaxation\nalgorithm by exploiting the monotone submodularity property of the interference\nmetric and identifying Pareto optimal solutions for MIST. Simulation results\ndemonstrate and validate the performance of the proposed algorithm.",
            "author": [
                "Rupei Xu",
                "Yuming Jiang",
                "Jason P. Jue"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04418v1",
                "http://arxiv.org/pdf/2312.04418v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04414v1",
            "title": "A single-phonon directional coupler",
            "updated": "2023-12-07T16:36:17Z",
            "published": "2023-12-07T16:36:17Z",
            "summary": "Integrated photonics has enabled countless technologies in\ntelecommunications, spectroscopy, metrology, quantum optics, and quantum\ninformation processing. Using highly confined guided optical modes is the key\nthat has made integrated circuits possible and has lead to scaling of complex\ndesigns, benefiting from their small footprint. At the same time, the field of\nquantum acoustics has recently gained significant attention due to its various\npotential advantages over its photonic counterparts, including smaller mode\nvolume, lower energy, and orders of magnitude slower propagation speeds, as\nwell as the potential for interconnecting distinct quantum systems. Developing\nanalogous integrated phononic technology is critical for realizing the full\npotential of phonons and could lead to groundbreaking new applications, such as\nscalable quantum computing and hybrid quantum devices. In this work, we\ndemonstrate for the first time a 4-port directional coupler for quantum\nmechanical excitations - a crucial component for integrated phononic circuits.\nAdjusting the length of the coupling region allows to realize phononic beam\nsplitters with varying splitting ratios. By sending a single-phonon Fock state\nonto one of these phononic splitters, we demonstrate the capability of using\nthe directional coupler directly in the quantum regime. Our work provides an\nessential step towards an integrated phononic platform for both classical and\nquantum technologies applications.",
            "author": [
                "Amirparsa Zivari",
                "Niccol\u00f2 Fiaschi",
                "Lorenzo Scarpelli",
                "Menno Jansen",
                "Roel Burgwal",
                "Ewold Verhagen",
                "Simon Gr\u00f6blacher"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04414v1",
                "http://arxiv.org/pdf/2312.04414v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04413v1",
            "title": "On Schwinger-like pair production of baryons and new non-perturbative\n  processes in electric field",
            "updated": "2023-12-07T16:34:50Z",
            "published": "2023-12-07T16:34:50Z",
            "summary": "We consider the Schwinger production of baryons in an external electric field\nin the worldline instanton approach. The process occurs in the confinement\nregime hence the holographic QCD and the Chiral Lagrangian are used as the\ntools. The new exponentially suppressed processes in a constant electric field\ninvolving the composite worldline instantons are suggested. These include the\nnon-perturbative decay of a neutron into a proton and charged meson and the\nspontaneous production of $p\\bar{n}\\pi^{-}$ and $n\\bar{p}\\pi^{+}$ states.",
            "author": [
                "Alexander Gorsky",
                "Arseniy Pikalov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04413v1",
                "http://arxiv.org/pdf/2312.04413v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04412v1",
            "title": "Developing Elementary Federated Learning Algorithms Leveraging the\n  ChatGPT",
            "updated": "2023-12-07T16:34:47Z",
            "published": "2023-12-07T16:34:47Z",
            "summary": "The Python Testbed for Federated Learning Algorithms is a simple Python FL\nframework easy to use by ML&AI developers who do not need to be professional\nprogrammers, and this paper shows that it is also amenable to emerging AI\ntools. In this paper, we successfully developed three elementary FL algorithms\nusing the following three steps process: (i) specify context, (ii) ask ChatGPT\nto complete server and clients' callback functions, and (iii) verify the\ngenerated code.",
            "author": [
                "Miroslav Popovic",
                "Marko Popovic",
                "Ivan Kastelan",
                "Miodrag Djukic",
                "Ilija Basicevic"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04412v1",
                "http://arxiv.org/pdf/2312.04412v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04403v1",
            "title": "OT-Attack: Enhancing Adversarial Transferability of Vision-Language\n  Models via Optimal Transport Optimization",
            "updated": "2023-12-07T16:16:50Z",
            "published": "2023-12-07T16:16:50Z",
            "summary": "Vision-language pre-training (VLP) models demonstrate impressive abilities in\nprocessing both images and text. However, they are vulnerable to multi-modal\nadversarial examples (AEs). Investigating the generation of\nhigh-transferability adversarial examples is crucial for uncovering VLP models'\nvulnerabilities in practical scenarios. Recent works have indicated that\nleveraging data augmentation and image-text modal interactions can enhance the\ntransferability of adversarial examples for VLP models significantly. However,\nthey do not consider the optimal alignment problem between dataaugmented\nimage-text pairs. This oversight leads to adversarial examples that are overly\ntailored to the source model, thus limiting improvements in transferability. In\nour research, we first explore the interplay between image sets produced\nthrough data augmentation and their corresponding text sets. We find that\naugmented image samples can align optimally with certain texts while exhibiting\nless relevance to others. Motivated by this, we propose an Optimal\nTransport-based Adversarial Attack, dubbed OT-Attack. The proposed method\nformulates the features of image and text sets as two distinct distributions\nand employs optimal transport theory to determine the most efficient mapping\nbetween them. This optimal mapping informs our generation of adversarial\nexamples to effectively counteract the overfitting issues. Extensive\nexperiments across various network architectures and datasets in image-text\nmatching tasks reveal that our OT-Attack outperforms existing state-of-the-art\nmethods in terms of adversarial transferability.",
            "author": [
                "Dongchen Han",
                "Xiaojun Jia",
                "Yang Bai",
                "Jindong Gu",
                "Yang Liu",
                "Xiaochun Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04403v1",
                "http://arxiv.org/pdf/2312.04403v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04401v1",
            "title": "Competing d$_{xy}$ and s$_{\\pm }$ Pairing Symmetries in Superconducting\n  La$_{3}$Ni$_{2}$O$_{7}$ emerge from LDA+FLEX Calculations",
            "updated": "2023-12-07T16:15:16Z",
            "published": "2023-12-07T16:15:16Z",
            "summary": "With recent discoveries of superconductivity in infinite-layer nickelates,\nand in La$_{3}$Ni$_{2}$O$_{7}$ under high pressure, new opportunities appeared\nthat yet another family of high-temperature superconductors based on Ni element\nmay exist in Nature as was previously the case of cuprates and iron based\nmaterials. With their famous strong Coulomb correlations among 3d electrons and\nthe proximity to antiferromagnetic instability these systems represent a\nchallenge for their theoretical description, and most previous studies of\nsuperconductivity relied on the solutions of simplified few--orbital model\nHamiltonians. Here, on the other hand, we use a recently developed combination\nof density functional theory with momentum and frequency resolved\nself--energies deduced from the so--called Fluctuational-Exchange (FLEX)-type\nRandom Phase Approximation (RPA) to study spin fluctuation mediated pairing\ntendencies in La$_{3}$Ni$_{2}$O$_{7}$ under pressure. This methodology uses\nfirst--principle electronic structures of an actual material and is free of\ntight-binding parametrizations employed in model Hamiltonian approach. Based on\nour numerical diagonalization of the BCS Gap equation we show that competing\nd$_{xy}$ and s$_{\\pm }$ pairing symmetries emerge in superconducting\nLa$_{3}$Ni$_{2}$O$_{7}$ with the corresponding coupling constants becoming very\nlarge in the proximity of spin density wave instability. The results presented\nhere are discussed in light of numerous other calculations and provide\non--going experimental efforts with predictions that will allow further tests\nof our understanding of unconventional superconductors.",
            "author": [
                "Griffin Heier",
                "Kyungwha Park",
                "Sergey Y. Savrasov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04401v1",
                "http://arxiv.org/pdf/2312.04401v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04399v1",
            "title": "Resonant leptogenesis in minimal inverse seesaw ISS(2,2) model",
            "updated": "2023-12-07T16:10:56Z",
            "published": "2023-12-07T16:10:56Z",
            "summary": "We investigate the parameter space of the minimal inverse seesaw ISS(2,2)\nmodel for successful leptogenesis. The framework of ISS(2, 2) is realized by\naugmenting the Standard Model with two right-handed and two Standard Model\nsinglet neutrinos. The decay of the heavy sterile states which is essentially\nan admixture of the right-handed and SM singlet neutrino states produces the\nbaryon asymmetry of the universe. In this predictive model of leptogenesis, we\nstudy resonant leptogenesis where the mass splitting between the heavy sterile\nstates is naturally achieved. We review the possibility of generating the\nobserved baryon asymmetry of the universe via leptogenesis where the CP\nviolation comes solely from the low-energy CP phases. In addition, we study the\neffect of texture zero in the Dirac mass matrix on the parameter space of the\nmodel for successful resonant leptogenesis.",
            "author": [
                "Bikash Thapa",
                "Ng. K. Francis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04399v1",
                "http://arxiv.org/pdf/2312.04399v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04398v1",
            "title": "Intelligent Anomaly Detection for Lane Rendering Using Transformer with\n  Self-Supervised Pre-Training and Customized Fine-Tuning",
            "updated": "2023-12-07T16:10:10Z",
            "published": "2023-12-07T16:10:10Z",
            "summary": "The burgeoning navigation services using digital maps provide great\nconvenience to drivers. Nevertheless, the presence of anomalies in lane\nrendering map images occasionally introduces potential hazards, as such\nanomalies can be misleading to human drivers and consequently contribute to\nunsafe driving conditions. In response to this concern and to accurately and\neffectively detect the anomalies, this paper transforms lane rendering image\nanomaly detection into a classification problem and proposes a four-phase\npipeline consisting of data pre-processing, self-supervised pre-training with\nthe masked image modeling (MiM) method, customized fine-tuning using\ncross-entropy based loss with label smoothing, and post-processing to tackle it\nleveraging state-of-the-art deep learning techniques, especially those\ninvolving Transformer models. Various experiments verify the effectiveness of\nthe proposed pipeline. Results indicate that the proposed pipeline exhibits\nsuperior performance in lane rendering image anomaly detection, and notably,\nthe self-supervised pre-training with MiM can greatly enhance the detection\naccuracy while significantly reducing the total training time. For instance,\nemploying the Swin Transformer with Uniform Masking as self-supervised\npretraining (Swin-Trans-UM) yielded a heightened accuracy at 94.77% and an\nimproved Area Under The Curve (AUC) score of 0.9743 compared with the pure Swin\nTransformer without pre-training (Swin-Trans) with an accuracy of 94.01% and an\nAUC of 0.9498. The fine-tuning epochs were dramatically reduced to 41 from the\noriginal 280. In conclusion, the proposed pipeline, with its incorporation of\nself-supervised pre-training using MiM and other advanced deep learning\ntechniques, emerges as a robust solution for enhancing the accuracy and\nefficiency of lane rendering image anomaly detection in digital navigation\nsystems.",
            "author": [
                "Yongqi Dong",
                "Xingmin Lu",
                "Ruohan Li",
                "Wei Song",
                "Bart van Arem",
                "Haneen Farah"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04398v1",
                "http://arxiv.org/pdf/2312.04398v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04394v1",
            "title": "Parametric Amplification of a Quantum Pulse",
            "updated": "2023-12-07T16:07:06Z",
            "published": "2023-12-07T16:07:06Z",
            "summary": "Creating and manipulating quantum states of light requires nonlinear\ninteractions, but while nonlinear optics is inherently multi-mode, quantum\noptical analyses are often done with single-mode approximations. We present a\nmulti-mode theory for the transformation of a quantum pulse by Hamiltonians\nthat are quadratic in the field creation and annihilation operators. Our theory\ndescribes nonlinear processes, such as parametric amplification and squeezing,\nas well as all linear processes, such as dispersion and beam splitting. We show\nthat a single input pulse feeds only two distinct output modes and, for certain\nquantum states, just one. Our theory provides the quantum states in the output\nmodes, which are crucial for the application of pulses in quantum optics and\nquantum information.",
            "author": [
                "Offek Tziperman",
                "Victor Rueskov Christiansen",
                "Ido Kaminer",
                "Klaus M\u00f8lmer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04394v1",
                "http://arxiv.org/pdf/2312.04394v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04389v1",
            "title": "Revisiting inclusive production of J/psi and Upsilon in high-energy\n  gamma-gamma collisions",
            "updated": "2023-12-07T16:01:00Z",
            "published": "2023-12-07T16:01:00Z",
            "summary": "The impact of Next-to-Leading Order (NLO) QCD corrections to the differential\ndistributions of J/psi and Upsilon mesons produced inclusively in gamma-gamma\ncollisions is discussed for the kinematical conditions of LEP II for DELPHI and\nat the future Circular Electron-Positron Collider (CEPC). We take into account\nall sizeable contributions at LO in v^2 in NRQCD factorisation: 1) pure QED\nprocess gamma + gamma -> J/psi(3S^1_1) + \\gamma up to alpha^3 alpha_s, 2)\nsingle-resolved-photon contributions up to alpha_s^4, 3) gamma+gamma -> J/psi +\nc c-bar up to alpha^2 alpha_s and 4) gamma+gamma -> J/psi + ggg up to alpha^2\nalpha_s^3. We will also discuss the pure QED process as a contribution to the\nexclusive production in ultra-peripheral heavy-ion collisions (UPC) at the LHC.",
            "author": [
                "Yelyzaveta Yedelkina",
                "Jean-Philippe Lansberg",
                "Maxim Nefedov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04389v1",
                "http://arxiv.org/pdf/2312.04389v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "nucl-ex",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04385v1",
            "title": "AniRes2D: Anisotropic Residual-enhanced Diffusion for 2D MR\n  Super-Resolution",
            "updated": "2023-12-07T15:55:31Z",
            "published": "2023-12-07T15:55:31Z",
            "summary": "Anisotropic low-resolution (LR) magnetic resonance (MR) images are fast to\nobtain but hinder automated processing. We propose to use denoising diffusion\nprobabilistic models (DDPMs) to super-resolve these 2D-acquired LR MR slices.\nThis paper introduces AniRes2D, a novel approach combining DDPM with a residual\nprediction for 2D super-resolution (SR). Results demonstrate that AniRes2D\noutperforms several other DDPM-based models in quantitative metrics, visual\nquality, and out-of-domain evaluation. We use a trained AniRes2D to\nsuper-resolve 3D volumes slice by slice, where comparative quantitative results\nand reduced skull aliasing are achieved compared to a recent state-of-the-art\nself-supervised 3D super-resolution method. Furthermore, we explored the use of\nnoise conditioning augmentation (NCA) as an alternative augmentation technique\nfor DDPM-based SR models, but it was found to reduce performance. Our findings\ncontribute valuable insights to the application of DDPMs for SR of anisotropic\nMR images.",
            "author": [
                "Zejun Wu",
                "Samuel W. Remedios",
                "Blake E. Dewey",
                "Aaron Carass",
                "Jerry L. Prince"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04385v1",
                "http://arxiv.org/pdf/2312.04385v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04383v1",
            "title": "Elastic Recoil Imprinted on Free-electron Radiation",
            "updated": "2023-12-07T15:52:24Z",
            "published": "2023-12-07T15:52:24Z",
            "summary": "Free-electron radiation phenomena are treated almost exclusively with\nclassical electrodynamics, despite the intrinsic interaction being that of\nquantum electrodynamics. The lack of quantumness arises from the vast disparity\nbetween the electron energy and the much smaller photon energy, creating a\nsmall cross-section that makes quantum effects negligible. Here we identify a\nfundamentally distinct phenomenon of electron radiation that bypasses this\nenergy disparity, and thus displays extremely strong quantum features. This\nphenomenon arises from free-electron elastic recoil, which can influence\nfundamental radiation processes in ways thought so far to necessitate inelastic\nscattering. The underlying reason for the quantum radiation features, which\nhave no counterparts in classical theory, is the entanglement between each\nelastically recoiled electron and the photons it emitted. We show that this\nphenomenon is more accessible than all other types of quantum features in\nfree-electron radiation and can be detected in current experimental setups such\nas electron microscopes. These quantum radiation features could guide the\ndevelopment of compact coherent X-ray sources facilitated by nanophotonics and\nquantum optics.",
            "author": [
                "Xihang Shi",
                "Lee Wei Wesley Wong",
                "Sunchao Huang",
                "LiangJie Wong",
                "Ido Kaminer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04383v1",
                "http://arxiv.org/pdf/2312.04383v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04382v1",
            "title": "Adversarial Denoising Diffusion Model for Unsupervised Anomaly Detection",
            "updated": "2023-12-07T15:51:19Z",
            "published": "2023-12-07T15:51:19Z",
            "summary": "In this paper, we propose the Adversarial Denoising Diffusion Model (ADDM).\nThe ADDM is based on the Denoising Diffusion Probabilistic Model (DDPM) but\ncomplementarily trained by adversarial learning. The proposed adversarial\nlearning is achieved by classifying model-based denoised samples and samples to\nwhich random Gaussian noise is added to a specific sampling step. With the\naddition of explicit adversarial learning on data samples, ADDM can learn the\nsemantic characteristics of the data more robustly during training, which\nachieves a similar data sampling performance with much fewer sampling steps\nthan DDPM. We apply ADDM to anomaly detection in unsupervised MRI images.\nExperimental results show that the proposed ADDM outperformed existing\ngenerative model-based unsupervised anomaly detection methods. In particular,\ncompared to other DDPM-based anomaly detection methods, the proposed ADDM shows\nbetter performance with the same number of sampling steps and similar\nperformance with 50% fewer sampling steps.",
            "author": [
                "Jongmin Yu",
                "Hyeontaek Oh",
                "Jinhong Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04382v1",
                "http://arxiv.org/pdf/2312.04382v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04377v1",
            "title": "HARQ-IR Aided Short Packet Communications: BLER Analysis and Throughput\n  Maximization",
            "updated": "2023-12-07T15:47:18Z",
            "published": "2023-12-07T15:47:18Z",
            "summary": "This paper introduces hybrid automatic repeat request with incremental\nredundancy (HARQ-IR) to boost the reliability of short packet communications.\nThe finite blocklength information theory and correlated decoding events\ntremendously preclude the analysis of average block error rate (BLER).\nFortunately, the recursive form of average BLER motivates us to calculate its\nvalue through the trapezoidal approximation and Gauss-Laguerre quadrature.\nMoreover, the asymptotic analysis is performed to derive a simple expression\nfor the average BLER at high signal-to-noise ratio (SNR). Then, we study the\nmaximization of long term average throughput (LTAT) via power allocation\nmeanwhile ensuring the power and the BLER constraints. For tractability, the\nasymptotic BLER is employed to solve the problem through geometric programming\n(GP). However, the GP-based solution underestimates the LTAT at low SNR due to\na large approximation error in this case. Alternatively, we also develop a deep\nreinforcement learning (DRL)-based framework to learn power allocation policy.\nIn particular, the optimization problem is transformed into a constrained\nMarkov decision process, which is solved by integrating deep deterministic\npolicy gradient (DDPG) with subgradient method. The numerical results finally\ndemonstrate that the DRL-based method outperforms the GP-based one at low SNR,\nalbeit at the cost of increasing computational burden.",
            "author": [
                "Fuchao He",
                "Zheng Shi",
                "Guanghua Yang",
                "Xiaofan Li",
                "Xinrong Ye",
                "Shaodan Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04377v1",
                "http://arxiv.org/pdf/2312.04377v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04375v1",
            "title": "Generating Multiphase Fluid Configurations in Fractures using Diffusion\n  Models",
            "updated": "2023-12-07T15:46:54Z",
            "published": "2023-12-07T15:46:54Z",
            "summary": "Pore-scale simulations accurately describe transport properties of fluids in\nthe subsurface. These simulations enhance our understanding of applications\nsuch as assessing hydrogen storage efficiency and forecasting CO$_2$\nsequestration processes in underground reservoirs. Nevertheless, they are\ncomputationally expensive due to their mesoscopic nature. In addition, their\nstationary solutions are not guaranteed to be unique, so multiple runs with\ndifferent initial conditions must be performed to ensure sufficient sample\ncoverage. These factors complicate the task of obtaining representative and\nreliable forecasts. To overcome the high computational cost hurdle, we propose\na hybrid method that couples generative diffusion models and physics-based\nmodeling. Upon training a generative model, we synthesize samples that serve as\nthe initial conditions for physics-based simulations. We measure the relaxation\ntime (to stationary solutions) of the simulations, which serves as a validation\nmetric and early-stopping criterion. Our numerical experiments revealed that\nthe hybrid method exhibits a speed-up of up to 8.2 times compared to commonly\nused initialization methods. This finding offers compelling initial support\nthat the proposed diffusion model-based hybrid scheme has potentials to\nsignificantly decrease the time required for convergence of numerical\nsimulations without compromising the physical robustness.",
            "author": [
                "Jaehong Chung",
                "Agnese Marcato",
                "Eric J. Guiltinan",
                "Tapan Mukerji",
                "Yen Ting Lin",
                "Javier E. Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04375v1",
                "http://arxiv.org/pdf/2312.04375v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04373v1",
            "title": "Unmasking the Polygamous Nature of Quantum Nonlocality",
            "updated": "2023-12-07T15:44:24Z",
            "published": "2023-12-07T15:44:24Z",
            "summary": "Quantum mechanics imposes limits on the values of certain observables.\nPerhaps the most famous example is the uncertainty principle. Similar\ntrade-offs also exist for simultaneous violation of multiple Bell inequalities.\nIn the simplest case of three observers it has been shown that violation of one\nBell inequality precludes any violation of other inequalities, a property\ncalled monogamy of Bell violations. Forms of Bell monogamy have been linked to\nthe no-signalling principle and the inability of simultaneous violations of all\ninequalities is regarded as their fundamental characteristics. Here we show\nthat Bell monogamy does not hold universally and in fact the only monogamous\nsituation is that of three observers. Consequently, the nature of quantum\nnonlocality is truly polygamous. We present a systematic methodology for\nidentifying quantum states and tight Bell inequalities that do not obey the\nmonogamy principle for any number of more than three observers. The identified\npolygamous inequalities can be violated in state of the art setups and may be\nexploited for simultaneous self-testing of multiple stations in a quantum\nnetwork.",
            "author": [
                "Pawe\u0142 Cie\u015bli\u0144ski",
                "Mateusz Kowalczyk",
                "Wies\u0142aw Laskowski",
                "Tomasz Paterek",
                "Tam\u00e1s V\u00e9rtesi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04373v1",
                "http://arxiv.org/pdf/2312.04373v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04372v1",
            "title": "LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language\n  Model Programs",
            "updated": "2023-12-07T15:43:52Z",
            "published": "2023-12-07T15:43:52Z",
            "summary": "We present LaMPilot, a novel framework for planning in the field of\nautonomous driving, rethinking the task as a code-generation process that\nleverages established behavioral primitives. This approach aims to address the\nchallenge of interpreting and executing spontaneous user instructions such as\n\"overtake the car ahead,\" which have typically posed difficulties for existing\nframeworks. We introduce the LaMPilot benchmark specifically designed to\nquantitatively evaluate the efficacy of Large Language Models (LLMs) in\ntranslating human directives into actionable driving policies. We then evaluate\na wide range of state-of-the-art code generation language models on tasks from\nthe LaMPilot Benchmark. The results of the experiments showed that GPT-4, with\nhuman feedback, achieved an impressive task completion rate of 92.7% and a\nminimal collision rate of 0.9%. To encourage further investigation in this\narea, our code and dataset will be made available.",
            "author": [
                "Yunsheng Ma",
                "Can Cui",
                "Xu Cao",
                "Wenqian Ye",
                "Peiran Liu",
                "Juanwu Lu",
                "Amr Abdelraouf",
                "Rohit Gupta",
                "Kyungtae Han",
                "Aniket Bera",
                "James M. Rehg",
                "Ziran Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04372v1",
                "http://arxiv.org/pdf/2312.04372v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04370v1",
            "title": "Investigating the Design Space of Diffusion Models for Speech\n  Enhancement",
            "updated": "2023-12-07T15:40:55Z",
            "published": "2023-12-07T15:40:55Z",
            "summary": "Diffusion models are a new class of generative models that have shown\noutstanding performance in image generation literature. As a consequence,\nstudies have attempted to apply diffusion models to other tasks, such as speech\nenhancement. A popular approach in adapting diffusion models to speech\nenhancement consists in modelling a progressive transformation between the\nclean and noisy speech signals. However, one popular diffusion model framework\npreviously laid in image generation literature did not account for such a\ntransformation towards the system input, which prevents from relating the\nexisting diffusion-based speech enhancement systems with the aforementioned\ndiffusion model framework. To address this, we extend this framework to account\nfor the progressive transformation between the clean and noisy speech signals.\nThis allows us to apply recent developments from image generation literature,\nand to systematically investigate design aspects of diffusion models that\nremain largely unexplored for speech enhancement, such as the neural network\npreconditioning, the training loss weighting, the stochastic differential\nequation (SDE), or the amount of stochasticity injected in the reverse process.\nWe show that the performance of previous diffusion-based speech enhancement\nsystems cannot be attributed to the progressive transformation between the\nclean and noisy speech signals. Moreover, we show that a proper choice of\npreconditioning, training loss weighting, SDE and sampler allows to outperform\na popular diffusion-based speech enhancement system in terms of perceptual\nmetrics while using fewer sampling steps, thus reducing the computational cost\nby a factor of four.",
            "author": [
                "Philippe Gonzalez",
                "Zheng-Hua Tan",
                "Jan \u00d8stergaard",
                "Jesper Jensen",
                "Tommy Sonne Alstr\u00f8m",
                "Tobias May"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04370v1",
                "http://arxiv.org/pdf/2312.04370v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04369v1",
            "title": "SingingHead: A Large-scale 4D Dataset for Singing Head Animation",
            "updated": "2023-12-07T15:40:36Z",
            "published": "2023-12-07T15:40:36Z",
            "summary": "Singing, as a common facial movement second only to talking, can be regarded\nas a universal language across ethnicities and cultures, plays an important\nrole in emotional communication, art, and entertainment. However, it is often\noverlooked in the field of audio-driven facial animation due to the lack of\nsinging head datasets and the domain gap between singing and talking in rhythm\nand amplitude. To this end, we collect a high-quality large-scale singing head\ndataset, SingingHead, which consists of more than 27 hours of synchronized\nsinging video, 3D facial motion, singing audio, and background music from 76\nindividuals and 8 types of music. Along with the SingingHead dataset, we argue\nthat 3D and 2D facial animation tasks can be solved together, and propose a\nunified singing facial animation framework named UniSinger to achieve both\nsinging audio-driven 3D singing head animation and 2D singing portrait video\nsynthesis. Extensive comparative experiments with both SOTA 3D facial animation\nand 2D portrait animation methods demonstrate the necessity of singing-specific\ndatasets in singing head animation tasks and the promising performance of our\nunified facial animation framework.",
            "author": [
                "Sijing Wu",
                "Yunhao Li",
                "Weitian Zhang",
                "Jun Jia",
                "Yucheng Zhu",
                "Yichao Yan",
                "Guangtao Zhai"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04369v1",
                "http://arxiv.org/pdf/2312.04369v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04363v1",
            "title": "Refined analysis of $\u03a9^{-} \\bar\u03a9^{+}$ polarization in\n  electron-positron annihilation process",
            "updated": "2023-12-07T15:32:41Z",
            "published": "2023-12-07T15:32:41Z",
            "summary": "We investigate the production of spin-3/2 hyperon pairs, $\\Omega^-\n\\bar{\\Omega}^+$, in electron-positron annihilation within the helicity\namplitude formalism. A refined selection of helicity basis matrices is proposed\nto relate polarization expansion coefficients and spin density matrix elements\nand to illuminate their inherent physical interpretations and symmetrical\nproperties. With a novel parametrization scheme of helicity amplitudes, we\nperform an analysis of polarization correlation coefficients for double-tag\n$\\Omega^- \\bar{\\Omega}^+$ pairs. We present three sets of expressions to\ndescribe the decay of $\\Omega^{-}$ hyperons, and further address the existing\ntension in the measurements of its decay parameters, particularly\n$\\phi_{\\Omega}$. The method and the framework developed in this paper can also\nbe applied to studies of the production and decay mechanisms of other spin-3/2\nparticles.",
            "author": [
                "Zhe Zhang",
                "Jiao Jiao Song",
                "Ya-jin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04363v1",
                "http://arxiv.org/pdf/2312.04363v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04362v1",
            "title": "PCoQA: Persian Conversational Question Answering Dataset",
            "updated": "2023-12-07T15:29:34Z",
            "published": "2023-12-07T15:29:34Z",
            "summary": "Humans seek information regarding a specific topic through performing a\nconversation containing a series of questions and answers. In the pursuit of\nconversational question answering research, we introduce the PCoQA, the first\n\\textbf{P}ersian \\textbf{Co}nversational \\textbf{Q}uestion \\textbf{A}nswering\ndataset, a resource comprising information-seeking dialogs encompassing a total\nof 9,026 contextually-driven questions. Each dialog involves a questioner, a\nresponder, and a document from the Wikipedia; The questioner asks several\ninter-connected questions from the text and the responder provides a span of\nthe document as the answer for each question. PCoQA is designed to present\nnovel challenges compared to previous question answering datasets including\nhaving more open-ended non-factual answers, longer answers, and fewer lexical\noverlaps. This paper not only presents the comprehensive PCoQA dataset but also\nreports the performance of various benchmark models. Our models include\nbaseline models and pre-trained models, which are leveraged to boost the\nperformance of the model. The dataset and benchmarks are available at our\nGithub page.",
            "author": [
                "Hamed Hematian Hemati",
                "Atousa Toghyani",
                "Atena Souri",
                "Sayed Hesam Alavian",
                "Hossein Sameti",
                "Hamid Beigy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04362v1",
                "http://arxiv.org/pdf/2312.04362v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04358v1",
            "title": "Balance Correlations, Agentic Zeros, and Networks: The Structure of 192\n  Years of War and Peace",
            "updated": "2023-12-07T15:25:44Z",
            "published": "2023-12-07T15:25:44Z",
            "summary": "Original balance theory (Heider 1944) predicts human relations based on\nperceptions and attitudes between a pair of individuals (P - O) towards an\ninanimate object X. Social network extensions of his theory have replaced this\nX with a third individual. This has led to a plethora of adaptations that have\noften been inconsistent with Heider and with each other. We present a general\nmodel and formal notation for these social network extensions that permit\nsocial scientists to be more explicit about their balance theoretic statements.\nSpecifically, we formulate statements as a comparison of two conditional\nprobabilities of a tie, where the conditionals are defined by the 2-path\nrelation Ego - X - Alter. Given the importance Heider assigns to the role of\nnegative associations, we further identify negative ties as separate from\nnon-ties (neutral or zero-valued ties) and consider a signed graph to be a\nrestricted multigraph composed of three mutually exclusive and exhaustive\nrelations: positive ties, negative ties, and zero-ties. We stress that\nneutrality is the result of a triadic process. Combining these two features\ninto our theoretical frame results in 27 identifiable configurations. Drawing\non the work on Transitivity Correlation models, we propose a set of simple\ndescriptive statistics to measure the extent to which evidence for any\nstipulated balance configuration is present in a network. Finally, we\ndemonstrate how to apply this approach to assess network-level balance in a\nlarge data set consisting of friendly vs hostile relations between countries\nfrom 1816 to 2007. We find strong evidence particularly for one of the four\nclassic Heiderian balance theory predictions, and virtually no evidence in\nsupport of the imbalance predictions. However, we do find stable and surprising\nevidence that `neutral' ties are important in balancing the relations among\nnations.",
            "author": [
                "David Dekker",
                "David Krackhardt",
                "Patrick Doreian"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04358v1",
                "http://arxiv.org/pdf/2312.04358v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04355v1",
            "title": "Secure Cell-Free Integrated Sensing and Communication in the Presence of\n  Information and Sensing Eavesdroppers",
            "updated": "2023-12-07T15:21:55Z",
            "published": "2023-12-07T15:21:55Z",
            "summary": "This paper studies a secure cell-free integrated sensing and communication\n(ISAC) system, in which multiple ISAC transmitters collaboratively send\nconfidential information to multiple communication users (CUs) and concurrently\nconduct target detection. Different from prior works investigating\ncommunication security against potential information eavesdropping, we consider\nthe security of both communication and sensing in the presence of both\ninformation and sensing eavesdroppers that aim to intercept confidential\ncommunication information and extract target information, respectively. Towards\nthis end, we optimize the joint information and sensing transmit beamforming at\nthese ISAC transmitters for secure cell-free ISAC. Our objective is to maximize\nthe detection probability over a designated sensing area while ensuring the\nminimum signal-to-interference-plus-noise-ratio (SINR) requirements at CUs. Our\nformulation also takes into account the maximum tolerable signal-to-noise ratio\n(SNR) at information eavesdroppers for ensuring the confidentiality of\ninformation transmission, and the maximum detection probability constraints at\nsensing eavesdroppers for preserving sensing privacy. The formulated secure\njoint transmit beamforming problem is highly non-convex due to the intricate\ninterplay between the detection probabilities, beamforming vectors, and SINR\nconstraints. Fortunately, through strategic manipulation and via applying the\nsemidefinite relaxation (SDR) technique, we successfully obtain the globally\noptimal solution to the design problem by rigorously verifying the tightness of\nSDR. Furthermore, we present two alternative joint beamforming designs based on\nthe sensing SNR maximization over the specific sensing area and the coordinated\nbeamforming, respectively. Numerical results reveal the benefits of our\nproposed design over these alternative benchmarks.",
            "author": [
                "Zixiang Ren",
                "Jie Xu",
                "Ling Qiu",
                "Derrick Wing Kwan Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04355v1",
                "http://arxiv.org/pdf/2312.04355v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04350v1",
            "title": "CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language\n  Models",
            "updated": "2023-12-07T15:12:12Z",
            "published": "2023-12-07T15:12:12Z",
            "summary": "The ability to perform causal reasoning is widely considered a core feature\nof intelligence. In this work, we investigate whether large language models\n(LLMs) can coherently reason about causality. Much of the existing work in\nnatural language processing (NLP) focuses on evaluating commonsense causal\nreasoning in LLMs, thus failing to assess whether a model can perform causal\ninference in accordance with a set of well-defined formal rules. To address\nthis, we propose a new NLP task, causal inference in natural language, inspired\nby the \"causal inference engine\" postulated by Judea Pearl et al. We compose a\nlarge dataset, CLadder, with 10K samples: based on a collection of causal\ngraphs and queries (associational, interventional, and counterfactual), we\nobtain symbolic questions and ground-truth answers, through an oracle causal\ninference engine. These are then translated into natural language. We evaluate\nmultiple LLMs on our dataset, and we introduce and evaluate a bespoke\nchain-of-thought prompting strategy, CausalCoT. We show that our task is highly\nchallenging for LLMs, and we conduct an in-depth analysis to gain deeper\ninsight into the causal reasoning abilities of LLMs. Our data is open-sourced\nat https://huggingface.co/datasets/causalNLP/cladder, and our code can be found\nat https://github.com/causalNLP/cladder.",
            "author": [
                "Zhijing Jin",
                "Yuen Chen",
                "Felix Leeb",
                "Luigi Gresele",
                "Ojasv Kamal",
                "Zhiheng Lyu",
                "Kevin Blin",
                "Fernando Gonzalez Adauto",
                "Max Kleiman-Weiner",
                "Mrinmaya Sachan",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04350v1",
                "http://arxiv.org/pdf/2312.04350v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04348v1",
            "title": "When Input Integers are Given in the Unary Numeral Representation",
            "updated": "2023-12-07T15:09:24Z",
            "published": "2023-12-07T15:09:24Z",
            "summary": "Many NP-complete problems take integers as part of their input instances.\nThese input integers are generally binarized, that is, provided in the form of\nthe \"binary\" numeral representation, and the lengths of such binary forms are\nused as a basis unit to measure the computational complexity of the problems.\nIn sharp contrast, the \"unarization\" (or the \"unary\" numeral representation) of\nnumbers has been known to bring a remarkably different effect onto the\ncomputational complexity of the problems. When no computational-complexity\ndifference is observed between binarization and unarization of instances, on\nthe contrary, the problems are said to be strong NP-complete. This work\nattempts to spotlight an issue of how the unarization of instances affects the\ncomputational complexity of various combinatorial problems. We present numerous\nNP-complete (or even NP-hard) problems, which turn out to be easily solvable\nwhen input integers are represented in unary. We then discuss the computational\ncomplexities of such problems when taking unary-form integer inputs. We hope\nthat a list of such problems signifies the structural differences between\nstrong NP-completeness and non-strong NP-completeness.",
            "author": [
                "Tomoyuki Yamakami"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04348v1",
                "http://arxiv.org/pdf/2312.04348v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.CL",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04346v1",
            "title": "Improved Efficient Two-Stage Denoising Diffusion Power System\n  Measurement Recovery Against False Data Injection Attacks and Data Losses",
            "updated": "2023-12-07T15:06:06Z",
            "published": "2023-12-07T15:06:06Z",
            "summary": "Measurement uncertainties, represented by cyber-attacks and data losses,\nseriously degrade the quality of power system measurements. Fortunately, the\npowerful generation ability of the denoising diffusion models can enable more\nprecise measurement generation for power system data recovery. However, the\ncontrollable data generation and efficient computing methods of denoising\ndiffusion models for deterministic trajectory still need further investigation.\nTo this end, this paper proposes an improved two-stage denoising diffusion\nmodel (TSDM) to identify and reconstruct the measurements with various\nmeasurement uncertainties. The first stage of the model comprises a\nclassifier-guided conditional anomaly detection component, while the second\nstage involves diffusion-based measurement imputation component. Moreover, the\nproposed TSDM adopts precise means and optimal variances to accelerate the\ndiffusion generation process with subsequence sampling. Extensive numerical\ncase studies demonstrate that the proposed TSDM can accurately recover power\nsystem measurements despite strong randomness under renewable energy\nintegration and highly nonlinear dynamics under complex cyber-physical\ncontingencies. Additionally, the proposed TSDM has stronger robustness compared\nto existing reconstruction networks and exhibits lower computational complexity\nthan general denoising diffusion models.",
            "author": [
                "Jianhua Pei",
                "Jingyu Wang",
                "Dongyuan Shi",
                "Ping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04346v1",
                "http://arxiv.org/pdf/2312.04346v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04344v1",
            "title": "Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on\n  Prompt Engineering Strategies",
            "updated": "2023-12-07T15:05:59Z",
            "published": "2023-12-07T15:05:59Z",
            "summary": "OpenAI's latest large vision-language model (LVLM), GPT-4V(ision), has piqued\nconsiderable interest for its potential in medical applications. Despite its\npromise, recent studies and internal reviews highlight its underperformance in\nspecialized medical tasks. This paper explores the boundary of GPT-4V's\ncapabilities in medicine, particularly in processing complex imaging data from\nendoscopies, CT scans, and MRIs etc. Leveraging open-source datasets, we\nassessed its foundational competencies, identifying substantial areas for\nenhancement. Our research emphasizes prompt engineering, an often-underutilized\nstrategy for improving AI responsiveness. Through iterative testing, we refined\nthe model's prompts, significantly improving its interpretative accuracy and\nrelevance in medical imaging. From our comprehensive evaluations, we distilled\n10 effective prompt engineering techniques, each fortifying GPT-4V's medical\nacumen. These methodical enhancements facilitate more reliable, precise, and\nclinically valuable insights from GPT-4V, advancing its operability in critical\nhealthcare environments. Our findings are pivotal for those employing AI in\nmedicine, providing clear, actionable guidance on harnessing GPT-4V's full\ndiagnostic potential.",
            "author": [
                "Pengcheng Chen",
                "Ziyan Huang",
                "Zhongying Deng",
                "Tianbin Li",
                "Yanzhou Su",
                "Haoyu Wang",
                "Jin Ye",
                "Yu Qiao",
                "Junjun He"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04344v1",
                "http://arxiv.org/pdf/2312.04344v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04339v1",
            "title": "Merging by Matching Models in Task Subspaces",
            "updated": "2023-12-07T14:59:15Z",
            "published": "2023-12-07T14:59:15Z",
            "summary": "Model merging aims to cheaply combine individual task-specific models into a\nsingle multitask model. In this work, we view past merging methods as\nleveraging different notions of a ''task subspace'' in which models are matched\nbefore being merged. We connect the task subspace of a given model to its loss\nlandscape and formalize how this approach to model merging can be seen as\nsolving a linear system of equations. While past work has generally been\nlimited to linear systems that have a closed-form solution, we consider using\nthe conjugate gradient method to find a solution. We show that using the\nconjugate gradient method can outperform closed-form solutions, enables merging\nvia linear systems that are otherwise intractable to solve, and flexibly allows\nchoosing from a wide variety of initializations and estimates for the ''task\nsubspace''. We ultimately demonstrate that our merging framework called\n''Matching Models in their Task Subspace'' (MaTS) achieves state-of-the-art\nresults in multitask and intermediate-task model merging. We release all of the\ncode and checkpoints used in our work at https://github.com/r-three/mats.",
            "author": [
                "Derek Tam",
                "Mohit Bansal",
                "Colin Raffel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04339v1",
                "http://arxiv.org/pdf/2312.04339v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04338v1",
            "title": "Stochastic modelling of football matches",
            "updated": "2023-12-07T14:59:04Z",
            "published": "2023-12-07T14:59:04Z",
            "summary": "This paper develops a general framework for stochastic modeling of goals and\nother events in football (soccer) matches. The events are modelled as Cox\nprocesses (doubly stochastic Poisson processes) where the event intensities may\ndepend on all the modeled events as well as external factors. The model has a\nstrictly concave log-likelihood function which facilitates its fitting to\nobserved data. Besides event times, the model describes the random lengths of\nstoppage times which can have a strong influence on the final score of a match.\nThe model is illustrated on eight years of data from Campeonato Brasileiro de\nFutebol S\\'erie A. We find that dynamic regressors significantly improve the\nin-game predictive power of the model. In particular, a) when a team receives a\nred card, its goal intensity decreases more than 30%; b) the goal rate of a\nteam increases by 10% if it is losing by one goal and by 20% if its losing by\ntwo goals; and c) when the goal difference at the end of the second half is\nless than or equal to one, the stoppage time is on average more than one minute\nlonger than in matches with a difference of two goals.",
            "author": [
                "Luiz Fernando G. N. Maia",
                "Teemu Pennanen",
                "Moacyr A. H. B. da Silva",
                "Rodrigo S. Targino"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04338v1",
                "http://arxiv.org/pdf/2312.04338v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04337v1",
            "title": "Multi-View Unsupervised Image Generation with Cross Attention Guidance",
            "updated": "2023-12-07T14:55:13Z",
            "published": "2023-12-07T14:55:13Z",
            "summary": "The growing interest in novel view synthesis, driven by Neural Radiance Field\n(NeRF) models, is hindered by scalability issues due to their reliance on\nprecisely annotated multi-view images. Recent models address this by\nfine-tuning large text2image diffusion models on synthetic multi-view data.\nDespite robust zero-shot generalization, they may need post-processing and can\nface quality issues due to the synthetic-real domain gap. This paper introduces\na novel pipeline for unsupervised training of a pose-conditioned diffusion\nmodel on single-category datasets. With the help of pretrained self-supervised\nVision Transformers (DINOv2), we identify object poses by clustering the\ndataset through comparing visibility and locations of specific object parts.\nThe pose-conditioned diffusion model, trained on pose labels, and equipped with\ncross-frame attention at inference time ensures cross-view consistency, that is\nfurther aided by our novel hard-attention guidance. Our model, MIRAGE,\nsurpasses prior work in novel view synthesis on real images. Furthermore,\nMIRAGE is robust to diverse textures and geometries, as demonstrated with our\nexperiments on synthetic images generated with pretrained Stable Diffusion.",
            "author": [
                "Llukman Cerkezi",
                "Aram Davtyan",
                "Sepehr Sameni",
                "Paolo Favaro"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04337v1",
                "http://arxiv.org/pdf/2312.04337v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04336v1",
            "title": "An Updated Lagrangian particle hydrodynamics (ULPH) implementation of\n  heat conduction model in weakly-compressive fluid",
            "updated": "2023-12-07T14:53:58Z",
            "published": "2023-12-07T14:53:58Z",
            "summary": "Heat conduction is quite common in natural, industrial, and military\napplications. In this work, the updated Lagrangian particle hydrodynamics\n(ULPH) theory, is utilized and applied to solve heat conduction problems. Since\nheat conduction is a second-order problem, the high-order ULPH theory is\nemployed to establish the governing equations of heat conduction in ULPH, which\nis then validated using various numerical simulations. In this work, numerical\nsimulations have been carried out to solve both static heat conduction problems\nand dynamic heat convection problems. The results show good accuracy and\ncapability of the ULPH heat conduction model, suggesting promising prospects of\nthe ULPH theory in multiphysics problems. The findings of this paper suggest\nthat ULPH is effective in addressing convective heat transfer problems.",
            "author": [
                "Junsong Xiong",
                "Zhen Wang",
                "Xin Lai",
                "Lisheng Liu",
                "Xiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04336v1",
                "http://arxiv.org/pdf/2312.04336v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04333v1",
            "title": "Beyond Surface: Probing LLaMA Across Scales and Layers",
            "updated": "2023-12-07T14:50:41Z",
            "published": "2023-12-07T14:50:41Z",
            "summary": "This paper presents an in-depth analysis of Large Language Models (LLMs),\nfocusing on LLaMA, a prominent open-source foundational model in natural\nlanguage processing. Instead of assessing LLaMA through its generative output,\nwe design multiple-choice tasks to probe its intrinsic understanding in\nhigh-order tasks such as reasoning and computation. We examine the model\nhorizontally, comparing different sizes, and vertically, assessing different\nlayers. We unveil several key and uncommon findings based on the designed\nprobing tasks: (1) Horizontally, enlarging model sizes almost could not\nautomatically impart additional knowledge or computational prowess. Instead, it\ncan enhance reasoning abilities, especially in math problem solving, and helps\nreduce hallucinations, but only beyond certain size thresholds; (2) In vertical\nanalysis, the lower layers of LLaMA lack substantial arithmetic and factual\nknowledge, showcasing logical thinking, multilingual and recognitive abilities,\nwith top layers housing most computational power and real-world knowledge.",
            "author": [
                "Nuo Chen",
                "Ning Wu",
                "Shining Liang",
                "Ming Gong",
                "Linjun Shou",
                "Dongmei Zhang",
                "Jia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04333v1",
                "http://arxiv.org/pdf/2312.04333v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04327v1",
            "title": "Learning to sample in Cartesian MRI",
            "updated": "2023-12-07T14:38:07Z",
            "published": "2023-12-07T14:38:07Z",
            "summary": "Despite its exceptional soft tissue contrast, Magnetic Resonance Imaging\n(MRI) faces the challenge of long scanning times compared to other modalities\nlike X-ray radiography. Shortening scanning times is crucial in clinical\nsettings, as it increases patient comfort, decreases examination costs and\nimproves throughput. Recent advances in compressed sensing (CS) and deep\nlearning allow accelerated MRI acquisition by reconstructing high-quality\nimages from undersampled data. While reconstruction algorithms have received\nmost of the focus, designing acquisition trajectories to optimize\nreconstruction quality remains an open question. This thesis explores two\napproaches to address this gap in the context of Cartesian MRI. First, we\npropose two algorithms, lazy LBCS and stochastic LBCS, that significantly\nimprove upon G\\\"ozc\\\"u et al.'s greedy learning-based CS (LBCS) approach. These\nalgorithms scale to large, clinically relevant scenarios like multi-coil 3D MR\nand dynamic MRI, previously inaccessible to LBCS. Additionally, we demonstrate\nthat generative adversarial networks (GANs) can serve as a natural criterion\nfor adaptive sampling by leveraging variance in the measurement domain to guide\nacquisition. Second, we delve into the underlying structures or assumptions\nthat enable mask design algorithms to perform well in practice. Our experiments\nreveal that state-of-the-art deep reinforcement learning (RL) approaches, while\ncapable of adaptation and long-horizon planning, offer only marginal\nimprovements over stochastic LBCS, which is neither adaptive nor does long-term\nplanning. Altogether, our findings suggest that stochastic LBCS and similar\nmethods represent promising alternatives to deep RL. They shine in particular\nby their scalability and computational efficiency and could be key in the\ndeployment of optimized acquisition trajectories in Cartesian MRI.",
            "author": [
                "Thomas Sanchez"
            ],
            "link": [
                "http://dx.doi.org/10.5075/epfl-thesis-9981",
                "http://arxiv.org/abs/2312.04327v1",
                "http://arxiv.org/pdf/2312.04327v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04324v1",
            "title": "DiaPer: End-to-End Neural Diarization with Perceiver-Based Attractors",
            "updated": "2023-12-07T14:33:27Z",
            "published": "2023-12-07T14:33:27Z",
            "summary": "Until recently, the field of speaker diarization was dominated by cascaded\nsystems. Due to their limitations, mainly regarding overlapped speech and\ncumbersome pipelines, end-to-end models have gained great popularity lately.\nOne of the most successful models is end-to-end neural diarization with\nencoder-decoder based attractors (EEND-EDA). In this work, we replace the EDA\nmodule with a Perceiver-based one and show its advantages over EEND-EDA; namely\nobtaining better performance on the largely studied Callhome dataset, finding\nthe quantity of speakers in a conversation more accurately, and running\ninference on almost half of the time on long recordings. Furthermore, when\nexhaustively compared with other methods, our model, DiaPer, reaches remarkable\nperformance with a very lightweight design. Besides, we perform comparisons\nwith other works and a cascaded baseline across more than ten public wide-band\ndatasets. Together with this publication, we release the code of DiaPer as well\nas models trained on public and free data.",
            "author": [
                "Federico Landini",
                "Mireia Diez",
                "Themos Stafylakis",
                "Luk\u00e1\u0161 Burget"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04324v1",
                "http://arxiv.org/pdf/2312.04324v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04323v1",
            "title": "Equivariant Scalar Fields for Molecular Docking with Fast Fourier\n  Transforms",
            "updated": "2023-12-07T14:32:32Z",
            "published": "2023-12-07T14:32:32Z",
            "summary": "Molecular docking is critical to structure-based virtual screening, yet the\nthroughput of such workflows is limited by the expensive optimization of\nscoring functions involved in most docking algorithms. We explore how machine\nlearning can accelerate this process by learning a scoring function with a\nfunctional form that allows for more rapid optimization. Specifically, we\ndefine the scoring function to be the cross-correlation of multi-channel ligand\nand protein scalar fields parameterized by equivariant graph neural networks,\nenabling rapid optimization over rigid-body degrees of freedom with fast\nFourier transforms. The runtime of our approach can be amortized at several\nlevels of abstraction, and is particularly favorable for virtual screening\nsettings with a common binding pocket. We benchmark our scoring functions on\ntwo simplified docking-related tasks: decoy pose scoring and rigid conformer\ndocking. Our method attains similar but faster performance on crystal\nstructures compared to the widely-used Vina and Gnina scoring functions, and is\nmore robust on computationally predicted structures. Code is available at\nhttps://github.com/bjing2016/scalar-fields.",
            "author": [
                "Bowen Jing",
                "Tommi Jaakkola",
                "Bonnie Berger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04323v1",
                "http://arxiv.org/pdf/2312.04323v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04318v1",
            "title": "MIMo: A Multi-Modal Infant Model for Studying Cognitive Development",
            "updated": "2023-12-07T14:21:31Z",
            "published": "2023-12-07T14:21:31Z",
            "summary": "Human intelligence and human consciousness emerge gradually during the\nprocess of cognitive development. Understanding this development is an\nessential aspect of understanding the human mind and may facilitate the\nconstruction of artificial minds with similar properties. Importantly, human\ncognitive development relies on embodied interactions with the physical and\nsocial environment, which is perceived via complementary sensory modalities.\nThese interactions allow the developing mind to probe the causal structure of\nthe world. This is in stark contrast to common machine learning approaches,\ne.g., for large language models, which are merely passively ``digesting'' large\namounts of training data, but are not in control of their sensory inputs.\nHowever, computational modeling of the kind of self-determined embodied\ninteractions that lead to human intelligence and consciousness is a formidable\nchallenge. Here we present MIMo, an open-source multi-modal infant model for\nstudying early cognitive development through computer simulations. MIMo's body\nis modeled after an 18-month-old child with detailed five-fingered hands. MIMo\nperceives its surroundings via binocular vision, a vestibular system,\nproprioception, and touch perception through a full-body virtual skin, while\ntwo different actuation models allow control of his body. We describe the\ndesign and interfaces of MIMo and provide examples illustrating its use. All\ncode is available at https://github.com/trieschlab/MIMo .",
            "author": [
                "Dominik Mattern",
                "Pierre Schumacher",
                "Francisco M. L\u00f3pez",
                "Marcel C. Raabe",
                "Markus R. Ernst",
                "Arthur Aubret",
                "Jochen Triesch"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04318v1",
                "http://arxiv.org/pdf/2312.04318v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04317v1",
            "title": "Freezing-induced topological transition of double-emulsion",
            "updated": "2023-12-07T14:19:42Z",
            "published": "2023-12-07T14:19:42Z",
            "summary": "Solidification of complex liquids is pertinent to numerous natural and\nindustrial processes. Here, we examine the freezing of a W/O/W double-emulsion,\ni.e., water-in-oil compound droplets dispersed in water. We show that the\nsolidification of such hierarchical emulsions can trigger a topological\ntransition; for example, in our case, we observe the transition from the stable\nW/O/W state to a (frozen) O/W single-emulsion configuration. Strikingly, this\ntransition is characterised by sudden expulsion of the inner water drop from\nthe encapsulating oil droplet. We propose that this topological transition is\ntriggered by the freezing of the encapsulating oil droplet from the outside in,\nputting tension on the inner water drop thus, destabilizing the W/O/W\nconfiguration. Using high-speed imaging we characterize the destabilization\nprocess. Interestingly, we find that below a critical size of the inner drop,\n$R_{\\mathrm{in,crit}} \\approx 19 \\, \\mu\\mathrm{m}$, the topological transition\ndoes not occur any more and the double-emulsion remains stable, in line with\nour interpretation.",
            "author": [
                "Jochem G. Meijer",
                "Pallav Kant",
                "Detlef Lohse"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04317v1",
                "http://arxiv.org/pdf/2312.04317v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04316v1",
            "title": "Towards Knowledge-driven Autonomous Driving",
            "updated": "2023-12-07T14:17:17Z",
            "published": "2023-12-07T14:17:17Z",
            "summary": "This paper explores the emerging knowledge-driven autonomous driving\ntechnologies. Our investigation highlights the limitations of current\nautonomous driving systems, in particular their sensitivity to data bias,\ndifficulty in handling long-tail scenarios, and lack of interpretability.\nConversely, knowledge-driven methods with the abilities of cognition,\ngeneralization and life-long learning emerge as a promising way to overcome\nthese challenges. This paper delves into the essence of knowledge-driven\nautonomous driving and examines its core components: dataset \\& benchmark,\nenvironment, and driver agent. By leveraging large language models, world\nmodels, neural rendering, and other advanced artificial intelligence\ntechniques, these components collectively contribute to a more holistic,\nadaptive, and intelligent autonomous driving system. The paper systematically\norganizes and reviews previous research efforts in this area, and provides\ninsights and guidance for future research and practical applications of\nautonomous driving. We will continually share the latest updates on\ncutting-edge developments in knowledge-driven autonomous driving along with the\nrelevant valuable open-source resources at:\n\\url{https://github.com/PJLab-ADG/awesome-knowledge-driven-AD}.",
            "author": [
                "Xin Li",
                "Yeqi Bai",
                "Pinlong Cai",
                "Licheng Wen",
                "Daocheng Fu",
                "Bo Zhang",
                "Xuemeng Yang",
                "Xinyu Cai",
                "Tao Ma",
                "Jianfei Guo",
                "Xing Gao",
                "Min Dou",
                "Botian Shi",
                "Yong Liu",
                "Liang He",
                "Yu Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04316v1",
                "http://arxiv.org/pdf/2312.04316v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04314v1",
            "title": "GPT4SGG: Synthesizing Scene Graphs from Holistic and Region-specific\n  Narratives",
            "updated": "2023-12-07T14:11:00Z",
            "published": "2023-12-07T14:11:00Z",
            "summary": "Learning scene graphs from natural language descriptions has proven to be a\ncheap and promising scheme for Scene Graph Generation (SGG). However, such\nunstructured caption data and its processing are troubling the learning an\nacurrate and complete scene graph. This dilema can be summarized as three\npoints. First, traditional language parsers often fail to extract meaningful\nrelationship triplets from caption data. Second, grounding unlocalized objects\nin parsed triplets will meet ambiguity in visual-language alignment. Last,\ncaption data typically are sparse and exhibit bias to partial observations of\nimage content. These three issues make it hard for the model to generate\ncomprehensive and accurate scene graphs. To fill this gap, we propose a simple\nyet effective framework, GPT4SGG, to synthesize scene graphs from holistic and\nregion-specific narratives. The framework discards traditional language parser,\nand localize objects before obtaining relationship triplets. To obtain\nrelationship triplets, holistic and dense region-specific narratives are\ngenerated from the image. With such textual representation of image data and a\ntask-specific prompt, an LLM, particularly GPT-4, directly synthesizes a scene\ngraph as \"pseudo labels\". Experimental results showcase GPT4SGG significantly\nimproves the performance of SGG models trained on image-caption data. We\nbelieve this pioneering work can motivate further research into mining the\nvisual reasoning capabilities of LLMs.",
            "author": [
                "Zuyao Chen",
                "Jinlin Wu",
                "Zhen Lei",
                "Zhaoxiang Zhang",
                "Changwen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04314v1",
                "http://arxiv.org/pdf/2312.04314v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04311v1",
            "title": "Finding Interpretable Class-Specific Patterns through Efficient Neural\n  Search",
            "updated": "2023-12-07T14:09:18Z",
            "published": "2023-12-07T14:09:18Z",
            "summary": "Discovering patterns in data that best describe the differences between\nclasses allows to hypothesize and reason about class-specific mechanisms. In\nmolecular biology, for example, this bears promise of advancing the\nunderstanding of cellular processes differing between tissues or diseases,\nwhich could lead to novel treatments. To be useful in practice, methods that\ntackle the problem of finding such differential patterns have to be readily\ninterpretable by domain experts, and scalable to the extremely high-dimensional\ndata.\n  In this work, we propose a novel, inherently interpretable binary neural\nnetwork architecture DIFFNAPS that extracts differential patterns from data.\nDiffNaps is scalable to hundreds of thousands of features and robust to noise,\nthus overcoming the limitations of current state-of-the-art methods in\nlarge-scale applications such as in biology. We show on synthetic and real\nworld data, including three biological applications, that, unlike its\ncompetitors, DiffNaps consistently yields accurate, succinct, and interpretable\nclass descriptions",
            "author": [
                "Nils Philipp Walter",
                "Jonas Fischer",
                "Jilles Vreeken"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04311v1",
                "http://arxiv.org/pdf/2312.04311v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04310v1",
            "title": "Elastohydrodynamic interactions in soft hydraulic knots",
            "updated": "2023-12-07T14:08:45Z",
            "published": "2023-12-07T14:08:45Z",
            "summary": "Soft intertwined channel systems are frequently found in fluid flow networks\nin nature. The passage geometry of these systems can deform due to fluid flow,\nwhich can cause the relationship between flow rate and pressure drop to deviate\nfrom Hagen-Poiseuille's linear law. Although fluid-structure interactions in\nsingle deformable channels have been extensively studied, such as in Starling's\nresistor and its variations, the flow transport capacity of an intertwined\nchannel with multiple self-intersections (a \"hydraulic knot\"), is still an open\nquestion. We present experiments and theory on soft hydraulic knots formed by\ninterlinked microfluidic devices comprising two intersecting channels separated\nby a thin elastomeric membrane. Our experiments show flow-pressure\nrelationships similar to flow limitation, where the limiting flow rate depends\non the knot configuration. To explain our observations, we develop a\nmathematical model based on lubrication theory coupled with tension-dominated\nmembrane deflections that compares favorably to our experimental data. Finally,\nwe present two potential hydraulic knot applications for microfluidic flow\nrectification and attenuation.",
            "author": [
                "Magnus V. Paludan",
                "Benjamin Dollet",
                "Philippe Marmottant",
                "Kaare H. Jensen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04310v1",
                "http://arxiv.org/pdf/2312.04310v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04306v1",
            "title": "nerblackbox: A High-level Library for Named Entity Recognition in Python",
            "updated": "2023-12-07T14:04:15Z",
            "published": "2023-12-07T14:04:15Z",
            "summary": "We present nerblackbox, a python library to facilitate the use of\nstate-of-the-art transformer-based models for named entity recognition. It\nprovides simple-to-use yet powerful methods to access data and models from a\nwide range of sources, for fully automated model training and evaluation as\nwell as versatile model inference. While many technical challenges are solved\nand hidden from the user by default, nerblackbox also offers fine-grained\ncontrol and a rich set of customizable features. It is thus targeted both at\napplication-oriented developers as well as machine learning experts and\nresearchers.",
            "author": [
                "Felix Stollenwerk"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04306v1",
                "http://arxiv.org/pdf/2312.04306v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04304v1",
            "title": "Pair correlations of the hybridized orbitals in a ladder model for the\n  bilayer nickelate La$_3$Ni$_2$O$_7$",
            "updated": "2023-12-07T13:53:37Z",
            "published": "2023-12-07T13:53:37Z",
            "summary": "To clarify the nature of high-temperature superconductivity in the bilayer\nnickelate La$_3$Ni$_2$O$_7$ under pressure, we investigate, using the\ndensity-matrix renormalization group method, the pair correlations in the\ntwo-orbital $t$-$J$ ladder model. While the interchain-intraorbital pair\ncorrelations exhibit a slow power-law decay in both orbitals, the interorbital\npair correlation also develops due to the hybridization via interorbital\nhopping. These intra and interorbital pair correlations are enhanced by Hund's\ncoupling, but more importantly, the interorbital pairing correlation develops\neven without Hund's coupling, where apparent interorbital pairing glue is\nabsent. Our finding suggests that the hybridized two-orbital picture precisely\ndescribes superconductivity in the bilayer nickelate.",
            "author": [
                "Masataka Kakoi",
                "Tatsuya Kaneko",
                "Hirofumi Sakakibara",
                "Masayuki Ochi",
                "Kazuhiko Kuroki"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04304v1",
                "http://arxiv.org/pdf/2312.04304v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04302v1",
            "title": "Prompt Highlighter: Interactive Control for Multi-Modal LLMs",
            "updated": "2023-12-07T13:53:29Z",
            "published": "2023-12-07T13:53:29Z",
            "summary": "This study targets a critical aspect of multi-modal LLMs' (LLMs&VLMs)\ninference: explicit controllable text generation. Multi-modal LLMs empower\nmulti-modality understanding with the capability of semantic generation yet\nbring less explainability and heavier reliance on prompt contents due to their\nautoregressive generative nature. While manipulating prompt formats could\nimprove outputs, designing specific and precise prompts per task can be\nchallenging and ineffective. To tackle this issue, we introduce a novel\ninference method, Prompt Highlighter, which enables users to highlight specific\nprompt spans to interactively control the focus during generation. Motivated by\nthe classifier-free diffusion guidance, we form regular and unconditional\ncontext pairs based on highlighted tokens, demonstrating that the\nautoregressive generation in models can be guided in a classifier-free way.\nNotably, we find that, during inference, guiding the models with highlighted\ntokens through the attention weights leads to more desired outputs. Our\napproach is compatible with current LLMs and VLMs, achieving impressive\ncustomized generation results without training. Experiments confirm its\neffectiveness in focusing on input contexts and generating reliable content.\nWithout tuning on LLaVA-v1.5, our method secured 69.5 in the MMBench test and\n1552.5 in MME-perception. The code is available at:\nhttps://github.com/dvlab-research/Prompt-Highlighter/",
            "author": [
                "Yuechen Zhang",
                "Shengju Qian",
                "Bohao Peng",
                "Shu Liu",
                "Jiaya Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04302v1",
                "http://arxiv.org/pdf/2312.04302v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04298v1",
            "title": "Coherent state switching using vibrational polaritons in an asymmetric\n  double-well potential",
            "updated": "2023-12-07T13:41:00Z",
            "published": "2023-12-07T13:41:00Z",
            "summary": "The quantum dynamics of vibrational polaritonic states arising from the\ninteraction of a bistable molecule with the quantized mode of a Fabry-Perot\nmicrocavity is investigated using an asymmetric double-well potential as a\nsimplified one-dimensional model of a reactive molecule. After discussing the\nrole of the light-matter coupling strength in the emergence of avoided\ncrossings between polaritonic states, we investigate the possibility of using\nthese crossings in order to trigger a dynamical switching of these states from\none potential well to the other. Two schemes are proposed to achieve this\ncoherent state switching, either by preparing the molecule in an appropriate\nvibrational excited state before inserting it into the cavity, or by applying a\nshort laser pulse inside the cavity to obtain a coherent superposition of\npolaritonic states. The respective influences of the dipole amplitude and\npotential asymmetry on the coherent switching process are also discussed.",
            "author": [
                "Lo\u00efse Attal",
                "Florent Calvo",
                "Cyril Falvo",
                "Pascal Parneix"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04298v1",
                "http://arxiv.org/pdf/2312.04298v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04297v1",
            "title": "Non-commutative probability insights into the double-scaling limit SYK\n  Model with constant perturbations: moments, cumulants, and $q$-independence",
            "updated": "2023-12-07T13:40:45Z",
            "published": "2023-12-07T13:40:45Z",
            "summary": "Extending the results of \\cite{Wu}, we study the double-scaling limit SYK\n(DSSYK) model with an additional diagonal matrix with a fixed number $c$ of\nnonzero constant entries $\\theta$. This constant diagonal term can be rewritten\nin terms of Majorana fermion products. Its specific formula depends on the\nvalue of $c$. We find exact expressions for the moments of this model. More\nimportantly, by proposing a moment-cumulant relation, we reinterpret the effect\nof introducing a constant term in the context of non-commutative probability\ntheory. This gives rise to a $\\tilde{q}$ dependent mixture of independences\nwithin the moment formula. The parameter $\\tilde{q}$, derived from the\nq-Ornstein-Uhlenbeck (q-OU) process, controls this transformation. It\ninterpolates between classical independence ($\\tilde{q}=1$) and Boolean\nindependence ($\\tilde{q}=0$). The underlying combinatorial structures of this\nmodel provide the non-commutative probability connections. Additionally, we\nexplore the potential relation between these connections and their\ngravitational path integral counterparts.",
            "author": [
                "Shuang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04297v1",
                "http://arxiv.org/pdf/2312.04297v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "hep-th",
                "math.CO",
                "math.MP",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04294v1",
            "title": "Energy-Efficient Internet of Things Monitoring with Content-Based\n  Wake-Up Radio",
            "updated": "2023-12-07T13:32:27Z",
            "published": "2023-12-07T13:32:27Z",
            "summary": "The use of Wake-Up Radio (WUR) in Internet of Things (IoT) networks can\nsignificantly improve their energy efficiency: battery-powered sensors can\nremain in a low-power (sleep) mode while listening for wake-up messages using\ntheir WUR and reactivate only when polled. However, polling-based WUR may still\nlead to wasted energy if values sensed by the polled sensors provide no new\ninformation to the receiver, or in general have a low Value of Information\n(VoI). In this paper, we design a content-based WUR that tracks the process\nobserved by the sensors and only wakes up the sensor if its estimated update's\nVoI is higher than a threshold communicated through the poll. If the sensor\ndoes not reply to the polling request, the Gateway (GW) can make a Bayesian\nupdate, knowing that either the sensor value substantially confirms its current\nestimate or the transmission failed due to the wireless channel. We analyze the\ntrade-off between the tracking error and the battery lifetime of the sensors,\nshowing that content-based WUR can provide fine-grained control of this\ntrade-off and significantly increase the battery lifetime of the node with a\nminimal Mean Squared Error (MSE) increase.",
            "author": [
                "Anay Ajit Deshpande",
                "Federico Chiariotti",
                "Andrea Zanella"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04294v1",
                "http://arxiv.org/pdf/2312.04294v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04290v1",
            "title": "Convergence Analysis of Opto-Electronic Oscillator based Coherent Ising\n  Machines",
            "updated": "2023-12-07T13:18:13Z",
            "published": "2023-12-07T13:18:13Z",
            "summary": "Ising machines are purported to be better at solving large-scale\ncombinatorial optimisation problems better than conventional von Neumann\ncomputers. However, these Ising machines are widely believed to be heuristics,\nwhose promise is observed empirically rather than obtained theoretically. We\nbridge this gap by considering an opto-electronic oscillator based coherent\nIsing machine, and providing the first analytical proof that under reasonable\nassumptions, the OEO-CIM is not a heuristic approach. We find and prove bounds\non its performance in terms of the expected difference between the objective\nvalue at the final iteration and the optimal one, and on the number of\niterations required by it. In the process, we emphasise on some of its\nlimitations such as the inability to handle asymmetric coupling between spins,\nand the absence of external magnetic field applied on them (both of which are\nnecessary in many optimisation problems), along with some issues in its\nconvergence. We overcome these limitations by proposing suitable adjustments\nand prove that the improved architecture is guaranteed to converge to the\noptimum of the relaxed objective function.",
            "author": [
                "Sayantan Pramanik",
                "Sourav Chatterjee",
                "Harshkumar Oza"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04290v1",
                "http://arxiv.org/pdf/2312.04290v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04283v1",
            "title": "A sufficient condition for superstatistics in steady state ensembles",
            "updated": "2023-12-07T13:07:15Z",
            "published": "2023-12-07T13:07:15Z",
            "summary": "In recent years, the theory of superstatistics, which aims to describe\nnon-equilibrium steady state systems, has gained attention due to its different\nreal world applications, highlighting its versatility and concise mathematical\nformulation in terms of a probability density for the inverse temperature\n$\\beta=1/k_{B}T$. When exploring the domain of application of the\nsuperstatistical theory, recent works have shown some necessary conditions for\na superstatistical description of a given steady state, in terms of the\nfundamental and microcanonical inverse temperature. In this work, a new theorem\nthat establishes a sufficient condition for the existence of a superstatistical\ndescription of a particular steady state is presented, using the language of\nmoment-generating functions and connecting them with properties of the\nderivatives of the fundamental inverse temperature.",
            "author": [
                "Constanza Far\u00edas",
                "Sergio Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04283v1",
                "http://arxiv.org/pdf/2312.04283v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04282v1",
            "title": "Adaptive Recursive Query Optimization",
            "updated": "2023-12-07T13:06:27Z",
            "published": "2023-12-07T13:06:27Z",
            "summary": "Performance-critical industrial applications, including large-scale program,\nnetwork, and distributed system analyses, are increasingly reliant on recursive\nqueries for data analysis. Yet traditional relational algebra-based query\noptimization techniques do not scale well to recursive query processing due to\nthe iterative nature of query evaluation, where relation cardinalities can\nchange unpredictably during the course of a single query execution. To avoid\nerror-prone cardinality estimation, adaptive query processing techniques use\nruntime information to inform query optimization, but these systems are not\noptimized for the specific needs of recursive query processing. In this paper,\nwe introduce Adaptive Metaprogramming, an innovative technique that shifts\nrecursive query optimization and code generation from compile-time to runtime\nusing principled metaprogramming, enabling dynamic optimization and\nre-optimization before and after query execution has begun. We present a custom\njoin-ordering optimization applicable at multiple stages during query\ncompilation and execution. Through Carac, we evaluate the optimization\npotential of Adaptive Metaprogramming and show unoptimized recursive query\nexecution time can be improved by three orders of magnitude and hand-optimized\nqueries by 4x.",
            "author": [
                "Anna Herlihy",
                "Guillaume Martres",
                "Anastasia Ailamaki",
                "Martin Odersky"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04282v1",
                "http://arxiv.org/pdf/2312.04282v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04272v1",
            "title": "Direct data-driven control of input saturated systems: a LMI-based\n  approach",
            "updated": "2023-12-07T12:52:57Z",
            "published": "2023-12-07T12:52:57Z",
            "summary": "In this paper, we revisit three intricate control challenges in the context\nof input-saturated systems, adopting a direct data-driven perspective.\nDiverging from the traditional two-stage process involving system\nidentification and model-based control, our approach dispenses with the need\nfor an explicit model description. By harnessing a combination of data-based\nclosed-loop representation, Lyapunov theory, instrumental variables, and a\ngeneralized sector condition, we formulate data-driven linear matrix\ninequalities (LMIs). These LMIs are employed to maximize the basin of\nattraction, minimize the closed-loop reachable set with bounded disturbances,\nand propose a new data-driven $\\ell_2$-gain minimization. Through\ndemonstrations on benchmark examples, we shed light on the merits and\nlimitations of transitioning from indirect to direct design strategies for\ninput-saturated plants, emphasizing notable advantages in handling nonlinear\ndynamics.",
            "author": [
                "Federico Porcari",
                "Valentina Breschi",
                "Luca Zaccarian",
                "Simone Formentin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04272v1",
                "http://arxiv.org/pdf/2312.04272v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04270v1",
            "title": "Stability of buoyant-Couette flow in a vertical porous slot",
            "updated": "2023-12-07T12:51:40Z",
            "published": "2023-12-07T12:51:40Z",
            "summary": "The stability of two-dimensional buoyancy-driven convection in a vertical\nporous slot, wherein a plane Couette flow is additionally present, is studied.\nThis complex fluid flow scenario is examined under the influence of Robin-type\nboundary conditions, which are applied to perturbations in both velocity and\ntemperature. The inclusion of a time-derivative velocity term within the Darcy\nmomentum equation notably introduces intricacies to the study. The stability of\nthe basic natural convection flow is primarily governed by several key\nparameters namely, the P\\'eclet number, the Prandtl-Darcy number, the Biot\nnumber and a non-negative parameter that dictates the nature of the vertical\nboundaries. Through numerical analysis, the stability eigenvalue problem is\nsolved for a variety of combinations of boundary conditions. The outcomes of\nthis analysis reveal the critical threshold values that signify the onset of\ninstability. Furthermore, a detailed examination of the stability of the system\nhas provided insights into both its commonalities and distinctions under\ndifferent conditions. It is observed that, except for the scenario featuring\nimpermeable-isothermal boundaries, the underlying base flow exhibits\ninstability when subjected to various other configurations of perturbed\nvelocity and temperature boundary conditions. This underscores the notion that\nthe presence of Couette flow alone does not suffice to induce instability\nwithin the system. The plots depicting neutral stability curves show either\nbi-modal or uni-modal characteristics, contingent upon specific parameter\nvalues that influence the onset of instability.",
            "author": [
                "B. M. Shankar",
                "I. S. Shivakumara"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04270v1",
                "http://arxiv.org/pdf/2312.04270v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04268v1",
            "title": "Gate-controlled supercurrent effect in dry-etched Dayem bridges of\n  non-centrosymmetric niobium rhenium",
            "updated": "2023-12-07T12:50:08Z",
            "published": "2023-12-07T12:50:08Z",
            "summary": "The application of a gate voltage to control the superconducting current\nflowing through a nanoscale superconducting constriction, named as\ngate-controlled supercurrent (GCS), has raised great interest for fundamental\nand technological reasons. To gain a deeper understanding of this effect and\ndevelop superconducting technologies based on it, the material and physical\nparameters crucial for GCS must be identified. Top-down fabrication protocols\nshould be also optimized to increase device scalability, although studies\nsuggest that top-down fabricated devices are more resilient to show GCS. Here,\nwe investigate gated superconducting nanobridges made with a top-down\nfabrication process from thin films of the non-centrosymmetric superconductor\nNbRe. Unlike other devices previously reported, our NbRe devices systematically\nexhibit GCS, when made in specific conditions, which paves the way for higher\ndevice scalability. Our results also suggest that surface properties of NbRe\nnanobridges and their modification during fabrication are key for GCS.",
            "author": [
                "Jennifer Koch",
                "Carla Cirillo",
                "Sebastiano Battisti",
                "Leon Ruf",
                "Zahra Makhdoumi Kakhaki",
                "Alessandro Paghi",
                "Armen Gulian",
                "Serafim Teknowijoyo",
                "Giorgio De Simoni",
                "Francesco Giazotto",
                "Carmine Attanasio",
                "Elke Scheer",
                "Angelo Di Bernardo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04268v1",
                "http://arxiv.org/pdf/2312.04268v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04265v1",
            "title": "Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for\n  Domain Generalized Semantic Segmentation",
            "updated": "2023-12-07T12:43:00Z",
            "published": "2023-12-07T12:43:00Z",
            "summary": "In this paper, we first assess and harness various Vision Foundation Models\n(VFMs) in the context of Domain Generalized Semantic Segmentation (DGSS).\nDriven by the motivation that Leveraging Stronger pre-trained models and Fewer\ntrainable parameters for Superior generalizability, we introduce a robust\nfine-tuning approach, namely Rein, to parameter-efficiently harness VFMs for\nDGSS. Built upon a set of trainable tokens, each linked to distinct instances,\nRein precisely refines and forwards the feature maps from each layer to the\nnext layer within the backbone. This process produces diverse refinements for\ndifferent categories within a single image. With fewer trainable parameters,\nRein efficiently fine-tunes VFMs for DGSS tasks, surprisingly surpassing full\nparameter fine-tuning. Extensive experiments across various settings\ndemonstrate that Rein significantly outperforms state-of-the-art methods.\nRemarkably, with just an extra 1% of trainable parameters within the frozen\nbackbone, Rein achieves a mIoU of 68.1% on the Cityscapes, without accessing\nany real urban-scene datasets.",
            "author": [
                "Zhixiang Wei",
                "Lin Chen",
                "Yi Jin",
                "Xiaoxiao Ma",
                "Tianle Liu",
                "Pengyang Lin",
                "Ben Wang",
                "Huaian Chen",
                "Jinjin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04265v1",
                "http://arxiv.org/pdf/2312.04265v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04262v1",
            "title": "PsyChat: A Client-Centric Dialogue System for Mental Health Support",
            "updated": "2023-12-07T12:40:00Z",
            "published": "2023-12-07T12:40:00Z",
            "summary": "Dialogue systems are increasingly integrated into mental health support to\nhelp clients facilitate exploration, gain insight, take action, and ultimately\nheal themselves. For a dialogue system to be practical and user-friendly, it\nshould be client-centric, focusing on the client's behaviors. However, existing\ndialogue systems publicly available for mental health support often concentrate\nsolely on the counselor's strategies rather than the behaviors expressed by\nclients. This can lead to the implementation of unreasonable or inappropriate\ncounseling strategies and corresponding responses from the dialogue system. To\naddress this issue, we propose PsyChat, a client-centric dialogue system that\nprovides psychological support through online chat. The client-centric dialogue\nsystem comprises five modules: client behavior recognition, counselor strategy\nselection, input packer, response generator intentionally fine-tuned to produce\nresponses, and response selection. Both automatic and human evaluations\ndemonstrate the effectiveness and practicality of our proposed dialogue system\nfor real-life mental health support. Furthermore, we employ our proposed\ndialogue system to simulate a real-world client-virtual-counselor interaction\nscenario. The system is capable of predicting the client's behaviors, selecting\nappropriate counselor strategies, and generating accurate and suitable\nresponses, as demonstrated in the scenario.",
            "author": [
                "Huachuan Qiu",
                "Anqi Li",
                "Lizhi Ma",
                "Zhenzhong Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04262v1",
                "http://arxiv.org/pdf/2312.04262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04260v1",
            "title": "Varying Constants and the Brans-Dicke theory: a new landscape in\n  cosmological energy conservation",
            "updated": "2023-12-07T12:37:49Z",
            "published": "2023-12-07T12:37:49Z",
            "summary": "We develop the Brans-Dicke theory of gravity in the context of varying\nconstants of Nature. Using the unimodular formalism of General Relativity, we\ncreate a platform to provide physical relational times giving the evolution of\nphysical constants. We therefore review the ideas and experiments behind\nvarying constants, mostly focusing on the speed of light and the gravitational\nconstant. Then, we apply this idea to the energy conservation in cosmology,\nillustrating the arising patterns. Motivated by a varying gravitational\nconstant resulting from Mach's principle, we develop the unimodular formalism\nof varying constants in the Brans-Dicke theory. Doing so, we obtain several\noriginal results, some of which can be compared with phenomenological\nobservation. Finally, we suggest how a varying Brans-Dicke parameter could be\nlinked to the Cosmological Constant problem.",
            "author": [
                "Paolo Massimo Bassani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04260v1",
                "http://arxiv.org/pdf/2312.04260v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04257v1",
            "title": "Proxima: Near-storage Acceleration for Graph-based Approximate Nearest\n  Neighbor Search in 3D NAND",
            "updated": "2023-12-07T12:32:18Z",
            "published": "2023-12-07T12:32:18Z",
            "summary": "Approximate nearest neighbor search (ANNS) plays an indispensable role in a\nwide variety of applications, including recommendation systems, information\nretrieval, and semantic search. Among the cutting-edge ANNS algorithms,\ngraph-based approaches provide superior accuracy and scalability on massive\ndatasets. However, the best-performing graph-based ANN search solutions incur\ntens of hundreds of memory footprints as well as costly distance computation,\nthus hindering their efficient deployment at scale. The 3D NAND flash is\nemerging as a promising device for data-intensive applications due to its high\ndensity and nonvolatility. In this work, we present the near-storage processing\n(NSP)-based ANNS solution Proxima, to accelerate graph-based ANNS with\nalgorithm-hardware co-design in 3D NAND flash. Proxima significantly reduces\nthe complexity of graph search by leveraging the distance approximation and\nearly termination. On top of the algorithmic enhancement, we implement Proxima\nsearch algorithm in 3D NAND flash using the heterogeneous integration\ntechnique. To maximize 3D NAND's bandwidth utilization, we present customized\ndataflow and optimized data allocation scheme. Our evaluation results show\nthat: compared to graph ANNS on CPU and GPU, Proxima achieves a magnitude\nimprovement in throughput or energy efficiency. Proxima yields 7x to 13x\nspeedup over existing ASIC designs. Furthermore, Proxima achieves a good\nbalance between accuracy, efficiency and storage density compared to previous\nNSP-based accelerators.",
            "author": [
                "Weihong Xu",
                "Junwei Chen",
                "Po-Kai Hsu",
                "Jaeyoung Kang",
                "Minxuan Zhou",
                "Sumukh Pinge",
                "Shimeng Yu",
                "Tajana Rosing"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04257v1",
                "http://arxiv.org/pdf/2312.04257v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04254v1",
            "title": "Diffusion-Dependent Pattern Formation on Crystal Surfaces",
            "updated": "2023-12-07T12:26:48Z",
            "published": "2023-12-07T12:26:48Z",
            "summary": "The growth of a crystal is usually determined by its surface. Many factors\ninfluence the growth dynamics. Energy barriers associated with the presence of\nsteps most often decide about the emerging pattern. The height and type of\nEhrlich-Schwoebel step barriers lead to the growth of nanocolumns, nanowires,\npyramids, and bunches or meanders in the same system. Surface diffusion is\nanother factor that determines the nature of growth. We used the (2+1)D\ncellular automaton model to investigate the additional effect of diffusion\nalong with step barriers. We show that when we only change the diffusion rate,\nthe length of the meanders or the height of the bunches increase, while the\ncracked structure of the nanopillars changes into very long, tall nanowires. We\nshow that the length of the step-step correlation is a good characterization of\nthe resulting patterns.",
            "author": [
                "Marta Anna Chabowska",
                "Magdalena A. Za\u0142uska-Kotur"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acsomega.3c06377",
                "http://arxiv.org/abs/2312.04254v1",
                "http://arxiv.org/pdf/2312.04254v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04252v1",
            "title": "A Mott-Schottky Analysis of Mesoporous Silicon in Aqueous Electrolyte by\n  Electrochemical Impedance Spectroscopy",
            "updated": "2023-12-07T12:22:21Z",
            "published": "2023-12-07T12:22:21Z",
            "summary": "Nanoporosity in silicon leads to completely new functionalities of this\nmainstream semiconductor. In recent years, it has been shown that filling the\npores with aqueous electrolytes in addition opens a particularly wide field for\nmodifying and achieving active control of these functionalities, e.g., for\nelectrochemo-mechanical actuation and tunable photonics, or for the design of\non-chip supercapacitors. However, a mechanistic understanding of these new\nfeatures has been hampered by the lack of a detailed characterization of the\nelectrochemical behavior of mesoporous silicon in aqueous electrolytes. Here,\nthe capacitive, potential-controlled charging of the electrical double layer in\na mesoporous silicon electrode (pore diameter $7\\,\\mathrm{nm}$) imbibed with\nperchloric acid solution is studied by electrochemical impedance spectroscopy.\nThorough measurements with detailed explanations of the observed phenomena lead\nto a comprehensive understanding of the capacitive properties of porous\nsilicon. An analysis based on the Mott-Schottky equation allows general\nconclusions to be drawn about the state of the band structure within the pore\nwalls. Essential parameters such as the flat band potential, the doping density\nand the width of the space charge region can be determined. A comparison with\nbulk silicon shows that the flat band potential in particular is significantly\naltered by the introduction of nanopores, as it shifts from\n$1.4\\pm0.1\\,\\mathrm{V}$ to $1.9\\pm0.2\\,\\mathrm{V}$. Overall, this study\nprovides a unique insight into the electrochemical processes, especially the\nelectrical double layer charging, of nanoporous semiconductor electrodes.",
            "author": [
                "Manuel Brinker",
                "Patrick Huber"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04252v1",
                "http://arxiv.org/pdf/2312.04252v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "cond-mat.soft",
                "physics.app-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04249v1",
            "title": "Extending Answer Set Programming with Rational Numbers",
            "updated": "2023-12-07T12:11:25Z",
            "published": "2023-12-07T12:11:25Z",
            "summary": "Answer Set Programming (ASP) is a widely used declarative programming\nparadigm that has shown great potential in solving complex computational\nproblems. However, the inability to natively support non-integer arithmetic has\nbeen highlighted as a major drawback in real-world applications. This feature\nis crucial to accurately model and manage real-world data and information as\nemerged in various contexts, such as the smooth movement of video game\ncharacters, the 3D movement of mechanical arms, and data streamed by sensors.\nNevertheless, extending ASP in this direction, without affecting its\ndeclarative nature and its well-defined semantics, poses non-trivial\nchallenges; thus, no ASP system is able to reason natively with non-integer\ndomains. Indeed, the widespread floating-point arithmetic is not applicable to\nthe ASP case, as the reproducibility of results cannot be guaranteed and the\nsemantics of an ASP program would not be uniquely and declaratively determined,\nregardless of the employed machine or solver. To overcome such limitations and\nin the realm of pure ASP, this paper proposes an extension of ASP in which\nnon-integers are approximated to rational numbers, fully granting\nreproducibility and declarativity. We provide a well-defined semantics for the\nASP-Core-2 standard extended with rational numbers and an implementation\nthereof. We hope this work could serve as a stepping stone towards a more\nexpressive and versatile ASP language that can handle a broader range of\nreal-world problems.",
            "author": [
                "Francesco Pacenza",
                "Jessica Zangari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04249v1",
                "http://arxiv.org/pdf/2312.04249v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "cs.PL",
                "cs.SE",
                "D.1.6; D.3.1; D.3.3; I.2.4; I.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04245v1",
            "title": "Mastering Complex Coordination through Attention-based Dynamic Graph",
            "updated": "2023-12-07T12:02:14Z",
            "published": "2023-12-07T12:02:14Z",
            "summary": "The coordination between agents in multi-agent systems has become a popular\ntopic in many fields. To catch the inner relationship between agents, the graph\nstructure is combined with existing methods and improves the results. But in\nlarge-scale tasks with numerous agents, an overly complex graph would lead to a\nboost in computational cost and a decline in performance. Here we present\nDAGMIX, a novel graph-based value factorization method. Instead of a complete\ngraph, DAGMIX generates a dynamic graph at each time step during training, on\nwhich it realizes a more interpretable and effective combining process through\nthe attention mechanism. Experiments show that DAGMIX significantly outperforms\nprevious SOTA methods in large-scale scenarios, as well as achieving promising\nresults on other tasks.",
            "author": [
                "Guangchong Zhou",
                "Zhiwei Xu",
                "Zeren Zhang",
                "Guoliang Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04245v1",
                "http://arxiv.org/pdf/2312.04245v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04240v1",
            "title": "General teleportation channel in Fermionic Quantum Theory",
            "updated": "2023-12-07T11:52:45Z",
            "published": "2023-12-07T11:52:45Z",
            "summary": "Quantum Teleportation is a very useful scheme for transferring quantum\ninformation. Given that the quantum information is encoded in a state of a\nsystem of distinguishable particles, and given that the shared bi-partite\nentangled state is also that of a system of distinguishable particles, the\noptimal teleportation fidelity of the shared state is known to be\n$(F_{max}d+1)/(d+1)$ with $F_{max}$ being the `maximal singlet fraction' of the\nshared state. In the present work, we address the question of optimal\nteleportation fidelity given that the quantum information to be teleported is\nencoded in Fermionic modes while a $2N$-mode state of a system of Fermions\n(with maximum $2N$ no. of Fermions -- in the second quantization language) is\nshared between the sender and receiver with each party possessing $N$ modes of\nthe $2N$-mode state. Parity Superselection Rule (PSSR) in Fermionic Quantum\nTheory (FQT) puts constraint on the allowed set of physical states and\noperations, and thereby, leads to a different notion of Quantum Teleportation.\nDue to PSSR, we introduce restricted Clifford twirl operations that constitute\nthe Unitary 2-design in case of FQT, and show that the structure of the\ncanonical form of Fermionic invariant shared state differs from that of the\nisotropic state -- the corresponding canonical invariant form for teleportation\nin Standard Quantum Theory (SQT). We provide a lower bound on the optimal\nteleportation fidelity in FQT and compare the result with teleportation in SQT.\nSurprisingly, we find that, under separable measurements on a bipartite\nFermionic state, input and output states of the Fermionic teleportation channel\ncannot be distinguished operationally, even if a particular kind of resource\nstate with `maximal singlet fraction' being less than unity is used.",
            "author": [
                "Sanam Khan",
                "R. Jehadeesan",
                "Sibasish Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04240v1",
                "http://arxiv.org/pdf/2312.04240v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04239v1",
            "title": "A perturbative construction of primitive forms from log Landau-Ginzburg\n  mirrors of toric manifolds",
            "updated": "2023-12-07T11:52:07Z",
            "published": "2023-12-07T11:52:07Z",
            "summary": "We introduce the notion of a logarithmic Landau-Ginzburg (log LG) model,\nwhich is essentially given by equipping the central degenerate fiber of the\nfamily of Landau-Ginzburg (LG) models mirror to a projective toric manifold\nwith a natural log structure. We show that the state space of the mirror log LG\nmodel is naturally isomorphic to that of the original toric manifold. Following\nLi-Li-Saito, we give a perturbative construction of primitive forms by studying\nthe deformation theory of such a log LG model, which involves both smoothing of\nthe central degenerate fiber and unfolding of the superpotential. This yields a\nlogarithmic Frobenius manifold structure on the base space of the universal\nunfolding. The primitive forms and flat coordinates we obtained are computable\nand closely related to the bulk-deformed Lagrangian Floer superpotential of a\nprojective toric manifold, at least in the semi-Fano case.",
            "author": [
                "Kwokwai Chan",
                "Ziming Nikolas Ma",
                "Hao Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04239v1",
                "http://arxiv.org/pdf/2312.04239v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04237v1",
            "title": "A coherent radio flash following a neutron star merger",
            "updated": "2023-12-07T11:50:01Z",
            "published": "2023-12-07T11:50:01Z",
            "summary": "The mergers of two neutron stars are exceptional multi-messenger events that\nenable us to probe fundamental physics in one of the most extreme environments\nin the Universe. Multi-wavelength follow-up observations are essential in order\nto probe the physics of the outflows from and remnants of these neutron star\nmergers, both when detected as short gamma-ray bursts (GRBs) and as\ngravitational wave events. Rapid follow-up can provide localisations for\ntargeted deep follow-up observations and, ideally, a distance measurement,\nwhich constrains for instance the energetics of the merger. A key outstanding\nquestion is the remnant's nature: with its expected mass and rapid spin, it\ncould either be a black hole or a supramassive, likely highly magnetised\nneutron star (a magnetar). Both can power a GRB, but rapidly spinning magnetars\nare additionally predicted to emit coherent radio bursts following their\nformation and may constitute a small fraction of the progenitors of fast radio\nbursts. Black holes, by contrast, are not expected to emit coherent radio\nbursts in the time following the GRB itself. Here we present rapid follow-up\nobservations of the short GRB 201006A using LOFAR. We have detected a\n5.6$\\sigma$, short, coherent radio flash at 144 MHz at 76.6 mins post-burst.\nThis radio flash is 27 arcsec offset from the GRB location, which has a\nprobability of occurring by chance of $\\sim$0.5% (2.6$\\sigma$) when accounting\nfor measurement uncertainties. Despite the offset, we show that the probability\nof finding an unrelated transient within 40 arcsec of the GRB location is\n$<10^{-6}$ and conclude that this is likely to be the radio counterpart to GRB\n201006A. The radio flash is tentatively (2.5$\\sigma$) shown to be highly\ndispersed, allowing a distance estimate, corresponding to a redshift of\n$0.58\\pm0.06$, that is in the range of typical short GRB distances. Using the\nestimated distance, the...",
            "author": [
                "A. Rowlinson",
                "I. de Ruiter",
                "R. L. C. Starling",
                "K. M. Rajwade",
                "A. Hennessy",
                "R. A. M. J. Wijers",
                "G. E. Anderson",
                "M. Mevius",
                "D. Ruhe",
                "K. Gourdji",
                "A. J. van der Horst",
                "S. ter Veen",
                "K. Wiersema"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04237v1",
                "http://arxiv.org/pdf/2312.04237v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04234v1",
            "title": "Graph Convolutions Enrich the Self-Attention in Transformers!",
            "updated": "2023-12-07T11:40:32Z",
            "published": "2023-12-07T11:40:32Z",
            "summary": "Transformers, renowned for their self-attention mechanism, have achieved\nstate-of-the-art performance across various tasks in natural language\nprocessing, computer vision, time-series modeling, etc. However, one of the\nchallenges with deep Transformer models is the oversmoothing problem, where\nrepresentations across layers converge to indistinguishable values, leading to\nsignificant performance degradation. We interpret the original self-attention\nas a simple graph filter and redesign it from a graph signal processing (GSP)\nperspective. We propose graph-filter-based self-attention (GFSA) to learn a\ngeneral yet effective one, whose complexity, however, is slightly larger than\nthat of the original self-attention mechanism. We demonstrate that GFSA\nimproves the performance of Transformers in various fields, including computer\nvision, natural language processing, graph pattern classification, speech\nrecognition, and code classification.",
            "author": [
                "Jeongwhan Choi",
                "Hyowon Wi",
                "Jayoung Kim",
                "Yehjin Shin",
                "Kookjin Lee",
                "Nathaniel Trask",
                "Noseong Park"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04234v1",
                "http://arxiv.org/pdf/2312.04234v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04232v1",
            "title": "Emergent Error Correcting States in Networks of Nonlinear Oscillators",
            "updated": "2023-12-07T11:31:24Z",
            "published": "2023-12-07T11:31:24Z",
            "summary": "Networks of nonlinear oscillators can exhibit complex collective behaviour\nranging from synchronised states to chaos. Here, we simulate the dynamics of\nthree coupled Duffing oscillators whose multiple equilibrium states can be used\nfor information processing and storage. Our analysis reveals that even for this\nsmall network, there is the emergence of an error correcting phase where the\nsystem autonomously corrects errors from random impulses. The system has\nseveral surprising and attractive features, including dynamic isolation of\nresonators exposed to extreme impulses and the ability to correct simultaneous\nerrors. The existence of an error correcting phase opens the prospect of\nfault-tolerant information storage, with particular applications in\nnanomechanical computing.",
            "author": [
                "Xiaoya Jin",
                "Christopher G. Baker",
                "Erick Romero",
                "Nicholas P. Mauranyapin",
                "Timothy M. F. Hirsch",
                "Warwick P. Bowen",
                "Glen I. Harris"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04232v1",
                "http://arxiv.org/pdf/2312.04232v1"
            ],
            "primary_category": "physics.class-ph",
            "category": [
                "physics.class-ph",
                "cond-mat.dis-nn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04231v1",
            "title": "Adventures of Trustworthy Vision-Language Models: A Survey",
            "updated": "2023-12-07T11:31:20Z",
            "published": "2023-12-07T11:31:20Z",
            "summary": "Recently, transformers have become incredibly popular in computer vision and\nvision-language tasks. This notable rise in their usage can be primarily\nattributed to the capabilities offered by attention mechanisms and the\noutstanding ability of transformers to adapt and apply themselves to a variety\nof tasks and domains. Their versatility and state-of-the-art performance have\nestablished them as indispensable tools for a wide array of applications.\nHowever, in the constantly changing landscape of machine learning, the\nassurance of the trustworthiness of transformers holds utmost importance. This\npaper conducts a thorough examination of vision-language transformers,\nemploying three fundamental principles of responsible AI: Bias, Robustness, and\nInterpretability. The primary objective of this paper is to delve into the\nintricacies and complexities associated with the practical use of transformers,\nwith the overarching goal of advancing our comprehension of how to enhance\ntheir reliability and accountability.",
            "author": [
                "Mayank Vatsa",
                "Anubhooti Jain",
                "Richa Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04231v1",
                "http://arxiv.org/pdf/2312.04231v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04230v1",
            "title": "Resource-Efficient Quantum Circuits for Molecular Simulations: A Case\n  Study of Umbrella Inversion in Ammonia",
            "updated": "2023-12-07T11:30:09Z",
            "published": "2023-12-07T11:30:09Z",
            "summary": "We conducted a thorough evaluation of various state-of-the-art strategies to\nprepare the ground state wavefunction of a system on a quantum computer,\nspecifically within the framework of variational quantum eigensolver (VQE).\nDespite the advantages of VQE and its variants, the current quantum\ncomputational chemistry calculations often provide inaccurate results for\nlarger molecules, mainly due to the polynomial growth in the depth of quantum\ncircuits and the number of two-qubit gates, such as CNOT gates. To alleviate\nthis problem, we aim to design efficient quantum circuits that would outperform\nthe existing ones on the current noisy quantum devices. In this study, we\ndesigned a novel quantum circuit that reduces the required circuit depth and\nnumber of two-qubit entangling gates by about 60%, while retaining the accuracy\nof the ground state energies close to the chemical accuracy. Moreover, even in\nthe presence of device noise, these novel shallower circuits yielded\nsubstantially low error rates than the existing approaches for predicting the\nground state energies of molecules. By considering the umbrella inversion\nprocess in ammonia molecule as an example, we demonstrated the advantages of\nthis new approach and estimated the energy barrier for the inversion process.",
            "author": [
                "M. R. Nirmal",
                "Sharma S. R. K. C. Yamijala",
                "Kalpak Ghosh",
                "Sumit Kumar",
                "Manoj Nambiar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04230v1",
                "http://arxiv.org/pdf/2312.04230v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04229v1",
            "title": "Accelerated Real-Life (ARL) Testing and Characterization of Automotive\n  LiDAR Sensors to facilitate the Development and Validation of Enhanced Sensor\n  Models",
            "updated": "2023-12-07T11:28:04Z",
            "published": "2023-12-07T11:28:04Z",
            "summary": "In the realm of automated driving simulation and sensor modeling, the need\nfor highly accurate sensor models is paramount for ensuring the reliability and\nsafety of advanced driving assistance systems (ADAS). Hence, numerous works\nfocus on the development of high-fidelity models of ADAS sensors, such as\ncamera, Radar as well as modern LiDAR systems to simulate the sensor behavior\nin different driving scenarios, even under varying environmental conditions,\nconsidering for example adverse weather effects. However, aging effects of\nsensors, leading to suboptimal system performance, are mostly overlooked by\ncurrent simulation techniques. This paper introduces a cutting-edge\nHardware-in-the-Loop (HiL) test bench designed for the automated, accelerated\naging and characterization of Automotive LiDAR sensors. The primary objective\nof this research is to address the aging effects of LiDAR sensors over the\nproduct life cycle, specifically focusing on aspects such as laser beam profile\ndeterioration, output power reduction and intrinsic parameter drift, which are\nmostly neglected in current sensor models. By that, this proceeding research is\nintended to path the way, not only towards identifying and modeling respective\ndegradation effects, but also to suggest quantitative model validation metrics.",
            "author": [
                "Marcel Kettelgerdes",
                "Tjorven Hillmann",
                "Thomas Hirmer",
                "H\u00fcseyin Erdogan",
                "Bernhard Wunderle",
                "Gordon Elger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04229v1",
                "http://arxiv.org/pdf/2312.04229v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04227v1",
            "title": "Optimizing Mentor-Student Communication with Symbolic Design for Message\n  States",
            "updated": "2023-12-07T11:22:19Z",
            "published": "2023-12-07T11:22:19Z",
            "summary": "In the mentor-student communication process, students often struggle to\nreceive prompt and clear guidance from their mentors, making it challenging to\ndetermine their next steps. When mentors don't respond promptly, it can lead to\nstudent confusion, as they may be uncertain whether their message has been\nacknowledged without resulting action. Instead of the binary options of \"read\"\nand \"unread,\" there's a pressing need for more nuanced descriptions of message\nstates. To tackle this ambiguity, we've developed a set of symbols to precisely\nrepresent the cognitive states associated with messages in transit. Through\nexperimentation, this design not only assists mentors and students in\neffectively labeling their responses but also mitigates unnecessary\nmisunderstandings. By utilizing symbols for accurate information and\nunderstanding state marking, we've enhanced communication efficiency between\nmentors and students, thereby improving the quality and efficacy of\ncommunication in mentor-student relationships.",
            "author": [
                "Yuanzhe Jin",
                "Jiali Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04227v1",
                "http://arxiv.org/pdf/2312.04227v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04221v1",
            "title": "Optimal quantum communication networks: capacitance versus security",
            "updated": "2023-12-07T11:11:18Z",
            "published": "2023-12-07T11:11:18Z",
            "summary": "The rate and security of quantum communications between users placed at\narbitrary points of a quantum communication network depend on the structure of\nthe network, on its extension and on the nature of the communication channels.\nIn this work we propose a strategy of network optimization that intertwines\nclassical network approaches and quantum information theory. Specifically, by\nsuitably defining a quantum efficiency functional, we identify the optimal\nquantum communication connections through the network by balancing security and\nthe quantum communication rate. The optimized network is then constructed as\nthe network of the maximal quantum efficiency connections and its performance\nis evaluated by studying the scaling of average properties as functions of the\nnumber of nodes and of the network spatial extension.",
            "author": [
                "Lorenzo Cirigliano",
                "Valentina Brosco",
                "Claudio Castellano",
                "Claudio Conti",
                "Laura Pilozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04221v1",
                "http://arxiv.org/pdf/2312.04221v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04219v1",
            "title": "Swap distance minimization in SOV languages. Cognitive and mathematical\n  foundations",
            "updated": "2023-12-07T11:10:28Z",
            "published": "2023-12-07T11:10:28Z",
            "summary": "Distance minimization is a general principle of language. A special case of\nthis principle in the domain of word order is swap distance minimization. This\nprinciple predicts that variations from a canonical order that are reached by\nfewer swaps of adjacent constituents are lest costly and thus more likely. Here\nwe investigate the principle in the context of the triple formed by subject\n(S), object (O) and verb (V). We introduce the concept of word order rotation\nas a cognitive underpinning of that prediction. When the canonical order of a\nlanguage is SOV, the principle predicts SOV < SVO, OSV < VSO, OVS < VOS, in\norder of increasing cognitive cost. We test the prediction in three flexible\norder SOV languages: Korean (Koreanic), Malayalam (Dravidian), and Sinhalese\n(Indo-European). Evidence of swap distance minimization is found in all three\nlanguages, but it is weaker in Sinhalese. Swap distance minimization is\nstronger than a preference for the canonical order in Korean and especially\nMalayalam.",
            "author": [
                "Ramon Ferrer-i-Cancho",
                "Savithry Namboodiripad"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04219v1",
                "http://arxiv.org/pdf/2312.04219v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04218v1",
            "title": "Delayed switching identities and multi-marginal solutions to the\n  Skorokhod embedding problem",
            "updated": "2023-12-07T11:09:36Z",
            "published": "2023-12-07T11:09:36Z",
            "summary": "In this article, we consider a generalisation of the Skorokhod embedding\nproblem (SEP) with a delayed starting time. In the delayed SEP, we look for\nstopping times which embed a given measure in a stochastic process, which occur\nafter a given delay time. Our first contribution is to show that the switching\nidentities introduced in a recent paper of Backhoff, Cox, Grass and Huesmann\nextend to the case with a delay.\n  We then show that the delayed switching identities can be used to establish\nan optimal stopping representation of Root and Rost solutions to the\nmulti-marginal Skorokhod embedding problem. We achieve this by rephrasing the\nmulti-period problem into a one-period framework with delay. This not only\nrecovers the known multi-marginal representation of Root, but also establishes\na previously unknown optimal stopping representation associated to the\nmulti-marginal Rost solution. The Rost case is more complex than the Root case\nsince it naturally requires randomisation for general initial measures, and we\ndevelop the necessary tools to develop these solutions. Our work also provides\na comprehensive and complete treatment of discrete Root and Rost solutions,\nembedding discrete measures into simple symmetric random walks.",
            "author": [
                "Alexander M. G. Cox",
                "Annemarie M. Grass"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04218v1",
                "http://arxiv.org/pdf/2312.04218v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60G40, 60J65, 90C41 (Primary) 91G20 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04216v1",
            "title": "CODEX: A Cluster-Based Method for Explainable Reinforcement Learning",
            "updated": "2023-12-07T11:04:37Z",
            "published": "2023-12-07T11:04:37Z",
            "summary": "Despite the impressive feats demonstrated by Reinforcement Learning (RL),\nthese algorithms have seen little adoption in high-risk, real-world\napplications due to current difficulties in explaining RL agent actions and\nbuilding user trust. We present Counterfactual Demonstrations for Explanation\n(CODEX), a method that incorporates semantic clustering, which can effectively\nsummarize RL agent behavior in the state-action space. Experimentation on the\nMiniGrid and StarCraft II gaming environments reveals the semantic clusters\nretain temporal as well as entity information, which is reflected in the\nconstructed summary of agent behavior. Furthermore, clustering the\ndiscrete+continuous game-state latent representations identifies the most\ncrucial episodic events, demonstrating a relationship between the latent and\nsemantic spaces. This work contributes to the growing body of work that strives\nto unlock the power of RL for widespread use by leveraging and extending\ntechniques from Natural Language Processing.",
            "author": [
                "Timothy K. Mathes",
                "Jessica Inman",
                "Andr\u00e9s Col\u00f3n",
                "Simon Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04216v1",
                "http://arxiv.org/pdf/2312.04216v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04215v1",
            "title": "Guided Reconstruction with Conditioned Diffusion Models for Unsupervised\n  Anomaly Detection in Brain MRIs",
            "updated": "2023-12-07T11:03:42Z",
            "published": "2023-12-07T11:03:42Z",
            "summary": "Unsupervised anomaly detection in Brain MRIs aims to identify abnormalities\nas outliers from a healthy training distribution. Reconstruction-based\napproaches that use generative models to learn to reconstruct healthy brain\nanatomy are commonly used for this task. Diffusion models are an emerging class\nof deep generative models that show great potential regarding reconstruction\nfidelity. However, they face challenges in preserving intensity characteristics\nin the reconstructed images, limiting their performance in anomaly detection.\nTo address this challenge, we propose to condition the denoising mechanism of\ndiffusion models with additional information about the image to reconstruct\ncoming from a latent representation of the noise-free input image. This\nconditioning enables high-fidelity reconstruction of healthy brain structures\nwhile aligning local intensity characteristics of input-reconstruction pairs.\nWe evaluate our method's reconstruction quality, domain adaptation features and\nfinally segmentation performance on publicly available data sets with various\npathologies. Using our proposed conditioning mechanism we can reduce the\nfalse-positive predictions and enable a more precise delineation of anomalies\nwhich significantly enhances the anomaly detection performance compared to\nestablished state-of-the-art approaches to unsupervised anomaly detection in\nbrain MRI. Furthermore, our approach shows promise in domain adaptation across\ndifferent MRI acquisitions and simulated contrasts, a crucial property of\ngeneral anomaly detection methods.",
            "author": [
                "Finn Behrendt",
                "Debayan Bhattacharya",
                "Robin Mieling",
                "Lennart Maack",
                "Julia Kr\u00fcger",
                "Roland Opfer",
                "Alexander Schlaefer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04215v1",
                "http://arxiv.org/pdf/2312.04215v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04214v1",
            "title": "Accurate Distances Measures and Machine Learning of the Texture-Property\n  Relation for Crystallographic Textures Represented by One-Point Statistics",
            "updated": "2023-12-07T11:02:41Z",
            "published": "2023-12-07T11:02:41Z",
            "summary": "The crystallographic texture of metallic materials is a key microstructural\nfeature that is responsible for the anisotropic behavior, e.g., important in\nforming operations. In materials science, crystallographic texture is commonly\ndescribed by the orientation distribution function, which is defined as the\nprobability density function of the orientations of the monocrystal grains\nconforming a polycrystalline material. For representing the orientation\ndistribution function, there are several approaches such as using generalized\nspherical harmonics, orientation histograms, and pole figure images . Measuring\ndistances between crystallographic textures is essential for any task that\nrequires assessing texture similarities, e.g. to guide forming processes.\nTherefore, we introduce novel distance measures based on (i) the Earth Movers\nDistance that takes into account local distance information encoded in\nhistogram-based texture representations and (ii) a distance measure based on\npole figure images. For this purpose, we evaluate and compare existing distance\nmeasures for selected use-cases. The present study gives insights into\nadvantages and drawbacks of using certain texture representations and distance\nmeasures with emphasis on applications in materials design and optimal process\ncontrol.",
            "author": [
                "Tarek Iraki",
                "Lukas Morand",
                "Norbert Link",
                "Stefan Sandfeld",
                "Dirk Helm"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04214v1",
                "http://arxiv.org/pdf/2312.04214v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04210v1",
            "title": "Constraint Model for the Satellite Image Mosaic Selection Problem",
            "updated": "2023-12-07T10:52:16Z",
            "published": "2023-12-07T10:52:16Z",
            "summary": "Satellite imagery solutions are widely used to study and monitor different\nregions of the Earth. However, a single satellite image can cover only a\nlimited area. In cases where a larger area of interest is studied, several\nimages must be stitched together to create a single larger image, called a\nmosaic, that can cover the area. Today, with the increasing number of satellite\nimages available for commercial use, selecting the images to build the mosaic\nis challenging, especially when the user wants to optimize one or more\nparameters, such as the total cost and the cloud coverage percentage in the\nmosaic. More precisely, for this problem the input is an area of interest,\nseveral satellite images intersecting the area, a list of requirements relative\nto the image and the mosaic, such as cloud coverage percentage, image\nresolution, and a list of objectives to optimize. We contribute to the\nconstraint and mixed integer lineal programming formulation of this new\nproblem, which we call the \\textit{satellite image mosaic selection problem},\nwhich is a multi-objective extension of the polygon cover problem. We propose a\ndataset of realistic and challenging instances, where the images were captured\nby the satellite constellations SPOT, Pl\\'eiades and Pl\\'eiades Neo. We\nevaluate and compare the two proposed models and show their efficiency for\nlarge instances, up to 200 images.",
            "author": [
                "Manuel Combarro Sim\u00f3n",
                "Pierre Talbot",
                "Gr\u00e9goire Danoy",
                "Jedrzej Musial",
                "Mohammed Alswaitti",
                "Pascal Bouvry"
            ],
            "link": [
                "http://dx.doi.org/10.4230/LIPIcs.CP.2023.44",
                "http://arxiv.org/abs/2312.04210v1",
                "http://arxiv.org/pdf/2312.04210v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04206v1",
            "title": "Affine Symmetries for ABJM Partition Function and its Generalization",
            "updated": "2023-12-07T10:47:06Z",
            "published": "2023-12-07T10:47:06Z",
            "summary": "Partially motivated by the fact that the grand partition function of the ABJM\ntheory or its generalization is expressed by a spectral operator enjoying\nsymmetries of the Weyl group, it was found that the grand partition function\nsatisfies the q-Painleve equation, which is constructed from the affine Weyl\ngroup. In this paper we clarify the affine symmetries of the grand partition\nfunction. With the affine symmetries, we find that the grand partition function\nextends naturally outside the fundamental domain of duality cascades and once\nthe Painleve equation holds in the fundamental domain, so does it outside.",
            "author": [
                "Sanefumi Moriyama",
                "Tomoki Nosaka"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04206v1",
                "http://arxiv.org/pdf/2312.04206v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04202v1",
            "title": "Probing levitodynamics with multi-stochastic forces and the simple\n  applications on the dark matter detection in optical levitation experiment",
            "updated": "2023-12-07T10:39:08Z",
            "published": "2023-12-07T10:39:08Z",
            "summary": "If the terrestrial environment is permeated by dark matter, the levitation\nexperiences damping forces and fluctuations attributed to dark matter. This\npaper investigates levitodynamics with multiple stochastic forces, including\nthermal drag, photon recoil, feedback, etc., assuming that all of these forces\nadhere to the fluctuation-dissipation theorem. The ratio of total damping to\nthe stochastic damping coefficient distinguishes the levitodynamics from cases\ninvolving only one single stochastic force. The heating and cooling processes\nare formulated to determine the limits of temperature change. All sources of\nstochastic forces are comprehensively examined, revealing that dark matter\ncollisions cannot be treated analogously to fluid dynamics. Additionally, a\nmeticulous analysis is presented, elucidating the intricate relationship\nbetween the fundamental transfer cross-section and the macroscopic transfer\ncross-section. While the dark damping coefficient is suppressed by the mass of\nthe levitated particle, scattering can be coherently enhanced based on the\nscale of the component microscopic particle, the atomic form factor, and the\nstatic structure factor. Hence, dark damping holds the potential to provide\nvaluable insights into the detection of the macroscopic strength of fundamental\nparticles. We propose experimental procedures for levitation and employ linear\nestimation to extract the dark damping coefficient. Utilizing current\nlevitation results, we demonstrate that the fundamental transfer cross section\nof dark matter can be of the order $\\sigma^{\\rm D}_{T}\\lsim {\\cal\nO}(10^{-26})\\rm cm^2$.",
            "author": [
                "Xi Cheng",
                "Ji-Heng Guo",
                "Wenyu Wang",
                "Bin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04202v1",
                "http://arxiv.org/pdf/2312.04202v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "hep-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04193v1",
            "title": "Language Model Knowledge Distillation for Efficient Question Answering\n  in Spanish",
            "updated": "2023-12-07T10:21:22Z",
            "published": "2023-12-07T10:21:22Z",
            "summary": "Recent advances in the development of pre-trained Spanish language models has\nled to significant progress in many Natural Language Processing (NLP) tasks,\nsuch as question answering. However, the lack of efficient models imposes a\nbarrier for the adoption of such models in resource-constrained environments.\nTherefore, smaller distilled models for the Spanish language could be proven to\nbe highly scalable and facilitate their further adoption on a variety of tasks\nand scenarios. In this work, we take one step in this direction by developing\nSpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient\nquestion answering in Spanish. To achieve this, we employ knowledge\ndistillation from a large model onto a lighter model that allows for a wider\nimplementation, even in areas with limited computational resources, whilst\nattaining negligible performance sacrifice. Our experiments show that the dense\ndistilled model can still preserve the performance of its larger counterpart,\nwhile significantly increasing inference speedup. This work serves as a\nstarting point for further research and investigation of model compression\nefforts for Spanish language models across various NLP tasks.",
            "author": [
                "Adri\u00e1n Bazaga",
                "Pietro Li\u00f2",
                "Gos Micklem"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04193v1",
                "http://arxiv.org/pdf/2312.04193v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04191v1",
            "title": "Subsets of groups with context-free preimages",
            "updated": "2023-12-07T10:18:46Z",
            "published": "2023-12-07T10:18:46Z",
            "summary": "We study subsets $E$ of finitely generated groups where the set of all words\nover a given finite generating set that lie in $E$ forms a context-free\nlanguage. We call these sets recognisably context-free. They are invariant of\nthe choice of generating set and a theorem of Muller and Schupp fully\nclassifies when the set $\\{1\\}$ can be recognisably context-free. We extend\nMuller and Schupp's result to show that a group $G$ admits a finite\nrecognisably context-free subset if and only if $G$ is virtually free. We show\nthat every conjugacy class of a group $G$ is recognisably context-free if and\nonly if $G$ is virtually free. We conclude by showing that a coset is\nrecognisably context-free if and only if the Schreier coset graph of the\ncorresponding subgroup is quasi-isometric to a tree.",
            "author": [
                "Alex Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04191v1",
                "http://arxiv.org/pdf/2312.04191v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR",
                "cs.FL",
                "03D05, 20F10, 20F65, 68Q45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04187v1",
            "title": "Enumerating Complexity Revisited",
            "updated": "2023-12-07T10:14:42Z",
            "published": "2023-12-07T10:14:42Z",
            "summary": "We reduce the best-known upper bound on the length of a program that\nenumerates a set in terms of the probability of it being enumerated by a random\nprogram. We prove a general result that any linear upper bound for finite sets\nimplies the same linear bound for infinite sets.\n  So far, the best-known upper bound was given by Solovay. He showed that the\nminimum length of a program enumerating a subset $S$ of natural numbers is\nbounded by minus three binary logarithms of the probability that a random\nprogram will enumerate $S$. Later, Vereshchagin showed that the constant can be\nimproved from three to two for finite sets. In this work, using an improvement\nof the method proposed by Solovay, we demonstrate that any bound for finite\nsets implies the same for infinite sets, modulo logarithmic factors. Using\nVereshchagin's result, we improve the current best-known upper bound from three\nto two.",
            "author": [
                "Alexander Shekhovtsov",
                "Georgii Zakharov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04187v1",
                "http://arxiv.org/pdf/2312.04187v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04184v1",
            "title": "Enhancing quantum contrast by using an EMCCD as a photon number\n  resolving device",
            "updated": "2023-12-07T10:11:27Z",
            "published": "2023-12-07T10:11:27Z",
            "summary": "The Electron Multiplying Charge Coupled Devices (EMCCD), owing to their high\nquantum efficiency and decent spatial resolution, are widely used to study\ntypical quantum optical phenomena such as spatial entanglement and related\napplications. Researchers have already developed a procedure that enables us to\nstatistically determine whether a pixel detects a single photon or not based on\nwhether its output is higher or lower than the estimated noise level. However,\nthese techniques are limited to extremely low photon numbers ( $\\approx 0.15$\nmean number of photons per pixel per exposure), allowing for at most one photon\nper pixel. This limitation hinders applications due to the large number of\nframes required for any study. In this work, we present a method to estimate\nthe mean rate of photons per pixel per frame for a specific exposure time.\nSubsequently, we make a statistical estimate of the number of photons ($\\geq\n1$) incident on each pixel. This allows us to effectively utilize the EMCCD as\na photon number resolving device, which significantly reduces the required\nexperimentation time. As evidence of our approach, we quantify contrast in\nquantum correlation exhibited by a pair of spatially entangled photons\ngenerated by Spontaneous Parametric Down Conversion process. We employ the\nstandard methods commonly used within the scientific community for comparison\nwith our proposed method. We find an enhancement in the signal to noise ratio\nby about a factor of 3 for identical number of frames. This implies that this\ntechnique can achieve excellent results only within half the data collection\ntime as compared to the conventional techniques.",
            "author": [
                "Rounak Chatterjee",
                "Vikas Bhat",
                "Kiran Bajar",
                "Sushil Mujumdar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04184v1",
                "http://arxiv.org/pdf/2312.04184v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04183v1",
            "title": "Enhanced data Detection for Massive MIMO with 1-Bit ADCs",
            "updated": "2023-12-07T10:11:20Z",
            "published": "2023-12-07T10:11:20Z",
            "summary": "We present new insightful results on the uplink data detection for massive\nmultiple-input multiple-output systems with 1-bit analog-to-digital converters.\nThe expected values of the soft-estimated symbols (i.e., after the linear\ncombining and prior to the data detection) have been recently characterized for\nmultiple user equipments (UEs) and maximum ratio combining (MRC) receiver at\nthe base station. In this paper, we first provide a numerical evaluation of the\nexpected value of the soft-estimated symbols with zero-forcing (ZF) and minimum\nmean squared error (MMSE) receivers for a multi-UE setting with correlated\nRayleigh fading. Then, we propose a joint data detection (JD) strategy, which\nexploits the interdependence among the soft-estimated symbols of the\ninterfering UEs, along with its low-complexity variant. These strategies are\ncompared with a naive approach that adapts the maximum-likelihood data\ndetection to the 1-bit quantization. Numerical results show that ZF and MMSE\nprovide considerable gains over MRC in terms of symbol error rate. Moreover,\nthe proposed JD and its low-complexity variant provide a significant boost in\ncomparison with the single-UE data detection.",
            "author": [
                "Amin Radbord",
                "Italo Atzeni",
                "Antti Tolli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04183v1",
                "http://arxiv.org/pdf/2312.04183v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04181v1",
            "title": "Cell segmentation of in situ transcriptomics data using signed graph\n  partitioning",
            "updated": "2023-12-07T10:08:07Z",
            "published": "2023-12-07T10:08:07Z",
            "summary": "The locations of different mRNA molecules can be revealed by multiplexed in\nsitu RNA detection. By assigning detected mRNA molecules to individual cells,\nit is possible to identify many different cell types in parallel. This in turn\nenables investigation of the spatial cellular architecture in tissue, which is\ncrucial for furthering our understanding of biological processes and diseases.\nHowever, cell typing typically depends on the segmentation of cell nuclei,\nwhich is often done based on images of a DNA stain, such as DAPI. Limiting cell\ndefinition to a nuclear stain makes it fundamentally difficult to determine\naccurate cell borders, and thereby also difficult to assign mRNA molecules to\nthe correct cell. As such, we have developed a computational tool that segments\ncells solely based on the local composition of mRNA molecules. First, a small\nneural network is trained to compute attractive and repulsive edges between\npairs of mRNA molecules. The signed graph is then partitioned by a mutex\nwatershed into components corresponding to different cells. We evaluated our\nmethod on two publicly available datasets and compared it against the current\nstate-of-the-art and older baselines. We conclude that combining neural\nnetworks with combinatorial optimization is a promising approach for cell\nsegmentation of in situ transcriptomics data.",
            "author": [
                "Axel Andersson",
                "Andrea Behanova",
                "Carolina W\u00e4hlby",
                "Filip Malmberg"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-42795-4_13",
                "http://arxiv.org/abs/2312.04181v1",
                "http://arxiv.org/pdf/2312.04181v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04179v1",
            "title": "Mancha3D code: Multi-purpose Advanced Non-ideal MHD Code for High\n  resolution simulations in Astrophysics",
            "updated": "2023-12-07T10:06:13Z",
            "published": "2023-12-07T10:06:13Z",
            "summary": "The Mancha3D code is a versatile tool for numerical simulations of\nmagnetohydrodynamic processes in solar/stellar atmospheres. The code includes\nnon-ideal physics derived from plasma partial ionization, a realistic equation\nof state and radiative transfer, which allows performing high quality realistic\nsimulations of magneto-convection, as well as idealized simulations of\nparticular processes, such as wave propagation, instabilities or energetic\nevents. The paper summarizes the equations and methods used in the Mancha3D\ncode. It also describes its numerical stability and parallel performance and\nefficiency. The code is based on a finite difference discretization and\nmemory-saving Runge-Kutta (RK) scheme. It handles non-ideal effects through\nsuper-time stepping and Hall diffusion schemes, and takes into account thermal\nconduction by solving an additional hyperbolic equation for the heat flux. The\ncode is easily configurable to perform different kinds of simulations. Several\nexamples of the code usage are given. It is demonstrated that splitting\nvariables into equilibrium and perturbation parts is essential for simulations\nof wave propagation in a static background. A perfectly matched layer (PML)\nboundary condition built into the code greatly facilitates a non-reflective\nopen boundary implementation. Spatial filtering is an important numerical\nremedy to eliminate grid-size perturbations enhancing the code stability.\nParallel performance analysis reveals that the code is strongly memory bound,\nwhich is a natural consequence of the numerical techniques used, such as split\nvariables and PML boundary conditions. Both strong and weak scalings show\nadequate performance up till several thousands of CPUs.",
            "author": [
                "M. Modestov",
                "E. Khomenko",
                "N. Vitas",
                "A. de Vicente",
                "A. Navarro",
                "P. A. Gonzalez-Morales",
                "M. Collados",
                "T. Felipe",
                "D. Martinez-Gomez",
                "P. Hunana",
                "M. Luna",
                "M. Koll Pistarini",
                "B. Popescu Braileanu",
                "A. Perdomo Garcia",
                "V. Liakh",
                "I. Santamaria",
                "M. M. Gomez Miguez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04179v1",
                "http://arxiv.org/pdf/2312.04179v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04174v1",
            "title": "Coherent energy and force uncertainty in deep learning force fields",
            "updated": "2023-12-07T09:49:05Z",
            "published": "2023-12-07T09:49:05Z",
            "summary": "In machine learning energy potentials for atomic systems, forces are commonly\nobtained as the negative derivative of the energy function with respect to\natomic positions. To quantify aleatoric uncertainty in the predicted energies,\na widely used modeling approach involves predicting both a mean and variance\nfor each energy value. However, this model is not differentiable under the\nusual white noise assumption, so energy uncertainty does not naturally\ntranslate to force uncertainty. In this work we propose a machine learning\npotential energy model in which energy and force aleatoric uncertainty are\nlinked through a spatially correlated noise process. We demonstrate our\napproach on an equivariant messages passing neural network potential trained on\nenergies and forces on two out-of-equilibrium molecular datasets. Furthermore,\nwe also show how to obtain epistemic uncertainties in this setting based on a\nBayesian interpretation of deep ensemble models.",
            "author": [
                "Peter Bj\u00f8rn J\u00f8rgensen",
                "Jonas Busk",
                "Ole Winther",
                "Mikkel N. Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04174v1",
                "http://arxiv.org/pdf/2312.04174v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04167v1",
            "title": "Mixture of Dynamical Variational Autoencoders for Multi-Source\n  Trajectory Modeling and Separation",
            "updated": "2023-12-07T09:36:31Z",
            "published": "2023-12-07T09:36:31Z",
            "summary": "In this paper, we propose a latent-variable generative model called mixture\nof dynamical variational autoencoders (MixDVAE) to model the dynamics of a\nsystem composed of multiple moving sources. A DVAE model is pre-trained on a\nsingle-source dataset to capture the source dynamics. Then, multiple instances\nof the pre-trained DVAE model are integrated into a multi-source mixture model\nwith a discrete observation-to-source assignment latent variable. The posterior\ndistributions of both the discrete observation-to-source assignment variable\nand the continuous DVAE variables representing the sources content/position are\nestimated using a variational expectation-maximization algorithm, leading to\nmulti-source trajectories estimation. We illustrate the versatility of the\nproposed MixDVAE model on two tasks: a computer vision task, namely\nmulti-object tracking, and an audio processing task, namely single-channel\naudio source separation. Experimental results show that the proposed method\nworks well on these two tasks, and outperforms several baseline methods.",
            "author": [
                "Xiaoyu Lin",
                "Laurent Girin",
                "Xavier Alameda-Pineda"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04167v1",
                "http://arxiv.org/pdf/2312.04167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04166v1",
            "title": "Improving Communication Efficiency of Federated Distillation via\n  Accumulating Local Updates",
            "updated": "2023-12-07T09:36:18Z",
            "published": "2023-12-07T09:36:18Z",
            "summary": "As an emerging federated learning paradigm, federated distillation enables\ncommunication-efficient model training by transmitting only small-scale\nknowledge during the learning process. To further improve the communication\nefficiency of federated distillation, we propose a novel technique, ALU, which\naccumulates multiple rounds of local updates before transferring the knowledge\nto the central server. ALU drastically decreases the frequency of communication\nin federated distillation, thereby significantly reducing the communication\noverhead during the training process. Empirical experiments demonstrate the\nsubstantial effect of ALU in improving the communication efficiency of\nfederated distillation.",
            "author": [
                "Zhiyuan Wu",
                "Sheng Sun",
                "Yuwei Wang",
                "Min Liu",
                "Tian Wen",
                "Wen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04166v1",
                "http://arxiv.org/pdf/2312.04166v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04160v1",
            "title": "Text as Image: Learning Transferable Adapter for Multi-Label\n  Classification",
            "updated": "2023-12-07T09:22:20Z",
            "published": "2023-12-07T09:22:20Z",
            "summary": "Pre-trained vision-language models have notably accelerated progress of\nopen-world concept recognition. Their impressive zero-shot ability has recently\nbeen transferred to multi-label image classification via prompt tuning,\nenabling to discover novel labels in an open-vocabulary manner. However, this\nparadigm suffers from non-trivial training costs, and becomes computationally\nprohibitive for a large number of candidate labels. To address this issue, we\nnote that vision-language pre-training aligns images and texts in a unified\nembedding space, making it potential for an adapter network to identify labels\nin visual modality while be trained in text modality. To enhance such\ncross-modal transfer ability, a simple yet effective method termed random\nperturbation is proposed, which enables the adapter to search for potential\nvisual embeddings by perturbing text embeddings with noise during training,\nresulting in better performance in visual modality. Furthermore, we introduce\nan effective approach to employ large language models for multi-label\ninstruction-following text generation. In this way, a fully automated pipeline\nfor visual label recognition is developed without relying on any manual data.\nExtensive experiments on public benchmarks show the superiority of our method\nin various multi-label classification tasks.",
            "author": [
                "Xuelin Zhu",
                "Jiuxin Cao",
                "Jian liu",
                "Dongqi Tang",
                "Furong Xu",
                "Weijia Liu",
                "Jiawei Ge",
                "Bo Liu",
                "Qingpei Guo",
                "Tianyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04160v1",
                "http://arxiv.org/pdf/2312.04160v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04159v1",
            "title": "Zero-Touch Networks: Towards Next-Generation Network Automation",
            "updated": "2023-12-07T09:21:41Z",
            "published": "2023-12-07T09:21:41Z",
            "summary": "The Zero-touch network and Service Management (ZSM) framework represents an\nemerging paradigm in the management of the fifth-generation (5G) and Beyond\n(5G+) networks, offering automated self-management and self-healing\ncapabilities to address the escalating complexity and the growing data volume\nof modern networks. ZSM frameworks leverage advanced technologies such as\nMachine Learning (ML) to enable intelligent decision-making and reduce human\nintervention. This paper presents a comprehensive survey of Zero-Touch Networks\n(ZTNs) within the ZSM framework, covering network optimization, traffic\nmonitoring, energy efficiency, and security aspects of next-generational\nnetworks. The paper explores the challenges associated with ZSM, particularly\nthose related to ML, which necessitate the need to explore diverse network\nautomation solutions. In this context, the study investigates the application\nof Automated ML (AutoML) in ZTNs, to reduce network management costs and\nenhance performance. AutoML automates the selection and tuning process of a ML\nmodel for a given task. Specifically, the focus is on AutoML's ability to\npredict application throughput and autonomously adapt to data drift.\nExperimental results demonstrate the superiority of the proposed AutoML\npipeline over traditional ML in terms of prediction accuracy. Integrating\nAutoML and ZSM concepts significantly reduces network configuration and\nmanagement efforts, allowing operators to allocate more time and resources to\nother important tasks. The paper also provides a high-level 5G system\narchitecture incorporating AutoML and ZSM concepts. This research highlights\nthe potential of ZTNs and AutoML to revolutionize the management of 5G+\nnetworks, enabling automated decision-making and empowering network operators\nto achieve higher efficiency, improved performance, and enhanced user\nexperience.",
            "author": [
                "Mirna El Rajab",
                "Li Yang",
                "Abdallah Shami"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04159v1",
                "http://arxiv.org/pdf/2312.04159v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "68T01, 68M10, 90B18",
                "I.2.0; I.2.2; C.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04158v1",
            "title": "Safety-Enhanced Self-Learning for Optimal Power Converter Control",
            "updated": "2023-12-07T09:19:38Z",
            "published": "2023-12-07T09:19:38Z",
            "summary": "Data-driven learning-based control methods such as reinforcement learning\n(RL) have become increasingly popular with recent proliferation of the machine\nlearning paradigm. These methods address the parameter sensitiveness and\nunmodeled dynamics in model-based controllers, such as finite control-set model\npredictive control. RL agents are typically utilized in simulation\nenvironments, where they are allowed to explore multiple \"unsafe\" actions\nduring the learning process. However, this type of learning is not applicable\nto online self-learning of controllers in physical power converters, because\nunsafe actions would damage them. To address this, this letter proposes a safe\nonline RL-based control framework to autonomously find the optimal switching\nstrategy for the power converters, while ensuring system safety during the\nentire self-learning process. The proposed safe online RL-based control is\nvalidated in a practical testbed on a two-level voltage source converter\nsystem, and the results confirm the effectiveness of the proposed method.",
            "author": [
                "Yihao Wan",
                "Qianwen Xu",
                "Tomislav Dragi\u010devi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04158v1",
                "http://arxiv.org/pdf/2312.04158v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04157v1",
            "title": "Evolution of the magnetic field and flows of solar active regions with\n  persistent magnetic bipoles before emergence",
            "updated": "2023-12-07T09:15:02Z",
            "published": "2023-12-07T09:15:02Z",
            "summary": "Magnetic active regions on the Sun are harbingers of space weather events.\nUnderstanding the physics of how they form and evolve will improve space\nweather forecasting. Our aim is to characterise the surface magnetic field and\nflows for a sample of active regions with persistent magnetic bipoles prior to\nemergence. We identified 42 emerging active regions (EARs), in the Solar\nDynamics Observatory Helioseismic Emerging Active Region survey (Schunker et\nal. 2016), associated with small magnetic bipoles at least one day before the\ntime of emergence. We then identified a contrasting sample of 42 EARs that\nemerge more abruptly without bipoles before emergence. We computed the\nsupergranulation scale surface flows using helioseismic holography. We averaged\nthe flow maps and magnetic field maps over all active regions in each sample at\neach time interval from 2 days before emergence to 1 day after. We found that\nEARs associated with a persistent pre-emergence bipole evolve to be, on\naverage, lower flux active regions than EARs that emerge more abruptly.\nFurther, we found that the EARs that emerge more abruptly do so with a\ndiverging flow of $(3\\pm 0.6) \\times 10^{-6}$ s$^{-1}$ on the order of 50-100\nms$^{-1}$. Our results suggest that there is a statistical dependence of the\nsurface flow signature throughout the emergence process on the maximum magnetic\nflux of the active region.",
            "author": [
                "Camron S. Alley",
                "Hannah Schunker"
            ],
            "link": [
                "http://dx.doi.org/10.1017/pasa.2023.52",
                "http://arxiv.org/abs/2312.04157v1",
                "http://arxiv.org/pdf/2312.04157v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04155v1",
            "title": "Resource Allocation for Semantic Communication under Physical-layer\n  Security",
            "updated": "2023-12-07T09:12:26Z",
            "published": "2023-12-07T09:12:26Z",
            "summary": "Semantic communication is deemed as a revolution of Shannon's paradigm in the\nsix-generation (6G) wireless networks. It aims at transmitting the extracted\ninformation rather than the original data, which receivers will try to recover.\nIntuitively, the larger extracted information, the longer latency of semantic\ncommunication will be. Besides, larger extracted information will result in\nmore accurate reconstructed information, thereby causing a higher utility of\nthe semantic communication system. Shorter latency and higher utility are\ndesirable objectives for the system, so there will be a trade-off between\nutility and latency. This paper proposes a joint optimization algorithm for\ntotal latency and utility. Moreover, security is essential for the semantic\ncommunication system. We incorporate the secrecy rate, a physical-layer\nsecurity method, into the optimization problem. The secrecy rate is the\ncommunication rate at which no information is disclosed to an eavesdropper.\nExperimental results demonstrate that the proposed algorithm obtains the best\njoint optimization performance compared to the baselines.",
            "author": [
                "Yang Li",
                "Xinyu Zhou",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04155v1",
                "http://arxiv.org/pdf/2312.04155v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04152v1",
            "title": "EulerMormer: Robust Eulerian Motion Magnification via Dynamic Filtering\n  within Transformer",
            "updated": "2023-12-07T09:10:16Z",
            "published": "2023-12-07T09:10:16Z",
            "summary": "Video Motion Magnification (VMM) aims to break the resolution limit of human\nvisual perception capability and reveal the imperceptible minor motion that\ncontains valuable information in the macroscopic domain. However, challenges\narise in this task due to photon noise inevitably introduced by photographic\ndevices and spatial inconsistency in amplification, leading to flickering\nartifacts in static fields and motion blur and distortion in dynamic fields in\nthe video. Existing methods focus on explicit motion modeling without\nemphasizing prioritized denoising during the motion magnification process. This\npaper proposes a novel dynamic filtering strategy to achieve static-dynamic\nfield adaptive denoising. Specifically, based on Eulerian theory, we separate\ntexture and shape to extract motion representation through inter-frame shape\ndifferences, expecting to leverage these subdivided features to solve this task\nfinely. Then, we introduce a novel dynamic filter that eliminates noise cues\nand preserves critical features in the motion magnification and amplification\ngeneration phases. Overall, our unified framework, EulerMormer, is a pioneering\neffort to first equip with Transformer in learning-based VMM. The core of the\ndynamic filter lies in a global dynamic sparse cross-covariance attention\nmechanism that explicitly removes noise while preserving vital information,\ncoupled with a multi-scale dual-path gating mechanism that selectively\nregulates the dependence on different frequency features to reduce spatial\nattenuation and complement motion boundaries. We demonstrate extensive\nexperiments that EulerMormer achieves more robust video motion magnification\nfrom the Eulerian perspective, significantly outperforming state-of-the-art\nmethods. The source code is available at\nhttps://github.com/VUT-HFUT/EulerMormer.",
            "author": [
                "Fei Wang",
                "Dan Guo",
                "Kun Li",
                "Meng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04152v1",
                "http://arxiv.org/pdf/2312.04152v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04146v1",
            "title": "High-throughput study of the phase constitution of the thin film system\n  Mg-Mn-Al-O in relation to Li recovery from slags",
            "updated": "2023-12-07T09:01:20Z",
            "published": "2023-12-07T09:01:20Z",
            "summary": "The increasing importance of recycling makes the recovery of valuable\nelements from slags interesting, e.g., by the concept of engineered artificial\nminerals (EnAMs). In this concept, it is aimed for the formation of EnAMs,\nmeaning phase(s) with a high content of the to-be-recovered element(s) from\nslags of pyrometallurgical recycling processes. For this, understanding the\nphase constitution of the slag systems is of high importance. The system\nMg-Mn-Al-O is a metal oxide slag subsystem from Li-ion battery recycling, that\nis critical for the formation of spinel phases, which are competing phases to\nthe possible Li-containing EnAM phase LiAlO2. Here, the phase constitution was\ninvestigated using a thin film materials library that covers the composition\nspace (Mg14-69Mn11-38Al14-74)Ox. By means of high-throughput energy-dispersive\nX-ray spectroscopy and X-ray diffraction, the formation of the spinel solid\nsolution phase was confirmed for a wide composition space. Increasing\npreferential orientation of the spinel solid solution along (400) with\nincreasing Mg content was identified. X-ray photoelectron spectroscopy was used\nto measure the near-surface composition of selected areas of the materials\nlibrary, and detailed peak fitting of the Mn 2p3/2 region revealed the Mn\noxidation state to be a mixture of Mn2+ and Mn3+. For one measurement area of\nthe materials library containing equal atomic amounts of Mg, Mn and Al,\ntransmission electron microscopy showed that the approximately 420 nm-thick\nfilm consists of columnar spinel grains with Mg, Mn and Al being evenly\ndistributed. Based on these results, we suggest that the shown high likelihood\nof spinel formation in slags might be influenced by controlling the Mn\noxidation state to enable the formation of desirable EnAM phases.",
            "author": [
                "Florian Lourens",
                "Ellen Suhr",
                "Alena Schnickmann",
                "Thomas Schirmer",
                "Alfred Ludwig"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04146v1",
                "http://arxiv.org/pdf/2312.04146v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04145v1",
            "title": "Diffusing Colors: Image Colorization with Text Guided Diffusion",
            "updated": "2023-12-07T08:59:20Z",
            "published": "2023-12-07T08:59:20Z",
            "summary": "The colorization of grayscale images is a complex and subjective task with\nsignificant challenges. Despite recent progress in employing large-scale\ndatasets with deep neural networks, difficulties with controllability and\nvisual quality persist. To tackle these issues, we present a novel image\ncolorization framework that utilizes image diffusion techniques with granular\ntext prompts. This integration not only produces colorization outputs that are\nsemantically appropriate but also greatly improves the level of control users\nhave over the colorization process. Our method provides a balance between\nautomation and control, outperforming existing techniques in terms of visual\nquality and semantic coherence. We leverage a pretrained generative Diffusion\nModel, and show that we can finetune it for the colorization task without\nlosing its generative power or attention to text prompts. Moreover, we present\na novel CLIP-based ranking model that evaluates color vividness, enabling\nautomatic selection of the most suitable level of vividness based on the\nspecific scene semantics. Our approach holds potential particularly for color\nenhancement and historical image colorization.",
            "author": [
                "Nir Zabari",
                "Aharon Azulay",
                "Alexey Gorkor",
                "Tavi Halperin",
                "Ohad Fried"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04145v1",
                "http://arxiv.org/pdf/2312.04145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04140v1",
            "title": "Polarimetric Light Transport Analysis for Specular Inter-reflection",
            "updated": "2023-12-07T08:55:28Z",
            "published": "2023-12-07T08:55:28Z",
            "summary": "Polarization is well known for its ability to decompose diffuse and specular\nreflections. However, the existing decomposition methods only focus on direct\nreflection and overlook multiple reflections, especially specular\ninter-reflection. In this paper, we propose a novel decomposition method for\nhandling specular inter-reflection of metal objects by using a unique\npolarimetric feature: the rotation direction of linear polarization. This\nrotation direction serves as a discriminative factor between direct and\ninter-reflection on specular surfaces. To decompose the reflectance components,\nwe actively rotate the linear polarization of incident light and analyze the\nrotation direction of the reflected light. We evaluate our method using both\nsynthetic and real data, demonstrating its effectiveness in decomposing\nspecular inter-reflections of metal objects. Furthermore, we demonstrate that\nour method can be combined with other decomposition methods for a detailed\nanalysis of light transport. As a practical application, we show its\neffectiveness in improving the accuracy of 3D measurement against strong\nspecular inter-reflection.",
            "author": [
                "Ryota Maeda",
                "Shinsaku Hiura"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04140v1",
                "http://arxiv.org/pdf/2312.04140v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04135v1",
            "title": "A Novel Federated Learning-based Intrusion Detection System for Flying\n  Ad Hoc Networks",
            "updated": "2023-12-07T08:50:25Z",
            "published": "2023-12-07T08:50:25Z",
            "summary": "Unmanned aerial vehicles (UAVs) in flying ad-hoc networks (FANETs) face\nsecurity challenges due to the dynamic and distributed nature of these\nnetworks. This paper presents the Federated Learning-based Intrusion Detection\nSystem (FL-IDS), an innovative approach designed to improve FANET security.\nFL-IDS leverages federated learning to address privacy concerns of centralized\nintrusion detection systems. FL-IDS operates in a decentralized manner,\nenabling UAVs to collaboratively train a global intrusion detection model\nwithout sharing raw data. Local models are assigned to each UAV, using\nclient-specific data, and only updated model weights are shared with a central\nserver. This preserves privacy while utilizing collective intelligence for\neffective intrusion detection. Experimental results show FL-IDS's competitive\nperformance with Central IDS (C-IDS) while mitigating privacy concerns. The\nBias Towards Specific Clients (BTSC) method further enhances FL-IDS\nperformance, surpassing C-IDS even at lower attacker ratios. A comparative\nanalysis with traditional intrusion detection methods, including Local IDS\n(L-IDS), provides insights into FL-IDS's strengths. This study significantly\ncontributes to FANET security by introducing a privacy-aware, decentralized\nintrusion detection approach tailored to the unique challenges of UAV networks.",
            "author": [
                "Ozlem Ceviz",
                "Pinar Sadioglu",
                "Sevil Sen",
                "Vassilios G. Vassilakis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04135v1",
                "http://arxiv.org/pdf/2312.04135v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04134v1",
            "title": "Using a Large Language Model to generate a Design Structure Matrix",
            "updated": "2023-12-07T08:48:54Z",
            "published": "2023-12-07T08:48:54Z",
            "summary": "The Design Structure Matrix (DSM) is an established method used in dependency\nmodelling, especially in the design of complex engineering systems. The\ngeneration of DSM is traditionally carried out through manual means and can\ninvolve interviewing experts to elicit critical system elements and the\nrelationships between them. Such manual approaches can be time-consuming and\ncostly. This paper presents a workflow that uses a Large Language Model (LLM)\nto support the generation of DSM and improve productivity. A prototype of the\nworkflow was developed in this work and applied on a diesel engine DSM\npublished previously. It was found that the prototype could reproduce 357 out\nof 462 DSM entries published (i.e. 77.3%), suggesting that the work can aid DSM\ngeneration. A no-code version of the prototype is made available online to\nsupport future research.",
            "author": [
                "Edwin C. Y. Koh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04134v1",
                "http://arxiv.org/pdf/2312.04134v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04132v1",
            "title": "Spin-flip gluon GTMD $F_{1,2}$ at small-$x$",
            "updated": "2023-12-07T08:41:49Z",
            "published": "2023-12-07T08:41:49Z",
            "summary": "Spin-flip processes in the deep inelastic scatterings are thought to be\nsuppressed in the high energy. Recent studies by Hatta and Zhou, however, show\nthat gluon generalized parton distribution (GPD) $E_g$, which is associated\nwith spin-flip processes, exhibits the Regge behavior identical to the BFKL\nPomeron. This was done by deriving the small-$x$ evolution equation for the\nreal part of $F$-type spin-flip gluon GTMDs $F_{1,2}$. In this article, we have\nshown that though the evolution equation for ${\\rm Re}(F_{1,2})$ has IR poles -\nthey all mutually cancel - making the equation IR finite and self-consistent.\nWe also have analytically solved the equations in the dilute regime and find\nsmall-$x$ asymptotics of the GTMDs ${\\rm Re}(F_{1,2})$ as \\begin{eqnarray} {\\rm\nRe}(F_{1,2}) \\sim \\left(\\frac{1}{x}\\right)^{\\alpha_s\\left(4\\ln2-8/3\\right)}\n\\left(\\cos 3\\phi_{k\\Delta} +\\cos \\phi_{k\\Delta}\\right). \\nonumber\n\\end{eqnarray} Interestingly, the surviving solution corresponds to conformal\nspin $n=2$ and carries an explicit $\\cos 3\\phi_{k\\Delta} + \\cos \\phi_{k\\Delta}$\nazimuthal dependence. As the imaginary part of $F_{1,2}$, is related to the\nspin-dependent odderon or Gluon Siver function and scales as ${\\rm Im}(F_{1,2})\n\\sim x^{0}$, the positive intercept for ${\\rm Re}(F_{1,2})$, implies that it is\nexpected to dominate over the gluon Siver function in the small-$x$ limit - and\nmay directly impact the modeling of unpolarised GTMDs and associated spin-flip\nprocesses.",
            "author": [
                "Sanskriti Agrawal",
                "Nahid Vasim",
                "Raktim Abir"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04132v1",
                "http://arxiv.org/pdf/2312.04132v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-lat",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04131v1",
            "title": "Joint Training or Not: An Exploration of Pre-trained Speech Models in\n  Audio-Visual Speaker Diarization",
            "updated": "2023-12-07T08:40:37Z",
            "published": "2023-12-07T08:40:37Z",
            "summary": "The scarcity of labeled audio-visual datasets is a constraint for training\nsuperior audio-visual speaker diarization systems. To improve the performance\nof audio-visual speaker diarization, we leverage pre-trained supervised and\nself-supervised speech models for audio-visual speaker diarization.\nSpecifically, we adopt supervised~(ResNet and ECAPA-TDNN) and self-supervised\npre-trained models~(WavLM and HuBERT) as the speaker and audio embedding\nextractors in an end-to-end audio-visual speaker diarization~(AVSD) system.\nThen we explore the effectiveness of different frameworks, including\nTransformer, Conformer, and cross-attention mechanism, in the audio-visual\ndecoder. To mitigate the degradation of performance caused by separate\ntraining, we jointly train the audio encoder, speaker encoder, and audio-visual\ndecoder in the AVSD system. Experiments on the MISP dataset demonstrate that\nthe proposed method achieves superior performance and obtained third place in\nMISP Challenge 2022.",
            "author": [
                "Huan Zhao",
                "Li Zhang",
                "Yue Li",
                "Yannan Wang",
                "Hongji Wang",
                "Wei Rao",
                "Qing Wang",
                "Lei Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04131v1",
                "http://arxiv.org/pdf/2312.04131v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04127v1",
            "title": "Analyzing the Inherent Response Tendency of LLMs: Real-World\n  Instructions-Driven Jailbreak",
            "updated": "2023-12-07T08:29:58Z",
            "published": "2023-12-07T08:29:58Z",
            "summary": "Extensive work has been devoted to improving the safety mechanism of Large\nLanguage Models (LLMs). However, in specific scenarios, LLMs still generate\nharmful responses when faced with malicious instructions, a phenomenon referred\nto as \"Jailbreak Attack\". In our research, we introduce a novel jailbreak\nattack method (\\textbf{RADIAL}), which consists of two steps: 1) Inherent\nResponse Tendency Analysis: we analyze the inherent affirmation and rejection\ntendency of LLMs to react to real-world instructions. 2) Real-World\nInstructions-Driven Jailbreak: based on our analysis, we strategically choose\nseveral real-world instructions and embed malicious instructions into them to\namplify the LLM's potential to generate harmful responses. On three open-source\nhuman-aligned LLMs, our method achieves excellent jailbreak attack performance\nfor both Chinese and English malicious instructions. Besides, we guided\ndetailed ablation experiments and verified the effectiveness of our core idea\n\"Inherent Response Tendency Analysis\". Our exploration also exposes the\nvulnerability of LLMs to being induced into generating more detailed harmful\nresponses in subsequent rounds of dialogue.",
            "author": [
                "Yanrui Du",
                "Sendong Zhao",
                "Ming Ma",
                "Yuhan Chen",
                "Bing Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04127v1",
                "http://arxiv.org/pdf/2312.04127v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04124v1",
            "title": "Formal multiple Eisenstein series and their derivations",
            "updated": "2023-12-07T08:27:26Z",
            "published": "2023-12-07T08:27:26Z",
            "summary": "We introduce the algebra of formal multiple Eisenstein series and study its\nderivations. This algebra is motivated by the classical multiple Eisenstein\nseries, introduced by Gangl-Kaneko-Zagier as a hybrid of classical Eisenstein\nseries and multiple zeta values. In depth one, we obtain formal versions of the\nEisenstein series satisfying the same algebraic relations as the classical\nEisenstein series. In particular, they generate an algebra whose elements we\ncall formal quasimodular forms. We show that the algebra of formal multiple\nEisenstein series is an $\\mathfrak{sl}_2$-algebra by formalizing the usual\nderivations for quasimodular forms and extending them naturally to the whole\nalgebra. Additionally, we introduce some families of derivations for general\nquasi-shuffle algebras, providing a broader context for these derivations.\nFurther, we prove that a quotient of this algebra is isomorphic to the algebra\nof formal multiple zeta values. This gives a novel and purely formal approach\nto classical (quasi)modular forms and builds a new link between (formal)\nmultiple zeta values and modular forms.",
            "author": [
                "Henrik Bachmann",
                "Jan-Willem van Ittersum",
                "Nils Matthes"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04124v1",
                "http://arxiv.org/pdf/2312.04124v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.QA",
                "11F11, 11M32 (Primary), 13N15, 16T30 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04122v1",
            "title": "First Principles Investigation on Structural and Optoelectronic\n  Properties of newly designed Janus Lead Halides PbXY (X, Y = F, Cl, Br, I )",
            "updated": "2023-12-07T08:23:06Z",
            "published": "2023-12-07T08:23:06Z",
            "summary": "Here, we design a novel class of Janus structures PbXY(X,Y = F, Cl, Br, I)\nand propose it for the solar mediated photocatalytic water splitting hydrogen\nproduction as well as for the photovoltaic solarcell applications. Charge\nanalysis shows that covalent bonding for less electronegative atoms and ionic\nbonding for more electronegative atoms. Strong dual bonding like ionic one side\nand covalent other side is observed when heavy and lighter atoms are part of\nthe same Janus structures. The as designed Janus structures show good dynamical\nstability through phonon calculations. Basic electronic structure using\nGeneralised Gradient Approximation(GGA) reveal both direct and indirect nature\nof band gap with large tunability. Heyd-Scuseria-Ernzerhof (HSE) electronic\nstructure calculations are performed and wider band gaps are predicted for\nthese Janus structures. The calculated effective masses of charge carriers show\nrobust charge carrier dynamics. The orbital resolved electronic density of\nstates (DOS) shows that the conduction band edge is composed of pz orbital of\nPb atom. The partialcharge density calculated at conduction band minimum (CBM)\nalso support the result obtained from PDOS analysis. Breaking of\ncentrosymmetry, polarization in the out of plane direction, the z-oriented\norbitals of CBM all points that these materials are suitable for shift current\ngeneration. The calculated optical absorption spectra show that the Janus\nstructures are suitable for visible light absorption. The calculated potential\ndifference between the top and bottom layer show significant variation and\nmaximum (1.02 eV) is observed for PbClF. Further, we show that combining both\npotential difference and HSE bandgap, valence band maximum(VBM) and CBM\nstraddle the water redox potentials, thus making the Janus structures suitable\nfor water redox reactions.",
            "author": [
                "Anjana E Sudheer",
                "Golla Tejaswini",
                "D Murali",
                "Matthias Posselt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04122v1",
                "http://arxiv.org/pdf/2312.04122v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04118v1",
            "title": "Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic\n  Play",
            "updated": "2023-12-07T08:18:40Z",
            "published": "2023-12-07T08:18:40Z",
            "summary": "Infants' ability to recognize and categorize objects develops gradually. The\nsecond year of life is marked by both the emergence of more semantic visual\nrepresentations and a better understanding of word meaning. This suggests that\nlanguage input may play an important role in shaping visual representations.\nHowever, even in suitable contexts for word learning like dyadic play sessions,\ncaregivers utterances are sparse and ambiguous, often referring to objects that\nare different from the one to which the child attends. Here, we systematically\ninvestigate to what extent caregivers' utterances can nevertheless enhance\nvisual representations. For this we propose a computational model of visual\nrepresentation learning during dyadic play. We introduce a synthetic dataset of\nego-centric images perceived by a toddler-agent that moves and rotates toy\nobjects in different parts of its home environment while hearing caregivers'\nutterances, modeled as captions. We propose to model toddlers' learning as\nsimultaneously aligning representations for 1) close-in-time images and 2)\nco-occurring images and utterances. We show that utterances with statistics\nmatching those of real caregivers give rise to representations supporting\nimproved category recognition. Our analysis reveals that a small\ndecrease/increase in object-relevant naming frequencies can drastically impact\nthe learned representations. This affects the attention on object names within\nan utterance, which is required for efficient visuo-linguistic alignment.\nOverall, our results support the hypothesis that caregivers' naming utterances\ncan improve toddlers' visual representations.",
            "author": [
                "Timothy Schauml\u00f6ffel",
                "Arthur Aubret",
                "Gemma Roig",
                "Jochen Triesch"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04118v1",
                "http://arxiv.org/pdf/2312.04118v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04114v1",
            "title": "TI-DNS: A Trusted and Incentive DNS Resolution Architecture based on\n  Blockchain",
            "updated": "2023-12-07T08:03:10Z",
            "published": "2023-12-07T08:03:10Z",
            "summary": "Domain Name System (DNS) is a critical component of the Internet\ninfrastructure, responsible for translating domain names into IP addresses.\nHowever, DNS is vulnerable to some malicious attacks, including DNS cache\npoisoning, which redirects users to malicious websites displaying offensive or\nillegal content. Existing countermeasures often suffer from at least one of the\nfollowing weakness: weak attack resistance, high overhead, or complex\nimplementation. To address these challenges, this paper presents TI-DNS, a\nblockchain-based DNS resolution architecture designed to detect and correct the\nforged DNS records caused by the cache poisoning attacks in the DNS resolution\nprocess. TI-DNS leverages a multi-resolver Query Vote mechanism to ensure the\ncredibility of verified records on the blockchain ledger and a stake-based\nincentive mechanism to promote well-behaved participation. Importantly, TI-DNS\nis easy to be adopted as it only requires modifications to the resolver side of\ncurrent DNS infrastructure. Finally, we develop a prototype and evaluate it\nagainst alternative solutions. The result demonstrates that TI-DNS effectively\nand efficiently solves DNS cache poisoning.",
            "author": [
                "Yufan Fu",
                "Jiuqi Wei",
                "Ying Li",
                "Botao Peng",
                "Xiaodong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04114v1",
                "http://arxiv.org/pdf/2312.04114v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04112v1",
            "title": "The operating diagram of a flocculation model in the chemostat and its\n  dependence on the biological parameters",
            "updated": "2023-12-07T07:56:29Z",
            "published": "2023-12-07T07:56:29Z",
            "summary": "In this paper, we consider a flocculation model in a chemostat where one\nspecies is present in two forms: planktonic and aggregated bacteria with the\npresence of a single resource. The removal rates of isolated and attached\nbacteria are distinct and include the specific death rates. Considering\ndistinct yield coefficients with a large class of growth rates, we present a\nmathematical analysis of the model by establishing the necessary and sufficient\nconditions of the existence and local asymptotic stability of all steady states\naccording to the two operating parameters which are the dilution rate and the\ninflowing concentration of the substrate. Using these conditions, we determine\nfirst theoretically the operating diagram of the flocculation process\ndescribing the asymptotic behavior of the system with respect to two control\nparameters. The bifurcations analysis shows a rich set of possible types of\nbifurcations: transcritical bifurcation or branch points of steady states,\nsaddle-node bifurcation or limit points of steady states, Hopf, and homoclinic\nbifurcations. Using the numerical method with MATCONT software based on a\ncontinuation and correction algorithm, we find the same operating diagram\nobtained theoretically. However, MATCONT detects other types of two-parameter\nbifurcations such as Bogdanov-Takens and Cusp bifurcations.",
            "author": [
                "Radhouane Fekih-Salem",
                "Tewfik Sari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04112v1",
                "http://arxiv.org/pdf/2312.04112v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04111v1",
            "title": "Breaking the Entanglement of Homophily and Heterophily in\n  Semi-supervised Node Classification",
            "updated": "2023-12-07T07:54:11Z",
            "published": "2023-12-07T07:54:11Z",
            "summary": "Recently, graph neural networks (GNNs) have shown prominent performance in\nsemi-supervised node classification by leveraging knowledge from the graph\ndatabase. However, most existing GNNs follow the homophily assumption, where\nconnected nodes are more likely to exhibit similar feature distributions and\nthe same labels, and such an assumption has proven to be vulnerable in a\ngrowing number of practical applications. As a supplement, heterophily reflects\ndissimilarity in connected nodes, which has gained significant attention in\ngraph learning. To this end, data engineers aim to develop a powerful GNN model\nthat can ensure performance under both homophily and heterophily. Despite\nnumerous attempts, most existing GNNs struggle to achieve optimal node\nrepresentations due to the constraints of undirected graphs. The neglect of\ndirected edges results in sub-optimal graph representations, thereby hindering\nthe capacity of GNNs. To address this issue, we introduce AMUD, which\nquantifies the relationship between node profiles and topology from a\nstatistical perspective, offering valuable insights for \\underline{A}daptively\n\\underline{M}odeling the natural directed graphs as the \\underline{U}ndirected\nor \\underline{D}irected graph to maximize the benefits from subsequent graph\nlearning. Furthermore, we propose \\underline{A}daptive \\underline{D}irected\n\\underline{P}attern \\underline{A}ggregation (ADPA) as a new directed graph\nlearning paradigm for AMUD. Empirical studies have demonstrated that AMUD\nguides efficient graph learning. Meanwhile, extensive experiments on 14\nbenchmark datasets substantiate the impressive performance of ADPA,\noutperforming baselines by significant margins of 3.96\\%.",
            "author": [
                "Henan Sun",
                "Xunkai Li",
                "Zhengyu Wu",
                "Daohan Su",
                "Rong-Hua Li",
                "Guoren Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04111v1",
                "http://arxiv.org/pdf/2312.04111v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04109v1",
            "title": "Bridge the Present and Future: A Cross-Layer Matching Game in Dynamic\n  Cloud-Aided Mobile Edge Networks",
            "updated": "2023-12-07T07:52:55Z",
            "published": "2023-12-07T07:52:55Z",
            "summary": "Cloud-aided mobile edge networks (CAMENs) allow edge servers (ESs) to\npurchase resources from remote cloud servers (CSs), while overcoming resource\nshortage when handling computation-intensive tasks of mobile users (MUs).\nConventional trading mechanisms (e.g., onsite trading) confront many\nchallenges, including decision-making overhead (e.g., latency) and potential\ntrading failures. This paper investigates a series of cross-layer matching\nmechanisms to achieve stable and cost-effective resource provisioning across\ndifferent layers (i.e., MUs, ESs, CSs), seamlessly integrated into a novel\nhybrid paradigm that incorporates futures and spot trading. In futures trading,\nwe explore an overbooking-driven aforehand cross-layer matching (OA-CLM)\nmechanism, facilitating two future contract types: contract between MUs and\nESs, and contract between ESs and CSs, while assessing potential risks under\nhistorical statistical analysis. In spot trading, we design two backup plans\nrespond to current network/market conditions: determination on contractual MUs\nthat should switch to local processing from edge/cloud services; and an onsite\ncross-layer matching (OS-CLM) mechanism that engages participants in real-time\npractical transactions. We next show that our matching mechanisms theoretically\nsatisfy stability, individual rationality, competitive equilibrium, and weak\nPareto optimality. Comprehensive simulations in real-world and numerical\nnetwork settings confirm the corresponding efficacy, while revealing remarkable\nimprovements in time/energy efficiency and social welfare.",
            "author": [
                "Houyi Qi",
                "Minghui Liwang",
                "Xianbin Wang",
                "Li Li",
                "Wei Gong",
                "Jian Jin",
                "Zhenzhen Jiao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04109v1",
                "http://arxiv.org/pdf/2312.04109v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04103v1",
            "title": "Enhancing the Rationale-Input Alignment for Self-explaining\n  Rationalization",
            "updated": "2023-12-07T07:37:15Z",
            "published": "2023-12-07T07:37:15Z",
            "summary": "Rationalization empowers deep learning models with self-explaining\ncapabilities through a cooperative game, where a generator selects a\nsemantically consistent subset of the input as a rationale, and a subsequent\npredictor makes predictions based on the selected rationale. In this paper, we\ndiscover that rationalization is prone to a problem named \\emph{rationale\nshift}, which arises from the algorithmic bias of the cooperative game.\nRationale shift refers to a situation where the semantics of the selected\nrationale may deviate from the original input, but the predictor still produces\naccurate predictions based on the deviation, resulting in a compromised\ngenerator with misleading feedback.\n  To address this issue, we first demonstrate the importance of the alignment\nbetween the rationale and the full input through both empirical observations\nand theoretical analysis. Subsequently, we introduce a novel approach called\nDAR (\\textbf{D}iscriminatively \\textbf{A}ligned \\textbf{R}ationalization),\nwhich utilizes an auxiliary module pretrained on the full input to\ndiscriminatively align the selected rationale and the original input. We\ntheoretically illustrate how DAR accomplishes the desired alignment, thereby\novercoming the rationale shift problem. The experiments on two widely used\nreal-world benchmarks show that the proposed method significantly improves the\nexplanation quality (measured by the overlap between the model-selected\nexplanation and the human-annotated rationale) as compared to state-of-the-art\ntechniques. Additionally, results on two synthetic settings further validate\nthe effectiveness of DAR in addressing the rationale shift problem.",
            "author": [
                "Wei Liu",
                "Haozhao Wang",
                "Jun Wang",
                "Zhiying Deng",
                "YuanKai Zhang",
                "Cheng Wang",
                "Ruixuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04103v1",
                "http://arxiv.org/pdf/2312.04103v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04098v1",
            "title": "Unveiling a hidden bar-like structure in NGC1087: kinematic and\n  photometric evidence using MUSE/VLT, ALMA and JWST",
            "updated": "2023-12-07T07:23:46Z",
            "published": "2023-12-07T07:23:46Z",
            "summary": "We report a faint non-axisymmetric structure in NGC\\,1087 through the use of\nJWST Near Infrared Camera { (NIRCam)}, with an associated kinematic counterpart\nobserved as an oval distortion in the stellar velocity map, \\ha~and\nCO~$J=2\\rightarrow1$ velocity fields. This structure is not evident in the MUSE\noptical continuum images but only revealed in the near-IR with the F200W and\nF300M band filters at $2\\mu$m and $3\\mu$m respectively. Due to its elongation,\nthis structure resembles a stellar bar although with remarkable differences\nwith respect to conventional stellar bars. Most of the near-IR emission is\nconcentrated within $6\\arcsec~\\sim500$~pc with a maximum extension up to\n1.2~kpc. The spatial extension of the large-scale non-circular motions is\ncoincident with the bar, which undoubtedly confirms the presence of a\nnon-axisymmetric perturbation in the potential of NGC\\,1087. The oval\ndistortion is enhanced in CO due to its dynamically cold nature rather than in\n\\ha. We found that the kinematics in all phases including stellar, ionized and\nmolecular, can be described simultaneously by a model containing a bisymmetric\nperturbation; however, we find that an inflow model of gas along the bar major\naxis is also likely. Furthermore the molecular mass inflow rate associated can\nexplain the observed star formation rate in the bar.\n  This reinforces the idea that bars are mechanisms for transporting gas and\ntriggering star formation. This work contributes to our understanding of\nnon-axisymmetry in galaxies using the most sophisticated data so far.",
            "author": [
                "Carlos L\u00f3pez-Cob\u00e1",
                "Lihwai Lin",
                "Sebasti\u00e1n F. S\u00e1nchez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04098v1",
                "http://arxiv.org/pdf/2312.04098v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04097v1",
            "title": "Comments on a Paper by Narovlansky and Verlinde",
            "updated": "2023-12-07T07:23:34Z",
            "published": "2023-12-07T07:23:34Z",
            "summary": "The double-scaled infinite temperature limit of the SYK model has been\nconjectured by Rahman and Susskind (RS) [1, 2, 3, 4], and independently by\nVerlinde [5] to be dual to a certain low dimensional de Sitter space. In a\nrecent discussion of this conjecture Narovlansky and Verlinde (NV) [6] came to\nconclusions which radically differ from those of RS. In particular these\nconclusions disagree by factors which diverge as $N \\to \\infty$. Among these is\na mismatch between the scaling of boundary entropy and bulk horizon area. In\nthis note, we point out differences in two key assumptions made by RS and NV\nwhich lead to these mismatches, and explain why we think the RS assumptions are\ncorrect. When the NV assumptions, which we believe are unwarranted, are\nreplaced by those of RS, the conclusions match both RS and the standard\nrelation between entropy and area.\n  In the process of discussing these, we will shed some light on: the various\nnotions of temperature that appear in the duality; the relationship between\nHamiltonian energy and bulk mass; and the location of bulk conical defect\nstates in the spectrum of DSSYK$_{\\infty}$.",
            "author": [
                "Adel A Rahman",
                "Leonard Susskind"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04097v1",
                "http://arxiv.org/pdf/2312.04097v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04094v1",
            "title": "Singular backward stochastic Volterra integral equations in infinite\n  dimensional spaces",
            "updated": "2023-12-07T07:14:52Z",
            "published": "2023-12-07T07:14:52Z",
            "summary": "In this paper, the notion of singular backward stochastic Volterra integral\nequations (singular BSVIEs for short) in infinite dimensional space is\nintroduced, and the corresponding well-posedness is carefully established. A\nclass of singularity conditions are proposed, which not only cover that of\nfractional kernel, Volterra Heston model kernel, completely monotone kernels,\nto mention a few, but also happen to be used in the forward stochastic Volterra\nintegral with new conclusions arising. Motivated by mathematical physics\nproblem such as the viscoelasticity/thermoviscoelasticity of materials, heat\nconduction in materials with memory, optimal control problems of abstract\nstochastic Volterra integral equations (including fractional stochastic\nevolution equations and stochastic evolutionary integral equations) are\npresented. At last, our BSVIEs are surprisingly used in maximum principle of\ncontrolled stochastic delay evolution equations. One advantage of this new\nstandpoint is that the final cost functional can naturally depend on the past\nstate for the first time.",
            "author": [
                "Tianxiao Wang",
                "Mengliang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04094v1",
                "http://arxiv.org/pdf/2312.04094v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04091v1",
            "title": "Hyperarithmetical Complexity of Infinitary Action Logic with\n  Multiplexing",
            "updated": "2023-12-07T07:05:48Z",
            "published": "2023-12-07T07:05:48Z",
            "summary": "In 2023, Kuznetsov and Speranski introduced infinitary action logic with\nmultiplexing $!^m\\nabla \\mathrm{ACT}_\\omega$ and proved that the derivability\nproblem for it lies between the $\\omega$ and $\\omega^\\omega$ levels of the\nhyperarithmetical hierarchy. We prove that this problem is\n$\\Delta^0_{\\omega^\\omega}$-complete under Turing reductions. Namely, we prove\nthat it is recursively isomorphic to the satisfaction predicate for computable\ninfinitary formulas of rank less than $\\omega^\\omega$ in the language of\narithmetic. We also prove this result for the fragment of $!^m\\nabla\n\\mathrm{ACT}_\\omega$ where Kleene star is not allowed to be in the scope of the\nsubexponential. Finally, we present a family of logics, which are fragments of\n$!^m\\nabla \\mathrm{ACT}_\\omega$, such that the complexity of the $k$-th logic\nis between $\\Delta^0_{\\omega^k}$ and $\\Delta^0_{\\omega^{k+1}}$.",
            "author": [
                "Tikhon Pshenitsyn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04091v1",
                "http://arxiv.org/pdf/2312.04091v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04087v1",
            "title": "VRPTEST: Evaluating Visual Referring Prompting in Large Multimodal\n  Models",
            "updated": "2023-12-07T06:53:55Z",
            "published": "2023-12-07T06:53:55Z",
            "summary": "With recent advancements in Large Multimodal Models (LMMs) across various\ndomains, a novel prompting method called visual referring prompting has\nemerged, showing significant potential in enhancing human-computer interaction\nwithin multimodal systems. This method offers a more natural and flexible\napproach to human interaction with these systems compared to traditional text\ndescriptions or coordinates. However, the categorization of visual referring\nprompting remains undefined, and its impact on the performance of LMMs has yet\nto be formally examined. In this study, we conduct the first comprehensive\nanalysis of LMMs using a variety of visual referring prompting strategies. We\nintroduce a benchmark dataset called VRPTEST, comprising 3 different visual\ntasks and 2,275 images, spanning diverse combinations of prompt strategies.\nUsing VRPTEST, we conduct a comprehensive evaluation of eight versions of\nprominent open-source and proprietary foundation models, including two early\nversions of GPT-4V. We develop an automated assessment framework based on\nsoftware metamorphic testing techniques to evaluate the accuracy of LMMs\nwithout the need for human intervention or manual labeling. We find that the\ncurrent proprietary models generally outperform the open-source ones, showing\nan average accuracy improvement of 22.70%; however, there is still potential\nfor improvement. Moreover, our quantitative analysis shows that the choice of\nprompt strategy significantly affects the accuracy of LMMs, with variations\nranging from -17.5% to +7.3%. Further case studies indicate that an appropriate\nvisual referring prompting strategy can improve LMMs' understanding of context\nand location information, while an unsuitable one might lead to answer\nrejection. We also provide insights on minimizing the negative impact of visual\nreferring prompting on LMMs.",
            "author": [
                "Zongjie Li",
                "Chaozheng Wang",
                "Chaowei Liu",
                "Pingchuan Ma",
                "Daoyuan Wu",
                "Shuai Wang",
                "Cuiyun Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04087v1",
                "http://arxiv.org/pdf/2312.04087v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04077v1",
            "title": "When is Plasmode simulation superior to parametric simulation when\n  estimating the MSE of the least squares estimator in linear regression?",
            "updated": "2023-12-07T06:44:00Z",
            "published": "2023-12-07T06:44:00Z",
            "summary": "Simulation is a crucial tool for the evaluation and comparison of statistical\nmethods. How to design fair and neutral simulation studies is therefore of\ngreat interest for both researchers developing new methods and practitioners\nconfronted with the choice of the most suitable method. The term simulation\nusually refers to parametric simulation, that is, computer experiments using\nartificial data made up of pseudo-random numbers. Plasmode simulation, that is,\ncomputer experiments using the combination of resampling feature data from a\nreal-life dataset and generating the target variable with a user-selected\noutcome-generating model (OGM), is an alternative that is often claimed to\nproduce more realistic data. We compare parametric and Plasmode simulation for\nthe example of estimating the mean squared error of the least squares estimator\nin linear regression. If the true underlying data-generating process (DGP) and\nthe OGM were known, parametric simulation would be the best choice in terms of\nestimating the MSE well. However, in reality, both are usually unknown, so\nresearchers have to make assumptions: in Plasmode simulation studies for the\nOGM, in parametric simulation for both DGP and OGM. Most likely, these\nassumptions do not reflect the truth. Here, we aim to find out how assumptions\ndeviating from the true DGP and the true OGM affect the performance of\nparametric simulation and Plasmode simulations in the context of MSE estimation\nfor the least squares estimator and in which situations which simulation type\nis preferable. Our results suggest that the preferable simulation method\ndepends on many factors, including the number of features, and how the\nassumptions of a parametric simulation differ from the true DGP. Also, the\nresampling strategy used for Plasmode influences the results. In particular,\nsubsampling with a small sampling proportion can be recommended.",
            "author": [
                "Marieke Stolte",
                "Nicholas Schreck",
                "Alla Slynko",
                "Maral Saadati",
                "Axel Benner",
                "J\u00f6rg Rahnenf\u00fchrer",
                "Andrea Bommert"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04077v1",
                "http://arxiv.org/pdf/2312.04077v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04076v1",
            "title": "Large Language Models are Good Prompt Learners for Low-Shot Image\n  Classification",
            "updated": "2023-12-07T06:43:34Z",
            "published": "2023-12-07T06:43:34Z",
            "summary": "Low-shot image classification, where training images are limited or\ninaccessible, has benefited from recent progress on pre-trained vision-language\n(VL) models with strong generalizability, e.g. CLIP. Prompt learning methods\nbuilt with VL models generate text features from the class names that only have\nconfined class-specific information. Large Language Models (LLMs), with their\nvast encyclopedic knowledge, emerge as the complement. Thus, in this paper, we\ndiscuss the integration of LLMs to enhance pre-trained VL models, specifically\non low-shot classification. However, the domain gap between language and vision\nblocks the direct application of LLMs. Thus, we propose LLaMP, Large Language\nModels as Prompt learners, that produces adaptive prompts for the CLIP text\nencoder, establishing it as the connecting bridge. Experiments show that,\ncompared with other state-of-the-art prompt learning methods, LLaMP yields\nbetter performance on both zero-shot generalization and few-shot image\nclassification, over a spectrum of 11 datasets.",
            "author": [
                "Zhaoheng Zheng",
                "Jingmin Wei",
                "Xuefeng Hu",
                "Haidong Zhu",
                "Ram Nevatia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04076v1",
                "http://arxiv.org/pdf/2312.04076v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04068v1",
            "title": "Making Translators Privacy-aware on the User's Side",
            "updated": "2023-12-07T06:23:17Z",
            "published": "2023-12-07T06:23:17Z",
            "summary": "We propose PRISM to enable users of machine translation systems to preserve\nthe privacy of data on their own initiative. There is a growing demand to apply\nmachine translation systems to data that require privacy protection. While\nseveral machine translation engines claim to prioritize privacy, the extent and\nspecifics of such protection are largely ambiguous. First, there is often a\nlack of clarity on how and to what degree the data is protected. Even if\nservice providers believe they have sufficient safeguards in place,\nsophisticated adversaries might still extract sensitive information. Second,\nvulnerabilities may exist outside of these protective measures, such as within\ncommunication channels, potentially leading to data leakage. As a result, users\nare hesitant to utilize machine translation engines for data demanding high\nlevels of privacy protection, thereby missing out on their benefits. PRISM\nresolves this problem. Instead of relying on the translation service to keep\ndata safe, PRISM provides the means to protect data on the user's side. This\napproach ensures that even machine translation engines with inadequate privacy\nmeasures can be used securely. For platforms already equipped with privacy\nsafeguards, PRISM acts as an additional protection layer, reinforcing their\nsecurity furthermore. PRISM adds these privacy features without significantly\ncompromising translation accuracy. Our experiments demonstrate the\neffectiveness of PRISM using real-world translators, T5 and ChatGPT\n(GPT-3.5-turbo), and the datasets with two languages. PRISM effectively\nbalances privacy protection with translation accuracy.",
            "author": [
                "Ryoma Sato"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04068v1",
                "http://arxiv.org/pdf/2312.04068v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04066v1",
            "title": "Combining inherent knowledge of vision-language models with unsupervised\n  domain adaptation through self-knowledge distillation",
            "updated": "2023-12-07T06:16:39Z",
            "published": "2023-12-07T06:16:39Z",
            "summary": "Unsupervised domain adaptation (UDA) tries to overcome the tedious work of\nlabeling data by leveraging a labeled source dataset and transferring its\nknowledge to a similar but different target dataset. On the other hand, current\nvision-language models exhibit astonishing zero-shot prediction capabilities.\nIn this work, we combine knowledge gained through UDA with the inherent\nknowledge of vision-language models. In a first step, we generate the zero-shot\npredictions of the source and target dataset using the vision-language model.\nSince zero-shot predictions usually exhibit a large entropy, meaning that the\nclass probabilities are rather evenly distributed, we first adjust the\ndistribution to accentuate the winning probabilities. This is done using both\nsource and target data to keep the relative confidence between source and\ntarget data. We then employ a conventional DA method, to gain the knowledge\nfrom the source dataset, in combination with self-knowledge distillation, to\nmaintain the inherent knowledge of the vision-language model. We further\ncombine our method with a gradual source domain expansion strategy (GSDE) and\nshow that this strategy can also benefit by including zero-shot predictions. We\nconduct experiments and ablation studies on three benchmarks (OfficeHome,\nVisDA, and DomainNet) and outperform state-of-the-art methods. We further show\nin ablation studies the contributions of different parts of our algorithm.",
            "author": [
                "Thomas Westfechtel",
                "Dexuan Zhang",
                "Tatsuya Harada"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04066v1",
                "http://arxiv.org/pdf/2312.04066v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04063v1",
            "title": "An unsupervised approach towards promptable defect segmentation in\n  laser-based additive manufacturing by Segment Anything",
            "updated": "2023-12-07T06:03:07Z",
            "published": "2023-12-07T06:03:07Z",
            "summary": "Foundation models are currently driving a paradigm shift in computer vision\ntasks for various fields including biology, astronomy, and robotics among\nothers, leveraging user-generated prompts to enhance their performance. In the\nmanufacturing domain, accurate image-based defect segmentation is imperative to\nensure product quality and facilitate real-time process control. However, such\ntasks are often characterized by multiple challenges including the absence of\nlabels and the requirement for low latency inference among others. To address\nthese issues, we construct a framework for image segmentation using a\nstate-of-the-art Vision Transformer (ViT) based Foundation model (Segment\nAnything Model) with a novel multi-point prompt generation scheme using\nunsupervised clustering. We apply our framework to perform real-time porosity\nsegmentation in a case study of laser base powder bed fusion (L-PBF) and obtain\nhigh Dice Similarity Coefficients (DSC) without the necessity for any\nsupervised fine-tuning in the model. Using such lightweight foundation model\ninference in conjunction with unsupervised prompt generation, we envision the\nconstruction of a real-time anomaly detection pipeline that has the potential\nto revolutionize the current laser-based additive manufacturing processes,\nthereby facilitating the shift towards Industry 4.0 and promoting defect-free\nproduction along with operational efficiency.",
            "author": [
                "Israt Zarin Era",
                "Imtiaz Ahmed",
                "Zhichao Liu",
                "Srinjoy Das"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04063v1",
                "http://arxiv.org/pdf/2312.04063v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04062v1",
            "title": "A Low-Overhead Incorporation-Extrapolation based Few-Shot CSI Feedback\n  Framework for Massive MIMO Systems",
            "updated": "2023-12-07T06:01:47Z",
            "published": "2023-12-07T06:01:47Z",
            "summary": "Accurate channel state information (CSI) is essential for downlink precoding\nat the base station (BS), especially for frequency FDD wideband massive MIMO\nsystems with OFDM. In FDD systems, CSI is attained through CSI feedback from\nthe user equipment (UE). However, large-scale antennas and large number of\nsubcarriers significantly increase CSI feedback overhead. Deep learning-based\nCSI feedback methods have received tremendous attention in recent years due to\ntheir great capability of compressing CSI. Nonetheless, large amounts of\ncollected samples are required to train deep learning models, which is severely\nchallenging in practice. Besides, with the rapidly increasing number of\nantennas and subcarriers, most of these deep learning methods' CSI feedback\noverhead also grow dramatically, owing to their focus on full-dimensional CSI\nfeedback. To address this issue, in this paper, we propose a low-overhead\nIncorporation-Extrapolation based Few-Shot CSI feedback Framework (IEFSF) for\nmassive MIMO systems. To further reduce the feedback overhead, a\nlow-dimensional eigenvector-based CSI matrix is first formed with the\nincorporation process at the UE, and then recovered to the full-dimensional\neigenvector-based CSI matrix at the BS via the extrapolation process. After\nthat, to alleviate the necessity of the extensive collected samples and enable\nfew-shot CSI feedback, we further propose a knowledge-driven data augmentation\nmethod and an artificial intelligence-generated content (AIGC) -based data\naugmentation method by exploiting the domain knowledge of wireless channels and\nby exploiting a novel generative model, respectively. Numerical results\ndemonstrate that the proposed IEFSF can significantly reduce CSI feedback\noverhead by 16 times compared with existing CSI feedback methods while\nmaintaining higher feedback accuracy using only several hundreds of collected\nsamples.",
            "author": [
                "Binggui Zhou",
                "Xi Yang",
                "Jintao Wang",
                "Shaodan Ma",
                "Feifei Gao",
                "Guanghua Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04062v1",
                "http://arxiv.org/pdf/2312.04062v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04060v1",
            "title": "Differentiable Registration of Images and LiDAR Point Clouds with\n  VoxelPoint-to-Pixel Matching",
            "updated": "2023-12-07T05:46:10Z",
            "published": "2023-12-07T05:46:10Z",
            "summary": "Cross-modality registration between 2D images from cameras and 3D point\nclouds from LiDARs is a crucial task in computer vision and robotic. Previous\nmethods estimate 2D-3D correspondences by matching point and pixel patterns\nlearned by neural networks, and use Perspective-n-Points (PnP) to estimate\nrigid transformation during post-processing. However, these methods struggle to\nmap points and pixels to a shared latent space robustly since points and pixels\nhave very different characteristics with patterns learned in different manners\n(MLP and CNN), and they also fail to construct supervision directly on the\ntransformation since the PnP is non-differentiable, which leads to unstable\nregistration results. To address these problems, we propose to learn a\nstructured cross-modality latent space to represent pixel features and 3D\nfeatures via a differentiable probabilistic PnP solver. Specifically, we design\na triplet network to learn VoxelPoint-to-Pixel matching, where we represent 3D\nelements using both voxels and points to learn the cross-modality latent space\nwith pixels. We design both the voxel and pixel branch based on CNNs to operate\nconvolutions on voxels/pixels represented in grids, and integrate an additional\npoint branch to regain the information lost during voxelization. We train our\nframework end-to-end by imposing supervisions directly on the predicted pose\ndistribution with a probabilistic PnP solver. To explore distinctive patterns\nof cross-modality features, we design a novel loss with adaptive-weighted\noptimization for cross-modality feature description. The experimental results\non KITTI and nuScenes datasets show significant improvements over the\nstate-of-the-art methods. The code and models are available at\nhttps://github.com/junshengzhou/VP2P-Match.",
            "author": [
                "Junsheng Zhou",
                "Baorui Ma",
                "Wenyuan Zhang",
                "Yi Fang",
                "Yu-Shen Liu",
                "Zhizhong Han"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04060v1",
                "http://arxiv.org/pdf/2312.04060v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04059v1",
            "title": "Comparing Large Language Model AI and Human-Generated Coaching Messages\n  for Behavioral Weight Loss",
            "updated": "2023-12-07T05:45:24Z",
            "published": "2023-12-07T05:45:24Z",
            "summary": "Automated coaching messages for weight control can save time and costs, but\ntheir repetitive, generic nature may limit their effectiveness compared to\nhuman coaching. Large language model (LLM) based artificial intelligence (AI)\nchatbots, like ChatGPT, could offer more personalized and novel messages to\naddress repetition with their data-processing abilities. While LLM AI\ndemonstrates promise to encourage healthier lifestyles, studies have yet to\nexamine the feasibility and acceptability of LLM-based BWL coaching. 87 adults\nin a weight-loss trial rated ten coaching messages' helpfulness (five\nhuman-written, five ChatGPT-generated) using a 5-point Likert scale, providing\nadditional open-ended feedback to justify their ratings. Participants also\nidentified which messages they believed were AI-generated. The evaluation\noccurred in two phases: messages in Phase 1 were perceived as impersonal and\nnegative, prompting revisions for Phase 2 messages. In Phase 1, AI-generated\nmessages were rated less helpful than human-written ones, with 66 percent\nreceiving a helpfulness rating of 3 or higher. However, in Phase 2, the AI\nmessages matched the human-written ones regarding helpfulness, with 82% scoring\nthree or above. Additionally, 50% were misidentified as human-written,\nsuggesting AI's sophistication in mimicking human-generated content. A thematic\nanalysis of open-ended feedback revealed that participants appreciated AI's\nempathy and personalized suggestions but found them more formulaic, less\nauthentic, and too data-focused. This study reveals the preliminary feasibility\nand acceptability of LLM AIs, like ChatGPT, in crafting potentially effective\nweight control coaching messages. Our findings also underscore areas for future\nenhancement.",
            "author": [
                "Zhuoran Huang",
                "Michael P. Berry",
                "Christina Chwyl",
                "Gary Hsieh",
                "Jing Wei",
                "Evan M. Forman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04059v1",
                "http://arxiv.org/pdf/2312.04059v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04057v1",
            "title": "UOCS-XI. Study of blue straggler stars in open cluster NGC 7142 using\n  UVIT/AstroSat",
            "updated": "2023-12-07T05:38:33Z",
            "published": "2023-12-07T05:38:33Z",
            "summary": "We present a study of blue straggler stars (BSSs) of open cluster NGC 7142\nusing AstroSat/UVIT data and other archival data. Using a machine\nlearning-based algorithm, ML-MOC, on Gaia DR3 data, we find 546 sources as\ncluster members. Based on the location on the Gaia color-magnitude diagram, we\nidentify ten BSS candidates, also detected in UVIT/F148W filter. We study the\nvariable nature of BSSs by constructing their light curves using the TESS data.\nTwo BSSs reported as eclipsing binaries in Gaia DR3 are confirmed to be\neclipsing binaries based on our analysis and also show the presence of hot\ncompanions as per the multi-wavelength spectral energy distributions (SEDs).\nThe physical parameters of the hot companions of these two BSSs derived by\nfitting binary models to their light curves and those derived from the SEDs are\nfound to be in good agreement. Additionally, five more BSSs in the cluster\nshows UV excess, four of which are likely to have a hot companion based on\nSEDs. The hot companions with the estimated temperatures $\\sim$14000 $-$ 28000\nK, radii $\\sim$0.01 $-$ 0.05 R$_{\\odot}$, and luminosities $\\sim$0.03 $-$ 0.1\nL$_{\\odot}$, are inferred to be extremely low mass ($<$ 0.2 M$_{\\odot}$),\nlow-mass (0.2 $-$ 0.4 M$_{\\odot}$), normal-mass (0.4 $-$ 0.6 M$_{\\odot}$), and\nhigh-mass ($>$ 0.6 M$_{\\odot}$) white dwarfs (WD). For the first time in an\nopen cluster, we find the entire range of masses in WDs found as hot companions\nof BSSs. These masses imply that the Case-A/Case-B mass transfer as well as\nmerger are responsible for the formation of at least 60$\\%$ of the BSSs of this\ncluster.",
            "author": [
                "Anju Panthi",
                "Kaushar Vaidya",
                "Nagaraj Vernekar",
                "Annapurni Subramaniam",
                "Vikrant Jadhav",
                "Manan Agarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04057v1",
                "http://arxiv.org/pdf/2312.04057v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04052v1",
            "title": "Multimodal Misinformation Detection in a South African Social Media\n  Environment",
            "updated": "2023-12-07T05:20:15Z",
            "published": "2023-12-07T05:20:15Z",
            "summary": "With the constant spread of misinformation on social media networks, a need\nhas arisen to continuously assess the veracity of digital content. This need\nhas inspired numerous research efforts on the development of misinformation\ndetection (MD) models. However, many models do not use all information\navailable to them and existing research contains a lack of relevant datasets to\ntrain the models, specifically within the South African social media\nenvironment. The aim of this paper is to investigate the transferability of\nknowledge of a MD model between different contextual environments. This\nresearch contributes a multimodal MD model capable of functioning in the South\nAfrican social media environment, as well as introduces a South African\nmisinformation dataset. The model makes use of multiple sources of information\nfor misinformation detection, namely: textual and visual elements. It uses\nbidirectional encoder representations from transformers (BERT) as the textual\nencoder and a residual network (ResNet) as the visual encoder. The model is\ntrained and evaluated on the Fakeddit dataset and a South African\nmisinformation dataset. Results show that using South African samples in the\ntraining of the model increases model performance, in a South African\ncontextual environment, and that a multimodal model retains significantly more\nknowledge than both the textual and visual unimodal models. Our study suggests\nthat the performance of a misinformation detection model is influenced by the\ncultural nuances of its operating environment and multimodal models assist in\nthe transferability of knowledge between different contextual environments.\nTherefore, local data should be incorporated into the training process of a\nmisinformation detection model in order to optimize model performance.",
            "author": [
                "Amica De Jager",
                "Vukosi Marivate",
                "Abioudun Modupe"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-49002-6_19",
                "http://arxiv.org/abs/2312.04052v1",
                "http://arxiv.org/pdf/2312.04052v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04047v1",
            "title": "Conformal Operator Content of the Wilson-Fisher Transition on Fuzzy\n  Sphere Bilayers",
            "updated": "2023-12-07T05:07:48Z",
            "published": "2023-12-07T05:07:48Z",
            "summary": "The Wilson-Fisher criticality provides a paradigm for a large class of phase\ntransitions in nature (e.g., helium, ferromagnets). In the three dimension,\nWilson-Fisher critical points are not exactly solvable due to the\nstrongly-correlated feature, so one has to resort to non-perturbative tools\nsuch as numerical simulations. Here, we design a microscopic model of\nHeisenberg magnet bilayer and study the underlying Wilson-Fisher\n$\\mathrm{O}(3)$ transition through the lens of fuzzy sphere regularization. We\nuncover a wealth of crucial information which directly reveals the emergent\nconformal symmetry regarding this fixed point. In specific, we accurately\ncalculate and analyze the energy spectra at the transition, and explicitly\nidentify the existence of a conserved Noether current, a stress tensor and\nrelevant primary fields. Most importantly, the primaries and their descendants\nform a fingerprint conformal tower structure, pointing to an almost perfect\nstate-operator correspondence. Furthermore, by examining the leading rank-4\nsymmetric tensor operator, we demonstrate the cubic perturbation is relevant,\nimplying the critical $\\mathrm{O}(3)$ model is unstable to cubic anisotropy, in\nagreement with the renormalization group and bootstrap calculations. The\nsuccessful dissection of conformal content of the Wilson-Fisher universality\nclass extends the horizon of the fuzzy sphere method and paves the way for\nexploring higher dimensional conformal field theories.",
            "author": [
                "Chao Han",
                "Liangdong Hu",
                "W. Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04047v1",
                "http://arxiv.org/pdf/2312.04047v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04045v1",
            "title": "Partial Information Breeds Systemic Risk",
            "updated": "2023-12-07T05:07:12Z",
            "published": "2023-12-07T05:07:12Z",
            "summary": "This paper considers finitely many investors who perform mean-variance\nportfolio selection under a relative performance criterion. That is, each\ninvestor is concerned about not only her terminal wealth, but how it compares\nto the average terminal wealth of all investors (i.e., the mean field). At the\ninter-personal level, each investor selects a trading strategy in response to\nothers' strategies (which affect the mean field). The selected strategy\nadditionally needs to yield an equilibrium intra-personally, so as to resolve\ntime inconsistency among the investor's current and future selves (triggered by\nthe mean-variance objective). A Nash equilibrium we look for is thus a tuple of\ntrading strategies under which every investor achieves her intra-personal\nequilibrium simultaneously. We derive such a Nash equilibrium explicitly in the\nidealized case of full information (i.e., the dynamics of the underlying stock\nis perfectly known), and semi-explicitly in the realistic case of partial\ninformation (i.e., the stock evolution is observed, but the expected return of\nthe stock is not precisely known). The formula under partial information\ninvolves an additional state process that serves to filter the true state of\nthe expected return. Its effect on trading is captured by two degenerate Cauchy\nproblems, one of which depends on the other, whose solutions are constructed by\nelliptic regularization and a stability analysis of the state process. Our\nresults indicate that partial information alone can reduce investors' wealth\nsignificantly, thereby causing or aggravating systemic risk. Intriguingly, in\ntwo different scenarios of the expected return (i.e., it is constant or\nalternating between two values), our Nash equilibrium formula spells out two\ndistinct manners systemic risk materializes.",
            "author": [
                "Yu-Jui Huang",
                "Li-Hsien Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04045v1",
                "http://arxiv.org/pdf/2312.04045v1"
            ],
            "primary_category": "q-fin.MF",
            "category": [
                "q-fin.MF",
                "math.OC",
                "91G45, 91A80, 93E11"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04044v1",
            "title": "Residual Graph Convolutional Network for Bird's-Eye-View Semantic\n  Segmentation",
            "updated": "2023-12-07T05:04:41Z",
            "published": "2023-12-07T05:04:41Z",
            "summary": "Retrieving spatial information and understanding the semantic information of\nthe surroundings are important for Bird's-Eye-View (BEV) semantic segmentation.\nIn the application of autonomous driving, autonomous vehicles need to be aware\nof their surroundings to drive safely. However, current BEV semantic\nsegmentation techniques, deep Convolutional Neural Networks (CNNs) and\ntransformers, have difficulties in obtaining the global semantic relationships\nof the surroundings at the early layers of the network. In this paper, we\npropose to incorporate a novel Residual Graph Convolutional (RGC) module in\ndeep CNNs to acquire both the global information and the region-level semantic\nrelationship in the multi-view image domain. Specifically, the RGC module\nemploys a non-overlapping graph space projection to efficiently project the\ncomplete BEV information into graph space. It then builds interconnected\nspatial and channel graphs to extract spatial information between each node and\nchannel information within each node (i.e., extract contextual relationships of\nthe global features). Furthermore, it uses a downsample residual process to\nenhance the coordinate feature reuse to maintain the global information. The\nsegmentation data augmentation and alignment module helps to simultaneously\naugment and align BEV features and ground truth to geometrically preserve their\nalignment to achieve better segmentation results. Our experimental results on\nthe nuScenes benchmark dataset demonstrate that the RGC network outperforms\nfour state-of-the-art networks and its four variants in terms of IoU and mIoU.\nThe proposed RGC network achieves a higher mIoU of 3.1% than the best\nstate-of-the-art network, BEVFusion. Code and models will be released.",
            "author": [
                "Qiuxiao Chen",
                "Xiaojun Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04044v1",
                "http://arxiv.org/pdf/2312.04044v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04043v1",
            "title": "Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes",
            "updated": "2023-12-07T05:04:33Z",
            "published": "2023-12-07T05:04:33Z",
            "summary": "In this paper, we democratise 3D content creation, enabling precise\ngeneration of 3D shapes from abstract sketches while overcoming limitations\ntied to drawing skills. We introduce a novel part-level modelling and alignment\nframework that facilitates abstraction modelling and cross-modal\ncorrespondence. Leveraging the same part-level decoder, our approach seamlessly\nextends to sketch modelling by establishing correspondence between CLIPasso\nedgemaps and projected 3D part regions, eliminating the need for a dataset\npairing human sketches and 3D shapes. Additionally, our method introduces a\nseamless in-position editing process as a byproduct of cross-modal part-aligned\nmodelling. Operating in a low-dimensional implicit space, our approach\nsignificantly reduces computational demands and processing time.",
            "author": [
                "Hmrishav Bandyopadhyay",
                "Subhadeep Koley",
                "Ayan Das",
                "Aneeshan Sain",
                "Pinaki Nath Chowdhury",
                "Tao Xiang",
                "Ayan Kumar Bhunia",
                "Yi-Zhe Song"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04043v1",
                "http://arxiv.org/pdf/2312.04043v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04041v1",
            "title": "Astronomy as a Field: A Guide for Aspiring Astrophysicists",
            "updated": "2023-12-07T05:00:41Z",
            "published": "2023-12-07T05:00:41Z",
            "summary": "This book was created as part of the SIRIUS B VERGE program to orient\nstudents to astrophysics as a broad field. The 2023-2024 VERGE program and the\nprinting of this book is funded by the Women and Girls in Astronomy Program via\nthe International Astronomical Union's North American Regional Office of\nAstronomy for Development and the Heising-Simons Foundation; as a result, this\ndocument is written by women in astronomy for girls who are looking to pursue\nthe field. However, given its universal nature, the material covered in this\nguide is useful for anyone interested in pursuing astrophysics professionally.",
            "author": [
                "Ava Polzin",
                "Yasmeen Asali",
                "Sanah Bhimani",
                "Madison Brady",
                "Mandy C. Chen",
                "Lindsay DeMarchi",
                "Michelle Gurevich",
                "Emily Lichko",
                "Emma Louden",
                "Julie Malewicz",
                "Samantha Pagan",
                "Malena Rice",
                "Zili Shen",
                "Emily Simon",
                "Candice Stauffer",
                "J. Luna Zagorac",
                "Katie Auchettl",
                "Katelyn Breivik",
                "Hsiao-Wen Chen",
                "Deanne Coppejans",
                "Sthabile Kolwa",
                "Raffaella Margutti",
                "Priyamvada Natarajan",
                "Erica Nelson",
                "Kim L. Page",
                "Silvia Toonen",
                "Katherine E. Whitaker",
                "Irina Zhuravleva"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04041v1",
                "http://arxiv.org/pdf/2312.04041v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "physics.ed-ph",
                "physics.pop-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04037v1",
            "title": "A Survey on Radar-Based Fall Detection",
            "updated": "2023-12-07T04:41:32Z",
            "published": "2023-12-07T04:41:32Z",
            "summary": "Fall detection, particularly critical for high-risk demographics like the\nelderly, is a key public health concern where timely detection can greatly\nminimize harm. With the advancements in radio frequency technology, radar has\nemerged as a powerful tool for human detection and tracking. Traditional\nmachine learning algorithms, such as Support Vector Machines (SVM) and\nk-Nearest Neighbors (kNN), have shown promising outcomes. However, deep\nlearning approaches, notably Convolutional Neural Networks (CNN) and Recurrent\nNeural Networks (RNN), have outperformed in learning intricate features and\nmanaging large, unstructured datasets. This survey offers an in-depth analysis\nof radar-based fall detection, with emphasis on Micro-Doppler, Range-Doppler,\nand Range-Doppler-Angles techniques. We discuss the intricacies and challenges\nin fall detection and emphasize the necessity for a clear definition of falls\nand appropriate detection criteria, informed by diverse influencing factors. We\npresent an overview of radar signal processing principles and the underlying\ntechnology of radar-based fall detection, providing an accessible insight into\nmachine learning and deep learning algorithms. After examining 74 research\narticles on radar-based fall detection published since 2000, we aim to bridge\ncurrent research gaps and underscore the potential future research strategies,\nemphasizing the real-world applications possibility and the unexplored\npotential of deep learning in improving radar-based fall detection.",
            "author": [
                "Shuting Hu",
                "Siyang Cao",
                "Nima Toosizadeh",
                "Jennifer Barton",
                "Melvin G. Hector",
                "Mindy J. Fain"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04037v1",
                "http://arxiv.org/pdf/2312.04037v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04036v1",
            "title": "DiffusionPhase: Motion Diffusion in Frequency Domain",
            "updated": "2023-12-07T04:39:22Z",
            "published": "2023-12-07T04:39:22Z",
            "summary": "In this study, we introduce a learning-based method for generating\nhigh-quality human motion sequences from text descriptions (e.g., ``A person\nwalks forward\"). Existing techniques struggle with motion diversity and smooth\ntransitions in generating arbitrary-length motion sequences, due to limited\ntext-to-motion datasets and the pose representations used that often lack\nexpressiveness or compactness. To address these issues, we propose the first\nmethod for text-conditioned human motion generation in the frequency domain of\nmotions. We develop a network encoder that converts the motion space into a\ncompact yet expressive parameterized phase space with high-frequency details\nencoded, capturing the local periodicity of motions in time and space with high\naccuracy. We also introduce a conditional diffusion model for predicting\nperiodic motion parameters based on text descriptions and a start pose,\nefficiently achieving smooth transitions between motion sequences associated\nwith different text descriptions. Experiments demonstrate that our approach\noutperforms current methods in generating a broader variety of high-quality\nmotions, and synthesizing long sequences with natural transitions.",
            "author": [
                "Weilin Wan",
                "Yiming Huang",
                "Shutong Wu",
                "Taku Komura",
                "Wenping Wang",
                "Dinesh Jayaraman",
                "Lingjie Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04036v1",
                "http://arxiv.org/pdf/2312.04036v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04035v1",
            "title": "Defense against ML-based Power Side-channel Attacks on DNN Accelerators\n  with Adversarial Attacks",
            "updated": "2023-12-07T04:38:01Z",
            "published": "2023-12-07T04:38:01Z",
            "summary": "Artificial Intelligence (AI) hardware accelerators have been widely adopted\nto enhance the efficiency of deep learning applications. However, they also\nraise security concerns regarding their vulnerability to power side-channel\nattacks (SCA). In these attacks, the adversary exploits unintended\ncommunication channels to infer sensitive information processed by the\naccelerator, posing significant privacy and copyright risks to the models.\nAdvanced machine learning algorithms are further employed to facilitate the\nside-channel analysis and exacerbate the privacy issue of AI accelerators.\nTraditional defense strategies naively inject execution noise to the runtime of\nAI models, which inevitably introduce large overheads.\n  In this paper, we present AIAShield, a novel defense methodology to safeguard\nFPGA-based AI accelerators and mitigate model extraction threats via\npower-based SCAs. The key insight of AIAShield is to leverage the prominent\nadversarial attack technique from the machine learning community to craft\ndelicate noise, which can significantly obfuscate the adversary's side-channel\nobservation while incurring minimal overhead to the execution of the protected\nmodel. At the hardware level, we design a new module based on ring oscillators\nto achieve fine-grained noise generation. At the algorithm level, we repurpose\nNeural Architecture Search to worsen the adversary's extraction results.\nExtensive experiments on the Nvidia Deep Learning Accelerator (NVDLA)\ndemonstrate that AIAShield outperforms existing solutions with excellent\ntransferability.",
            "author": [
                "Xiaobei Yan",
                "Chip Hong Chang",
                "Tianwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04035v1",
                "http://arxiv.org/pdf/2312.04035v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04034v1",
            "title": "Pseudogap formation in organic superconductors",
            "updated": "2023-12-07T04:28:43Z",
            "published": "2023-12-07T04:28:43Z",
            "summary": "The condensation of paired fermions into superfluid states changes\nprogressively depending on the coupling strength. At the midpoint of the\ncrossover between Bardeen--Cooper--Schrieffer (BCS) weak-coupling and\nBose--Einstein condensate (BEC) strong-coupling limits, paired fermions\ncondensate most robustly, thereby leading to the emergence of a pseudogap due\nto enhanced pairing fluctuations. In the case of electrons in solids,\nexcessively strong interactions often induce competing electronic orders\ninstead of strong-coupling superconductivity, and experimental comprehension of\nthe pseudogap remains incomplete. In this study, we provide experimental\nevidence demonstrating the opening of a pseudogap, marking the incipient stage\nof the BCS-BEC crossover in the organic system $\\kappa$-(BEDT-TTF)$_2$$X$. By\ncontrolling electron correlations, we investigate the thermodynamic properties\nof the BCS-BEC crossover and pseudogap phase. Since the superconductivity of\n$\\kappa$-(BEDT-TTF)$_2$$X$ arises from a simple Fermi liquid that does not\nexhibit any other electronic orders, our study shed light on the inherent\nnature of the BCS-BEC crossover.",
            "author": [
                "Shusaku Imajo",
                "Takuya Kobayashi",
                "Yuki Matsumura",
                "Taiki Maeda",
                "Yasuhiro Nakazawa",
                "Hiromi Taniguchi",
                "Koichi Kindo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04034v1",
                "http://arxiv.org/pdf/2312.04034v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04032v1",
            "title": "RoAST: Robustifying Language Models via Adversarial Perturbation with\n  Selective Training",
            "updated": "2023-12-07T04:23:36Z",
            "published": "2023-12-07T04:23:36Z",
            "summary": "Fine-tuning pre-trained language models (LMs) has become the de facto\nstandard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to\nrobustness issues, such as adversarial robustness and model calibration.\nSeveral perspectives of robustness for LMs have been studied independently, but\nlacking a unified consideration in multiple perspectives. In this paper, we\npropose Robustifying LMs via Adversarial perturbation with Selective Training\n(RoAST), a simple yet effective fine-tuning technique to enhance the\nmulti-perspective robustness of LMs in a unified way. RoAST effectively\nincorporates two important sources for the model robustness, robustness on the\nperturbed inputs and generalizable knowledge in pre-trained LMs. To be\nspecific, RoAST introduces adversarial perturbation during fine-tuning while\nthe model parameters are selectively updated upon their relative importance to\nminimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by\nincorporating four representative perspectives of model robustness, we\ndemonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning\nmethods on six different types of LMs, which indicates its usefulness in\npractice.",
            "author": [
                "Jaehyung Kim",
                "Yuning Mao",
                "Rui Hou",
                "Hanchao Yu",
                "Davis Liang",
                "Pascale Fung",
                "Qifan Wang",
                "Fuli Feng",
                "Lifu Huang",
                "Madian Khabsa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04032v1",
                "http://arxiv.org/pdf/2312.04032v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04024v1",
            "title": "k* Distribution: Evaluating the Latent Space of Deep Neural Networks\n  using Local Neighborhood Analysis",
            "updated": "2023-12-07T03:42:48Z",
            "published": "2023-12-07T03:42:48Z",
            "summary": "Most examinations of neural networks' learned latent spaces typically employ\ndimensionality reduction techniques such as t-SNE or UMAP. While these methods\neffectively capture the overall sample distribution in the entire learned\nlatent space, they tend to distort the structure of sample distributions within\nspecific classes in the subset of the latent space. This distortion complicates\nthe task of easily distinguishing classes identifiable by neural networks. In\nresponse to this challenge, we introduce the k* Distribution methodology. This\napproach focuses on capturing the characteristics and structure of sample\ndistributions for individual classes within the subset of the learned latent\nspace using local neighborhood analysis. The key concept is to facilitate easy\ncomparison of different k* distributions, enabling analysis of how various\nclasses are processed by the same neural network. This provides a more profound\nunderstanding of existing contemporary visualizations. Our study reveals three\ndistinct distributions of samples within the learned latent space subset: a)\nFractured, b) Overlapped, and c) Clustered. We note and demonstrate that the\ndistribution of samples within the network's learned latent space significantly\nvaries depending on the class. Furthermore, we illustrate that our analysis can\nbe applied to explore the latent space of diverse neural network architectures,\nvarious layers within neural networks, transformations applied to input\nsamples, and the distribution of training and testing data for neural networks.\nWe anticipate that our approach will facilitate more targeted investigations\ninto neural networks by collectively examining the distribution of different\nsamples within the learned latent space.",
            "author": [
                "Shashank Kotyan",
                "Ueda Tatsuya",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04024v1",
                "http://arxiv.org/pdf/2312.04024v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04022v1",
            "title": "Analysis of Coding Gain Due to In-Loop Reshaping",
            "updated": "2023-12-07T03:42:29Z",
            "published": "2023-12-07T03:42:29Z",
            "summary": "Reshaping, a point operation that alters the characteristics of signals, has\nbeen shown capable of improving the compression ratio in video coding\npractices. Out-of-loop reshaping that directly modifies the input video signal\nwas first adopted as the supplemental enhancement information~(SEI) for the\nHEVC/H.265 without the need of altering the core design of the video codec.\nVVC/H.266 further improves the coding efficiency by adopting in-loop reshaping\nthat modifies the residual signal being processed in the hybrid coding loop. In\nthis paper, we theoretically analyze the rate-distortion performance of the\nin-loop reshaping and use experiments to verify the theoretical result. We\nprove that the in-loop reshaping can improve coding efficiency when the entropy\ncoder adopted in the coding pipeline is suboptimal, which is in line with the\npractical scenarios that video codecs operate in. We derive the PSNR gain in a\nclosed form and show that the theoretically predicted gain is consistent with\nthat measured from experiments using standard testing video sequences.",
            "author": [
                "Chau-Wai Wong",
                "Chang-Hong Fu",
                "Mengting Xu",
                "Guan-Ming Su"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04022v1",
                "http://arxiv.org/pdf/2312.04022v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04021v1",
            "title": "A Study on the Calibration of In-context Learning",
            "updated": "2023-12-07T03:37:39Z",
            "published": "2023-12-07T03:37:39Z",
            "summary": "Modern auto-regressive language models are trained to minimize log loss on\nbroad data by predicting the next token so they are expected to get calibrated\nanswers when framing a problem as a next-token prediction task. We study this\nfor in-context learning (ICL), a widely used way to adapt frozen large language\nmodels (LLMs) via crafting prompts, and investigate the trade-offs between\nperformance and calibration on a wide range of natural language understanding\nand reasoning tasks. We conduct extensive experiments to show that such\ntrade-offs may get worse as we increase model size, incorporate more ICL\nexamples, and fine-tune models using instruction, dialog, or reinforcement\nlearning from human feedback (RLHF) on carefully curated datasets. Furthermore,\nwe find that common recalibration techniques that are widely effective such as\ntemperature scaling provide limited gains in calibration errors, suggesting\nthat new methods may be required for settings where models are expected to be\nreliable.",
            "author": [
                "Hanlin Zhang",
                "Yi-Fan Zhang",
                "Yaodong Yu",
                "Dhruv Madeka",
                "Dean Foster",
                "Eric Xing",
                "Hima Lakkaraju",
                "Sham Kakade"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04021v1",
                "http://arxiv.org/pdf/2312.04021v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04019v1",
            "title": "Efficiently Predicting Protein Stability Changes Upon Single-point\n  Mutation with Large Language Models",
            "updated": "2023-12-07T03:25:49Z",
            "published": "2023-12-07T03:25:49Z",
            "summary": "Predicting protein stability changes induced by single-point mutations has\nbeen a persistent challenge over the years, attracting immense interest from\nnumerous researchers. The ability to precisely predict protein thermostability\nis pivotal for various subfields and applications in biochemistry, including\ndrug development, protein evolution analysis, and enzyme synthesis. Despite the\nproposition of multiple methodologies aimed at addressing this issue, few\napproaches have successfully achieved optimal performance coupled with high\ncomputational efficiency. Two principal hurdles contribute to the existing\nchallenges in this domain. The first is the complexity of extracting and\naggregating sufficiently representative features from proteins. The second\nrefers to the limited availability of experimental data for protein mutation\nanalysis, further complicating the comprehensive evaluation of model\nperformance on unseen data samples. With the advent of Large Language\nModels(LLM), such as the ESM models in protein research, profound\ninterpretation of protein features is now accessibly aided by enormous training\ndata. Therefore, LLMs are indeed to facilitate a wide range of protein\nresearch. In our study, we introduce an ESM-assisted efficient approach that\nintegrates protein sequence and structural features to predict the\nthermostability changes in protein upon single-point mutations. Furthermore, we\nhave curated a dataset meticulously designed to preclude data leakage,\ncorresponding to two extensively employed test datasets, to facilitate a more\nequitable model comparison.",
            "author": [
                "Yijie Zhang",
                "Zhangyang Gao",
                "Cheng Tan",
                "Stan Z. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04019v1",
                "http://arxiv.org/pdf/2312.04019v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04018v1",
            "title": "Ricci-Notation Tensor Framework for Model-Based Approaches to Imaging",
            "updated": "2023-12-07T03:25:40Z",
            "published": "2023-12-07T03:25:40Z",
            "summary": "Model-based approaches to imaging, like specialized image enhancements in\nastronomy, favour physics-based models which facilitate explanations of\nrelationships between observed inputs and computed outputs. While this paper\nfeatures a tutorial example, inspired by exoplanet imaging, that reveals\nembedded 2D fast Fourier transforms in an image enhancement model, the work is\nactually about the tensor algebra and software, or tensor frameworks, available\nfor model-based imaging. The paper proposes a Ricci-notation tensor (RT)\nframework, comprising an extended Ricci notation, which aligns well with the\nsymbolic dual-index algebra of non-Euclidean geometry, and codesigned\nobject-oriented software, called the RTToolbox for MATLAB. Extensions offer\nnovel representations for entrywise, pagewise, and broadcasting operations\npopular in extended matrix-vector (EMV) frameworks for imaging. Complementing\nthe EMV algebra computable with MATLAB, the RTToolbox demonstrates programmatic\nand computational efficiency thanks to careful design of tensor and dual-index\nclasses. Compared to a numeric tensor predecessor, the RT framework enables\nsuperior ways to model imaging problems and, thereby, to develop solutions.",
            "author": [
                "Dileepan Joseph"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04018v1",
                "http://arxiv.org/pdf/2312.04018v1"
            ],
            "primary_category": "cs.MS",
            "category": [
                "cs.MS",
                "astro-ph.IM",
                "eess.IV",
                "G.4; I.4.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04016v1",
            "title": "PartDistill: 3D Shape Part Segmentation by Vision-Language Model\n  Distillation",
            "updated": "2023-12-07T03:10:03Z",
            "published": "2023-12-07T03:10:03Z",
            "summary": "This paper proposes a cross-modal distillation framework, PartDistill, which\ntransfers 2D knowledge from vision-language models (VLMs) to facilitate 3D\nshape part segmentation. PartDistill addresses three major challenges in this\ntask: the lack of 3D segmentation in invisible or undetected regions in the 2D\nprojections, inaccurate and inconsistent 2D predictions by VLMs, and the lack\nof knowledge accumulation across different 3D shapes. PartDistill consists of a\nteacher network that uses a VLM to make 2D predictions and a student network\nthat learns from the 2D predictions while extracting geometrical features from\nmultiple 3D shapes to carry out 3D part segmentation. A bi-directional\ndistillation, including forward and backward distillations, is carried out\nwithin the framework, where the former forward distills the 2D predictions to\nthe student network, and the latter improves the quality of the 2D predictions,\nwhich subsequently enhances the final 3D part segmentation. Moreover,\nPartDistill can exploit generative models that facilitate effortless 3D shape\ncreation for generating knowledge sources to be distilled. Through extensive\nexperiments, PartDistill boosts the existing methods with substantial margins\non widely used ShapeNetPart and PartE datasets, by more than 15% and 12% higher\nmIoU scores, respectively.",
            "author": [
                "Ardian Umam",
                "Cheng-Kun Yang",
                "Min-Hung Chen",
                "Jen-Hui Chuang",
                "Yen-Yu Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04016v1",
                "http://arxiv.org/pdf/2312.04016v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04013v1",
            "title": "A self-improvable Polymer Discovery Framework Based on Conditional\n  Generative Model",
            "updated": "2023-12-07T03:00:38Z",
            "published": "2023-12-07T03:00:38Z",
            "summary": "In this work, we introduce a polymer discovery platform designed to identify\npolymers with tailored properties efficiently, exemplified through the\ndiscovery of high-performance polymer electrolytes. The platform integrates\nthree core components: a conditioned generative model, validation modules, and\na feedback mechanism, creating a self-improving system for material innovation.\nTo demonstrate the efficacy of this platform, it is used to identify polymer\nelectrolyte materials with high ionic conductivity. A simple conditional\ngenerative model, based on the minGPT architecture, can effectively generate\ncandidate polymers that exhibit a mean ionic conductivity that is significantly\ngreater than those in the original training set. This approach, coupled with\nmolecular dynamics simulations for validation and a specifically designed\nacquisition mechanism, allows the platform to refine its output iteratively.\nNotably, after the first iteration, we observed an increase in both the mean\nand the lower bound of the ionic conductivity of the new polymer candidates.\nThe platform's effectiveness is underscored by the identification of 19 polymer\nrepeating units, each displaying a computed ionic conductivity surpassing that\nof Polyethylene Oxide (PEO). The discovery of these polymers validates the\nplatform's efficacy in identifying potential polymer materials. Acknowledging\ncurrent limitations, future work will focus on enhancing modeling techniques,\nvalidation processes, and acquisition strategies, aiming for broader\napplicability in polymer science and machine learning.",
            "author": [
                "Xiangyun Lei",
                "Weike Ye",
                "Zhenze Yang",
                "Daniel Schweigert",
                "Ha-Kyung Kwon",
                "Arash Khajeh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04013v1",
                "http://arxiv.org/pdf/2312.04013v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04008v1",
            "title": "Natural-language-driven Simulation Benchmark and Copilot for Efficient\n  Production of Object Interactions in Virtual Road Scenes",
            "updated": "2023-12-07T02:55:46Z",
            "published": "2023-12-07T02:55:46Z",
            "summary": "We advocate the idea of the natural-language-driven(NLD) simulation to\nefficiently produce the object interactions between multiple objects in the\nvirtual road scenes, for teaching and testing the autonomous driving systems\nthat should take quick action to avoid collision with obstacles with\nunpredictable motions. The NLD simulation allows the brief natural-language\ndescription to control the object interactions, significantly reducing the\nhuman efforts for creating a large amount of interaction data. To facilitate\nthe research of NLD simulation, we collect the Language-to-Interaction(L2I)\nbenchmark dataset with 120,000 natural-language descriptions of object\ninteractions in 6 common types of road topologies. Each description is\nassociated with the programming code, which the graphic render can use to\nvisually reconstruct the object interactions in the virtual scenes. As a\nmethodology contribution, we design SimCopilot to translate the interaction\ndescriptions to the renderable code. We use the L2I dataset to evaluate\nSimCopilot's abilities to control the object motions, generate complex\ninteractions, and generalize interactions across road topologies. The L2I\ndataset and the evaluation results motivate the relevant research of the NLD\nsimulation.",
            "author": [
                "Kairui Yang",
                "Zihao Guo",
                "Gengjie Lin",
                "Haotian Dong",
                "Die Zuo",
                "Jibin Peng",
                "Zhao Huang",
                "Zhecheng Xu",
                "Fupeng Li",
                "Ziyun Bai",
                "Di Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04008v1",
                "http://arxiv.org/pdf/2312.04008v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04005v1",
            "title": "KOALA: Self-Attention Matters in Knowledge Distillation of Latent\n  Diffusion Models for Memory-Efficient and Fast Image Synthesis",
            "updated": "2023-12-07T02:46:18Z",
            "published": "2023-12-07T02:46:18Z",
            "summary": "Stable diffusion is the mainstay of the text-to-image (T2I) synthesis in the\ncommunity due to its generation performance and open-source nature. Recently,\nStable Diffusion XL (SDXL), the successor of stable diffusion, has received a\nlot of attention due to its significant performance improvements with a higher\nresolution of 1024x1024 and a larger model. However, its increased computation\ncost and model size require higher-end hardware(e.g., bigger VRAM GPU) for\nend-users, incurring higher costs of operation. To address this problem, in\nthis work, we propose an efficient latent diffusion model for text-to-image\nsynthesis obtained by distilling the knowledge of SDXL. To this end, we first\nperform an in-depth analysis of the denoising U-Net in SDXL, which is the main\nbottleneck of the model, and then design a more efficient U-Net based on the\nanalysis. Secondly, we explore how to effectively distill the generation\ncapability of SDXL into an efficient U-Net and eventually identify four\nessential factors, the core of which is that self-attention is the most\nimportant part. With our efficient U-Net and self-attention-based knowledge\ndistillation strategy, we build our efficient T2I models, called KOALA-1B &\n-700M, while reducing the model size up to 54% and 69% of the original SDXL\nmodel. In particular, the KOALA-700M is more than twice as fast as SDXL while\nstill retaining a decent generation quality. We hope that due to its balanced\nspeed-performance tradeoff, our KOALA models can serve as a cost-effective\nalternative to SDXL in resource-constrained environments.",
            "author": [
                "Youngwan Lee",
                "Kwanyong Park",
                "Yoorhim Cho",
                "Yong-Ju Lee",
                "Sung Ju Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04005v1",
                "http://arxiv.org/pdf/2312.04005v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.04004v1",
            "title": "Occlusion-based Detection of Trojan-triggering Inputs in Large Language\n  Models of Code",
            "updated": "2023-12-07T02:44:35Z",
            "published": "2023-12-07T02:44:35Z",
            "summary": "Large language models (LLMs) are becoming an integrated part of software\ndevelopment. These models are trained on large datasets for code, where it is\nhard to verify each data point. Therefore, a potential attack surface can be to\ninject poisonous data into the training data to make models vulnerable, aka\ntrojaned. It can pose a significant threat by hiding manipulative behaviors\ninside models, leading to compromising the integrity of the models in\ndownstream tasks.\n  In this paper, we propose an occlusion-based human-in-the-loop technique,\nOSeql, to distinguish trojan-triggering inputs of code. The technique is based\non the observation that trojaned neural models of code rely heavily on the\ntriggering part of input; hence, its removal would change the confidence of the\nmodels in their prediction substantially. Our results suggest that OSeql can\ndetect the triggering inputs with almost 100% recall. We discuss the problem of\nfalse positives and how to address them. These results provide a baseline for\nfuture studies in this field.",
            "author": [
                "Aftab Hussain",
                "Md Rafiqul Islam Rabin",
                "Toufique Ahmed",
                "Mohammad Amin Alipour",
                "Bowen Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.04004v1",
                "http://arxiv.org/pdf/2312.04004v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03998v1",
            "title": "Series2Vec: Similarity-based Self-supervised Representation Learning for\n  Time Series Classification",
            "updated": "2023-12-07T02:30:40Z",
            "published": "2023-12-07T02:30:40Z",
            "summary": "We argue that time series analysis is fundamentally different in nature to\neither vision or natural language processing with respect to the forms of\nmeaningful self-supervised learning tasks that can be defined. Motivated by\nthis insight, we introduce a novel approach called \\textit{Series2Vec} for\nself-supervised representation learning. Unlike other self-supervised methods\nin time series, which carry the risk of positive sample variants being less\nsimilar to the anchor sample than series in the negative set, Series2Vec is\ntrained to predict the similarity between two series in both temporal and\nspectral domains through a self-supervised task. Series2Vec relies primarily on\nthe consistency of the unsupervised similarity step, rather than the intrinsic\nquality of the similarity measurement, without the need for hand-crafted data\naugmentation. To further enforce the network to learn similar representations\nfor similar time series, we propose a novel approach that applies\norder-invariant attention to each representation within the batch during\ntraining. Our evaluation of Series2Vec on nine large real-world datasets, along\nwith the UCR/UEA archive, shows enhanced performance compared to current\nstate-of-the-art self-supervised techniques for time series. Additionally, our\nextensive experiments show that Series2Vec performs comparably with fully\nsupervised training and offers high efficiency in datasets with limited-labeled\ndata. Finally, we show that the fusion of Series2Vec with other representation\nlearning models leads to enhanced performance for time series classification.\nCode and models are open-source at\n\\url{https://github.com/Navidfoumani/Series2Vec.}",
            "author": [
                "Navid Mohammadi Foumani",
                "Chang Wei Tan",
                "Geoffrey I. Webb",
                "Mahsa Salehi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03998v1",
                "http://arxiv.org/pdf/2312.03998v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03997v1",
            "title": "Asymmetrical post quench transport in an embedded parity time symmetric\n  Su-Schrieffer-Heeger system",
            "updated": "2023-12-07T02:28:23Z",
            "published": "2023-12-07T02:28:23Z",
            "summary": "We study the effect of PT-symmetric non-hermiticity on the transport of edge\nstate probability density arising as a result of a quench. A hybrid system\ninvolving a PT-symmetric SSH region sandwiched between two plain SSH systems is\ndesigned to study the dynamics. Geometrical arguments and numerical\ncalculations were made to ascertain the nature of edge states. We then compute\nthe quench dynamics numerically and demonstrate that the post-quench\nprobability density light cones exhibit contrasting shapes as a result of\nasymmetrical reflections from the non-Hermitian part of the system depending on\nthe direction of propagation of the transporting wave and, hence, on the\ninitial localization of the edge state.",
            "author": [
                "Anirban Ghosh",
                "Andy Martin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03997v1",
                "http://arxiv.org/pdf/2312.03997v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03995v1",
            "title": "The EDGE-CALIFA survey: Molecular Gas and Star Formation Activity Across\n  the Green Valley",
            "updated": "2023-12-07T02:21:42Z",
            "published": "2023-12-07T02:21:42Z",
            "summary": "We present a $^{12}$CO($J$=2-1) survey of 60 local galaxies using data from\nthe Atacama Large Millimeter/submillimeter Compact Array as part of the\nExtragalactic Database for Galaxy Evolution: the ACA EDGE survey. These\ngalaxies all have integral field spectroscopy from the CALIFA survey. Compared\nto other local galaxy surveys, ACA EDGE is designed to mitigate selection\neffects based on CO brightness and morphological type. Of the 60 galaxies in\nACA EDGE, 36 are on the star-formation main sequence, 13 are on the red\nsequence, and 11 lie in the ``green valley\" transition between these sequences.\nWe test how star formation quenching processes affect the star formation rate\n(SFR) per unit molecular gas mass, SFE$_{\\rm mol}=$SFR/$M_{\\rm mol}$, and\nrelated quantities in galaxies with stellar masses\n$10\\leq$log[$M_\\star/$M$_\\odot$]$\\leq11.5$ covering the full range of\nmorphological types. We observe a systematic decrease of the\nmolecular-to-stellar mass fraction ($R^{\\rm mol}_{\\star}$) with decreasing\nlevel of star formation activity, with green valley galaxies having also lower\nSFE$_{\\rm mol}$ than galaxies on the main sequence. On average, we find that\nthe spatially resolved SFE$_{\\rm mol}$ within the bulge region of green valley\ngalaxies is lower than in the bulges of main sequence galaxies if we adopt a\nconstant CO-to-H$_2$ conversion factor, $\\alpha_{\\rm CO}$. While efficiencies\nin main sequence galaxies remain almost constant with galactocentric radius, in\ngreen valley galaxies we note a systematic increase of SFE$_{\\rm mol}$, $R^{\\rm\nmol}_{\\star}$, and specific star formation rate, sSFR, with increasing radius.\nOur results suggest that although gas depletion (or removal) seems to be the\nmost important driver of the star-formation quenching in galaxies transiting\nthrough the green valley, a reduction in star formation efficiency is also\nrequired during this stage.",
            "author": [
                "Vicente Villanueva",
                "Alberto D. Bolatto",
                "Stuart N. Vogel",
                "Tony Wong",
                "Adam K. Leroy",
                "Sebastian F. Sanchez",
                "Rebecca C. Levy",
                "Erik Rosolowsky",
                "Dario Colombo",
                "Veselina Kalinova",
                "Serena Cronin",
                "Peter Teuben",
                "Monica Rubio",
                "Zein Bazzi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03995v1",
                "http://arxiv.org/pdf/2312.03995v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03993v1",
            "title": "Style Transfer to Calvin and Hobbes comics using Stable Diffusion",
            "updated": "2023-12-07T02:21:31Z",
            "published": "2023-12-07T02:21:31Z",
            "summary": "This project report summarizes our journey to perform stable diffusion\nfine-tuning on a dataset containing Calvin and Hobbes comics. The purpose is to\nconvert any given input image into the comic style of Calvin and Hobbes,\nessentially performing style transfer. We train stable-diffusion-v1.5 using Low\nRank Adaptation (LoRA) to efficiently speed up the fine-tuning process. The\ndiffusion itself is handled by a Variational Autoencoder (VAE), which is a\nU-net. Our results were visually appealing for the amount of training time and\nthe quality of input data that went into training.",
            "author": [
                "Sloke Shrestha",
                "Sundar Sripada V. S.",
                "Asvin Venkataramanan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03993v1",
                "http://arxiv.org/pdf/2312.03993v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03989v1",
            "title": "Rapid detection of rare events from in situ X-ray diffraction data using\n  machine learning",
            "updated": "2023-12-07T02:14:39Z",
            "published": "2023-12-07T02:14:39Z",
            "summary": "High-energy X-ray diffraction methods can non-destructively map the 3D\nmicrostructure and associated attributes of metallic polycrystalline\nengineering materials in their bulk form. These methods are often combined with\nexternal stimuli such as thermo-mechanical loading to take snapshots over time\nof the evolving microstructure and attributes. However, the extreme data\nvolumes and the high costs of traditional data acquisition and reduction\napproaches pose a barrier to quickly extracting actionable insights and\nimproving the temporal resolution of these snapshots. Here we present a fully\nautomated technique capable of rapidly detecting the onset of plasticity in\nhigh-energy X-ray microscopy data. Our technique is computationally faster by\nat least 50 times than the traditional approaches and works for data sets that\nare up to 9 times sparser than a full data set. This new technique leverages\nself-supervised image representation learning and clustering to transform\nmassive data into compact, semantic-rich representations of visually salient\ncharacteristics (e.g., peak shapes). These characteristics can be a rapid\nindicator of anomalous events such as changes in diffraction peak shapes. We\nanticipate that this technique will provide just-in-time actionable information\nto drive smarter experiments that effectively deploy multi-modal X-ray\ndiffraction methods that span many decades of length scales.",
            "author": [
                "Weijian Zheng",
                "Jun-Sang Park",
                "Peter Kenesei",
                "Ahsan Ali",
                "Zhengchun Liu",
                "Ian T. Foster",
                "Nicholas Schwarz",
                "Rajkumar Kettimuthu",
                "Antonino Miceli",
                "Hemant Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03989v1",
                "http://arxiv.org/pdf/2312.03989v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci",
                "eess.IV",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03988v1",
            "title": "Enhanced high-dimensional teleportation in correlated amplitude damping\n  noise by weak measurement and environment-assisted measurement",
            "updated": "2023-12-07T02:09:59Z",
            "published": "2023-12-07T02:09:59Z",
            "summary": "High-dimensional teleportation provides various benefits in quantum networks\nand repeaters, but all these advantages rely on the high-quality distribution\nof high-dimensional entanglement over a noisy channel. It is essential to\nconsider correlation effects when two entangled qutrits travel consecutively\nthrough the same channel. In this paper, we present two strategies for\nenhancing qutrit teleportation in correlated amplitude damping (CAD) noise by\nweak measurement (WM) and environment-assisted measurement (EAM). The fidelity\nof both approaches has been dramatically improved due to the probabilistic\nnature of WM and EAM. We have observed that the correlation effects of CAD\nnoise result in an increase in the probability of success. A comparison has\ndemonstrated that the EAM scheme consistently outperforms the WM scheme in\nregard to fidelity. Our research expands the capabilities of WM and EAM as\nquantum techniques to combat CAD noise in qutrit teleportation, facilitating\nthe development of advanced quantum technologies in high-dimensional systems.",
            "author": [
                "Xing Xiao",
                "Tian-Xiang Lu",
                "Yan-Ling Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03988v1",
                "http://arxiv.org/pdf/2312.03988v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03987v1",
            "title": "Cost-Effective In-Context Learning for Entity Resolution: A Design Space\n  Exploration",
            "updated": "2023-12-07T02:09:27Z",
            "published": "2023-12-07T02:09:27Z",
            "summary": "Entity resolution (ER) is an important data integration task with a wide\nspectrum of applications. The state-of-the-art solutions on ER rely on\npre-trained language models (PLMs), which require fine-tuning on a lot of\nlabeled matching/non-matching entity pairs. Recently, large languages models\n(LLMs), such as GPT-4, have shown the ability to perform many tasks without\ntuning model parameters, which is known as in-context learning (ICL) that\nfacilitates effective learning from a few labeled input context demonstrations.\nHowever, existing ICL approaches to ER typically necessitate providing a task\ndescription and a set of demonstrations for each entity pair and thus have\nlimitations on the monetary cost of interfacing LLMs. To address the problem,\nin this paper, we provide a comprehensive study to investigate how to develop a\ncost-effective batch prompting approach to ER. We introduce a framework BATCHER\nconsisting of demonstration selection and question batching and explore\ndifferent design choices that support batch prompting for ER. We also devise a\ncovering-based demonstration selection strategy that achieves an effective\nbalance between matching accuracy and monetary cost. We conduct a thorough\nevaluation to explore the design space and evaluate our proposed strategies.\nThrough extensive experiments, we find that batch prompting is very\ncost-effective for ER, compared with not only PLM-based methods fine-tuned with\nextensive labeled data but also LLM-based methods with manually designed\nprompting. We also provide guidance for selecting appropriate design choices\nfor batch prompting.",
            "author": [
                "Meihao Fan",
                "Xiaoyue Han",
                "Ju Fan",
                "Chengliang Chai",
                "Nan Tang",
                "Guoliang Li",
                "Xiaoyong Du"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03987v1",
                "http://arxiv.org/pdf/2312.03987v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03986v1",
            "title": "An Unsupervised Machine Learning Scheme for Index-Based CSI Feedback in\n  Wi-Fi",
            "updated": "2023-12-07T02:04:32Z",
            "published": "2023-12-07T02:04:32Z",
            "summary": "With the ever-increasing demand for high-speed wireless data transmission,\nbeamforming techniques have been proven to be crucial in improving the data\nrate and the signal-to-noise ratio (SNR) at the receiver. However, they require\nfeedback mechanisms that need an overhead of information and increase the\nsystem complexity, potentially challenging the efficiency and capacity of\nmodern wireless networks. This paper investigates novel index-based feedback\nmechanisms that aim at reducing the beamforming feedback overhead in Wi-Fi\nlinks. The proposed methods mitigate the overhead by generating a set of\ncandidate beamforming vectors using an unsupervised learning-based framework.\nThe amount of feedback information required is thus reduced by using the index\nof the candidate as feedback instead of transmitting the entire beamforming\nmatrix. We explore several methods that consider different representations of\nthe data in the candidate set. In particular, we propose five different ways to\ngenerate and represent the candidate sets that consider the covariance matrices\nof the channel, serialize the feedback matrix, and account for the effective\ndistance, among others. Additionally, we also discuss the implications of using\npartial information in the compressed beamforming feedback on the link\nperformance and compare it with the newly proposed index-based methods.\nExtensive IEEE 802.11 standard-compliant simulation results show that the\nproposed methods effectively minimize the feedback overhead, enhancing the\nthroughput while maintaining an adequate link performance.",
            "author": [
                "Mrugen Deshmukh",
                "Zinan Lin",
                "Hanqing Lou",
                "Mahmoud Kamel",
                "Rui Yang",
                "Ismail Guvenc"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03986v1",
                "http://arxiv.org/pdf/2312.03986v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03985v1",
            "title": "Flux tunable graphene-based superconducting quantum circuits coupled to\n  3D cavity",
            "updated": "2023-12-07T02:04:10Z",
            "published": "2023-12-07T02:04:10Z",
            "summary": "Correlation between transmon and its composite Josephson junctions (JJ) plays\nan important role in designing new types of superconducting qubits based on\nquantum materials. It is desirable to have a type of device that not only\nallows exploration for use in quantum information processing but also probing\nintrinsic properties in the composite JJs. Here, we construct a flux-tunable 3D\ntransmon-type superconducting quantum circuit made of graphene as a\nproof-of-concept prototype device. This 3D transmon-type device not only\nenables coupling to 3D cavities for microwave probes but also permits DC\ntransport measurements on the same device, providing useful connections between\ntransmon properties and critical currents associated with JJ's properties. We\nhave demonstrated how flux-modulation in cavity frequency and DC critical\ncurrent can be correlated under the influence of Fraunhofer pattern of JJs in\nan asymmetric SQUID. The correlation analysis was further extended to link the\nflux-modulated transmon properties, such as flux-tunability in qubit and cavity\nfrequencies, with SQUID symmetry analysis based on DC measurements. Our study\npaves the way towards integrating novel materials for exploration of new types\nof quantum devices for future technology while probing underlying physics in\nthe composite materials.",
            "author": [
                "Kuei-Lin Chiu",
                "Youyi Chang",
                "Avishma J. Lasrado",
                "Cheng-Han Lo",
                "Yung-Hsiang Chen",
                "Tao-Yi Hsu",
                "Yen-Chih Chen",
                "Yi-Chen Tsai",
                "Samina",
                "Yen-Hsiang Lin",
                "Chung-Ting Ke"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03985v1",
                "http://arxiv.org/pdf/2312.03985v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03984v1",
            "title": "Taking control of compressible modes: bulk viscosity and the turbulent\n  dynamo",
            "updated": "2023-12-07T02:03:51Z",
            "published": "2023-12-07T02:03:51Z",
            "summary": "Many polyatomic astrophysical plasmas are compressible and out of chemical\nand thermal equilibrium, and yet, due to Stokes' hypothesis, a means to\ncarefully control the decay of compressible modes in these systems has largely\nbeen neglected. This is especially important for small-scale, turbulent dynamo\nprocesses, which are known to be sensitive to the effects of compression. To\ncontrol the viscous properties of the compressible modes, we perform\nsupersonic, visco-resistive dynamo simulations with additional bulk viscosity\n$\\nu_{\\rm bulk}$, deriving a new $\\nu_{\\rm bulk}$ Reynolds number $\\rm{Re}_{\\rm\nbulk}$, and viscous Prandtl number $\\rm{P}\\nu \\equiv \\rm{Re}_{\\rm bulk} /\n\\rm{Re}_{\\rm shear}$, where $\\rm{Re}_{\\rm shear}$ is the shear viscosity\nReynolds number. For $10^{-3} \\leq \\rm{P}\\nu \\leq \\infty$, we explore a broad\nrange of statistics critical to the dynamo problem, including the integral and\nspectral energy ratios, growth rates, and the magnetic $E_{\\rm mag}(k)$ and\nkinetic $E_{\\rm kin}(k)$ energy spectrum. We derive a general framework for\ndecomposing $E_{\\rm mag}$ growth rates into incompressible and compressible\nterms via orthogonal tensor decompositions of $\\nabla\\otimes\\mathbf{v}$, where\n$\\mathbf{v}$ is the fluid velocity. We find that compressible modes play a dual\nrole, growing and decaying $E_{\\rm mag}$, and that field-line stretching is the\nmain driver of growth, even in supersonic dynamos. In the absence of $\\nu_{\\rm\nbulk}$, compressible modes pile up on small-scales, creating an apparent\nspectral bottleneck, which disappears for $\\rm{P}\\nu \\approx 1$. As $\\rm{P}\\nu$\ndecreases, compressible modes are dissipated at increasingly larger scales, in\nturn suppressing incompressible modes through a coupling between viscosity\noperators. We emphasise the importance of further understanding the role of\n$\\nu_{\\rm bulk}$ in compressible astrophysical plasmas.",
            "author": [
                "James R. Beattie",
                "Christoph Federrath",
                "Neco Kriel",
                "Justin Kin Jun Hew",
                "Amitava Bhattacharjee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03984v1",
                "http://arxiv.org/pdf/2312.03984v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.HE",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03982v1",
            "title": "Logical quantum processor based on reconfigurable atom arrays",
            "updated": "2023-12-07T01:54:45Z",
            "published": "2023-12-07T01:54:45Z",
            "summary": "Suppressing errors is the central challenge for useful quantum computing,\nrequiring quantum error correction for large-scale processing. However, the\noverhead in the realization of error-corrected ``logical'' qubits, where\ninformation is encoded across many physical qubits for redundancy, poses\nsignificant challenges to large-scale logical quantum computing. Here we report\nthe realization of a programmable quantum processor based on encoded logical\nqubits operating with up to 280 physical qubits. Utilizing logical-level\ncontrol and a zoned architecture in reconfigurable neutral atom arrays, our\nsystem combines high two-qubit gate fidelities, arbitrary connectivity, as well\nas fully programmable single-qubit rotations and mid-circuit readout. Operating\nthis logical processor with various types of encodings, we demonstrate\nimprovement of a two-qubit logic gate by scaling surface code distance from d=3\nto d=7, preparation of color code qubits with break-even fidelities,\nfault-tolerant creation of logical GHZ states and feedforward entanglement\nteleportation, as well as operation of 40 color code qubits. Finally, using\nthree-dimensional [[8,3,2]] code blocks, we realize computationally complex\nsampling circuits with up to 48 logical qubits entangled with hypercube\nconnectivity with 228 logical two-qubit gates and 48 logical CCZ gates. We find\nthat this logical encoding substantially improves algorithmic performance with\nerror detection, outperforming physical qubit fidelities at both cross-entropy\nbenchmarking and quantum simulations of fast scrambling. These results herald\nthe advent of early error-corrected quantum computation and chart a path toward\nlarge-scale logical processors.",
            "author": [
                "Dolev Bluvstein",
                "Simon J. Evered",
                "Alexandra A. Geim",
                "Sophie H. Li",
                "Hengyun Zhou",
                "Tom Manovitz",
                "Sepehr Ebadi",
                "Madelyn Cain",
                "Marcin Kalinowski",
                "Dominik Hangleiter",
                "J. Pablo Bonilla Ataides",
                "Nishad Maskara",
                "Iris Cong",
                "Xun Gao",
                "Pedro Sales Rodriguez",
                "Thomas Karolyshyn",
                "Giulia Semeghini",
                "Michael J. Gullans",
                "Markus Greiner",
                "Vladan Vuletic",
                "Mikhail D. Lukin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03982v1",
                "http://arxiv.org/pdf/2312.03982v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.quant-gas",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03978v1",
            "title": "Enhanced Index-Based Feedback Overhead Reduction for WLANs",
            "updated": "2023-12-07T01:24:13Z",
            "published": "2023-12-07T01:24:13Z",
            "summary": "Compressed beamforming algorithm is used in the current Wi-Fi standard to\nreduce the beamforming feedback overhead (BFO). However, with each new\namendment of the standard the number of supported antennas in Wi-Fi devices\nincreases, leading to increased BFO and hampering the throughput despite using\ncompressed beamforming. In this paper, a novel index-based method is presented\nto reduce the BFO in Wi-Fi links. In particular, a k-means clustering-based\napproach is presented to generate candidate beamforming feedback matrices,\nthereby reducing the BFO to only the index of the said candidate matrices. With\nextensive simulation results, we compare the newly proposed method with the\nIEEE 802.11be baseline and our previously published index-based method. We show\napproximately 54% gain in throughput at high signal-to-noise (SNR) against the\nIEEE 802.11be baseline. Our comparison also shows approximately 4 dB gain\ncompared to our previously published method at the packet-error-rate (PER) of\n0.01 using MCS index 11. Additionally, we also discuss the impact of the\ndistance metric chosen for clustering as well as candidate selection on the\nlink performance.",
            "author": [
                "Mrugen Deshmukh",
                "Zinan Lin",
                "Hanqing Lou",
                "Mahmoud Kamel",
                "Rui Yang",
                "Ismail Guvenc"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03978v1",
                "http://arxiv.org/pdf/2312.03978v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03977v1",
            "title": "RIS-Aided Interference Cancellation for Joint Device-to-Device and\n  Cellular Communications",
            "updated": "2023-12-07T01:23:18Z",
            "published": "2023-12-07T01:23:18Z",
            "summary": "Joint device-to-device (D2D) and cellular communication is a promising\ntechnology for enhancing the spectral efficiency of future wireless networks.\nHowever, the interference management problem is challenging since the operating\ndevices and the cellular users share the same spectrum. The emerging\nreconfigurable intelligent surfaces (RIS) technology is a potentially ideal\nsolution for this interference problem since RISs can shape the wireless\nchannel in desired ways. This paper considers an RIS-aided joint D2D and\ncellular communication system where the RIS is exploited to cancel interference\nto the D2D links and maximize the minimum signal-to-interference plus noise\n(SINR) of the device pairs and cellular users. First, we adopt a popular\nalternating optimization (AO) approach to solve the minimum SINR maximization\nproblem. Then, we propose an interference cancellation (IC)-based approach\nwhose complexity is much lower than that of the AO algorithm. We derive a\nrepresentation for the RIS phase shift vector which cancels the interference to\nthe D2D links. Based on this representation, the RIS phase shift optimization\nproblem is transformed into an effective D2D channel optimization. We show that\nthe AO approach can converge faster and can even give better performance when\nit is initialized by the proposed IC solution. We also show that for the case\nof a single D2D pair, the proposed IC approach can be implemented with limited\nfeedback from the single receive device.",
            "author": [
                "Ly V. Nguyen",
                "A. Lee Swindlehurst"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03977v1",
                "http://arxiv.org/pdf/2312.03977v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03973v1",
            "title": "Physical Models for the Astrophysical Population of Black Holes:\n  Application to the Bump in the Mass Distribution of Gravitational Wave\n  Sources",
            "updated": "2023-12-07T01:18:05Z",
            "published": "2023-12-07T01:18:05Z",
            "summary": "Gravitational wave observations of binary black holes have revealed\nunexpected structure in the black hole mass distribution. Previous studies of\nthe mass distribution employ physically-motivated phenomenological models and\ninfer the parameters that directly control the features of the mass\ndistribution that are allowed in their model, associating the constraints on\nthose parameters with their physical motivations. In this work, we take an\nalternative approach in which we introduce a model parameterizing the\nunderlying stellar and core-collapse physics and obtaining the remnant black\nhole distribution as a derived byproduct. In doing so, we directly constrain\nthe stellar physics necessary to explain the astrophysical distribution of\nblack hole properties under a given model. We apply this approach to modeling\nthe mapping between stellar core mass and remnant black hole mass, including\nthe effects of mass loss due to the pulsational pair instability supernova\n(PPISN) process, which has been proposed as an explanation for the observed\nexcess of black holes at $\\sim 35 M_\\odot$. Placing constraints on the nuclear\nreaction rates necessary to explain the PPISN parameters, we conclude that the\npeak observed at $\\sim 35 M_\\odot$ is highly unlikely to be a signature from\nthe PPISN process. This procedure can be applied to modeling any physical\nprocess that underlies the astrophysical mass distribution. Allowing the\nparameters of the core-remnant mass relationship to evolve with redshift\npermits correlated and physically reasonable changes in the location, shape,\nand amplitude of features in the mass function. We find that the current data\nare consistent with no redshift evolution in the core-remnant mass\nrelationship, but ultimately place only weak constraints on the change of these\nparameters.",
            "author": [
                "Jacob Golomb",
                "Maximiliano Isi",
                "Will Farr"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03973v1",
                "http://arxiv.org/pdf/2312.03973v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03970v1",
            "title": "Improving Medical Report Generation with Adapter Tuning and Knowledge\n  Enhancement in Vision-Language Foundation Models",
            "updated": "2023-12-07T01:01:45Z",
            "published": "2023-12-07T01:01:45Z",
            "summary": "Medical report generation demands automatic creation of coherent and precise\ndescriptions for medical images. However, the scarcity of labelled medical\nimage-report pairs poses formidable challenges in developing large-scale neural\nnetworks capable of harnessing the potential of artificial intelligence,\nexemplified by large language models. This study builds upon the\nstate-of-the-art vision-language pre-training and fine-tuning approach, BLIP-2,\nto customize general large-scale foundation models. Integrating adapter tuning\nand a medical knowledge enhancement loss, our model significantly improves\naccuracy and coherence. Validation on the dataset of ImageCLEFmedical 2023\ndemonstrates our model's prowess, achieving the best-averaged results against\nseveral state-of-the-art methods. Significant improvements in ROUGE and CIDEr\nunderscore our method's efficacy, highlighting promising outcomes for the rapid\nmedical-domain adaptation of the vision-language foundation models in\naddressing challenges posed by data scarcity.",
            "author": [
                "Shibin Wu",
                "Bang Yang",
                "Zhiyu Ye",
                "Haoqian Wang",
                "Hairong Zheng",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03970v1",
                "http://arxiv.org/pdf/2312.03970v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03955v1",
            "title": "Properties of Relativistic Bouncing Microbursts",
            "updated": "2023-12-06T23:46:04Z",
            "published": "2023-12-06T23:46:04Z",
            "summary": "Microbursts are short duration intensifications in precipitating electron\nflux that are believed to be a significant contributor to electron losses in\nthe magnetosphere. Microbursts have been observed in the form of bouncing\nelectron packets, which offer a unique opportunity to study the properties of\nmicrobursts and their importance as a loss process. We present a collection of\nbouncing microbursts observed by the HILT instrument on SAMPEX from\n1994-2004.We analyze the locations of the bouncing microbursts in L and MLT and\nfind they align well with the properties of relativistic microbursts as a\nwhole. We find that that the majority of bouncing microbursts observed by\nSAMPEX have scale sizes of 30km at the point of observation, or about 1500km\nwhen mapped to the equator.The time separation between the peaks of these\nbouncing microbursts is usually either half a bounce period or a whole bounce\nperiod.",
            "author": [
                "Wyatt Wetzel",
                "John Sample",
                "Eric Engel",
                "Mykhaylo Shumko"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03955v1",
                "http://arxiv.org/pdf/2312.03955v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03950v1",
            "title": "A Scalable and Generalizable Pathloss Map Prediction",
            "updated": "2023-12-06T23:22:49Z",
            "published": "2023-12-06T23:22:49Z",
            "summary": "Large-scale channel prediction, i.e., estimation of the pathloss from\ngeographical/morphological/building maps, is an essential component of wireless\nnetwork planning. Ray tracing (RT)-based methods have been widely used for many\nyears, but they require significant computational effort that may become\nprohibitive with the increased network densification and/or use of higher\nfrequencies in B5G/6G systems. In this paper, we propose a data-driven,\nmodel-free pathloss map prediction (PMP) method, called PMNet. PMNet uses a\nsupervised learning approach: it is trained on a limited amount of RT (or\nchannel measurement) data and map data. Once trained, PMNet can predict\npathloss over location with high accuracy (an RMSE level of $10^{-2}$) in a few\nmilliseconds. We further extend PMNet by employing transfer learning (TL). TL\nallows PMNet to learn a new network scenario quickly (x5.6 faster training) and\nefficiently (using x4.5 less data) by transferring knowledge from a pre-trained\nmodel, while retaining accuracy. Our results demonstrate that PMNet is a\nscalable and generalizable ML-based PMP method, showing its potential to be\nused in several network optimization applications.",
            "author": [
                "Ju-Hyung Lee",
                "Andreas F. Molisch"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03950v1",
                "http://arxiv.org/pdf/2312.03950v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03938v1",
            "title": "Adapting HouseDiffusion for conditional Floor Plan generation on\n  Modified Swiss Dwellings dataset",
            "updated": "2023-12-06T22:35:59Z",
            "published": "2023-12-06T22:35:59Z",
            "summary": "Automated floor plan generation has recently gained momentum with several\nmethods that have been proposed. The CVAAD Floor Plan Auto-Completion workshop\nchallenge introduced MSD, a new dataset that includes existing structural walls\nof the building as an additional input constraint. This technical report\npresents an approach for extending a recent work, HouseDiffusion\n(arXiv:2211.13287 [cs.CV]), to the MSD dataset. The adaption involves modifying\nthe model's transformer layers to condition on a set of wall lines. The report\nintroduces a pre-processing pipeline to extract wall lines from the binary mask\nof the building structure provided as input. Additionally, it was found that a\ndata processing procedure that simplifies all room polygons to rectangles leads\nto better performance. This indicates that future work should explore better\nrepresentations of variable-length polygons in diffusion models. The code will\nbe made available at a later date.",
            "author": [
                "Emanuel Kuhn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03938v1",
                "http://arxiv.org/pdf/2312.03938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03936v1",
            "title": "The Potential of Vision-Language Models for Content Moderation of\n  Children's Videos",
            "updated": "2023-12-06T22:29:16Z",
            "published": "2023-12-06T22:29:16Z",
            "summary": "Natural language supervision has been shown to be effective for zero-shot\nlearning in many computer vision tasks, such as object detection and activity\nrecognition. However, generating informative prompts can be challenging for\nmore subtle tasks, such as video content moderation. This can be difficult, as\nthere are many reasons why a video might be inappropriate, beyond violence and\nobscenity. For example, scammers may attempt to create junk content that is\nsimilar to popular educational videos but with no meaningful information. This\npaper evaluates the performance of several CLIP variations for content\nmoderation of children's cartoons in both the supervised and zero-shot setting.\nWe show that our proposed model (Vanilla CLIP with Projection Layer)\noutperforms previous work conducted on the Malicious or Benign (MOB) benchmark\nfor video content moderation. This paper presents an in depth analysis of how\ncontext-specific language prompts affect content moderation performance. Our\nresults indicate that it is important to include more context in content\nmoderation prompts, particularly for cartoon videos as they are not well\nrepresented in the CLIP training data.",
            "author": [
                "Syed Hammad Ahmed",
                "Shengnan Hu",
                "Gita Sukthankar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03936v1",
                "http://arxiv.org/pdf/2312.03936v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03929v1",
            "title": "Simulation of a L\u00e9vy process, its extremum, and hitting time of the\n  extremum via characteristic functions",
            "updated": "2023-12-06T22:11:20Z",
            "published": "2023-12-06T22:11:20Z",
            "summary": "We suggest a general framework for simulation of the triplet $(X_T,\\bar X_\nT,\\tau_T)$ (L\\'evy process, its extremum, and hitting time of the extremum),\nand, separately, $X_T,\\bar X_ T$ and pairs $(X_T,\\bar X_ T)$, $(\\bar X_\nT,\\tau_T)$,\n  $(\\bar X_ T-X_T,\\tau_T)$, via characteristic functions and conditional\ncharacteristic functions. The conformal deformations technique allows one to\nevaluate probability distributions, joint probability distributions and\nconditional probability distributions accurately and fast. For simulations in\nthe far tails of the distribution, we precalculate and store the values of the\n(conditional) characteristic functions on multi-grids on appropriate surfaces\nin $C^n$, and use these values to calculate the quantiles in the tails. For\nsimulation in the central part of a distribution, we precalculate the values of\nthe cumulative distribution at points of a non-uniform (multi-)grid, and use\ninterpolation to calculate quantiles.",
            "author": [
                "Svetlana Boyarchenko",
                "Sergei Levendorskii"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03929v1",
                "http://arxiv.org/pdf/2312.03929v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "math.PR",
                "60-08, 42A38, 42B10, 44A10, 65R10, 65G51, 91G20, 91G60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03928v1",
            "title": "Adaptive Weighted Co-Learning for Cross-Domain Few-Shot Learning",
            "updated": "2023-12-06T22:09:52Z",
            "published": "2023-12-06T22:09:52Z",
            "summary": "Due to the availability of only a few labeled instances for the novel target\nprediction task and the significant domain shift between the well annotated\nsource domain and the target domain, cross-domain few-shot learning (CDFSL)\ninduces a very challenging adaptation problem. In this paper, we propose a\nsimple Adaptive Weighted Co-Learning (AWCoL) method to address the CDFSL\nchallenge by adapting two independently trained source prototypical\nclassification models to the target task in a weighted co-learning manner. The\nproposed method deploys a weighted moving average prediction strategy to\ngenerate probabilistic predictions from each model, and then conducts adaptive\nco-learning by jointly fine-tuning the two models in an alternating manner\nbased on the pseudo-labels and instance weights produced from the predictions.\nMoreover, a negative pseudo-labeling regularizer is further deployed to improve\nthe fine-tuning process by penalizing false predictions. Comprehensive\nexperiments are conducted on multiple benchmark datasets and the empirical\nresults demonstrate that the proposed method produces state-of-the-art CDFSL\nperformance.",
            "author": [
                "Abdullah Alchihabi",
                "Marzi Heidari",
                "Yuhong Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03928v1",
                "http://arxiv.org/pdf/2312.03928v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03922v1",
            "title": "Slepian Beamforming: Broadband Beamforming using Streaming Least Squares",
            "updated": "2023-12-06T21:47:58Z",
            "published": "2023-12-06T21:47:58Z",
            "summary": "In this paper we revisit the classical problem of estimating a signal as it\nimpinges on a multi-sensor array. We focus on the case where the impinging\nsignal's bandwidth is appreciable and is operating in a broadband regime.\nEstimating broadband signals, often termed broadband (or wideband) beamforming,\nis traditionally done through filter and summation, true time delay, or a\ncoupling of the two. Our proposed method deviates substantially from these\nparadigms in that it requires no notion of filtering or true time delay. We use\nblocks of samples taken directly from the sensor outputs to fit a robust\nSlepian subspace model using a least squares approach. We then leverage this\nmodel to estimate uniformly spaced samples of the impinging signal. Alongside a\ncareful discussion of this model and how to choose its parameters we show how\nto fit the model to new blocks of samples as they are received, producing a\nstreaming output. We then go on to show how this method naturally extends to\nadaptive beamforming scenarios, where we leverage signal statistics to\nattenuate interfering sources. Finally, we discuss how to use our model to\nestimate from dimensionality reducing measurements. Accompanying these\ndiscussions are extensive numerical experiments establishing that our method\noutperforms existing filter based approaches while being comparable in terms of\ncomputational complexity.",
            "author": [
                "Coleman DeLude",
                "Mark A. Davenport",
                "Justin Romberg"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03922v1",
                "http://arxiv.org/pdf/2312.03922v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03920v1",
            "title": "Optimizing Closed Payment Networks on the Lightning Network: Dual\n  Central Node Approach",
            "updated": "2023-12-06T21:35:19Z",
            "published": "2023-12-06T21:35:19Z",
            "summary": "The Lightning Network, known for its millisecond settlement speeds and low\ntransaction fees, offers a compelling alternative to traditional payment\nprocessors, which often have higher fees and longer processing times. This is\nparticularly significant for the unbanked population, which lacks access to\nstandard financial services. Our research targets businesses looking to shift\ntheir client to client payment processes, such as B2B invoicing, remittances,\nand cross-border transactions, to the Lightning Network. We compare the\nefficiency of interconnected mesh nodes (complete graph topology) with central\nrouting nodes (star graph topology), with a specific focus on the dual central\nnode approach. This approach introduces features like circular rebalancing,\nredundancy, and a closed network system. Through a basic SimPy model, we assess\nthe network's throughput in a 100 node scenario. While this approach\ncentralizes a technology initially designed for decentralization, it fosters\nbroader enterprise adoption of Bitcoin-based payment networks and encourages\nparticipation in the decentralized financial ecosystem. Our study also\nconsiders the regulatory implications of using central routing nodes, possibly\nclassified as payment processors under Money Transmission Laws (MTL). These\nfindings aim to contribute to the discourse on the Lightning Network's\napplication in business, highlighting its potential to drive shifts in\nfinancial technology towards more decentralized systems.",
            "author": [
                "Jeffy Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03920v1",
                "http://arxiv.org/pdf/2312.03920v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.NI",
                "C.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03919v1",
            "title": "Indivisibility and uniform computational strength",
            "updated": "2023-12-06T21:34:37Z",
            "published": "2023-12-06T21:34:37Z",
            "summary": "A countable structure is indivisible if for every coloring with finite range\nthere is a monochromatic isomorphic subcopy of the structure. Each indivisible\nstructure $\\mathcal{S}$ naturally corresponds to an indivisibility problem\n$\\mathsf{Ind}\\ \\mathcal{S}$, which outputs such a subcopy given a presentation\nand coloring. We investigate the Weihrauch complexity of the indivisibility\nproblems for two structures: the rational numbers $\\mathbb{Q}$ as a linear\norder, and the equivalence relation $\\mathscr{E}$ with countably many\nequivalence classes each having countably many members. We separate the\nWeihrauch degrees of both $\\mathsf{Ind}\\ \\mathbb{Q}$ and $\\mathsf{Ind}\\\n\\mathscr{E}$ from several benchmark problems, showing in particular that\n$\\mathsf{C}_\\mathbb{N} \\vert_\\mathrm{W} \\mathsf{Ind}\\ \\mathbb{Q}$ and hence\n$\\mathsf{Ind}\\ \\mathbb{Q}$ is strictly weaker than the problem of finding an\ninterval in which some color is dense for a given coloring of $\\mathbb{Q}$; and\nthat the Weihrauch degree of $\\mathsf{Ind}\\ \\mathscr{E}_k$ is strictly between\nthose of $\\mathsf{SRT}^2_k$ and $\\mathsf{RT}^2_k$, where $\\mathsf{Ind}\\\n\\mathcal{S}_k$ is the restriction of $\\mathsf{Ind}\\ \\mathcal{S}$ to\n$k$-colorings.",
            "author": [
                "Kenneth Gill"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03919v1",
                "http://arxiv.org/pdf/2312.03919v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "cs.LO",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03913v1",
            "title": "Controllable Human-Object Interaction Synthesis",
            "updated": "2023-12-06T21:14:20Z",
            "published": "2023-12-06T21:14:20Z",
            "summary": "Synthesizing semantic-aware, long-horizon, human-object interaction is\ncritical to simulate realistic human behaviors. In this work, we address the\nchallenging problem of generating synchronized object motion and human motion\nguided by language descriptions in 3D scenes. We propose Controllable\nHuman-Object Interaction Synthesis (CHOIS), an approach that generates object\nmotion and human motion simultaneously using a conditional diffusion model\ngiven a language description, initial object and human states, and sparse\nobject waypoints. While language descriptions inform style and intent,\nwaypoints ground the motion in the scene and can be effectively extracted using\nhigh-level planning methods. Naively applying a diffusion model fails to\npredict object motion aligned with the input waypoints and cannot ensure the\nrealism of interactions that require precise hand-object contact and\nappropriate contact grounded by the floor. To overcome these problems, we\nintroduce an object geometry loss as additional supervision to improve the\nmatching between generated object motion and input object waypoints. In\naddition, we design guidance terms to enforce contact constraints during the\nsampling process of the trained diffusion model.",
            "author": [
                "Jiaman Li",
                "Alexander Clegg",
                "Roozbeh Mottaghi",
                "Jiajun Wu",
                "Xavier Puig",
                "C. Karen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03913v1",
                "http://arxiv.org/pdf/2312.03913v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03912v1",
            "title": "Collaboration or Corporate Capture? Quantifying NLP's Reliance on\n  Industry Artifacts and Contributions",
            "updated": "2023-12-06T21:12:22Z",
            "published": "2023-12-06T21:12:22Z",
            "summary": "The advent of transformers, higher computational budgets, and big data has\nengendered remarkable progress in Natural Language Processing (NLP). Impressive\nperformance of industry pre-trained models has garnered public attention in\nrecent years and made news headlines. That these are industry models is\nnoteworthy. Rarely, if ever, are academic institutes producing exciting new NLP\nmodels. Using these models is critical for competing on NLP benchmarks and\ncorrespondingly to stay relevant in NLP research. We surveyed 100 papers\npublished at EMNLP 2022 to determine whether this phenomenon constitutes a\nreliance on industry for NLP publications.\n  We find that there is indeed a substantial reliance. Citations of industry\nartifacts and contributions across categories is at least three times greater\nthan industry publication rates per year. Quantifying this reliance does not\nsettle how we ought to interpret the results. We discuss two possible\nperspectives in our discussion: 1) Is collaboration with industry still\ncollaboration in the absence of an alternative? Or 2) has free NLP inquiry been\ncaptured by the motivations and research direction of private corporations?",
            "author": [
                "Will Aitken",
                "Mohamed Abdalla",
                "Karen Rudie",
                "Catherine Stinson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03912v1",
                "http://arxiv.org/pdf/2312.03912v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03906v1",
            "title": "Computing the Volume of a Restricted Independent Set Polytope\n  Deterministically",
            "updated": "2023-12-06T20:59:27Z",
            "published": "2023-12-06T20:59:27Z",
            "summary": "We construct a quasi-polynomial time deterministic approximation algorithm\nfor computing the volume of an independent set polytope with restrictions.\nRandomized polynomial time approximation algorithms for computing the volume of\na convex body have been known now for several decades, but the corresponding\ndeterministic counterparts are not available, and our algorithm is the first of\nthis kind. The class of polytopes for which our algorithm applies arises as\nlinear programming relaxation of the independent set problem with the\nadditional restriction that each variable takes value in the interval\n$[0,1-\\alpha]$ for some $\\alpha<1/2$. (We note that the $\\alpha\\ge 1/2$ case is\ntrivial).\n  We use the correlation decay method for this problem applied to its\nappropriate and natural discretization. The method works provided $\\alpha>\n1/2-O(1/\\Delta^2)$, where $\\Delta$ is the maximum degree of the graph. When\n$\\Delta=3$ (the sparsest non-trivial case), our method works provided\n$0.488<\\alpha<0.5$. Interestingly, the interpolation method, which is based on\nanalyzing complex roots of the associated partition functions, fails even in\nthe trivial case when the underlying graph is a singleton.",
            "author": [
                "David Gamarnik",
                "Devin Smedira"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03906v1",
                "http://arxiv.org/pdf/2312.03906v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "math.CO",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03905v1",
            "title": "A Pseudo-Semantic Loss for Autoregressive Models with Logical\n  Constraints",
            "updated": "2023-12-06T20:58:07Z",
            "published": "2023-12-06T20:58:07Z",
            "summary": "Neuro-symbolic AI bridges the gap between purely symbolic and neural\napproaches to learning. This often requires maximizing the likelihood of a\nsymbolic constraint w.r.t the neural network's output distribution. Such output\ndistributions are typically assumed to be fully-factorized. This limits the\napplicability of neuro-symbolic learning to the more expressive autoregressive\ndistributions, e.g., transformers. Under such distributions, computing the\nlikelihood of even simple constraints is #P-hard. Instead of attempting to\nenforce the constraint on the entire output distribution, we propose to do so\non a random, local approximation thereof. More precisely, we optimize the\nlikelihood of the constraint under a pseudolikelihood-based approximation\ncentered around a model sample. Our approximation is factorized, allowing the\nreuse of solutions to sub-problems, a main tenet for efficiently computing\nneuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of\nthe likelihood, exhibiting low entropy and KL-divergence around the model\nsample. We evaluate our approach on Sudoku and shortest-path prediction cast as\nautoregressive generation, and observe that we greatly improve upon the base\nmodel's ability to predict logically-consistent outputs. We also evaluate on\nthe task of detoxifying large language models. Using a simple constraint\ndisallowing a list of toxic words, we are able to steer the model's outputs\naway from toxic generations, achieving SoTA detoxification compared to previous\napproaches.",
            "author": [
                "Kareem Ahmed",
                "Kai-Wei Chang",
                "Guy Van den Broeck"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03905v1",
                "http://arxiv.org/pdf/2312.03905v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03900v1",
            "title": "Community Detection in High-Dimensional Graph Ensembles",
            "updated": "2023-12-06T20:50:29Z",
            "published": "2023-12-06T20:50:29Z",
            "summary": "Detecting communities in high-dimensional graphs can be achieved by applying\nrandom matrix theory where the adjacency matrix of the graph is modeled by a\nStochastic Block Model (SBM). However, the SBM makes an unrealistic assumption\nthat the edge probabilities are homogeneous within communities, i.e., the edges\noccur with the same probabilities. The Degree-Corrected SBM is a generalization\nof the SBM that allows these edge probabilities to be different, but existing\nresults from random matrix theory are not directly applicable to this\nheterogeneous model. In this paper, we derive a transformation of the adjacency\nmatrix that eliminates this heterogeneity and preserves the relevant\neigenstructure for community detection. We propose a test based on the extreme\neigenvalues of this transformed matrix and (1) provide a method for controlling\nthe significance level, (2) formulate a conjecture that the test achieves power\none for all positive significance levels in the limit as the number of nodes\napproaches infinity, and (3) provide empirical evidence and theory supporting\nthese claims.",
            "author": [
                "Robert Malinas",
                "Dogyoon Song",
                "Alfred O. Hero III"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03900v1",
                "http://arxiv.org/pdf/2312.03900v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03897v1",
            "title": "Revisiting the Optimality of Word Lengths",
            "updated": "2023-12-06T20:41:47Z",
            "published": "2023-12-06T20:41:47Z",
            "summary": "Zipf (1935) posited that wordforms are optimized to minimize utterances'\ncommunicative costs. Under the assumption that cost is given by an utterance's\nlength, he supported this claim by showing that words' lengths are inversely\ncorrelated with their frequencies. Communicative cost, however, can be\noperationalized in different ways. Piantadosi et al. (2011) claim that cost\nshould be measured as the distance between an utterance's information rate and\nchannel capacity, which we dub the channel capacity hypothesis (CCH) here.\nFollowing this logic, they then proposed that a word's length should be\nproportional to the expected value of its surprisal (negative log-probability\nin context). In this work, we show that Piantadosi et al.'s derivation does not\nminimize CCH's cost, but rather a lower bound, which we term CCH-lower. We\npropose a novel derivation, suggesting an improved way to minimize CCH's cost.\nUnder this method, we find that a language's word lengths should instead be\nproportional to the surprisal's expectation plus its variance-to-mean ratio.\nExperimentally, we compare these three communicative cost functions: Zipf's,\nCCH-lower , and CCH. Across 13 languages and several experimental settings, we\nfind that length is better predicted by frequency than either of the other\nhypotheses. In fact, when surprisal's expectation, or expectation plus\nvariance-to-mean ratio, is estimated using better language models, it leads to\nworse word length predictions. We take these results as evidence that Zipf's\nlongstanding hypothesis holds.",
            "author": [
                "Tiago Pimentel",
                "Clara Meister",
                "Ethan Gotlieb Wilcox",
                "Kyle Mahowald",
                "Ryan Cotterell"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03897v1",
                "http://arxiv.org/pdf/2312.03897v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03895v1",
            "title": "HLoOP -- Hyperbolic 2-space Local Outlier Probabilities",
            "updated": "2023-12-06T20:38:39Z",
            "published": "2023-12-06T20:38:39Z",
            "summary": "Hyperbolic geometry has recently garnered considerable attention in machine\nlearning due to its capacity to embed hierarchical graph structures with low\ndistortions for further downstream processing. This paper introduces a simple\nframework to detect local outliers for datasets grounded in hyperbolic 2-space\nreferred to as HLoOP (Hyperbolic Local Outlier Probability). Within a Euclidean\nspace, well-known techniques for local outlier detection are based on the Local\nOutlier Factor (LOF) and its variant, the LoOP (Local Outlier Probability),\nwhich incorporates probabilistic concepts to model the outlier level of a data\nvector. The developed HLoOP combines the idea of finding nearest neighbors,\ndensity-based outlier scoring with a probabilistic, statistically oriented\napproach. Therefore, the method consists in computing the Riemmanian distance\nof a data point to its nearest neighbors following a Gaussian probability\ndensity function expressed in a hyperbolic space. This is achieved by defining\na Gaussian cumulative distribution in this space. The HLoOP algorithm is tested\non the WordNet dataset yielding promising results. Code and data will be made\navailable on request for reproductibility.",
            "author": [
                "Cl\u00e9mence Allietta",
                "Jean-Philippe Condomines",
                "Jean-Yves Tourneret",
                "Emmanuel Lochin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03895v1",
                "http://arxiv.org/pdf/2312.03895v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03889v1",
            "title": "A Masked Pruning Approach for Dimensionality Reduction in\n  Communication-Efficient Federated Learning Systems",
            "updated": "2023-12-06T20:29:23Z",
            "published": "2023-12-06T20:29:23Z",
            "summary": "Federated Learning (FL) represents a growing machine learning (ML) paradigm\ndesigned for training models across numerous nodes that retain local datasets,\nall without directly exchanging the underlying private data with the parameter\nserver (PS). Its increasing popularity is attributed to notable advantages in\nterms of training deep neural network (DNN) models under privacy aspects and\nefficient utilization of communication resources. Unfortunately, DNNs suffer\nfrom high computational and communication costs, as well as memory consumption\nin intricate tasks. These factors restrict the applicability of FL algorithms\nin communication-constrained systems with limited hardware resources.\n  In this paper, we develop a novel algorithm that overcomes these limitations\nby synergistically combining a pruning-based method with the FL process,\nresulting in low-dimensional representations of the model with minimal\ncommunication cost, dubbed Masked Pruning over FL (MPFL). The algorithm\noperates by initially distributing weights to the nodes through the PS.\nSubsequently, each node locally trains its model and computes pruning masks.\nThese low-dimensional masks are then transmitted back to the PS, which\ngenerates a consensus pruning mask, broadcasted back to the nodes. This\niterative process enhances the robustness and stability of the masked pruning\nmodel. The generated mask is used to train the FL model, achieving significant\nbandwidth savings. We present an extensive experimental study demonstrating the\nsuperior performance of MPFL compared to existing methods. Additionally, we\nhave developed an open-source software package for the benefit of researchers\nand developers in related fields.",
            "author": [
                "Tamir L. S. Gez",
                "Kobi Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03889v1",
                "http://arxiv.org/pdf/2312.03889v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03882v1",
            "title": "Signal Detection in Ambient Backscatter Systems: Fundamentals, Methods,\n  and Trends",
            "updated": "2023-12-06T20:11:17Z",
            "published": "2023-12-06T20:11:17Z",
            "summary": "Internet-of-Things (IoT) is rapidly growing in wireless technology, aiming to\nconnect vast numbers of devices to gather and distribute vital information.\nDespite individual devices having low energy consumption, the cumulative demand\nresults in significant energy usage. Consequently, the concept of\nultra-low-power tags gains appeal. Such tags communicate by reflecting rather\nthan generating the radio frequency (RF) signals by themselves. Thus, these\nbackscatter tags can be low-cost and battery-free. The RF signals can be\nambient sources such as wireless-fidelity (Wi-Fi), cellular, or television (TV)\nsignals, or the system can generate them externally. Backscatter channel\ncharacteristics are different from conventional point-to-point or cooperative\nrelay channels. These systems are also affected by a strong interference link\nbetween the RF source and the tag besides the direct and backscattering links,\nmaking signal detection challenging. This paper provides an overview of the\nfundamentals, challenges, and ongoing research in signal detection for AmBC\nnetworks. It delves into various detection methods, discussing their advantages\nand drawbacks. The paper's emphasis on signal detection sets it apart and\npositions it as a valuable resource for IoT and wireless communication\nprofessionals and researchers.",
            "author": [
                "Shayan Zargari",
                "Azar Hakimi",
                "Fatemeh Rezaei",
                "Chintha Tellambura",
                "Amine Maaref"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03882v1",
                "http://arxiv.org/pdf/2312.03882v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03881v1",
            "title": "FoMo Rewards: Can we cast foundation models as reward functions?",
            "updated": "2023-12-06T20:11:02Z",
            "published": "2023-12-06T20:11:02Z",
            "summary": "We explore the viability of casting foundation models as generic reward\nfunctions for reinforcement learning. To this end, we propose a simple pipeline\nthat interfaces an off-the-shelf vision model with a large language model.\nSpecifically, given a trajectory of observations, we infer the likelihood of an\ninstruction describing the task that the user wants an agent to perform. We\nshow that this generic likelihood function exhibits the characteristics ideally\nexpected from a reward function: it associates high values with the desired\nbehaviour and lower values for several similar, but incorrect policies.\nOverall, our work opens the possibility of designing open-ended agents for\ninteractive tasks via foundation models.",
            "author": [
                "Ekdeep Singh Lubana",
                "Johann Brehmer",
                "Pim de Haan",
                "Taco Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03881v1",
                "http://arxiv.org/pdf/2312.03881v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03879v1",
            "title": "Field-driven transition from quantum spin liquid to magnetic order in\n  triangular-lattice antiferromagnets",
            "updated": "2023-12-06T19:59:31Z",
            "published": "2023-12-06T19:59:31Z",
            "summary": "Recently several triangular-lattice magnets with delafossite structure have\nbeen found to display spin-liquid behavior down to the lowest temperatures.\nRemarkably, applying a magnetic field destroys the spin liquid which then gives\nway to symmetry-breaking states, identified as semiclassical coplanar states\nincluding a magnetization plateau at 1/3 total magnetization. Here we provide a\ntheoretical approach rationalizing this dichotomy, utilizing a Schwinger-boson\ntheory that captures both ordered and disordered magnetic phases. We show that\na zero-field spin liquid, driven by strong frustration, is naturally\ndestabilized in a magnetic field via spinon condensation. Symmetry-breaking\norder akin to the standard triangular-lattice Heisenberg model then arises via\nan order-by-disorder mechanism. We discuss implications for pertinent\nexperiments.",
            "author": [
                "Santanu Dey",
                "Joseph Maciejko",
                "Matthias Vojta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03879v1",
                "http://arxiv.org/pdf/2312.03879v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03877v1",
            "title": "Exploring correlations between HEFT Higgs couplings $\u03ba_V$ and\n  $\u03ba_{2V}$ via HH production at $e^+e^-$ colliders",
            "updated": "2023-12-06T19:46:46Z",
            "published": "2023-12-06T19:46:46Z",
            "summary": "In this work we explore the phenomenological implications at future $e^+e^-$\ncolliders of assuming anomalous couplings of the Higgs boson to gauge bosons\n$HVV$ and $HHVV$ ($V=W,Z$) given by the $\\kappa$-modifiers with respect to the\nStandard Model couplings, $\\kappa_V$ and $\\kappa_{2V}$, respectively. For this\nstudy we use the Higgs Effective Field Theory (HEFT) where these two $\\kappa$\nparameters are identified with the two most relevant effective couplings at\nleading order, concretely $a=\\kappa_V$ and $b=\\kappa_{2V}$. Our focus is put on\nthese two couplings and their potential correlations which we believe carry\ninteresting information on the underlying ultraviolet theory. The particular\nstudied process is $e^+e^- \\to HH \\nu \\bar \\nu$, where the vector boson\nscattering subprocess $WW \\to HH$ plays a central role, specially at the\nlargest planned energy colliders. Our detailed study of this process as a\nfunction of the energy and the angular variables indicates that the produced\nHiggs bosons in the BSM scenarios will have in general a high transversality as\ncompared to the SM case if $\\kappa_V^2 \\neq \\kappa_{2V}$. In order to enhance\nthe sensitivity to these HEFT parameters $\\kappa_V$ and $\\kappa_{2V}$ and their\npotential correlations we propose here some selected differential cross\nsections for the $e^+e^- \\to HH \\nu \\bar\\nu$ process where different kinematic\nproperties of the BSM case with respect to the SM are manifested. Finally, we\nwill focus on the dominant Higgs decays to $b \\bar b$ pairs leading to final\nevents with 4 $b$-jets and missing transverse energy from the undetected\nneutrinos and will provide the expected accessibility to the\n$(\\kappa_V,\\kappa_{2V})$ effective couplings and their potential correlations.\nIn our study we will consider the three projected energies for $e^+e^-$\ncolliders of 500 GeV, 1000 GeV and 3000 GeV.",
            "author": [
                "J. M. D\u00e1vila",
                "D. Domenech",
                "M. J. Herrero",
                "R. A. Morales"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03877v1",
                "http://arxiv.org/pdf/2312.03877v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03873v1",
            "title": "Optimizing $CO_{2}$ Capture in Pressure Swing Adsorption Units: A Deep\n  Neural Network Approach with Optimality Evaluation and Operating Maps for\n  Decision-Making",
            "updated": "2023-12-06T19:43:37Z",
            "published": "2023-12-06T19:43:37Z",
            "summary": "This study presents a methodology for surrogate optimization of cyclic\nadsorption processes, focusing on enhancing Pressure Swing Adsorption units for\ncarbon dioxide ($CO_{2}$) capture. We developed and implemented a\nmultiple-input, single-output (MISO) framework comprising two deep neural\nnetwork (DNN) models, predicting key process performance indicators. These\nmodels were then integrated into an optimization framework, leveraging particle\nswarm optimization (PSO) and statistical analysis to generate a comprehensive\nPareto front representation. This approach delineated feasible operational\nregions (FORs) and highlighted the spectrum of optimal decision-making\nscenarios. A key aspect of our methodology was the evaluation of optimization\neffectiveness. This was accomplished by testing decision variables derived from\nthe Pareto front against a phenomenological model, affirming the surrogate\nmodels reliability. Subsequently, the study delved into analyzing the feasible\noperational domains of these decision variables. A detailed correlation map was\nconstructed to elucidate the interplay between these variables, thereby\nuncovering the most impactful factors influencing process behavior. The study\noffers a practical, insightful operational map that aids operators in\npinpointing the optimal process location and prioritizing specific operational\ngoals.",
            "author": [
                "Carine Menezes Rebello",
                "Idelfonso B. R. Nogueira"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03873v1",
                "http://arxiv.org/pdf/2312.03873v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03872v1",
            "title": "The BigCode Project Governance Card",
            "updated": "2023-12-06T19:37:08Z",
            "published": "2023-12-06T19:37:08Z",
            "summary": "This document serves as an overview of the different mechanisms and areas of\ngovernance in the BigCode project. It aims to support transparency by providing\nrelevant information about choices that were made during the project to the\nbroader public, and to serve as an example of intentional governance of an open\nresearch project that future endeavors can leverage to shape their own\napproach. The first section, Project Structure, covers the project\norganization, its stated goals and values, its internal decision processes, and\nits funding and resources. The second section, Data and Model Governance,\ncovers decisions relating to the questions of data subject consent, privacy,\nand model release.",
            "author": [
                "BigCode collaboration",
                "Sean Hughes",
                "Harm de Vries",
                "Jennifer Robinson",
                "Carlos Mu\u00f1oz Ferrandis",
                "Loubna Ben Allal",
                "Leandro von Werra",
                "Jennifer Ding",
                "Sebastien Paquet",
                "Yacine Jernite"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03872v1",
                "http://arxiv.org/pdf/2312.03872v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03863v1",
            "title": "Efficient Large Language Models: A Survey",
            "updated": "2023-12-06T19:18:42Z",
            "published": "2023-12-06T19:18:42Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nimportant tasks such as natural language understanding, language generation,\nand complex reasoning and have the potential to make a substantial impact on\nour society. Such capabilities, however, come with the considerable resources\nthey demand, highlighting the strong need to develop effective techniques for\naddressing their efficiency challenges. In this survey, we provide a systematic\nand comprehensive review of efficient LLMs research. We organize the literature\nin a taxonomy consisting of three main categories, covering distinct yet\ninterconnected efficient LLMs topics from model-centric, data-centric, and\nframework-centric perspective, respectively. We have also created a GitHub\nrepository where we compile the papers featured in this survey at\nhttps://github.com/AIoT-MLSys-Lab/EfficientLLMs,\nhttps://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey, and will actively\nmaintain this repository and incorporate new research as it emerges. We hope\nour survey can serve as a valuable resource to help researchers and\npractitioners gain a systematic understanding of the research developments in\nefficient LLMs and inspire them to contribute to this important and exciting\nfield.",
            "author": [
                "Zhongwei Wan",
                "Xin Wang",
                "Che Liu",
                "Samiul Alam",
                "Yu Zheng",
                "Zhongnan Qu",
                "Shen Yan",
                "Yi Zhu",
                "Quanlu Zhang",
                "Mosharaf Chowdhury",
                "Mi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03863v1",
                "http://arxiv.org/pdf/2312.03863v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03859v1",
            "title": "Towards Tight Bounds for the Graph Homomorphism Problem Parameterized by\n  Cutwidth via Asymptotic Rank Parameters",
            "updated": "2023-12-06T19:15:10Z",
            "published": "2023-12-06T19:15:10Z",
            "summary": "A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping\nfrom $V(G)$ to $V(H)$. In the graph homomorphism problem, denoted by $Hom(H)$,\nthe graph $H$ is fixed and we need to determine if there exists a homomorphism\nfrom an instance graph $G$ to $H$. We study the complexity of the problem\nparameterized by the cutwidth of $G$.\n  We aim, for each $H$, for algorithms for $Hom(H)$ running in time $c_H^k\nn^{\\mathcal{O}(1)}$ and matching lower bounds that exclude $c_H^{k \\cdot\no(1)}n^{\\mathcal{O}(1)}$ or $c_H^{k(1-\\Omega(1))}n^{\\mathcal{O}(1)}$ time\nalgorithms under the (Strong) Exponential Time Hypothesis.\n  In the paper we introduce a new parameter that we call $\\mathrm{mimsup}(H)$.\nOur main contribution is strong evidence of a close connection between $c_H$\nand $\\mathrm{mimsup}(H)$:\n  * an information-theoretic argument that the number of states needed in a\nnatural dynamic programming algorithm is at most $\\mathrm{mimsup}(H)^k$,\n  * lower bounds that show that for almost all graphs $H$ indeed we have $c_H\n\\geq \\mathrm{mimsup}(H)$, assuming the (Strong) Exponential-Time Hypothesis,\nand\n  * an algorithm with running time $\\exp ( {\\mathcal{O}( \\mathrm{mimsup}(H)\n\\cdot k \\log k)}) n^{\\mathcal{O}(1)}$.\n  The parameter $\\mathrm{mimsup}(H)$ can be thought of as the $p$-th root of\nthe maximum induced matching number in the graph obtained by multiplying $p$\ncopies of $H$ via certain graph product, where $p$ tends to infinity. It can\nalso be defined as an asymptotic rank parameter of the adjacency matrix of $H$.\nOur results tightly link the parameterized complexity of a problem to such an\nasymptotic rank parameter for the first time.",
            "author": [
                "Carla Groenland",
                "Isja Mannens",
                "Jesper Nederlof",
                "Marta Piecyk",
                "Pawe\u0142 Rz\u0105\u017cewski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03859v1",
                "http://arxiv.org/pdf/2312.03859v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03858v1",
            "title": "Stop Hiding The Sharp Knives: The WebAssembly Linux Interface",
            "updated": "2023-12-06T19:11:15Z",
            "published": "2023-12-06T19:11:15Z",
            "summary": "WebAssembly is gaining popularity as a portable binary format targetable from\nmany programming languages. With a well-specified low-level virtual instruction\nset, minimal memory footprint and many high-performance implementations, it has\nbeen successfully adopted for lightweight in-process memory sandboxing in many\ncontexts. Despite these advantages, WebAssembly lacks many standard system\ninterfaces, making it difficult to reuse existing applications.\n  This paper proposes WALI: The WebAssembly Linux Interface, a thin layer over\nLinux's userspace system calls, creating a new class of virtualization where\nWebAssembly seamlessly interacts with native processes and the underlying\noperating system. By virtualizing the lowest level of userspace, WALI offers\napplication portability with little effort and reuses existing compiler\nbackends. With WebAssembly's control flow integrity guarantees, these modules\ngain an additional level of protection against remote code injection attacks.\nFurthermore, capability-based APIs can themselves be virtualized and\nimplemented in terms of WALI, improving reuse and robustness through better\nlayering. We present an implementation of WALI in a modern WebAssembly engine\nand evaluate its performance on a number of applications which we can now\ncompile with mostly trivial effort.",
            "author": [
                "Arjun Ramesh",
                "Tianshu Huang",
                "Ben L. Titzer",
                "Anthony Rowe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03858v1",
                "http://arxiv.org/pdf/2312.03858v1"
            ],
            "primary_category": "cs.OS",
            "category": [
                "cs.OS",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03854v1",
            "title": "Gaia DR3 data consistent with a short bar connected to a spiral arm",
            "updated": "2023-12-06T19:08:20Z",
            "published": "2023-12-06T19:08:20Z",
            "summary": "We use numerical simulations to model Gaia DR3 data with the aim of\nconstraining the Milky Way bar and spiral structure parameters. We show that\nboth the morphology and the velocity field in Milky Way-like galactic disc\nmodels are strong functions of time, changing dramatically over a few tens of\nMyr. This suggests that by finding a good match to the observed radial velocity\nfield, v_R(x,y), we can constrain the bar-spiral orientation. Incorporating\nuncertainties into our models is necessary to match the data; most importantly,\na heliocentric distance uncertainty above 10-15% distorts the bar's shape and\n$v_R$ quadrupole pattern morphology, and decreases its apparent angle with\nrespect to the Sun-Galactocentric line. An excellent match to the \\Gaia DR3\n$v_R(x,y)$ field is found for a simulation with a bar length R_b~3.6 kpc. We\nargue that the data are consistent with a MW bar as short as ~3 kpc, for\nmoderate strength inner disc spiral structure (A_2/A_0~0.25) or, alternatively,\nwith a bar length up to ~5.2 kpc, provided that spiral arms are quite weak\n(A_2/A_0~0.1), and is most likely in the process of disconnecting from a spiral\narm. We demonstrate that the bar angle and distance uncertainty can similarly\naffect the match between our models and the data - a smaller bar angle (20 deg\ninstead of 30 deg) requires smaller distance uncertainty (20% instead of 30%)\nto explain the observations. Fourier components of the face-on density\ndistribution of our models suggest that the MW does not have strong m=1 and/or\nm=3 spirals inside the solar radius.",
            "author": [
                "E. Vislosky",
                "I. Minchev",
                "S. Khoperskov",
                "M. Martig",
                "T. Buck",
                "T. Hilmi",
                "B. Ratcliffe",
                "J. Bland-Hawthorn",
                "A. C. Quillen",
                "M. Steinmetz",
                "R. de Jong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03854v1",
                "http://arxiv.org/pdf/2312.03854v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03853v1",
            "title": "Dr. Jekyll and Mr. Hyde: Two Faces of LLMs",
            "updated": "2023-12-06T19:07:38Z",
            "published": "2023-12-06T19:07:38Z",
            "summary": "This year, we witnessed a rise in the use of Large Language Models,\nespecially when combined with applications like chatbot assistants. Safety\nmechanisms and specialized training procedures are put in place to prevent\nimproper responses from these assistants. In this work, we bypass these\nmeasures for ChatGPT and Bard (and, to some extent, Bing chat) by making them\nimpersonate complex personas with opposite characteristics as those of the\ntruthful assistants they are supposed to be. We start by creating elaborate\nbiographies of these personas, which we then use in a new session with the same\nchatbots. Our conversation followed a role-play style to get the response the\nassistant was not allowed to provide. By making use of personas, we show that\nthe response that is prohibited is actually provided, making it possible to\nobtain unauthorized, illegal, or harmful information. This work shows that by\nusing adversarial personas, one can overcome safety mechanisms set out by\nChatGPT and Bard. It also introduces several ways of activating such\nadversarial personas, altogether showing that both chatbots are vulnerable to\nthis kind of attack.",
            "author": [
                "Matteo Gioele Collu",
                "Tom Janssen-Groesbeek",
                "Stefanos Koffas",
                "Mauro Conti",
                "Stjepan Picek"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03853v1",
                "http://arxiv.org/pdf/2312.03853v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03849v1",
            "title": "LEGO: Learning EGOcentric Action Frame Generation via Visual Instruction\n  Tuning",
            "updated": "2023-12-06T19:02:40Z",
            "published": "2023-12-06T19:02:40Z",
            "summary": "Generating instructional images of human daily actions from an egocentric\nviewpoint serves a key step towards efficient skill transfer. In this paper, we\nintroduce a novel problem -- egocentric action frame generation. The goal is to\nsynthesize the action frame conditioning on the user prompt question and an\ninput egocentric image that captures user's environment. Notably, existing\negocentric datasets lack the detailed annotations that describe the execution\nof actions. Additionally, the diffusion-based image manipulation models fail to\ncontrol the state change of an action within the corresponding egocentric image\npixel space. To this end, we finetune a visual large language model (VLLM) via\nvisual instruction tuning for curating the enriched action descriptions to\naddress our proposed problem. Moreover, we propose to Learn EGOcentric (LEGO)\naction frame generation using image and text embeddings from VLLM as additional\nconditioning. We validate our proposed model on two egocentric datasets --\nEgo4D and Epic-Kitchens. Our experiments show prominent improvement over prior\nimage manipulation models in both quantitative and qualitative evaluation. We\nalso conduct detailed ablation studies and analysis to provide insights on our\nmethod.",
            "author": [
                "Bolin Lai",
                "Xiaoliang Dai",
                "Lawrence Chen",
                "Guan Pang",
                "James M. Rehg",
                "Miao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03849v1",
                "http://arxiv.org/pdf/2312.03849v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03840v1",
            "title": "Transient localization from the interaction with quantum bosons",
            "updated": "2023-12-06T19:00:05Z",
            "published": "2023-12-06T19:00:05Z",
            "summary": "We carefully revisit the electron-boson scattering problem, going beyond\npopular semi-classical treatments. By providing numerically exact results valid\nat finite temperatures, we demonstrate the existence of a regime of\nelectron-boson scattering where quantum localization processes become relevant\ndespite the absence of extrinsic disorder. Localization in the Anderson sense\nis caused by the emergent randomness resulting from a large thermal boson\npopulation, being effective at transient times before diffusion can set in.\nCompelling evidence of this transient localization phenomenon is provided by\nthe observation of a distinctive displaced Drude peak (DDP) in the optical\nabsorption and the ensuing suppression of conductivity. Our findings identify a\ngeneral route for anomalous metallic behavior that can broadly apply in\ninteracting quantum matter.",
            "author": [
                "H. Rammal",
                "A. Ralko",
                "S. Ciuchi",
                "S. Fratini"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03840v1",
                "http://arxiv.org/pdf/2312.03840v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.dis-nn",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03826v1",
            "title": "A Duet of Freeze-in and Freeze-out: Lepton-Flavored Dark Matter and Muon\n  Colliders",
            "updated": "2023-12-06T19:00:01Z",
            "published": "2023-12-06T19:00:01Z",
            "summary": "We study a Lepton-Flavored Dark Matter model and its signatures at a future\nMuon Collider. We focus on the less-explored regime of feeble dark matter\ninteractions, which suppresses the dangerous lepton-flavor violating processes,\ngives rise to dark matter freeze-in production, and leads to long-lived\nparticle signatures at colliders. We find that the interplay of dark matter\nfreeze-in and its mediator freeze-out gives rise to an upper bound of around\nTeV scales on the dark matter mass. The signatures of this model depend on the\nlifetime of the mediator, and can range from generic prompt decays to more\nexotic long-lived particle signals. In the prompt region, we calculate the\nsignal yield, study useful kinematics cuts, and report tolerable systematics\nthat would allow for a $5\\sigma$ discovery. In the long-lived region, we\ncalculate the number of charged tracks and displaced lepton signals of our\nmodel in different parts of the detector, and uncover kinematic features that\ncan be used for background rejection. We show that, unlike in hadron colliders,\nmultiple production channels contribute significantly which leads to sharply\ndistinct kinematics for electroweakly-charged long-lived particle signals.\nUltimately, the collider signatures of this lepton-flavored dark matter model\nare common amongst models of electroweak-charged new physics, rendering this\nmodel a useful and broadly applicable benchmark model for future Muon Collider\nstudies that can help inform work on detector design and studies of\nsystematics.",
            "author": [
                "Pouya Asadi",
                "Aria Radick",
                "Tien-Tien Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03826v1",
                "http://arxiv.org/pdf/2312.03826v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03820v1",
            "title": "The Ambient Space Formalism",
            "updated": "2023-12-06T19:00:00Z",
            "published": "2023-12-06T19:00:00Z",
            "summary": "We present a new formalism to solve the kinematical constraints due to Weyl\ninvariance for CFTs in curved backgrounds and/or non-trivial states, and we\napply it to thermal CFTs and to CFTs on squashed spheres. The ambient space\nformalism is based on constructing a class of geometric objects that are Weyl\ncovariant and identifying them as natural building blocks of correlation\nfunctions. We construct (scalar) $n$-point functions and we illustrate the\nformalism with a detailed computation of 2-point functions. We compare our\nresults for thermal 2-point functions with results that follow from thermal\nOPEs and holographic computations, finding exact agreement. In our holographic\ncomputation we also obtain the OPE coefficient of the leading double-twist\ncontribution, and we discuss how the double-twist coefficients may be computed\nfrom the multi-energy-momentum contributions, given knowledge of the analytic\nstructure of the correlator. The 2-point function for the CFT on squashed\nspheres is a new result. We also discuss the relation of our work to flat\nholography.",
            "author": [
                "Enrico Parisini",
                "Kostas Skenderis",
                "Benjamin Withers"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03820v1",
                "http://arxiv.org/pdf/2312.03820v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03703v1",
            "title": "Skeleton-in-Context: Unified Skeleton Sequence Modeling with In-Context\n  Learning",
            "updated": "2023-12-06T18:59:44Z",
            "published": "2023-12-06T18:59:44Z",
            "summary": "In-context learning provides a new perspective for multi-task modeling for\nvision and NLP. Under this setting, the model can perceive tasks from prompts\nand accomplish them without any extra task-specific head predictions or model\nfine-tuning. However, Skeleton sequence modeling via in-context learning\nremains unexplored. Directly applying existing in-context models from other\nareas onto skeleton sequences fails due to the inter-frame and cross-task pose\nsimilarity that makes it outstandingly hard to perceive the task correctly from\na subtle context. To address this challenge, we propose Skeleton-in-Context\n(SiC), an effective framework for in-context skeleton sequence modeling. Our\nSiC is able to handle multiple skeleton-based tasks simultaneously after a\nsingle training process and accomplish each task from context according to the\ngiven prompt. It can further generalize to new, unseen tasks according to\ncustomized prompts. To facilitate context perception, we additionally propose a\ntask-unified prompt, which adaptively learns tasks of different natures, such\nas partial joint-level generation, sequence-level prediction, or 2D-to-3D\nmotion prediction. We conduct extensive experiments to evaluate the\neffectiveness of our SiC on multiple tasks, including motion prediction, pose\nestimation, joint completion, and future pose estimation. We also evaluate its\ngeneralization capability on unseen tasks such as motion-in-between. These\nexperiments show that our model achieves state-of-the-art multi-task\nperformance and even outperforms single-task methods on certain tasks.",
            "author": [
                "Xinshun Wang",
                "Zhongbin Fang",
                "Xia Li",
                "Xiangtai Li",
                "Chen Chen",
                "Mengyuan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03703v1",
                "http://arxiv.org/pdf/2312.03703v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03701v1",
            "title": "Self-conditioned Image Generation via Generating Representations",
            "updated": "2023-12-06T18:59:31Z",
            "published": "2023-12-06T18:59:31Z",
            "summary": "This paper presents $\\textbf{R}$epresentation-$\\textbf{C}$onditioned image\n$\\textbf{G}$eneration (RCG), a simple yet effective image generation framework\nwhich sets a new benchmark in class-unconditional image generation. RCG does\nnot condition on any human annotations. Instead, it conditions on a\nself-supervised representation distribution which is mapped from the image\ndistribution using a pre-trained encoder. During generation, RCG samples from\nsuch representation distribution using a representation diffusion model (RDM),\nand employs a pixel generator to craft image pixels conditioned on the sampled\nrepresentation. Such a design provides substantial guidance during the\ngenerative process, resulting in high-quality image generation. Tested on\nImageNet 256$\\times$256, RCG achieves a Frechet Inception Distance (FID) of\n3.31 and an Inception Score (IS) of 253.4. These results not only significantly\nimprove the state-of-the-art of class-unconditional image generation but also\nrival the current leading methods in class-conditional image generation,\nbridging the long-standing performance gap between these two tasks. Code is\navailable at https://github.com/LTH14/rcg.",
            "author": [
                "Tianhong Li",
                "Dina Katabi",
                "Kaiming He"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03701v1",
                "http://arxiv.org/pdf/2312.03701v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03818v1",
            "title": "Alpha-CLIP: A CLIP Model Focusing on Wherever You Want",
            "updated": "2023-12-06T18:59:30Z",
            "published": "2023-12-06T18:59:30Z",
            "summary": "Contrastive Language-Image Pre-training (CLIP) plays an essential role in\nextracting valuable content information from images across diverse tasks. It\naligns textual and visual modalities to comprehend the entire image, including\nall the details, even those irrelevant to specific tasks. However, for a finer\nunderstanding and controlled editing of images, it becomes crucial to focus on\nspecific regions of interest, which can be indicated as points, masks, or boxes\nby humans or perception models. To fulfill the requirements, we introduce\nAlpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to\nsuggest attentive regions and fine-tuned with constructed millions of RGBA\nregion-text pairs. Alpha-CLIP not only preserves the visual recognition ability\nof CLIP but also enables precise control over the emphasis of image contents.\nIt demonstrates effectiveness in various tasks, including but not limited to\nopen-world recognition, multimodal large language models, and conditional 2D /\n3D generation. It has a strong potential to serve as a versatile tool for\nimage-related tasks.",
            "author": [
                "Zeyi Sun",
                "Ye Fang",
                "Tong Wu",
                "Pan Zhang",
                "Yuhang Zang",
                "Shu Kong",
                "Yuanjun Xiong",
                "Dahua Lin",
                "Jiaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03818v1",
                "http://arxiv.org/pdf/2312.03818v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03700v1",
            "title": "OneLLM: One Framework to Align All Modalities with Language",
            "updated": "2023-12-06T18:59:19Z",
            "published": "2023-12-06T18:59:19Z",
            "summary": "Multimodal large language models (MLLMs) have gained significant attention\ndue to their strong multimodal understanding capability. However, existing\nworks rely heavily on modality-specific encoders, which usually differ in\narchitecture and are limited to common modalities. In this paper, we present\nOneLLM, an MLLM that aligns eight modalities to language using a unified\nframework. We achieve this through a unified multimodal encoder and a\nprogressive multimodal alignment pipeline. In detail, we first train an image\nprojection module to connect a vision encoder with LLM. Then, we build a\nuniversal projection module (UPM) by mixing multiple image projection modules\nand dynamic routing. Finally, we progressively align more modalities to LLM\nwith the UPM. To fully leverage the potential of OneLLM in following\ninstructions, we also curated a comprehensive multimodal instruction dataset,\nincluding 2M items from image, audio, video, point cloud, depth/normal map, IMU\nand fMRI brain activity. OneLLM is evaluated on 25 diverse benchmarks,\nencompassing tasks such as multimodal captioning, question answering and\nreasoning, where it delivers excellent performance. Code, data, model and\nonline demo are available at https://github.com/csuhan/OneLLM",
            "author": [
                "Jiaming Han",
                "Kaixiong Gong",
                "Yiyuan Zhang",
                "Jiaqi Wang",
                "Kaipeng Zhang",
                "Dahua Lin",
                "Yu Qiao",
                "Peng Gao",
                "Xiangyu Yue"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03700v1",
                "http://arxiv.org/pdf/2312.03700v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03699v2",
            "title": "PROMISE: A Framework for Model-Driven Stateful Prompt Orchestration",
            "updated": "2023-12-07T10:19:27Z",
            "published": "2023-12-06T18:59:11Z",
            "summary": "The advent of increasingly powerful language models has raised expectations\nfor language-based interactions. However, controlling these models is a\nchallenge, emphasizing the need to be able to investigate the feasibility and\nvalue of their application. We present PROMISE, a framework that facilitates\nthe development of complex language-based interactions with information\nsystems. Its use of state machine modeling concepts enables model-driven,\ndynamic prompt orchestration across hierarchically nested states and\ntransitions. This improves the control of the behavior of language models and\nthus enables their effective and efficient use. We show the benefits of PROMISE\nin the context of application scenarios within health information systems and\ndemonstrate its ability to handle complex interactions.",
            "author": [
                "Wenyuan Wu",
                "Jasmin Heierli",
                "Max Meisterhans",
                "Adrian Moser",
                "Andri F\u00e4rber",
                "Mateusz Dolata",
                "Elena Gavagnin",
                "Alexandre de Spindler",
                "Gerhard Schwabe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03699v2",
                "http://arxiv.org/pdf/2312.03699v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03694v2",
            "title": "Parameter-Efficient Transfer Learning of Audio Spectrogram Transformers",
            "updated": "2023-12-07T08:13:58Z",
            "published": "2023-12-06T18:55:34Z",
            "summary": "The common modus operandi of fine-tuning large pre-trained Transformer models\nentails the adaptation of all their parameters (i.e., full fine-tuning). While\nachieving striking results on multiple tasks, this approach becomes unfeasible\nas the model size and the number of downstream tasks increase. In natural\nlanguage processing and computer vision, parameter-efficient approaches like\nprompt-tuning and adapters have emerged as solid alternatives by fine-tuning\nonly a small number of extra parameters, without sacrificing performance\naccuracy. Specifically, adapters, due to their flexibility, have recently\ngarnered significant attention, leading to several variants. For audio\nclassification tasks, the Audio Spectrogram Transformer model shows impressive\nresults. However, surprisingly, how to efficiently adapt it to several\ndownstream tasks has not been tackled before. In this paper, we bridge this gap\nand present a detailed investigation of common parameter-efficient methods,\nrevealing that adapters consistently outperform the other methods across four\nbenchmarks. This trend is also confirmed in few-shot learning settings and when\nthe total number of trainable parameters increases, demonstrating adapters\nsuperior scalability. We finally study the best adapter configuration, as well\nas the role of residual connections in the learning process.",
            "author": [
                "Umberto Cappellazzo",
                "Daniele Falavigna",
                "Alessio Brutti",
                "Mirco Ravanelli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03694v2",
                "http://arxiv.org/pdf/2312.03694v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03690v1",
            "title": "Inverse Design of Vitrimeric Polymers by Molecular Dynamics and\n  Generative Modeling",
            "updated": "2023-12-06T18:53:45Z",
            "published": "2023-12-06T18:53:45Z",
            "summary": "Vitrimer is a new class of sustainable polymers with the ability of\nself-healing through rearrangement of dynamic covalent adaptive networks.\nHowever, a limited choice of constituent molecules restricts their property\nspace, prohibiting full realization of their potential applications. Through a\ncombination of molecular dynamics (MD) simulations and machine learning (ML),\nparticularly a novel graph variational autoencoder (VAE) model, we establish a\nmethod for generating novel vitrimers and guide their inverse design based on\ndesired glass transition temperature (Tg). We build the first vitrimer dataset\nof one million and calculate Tg on 8,424 of them by high-throughput MD\nsimulations calibrated by a Gaussian process model. The proposed VAE employs\ndual graph encoders and a latent dimension overlapping scheme which allows for\nindividual representation of multi-component vitrimers. By constructing a\ncontinuous latent space containing necessary information of vitrimers, we\ndemonstrate high accuracy and efficiency of our framework in discovering novel\nvitrimers with desirable Tg beyond the training regime. The proposed vitrimers\nwith reasonable synthesizability cover a wide range of Tg and broaden the\npotential widespread usage of vitrimeric materials.",
            "author": [
                "Yiwen Zheng",
                "Prakash Thakolkaran",
                "Jake A. Smith",
                "Ziheng Lu",
                "Shuxin Zheng",
                "Bichlien H. Nguyen",
                "Siddhant Kumar",
                "Aniruddh Vashisth"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03690v1",
                "http://arxiv.org/pdf/2312.03690v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03689v1",
            "title": "Evaluating and Mitigating Discrimination in Language Model Decisions",
            "updated": "2023-12-06T18:53:01Z",
            "published": "2023-12-06T18:53:01Z",
            "summary": "As language models (LMs) advance, interest is growing in applying them to\nhigh-stakes societal decisions, such as determining financing or housing\neligibility. However, their potential for discrimination in such contexts\nraises ethical concerns, motivating the need for better methods to evaluate\nthese risks. We present a method for proactively evaluating the potential\ndiscriminatory impact of LMs in a wide range of use cases, including\nhypothetical use cases where they have not yet been deployed. Specifically, we\nuse an LM to generate a wide array of potential prompts that decision-makers\nmay input into an LM, spanning 70 diverse decision scenarios across society,\nand systematically vary the demographic information in each prompt. Applying\nthis methodology reveals patterns of both positive and negative discrimination\nin the Claude 2.0 model in select settings when no interventions are applied.\nWhile we do not endorse or permit the use of language models to make automated\ndecisions for the high-risk use cases we study, we demonstrate techniques to\nsignificantly decrease both positive and negative discrimination through\ncareful prompt engineering, providing pathways toward safer deployment in use\ncases where they may be appropriate. Our work enables developers and\npolicymakers to anticipate, measure, and address discrimination as language\nmodel capabilities and applications continue to expand. We release our dataset\nand prompts at https://huggingface.co/datasets/Anthropic/discrim-eval",
            "author": [
                "Alex Tamkin",
                "Amanda Askell",
                "Liane Lovitt",
                "Esin Durmus",
                "Nicholas Joseph",
                "Shauna Kravec",
                "Karina Nguyen",
                "Jared Kaplan",
                "Deep Ganguli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03689v1",
                "http://arxiv.org/pdf/2312.03689v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03687v1",
            "title": "MatterGen: a generative model for inorganic materials design",
            "updated": "2023-12-06T18:52:16Z",
            "published": "2023-12-06T18:52:16Z",
            "summary": "The design of functional materials with desired properties is essential in\ndriving technological advances in areas like energy storage, catalysis, and\ncarbon capture. Generative models provide a new paradigm for materials design\nby directly generating entirely novel materials given desired property\nconstraints. Despite recent progress, current generative models have low\nsuccess rate in proposing stable crystals, or can only satisfy a very limited\nset of property constraints. Here, we present MatterGen, a model that generates\nstable, diverse inorganic materials across the periodic table and can further\nbe fine-tuned to steer the generation towards a broad range of property\nconstraints. To enable this, we introduce a new diffusion-based generative\nprocess that produces crystalline structures by gradually refining atom types,\ncoordinates, and the periodic lattice. We further introduce adapter modules to\nenable fine-tuning towards any given property constraints with a labeled\ndataset. Compared to prior generative models, structures produced by MatterGen\nare more than twice as likely to be novel and stable, and more than 15 times\ncloser to the local energy minimum. After fine-tuning, MatterGen successfully\ngenerates stable, novel materials with desired chemistry, symmetry, as well as\nmechanical, electronic and magnetic properties. Finally, we demonstrate\nmulti-property materials design capabilities by proposing structures that have\nboth high magnetic density and a chemical composition with low supply-chain\nrisk. We believe that the quality of generated materials and the breadth of\nMatterGen's capabilities represent a major advancement towards creating a\nuniversal generative model for materials design.",
            "author": [
                "Claudio Zeni",
                "Robert Pinsler",
                "Daniel Z\u00fcgner",
                "Andrew Fowler",
                "Matthew Horton",
                "Xiang Fu",
                "Sasha Shysheya",
                "Jonathan Crabb\u00e9",
                "Lixin Sun",
                "Jake Smith",
                "Ryota Tomioka",
                "Tian Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03687v1",
                "http://arxiv.org/pdf/2312.03687v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03815v1",
            "title": "LLM as OS (llmao), Agents as Apps: Envisioning AIOS, Agents and the\n  AIOS-Agent Ecosystem",
            "updated": "2023-12-06T18:50:26Z",
            "published": "2023-12-06T18:50:26Z",
            "summary": "This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system ``with soul''. Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level).",
            "author": [
                "Yingqiang Ge",
                "Yujie Ren",
                "Wenyue Hua",
                "Shuyuan Xu",
                "Juntao Tan",
                "Yongfeng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03815v1",
                "http://arxiv.org/pdf/2312.03815v1"
            ],
            "primary_category": "cs.OS",
            "category": [
                "cs.OS",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03680v1",
            "title": "Periodic homogenization of a class of weakly coupled systems of linear\n  PDEs",
            "updated": "2023-12-06T18:43:04Z",
            "published": "2023-12-06T18:43:04Z",
            "summary": "In this article, basing upon probabilistic methods, we discuss periodic\nhomogenization of a class of weakly coupled systems of linear elliptic and\nparabolic partial differential equations. Under the assumption that the systems\nhave rapidly periodically oscillating coefficients, we first prove that the\nappropriately centered and scaled continuous component of the associated regime\nswitching diffusion process converges weakly to a Brownian motion with\ncovariance matrix given in terms of the coefficients of the systems. The\nhomogenization results then follow by employing probabilistic representation of\nthe solutions to the systems and the continuous mapping theorem. The presented\nresults generalize the well-known results related to periodic homogenization of\nthe classical elliptic boundary-value problem and the classical parabolic\ninitial-value problem for a single equation.",
            "author": [
                "Nikola Sandri\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03680v1",
                "http://arxiv.org/pdf/2312.03680v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.AP",
                "35B27, 35J57, 35K45, 60F17, 60J25, 60J60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03675v1",
            "title": "GeoShapley: A Game Theory Approach to Measuring Spatial Effects in\n  Machine Learning Models",
            "updated": "2023-12-06T18:39:29Z",
            "published": "2023-12-06T18:39:29Z",
            "summary": "This paper introduces GeoShapley, a game theory approach to measuring spatial\neffects in machine learning models. GeoShapley extends the Nobel Prize-winning\nShapley value framework in game theory by conceptualizing location as a player\nin a model prediction game, which enables the quantification of the importance\nof location and the synergies between location and other features in a model.\nGeoShapley is a model-agnostic approach and can be applied to statistical or\nblack-box machine learning models in various structures. The interpretation of\nGeoShapley is directly linked with spatially varying coefficient models for\nexplaining spatial effects and additive models for explaining non-spatial\neffects. Using simulated data, GeoShapley values are validated against known\ndata-generating processes and are used for cross-comparison of seven\nstatistical and machine learning models. An empirical example of house price\nmodeling is used to illustrate GeoShapley's utility and interpretation with\nreal world data. The method is available as an open-source Python package named\ngeoshapley.",
            "author": [
                "Ziqi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03675v1",
                "http://arxiv.org/pdf/2312.03675v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03671v1",
            "title": "Direct Exoplanet Detection Using Deep Convolutional Image Reconstruction\n  (ConStruct): A New Algorithm for Post-Processing High-Contrast Images",
            "updated": "2023-12-06T18:36:03Z",
            "published": "2023-12-06T18:36:03Z",
            "summary": "We present a novel machine-learning approach for detecting faint point\nsources in high-contrast adaptive optics imaging datasets. The most widely used\nalgorithms for primary subtraction aim to decouple bright stellar speckle noise\nfrom planetary signatures by subtracting an approximation of the temporally\nevolving stellar noise from each frame in an imaging sequence. Our approach\naims to improve the stellar noise approximation and increase the planet\ndetection sensitivity by leveraging deep learning in a novel direct imaging\npost-processing algorithm. We show that a convolutional autoencoder neural\nnetwork, trained on an extensive reference library of real imaging sequences,\naccurately reconstructs the stellar speckle noise at the location of a\npotential planet signal. This tool is used in a post-processing algorithm we\ncall Direct Exoplanet Detection with Convolutional Image Reconstruction, or\nConStruct. The reliability and sensitivity of ConStruct are assessed using real\nKeck/NIRC2 angular differential imaging datasets. Of the 30 unique point\nsources we examine, ConStruct yields a higher S/N than traditional PCA-based\nprocessing for 67$\\%$ of the cases and improves the relative contrast by up to\na factor of 2.6. This work demonstrates the value and potential of deep\nlearning to take advantage of a diverse reference library of point spread\nfunction realizations to improve direct imaging post-processing. ConStruct and\nits future improvements may be particularly useful as tools for post-processing\nhigh-contrast images from the James Webb Space Telescope and extreme adaptive\noptics instruments, both for the current generation and those being designed\nfor the upcoming 30 meter-class telescopes.",
            "author": [
                "Trevor N. Wolf",
                "Brandon A. Jones",
                "Brendan P. Bowler"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03671v1",
                "http://arxiv.org/pdf/2312.03671v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.EP",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03668v1",
            "title": "An Integration of Pre-Trained Speech and Language Models for End-to-End\n  Speech Recognition",
            "updated": "2023-12-06T18:34:42Z",
            "published": "2023-12-06T18:34:42Z",
            "summary": "Advances in machine learning have made it possible to perform various text\nand speech processing tasks, including automatic speech recognition (ASR), in\nan end-to-end (E2E) manner. Since typical E2E approaches require large amounts\nof training data and resources, leveraging pre-trained foundation models\ninstead of training from scratch is gaining attention. Although there have been\nattempts to use pre-trained speech and language models in ASR, most of them are\nlimited to using either. This paper explores the potential of integrating a\npre-trained speech representation model with a large language model (LLM) for\nE2E ASR. The proposed model enables E2E ASR by generating text tokens in an\nautoregressive manner via speech representations as speech prompts, taking\nadvantage of the vast knowledge provided by the LLM. Furthermore, the proposed\nmodel can incorporate remarkable developments for LLM utilization, such as\ninference optimization and parameter-efficient domain adaptation. Experimental\nresults show that the proposed model achieves performance comparable to modern\nE2E ASR models.",
            "author": [
                "Yukiya Hono",
                "Koh Mitsuda",
                "Tianyu Zhao",
                "Kentaro Mitsui",
                "Toshiaki Wakatsuki",
                "Kei Sawada"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03668v1",
                "http://arxiv.org/pdf/2312.03668v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03666v1",
            "title": "Towards small and accurate convolutional neural networks for acoustic\n  biodiversity monitoring",
            "updated": "2023-12-06T18:34:01Z",
            "published": "2023-12-06T18:34:01Z",
            "summary": "Automated classification of animal sounds is a prerequisite for large-scale\nmonitoring of biodiversity. Convolutional Neural Networks (CNNs) are among the\nmost promising algorithms but they are slow, often achieve poor classification\nin the field and typically require large training data sets. Our objective was\nto design CNNs that are fast at inference time and achieve good classification\nperformance while learning from moderate-sized data. Recordings from a\nrainforest ecosystem were used. Start and end-point of sounds from 20 bird\nspecies were manually annotated. Spectrograms from 10 second segments were used\nas CNN input. We designed simple CNNs with a frequency unwrapping layer\n(SIMP-FU models) such that any output unit was connected to all spectrogram\nfrequencies but only to a sub-region of time, the Receptive Field (RF). Our\nmodels allowed experimentation with different RF durations. Models either used\nthe time-indexed labels that encode start and end-point of sounds or simpler\nsegment-level labels. Models learning from time-indexed labels performed\nconsiderably better than their segment-level counterparts. Best classification\nperformances was achieved for models with intermediate RF duration of 1.5\nseconds. The best SIMP-FU models achieved AUCs over 0.95 in 18 of 20 classes on\nthe test set. On compact low-cost hardware the best SIMP-FU models evaluated up\nto seven times faster than real-time data acquisition. RF duration was a major\ndriver of classification performance. The optimum of 1.5 s was in the same\nrange as the duration of the sounds. Our models achieved good classification\nperformance while learning from moderate-sized training data. This is explained\nby the usage of time-indexed labels during training and adequately sized RF.\nResults confirm the feasibility of deploying small CNNs with good\nclassification performance on compact low-cost devices.",
            "author": [
                "Serge Zaugg",
                "Mike van der Schaar",
                "Florence Erbs",
                "Antonio Sanchez",
                "Joan V. Castell",
                "Emiliano Ramallo",
                "Michel Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03666v1",
                "http://arxiv.org/pdf/2312.03666v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03664v1",
            "title": "Generative agent-based modeling with actions grounded in physical,\n  social, or digital space using Concordia",
            "updated": "2023-12-06T18:33:50Z",
            "published": "2023-12-06T18:33:50Z",
            "summary": "Agent-based modeling has been around for decades, and applied widely across\nthe social and natural sciences. The scope of this research method is now\npoised to grow dramatically as it absorbs the new affordances provided by Large\nLanguage Models (LLM)s. Generative Agent-Based Models (GABM) are not just\nclassic Agent-Based Models (ABM)s where the agents talk to one another. Rather,\nGABMs are constructed using an LLM to apply common sense to situations, act\n\"reasonably\", recall common semantic knowledge, produce API calls to control\ndigital technologies like apps, and communicate both within the simulation and\nto researchers viewing it from the outside. Here we present Concordia, a\nlibrary to facilitate constructing and working with GABMs. Concordia makes it\neasy to construct language-mediated simulations of physically- or\ndigitally-grounded environments. Concordia agents produce their behavior using\na flexible component system which mediates between two fundamental operations:\nLLM calls and associative memory retrieval. A special agent called the Game\nMaster (GM), which was inspired by tabletop role-playing games, is responsible\nfor simulating the environment where the agents interact. Agents take actions\nby describing what they want to do in natural language. The GM then translates\ntheir actions into appropriate implementations. In a simulated physical world,\nthe GM checks the physical plausibility of agent actions and describes their\neffects. In digital environments simulating technologies such as apps and\nservices, the GM may handle API calls to integrate with external tools such as\ngeneral AI assistants (e.g., Bard, ChatGPT), and digital apps (e.g., Calendar,\nEmail, Search, etc.). Concordia was designed to support a wide array of\napplications both in scientific research and for evaluating performance of real\ndigital services by simulating users and/or generating synthetic data.",
            "author": [
                "Alexander Sasha Vezhnevets",
                "John P. Agapiou",
                "Avia Aharon",
                "Ron Ziv",
                "Jayd Matyas",
                "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n",
                "William A. Cunningham",
                "Simon Osindero",
                "Danny Karmon",
                "Joel Z. Leibo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03664v1",
                "http://arxiv.org/pdf/2312.03664v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03663v1",
            "title": "$H$-percolation with a random $H$",
            "updated": "2023-12-06T18:33:00Z",
            "published": "2023-12-06T18:33:00Z",
            "summary": "In $H$-percolation, we start with an Erd\\H{o}s--R\\'enyi graph ${\\mathcal\nG}_{n,p}$ and then iteratively add edges that complete copies of $H$. The\nprocess percolates if all edges missing from ${\\mathcal G}_{n,p}$ are\neventually added. We find the critical threshold $p_c$ when $H={\\mathcal\nG}_{k,1/2}$ is uniformly random, solving a problem of Balogh, Bollob\\'as and\nMorris.",
            "author": [
                "Zsolt Bartha",
                "Brett Kolesnik",
                "Gal Kronenberg"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03663v1",
                "http://arxiv.org/pdf/2312.03663v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "05C35, 05C80, 05C99, 60K35, 68Q80"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03661v1",
            "title": "Reason2Drive: Towards Interpretable and Chain-based Reasoning for\n  Autonomous Driving",
            "updated": "2023-12-06T18:32:33Z",
            "published": "2023-12-06T18:32:33Z",
            "summary": "Large vision-language models (VLMs) have garnered increasing interest in\nautonomous driving areas, due to their advanced capabilities in complex\nreasoning tasks essential for highly autonomous vehicle behavior. Despite their\npotential, research in autonomous systems is hindered by the lack of datasets\nwith annotated reasoning chains that explain the decision-making processes in\ndriving. To bridge this gap, we present Reason2Drive, a benchmark dataset with\nover 600K video-text pairs, aimed at facilitating the study of interpretable\nreasoning in complex driving environments. We distinctly characterize the\nautonomous driving process as a sequential combination of perception,\nprediction, and reasoning steps, and the question-answer pairs are\nautomatically collected from a diverse range of open-source outdoor driving\ndatasets, including nuScenes, Waymo and ONCE. Moreover, we introduce a novel\naggregated evaluation metric to assess chain-based reasoning performance in\nautonomous systems, addressing the semantic ambiguities of existing metrics\nsuch as BLEU and CIDEr. Based on the proposed benchmark, we conduct experiments\nto assess various existing VLMs, revealing insights into their reasoning\ncapabilities. Additionally, we develop an efficient approach to empower VLMs to\nleverage object-level perceptual elements in both feature extraction and\nprediction, further enhancing their reasoning accuracy. The code and dataset\nwill be released.",
            "author": [
                "Ming Nie",
                "Renyuan Peng",
                "Chunwei Wang",
                "Xinyue Cai",
                "Jianhua Han",
                "Hang Xu",
                "Li Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03661v1",
                "http://arxiv.org/pdf/2312.03661v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03659v1",
            "title": "The SAMI Galaxy Survey: $\u03a3_{\\rm SFR}$ drives the presence of\n  complex emission line profiles in star-forming galaxies",
            "updated": "2023-12-06T18:28:25Z",
            "published": "2023-12-06T18:28:25Z",
            "summary": "Galactic fountains driven by star formation result in a variety of kinematic\nstructures such as ionised winds and thick gas disks, both of which manifest as\ncomplex emission line profiles that can be parametrised by multiple Gaussian\ncomponents. We use integral field spectroscopy (IFS) from the SAMI Galaxy\nSurvey to spectrally resolve these features, traced by broad H$\\alpha$\ncomponents, and distinguish them from the star-forming thin disk, traced by\nnarrow components, in 3068 galaxies in the local Universe. Using a matched\nsample analysis technique, we demonstrate that the presence of complex emission\nline profiles in star-forming galaxies is most strongly correlated with the\nglobal star formation rate (SFR) surface density of the host galaxy measured\nwithin $1R_{\\rm e}$ ($\\Sigma_{{\\rm SFR},R_{\\rm e}}$), even when controlling for\nboth observational biases, including inclination, amplitude-to-noise and\nangular scale, and sample biases in parameters such as stellar mass and SFR.\nLeveraging the spatially resolved nature of the dataset, we determine that the\npresence of complex emission line profiles within individual spaxels is driven\nnot only by the local $\\Sigma_{\\rm SFR}$, but by the $\\Sigma_{{\\rm SFR},R_{\\rm\ne}}$ of the host galaxy. We also parametrise the clumpiness of the SFR within\nindividual galaxies, and find that $\\Sigma_{{\\rm SFR},R_{\\rm e}}$ is a stronger\npredictor of the presence of complex emission line profiles than clumpiness. We\nconclude that, with a careful treatment of observational effects, it is\npossible to identify structures traced by complex emission line profiles,\nincluding winds and thick ionised gas disks, at the spatial and spectral\nresolution of SAMI using the Gaussian decomposition technique.",
            "author": [
                "Henry R. M. Zovaro",
                "J. Trevor Mendel",
                "Brent Groves",
                "Lisa J. Kewley",
                "Matthew Colless",
                "Andrei Ristea",
                "Luca Cortese",
                "Sree Oh",
                "Francesco D'Eugenio",
                "Scott M. Croom",
                "\u00c1ngel R. L\u00f3pez-S\u00e1nchez",
                "Jesse van de Sande",
                "Sarah Brough",
                "Anne M. Medling",
                "Joss Bland-Hawthorn",
                "Julia J. Bryant"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03659v1",
                "http://arxiv.org/pdf/2312.03659v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03813v1",
            "title": "Improving Activation Steering in Language Models with Mean-Centring",
            "updated": "2023-12-06T18:27:07Z",
            "published": "2023-12-06T18:27:07Z",
            "summary": "Recent work in activation steering has demonstrated the potential to better\ncontrol the outputs of Large Language Models (LLMs), but it involves finding\nsteering vectors. This is difficult because engineers do not typically know how\nfeatures are represented in these models. We seek to address this issue by\napplying the idea of mean-centring to steering vectors. We find that taking the\naverage of activations associated with a target dataset, and then subtracting\nthe mean of all training activations, results in effective steering vectors. We\ntest this method on a variety of models on natural language tasks by steering\naway from generating toxic text, and steering the completion of a story towards\na target genre. We also apply mean-centring to extract function vectors, more\neffectively triggering the execution of a range of natural language tasks by a\nsignificant margin (compared to previous baselines). This suggests that\nmean-centring can be used to easily improve the effectiveness of activation\nsteering in a wide range of contexts.",
            "author": [
                "Ole Jorgensen",
                "Dylan Cope",
                "Nandi Schoots",
                "Murray Shanahan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03813v1",
                "http://arxiv.org/pdf/2312.03813v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03656v1",
            "title": "Interpretability Illusions in the Generalization of Simplified Models",
            "updated": "2023-12-06T18:25:53Z",
            "published": "2023-12-06T18:25:53Z",
            "summary": "A common method to study deep learning systems is to use simplified model\nrepresentations -- for example, using singular value decomposition to visualize\nthe model's hidden states in a lower dimensional space. This approach assumes\nthat the results of these simplified are faithful to the original model. Here,\nwe illustrate an important caveat to this assumption: even if the simplified\nrepresentations can accurately approximate the full model on the training set,\nthey may fail to accurately capture the model's behavior out of distribution --\nthe understanding developed from simplified representations may be an illusion.\nWe illustrate this by training Transformer models on controlled datasets with\nsystematic generalization splits. First, we train models on the Dyck\nbalanced-parenthesis languages. We simplify these models using tools like\ndimensionality reduction and clustering, and then explicitly test how these\nsimplified proxies match the behavior of the original model on various\nout-of-distribution test sets. We find that the simplified proxies are\ngenerally less faithful out of distribution. In cases where the original model\ngeneralizes to novel structures or deeper depths, the simplified versions may\nfail, or generalize better. This finding holds even if the simplified\nrepresentations do not directly depend on the training distribution. Next, we\nstudy a more naturalistic task: predicting the next character in a dataset of\ncomputer code. We find similar generalization gaps between the original model\nand simplified proxies, and conduct further analysis to investigate which\naspects of the code completion task are associated with the largest gaps.\nTogether, our results raise questions about the extent to which mechanistic\ninterpretations derived using tools like SVD can reliably predict what a model\nwill do in novel situations.",
            "author": [
                "Dan Friedman",
                "Andrew Lampinen",
                "Lucas Dixon",
                "Danqi Chen",
                "Asma Ghandeharioun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03656v1",
                "http://arxiv.org/pdf/2312.03656v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03654v1",
            "title": "Efficient Inverse Design Optimization through Multi-fidelity\n  Simulations, Machine Learning, and Search Space Reduction Strategies",
            "updated": "2023-12-06T18:20:46Z",
            "published": "2023-12-06T18:20:46Z",
            "summary": "This paper introduces a methodology designed to augment the inverse design\noptimization process in scenarios constrained by limited compute, through the\nstrategic synergy of multi-fidelity evaluations, machine learning models, and\noptimization algorithms. The proposed methodology is analyzed on two distinct\nengineering inverse design problems: airfoil inverse design and the scalar\nfield reconstruction problem. It leverages a machine learning model trained\nwith low-fidelity simulation data, in each optimization cycle, thereby\nproficiently predicting a target variable and discerning whether a\nhigh-fidelity simulation is necessitated, which notably conserves computational\nresources. Additionally, the machine learning model is strategically deployed\nprior to optimization to reduce the search space, thereby further accelerating\nconvergence toward the optimal solution. The methodology has been employed to\nenhance two optimization algorithms, namely Differential Evolution and Particle\nSwarm Optimization. Comparative analyses illustrate performance improvements\nacross both algorithms. Notably, this method is adeptly adaptable across any\ninverse design application, facilitating a harmonious synergy between a\nrepresentative low-fidelity machine learning model, and high-fidelity\nsimulation, and can be seamlessly applied across any variety of\npopulation-based optimization algorithms.",
            "author": [
                "Luka Grbcic",
                "Juliane M\u00fcller",
                "Wibe Albert de Jong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03654v1",
                "http://arxiv.org/pdf/2312.03654v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI",
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03649v1",
            "title": "Quantum Optics with Rydberg Superatoms",
            "updated": "2023-12-06T18:11:04Z",
            "published": "2023-12-06T18:11:04Z",
            "summary": "Quantum optics based on highly excited atoms, also known as Rydberg atoms,\nhas cemented itself as a powerful platform for the manipulation of light at the\nfew-photon level. The Rydberg blockade, resulting from the strong interaction\nbetween individual Rydberg atoms, can turn a large ensemble of atoms into a\nsystem which collectively resembles a single two-level emitter, a so-called\nRydberg superatom. The coupling of this artificial emitter to a driving\nphotonic mode is collectively enhanced by Rydberg interactions, enabling strong\ncoherent coupling at the few-photon level in free-space. The exquisite level of\ncontrol achievable through this has already demonstrated its utility in\napplications of quantum computing and information processing. Here, we review\nthe derivation of the collective coupling between a Rydberg superatom and a\nsingle light mode and discuss the similarity of this free-space setup to\nwaveguide quantum electrodynamics systems of quantum emitters coupled to\nphotonic waveguides. We also briefly review applications of Rydberg superatoms\nto quantum optics such as single-photon generation and single-photon\nsubtraction.",
            "author": [
                "Jan Kumlin",
                "Christoph Braun",
                "Christoph Tresp",
                "Nina Stiesdal",
                "Sebastian Hofferberth",
                "Asaf Paris-Mandoki"
            ],
            "link": [
                "http://dx.doi.org/10.1088/2399-6528/acd51d",
                "http://arxiv.org/abs/2312.03649v1",
                "http://arxiv.org/pdf/2312.03649v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03810v1",
            "title": "Observational constraints on the second-order primordial power spectrum:\n  Exploring a Continuous Spontaneous Localization inspired inflationary model",
            "updated": "2023-12-06T18:06:06Z",
            "published": "2023-12-06T18:06:06Z",
            "summary": "Inflation, a period of exponential expansion in the early Universe, is\nconsidered an important part of the standard $\\Lambda$CDM cosmological model,\nand plays a crucial role in explaining a wide range of current observations.\nThe standard inflationary model predicts a primordial spectrum of fluctuations\nthat is nearly scale-independent, fitting remarkably well the latest\nobservational data. Nevertheless, there is an ongoing discussion surrounding\nthe transition from an initial homogeneous and isotropic quantum state,\ncharacterizing the matter fields during inflation, to a classical\ninhomogeneous/anisotropic one, which gives rise to large-scale structure in the\nUniverse. To tackle this issue, in the present work we explore an inflationary\nscenario where quantum ``collapse'' (or reduction) occurs naturally during the\nevolution of the system; this model is inspired in the so called Continuous\nSpontaneous Localization (CSL) model. Our present work builds upon previous\nresults by considering the primordial power spectrum up to the second order in\nthe Hubble Flow Functions, where we perform an estimation of the model free\nparameters. By validating the predictions of the model against observational\ndata, we investigate whether this second-order calculation can explain the\nslight departure from the power law observed in the scalar spectral running\nindex. We hope this research contributes to the understanding of the\nquantum-to-classical transition and its implications for cosmology.",
            "author": [
                "Maria Pia Piccirilli",
                "Gabriel Leon"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.dark.2023.101390",
                "http://arxiv.org/abs/2312.03810v1",
                "http://arxiv.org/pdf/2312.03810v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03647v1",
            "title": "Editable Stain Transformation Of Histological Images Using Unpaired GANs",
            "updated": "2023-12-06T18:05:41Z",
            "published": "2023-12-06T18:05:41Z",
            "summary": "Double staining in histopathology, particularly for metaplastic breast\ncancer, typically employs H&E and P63 dyes. However, P63's tissue damage and\nhigh cost necessitate alternative methods. This study introduces xAI-CycleGAN,\nan advanced architecture combining Mask CycleGAN with explainability features\nand structure-preserving capabilities for transforming H&E stained breast\ntissue images into P63-like images. The architecture allows for output editing,\nenhancing resemblance to actual images and enabling further model refinement.\nWe showcase xAI-CycleGAN's efficacy in maintaining structural integrity and\ngenerating high-quality images. Additionally, a histopathologist survey\nindicates the generated images' realism is often comparable to actual images,\nvalidating our model's high-quality output.",
            "author": [
                "Tibor Sloboda",
                "Luk\u00e1\u0161 Hudec",
                "Wanda Bene\u0161ov\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03647v1",
                "http://arxiv.org/pdf/2312.03647v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03646v1",
            "title": "An Irredundant Decomposition of Data Flow with Affine Dependences",
            "updated": "2023-12-06T18:03:04Z",
            "published": "2023-12-06T18:03:04Z",
            "summary": "Optimization pipelines targeting polyhedral programs try to maximize the\ncompute throughput. Traditional approaches favor reuse and temporal locality;\nwhile the communicated volume can be low, failure to optimize spatial locality\nmay cause a low I/O performance.\n  Memory allocation schemes using data partitioning such as data tiling can\nimprove the spatial locality, but they are domain-specific and rarely applied\nby compilers when an existing allocation is supplied.\n  In this paper, we propose to derive a partitioned memory allocation for tiled\npolyhedral programs using their data flow information. We extend the existing\nMARS partitioning to handle affine dependences, and determine which dependences\ncan lead to a regular, simple control flow for communications.\n  While this paper consists in a theoretical study, previous work on data\npartitioning in inter-node scenarios has shown performance improvements due to\nbetter bandwidth utilization.",
            "author": [
                "Corentin Ferry",
                "Steven Derrien",
                "Sanjay Rajopadhye"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03646v1",
                "http://arxiv.org/pdf/2312.03646v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03645v1",
            "title": "Fairness and Deception in Human Interactions with Artificial Agents",
            "updated": "2023-12-06T18:00:02Z",
            "published": "2023-12-06T18:00:02Z",
            "summary": "Online information ecosystems are now central to our everyday social\ninteractions. Of the many opportunities and challenges this presents, the\ncapacity for artificial agents to shape individual and collective human\ndecision-making in such environments is of particular importance. In order to\nassess and manage the impact of artificial agents on human well-being, we must\nconsider not only the technical capabilities of such agents, but the impact\nthey have on human social dynamics at the individual and population level. We\napproach this problem by modelling the potential for artificial agents to\n\"nudge\" attitudes to fairness and cooperation in populations of human agents,\nwho update their behavior according to a process of social learning. We show\nthat the presence of artificial agents in a population playing the ultimatum\ngame generates highly divergent, multi-stable outcomes in the learning dynamics\nof human agents' behaviour. These outcomes correspond to universal fairness\n(successful nudging), universal selfishness (failed nudging), and a strategy of\nfairness towards artificial agents and selfishness towards other human agents\n(unintended consequences of nudging). We then consider the consequences of\nhuman agents shifting their behavior when they are aware that they are\ninteracting with an artificial agent. We show that under a wide range of\ncircumstances artificial agents can achieve optimal outcomes in their\ninteractions with human agents while avoiding deception. However we also find\nthat, in the donation game, deception tends to make nudging easier to achieve.",
            "author": [
                "Theodor Cimpeanu",
                "Alexander J. Stewart"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03645v1",
                "http://arxiv.org/pdf/2312.03645v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03644v1",
            "title": "MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit\n  Assignment",
            "updated": "2023-12-06T17:59:34Z",
            "published": "2023-12-06T17:59:34Z",
            "summary": "Offline Multi-agent Reinforcement Learning (MARL) is valuable in scenarios\nwhere online interaction is impractical or risky. While independent learning in\nMARL offers flexibility and scalability, accurately assigning credit to\nindividual agents in offline settings poses challenges due to partial\nobservability and emergent behavior. Directly transferring the online credit\nassignment method to offline settings results in suboptimal outcomes due to the\nabsence of real-time feedback and intricate agent interactions. Our approach,\nMACCA, characterizing the generative process as a Dynamic Bayesian Network,\ncaptures relationships between environmental variables, states, actions, and\nrewards. Estimating this model on offline data, MACCA can learn each agent's\ncontribution by analyzing the causal relationship of their individual rewards,\nensuring accurate and interpretable credit assignment. Additionally, the\nmodularity of our approach allows it to seamlessly integrate with various\noffline MARL methods. Theoretically, we proved that under the setting of the\noffline dataset, the underlying causal structure and the function for\ngenerating the individual rewards of agents are identifiable, which laid the\nfoundation for the correctness of our modeling. Experimentally, we tested MACCA\nin two environments, including discrete and continuous action settings. The\nresults show that MACCA outperforms SOTA methods and improves performance upon\ntheir backbones.",
            "author": [
                "Ziyan Wang",
                "Yali Du",
                "Yudi Zhang",
                "Meng Fang",
                "Biwei Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03644v1",
                "http://arxiv.org/pdf/2312.03644v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03640v1",
            "title": "Training Neural Networks on RAW and HDR Images for Restoration Tasks",
            "updated": "2023-12-06T17:47:16Z",
            "published": "2023-12-06T17:47:16Z",
            "summary": "The vast majority of standard image and video content available online is\nrepresented in display-encoded color spaces, in which pixel values are\nconveniently scaled to a limited range (0-1) and the color distribution is\napproximately perceptually uniform. In contrast, both camera RAW and high\ndynamic range (HDR) images are often represented in linear color spaces, in\nwhich color values are linearly related to colorimetric quantities of light.\nWhile training on commonly available display-encoded images is a\nwell-established practice, there is no consensus on how neural networks should\nbe trained for tasks on RAW and HDR images in linear color spaces. In this\nwork, we test several approaches on three popular image restoration\napplications: denoising, deblurring, and single-image super-resolution. We\nexamine whether HDR/RAW images need to be display-encoded using popular\ntransfer functions (PQ, PU21, mu-law), or whether it is better to train in\nlinear color spaces, but use loss functions that correct for perceptual\nnon-uniformity. Our results indicate that neural networks train significantly\nbetter on HDR and RAW images represented in display-encoded color spaces, which\noffer better perceptual uniformity than linear spaces. This small change to the\ntraining strategy can bring a very substantial gain in performance, up to 10-15\ndB.",
            "author": [
                "Lei Luo",
                "Alexandre Chapiro",
                "Xiaoyu Xiang",
                "Yuchen Fan",
                "Rakesh Ranjan",
                "Rafal Mantiuk"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03640v1",
                "http://arxiv.org/pdf/2312.03640v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03634v1",
            "title": "Singular cohomology of symplectic quotients by circle actions and Kirwan\n  surjectivity",
            "updated": "2023-12-06T17:30:51Z",
            "published": "2023-12-06T17:30:51Z",
            "summary": "Let $M$ be a symplectic manifold carrying a Hamiltonian $S^1$-action with\nmomentum map $J:M \\rightarrow \\mathbb{R}$ and consider the corresponding\nsymplectic quotient $\\mathcal{M}_0:=J^{-1}(0)/S^1$. We extend Sjamaar's complex\nof differential forms on $\\mathcal{M}_0$, whose cohomology is isomorphic to the\nsingular cohomology $H(\\mathcal{M}_0;\\mathbb{R})$ of $\\mathcal{M}_0$ with real\ncoefficients, to a complex of differential forms on $\\mathcal{M}_0$ associated\nwith a partial desingularization $\\widetilde{\\mathcal{M}}_0$, which we call\nresolution differential forms. The cohomology of that complex turns out to be\nisomorphic to the de Rham cohomology $H(\\widetilde{ \\mathcal{M}}_0)$ of\n$\\widetilde{\\mathcal{M}}_0$. Based on this, we derive a long exact sequence\ninvolving both $H(\\mathcal{M}_0;\\mathbb{R})$ and $H(\\widetilde{\n\\mathcal{M}}_0)$ and give conditions for its splitting. We then define a Kirwan\nmap $\\mathcal{K}:H_{S^1}(M) \\rightarrow H(\\widetilde{\\mathcal{M}}_0)$ from the\nequivariant cohomology $H_{S^1}(M)$ of $M$ to $H(\\widetilde{\\mathcal{M}}_0)$\nand show that its image contains the image of $H(\\mathcal{M}_0;\\mathbb{R})$ in\n$H(\\widetilde{\\mathcal{M}}_0)$ under the natural inclusion. Combining both\nresults in the case that all fixed point components of $M$ have vanishing odd\ncohomology we obtain a surjection $\\check \\kappa:H^\\textrm{ev}_{S^1}(M)\n\\rightarrow H^\\textrm{ev}(\\mathcal{M}_0;\\mathbb{R})$ in even degrees, while\nalready simple examples show that a similar surjection in odd degrees does not\nexist in general. As an interesting class of examples we study abelian polygon\nspaces.",
            "author": [
                "Benjamin Delarue",
                "Pablo Ramacher",
                "Maximilian Schmitt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03634v1",
                "http://arxiv.org/pdf/2312.03634v1"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03633v1",
            "title": "Not All Large Language Models (LLMs) Succumb to the \"Reversal Curse\": A\n  Comparative Study of Deductive Logical Reasoning in BERT and GPT Models",
            "updated": "2023-12-06T17:29:45Z",
            "published": "2023-12-06T17:29:45Z",
            "summary": "The \"Reversal Curse\" refers to the scenario where auto-regressive decoder\nlarge language models (LLMs), such as ChatGPT, trained on \"A is B\" fail to\nlearn \"B is A\", demonstrating a basic failure of logical deduction. This raises\na red flag in the use of GPT models for certain general tasks such as\nconstructing knowledge graphs, considering their adherence to this symmetric\nprinciple. In our study, we examined a bidirectional LLM, BERT, and found that\nit is immune to the reversal curse. Driven by ongoing efforts to construct\nbiomedical knowledge graphs with LLMs, we also embarked on evaluating more\ncomplex but essential deductive reasoning capabilities. This process included\nfirst training encoder and decoder language models to master the intersection\n($\\cap$) and union ($\\cup$) operations on two sets and then moving on to assess\ntheir capability to infer different combinations of union ($\\cup$) and\nintersection ($\\cap$) operations on three newly created sets. The findings\nshowed that while both encoder and decoder language models, trained for tasks\ninvolving two sets (union/intersection), were proficient in such scenarios,\nthey encountered difficulties when dealing with operations that included three\nsets (various combinations of union and intersection). Our research highlights\nthe distinct characteristics of encoder and decoder models in simple and\ncomplex logical reasoning. In practice, the choice between BERT and GPT should\nbe guided by the specific requirements and nature of the task at hand,\nleveraging their respective strengths in bidirectional context comprehension\nand sequence prediction.",
            "author": [
                "Jingye Yang",
                "Da Wu",
                "Kai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03633v1",
                "http://arxiv.org/pdf/2312.03633v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03632v1",
            "title": "Multimodal Data and Resource Efficient Device-Directed Speech Detection\n  with Large Foundation Models",
            "updated": "2023-12-06T17:29:03Z",
            "published": "2023-12-06T17:29:03Z",
            "summary": "Interactions with virtual assistants typically start with a trigger phrase\nfollowed by a command. In this work, we explore the possibility of making these\ninteractions more natural by eliminating the need for a trigger phrase. Our\ngoal is to determine whether a user addressed the virtual assistant based on\nsignals obtained from the streaming audio recorded by the device microphone. We\naddress this task by combining 1-best hypotheses and decoder signals from an\nautomatic speech recognition system with acoustic representations from an audio\nencoder as input features to a large language model (LLM). In particular, we\nare interested in data and resource efficient systems that require only a small\namount of training data and can operate in scenarios with only a single frozen\nLLM available on a device. For this reason, our model is trained on 80k or less\nexamples of multimodal data using a combination of low-rank adaptation and\nprefix tuning. We compare the proposed system to unimodal baselines and show\nthat the multimodal approach achieves lower equal-error-rates (EERs), while\nusing only a fraction of the training data. We also show that low-dimensional\nspecialized audio representations lead to lower EERs than high-dimensional\ngeneral audio representations.",
            "author": [
                "Dominik Wagner",
                "Alexander Churchill",
                "Siddharth Sigtia",
                "Panayiotis Georgiou",
                "Matt Mirsamadi",
                "Aarshee Mishra",
                "Erik Marchi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03632v1",
                "http://arxiv.org/pdf/2312.03632v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03631v1",
            "title": "MOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations",
            "updated": "2023-12-06T17:28:03Z",
            "published": "2023-12-06T17:28:03Z",
            "summary": "While recent years have seen rapid progress in image-conditioned text\ngeneration, image captioning still suffers from the fundamental issue of\nhallucinations, the generation of spurious details that cannot be inferred from\nthe given image. Dedicated methods for reducing hallucinations in image\ncaptioning largely focus on closed-vocabulary object tokens, ignoring most\ntypes of hallucinations that occur in practice. In this work, we propose MOCHa,\nan approach that harnesses advancements in reinforcement learning (RL) to\naddress the sequence-level nature of hallucinations in an open-world setup. To\noptimize for caption fidelity to the input image, we leverage ground-truth\nreference captions as proxies to measure the logical consistency of generated\ncaptions. However, optimizing for caption fidelity alone fails to preserve the\nsemantic adequacy of generations; therefore, we propose a multi-objective\nreward function that jointly targets these qualities, without requiring any\nstrong supervision. We demonstrate that these goals can be simultaneously\noptimized with our framework, enhancing performance for various captioning\nmodels of different scales. Our qualitative and quantitative results\ndemonstrate MOCHa's superior performance across various established metrics. We\nalso demonstrate the benefit of our method in the open-vocabulary setting. To\nthis end, we contribute OpenCHAIR, a new benchmark for quantifying\nopen-vocabulary hallucinations in image captioning models, constructed using\ngenerative foundation models. We will release our code, benchmark, and trained\nmodels.",
            "author": [
                "Assaf Ben-Kish",
                "Moran Yanuka",
                "Morris Alper",
                "Raja Giryes",
                "Hadar Averbuch-Elor"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03631v1",
                "http://arxiv.org/pdf/2312.03631v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03629v1",
            "title": "Freeform Direct-write and Rewritable Photonic Integrated Circuits in\n  Phase-Change Thin Films",
            "updated": "2023-12-06T17:21:05Z",
            "published": "2023-12-06T17:21:05Z",
            "summary": "Photonic integrated circuits (PICs) with rapid prototyping and reprogramming\ncapabilities promise revolutionary impacts on a plethora of photonic\ntechnologies. Here, we report direct-write and rewritable photonic circuits on\na low-loss phase change material (PCM) thin film. Complete end-to-end PICs are\ndirectly laser written in one step without additional fabrication processes,\nand any part of the circuit can be erased and rewritten, facilitating rapid\ndesign modification. We demonstrate the versatility of this technique for\ndiverse applications, including an optical interconnect fabric for\nreconfigurable networking, a photonic crossbar array for optical computing, and\na tunable optical filter for optical signal processing. By combining the\nprogrammability of the direct laser writing technique with PCM, our technique\nunlocks opportunities for programmable photonic networking, computing, and\nsignal processing. Moreover, the rewritable photonic circuits enable rapid\nprototyping and testing in a convenient and cost-efficient manner, eliminate\nthe need for nanofabrication facilities, and thus promote the proliferation of\nphotonics research and education to a broader community.",
            "author": [
                "Changming Wu",
                "Haoqin Deng",
                "Yi-Siou Huang",
                "Heshan Yu",
                "Ichiro Takeuchi",
                "Carlos A. R\u00edos Ocampo",
                "Mo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03629v1",
                "http://arxiv.org/pdf/2312.03629v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03626v1",
            "title": "TokenCompose: Grounding Diffusion with Token-level Supervision",
            "updated": "2023-12-06T17:13:15Z",
            "published": "2023-12-06T17:13:15Z",
            "summary": "We present TokenCompose, a Latent Diffusion Model for text-to-image\ngeneration that achieves enhanced consistency between user-specified text\nprompts and model-generated images. Despite its tremendous success, the\nstandard denoising process in the Latent Diffusion Model takes text prompts as\nconditions only, absent explicit constraint for the consistency between the\ntext prompts and the image contents, leading to unsatisfactory results for\ncomposing multiple object categories. TokenCompose aims to improve\nmulti-category instance composition by introducing the token-wise consistency\nterms between the image content and object segmentation maps in the finetuning\nstage. TokenCompose can be applied directly to the existing training pipeline\nof text-conditioned diffusion models without extra human labeling information.\nBy finetuning Stable Diffusion, the model exhibits significant improvements in\nmulti-category instance composition and enhanced photorealism for its generated\nimages.",
            "author": [
                "Zirui Wang",
                "Zhizhou Sha",
                "Zheng Ding",
                "Yilin Wang",
                "Zhuowen Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03626v1",
                "http://arxiv.org/pdf/2312.03626v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03624v1",
            "title": "Coherent pair injection as a route towards the enhancement of supersolid\n  order in many-body bosonic models",
            "updated": "2023-12-06T17:12:51Z",
            "published": "2023-12-06T17:12:51Z",
            "summary": "Over the last couple of decades, quantum simulators have been probing quantum\nmany-body physics with unprecedented levels of control. So far, the main focus\nhas been on the access to novel observables and dynamical conditions related to\ncondensed-matter models. However, the potential of quantum simulators goes\nbeyond the traditional scope of condensed-matter physics: Being based on\ndriven-dissipative quantum optical platforms, quantum simulators allow for\nprocesses that are typically not considered in condensed-matter physics. These\nprocesses can enrich in unexplored ways the phase diagram of well-established\nmodels. Taking the extended Bose-Hubbard model as the guiding example, in this\nwork we examine the impact of coherent pair injection, a process readily\navailable in, for example, superconducting circuit arrays. The interest behind\nthis process is that, in contrast to the standard injection of single\nexcitations, it can be configured to preserve the U(1) symmetry underlying the\nmodel. We prove that this process favors both superfluid and density-wave\norder, as opposed to insulation or homogeneous states, thereby providing a\nnovel route towards the access of lattice supersolidity.",
            "author": [
                "Emmanouil Grigoriou",
                "Zhiyao Ning",
                "Hang Su",
                "Benjamin L\u00f6ckler",
                "Ming Li",
                "Yoshitomo Kamiya",
                "Carlos Navarrete-Benlloch"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03624v1",
                "http://arxiv.org/pdf/2312.03624v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03620v1",
            "title": "Golden Gemini is All You Need: Finding the Sweet Spots for Speaker\n  Verification",
            "updated": "2023-12-06T17:08:49Z",
            "published": "2023-12-06T17:08:49Z",
            "summary": "Previous studies demonstrate the impressive performance of residual neural\nnetworks (ResNet) in speaker verification. The ResNet models treat the time and\nfrequency dimensions equally. They follow the default stride configuration\ndesigned for image recognition, where the horizontal and vertical axes exhibit\nsimilarities. This approach ignores the fact that time and frequency are\nasymmetric in speech representation. In this paper, we address this issue and\nlook for optimal stride configurations specifically tailored for speaker\nverification. We represent the stride space on a trellis diagram, and conduct a\nsystematic study on the impact of temporal and frequency resolutions on the\nperformance and further identify two optimal points, namely Golden Gemini,\nwhich serves as a guiding principle for designing 2D ResNet-based speaker\nverification models. By following the principle, a state-of-the-art ResNet\nbaseline model gains a significant performance improvement on VoxCeleb, SITW,\nand CNCeleb datasets with 7.70%/11.76% average EER/minDCF reductions,\nrespectively, across different network depths (ResNet18, 34, 50, and 101),\nwhile reducing the number of parameters by 16.5% and FLOPs by 4.1%. We refer to\nit as Gemini ResNet. Further investigation reveals the efficacy of the proposed\nGolden Gemini operating points across various training conditions and\narchitectures. Furthermore, we present a new benchmark, namely the Gemini\nDF-ResNet, using a cutting-edge model.",
            "author": [
                "Tianchi Liu",
                "Kong Aik Lee",
                "Qiongqiong Wang",
                "Haizhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03620v1",
                "http://arxiv.org/pdf/2312.03620v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03618v1",
            "title": "Beyond discounted returns: Robust Markov decision processes with average\n  and Blackwell optimality",
            "updated": "2023-12-06T17:04:08Z",
            "published": "2023-12-06T17:04:08Z",
            "summary": "Robust Markov Decision Processes (RMDPs) are a widely used framework for\nsequential decision-making under parameter uncertainty. RMDPs have been\nextensively studied when the objective is to maximize the discounted return,\nbut little is known for average optimality (optimizing the long-run average of\nthe rewards obtained over time) and Blackwell optimality (remaining discount\noptimal for all discount factors sufficiently close to 1). In this paper, we\nprove several foundational results for RMDPs beyond the discounted return. We\nshow that average optimal policies can be chosen stationary and deterministic\nfor sa-rectangular RMDPs but, perhaps surprisingly, that history-dependent\n(Markovian) policies strictly outperform stationary policies for average\noptimality in s-rectangular RMDPs. We also study Blackwell optimality for\nsa-rectangular RMDPs, where we show that {\\em approximate} Blackwell optimal\npolicies always exist, although Blackwell optimal policies may not exist. We\nalso provide a sufficient condition for their existence, which encompasses\nvirtually any examples from the literature. We then discuss the connection\nbetween average and Blackwell optimality, and we describe several algorithms to\ncompute the optimal average return. Interestingly, our approach leverages the\nconnections between RMDPs and stochastic games.",
            "author": [
                "Julien Grand-Clement",
                "Marek Petrik",
                "Nicolas Vieille"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03618v1",
                "http://arxiv.org/pdf/2312.03618v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03616v1",
            "title": "Post-starburst galaxies in SDSS-IV MaNGA: Two broad categories of\n  evolutionary pathways",
            "updated": "2023-12-06T17:00:00Z",
            "published": "2023-12-06T17:00:00Z",
            "summary": "We study the size-mass relation (SMR) and recent star formation history (SFH)\nof post-starburst (PSB) galaxies in the local Universe, using spatially\nresolved spectroscopy from the final data release of MaNGA. Our sample includes\n489 PSB galaxies: 94 cPSB galaxies with central PSB regions, 85 rPSB galaxies\nwith ring-like PSB regions and 310 iPSB galaxies with irregular PSB regions.\nWhen compared to control galaxies of similar SFR, redshift and mass, a similar\nSMR is found for all types of PSB samples except the cPSB galaxies which have\nsmaller sizes at intermediate masses ($9.5\\lesssim \\log_{10}(\\rm\nM_\\ast/M_\\odot)\\lesssim 10.5$). The iPSB galaxies in the star-forming sequence\n(iPSB-SF) show no/weak gradients in $\\textrm{D}_{n}(4000)$,\n$\\textrm{EW}(\\textrm{H}\\delta_{A})$ and $\\textrm{EW}(\\textrm{H}\\alpha)$,\nconsistent with the global star-forming status of this type of galaxies, while\nthe quiescent iPSB (iPSB-Q) sample shows negative gradients in\n$\\textrm{D}_{n}(4000)$ and positive gradients in\n$\\textrm{EW}(\\textrm{H}\\delta_{A})$, indicating older stellar populations in\nthe inner regions. Both cPSB and rPSB samples show positive gradients in\n$\\textrm{D}_{n}(4000)$ and negative gradients in\n$\\textrm{EW}(\\textrm{H}\\delta_{A})$, indicating younger stellar populations in\nthe inner regions. These results imply that the four types of PSB galaxies can\nbe broadly divided into two distinct categories in terms of evolutionary\npathway: (1) iPSB-SF and iPSB-Q which have SMRs and SFHs similar to control\ngalaxies, preferring an inside-out quenching process, (2) rPSB and cPSB which\nappear to be different stages of the same event, likely to follow the\noutside-in quenching process driven by disruption events such as mergers that\nresult in a more compact structure as quenching proceeds.",
            "author": [
                "Zhuo Cheng",
                "Cheng Li",
                "Niu Li",
                "Renbin Yan",
                "Houjun Mo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03616v1",
                "http://arxiv.org/pdf/2312.03616v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03607v1",
            "title": "From concrete mixture to structural design -- a holistic optimization\n  procedure in the presence of uncertainties",
            "updated": "2023-12-06T16:54:14Z",
            "published": "2023-12-06T16:54:14Z",
            "summary": "Designing civil structures such as bridges, dams or buildings is a complex\ntask requiring many synergies from several experts. Each is responsible for\ndifferent parts of the process. This is often done in a sequential manner, e.g.\nthe structural engineer makes a design under the assumption of certain material\nproperties (e.g. the strength class of the concrete), and then the material\nengineer optimizes the material with these restrictions. This paper proposes a\nholistic optimization procedure, which combines the concrete mixture design and\nstructural simulations in a joint, forward workflow that we ultimately seek to\ninvert. In this manner, new mixtures beyond standard ranges can be considered.\nAny design effort should account for the presence of uncertainties which can be\naleatoric or epistemic as when data is used to calibrate physical models or\nidentify models that fill missing links in the workflow. Inverting the causal\nrelations established poses several challenges especially when these involve\nphysics-based models which most often than not do not provide\nderivatives/sensitivities or when design constraints are present. To this end,\nwe advocate Variational Optimization, with proposed extensions and\nappropriately chosen heuristics to overcome the aforementioned challenges. The\nproposed methodology is illustrated using the design of a precast concrete beam\nwith the objective to minimize the global warming potential while satisfying a\nnumber of constraints associated with its load-bearing capacity after 28days\naccording to the Eurocode, the demoulding time as computed by a complex\nnonlinear Finite Element model, and the maximum temperature during the\nhydration.",
            "author": [
                "Atul Agrawal",
                "Erik Tamsen",
                "Phaedon-Stelios Koutsourelakis",
                "Joerg F. Unger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03607v1",
                "http://arxiv.org/pdf/2312.03607v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "physics.comp-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03606v1",
            "title": "DiffusionSat: A Generative Foundation Model for Satellite Imagery",
            "updated": "2023-12-06T16:53:17Z",
            "published": "2023-12-06T16:53:17Z",
            "summary": "Diffusion models have achieved state-of-the-art results on many modalities\nincluding images, speech, and video. However, existing models are not tailored\nto support remote sensing data, which is widely used in important applications\nincluding environmental monitoring and crop-yield prediction. Satellite images\nare significantly different from natural images -- they can be multi-spectral,\nirregularly sampled across time -- and existing diffusion models trained on\nimages from the Web do not support them. Furthermore, remote sensing data is\ninherently spatio-temporal, requiring conditional generation tasks not\nsupported by traditional methods based on captions or images. In this paper, we\npresent DiffusionSat, to date the largest generative foundation model trained\non a collection of publicly available large, high-resolution remote sensing\ndatasets. As text-based captions are sparsely available for satellite images,\nwe incorporate the associated metadata such as geolocation as conditioning\ninformation. Our method produces realistic samples and can be used to solve\nmultiple generative tasks including temporal generation, superresolution given\nmulti-spectral inputs and in-painting. Our method outperforms previous\nstate-of-the-art methods for satellite image generation and is the first\nlarge-scale $\\textit{generative}$ foundation model for satellite imagery.",
            "author": [
                "Samar Khanna",
                "Patrick Liu",
                "Linqi Zhou",
                "Chenlin Meng",
                "Robin Rombach",
                "Marshall Burke",
                "David Lobell",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03606v1",
                "http://arxiv.org/pdf/2312.03606v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03600v1",
            "title": "A Mixed Integer Quadratic Program for Valuing the Impact of Price and\n  Forecast Uncertainty for Wind Generators",
            "updated": "2023-12-06T16:42:53Z",
            "published": "2023-12-06T16:42:53Z",
            "summary": "Owners of wind power plants are exposed to financial risk in wholesale\nelectricity markets due to the uncertain nature of wind forecasts and price\nvolatility. In the event of a wind shortfall, the plant may have to repurchase\npower at a higher price in the real-time market. However, reducing the power\noffered in the day-ahead market may also be interpreted by regulators as\nphysical withholding. We formulate and solve a mixed-integer quadratic program\n(MIQP) that prices the uncertain portion of a wind generator's forecast to\nhedge against uncertainties and which addresses concerns around withholding. We\nexploit the structure of the MIQP inputs to introduce additional constraints to\nimprove computation time. Additionally, we provide a qualitative approach for\ngenerators and regulators to interpret the results of the MIQP. Finally, we\nsimulate a real-world application for a wind farm in New York using past wind\nforecasts and NYISO prices.",
            "author": [
                "Daniel Shen",
                "Marija Ilic"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03600v1",
                "http://arxiv.org/pdf/2312.03600v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03598v1",
            "title": "A Machine-Learning-Accelerated Quantum Transport Study on the Effects of\n  Superlattice Disorder and Strain in a Mid-wave Infrared Curved Sensor",
            "updated": "2023-12-06T16:42:34Z",
            "published": "2023-12-06T16:42:34Z",
            "summary": "An emerging device architecture for infrared imaging is the curved\nfocal-plane array which benefits from several optical advantages over the\ntraditional flat design. However, the curving process introduces additional\nstrain in the active region which must be taken into account. Type-II\nsuperlattices, a promising alternative to traditional bulk materials for use in\ninfrared photodetectors, is a candidate material for use in these devices, but\nthe transport properties of these highly heterogeneous materials are not\nstraightforward and can be affected by different material conditions, such as\nsuperlattice disorder and external strain. We present a comprehensive study of\nthe internal QE calculated for a curved device that incorporates finite element\nanalysis (FEA) modeling, nonequilibirium Green's functions (NEGF) calculations,\nand Gaussian Process (GP) regression. FEA is used for predicting the strain\nconfiguration throughout the active region induced by the curving procedure of\nthe device. NEGF is used to calculate the vertical hole mobility for a select\nset of strain configurations, from which the internal quantum efficiency of the\ndevice is approximated to predict performance under strained conditions. Then\nthis data set is used to train a GP model that maps the quantum efficiency QE\npredictions onto the spatial coordinates of the curved device, based on the\nstrain configuration predicted using FEA. This analysis is performed for ideal\nand disordered SLs to understand both the fundamental and practical limitations\nof the performance of these materials in curved devices.",
            "author": [
                "John Glennon",
                "Alexandros Kyrtsos",
                "Mark O'Masta",
                "Binh-Minh Nyguyen",
                "Enrico Bellotti"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03598v1",
                "http://arxiv.org/pdf/2312.03598v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03593v1",
            "title": "Streaming Algorithms for the $k$-Submodular Cover Problem",
            "updated": "2023-12-06T16:32:46Z",
            "published": "2023-12-06T16:32:46Z",
            "summary": "Given a natural number $k\\ge 2$, we consider the $k$-submodular cover problem\n($k$-SC). The objective is to find a minimum cost subset of a ground set\n$\\mathcal{X}$ subject to the value of a $k$-submodular utility function being\nat least a certain predetermined value $\\tau$. For this problem, we design a\nbicriteria algorithm with a cost at most $O(1/\\epsilon)$ times the optimal\nvalue, while the utility is at least $(1-\\epsilon)\\tau/r$, where $r$ depends on\nthe monotonicity of $g$.",
            "author": [
                "Wenqi Wang",
                "Gregory Gutin",
                "Yaping Mao",
                "Donglei Du",
                "Xiaoyan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03593v1",
                "http://arxiv.org/pdf/2312.03593v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03589v1",
            "title": "GA-NIFS: JWST discovers an offset AGN 740 million years after the Big\n  Bang",
            "updated": "2023-12-06T16:29:25Z",
            "published": "2023-12-06T16:29:25Z",
            "summary": "A surprising finding of recent studies is the large number of Active Galactic\nNuclei (AGN) associated with moderately massive black holes ($\\rm\n\\log(M_\\bullet/M_\\odot)\\sim 6-8$), in the first billion years after the Big\nBang ($z>5$). In this context, a relevant finding has been the large fraction\nof candidate dual AGN, both at large separations (several kpc) and in close\npairs (less than a kpc), likely in the process of merging. Frequent black hole\nmerging may be a route for black hole growth in the early Universe; however,\nprevious findings are still tentative and indirect. We present JWST/NIRSpec-IFU\nobservations of a galaxy at $z=7.15$ in which we find evidence for a $\\rm\n\\log(M_\\bullet/M_\\odot)\\sim7.7$ accreting black hole, as traced by a broad\ncomponent of H$\\beta$ emission, associated with the Broad Line Region (BLR)\naround the black hole. This BLR is offset by 620 pc in projection from the\ncentroid of strong rest-frame optical emission, with a velocity offset of\n$\\sim$40 km/s. The latter region is also characterized by (narrow) nebular\nemission features typical of AGN, hence also likely hosting another accreting\nblack hole, although obscured (type 2, narrow-line AGN). We exclude that the\noffset BLR is associated with Supernovae or massive stars, and we interpret\nthese results as two black holes in the process of merging. This finding may be\nrelevant for estimates of the rate and properties of gravitational wave signals\nfrom the early Universe that will be detected by future observatories like\nLISA.",
            "author": [
                "Hannah \u00dcbler",
                "Roberto Maiolino",
                "Pablo G. P\u00e9rez-Gonz\u00e1lez",
                "Francesco D'Eugenio",
                "Michele Perna",
                "Mirko Curti",
                "Santiago Arribas",
                "Andrew Bunker",
                "Stefano Carniani",
                "St\u00e9phane Charlot",
                "Bruno Rodr\u00edguez Del Pino",
                "William Baker",
                "Torsten B\u00f6ker",
                "Giovanni Cresci",
                "James Dunlop",
                "Norman A. Grogin",
                "Gareth C. Jones",
                "Nimisha Kumari",
                "Isabella Lamperti",
                "Nicolas Laporte",
                "Madeline A. Marshall",
                "Giovanni Mazzolari",
                "Eleonora Parlanti",
                "Tim Rawle",
                "Jan Scholtz",
                "Giacomo Venturi",
                "Joris Witstok"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03589v1",
                "http://arxiv.org/pdf/2312.03589v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03587v1",
            "title": "Language-Informed Visual Concept Learning",
            "updated": "2023-12-06T16:24:47Z",
            "published": "2023-12-06T16:24:47Z",
            "summary": "Our understanding of the visual world is centered around various concept\naxes, characterizing different aspects of visual entities. While different\nconcept axes can be easily specified by language, e.g. color, the exact visual\nnuances along each axis often exceed the limitations of linguistic\narticulations, e.g. a particular style of painting. In this work, our goal is\nto learn a language-informed visual concept representation, by simply\ndistilling large pre-trained vision-language models. Specifically, we train a\nset of concept encoders to encode the information pertinent to a set of\nlanguage-informed concept axes, with an objective of reproducing the input\nimage through a pre-trained Text-to-Image (T2I) model. To encourage better\ndisentanglement of different concept encoders, we anchor the concept embeddings\nto a set of text embeddings obtained from a pre-trained Visual Question\nAnswering (VQA) model. At inference time, the model extracts concept embeddings\nalong various axes from new test images, which can be remixed to generate\nimages with novel compositions of visual concepts. With a lightweight test-time\nfinetuning procedure, it can also generalize to novel concepts unseen at\ntraining.",
            "author": [
                "Sharon Lee",
                "Yunzhi Zhang",
                "Shangzhe Wu",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03587v1",
                "http://arxiv.org/pdf/2312.03587v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03585v1",
            "title": "Foundation Model Assisted Weakly Supervised Semantic Segmentation",
            "updated": "2023-12-06T16:21:06Z",
            "published": "2023-12-06T16:21:06Z",
            "summary": "This work aims to leverage pre-trained foundation models, such as contrastive\nlanguage-image pre-training (CLIP) and segment anything model (SAM), to address\nweakly supervised semantic segmentation (WSSS) using image-level labels. To\nthis end, we propose a coarse-to-fine framework based on CLIP and SAM for\ngenerating high-quality segmentation seeds. Specifically, we construct an image\nclassification task and a seed segmentation task, which are jointly performed\nby CLIP with frozen weights and two sets of learnable task-specific prompts. A\nSAM-based seeding (SAMS) module is designed and applied to each task to produce\neither coarse or fine seed maps. Moreover, we design a multi-label contrastive\nloss supervised by image-level labels and a CAM activation loss supervised by\nthe generated coarse seed map. These losses are used to learn the prompts,\nwhich are the only parts need to be learned in our framework. Once the prompts\nare learned, we input each image along with the learned segmentation-specific\nprompts into CLIP and the SAMS module to produce high-quality segmentation\nseeds. These seeds serve as pseudo labels to train an off-the-shelf\nsegmentation network like other two-stage WSSS methods. Experiments show that\nour method achieves the state-of-the-art performance on PASCAL VOC 2012 and\ncompetitive results on MS COCO 2014.",
            "author": [
                "Xiaobo Yang",
                "Xiaojin Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03585v1",
                "http://arxiv.org/pdf/2312.03585v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03583v1",
            "title": "Strong Convexity of Sets in Riemannian Manifolds",
            "updated": "2023-12-06T16:19:27Z",
            "published": "2023-12-06T16:19:27Z",
            "summary": "Convex curvature properties are important in designing and analyzing convex\noptimization algorithms in the Hilbertian or Riemannian settings. In the case\nof the Hilbertian setting, strongly convex sets are well studied. Herein, we\npropose various definitions of strong convexity for uniquely geodesic sets in a\nRiemannian manifold. We study their relationship, propose tools to determine\nthe geodesic strongly convex nature of sets, and analyze the convergence of\noptimization algorithms over those sets. In particular, we demonstrate that,\nwhen the Riemannian scaling inequalities hold, the Riemannian Frank-Wolfe\nalgorithm enjoys a global linear convergence rate.",
            "author": [
                "Damien Scieur",
                "Thomas Kerdreux",
                "Mart\u00ednez-Rubio",
                "Alexandre d'Aspremont",
                "Sebastian Pokutta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03583v1",
                "http://arxiv.org/pdf/2312.03583v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03577v1",
            "title": "Improving Bias Mitigation through Bias Experts in Natural Language\n  Understanding",
            "updated": "2023-12-06T16:15:00Z",
            "published": "2023-12-06T16:15:00Z",
            "summary": "Biases in the dataset often enable the model to achieve high performance on\nin-distribution data, while poorly performing on out-of-distribution data. To\nmitigate the detrimental effect of the bias on the networks, previous works\nhave proposed debiasing methods that down-weight the biased examples identified\nby an auxiliary model, which is trained with explicit bias labels. However,\nfinding a type of bias in datasets is a costly process. Therefore, recent\nstudies have attempted to make the auxiliary model biased without the guidance\n(or annotation) of bias labels, by constraining the model's training\nenvironment or the capability of the model itself. Despite the promising\ndebiasing results of recent works, the multi-class learning objective, which\nhas been naively used to train the auxiliary model, may harm the bias\nmitigation effect due to its regularization effect and competitive nature\nacross classes. As an alternative, we propose a new debiasing framework that\nintroduces binary classifiers between the auxiliary model and the main model,\ncoined bias experts. Specifically, each bias expert is trained on a binary\nclassification task derived from the multi-class classification task via the\nOne-vs-Rest approach. Experimental results demonstrate that our proposed\nstrategy improves the bias identification ability of the auxiliary model.\nConsequently, our debiased model consistently outperforms the state-of-the-art\non various challenge datasets.",
            "author": [
                "Eojin Jeon",
                "Mingyu Lee",
                "Juhyeong Park",
                "Yeachan Kim",
                "Wing-Lam Mok",
                "SangKeun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03577v1",
                "http://arxiv.org/pdf/2312.03577v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03575v1",
            "title": "Fluorescence Lifetime Hong-Ou-Mandel Sensing",
            "updated": "2023-12-06T16:13:52Z",
            "published": "2023-12-06T16:13:52Z",
            "summary": "Fluorescence Lifetime Imaging Microscopy in the time domain is typically\nperformed by recording the arrival time of photons either by using electronic\ntime tagging or a gated detector. As such the temporal resolution is limited by\nthe performance of the electronics to 100's of picoseconds. Here, we\ndemonstrate a fluorescence lifetime measurement technique based on\nphoton-bunching statistics with a resolution that is only dependent on the\nduration of the reference photon or laser pulse, which can readily reach the\n1-0.1 picosecond timescale. A range of fluorescent dyes having lifetimes\nspanning from 1.6 to 7 picoseconds have been here measured with only ~1 second\nmeasurement duration. We corroborate the effectiveness of the technique by\nmeasuring the Newtonian viscosity of glycerol/water mixtures by means of a\nmolecular rotor having over an order of magnitude variability in lifetime, thus\nintroducing a new method for contact-free nanorheology. Accessing fluorescence\nlifetime information at such high temporal resolution opens a doorway for a\nwide range of fluorescent markers to be adopted for studying yet unexplored\nfast biological processes, as well as fundamental interactions such as lifetime\nshortening in resonant plasmonic devices.",
            "author": [
                "Ashley Lyons",
                "Vytautas Zickus",
                "Ra\u00fal \u00c1lvarez-Mendoza",
                "Danilo Triggiani",
                "Vincenzo Tamma",
                "Niclas Westerberg",
                "Manlio Tassieri",
                "Daniele Faccio"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41467-023-43868-x",
                "http://arxiv.org/abs/2312.03575v1",
                "http://arxiv.org/pdf/2312.03575v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03570v1",
            "title": "Theta-Induced Diffusion on Tate Elliptic Curves over Non-Archimedean\n  Local Fields",
            "updated": "2023-12-06T16:02:31Z",
            "published": "2023-12-06T16:02:31Z",
            "summary": "A diffusion operator on the $K$-rational points of a Tate elliptic curve\n$E_q$ is constructed, where $K$ is a non-archimedean local field, as well as an\noperator on the Berkovich-analytification $E_q^{an}$ of $E_q$. These are\nintegral operators for measures coming from a regular $1$-form, and kernel\nfunctions constructed via theta functions. The second operator can be described\nvia certain non-archimedan curvature forms on $E_q^{an}$. The spectra of these\nself-adjoint bounded operators on the Hilbert spaces of $L^2$-functions are\nidentical and found to consist of finitely many eigenvalues. A study of the\ncorresponding heat equations yields a positive answer to the Cauchy problem,\nand induced Markov processes on the curve. Finally, some geometric information\nabout the $K$-rational points of $E_q$ is retrieved from the spectrum.",
            "author": [
                "Patrick Erik Bradley"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03570v1",
                "http://arxiv.org/pdf/2312.03570v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.AG",
                "14H52 (Primary), 58J35 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03567v1",
            "title": "XAIQA: Explainer-Based Data Augmentation for Extractive Question\n  Answering",
            "updated": "2023-12-06T15:59:06Z",
            "published": "2023-12-06T15:59:06Z",
            "summary": "Extractive question answering (QA) systems can enable physicians and\nresearchers to query medical records, a foundational capability for designing\nclinical studies and understanding patient medical history. However, building\nthese systems typically requires expert-annotated QA pairs. Large language\nmodels (LLMs), which can perform extractive QA, depend on high quality data in\ntheir prompts, specialized for the application domain. We introduce a novel\napproach, XAIQA, for generating synthetic QA pairs at scale from data naturally\navailable in electronic health records. Our method uses the idea of a\nclassification model explainer to generate questions and answers about medical\nconcepts corresponding to medical codes. In an expert evaluation with two\nphysicians, our method identifies $2.2\\times$ more semantic matches and\n$3.8\\times$ more clinical abbreviations than two popular approaches that use\nsentence transformers to create QA pairs. In an ML evaluation, adding our QA\npairs improves performance of GPT-4 as an extractive QA model, including on\ndifficult questions. In both the expert and ML evaluations, we examine\ntrade-offs between our method and sentence transformers for QA pair generation\ndepending on question difficulty.",
            "author": [
                "Joel Stremmel",
                "Ardavan Saeedi",
                "Hamid Hassanzadeh",
                "Sanjit Batra",
                "Jeffrey Hertzberg",
                "Jaime Murillo",
                "Eran Halperin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03567v1",
                "http://arxiv.org/pdf/2312.03567v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03564v1",
            "title": "Totally symmetric self-complementary plane partition matrices and\n  related polytopes",
            "updated": "2023-12-06T15:56:46Z",
            "published": "2023-12-06T15:56:46Z",
            "summary": "Plane partitions in the totally symmetric self-complementary symmetry class\n(TSSCPP) are known to be equinumerous with n x n alternating sign matrices, but\nno explicit bijection is known. In this paper, we give a bijection from these\nplane partitions to {0,1,-1}-matrices we call magog matrices, some of which are\nalternating sign matrices. We explore enumerative properties of these matrices\nrelated to natural statistics such as inversion number and number of negative\nones. We then investigate the polytope defined as their convex hull. We show\nthat all the magog matrices are extreme and give a partial inequality\ndescription. Finally, we define another TSSCPP polytope as the convex hull of\nTSSCPP boolean triangles and determine its dimension, inequalities, vertices,\nand facets.",
            "author": [
                "Vincent Holmlund",
                "Jessica Striker"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03564v1",
                "http://arxiv.org/pdf/2312.03564v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05A05, 52B05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03805v1",
            "title": "SYNC-CLIP: Synthetic Data Make CLIP Generalize Better in Data-Limited\n  Scenarios",
            "updated": "2023-12-06T15:54:05Z",
            "published": "2023-12-06T15:54:05Z",
            "summary": "Prompt learning is a powerful technique for transferring Vision-Language\nModels (VLMs) such as CLIP to downstream tasks. However, the prompt-based\nmethods that are fine-tuned solely with base classes may struggle to generalize\nto novel classes in open-vocabulary scenarios, especially when data are\nlimited. To address this issue, we propose an innovative approach called\nSYNC-CLIP that leverages SYNthetiC data for enhancing the generalization\ncapability of CLIP. Based on the observation of the distribution shift between\nthe real and synthetic samples, we treat real and synthetic samples as distinct\ndomains and propose to optimize separate domain prompts to capture\ndomain-specific information, along with the shared visual prompts to preserve\nthe semantic consistency between two domains. By aligning the cross-domain\nfeatures, the synthetic data from novel classes can provide implicit guidance\nto rebalance the decision boundaries. Experimental results on three model\ngeneralization tasks demonstrate that our method performs very competitively\nacross various benchmarks. Notably, SYNC-CLIP outperforms the state-of-the-art\ncompetitor PromptSRC by an average improvement of 3.0% on novel classes across\n11 datasets in open-vocabulary scenarios.",
            "author": [
                "Mushui Liu",
                "Weijie He",
                "Ziqian Lu",
                "Yunlong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03805v1",
                "http://arxiv.org/pdf/2312.03805v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03561v1",
            "title": "Blueprinting the Future: Automatic Item Categorization using\n  Hierarchical Zero-Shot and Few-Shot Classifiers",
            "updated": "2023-12-06T15:51:49Z",
            "published": "2023-12-06T15:51:49Z",
            "summary": "In testing industry, precise item categorization is pivotal to align exam\nquestions with the designated content domains outlined in the assessment\nblueprint. Traditional methods either entail manual classification, which is\nlaborious and error-prone, or utilize machine learning requiring extensive\ntraining data, often leading to model underfit or overfit issues. This study\nunveils a novel approach employing the zero-shot and few-shot Generative\nPretrained Transformer (GPT) classifier for hierarchical item categorization,\nminimizing the necessity for training data, and instead, leveraging human-like\nlanguage descriptions to define categories. Through a structured python\ndictionary, the hierarchical nature of examination blueprints is navigated\nseamlessly, allowing for a tiered classification of items across multiple\nlevels. An initial simulation with artificial data demonstrates the efficacy of\nthis method, achieving an average accuracy of 92.91% measured by the F1 score.\nThis method was further applied to real exam items from the 2022 In-Training\nExamination (ITE) conducted by the American Board of Family Medicine (ABFM),\nreclassifying 200 items according to a newly formulated blueprint swiftly in 15\nminutes, a task that traditionally could span several days among editors and\nphysicians. This innovative approach not only drastically cuts down\nclassification time but also ensures a consistent, principle-driven\ncategorization, minimizing human biases and discrepancies. The ability to\nrefine classifications by adjusting definitions adds to its robustness and\nsustainability.",
            "author": [
                "Ting Wang",
                "Keith Stelter",
                "Jenn Floyd",
                "Thomas O'Neill",
                "Nathaniel Hendrix",
                "Andrew Bazemore",
                "Kevin Rode",
                "Warren Newton"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03561v1",
                "http://arxiv.org/pdf/2312.03561v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03558v1",
            "title": "When an Image is Worth 1,024 x 1,024 Words: A Case Study in\n  Computational Pathology",
            "updated": "2023-12-06T15:40:28Z",
            "published": "2023-12-06T15:40:28Z",
            "summary": "This technical report presents LongViT, a vision Transformer that can process\ngigapixel images in an end-to-end manner. Specifically, we split the gigapixel\nimage into a sequence of millions of patches and project them linearly into\nembeddings. LongNet is then employed to model the extremely long sequence,\ngenerating representations that capture both short-range and long-range\ndependencies. The linear computation complexity of LongNet, along with its\ndistributed algorithm, enables us to overcome the constraints of both\ncomputation and memory. We apply LongViT in the field of computational\npathology, aiming for cancer diagnosis and prognosis within gigapixel\nwhole-slide images. Experimental results demonstrate that LongViT effectively\nencodes gigapixel images and outperforms previous state-of-the-art methods on\ncancer subtyping and survival prediction. Code and models will be available at\nhttps://aka.ms/LongViT.",
            "author": [
                "Wenhui Wang",
                "Shuming Ma",
                "Hanwen Xu",
                "Naoto Usuyama",
                "Jiayu Ding",
                "Hoifung Poon",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03558v1",
                "http://arxiv.org/pdf/2312.03558v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03556v1",
            "title": "Personalized Face Inpainting with Diffusion Models by Parallel Visual\n  Attention",
            "updated": "2023-12-06T15:39:03Z",
            "published": "2023-12-06T15:39:03Z",
            "summary": "Face inpainting is important in various applications, such as photo\nrestoration, image editing, and virtual reality. Despite the significant\nadvances in face generative models, ensuring that a person's unique facial\nidentity is maintained during the inpainting process is still an elusive goal.\nCurrent state-of-the-art techniques, exemplified by MyStyle, necessitate\nresource-intensive fine-tuning and a substantial number of images for each new\nidentity. Furthermore, existing methods often fall short in accommodating\nuser-specified semantic attributes, such as beard or expression. To improve\ninpainting results, and reduce the computational complexity during inference,\nthis paper proposes the use of Parallel Visual Attention (PVA) in conjunction\nwith diffusion models. Specifically, we insert parallel attention matrices to\neach cross-attention module in the denoising network, which attends to features\nextracted from reference images by an identity encoder. We train the added\nattention modules and identity encoder on CelebAHQ-IDI, a dataset proposed for\nidentity-preserving face inpainting. Experiments demonstrate that PVA attains\nunparalleled identity resemblance in both face inpainting and face inpainting\nwith language guidance tasks, in comparison to various benchmarks, including\nMyStyle, Paint by Example, and Custom Diffusion. Our findings reveal that PVA\nensures good identity preservation while offering effective\nlanguage-controllability. Additionally, in contrast to Custom Diffusion, PVA\nrequires just 40 fine-tuning steps for each new identity, which translates to a\nsignificant speed increase of over 20 times.",
            "author": [
                "Jianjin Xu",
                "Saman Motamed",
                "Praneetha Vaddamanu",
                "Chen Henry Wu",
                "Christian Haene",
                "Jean-Charles Bazin",
                "Fernando de la Torre"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03556v1",
                "http://arxiv.org/pdf/2312.03556v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03555v1",
            "title": "Enabling Edge Artificial Intelligence via Goal-oriented Deep Neural\n  Network Splitting",
            "updated": "2023-12-06T15:38:53Z",
            "published": "2023-12-06T15:38:53Z",
            "summary": "Deep Neural Network (DNN) splitting is one of the key enablers of edge\nArtificial Intelligence (AI), as it allows end users to pre-process data and\noffload part of the computational burden to nearby Edge Cloud Servers (ECSs).\nThis opens new opportunities and degrees of freedom in balancing energy\nconsumption, delay, accuracy, privacy, and other trustworthiness metrics. In\nthis work, we explore the opportunity of DNN splitting at the edge of 6G\nwireless networks to enable low energy cooperative inference with target delay\nand accuracy with a goal-oriented perspective. Going beyond the current\nliterature, we explore new trade-offs that take into account the accuracy\ndegradation as a function of the Splitting Point (SP) selection and wireless\nchannel conditions. Then, we propose an algorithm that dynamically controls SP\nselection, local computing resources, uplink transmit power and bandwidth\nallocation, in a goal-oriented fashion, to meet a target goal-effectiveness. To\nthe best of our knowledge, this is the first work proposing adaptive SP\nselection on the basis of all learning performance (i.e., energy, delay,\naccuracy), with the aim of guaranteeing the accomplishment of a goal (e.g.,\nminimize the energy consumption under latency and accuracy constraints).\nNumerical results show the advantages of the proposed SP selection and resource\nallocation, to enable energy frugal and effective edge AI.",
            "author": [
                "Francesco Binucci",
                "Mattia Merluzzi",
                "Paolo Banelli",
                "Emilio Calvanese Strinati",
                "Paolo Di Lorenzo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03555v1",
                "http://arxiv.org/pdf/2312.03555v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03549v2",
            "title": "Holmes: Towards Distributed Training Across Clusters with Heterogeneous\n  NIC Environment",
            "updated": "2023-12-07T09:26:07Z",
            "published": "2023-12-06T15:27:26Z",
            "summary": "Large language models (LLMs) such as GPT-3, OPT, and LLaMA have demonstrated\nremarkable accuracy in a wide range of tasks. However, training these models\ncan incur significant expenses, often requiring tens of thousands of GPUs for\nmonths of continuous operation. Typically, this training is carried out in\nspecialized GPU clusters equipped with homogeneous high-speed Remote Direct\nMemory Access (RDMA) network interface cards (NICs). The acquisition and\nmaintenance of such dedicated clusters is challenging. Current LLM training\nframeworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on\noptimizing training within homogeneous cluster settings. In this paper, we\nintroduce Holmes, a training framework for LLMs that employs thoughtfully\ncrafted data and model parallelism strategies over the heterogeneous NIC\nenvironment. Our primary technical contribution lies in a novel scheduling\nmethod that intelligently allocates distinct computational tasklets in LLM\ntraining to specific groups of GPU devices based on the characteristics of\ntheir connected NICs. Furthermore, our proposed framework, utilizing pipeline\nparallel techniques, demonstrates scalability to multiple GPU clusters, even in\nscenarios without high-speed interconnects between nodes in distinct clusters.\nWe conducted comprehensive experiments that involved various scenarios in the\nheterogeneous NIC environment. In most cases, our framework achieves\nperformance levels close to those achievable with homogeneous RDMA-capable\nnetworks (InfiniBand or RoCE), significantly exceeding training efficiency\nwithin the pure Ethernet environment. Additionally, we verified that our\nframework outperforms other mainstream LLM frameworks under heterogeneous NIC\nenvironment in terms of training efficiency and can be seamlessly integrated\nwith them.",
            "author": [
                "Fei Yang",
                "Shuang Peng",
                "Ning Sun",
                "Fangyu Wang",
                "Ke Tan",
                "Fu Wu",
                "Jiezhong Qiu",
                "Aimin Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03549v2",
                "http://arxiv.org/pdf/2312.03549v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03802v1",
            "title": "Emergent self-adaptation in an integrated photonic neural network for\n  backpropagation-free learning",
            "updated": "2023-12-06T15:25:18Z",
            "published": "2023-12-06T15:25:18Z",
            "summary": "Plastic self-adaptation, nonlinear recurrent dynamics and multi-scale memory\nare desired features in hardware implementations of neural networks, because\nthey enable them to learn, adapt and process information similarly to the way\nbiological brains do. In this work, we experimentally demonstrate these\nproperties occurring in arrays of photonic neurons. Importantly, this is\nrealised autonomously in an emergent fashion, without the need for an external\ncontroller setting weights and without explicit feedback of a global reward\nsignal. Using a hierarchy of such arrays coupled to a backpropagation-free\ntraining algorithm based on simple logistic regression, we are able to achieve\na performance of 98.2% on the MNIST task, a popular benchmark task looking at\nclassification of written digits. The plastic nodes consist of silicon\nphotonics microring resonators covered by a patch of phase-change material that\nimplements nonvolatile memory. The system is compact, robust, and\nstraightforward to scale up through the use of multiple wavelengths. Moreover,\nit constitutes a unique platform to test and efficiently implement biologically\nplausible learning schemes at a high processing speed.",
            "author": [
                "Alessio Lugnan",
                "Samarth Aggarwal",
                "Frank Br\u00fcckerhoff-Pl\u00fcckelmann",
                "C. David Wright",
                "Wolfram H. P. Pernice",
                "Harish Bhaskaran",
                "Peter Bienstman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03802v1",
                "http://arxiv.org/pdf/2312.03802v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03801v1",
            "title": "Generalization to New Sequential Decision Making Tasks with In-Context\n  Learning",
            "updated": "2023-12-06T15:19:28Z",
            "published": "2023-12-06T15:19:28Z",
            "summary": "Training autonomous agents that can learn new tasks from only a handful of\ndemonstrations is a long-standing problem in machine learning. Recently,\ntransformers have been shown to learn new language or vision tasks without any\nweight updates from only a few examples, also referred to as in-context\nlearning. However, the sequential decision making setting poses additional\nchallenges having a lower tolerance for errors since the environment's\nstochasticity or the agent's actions can lead to unseen, and sometimes\nunrecoverable, states. In this paper, we use an illustrative example to show\nthat naively applying transformers to sequential decision making problems does\nnot enable in-context learning of new tasks. We then demonstrate how training\non sequences of trajectories with certain distributional properties leads to\nin-context learning of new sequential decision making tasks. We investigate\ndifferent design choices and find that larger model and dataset sizes, as well\nas more task diversity, environment stochasticity, and trajectory burstiness,\nall result in better in-context learning of new out-of-distribution tasks. By\ntraining on large diverse offline datasets, our model is able to learn new\nMiniHack and Procgen tasks without any weight updates from just a handful of\ndemonstrations.",
            "author": [
                "Sharath Chandra Raparthy",
                "Eric Hambro",
                "Robert Kirk",
                "Mikael Henaff",
                "Roberta Raileanu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03801v1",
                "http://arxiv.org/pdf/2312.03801v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03543v1",
            "title": "GPT-4 Enhanced Multimodal Grounding for Autonomous Driving: Leveraging\n  Cross-Modal Attention with Large Language Models",
            "updated": "2023-12-06T15:14:30Z",
            "published": "2023-12-06T15:14:30Z",
            "summary": "In the field of autonomous vehicles (AVs), accurately discerning commander\nintent and executing linguistic commands within a visual context presents a\nsignificant challenge. This paper introduces a sophisticated encoder-decoder\nframework, developed to address visual grounding in AVs.Our Context-Aware\nVisual Grounding (CAVG) model is an advanced system that integrates five core\nencoders-Text, Image, Context, and Cross-Modal-with a Multimodal decoder. This\nintegration enables the CAVG model to adeptly capture contextual semantics and\nto learn human emotional features, augmented by state-of-the-art Large Language\nModels (LLMs) including GPT-4. The architecture of CAVG is reinforced by the\nimplementation of multi-head cross-modal attention mechanisms and a\nRegion-Specific Dynamic (RSD) layer for attention modulation. This\narchitectural design enables the model to efficiently process and interpret a\nrange of cross-modal inputs, yielding a comprehensive understanding of the\ncorrelation between verbal commands and corresponding visual scenes. Empirical\nevaluations on the Talk2Car dataset, a real-world benchmark, demonstrate that\nCAVG establishes new standards in prediction accuracy and operational\nefficiency. Notably, the model exhibits exceptional performance even with\nlimited training data, ranging from 50% to 75% of the full dataset. This\nfeature highlights its effectiveness and potential for deployment in practical\nAV applications. Moreover, CAVG has shown remarkable robustness and\nadaptability in challenging scenarios, including long-text command\ninterpretation, low-light conditions, ambiguous command contexts, inclement\nweather conditions, and densely populated urban environments. The code for the\nproposed model is available at our Github.",
            "author": [
                "Haicheng Liao",
                "Huanming Shen",
                "Zhenning Li",
                "Chengyue Wang",
                "Guofa Li",
                "Yiming Bie",
                "Chengzhong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03543v1",
                "http://arxiv.org/pdf/2312.03543v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03541v1",
            "title": "Path integral derivation of the thermofield double state in causal\n  diamonds",
            "updated": "2023-12-06T15:10:25Z",
            "published": "2023-12-06T15:10:25Z",
            "summary": "In this article, we follow the framework given in the article Physica A, 158,\npg 58-63 (1989) by R. Laflamme to derive the thermofield double state for a\ncausal diamond using the Euclidean path integral formalism, and subsequently\nderive the causal diamond temperature. The interpretation of the physical and\nfictitious system in the thermofield double state arises naturally from the\nboundary conditions of the fields defined on the Euclidean sections of the\ncylindrical background geometry $S^{1}_{\\beta}\\times \\mathbb{R}$, where $\\beta$\ndefines the periodicity of the Euclidean time coordinate and $S^{1}_{\\beta}$ is\nthe one-dimensional sphere (circle). The temperature detected by a static\ndiamond observer at $x=0$ matches with the thermofield double temperature\nderived via this path integral procedure.",
            "author": [
                "Abhijit Chakraborty",
                "Carlos R. Ord\u00f3\u00f1ez",
                "Gustavo Valdivia-Mera"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03541v1",
                "http://arxiv.org/pdf/2312.03541v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "math-ph",
                "math.MP",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03799v1",
            "title": "Low-power, Continuous Remote Behavioral Localization with Event Cameras",
            "updated": "2023-12-06T14:58:03Z",
            "published": "2023-12-06T14:58:03Z",
            "summary": "Researchers in natural science need reliable methods for quantifying animal\nbehavior. Recently, numerous computer vision methods emerged to automate the\nprocess. However, observing wild species at remote locations remains a\nchallenging task due to difficult lighting conditions and constraints on power\nsupply and data storage. Event cameras offer unique advantages for\nbattery-dependent remote monitoring due to their low power consumption and high\ndynamic range capabilities. We use this novel sensor to quantify a behavior in\nChinstrap penguins called ecstatic display. We formulate the problem as a\ntemporal action detection task, determining the start and end times of the\nbehavior. For this purpose, we recorded a colony of breeding penguins in\nAntarctica during several weeks and labeled event data on 16 nests. The\ndeveloped method consists of a generator of candidate time intervals\n(proposals) and a classifier of the actions within them. The experiments show\nthat the event cameras' natural response to motion is effective for continuous\nbehavior monitoring and detection, reaching a mean average precision (mAP) of\n58% (which increases to 63% in good weather conditions). The results also\ndemonstrate the robustness against various lighting conditions contained in the\nchallenging dataset. The low-power capabilities of the event camera allows to\nrecord three times longer than with a conventional camera. This work pioneers\nthe use of event cameras for remote wildlife observation, opening new\ninterdisciplinary opportunities. https://tub-rip.github.io/eventpenguins/",
            "author": [
                "Friedhelm Hamann",
                "Suman Ghosh",
                "Ignacio Juarez Martinez",
                "Tom Hart",
                "Alex Kacelnik",
                "Guillermo Gallego"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03799v1",
                "http://arxiv.org/pdf/2312.03799v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03523v1",
            "title": "Sig-Networks Toolkit: Signature Networks for Longitudinal Language\n  Modelling",
            "updated": "2023-12-06T14:34:30Z",
            "published": "2023-12-06T14:34:30Z",
            "summary": "We present an open-source, pip installable toolkit, Sig-Networks, the first\nof its kind for longitudinal language modelling. A central focus is the\nincorporation of Signature-based Neural Network models, which have recently\nshown success in temporal tasks. We apply and extend published research\nproviding a full suite of signature-based models. Their components can be used\nas PyTorch building blocks in future architectures. Sig-Networks enables\ntask-agnostic dataset plug-in, seamless pre-processing for sequential data,\nparameter flexibility, automated tuning across a range of models. We examine\nsignature networks under three different NLP tasks of varying temporal\ngranularity: counselling conversations, rumour stance switch and mood changes\nin social media threads, showing SOTA performance in all three, and provide\nguidance for future tasks. We release the Toolkit as a PyTorch package with an\nintroductory video, Git repositories for preprocessing and modelling including\nsample notebooks on the modeled NLP tasks.",
            "author": [
                "Talia Tseriotou",
                "Ryan Sze-Yin Chan",
                "Adam Tsakalidis",
                "Iman Munire Bilal",
                "Elena Kochkina",
                "Terry Lyons",
                "Maria Liakata"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03523v1",
                "http://arxiv.org/pdf/2312.03523v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03522v1",
            "title": "Interior H\u00f6lder and Calder\u00f3n-Zygmund estimates for fully nonlinear\n  equations with natural gradient growth",
            "updated": "2023-12-06T14:30:57Z",
            "published": "2023-12-06T14:30:57Z",
            "summary": "We establish local H\\\"older estimates for viscosity solutions of fully\nnonlinear second order equations with quadratic growth in the gradient and\nunbounded right-hand side in $L^q$ spaces, for an integrability threshold $q$\nguaranteeing the validity of the maximum principle. This is done through a\nnonlinear Harnack inequality for nonhomogeneous equations driven by a uniformly\nelliptic Isaacs operator and perturbed by a Hamiltonian term with natural\ngrowth in the gradient. As a byproduct, we derive a new Liouville property for\nentire $L^p$ viscosity solutions of fully nonlinear equations as well as a\nnonlinear Calder\\'on-Zygmund estimate for strong solutions of such equations.",
            "author": [
                "Alessandro Goffi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03522v1",
                "http://arxiv.org/pdf/2312.03522v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03518v1",
            "title": "On the exact spectral factorization of rational matrix functions with\n  applications to paraunitary filter banks",
            "updated": "2023-12-06T14:25:40Z",
            "published": "2023-12-06T14:25:40Z",
            "summary": "In this paper, we enhance a recent algorithm for approximate spectral\nfactorization of matrix functions, extending its capabilities to precisely\nfactorize rational matrices when an exact lower-upper triangular factorization\nis available. This novel approach leverages a fundamental component of the\nimproved algorithm for the precise design of rational paraunitary filter banks,\nallowing for the predetermined placement of zeros and poles. The introduced\nalgorithm not only advances the state-of-the-art in spectral factorization but\nalso opens new avenues for the tailored design of paraunitary filters with\nspecific spectral properties, offering significant potential for applications\nin signal processing and beyond.",
            "author": [
                "Lasha Ephremidze",
                "Gennady Mishuris",
                "Ilya Spitkovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03518v1",
                "http://arxiv.org/pdf/2312.03518v1"
            ],
            "primary_category": "math.CV",
            "category": [
                "math.CV",
                "47A68, 65T60, 15A83"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03513v1",
            "title": "Higgs self-coupling measurements at the FCC-hh",
            "updated": "2023-12-06T14:15:01Z",
            "published": "2023-12-06T14:15:01Z",
            "summary": "The hadron collider phase of the Future Circular Collider (FCC-hh) is a\nproton-proton collider operating at a center-of-mass energy of 100 TeV. It is\none of the most ambitious projects planned for the rest of this century and\noffers ample opportunities in the hunt for new physics, both through its direct\ndetection reach as well as through indirect evidence from precision\nmeasurements. Extracting a precision measurement of the Higgs self-coupling\nfrom the Higgs pair production cross-section will play a key role in our\nunderstanding of electroweak symmetry breaking, as the self-coupling gives\ninsight into the nature of the Higgs potential. With the large data set of in\ntotal 30 $\\text{ab}^{-1}$ which is envisioned to be collected during the FCC-hh\nruntime the Higgs self-coupling will be determined down to the percent level.\nThis paper presents prospect studies for Higgs self-coupling measurements in\nthe $b\\bar{b}\\gamma\\gamma$ and $b\\bar{b}\\ell\\ell + E_{\\text{T}}^{\\text{miss}}$\nfinal states, with the combined, expected precision on the Higgs self-coupling\nmodifier $\\kappa_{\\lambda}$ reaching 3.2-5.7% at 68% confidence level, assuming\nall other Higgs couplings follow their Standard Model expectations and\ndepending on the systematic uncertainties assumed. This high precision is\nmostly driven by the $b\\bar{b}\\gamma\\gamma$ final state analysis, while the\n$b\\bar{b}\\ell\\ell + E_{\\text{T}}^{\\text{miss}}$ final state - newly studied for\nits FCC-hh prospects in this document - on its own reaches a maximum precision\nof roughly 20% on $\\kappa_{\\lambda}$.",
            "author": [
                "Birgit Stapf",
                "Angela Taliercio",
                "Elisabetta Gallo",
                "Kerstin Tackmann",
                "Paola Mastrapasqua"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03513v1",
                "http://arxiv.org/pdf/2312.03513v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03795v1",
            "title": "AnimatableDreamer: Text-Guided Non-rigid 3D Model Generation and\n  Reconstruction with Canonical Score Distillation",
            "updated": "2023-12-06T14:13:54Z",
            "published": "2023-12-06T14:13:54Z",
            "summary": "Text-to-3D model adaptations have advanced static 3D model quality, but\nsequential 3D model generation, particularly for animatable objects with large\nmotions, is still scarce. Our work proposes AnimatableDreamer, a text-to-4D\ngeneration framework capable of generating diverse categories of non-rigid\nobjects while adhering to the object motions extracted from a monocular video.\nAt its core, AnimatableDreamer is equipped with our novel optimization design\ndubbed Canonical Score Distillation (CSD), which simplifies the generation\ndimension from 4D to 3D by denoising over different frames in the time-varying\ncamera spaces while conducting the distillation process in a unique canonical\nspace shared per video. Concretely, CSD ensures that score gradients\nback-propagate to the canonical space through differentiable warping, hence\nguaranteeing the time-consistent generation and maintaining morphological\nplausibility across different poses. By lifting the 3D generator to 4D with\nwarping functions, AnimatableDreamer offers a novel perspective on non-rigid 3D\nmodel generation and reconstruction. Besides, with inductive knowledge from a\nmulti-view consistent diffusion model, CSD regularizes reconstruction from\nnovel views, thus cyclically enhancing the generation process. Extensive\nexperiments demonstrate the capability of our method in generating\nhigh-flexibility text-guided 3D models from the monocular video, while also\nshowing improved reconstruction performance over typical non-rigid\nreconstruction methods. Project page https://AnimatableDreamer.github.io.",
            "author": [
                "Xinzhou Wang",
                "Yikai Wang",
                "Junliang Ye",
                "Zhengyi Wang",
                "Fuchun Sun",
                "Pengkun Liu",
                "Ling Wang",
                "Kai Sun",
                "Xintong Wang",
                "Bin He"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03795v1",
                "http://arxiv.org/pdf/2312.03795v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03510v2",
            "title": "Towards Sobolev Pruning",
            "updated": "2023-12-07T10:38:56Z",
            "published": "2023-12-06T14:13:30Z",
            "summary": "The increasing use of stochastic models for describing complex phenomena\nwarrants surrogate models that capture the reference model characteristics at a\nfraction of the computational cost, foregoing potentially expensive Monte Carlo\nsimulation. The predominant approach of fitting a large neural network and then\npruning it to a reduced size has commonly neglected shortcomings. The produced\nsurrogate models often will not capture the sensitivities and uncertainties\ninherent in the original model. In particular, (higher-order) derivative\ninformation of such surrogates could differ drastically. Given a large enough\nnetwork, we expect this derivative information to match. However, the pruned\nmodel will almost certainly not share this behavior.\n  In this paper, we propose to find surrogate models by using sensitivity\ninformation throughout the learning and pruning process. We build on work using\nInterval Adjoint Significance Analysis for pruning and combine it with the\nrecent advancements in Sobolev Training to accurately model the original\nsensitivity information in the pruned neural network based surrogate model. We\nexperimentally underpin the method on an example of pricing a multidimensional\nBasket option modelled through a stochastic differential equation with Brownian\nmotion. The proposed method is, however, not limited to the domain of\nquantitative finance, which was chosen as a case study for intuitive\ninterpretations of the sensitivities. It serves as a foundation for building\nfurther surrogate modelling techniques considering sensitivity information.",
            "author": [
                "Neil Kichler",
                "Sher Afghan",
                "Uwe Naumann"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03510v2",
                "http://arxiv.org/pdf/2312.03510v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03508v1",
            "title": "Convolutional neural network based decoders for surface codes",
            "updated": "2023-12-06T14:07:31Z",
            "published": "2023-12-06T14:07:31Z",
            "summary": "The decoding of error syndromes of surface codes with classical algorithms\nmay slow down quantum computation. To overcome this problem it is possible to\nimplement decoding algorithms based on artificial neural networks. This work\nreports a study of decoders based on convolutional neural networks, tested on\ndifferent code distances and noise models. The results show that decoders based\non convolutional neural networks have good performance and can adapt to\ndifferent noise models. Moreover, explainable machine learning techniques have\nbeen applied to the neural network of the decoder to better understand the\nbehaviour and errors of the algorithm, in order to produce a more robust and\nperforming algorithm.",
            "author": [
                "Simone Bordoni",
                "Stefano Giagu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s11128-023-03898-2",
                "http://arxiv.org/abs/2312.03508v1",
                "http://arxiv.org/pdf/2312.03508v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03505v1",
            "title": "Metadata for the Flux Density Calibration of the April 2018 Event\n  Horizon Telescope Data",
            "updated": "2023-12-06T14:01:58Z",
            "published": "2023-12-06T14:01:58Z",
            "summary": "The Event Horizon Telescope (EHT) observations carried out in 2018 April at\n1.3 mm wavelengths included 9 stations in the array, comprising 7 single-dish\ntelescopes and 2 phased arrays. The metadata package for the 2018 EHT observing\ncampaign contains calibration tables required for the a-priori amplitude\ncalibration of the 2018 April visibility data. This memo is the official\ndocumentation accompanying the release of the 2018 EHT metadata package,\nproviding an overview of the contents of the package. We describe how telescope\nsensitivities, gain curves and other relevant parameters for each station in\nthe EHT array were collected, processed, and validated to produce the\ncalibration tables.",
            "author": [
                "J. Y. Koay",
                "C. Romero-Ca\u00f1izales",
                "L. D. Matthews",
                "M. Janssen",
                "L. Blackburn",
                "R. P. J. Tilanus",
                "J. Park",
                "K. Asada",
                "S. Matsushita",
                "A. -K. Baczko",
                "N. La Bella",
                "C. -K. Chan",
                "G. B. Crew",
                "V. Fish",
                "N. Patel",
                "V. Ramakrishnan",
                "H. Rottmann",
                "J. Wagner",
                "K. Wiik",
                "P. Friberg",
                "C. Goddi",
                "S. Issaoun",
                "G. Keating",
                "J. Kim",
                "T. P. Krichbaum",
                "D. Marrone",
                "G. Narayanan",
                "A. Roy",
                "I. Ru\u00edz",
                "S. S\u00e1nchez",
                "P. Torne",
                "J. Weintroub"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03505v1",
                "http://arxiv.org/pdf/2312.03505v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03502v1",
            "title": "Improving the Generalization of Segmentation Foundation Model under\n  Distribution Shift via Weakly Supervised Adaptation",
            "updated": "2023-12-06T13:59:22Z",
            "published": "2023-12-06T13:59:22Z",
            "summary": "The success of large language models has inspired the computer vision\ncommunity to explore image segmentation foundation model that is able to\nzero/few-shot generalize through prompt engineering. Segment-Anything(SAM),\namong others, is the state-of-the-art image segmentation foundation model\ndemonstrating strong zero/few-shot generalization. Despite the success, recent\nstudies reveal the weakness of SAM under strong distribution shift. In\nparticular, SAM performs awkwardly on corrupted natural images, camouflaged\nimages, medical images, etc. Motivated by the observations, we aim to develop a\nself-training based strategy to adapt SAM to target distribution. Given the\nunique challenges of large source dataset, high computation cost and incorrect\npseudo label, we propose a weakly supervised self-training architecture with\nanchor regularization and low-rank finetuning to improve the robustness and\ncomputation efficiency of adaptation. We validate the effectiveness on 5 types\nof downstream segmentation tasks including natural clean/corrupted images,\nmedical images, camouflaged images and robotic images. Our proposed method is\ntask-agnostic in nature and outperforms pre-trained SAM and state-of-the-art\ndomain adaptation methods on almost all downstream tasks with the same testing\nprompt inputs.",
            "author": [
                "Haojie Zhang",
                "Yongyi Su",
                "Xun Xu",
                "Kui Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03502v1",
                "http://arxiv.org/pdf/2312.03502v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03793v1",
            "title": "AnimateZero: Video Diffusion Models are Zero-Shot Image Animators",
            "updated": "2023-12-06T13:39:35Z",
            "published": "2023-12-06T13:39:35Z",
            "summary": "Large-scale text-to-video (T2V) diffusion models have great progress in\nrecent years in terms of visual quality, motion and temporal consistency.\nHowever, the generation process is still a black box, where all attributes\n(e.g., appearance, motion) are learned and generated jointly without precise\ncontrol ability other than rough text descriptions. Inspired by image animation\nwhich decouples the video as one specific appearance with the corresponding\nmotion, we propose AnimateZero to unveil the pre-trained text-to-video\ndiffusion model, i.e., AnimateDiff, and provide more precise appearance and\nmotion control abilities for it. For appearance control, we borrow intermediate\nlatents and their features from the text-to-image (T2I) generation for ensuring\nthe generated first frame is equal to the given generated image. For temporal\ncontrol, we replace the global temporal attention of the original T2V model\nwith our proposed positional-corrected window attention to ensure other frames\nalign with the first frame well. Empowered by the proposed methods, AnimateZero\ncan successfully control the generating progress without further training. As a\nzero-shot image animator for given images, AnimateZero also enables multiple\nnew applications, including interactive video generation and real image\nanimation. The detailed experiments demonstrate the effectiveness of the\nproposed method in both T2V and related applications.",
            "author": [
                "Jiwen Yu",
                "Xiaodong Cun",
                "Chenyang Qi",
                "Yong Zhang",
                "Xintao Wang",
                "Ying Shan",
                "Jian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03793v1",
                "http://arxiv.org/pdf/2312.03793v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03494v1",
            "title": "Boosting legal case retrieval by query content selection with large\n  language models",
            "updated": "2023-12-06T13:36:20Z",
            "published": "2023-12-06T13:36:20Z",
            "summary": "Legal case retrieval, which aims to retrieve relevant cases to a given query\ncase, benefits judgment justice and attracts increasing attention. Unlike\ngeneric retrieval queries, legal case queries are typically long and the\ndefinition of relevance is closely related to legal-specific elements.\nTherefore, legal case queries may suffer from noise and sparsity of salient\ncontent, which hinders retrieval models from perceiving correct information in\na query. While previous studies have paid attention to improving retrieval\nmodels and understanding relevance judgments, we focus on enhancing legal case\nretrieval by utilizing the salient content in legal case queries. We first\nannotate the salient content in queries manually and investigate how sparse and\ndense retrieval models attend to those content. Then we experiment with various\nquery content selection methods utilizing large language models (LLMs) to\nextract or summarize salient content and incorporate it into the retrieval\nmodels. Experimental results show that reformulating long queries using LLMs\nimproves the performance of both sparse and dense models in legal case\nretrieval.",
            "author": [
                "Youchao Zhou",
                "Heyan Huang",
                "Zhijing Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03494v1",
                "http://arxiv.org/pdf/2312.03494v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03492v1",
            "title": "Learning From Scenarios for Stochastic Repairable Scheduling",
            "updated": "2023-12-06T13:32:17Z",
            "published": "2023-12-06T13:32:17Z",
            "summary": "When optimizing problems with uncertain parameter values in a linear\nobjective, decision-focused learning enables end-to-end learning of these\nvalues. We are interested in a stochastic scheduling problem, in which\nprocessing times are uncertain, which brings uncertain values in the\nconstraints, and thus repair of an initial schedule may be needed. Historical\nrealizations of the stochastic processing times are available. We show how\nexisting decision-focused learning techniques based on stochastic smoothing can\nbe adapted to this scheduling problem. We include an extensive experimental\nevaluation to investigate in which situations decision-focused learning\noutperforms the state of the art for such situations: scenario-based stochastic\noptimization.",
            "author": [
                "Kim van den Houten",
                "David M. J. Tax",
                "Esteban Freydell",
                "Mathijs de Weerdt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03492v1",
                "http://arxiv.org/pdf/2312.03492v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03491v1",
            "title": "Schrodinger Bridges Beat Diffusion Models on Text-to-Speech Synthesis",
            "updated": "2023-12-06T13:31:55Z",
            "published": "2023-12-06T13:31:55Z",
            "summary": "In text-to-speech (TTS) synthesis, diffusion models have achieved promising\ngeneration quality. However, because of the pre-defined data-to-noise diffusion\nprocess, their prior distribution is restricted to a noisy representation,\nwhich provides little information of the generation target. In this work, we\npresent a novel TTS system, Bridge-TTS, making the first attempt to substitute\nthe noisy Gaussian prior in established diffusion-based TTS methods with a\nclean and deterministic one, which provides strong structural information of\nthe target. Specifically, we leverage the latent representation obtained from\ntext input as our prior, and build a fully tractable Schrodinger bridge between\nit and the ground-truth mel-spectrogram, leading to a data-to-data process.\nMoreover, the tractability and flexibility of our formulation allow us to\nempirically study the design spaces such as noise schedules, as well as to\ndevelop stochastic and deterministic samplers. Experimental results on the\nLJ-Speech dataset illustrate the effectiveness of our method in terms of both\nsynthesis quality and sampling efficiency, significantly outperforming our\ndiffusion counterpart Grad-TTS in 50-step/1000-step synthesis and strong fast\nTTS models in few-step scenarios. Project page: https://bridge-tts.github.io/",
            "author": [
                "Zehua Chen",
                "Guande He",
                "Kaiwen Zheng",
                "Xu Tan",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03491v1",
                "http://arxiv.org/pdf/2312.03491v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03490v1",
            "title": "PneumoLLM: Harnessing the Power of Large Language Model for\n  Pneumoconiosis Diagnosis",
            "updated": "2023-12-06T13:31:52Z",
            "published": "2023-12-06T13:31:52Z",
            "summary": "The conventional pretraining-and-finetuning paradigm, while effective for\ncommon diseases with ample data, faces challenges in diagnosing data-scarce\noccupational diseases like pneumoconiosis. Recently, large language models\n(LLMs) have exhibits unprecedented ability when conducting multiple tasks in\ndialogue, bringing opportunities to diagnosis. A common strategy might involve\nusing adapter layers for vision-language alignment and diagnosis in a dialogic\nmanner. Yet, this approach often requires optimization of extensive learnable\nparameters in the text branch and the dialogue head, potentially diminishing\nthe LLMs' efficacy, especially with limited training data. In our work, we\ninnovate by eliminating the text branch and substituting the dialogue head with\na classification head. This approach presents a more effective method for\nharnessing LLMs in diagnosis with fewer learnable parameters. Furthermore, to\nbalance the retention of detailed image information with progression towards\naccurate diagnosis, we introduce the contextual multi-token engine. This engine\nis specialized in adaptively generating diagnostic tokens. Additionally, we\npropose the information emitter module, which unidirectionally emits\ninformation from image tokens to diagnosis tokens. Comprehensive experiments\nvalidate the superiority of our methods and the effectiveness of proposed\nmodules. Our codes can be found at\nhttps://github.com/CodeMonsterPHD/PneumoLLM/tree/main.",
            "author": [
                "Meiyue Song",
                "Zhihua Yu",
                "Jiaxin Wang",
                "Jiarui Wang",
                "Yuting Lu",
                "Baicun Li",
                "Xiaoxu Wang",
                "Qinghua Huang",
                "Zhijun Li",
                "Nikolaos I. Kanellakis",
                "Jiangfeng Liu",
                "Jing Wang",
                "Binglu Wang",
                "Juntao Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03490v1",
                "http://arxiv.org/pdf/2312.03490v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03489v1",
            "title": "Decomposing Thermodynamic Dissipation of Neural Dynamics via\n  Spatio-Temporal Oscillatory Modes",
            "updated": "2023-12-06T13:30:59Z",
            "published": "2023-12-06T13:30:59Z",
            "summary": "Recent developments in stochastic thermodynamics have elucidated various\nrelations between the entropy production rate (thermodynamics dissipation) and\nthe physical limits of information processing in nonequilibrium dynamical\nsystems, which have been actively used and opened new perspectives in the\nanalysis of real biological systems. Even in neuroscience, the importance of\nquantifying the entropy production has attracted increasing attention to\nunderstand the properties of information processing in the brain. However, the\nrelationships between entropy production rate and neural oscillations, such as\ndelta, theta, and alpha waves, which are prevalent in the brain, are unclear.\nHere, we derive a novel decomposition of the entropy production rate. We show\nthat one of the components of the entropy production rate, called the\nhousekeeping entropy production rate, can be decomposed into independent\npositive contributions from spatio-temporal oscillatory modes. Our\ndecomposition enables us to calculate the contribution to the housekeeping\nentropy production rate from oscillatory modes, as well as the spatial\ndistribution of the contributions. To demonstrate the utility of our\ndecomposition, we applied our decomposition to the electrocorticography (ECoG)\ndataset recorded during awake and anesthetized conditions in monkeys, where the\nproperties of oscillations change drastically. We showed the consistent trends\nacross different monkeys, i.e., the contributions of oscillatory modes from the\ndelta band were larger in the anesthetized condition than in the awake\ncondition, while those from the higher frequency bands, such as the theta band,\nwere smaller. These results allow us to interpret the change in the neural\noscillation in terms of stochastic thermodynamics and the physical limit of\ninformation processing.",
            "author": [
                "Daiki Sekizawa",
                "Sosuke Ito",
                "Masafumi Oizumi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03489v1",
                "http://arxiv.org/pdf/2312.03489v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03488v1",
            "title": "Modeling Aggregate Downwash Forces for Dense Multirotor Flight",
            "updated": "2023-12-06T13:30:49Z",
            "published": "2023-12-06T13:30:49Z",
            "summary": "Dense formation flight with multirotor swarms is a powerful, nature-inspired\nflight regime with numerous applications in the realworld. However, when\nmultirotors fly in close vertical proximity to each other, the propeller\ndownwash from the vehicles can have a destabilising effect on each other.\nUnfortunately, even in a homogeneous team, an accurate model of downwash forces\nfrom one vehicle is unlikely to be sufficient for predicting aggregate forces\nfrom multiple vehicles in formation.\n  In this work, we model the interaction patterns produced by one or more\nvehicles flying in close proximity to an ego-vehicle. We first present an\nexperimental test rig designed to capture 6-DOF exogenic forces acting on a\nmultirotor frame. We then study and characterize these measured forces as a\nfunction of the relative states of two multirotors flying various patterns in\nits vicinity.\n  Our analysis captures strong non-linearities present in the aggregation of\nthese interactions. Then, by modeling the formation as a graph, we present a\nnovel approach for learning the force aggregation function, and contrast it\nagainst simpler linear models. Finally, we explore how our proposed models\ngeneralize when a fourth vehicle is added to the formation.",
            "author": [
                "Jennifer Gielis",
                "Ajay Shankar",
                "Ryan Kortvelesy",
                "Amanda Prorok"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03488v1",
                "http://arxiv.org/pdf/2312.03488v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03487v1",
            "title": "How to detect the spacetime curvature without rulers and clocks. II.\n  Three-dimensional spacetime",
            "updated": "2023-12-06T13:30:32Z",
            "published": "2023-12-06T13:30:32Z",
            "summary": "We have generalized the results of the previous work [arXiv:2302.12209] to\nthe case of three-dimensional (3D) spacetime with two spatial and one temporal\ncoordinates. We have found that the flat Minkowski 3D spacetime is\n\"well-stitched\", which means that it possesses a structure described by 24\ncausal relations between 12 events. We have proved that a 3D spacetime is\n\"well-stitched\" if and only if it is conformally flat. The concept of a\n\"well-stitched\" spacetime does not rely on metrical information about lengths,\ntimes, etc., and does not belong to the metric geometry, but rather to geometry\nof incidence. We therefore have \"translated\" an important concept of a\nconformally-flat spacetime from the \"metric\" language of Riemannian geometry to\nthe \"non-metric\" language of the geometry of incidence. The results of this\npaper provide a tool for detecting the curvature of the 3D spacetime on the\nbasis of causal relations only, without any measurement instruments like rulers\nand clocks, provided that the spacetime is not conformally flat.",
            "author": [
                "A. V. Nenashev",
                "S. D. Baranovskii"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03487v1",
                "http://arxiv.org/pdf/2312.03487v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03483v1",
            "title": "Exploring Answer Information Methods for Question Generation with\n  Transformers",
            "updated": "2023-12-06T13:26:16Z",
            "published": "2023-12-06T13:26:16Z",
            "summary": "There has been a lot of work in question generation where different methods\nto provide target answers as input, have been employed. This experimentation\nhas been mostly carried out for RNN based models. We use three different\nmethods and their combinations for incorporating answer information and explore\ntheir effect on several automatic evaluation metrics. The methods that are used\nare answer prompting, using a custom product method using answer embeddings and\nencoder outputs, choosing sentences from the input paragraph that have answer\nrelated information, and using a separate cross-attention attention block in\nthe decoder which attends to the answer. We observe that answer prompting\nwithout any additional modes obtains the best scores across rouge, meteor\nscores. Additionally, we use a custom metric to calculate how many of the\ngenerated questions have the same answer, as the answer which is used to\ngenerate them.",
            "author": [
                "Talha Chafekar",
                "Aafiya Hussain",
                "Grishma Sharma",
                "Deepak Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03483v1",
                "http://arxiv.org/pdf/2312.03483v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03480v1",
            "title": "AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing\n  Evaluation Suite",
            "updated": "2023-12-06T13:19:56Z",
            "published": "2023-12-06T13:19:56Z",
            "summary": "We present the Granular AMR Parsing Evaluation Suite (GrAPES), a challenge\nset for Abstract Meaning Representation (AMR) parsing with accompanying\nevaluation metrics. AMR parsers now obtain high scores on the standard AMR\nevaluation metric Smatch, close to or even above reported inter-annotator\nagreement. But that does not mean that AMR parsing is solved; in fact, human\nevaluation in previous work indicates that current parsers still quite\nfrequently make errors on node labels or graph structure that substantially\ndistort sentence meaning. Here, we provide an evaluation suite that tests AMR\nparsers on a range of phenomena of practical, technical, and linguistic\ninterest. Our 36 categories range from seen and unseen labels, to structural\ngeneralization, to coreference. GrAPES reveals in depth the abilities and\nshortcomings of current AMR parsers.",
            "author": [
                "Jonas Groschwitz",
                "Shay B. Cohen",
                "Lucia Donatelli",
                "Meaghan Fowlie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03480v1",
                "http://arxiv.org/pdf/2312.03480v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "J.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03479v1",
            "title": "JAMMIN-GPT: Text-based Improvisation using LLMs in Ableton Live",
            "updated": "2023-12-06T13:19:34Z",
            "published": "2023-12-06T13:19:34Z",
            "summary": "We introduce a system that allows users of Ableton Live to create MIDI-clips\nby naming them with musical descriptions. Users can compose by typing the\ndesired musical content directly in Ableton's clip view, which is then inserted\nby our integrated system. This allows users to stay in the flow of their\ncreative process while quickly generating musical ideas. The system works by\nprompting ChatGPT to reply using one of several text-based musical formats,\nsuch as ABC notation, chord symbols, or drum tablature. This is an important\nstep in integrating generative AI tools into pre-existing musical workflows,\nand could be valuable for content makers who prefer to express their creative\nvision through descriptive language. Code is available at\nhttps://github.com/supersational/JAMMIN-GPT.",
            "author": [
                "Sven Hollowell",
                "Tashi Namgyal",
                "Paul Marshall"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03479v1",
                "http://arxiv.org/pdf/2312.03479v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.HC",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03477v1",
            "title": "From Detection to Action Recognition: An Edge-Based Pipeline for Robot\n  Human Perception",
            "updated": "2023-12-06T13:10:02Z",
            "published": "2023-12-06T13:10:02Z",
            "summary": "Mobile service robots are proving to be increasingly effective in a range of\napplications, such as healthcare, monitoring Activities of Daily Living (ADL),\nand facilitating Ambient Assisted Living (AAL). These robots heavily rely on\nHuman Action Recognition (HAR) to interpret human actions and intentions.\nHowever, for HAR to function effectively on service robots, it requires prior\nknowledge of human presence (human detection) and identification of individuals\nto monitor (human tracking). In this work, we propose an end-to-end pipeline\nthat encompasses the entire process, starting from human detection and\ntracking, leading to action recognition. The pipeline is designed to operate in\nnear real-time while ensuring all stages of processing are performed on the\nedge, reducing the need for centralised computation. To identify the most\nsuitable models for our mobile robot, we conducted a series of experiments\ncomparing state-of-the-art solutions based on both their detection performance\nand efficiency. To evaluate the effectiveness of our proposed pipeline, we\nproposed a dataset comprising daily household activities. By presenting our\nfindings and analysing the results, we demonstrate the efficacy of our approach\nin enabling mobile robots to understand and respond to human behaviour in\nreal-world scenarios relying mainly on the data from their RGB cameras.",
            "author": [
                "Petros Toupas",
                "Georgios Tsamis",
                "Dimitrios Giakoumis",
                "Konstantinos Votis",
                "Dimitrios Tzovaras"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03477v1",
                "http://arxiv.org/pdf/2312.03477v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03475v1",
            "title": "Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D\n  Diffusion",
            "updated": "2023-12-06T12:58:37Z",
            "published": "2023-12-06T12:58:37Z",
            "summary": "Recently, artificial intelligence for drug discovery has raised increasing\ninterest in both machine learning and chemistry domains. The fundamental\nbuilding block for drug discovery is molecule geometry and thus, the molecule's\ngeometrical representation is the main bottleneck to better utilize machine\nlearning techniques for drug discovery. In this work, we propose a pretraining\nmethod for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn\nboth the 2D bond (topology) and 3D conformation (geometry) information, and a\ndiffusion process model is applied to mimic the augmented trajectories of such\ntwo modalities, based on which, MoleculeJAE will learn the inherent chemical\nstructure in a self-supervised manner. Thus, the pretrained geometrical\nrepresentation in MoleculeJAE is expected to benefit downstream\ngeometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by\nreaching state-of-the-art performance on 15 out of 20 tasks by comparing it\nwith 12 competitive baselines.",
            "author": [
                "Weitao Du",
                "Jiujiu Chen",
                "Xuecang Zhang",
                "Zhiming Ma",
                "Shengchao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03475v1",
                "http://arxiv.org/pdf/2312.03475v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03470v1",
            "title": "Regular polygons, line operators, and elliptic modular surfaces as\n  realization spaces of matroids",
            "updated": "2023-12-06T12:50:03Z",
            "published": "2023-12-06T12:50:03Z",
            "summary": "We investigate the matroid realization space of a specific deformation of the\nregular $n$-gon with its lines of symmetry. It turns out that these particular\nrealization spaces are birational to the elliptic modular surfaces $\\Xi_{1}(n)$\nover the modular curve $X_1(n)$.\n  We obtain in that way a model of $\\Xi_{1}(n)$ defined over the rational\nnumbers. Furthermore, a natural geometric operator acts on these matroid\nrealizations. On the elliptic modular surface this operator corresponds to the\nmultiplication by $-2$ on the elliptic curves. That gives a new geometric way\nto compute the multiplication by $-2$ on elliptic curves.",
            "author": [
                "Lukas K\u00fchne",
                "Xavier Roulleau"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03470v1",
                "http://arxiv.org/pdf/2312.03470v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "math.CO",
                "14N20, 14J27, 14J25, 14G35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03465v1",
            "title": "Quantum-secured single-pixel imaging under general spoofing attack",
            "updated": "2023-12-06T12:41:50Z",
            "published": "2023-12-06T12:41:50Z",
            "summary": "In this paper, we introduce a quantum-secured single-pixel imaging (QS-SPI)\ntechnique designed to withstand spoofing attacks, wherein adversaries attempt\nto deceive imaging systems with fake signals. Unlike previous quantum-secured\nprotocols that impose a threshold error rate limiting their operation, even\nwith the existence of true signals, our approach not only identifies spoofing\nattacks but also facilitates the reconstruction of a true image. Our method\ninvolves the analysis of a specific mode correlation of a photon-pair, which is\nindependent of the mode used for image construction, to check security. Through\nthis analysis, we can identify both the targeted image region by the attack and\nthe type of spoofing attack, enabling reconstruction of the true image. A\nproof-of-principle demonstration employing polarization-correlation of a\nphoton-pair is provided, showcasing successful image reconstruction even under\nthe condition of spoofing signals 2000 times stronger than the true signals. We\nexpect our approach to be applied to quantum-secured signal processing such as\nquantum target detection or ranging.",
            "author": [
                "Jaesung Heo",
                "Taek Jeong",
                "Nam Hun Park",
                "Yonggi Jo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03465v1",
                "http://arxiv.org/pdf/2312.03465v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03464v1",
            "title": "Subnetwork-to-go: Elastic Neural Network with Dynamic Training and\n  Customizable Inference",
            "updated": "2023-12-06T12:40:06Z",
            "published": "2023-12-06T12:40:06Z",
            "summary": "Deploying neural networks to different devices or platforms is in general\nchallenging, especially when the model size is large or model complexity is\nhigh. Although there exist ways for model pruning or distillation, it is\ntypically required to perform a full round of model training or finetuning\nprocedure in order to obtain a smaller model that satisfies the model size or\ncomplexity constraints. Motivated by recent works on dynamic neural networks,\nwe propose a simple way to train a large network and flexibly extract a\nsubnetwork from it given a model size or complexity constraint during\ninference. We introduce a new way to allow a large model to be trained with\ndynamic depth and width during the training phase, and after the large model is\ntrained we can select a subnetwork from it with arbitrary depth and width\nduring the inference phase with a relatively better performance compared to\ntraining the subnetwork independently from scratch. Experiment results on a\nmusic source separation model show that our proposed method can effectively\nimprove the separation performance across different subnetwork sizes and\ncomplexities with a single large model, and training the large model takes\nsignificantly shorter time than training all the different subnetworks.",
            "author": [
                "Kai Li",
                "Yi Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03464v1",
                "http://arxiv.org/pdf/2312.03464v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03463v1",
            "title": "DBCopilot: Scaling Natural Language Querying to Massive Databases",
            "updated": "2023-12-06T12:37:28Z",
            "published": "2023-12-06T12:37:28Z",
            "summary": "Text-to-SQL simplifies database interactions by enabling non-experts to\nconvert their natural language (NL) questions into Structured Query Language\n(SQL) queries. While recent advances in large language models (LLMs) have\nimproved the zero-shot text-to-SQL paradigm, existing methods face scalability\nchallenges when dealing with massive, dynamically changing databases. This\npaper introduces DBCopilot, a framework that addresses these challenges by\nemploying a compact and flexible copilot model for routing across massive\ndatabases. Specifically, DBCopilot decouples the text-to-SQL process into\nschema routing and SQL generation, leveraging a lightweight\nsequence-to-sequence neural network-based router to formulate database\nconnections and navigate natural language questions through databases and\ntables. The routed schemas and questions are then fed into LLMs for efficient\nSQL generation. Furthermore, DBCopilot also introduced a reverse\nschema-to-question generation paradigm, which can learn and adapt the router\nover massive databases automatically without requiring manual intervention.\nExperimental results demonstrate that DBCopilot is a scalable and effective\nsolution for real-world text-to-SQL tasks, providing a significant advancement\nin handling large-scale schemas.",
            "author": [
                "Tianshu Wang",
                "Hongyu Lin",
                "Xianpei Han",
                "Le Sun",
                "Xiaoyang Chen",
                "Hao Wang",
                "Zhenyu Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03463v1",
                "http://arxiv.org/pdf/2312.03463v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03460v1",
            "title": "Modeling the dynamics of quantum systems coupled to large dimensional\n  baths using effective energy states",
            "updated": "2023-12-06T12:35:24Z",
            "published": "2023-12-06T12:35:24Z",
            "summary": "The quantum dynamics of a low-dimensional system in contact with a large but\nfinite harmonic bath is theoretically investigated by coarse-graining the bath\ninto a reduced set of effective energy states. In this model, the couplings\nbetween the system and the bath are obtained from the statistical average over\nthe discrete, degenerate effective states. Our model is aimed at intermediate\nbath sizes in which non-Markovian processes and energy transfer between the\nbath and the main system are important. The method is applied to a model system\nof a Morse oscillator coupled to 40 harmonic modes. The results are found to be\nin excellent agreement with the direct quantum dynamics simulations of\nBouakline et al. [J. Phys. Chem. A 116, 11118-11127 (2012)], but at a much\nlower computational cost. Extension to larger baths is discussed in comparison\nto the time-convolutionless method. We also extend this study to the case of a\nmicrocanonical bath with finite initial internal energies. The computational\nefficiency and convergence properties of the effective bath states model with\nrespect to relevant parameters are also discussed.",
            "author": [
                "Lo\u00efse Attal",
                "Cyril Falvo",
                "Florent Calvo",
                "Pascal Parneix"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03460v1",
                "http://arxiv.org/pdf/2312.03460v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03459v1",
            "title": "F3-Pruning: A Training-Free and Generalized Pruning Strategy towards\n  Faster and Finer Text-to-Video Synthesis",
            "updated": "2023-12-06T12:34:47Z",
            "published": "2023-12-06T12:34:47Z",
            "summary": "Recently Text-to-Video (T2V) synthesis has undergone a breakthrough by\ntraining transformers or diffusion models on large-scale datasets.\nNevertheless, inferring such large models incurs huge costs.Previous inference\nacceleration works either require costly retraining or are model-specific.To\naddress this issue, instead of retraining we explore the inference process of\ntwo mainstream T2V models using transformers and diffusion models.The\nexploration reveals the redundancy in temporal attention modules of both\nmodels, which are commonly utilized to establish temporal relations among\nframes.Consequently, we propose a training-free and generalized pruning\nstrategy called F3-Pruning to prune redundant temporal attention\nweights.Specifically, when aggregate temporal attention values are ranked below\na certain ratio, corresponding weights will be pruned.Extensive experiments on\nthree datasets using a classic transformer-based model CogVideo and a typical\ndiffusion-based model Tune-A-Video verify the effectiveness of F3-Pruning in\ninference acceleration, quality assurance and broad applicability.",
            "author": [
                "Sitong Su",
                "Jianzhi Liu",
                "Lianli Gao",
                "Jingkuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03459v1",
                "http://arxiv.org/pdf/2312.03459v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03458v1",
            "title": "Think from Words(TFW): Initiating Human-Like Cognition in Large Language\n  Models Through Think from Words for Japanese Text-level Classification",
            "updated": "2023-12-06T12:34:46Z",
            "published": "2023-12-06T12:34:46Z",
            "summary": "The proliferation of Large Language Models (LLMs) has spurred extensive\nresearch into LLM-related Prompt investigations, such as Instruction Learning\n(IL), In-context Learning (ICL), and Chain-of-Thought (CoT). These approaches\naim to improve LLMs' responses by enabling them to provide concise statements\nor examples for deeper contemplation when addressing questions. However,\nindependent thinking by LLMs can introduce variability in their thought\nprocesses, leading to potential inaccuracies. In response, our study seeks to\nbridge the gap between LLM and human-like thinking processes, recognizing that\ntext comprehension begins with understanding individual words. To tackle this\nchallenge, we have expanded the CoT method to cater to a specific domain. Our\napproach, known as \"Think from Words\" (TFW), initiates the comprehension\nprocess at the word level and then extends it to encompass the entire text. We\nalso propose \"TFW with Extra word-level information\" (TFW Extra), augmenting\ncomprehension with additional word-level data. To assess our methods, we employ\ntext classification on six Japanese datasets comprising text-level and\nword-level elements. Our findings not only validate the effectiveness of TFW\nbut also shed light on the impact of various word-level information types on\nLLMs' text comprehension, offering insights into their potential to cause\nmisinterpretations and errors in the overall comprehension of the final text.",
            "author": [
                "Chengguang Gan",
                "Qinghao Zhang",
                "Tatsunori Mori"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03458v1",
                "http://arxiv.org/pdf/2312.03458v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03455v1",
            "title": "Data is Overrated: Perceptual Metrics Can Lead Learning in the Absence\n  of Training Data",
            "updated": "2023-12-06T12:27:25Z",
            "published": "2023-12-06T12:27:25Z",
            "summary": "Perceptual metrics are traditionally used to evaluate the quality of natural\nsignals, such as images and audio. They are designed to mimic the perceptual\nbehaviour of human observers and usually reflect structures found in natural\nsignals. This motivates their use as loss functions for training generative\nmodels such that models will learn to capture the structure held in the metric.\nWe take this idea to the extreme in the audio domain by training a compressive\nautoencoder to reconstruct uniform noise, in lieu of natural data. We show that\ntraining with perceptual losses improves the reconstruction of spectrograms and\nre-synthesized audio at test time over models trained with a standard Euclidean\nloss. This demonstrates better generalisation to unseen natural signals when\nusing perceptual metrics.",
            "author": [
                "Tashi Namgyal",
                "Alexander Hepburn",
                "Raul Santos-Rodriguez",
                "Valero Laparra",
                "Jesus Malo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03455v1",
                "http://arxiv.org/pdf/2312.03455v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "eess.AS",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03450v1",
            "title": "Variational Autoencoder for Channel Estimation: Real-World Measurement\n  Insights",
            "updated": "2023-12-06T12:17:15Z",
            "published": "2023-12-06T12:17:15Z",
            "summary": "This work utilizes a variational autoencoder for channel estimation and\nevaluates it on real-world measurements. The estimator is trained solely on\nnoisy channel observations and parameterizes an approximation to the mean\nsquared error-optimal estimator by learning observation-dependent conditional\nfirst and second moments. The proposed estimator significantly outperforms\nrelated state-of-the-art estimators on real-world measurements. We investigate\nthe effect of pre-training with synthetic data and find that the proposed\nestimator exhibits comparable results to the related estimators if trained on\nsynthetic data and evaluated on the measurement data. Furthermore, pre-training\non synthetic data also helps to reduce the required measurement training\ndataset size.",
            "author": [
                "Michael Baur",
                "Benedikt B\u00f6ck",
                "Nurettin Turan",
                "Wolfgang Utschick"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03450v1",
                "http://arxiv.org/pdf/2312.03450v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03448v1",
            "title": "Extreme orbital $ab$-plane upper critical fields far beyond Pauli limit\n  in 4$H_{b}$-Ta(S, Se)$_{2}$ bulk crystals",
            "updated": "2023-12-06T12:13:46Z",
            "published": "2023-12-06T12:13:46Z",
            "summary": "Transition metal disulfides 4$H_{b}$-Ta(S, Se)$_{2}$ with natural\nheterostructure of 1${T}$- and 1${H}$-Ta(S, Se)$_{2}$ layers have became the\nfocus of correlated materials their unique combinations of Mott physics and\npossible topological superconductivity. In this work, we study the upper\ncritical fields $\\mu_{0}H_{c2}$ of 4$H_{b}$-TaS$_{2}$ and\n4$H_{b}$-TaS$_{1.99}$Se$_{0.01}$ single crystals systematically. Transport\nmeasurements up to 35 T show that both of ${ab}$-plane and ${c}$-axis upper\ncritical fields ($\\mu_{0}H_{c2,ab}$ and $\\mu_{0}H_{c2,c}$) for\n4$H_{b}$-TaS$_{2}$ and 4$H_{b}$-TaS$_{1.99}$Se$_{0.01}$ exhibit a linear\ntemperature dependent behavior down to 0.3 K, suggesting the three-dimensional\nsuperconductivity with dominant orbital depairing mechanism in bulk\n4$H_{b}$-Ta(S, Se)$_{2}$. However, the zero-temperature $\\mu_{0}H_{c2,ab}$(0)\nfor both crystals are far beyond the Pauli paramagnetic limit\n$\\mu_{0}H{\\rm_{P}}$. It could be explained by the effects of spin-momentum\nlocking in 1$H$-Ta(S, Se)$_{2}$ layers with local inversion symmetry broken and\nthe relatively weak intersublattice interaction between 1$H$ layers due to the\nexistence of 1$T$ layers.",
            "author": [
                "Fanyu Meng",
                "Yang Fu",
                "Senyang Pan",
                "Shangjie Tian",
                "Shaohua Yan",
                "Zhengyu Li",
                "Shouguo Wang",
                "Jinglei Zhang",
                "Hechang Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03448v1",
                "http://arxiv.org/pdf/2312.03448v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03789v1",
            "title": "Comparative Analysis of Multilingual Text Classification &\n  Identification through Deep Learning and Embedding Visualization",
            "updated": "2023-12-06T12:03:27Z",
            "published": "2023-12-06T12:03:27Z",
            "summary": "This research conducts a comparative study on multilingual text\nclassification methods, utilizing deep learning and embedding visualization.\nThe study employs LangDetect, LangId, FastText, and Sentence Transformer on a\ndataset encompassing 17 languages. It explores dimensionality's impact on\nclustering, revealing FastText's clearer clustering in 2D visualization due to\nits extensive multilingual corpus training. Notably, the FastText multi-layer\nperceptron model achieved remarkable accuracy, precision, recall, and F1 score,\noutperforming the Sentence Transformer model. The study underscores the\neffectiveness of these techniques in multilingual text classification,\nemphasizing the importance of large multilingual corpora for training\nembeddings. It lays the groundwork for future research and assists\npractitioners in developing language detection and classification systems.\nAdditionally, it includes the comparison of multi-layer perceptron, LSTM, and\nConvolution models for classification.",
            "author": [
                "Arinjay Wyawhare"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03789v1",
                "http://arxiv.org/pdf/2312.03789v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03443v1",
            "title": "Data-driven Crop Growth Simulation on Time-varying Generated Images\n  using Multi-conditional Generative Adversarial Networks",
            "updated": "2023-12-06T11:54:50Z",
            "published": "2023-12-06T11:54:50Z",
            "summary": "Image-based crop growth modeling can substantially contribute to precision\nagriculture by revealing spatial crop development over time, which allows an\nearly and location-specific estimation of relevant future plant traits, such as\nleaf area or biomass. A prerequisite for realistic and sharp crop image\ngeneration is the integration of multiple growth-influencing conditions in a\nmodel, such as an image of an initial growth stage, the associated growth time,\nand further information about the field treatment. We present a two-stage\nframework consisting first of an image prediction model and second of a growth\nestimation model, which both are independently trained. The image prediction\nmodel is a conditional Wasserstein generative adversarial network (CWGAN). In\nthe generator of this model, conditional batch normalization (CBN) is used to\nintegrate different conditions along with the input image. This allows the\nmodel to generate time-varying artificial images dependent on multiple\ninfluencing factors of different kinds. These images are used by the second\npart of the framework for plant phenotyping by deriving plant-specific traits\nand comparing them with those of non-artificial (real) reference images. For\nvarious crop datasets, the framework allows realistic, sharp image predictions\nwith a slight loss of quality from short-term to long-term predictions.\nSimulations of varying growth-influencing conditions performed with the trained\nframework provide valuable insights into how such factors relate to crop\nappearances, which is particularly useful in complex, less explored crop\nmixture systems. Further results show that adding process-based simulated\nbiomass as a condition increases the accuracy of the derived phenotypic traits\nfrom the predicted images. This demonstrates the potential of our framework to\nserve as an interface between an image- and process-based crop growth model.",
            "author": [
                "Lukas Drees",
                "Dereje T. Demie",
                "Madhuri R. Paul",
                "Johannes Leonhardt",
                "Sabine J. Seidel",
                "Thomas F. D\u00f6ring",
                "Ribana Roscher"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03443v1",
                "http://arxiv.org/pdf/2312.03443v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03438v1",
            "title": "On the Estimation Performance of Generalized Power Method for\n  Heteroscedastic Probabilistic PCA",
            "updated": "2023-12-06T11:41:17Z",
            "published": "2023-12-06T11:41:17Z",
            "summary": "The heteroscedastic probabilistic principal component analysis (PCA)\ntechnique, a variant of the classic PCA that considers data heterogeneity, is\nreceiving more and more attention in the data science and signal processing\ncommunities. In this paper, to estimate the underlying low-dimensional linear\nsubspace (simply called \\emph{ground truth}) from available heterogeneous data\nsamples, we consider the associated non-convex maximum-likelihood estimation\nproblem, which involves maximizing a sum of heterogeneous quadratic forms over\nan orthogonality constraint (HQPOC). We propose a first-order method --\ngeneralized power method (GPM) -- to tackle the problem and establish its\n\\emph{estimation performance} guarantee. Specifically, we show that, given a\nsuitable initialization, the distances between the iterates generated by GPM\nand the ground truth decrease at least geometrically to some threshold\nassociated with the residual part of certain \"population-residual\ndecomposition\". In establishing the estimation performance result, we prove a\nnovel local error bound property of another closely related optimization\nproblem, namely quadratic optimization with orthogonality constraint (QPOC),\nwhich is new and can be of independent interest. Numerical experiments are\nconducted to demonstrate the superior performance of GPM in both Gaussian noise\nand sub-Gaussian noise settings.",
            "author": [
                "Jinxin Wang",
                "Chonghe Jiang",
                "Huikang Liu",
                "Anthony Man-Cho So"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03438v1",
                "http://arxiv.org/pdf/2312.03438v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03436v1",
            "title": "Beyond Low Rank: A Graph-Based Propagation Approach to Tensor Completion\n  for Multi-Acquisition Scenarios",
            "updated": "2023-12-06T11:37:25Z",
            "published": "2023-12-06T11:37:25Z",
            "summary": "Tensor completion refers to the problem of recovering the missing, corrupted\nor unobserved entries in data represented by tensors. In this paper, we tackle\nthe tensor completion problem in the scenario in which multiple tensor\nacquisitions are available and do so without placing constraints on the\nunderlying tensor's rank. Whereas previous tensor completion work primarily\nfocuses on low-rank completion methods, we propose a novel graph-based\ndiffusion approach to the problem. Referred to as GraphProp, the method\npropagates observed entries around a graph-based representation of the tensor\nin order to recover the missing entries. A series of experiments have been\nperformed to validate the presented approach, including a\nsynthetically-generated tensor recovery experiment which shows that the method\ncan be used to recover both low and high rank tensor entries. The successful\ntensor completion capabilities of the approach are also demonstrated on a\nreal-world completion problem from the field of multispectral remote sensing\ncompletion. Using data acquired from the Landsat 7 platform, we synthetically\nobscure image sections in order to simulate the scenario in which image\nacquisitions overlap only partially. In these tests, we benchmark against\nalternative tensor completion approaches as well as existing graph signal\nrecovery methods, demonstrating the superior reconstruction performance of our\nmethod versus the state of the art.",
            "author": [
                "Iain Rolland",
                "Sivasakthy Selvakumaran",
                "Andrea Marinoni"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03436v1",
                "http://arxiv.org/pdf/2312.03436v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03427v1",
            "title": "Latent State Space Extension for interpretable hybrid mechanistic models",
            "updated": "2023-12-06T11:19:24Z",
            "published": "2023-12-06T11:19:24Z",
            "summary": "Mechanistic growth models play a major role in bioprocess engineering,\ndesign, and control. Their reasonable predictive power and their high level of\ninterpretability make them an essential tool for computer aided engineering\nmethods. Additionally, since they contain knowledge about cell physiology, the\nparameter estimates provide meaningful insights into the metabolism of the\nmicroorganism under study. However, the assumption of time invariance of the\nmodel parameters is often violated in real experiments, limiting their capacity\nto fully explain the observed dynamics. In this work, we propose a framework\nfor identifying such violations and producing insights into misspecified\nmechanisms. The framework achieves this by allowing kinetic and process\nparameters to vary in time. We demonstrate the framework's capabilities by\nfitting a hybrid model based on a simple mechanistic growth model for E. coli\nwith data generated in-silico by a much more complex one and identifying\nmissing kinetics.",
            "author": [
                "Judit Aizpuru",
                "Maxim Borisyak",
                "Peter Neubauer",
                "M. Nicolas Cruz Bournazou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03427v1",
                "http://arxiv.org/pdf/2312.03427v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03424v1",
            "title": "Physico-chemical Processes in Planet-forming Discs",
            "updated": "2023-12-06T11:13:06Z",
            "published": "2023-12-06T11:13:06Z",
            "summary": "This thesis summarises my scientific works in the field of thermo-chemical\nmodelling of planet-forming discs since 2009, in particular the development of\nthe Protoplanetary Disc Model (ProDiMo). By combining chemical rate networks\nwith continuum & line radiative transfer, and the calculation of all relevant\ndust and gas heating & cooling rates in an axisymmetric disc structure, these\nmodels make detailed predictions about the molecular composition of the disc,\nthe discs' internal gas and dust temperature structure, and the composition of\nice layers which form on the refractory dust grain surfaces. The development of\nProDiMo was a process that took about 15 years. I have started the ProDiMo\nproject and am the main developer, but without the involvement of an\ninternational team of scientists, in particular Inga Kamp, Wing-Fai Thi and\nChristian Rab, ProDiMo would not have its capabilities and would not be at the\nlevel of international recognition that is has achieved to date.\n  Using formal solutions of the line & continuum radiative transfer, we can\npredict the spectral appearance of these discs from optical to millimetre\nwavelengths, for example the continuum and line fluxes, monochromatic images,\nradial intensity profiles, high-resolution line profiles that probe the disc\ndynamics, visibilities and channel maps. A large part of this thesis describes\nthe publications that compared these predictions to disc observations that have\nbeen obtained by various space-borne and ground-based astronomical instruments,\nin particular Herschel/PACS, Spitzer/IRS, VLT/CRIRES, JWST/MIRI and ALMA. These\nobservations probe the gas and the dust in different radial disc regions and in\ndifferent layers above the midplane. This thesis summarises the conclusions\ndrawn from the ProDiMo thermo-chemical disc models about the chemical and\nphysical state of protoplanetary discs as the birth places of exoplanets.",
            "author": [
                "Peter Woitke"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03424v1",
                "http://arxiv.org/pdf/2312.03424v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03423v1",
            "title": "Markov Chain Monte Carlo Data Association for Sets of Trajectories",
            "updated": "2023-12-06T11:12:43Z",
            "published": "2023-12-06T11:12:43Z",
            "summary": "This paper considers a batch solution to the multi-object tracking problem\nbased on sets of trajectories. Specifically, we present two offline\nimplementations of the trajectory Poisson multi-Bernoulli mixture (TPMBM)\nfilter for batch data based on Markov chain Monte Carlo (MCMC) sampling of the\ndata association hypotheses. In contrast to online TPMBM implementations, the\nproposed offline implementations solve a large-scale, multi-scan data\nassociation problem across the entire time interval of interest, and therefore\nthey can fully exploit all the measurement information available. Furthermore,\nby leveraging the efficient hypothesis structure of TPMBM filters, the proposed\nimplementations compare favorably with other MCMC-based multi-object tracking\nalgorithms. Simulation results show that the TPMBM implementation using the\nMetropolis-Hastings algorithm presents state-of-the-art multiple trajectory\nestimation performance.",
            "author": [
                "Yuxuan Xia",
                "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez",
                "Lennart Svensson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03423v1",
                "http://arxiv.org/pdf/2312.03423v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03788v1",
            "title": "SmoothQuant+: Accurate and Efficient 4-bit Post-Training\n  WeightQuantization for LLM",
            "updated": "2023-12-06T11:10:55Z",
            "published": "2023-12-06T11:10:55Z",
            "summary": "Large language models (LLMs) have shown remarkable capabilities in various\ntasks. However their huge model size and the consequent demand for\ncomputational and memory resources also pose challenges to model deployment.\nCurrently, 4-bit post-training quantization (PTQ) has achieved some success in\nLLMs, reducing the memory footprint by approximately 75% compared to FP16\nmodels, albeit with some accuracy loss. In this paper, we propose SmoothQuant+,\nan accurate and efficient 4-bit weight-only PTQ that requires no additional\ntraining, which enables lossless in accuracy for LLMs for the first time. Based\non the fact that the loss of weight quantization is amplified by the activation\noutliers, SmoothQuant+ smoothes the activation outliers by channel before\nquantization, while adjusting the corresponding weights for mathematical\nequivalence, and then performs group-wise 4-bit weight quantization for linear\nlayers. We have integrated SmoothQuant+ into the vLLM framework, an advanced\nhigh-throughput inference engine specially developed for LLMs, and equipped it\nwith an efficient W4A16 CUDA kernels, so that vLLM can seamlessly support\nSmoothQuant+ 4-bit weight quantization. Our results show that, with\nSmoothQuant+, the Code Llama-34B model can be quantized and deployed on a A100\n40GB GPU, achieving lossless accuracy and a throughput increase of 1.9 to 4.0\ntimes compared to the FP16 model deployed on two A100 40GB GPUs. Moreover, the\nlatency per token is only 68% of the FP16 model deployed on two A100 40GB GPUs.\nThis is the state-of-the-art 4-bit weight quantization for LLMs as we know.",
            "author": [
                "Jiayi Pan",
                "Chengcan Wang",
                "Kaifu Zheng",
                "Yangguang Li",
                "Zhenyu Wang",
                "Bin Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03788v1",
                "http://arxiv.org/pdf/2312.03788v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03786v1",
            "title": "Large Exomoons unlikely around Kepler-1625 b and Kepler-1708 b",
            "updated": "2023-12-06T11:04:47Z",
            "published": "2023-12-06T11:04:47Z",
            "summary": "There are more than 200 moons in our Solar System, but their relatively small\nradii make similarly sized extrasolar moons very hard to detect with current\ninstruments. The best exomoon candidates so far are two nearly Neptune-sized\nbodies orbiting the Jupiter-sized transiting exoplanets Kepler-1625 b and\nKepler-1708 b, but their existence has been contested. Here we reanalyse the\nHubble and Kepler data used to identify the two exomoon candidates employing\nnested sampling and Bayesian inference techniques coupled with a fully\nautomated photodynamical transit model. We find that the evidence for the\nKepler-1625 b exomoon candidate comes almost entirely from the shallowness of\none transit observed with Hubble. We interpret this as a fitting artifact in\nwhich a moon transit is used to compensate for the unconstrained stellar limb\ndarkening. We also find much lower statistical evidence for the exomoon\ncandidate around Kepler-1708 b than previously reported. We suggest that visual\nevidence of the claimed exomoon transits is corrupted by stellar activity in\nthe Kepler light curve. Our injection-retrieval experiments of simulated\ntransits in the original Kepler data reveal false positive rates of 10.9% and\n1.6% for Kepler-1625 b and Kepler-1708 b, respectively. Moreover, genuine\ntransit signals of large exomoons would tend to exhibit much higher Bayesian\nevidence than these two claims. We conclude that neither Kepler-1625 b nor\nKepler-1708 b are likely to be orbited by a large exomoon.",
            "author": [
                "Ren\u00e9 Heller",
                "Michael Hippke"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41550-023-02148-w",
                "http://arxiv.org/abs/2312.03786v1",
                "http://arxiv.org/pdf/2312.03786v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03414v1",
            "title": "Compressed Context Memory For Online Language Model Interaction",
            "updated": "2023-12-06T10:50:43Z",
            "published": "2023-12-06T10:50:43Z",
            "summary": "This paper presents a novel context compression method for Transformer\nlanguage models in online scenarios such as ChatGPT, where the context\ncontinually expands. As the context lengthens, the attention process requires\nmore memory and computational resources, which in turn reduces the throughput\nof the language model. To this end, we propose a compressed context memory\nsystem that continually compresses the growing context into a compact memory\nspace. The compression process simply involves integrating a lightweight\nconditional LoRA into the language model's forward pass during inference. Based\non the compressed context memory, the language model can perform inference with\nreduced memory and attention operations. Through evaluations on conversation,\npersonalization, and multi-task learning, we demonstrate that our approach\nachieves the performance level of a full context model with $5\\times$ smaller\ncontext memory space. Codes are available at\nhttps://github.com/snu-mllab/context-memory.",
            "author": [
                "Jang-Hyun Kim",
                "Junyoung Yeom",
                "Sangdoo Yun",
                "Hyun Oh Song"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03414v1",
                "http://arxiv.org/pdf/2312.03414v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03410v1",
            "title": "Detecting Voice Cloning Attacks via Timbre Watermarking",
            "updated": "2023-12-06T10:48:36Z",
            "published": "2023-12-06T10:48:36Z",
            "summary": "Nowadays, it is common to release audio content to the public. However, with\nthe rise of voice cloning technology, attackers have the potential to easily\nimpersonate a specific person by utilizing his publicly released audio without\nany permission. Therefore, it becomes significant to detect any potential\nmisuse of the released audio content and protect its timbre from being\nimpersonated. To this end, we introduce a novel concept, \"Timbre Watermarking\",\nwhich embeds watermark information into the target individual's speech,\neventually defeating the voice cloning attacks. To ensure the watermark is\nrobust to the voice cloning model's learning process, we design an end-to-end\nvoice cloning-resistant detection framework. The core idea of our solution is\nto embed and extract the watermark in the frequency domain in a temporally\ninvariant manner. To acquire generalization across different voice cloning\nattacks, we modulate their shared process and integrate it into our framework\nas a distortion layer. Experiments demonstrate that the proposed timbre\nwatermarking can defend against different voice cloning attacks, exhibit strong\nresistance against various adaptive attacks (e.g., reconstruction-based removal\nattacks, watermark overwriting attacks), and achieve practicality in real-world\nservices such as PaddleSpeech, Voice-Cloning-App, and so-vits-svc. In addition,\nablation studies are also conducted to verify the effectiveness of our design.\nSome audio samples are available at\nhttps://timbrewatermarking.github.io/samples.",
            "author": [
                "Chang Liu",
                "Jie Zhang",
                "Tianwei Zhang",
                "Xi Yang",
                "Weiming Zhang",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03410v1",
                "http://arxiv.org/pdf/2312.03410v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03409v1",
            "title": "DeepPyramid+: Medical Image Segmentation using Pyramid View Fusion and\n  Deformable Pyramid Reception",
            "updated": "2023-12-06T10:47:11Z",
            "published": "2023-12-06T10:47:11Z",
            "summary": "Semantic Segmentation plays a pivotal role in many applications related to\nmedical image and video analysis. However, designing a neural network\narchitecture for medical image and surgical video segmentation is challenging\ndue to the diverse features of relevant classes, including heterogeneity,\ndeformability, transparency, blunt boundaries, and various distortions. We\npropose a network architecture, DeepPyramid+, which addresses diverse\nchallenges encountered in medical image and surgical video segmentation. The\nproposed DeepPyramid+ incorporates two major modules, namely \"Pyramid View\nFusion\" (PVF) and \"Deformable Pyramid Reception,\" (DPR), to address the\noutlined challenges. PVF replicates a deduction process within the neural\nnetwork, aligning with the human visual system, thereby enhancing the\nrepresentation of relative information at each pixel position. Complementarily,\nDPR introduces shape- and scale-adaptive feature extraction techniques using\ndilated deformable convolutions, enhancing accuracy and robustness in handling\nheterogeneous classes and deformable shapes. Extensive experiments conducted on\ndiverse datasets, including endometriosis videos, MRI images, OCT scans, and\ncataract and laparoscopy videos, demonstrate the effectiveness of DeepPyramid+\nin handling various challenges such as shape and scale variation, reflection,\nand blur degradation. DeepPyramid+ demonstrates significant improvements in\nsegmentation performance, achieving up to a 3.65% increase in Dice coefficient\nfor intra-domain segmentation and up to a 17% increase in Dice coefficient for\ncross-domain segmentation. DeepPyramid+ consistently outperforms\nstate-of-the-art networks across diverse modalities considering different\nbackbone networks, showcasing its versatility.",
            "author": [
                "Negin Ghamsarian",
                "Sebastian Wolf",
                "Martin Zinkernagel",
                "Klaus Schoeffmann",
                "Raphael Sznitman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03409v1",
                "http://arxiv.org/pdf/2312.03409v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03402v1",
            "title": "Multiple wave packets running in the photon number-space",
            "updated": "2023-12-06T10:28:03Z",
            "published": "2023-12-06T10:28:03Z",
            "summary": "If a two-level system coupled to a single-mode cavity is strongly driven by\nan external laser, instead of a continuous accumulation of photons in the\ncavity, oscillations in the mean photon number occur. These oscillations\ncorrespond to peaks of finite width running up and down in the photon number\ndistribution, reminiscent of wave packets in linear chain models. A single wave\npacket is found if the cavity is resonant to the external laser. Here, we show\nthat for finite detuning multiple packet structures can exist simultaneously,\noscillating at different frequencies and amplitudes. We further study the\ninfluence of dissipative effects resulting in the formation of a stationary\nstate, which depending on the parameters can be characterized by a bimodal\nphoton number distribution. While we give analytical limits for the maximally\nachievable photon number in the absence of any dissipation, surprisingly,\ndephasing processes can push the photon occupations towards higher photon\nnumbers.",
            "author": [
                "Luca Nimmesgern",
                "Moritz Cygorek",
                "Adam Mielnik-Pyszczorski",
                "Doris E. Reiter",
                "Alexei Vagov",
                "Vollrath Martin Axt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03402v1",
                "http://arxiv.org/pdf/2312.03402v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03401v1",
            "title": "Predicting Postoperative Intraocular Lens Dislocation in Cataract\n  Surgery via Deep Learning",
            "updated": "2023-12-06T10:27:15Z",
            "published": "2023-12-06T10:27:15Z",
            "summary": "A critical yet unpredictable complication following cataract surgery is\nintraocular lens dislocation. Postoperative stability is imperative, as even a\ntiny decentration of multifocal lenses or inadequate alignment of the torus in\ntoric lenses due to postoperative rotation can lead to a significant drop in\nvisual acuity. Investigating possible intraoperative indicators that can\npredict post-surgical instabilities of intraocular lenses can help prevent this\ncomplication. In this paper, we develop and evaluate the first fully-automatic\nframework for the computation of lens unfolding delay, rotation, and\ninstability during surgery. Adopting a combination of three types of CNNs,\nnamely recurrent, region-based, and pixel-based, the proposed framework is\nemployed to assess the possibility of predicting post-operative lens\ndislocation during cataract surgery. This is achieved via performing a\nlarge-scale study on the statistical differences between the behavior of\ndifferent brands of intraocular lenses and aligning the results with expert\nsurgeons' hypotheses and observations about the lenses. We exploit a\nlarge-scale dataset of cataract surgery videos featuring four intraocular lens\nbrands. Experimental results confirm the reliability of the proposed framework\nin evaluating the lens' statistics during the surgery. The Pearson correlation\nand t-test results reveal significant correlations between lens unfolding delay\nand lens rotation and significant differences between the intra-operative\nrotations stability of four groups of lenses. These results suggest that the\nproposed framework can help surgeons select the lenses based on the patient's\neye conditions and predict post-surgical lens dislocation.",
            "author": [
                "Negin Ghamsarian",
                "Doris Putzgruber-Adamitsch",
                "Stephanie Sarny",
                "Raphael Sznitman",
                "Klaus Schoeffmann",
                "Yosuf El-Shabrawi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03401v1",
                "http://arxiv.org/pdf/2312.03401v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03396v1",
            "title": "High-speed impulsive stimulated Brillouin microscopy",
            "updated": "2023-12-06T10:09:52Z",
            "published": "2023-12-06T10:09:52Z",
            "summary": "Brillouin microscopy, which maps elastic modulus from the frequency shift of\nscattered light, has evolved to a faster speed for the investigation of rapid\nbiomechanical changes. Impulsive stimulated Brillouin scattering (ISBS)\nspectroscopy has the potential to speed up measurement through the resonant\namplification interaction from pulsed excitation and time-domain continuous\ndetection. However, significant progress has not been achieved due to the\nlimitation in signal-to-noise ratio (SNR) and the corresponding need for\nexcessive averaging to maintain high spectral precision. Moreover, the limited\nspatial resolution also hinders its application in mechanical imaging. Here, by\nscrutinizing the SNR model, we design a high-speed ISBS microscope through\nmulti-parameter optimization including phase, reference power, and acquisition\ntime. Leveraging this, with the further assistance of the Matrix Pencil method\nfor data processing, three-dimensional mechanical images are mapped under\nmultiple contrast mechanisms for a millimeter-scale polydimethylsiloxane\npattern immersed in methanol, enabling the identification of these two\ntransparent materials without any contact or labeling. Our experimental results\ndemonstrate the capability to maintain high spectral precision and resolution\nat a sub-millisecond integration time for one pixel. With a two-order\nimprovement in the speed and a tenfold improvement in the spatial resolution\nover the state-of-the-art systems, this method makes it possible for ISBS\nmicroscopes to sensitively investigate rapid mechanical changes in time and\nspace.",
            "author": [
                "Jiarui Li",
                "Taoran Le",
                "Hongyuan Zhang",
                "Haoyun Wei",
                "Yan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03396v1",
                "http://arxiv.org/pdf/2312.03396v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03395v1",
            "title": "Diffused Task-Agnostic Milestone Planner",
            "updated": "2023-12-06T10:09:22Z",
            "published": "2023-12-06T10:09:22Z",
            "summary": "Addressing decision-making problems using sequence modeling to predict future\ntrajectories shows promising results in recent years. In this paper, we take a\nstep further to leverage the sequence predictive method in wider areas such as\nlong-term planning, vision-based control, and multi-task decision-making. To\nthis end, we propose a method to utilize a diffusion-based generative sequence\nmodel to plan a series of milestones in a latent space and to have an agent to\nfollow the milestones to accomplish a given task. The proposed method can learn\ncontrol-relevant, low-dimensional latent representations of milestones, which\nmakes it possible to efficiently perform long-term planning and vision-based\ncontrol. Furthermore, our approach exploits generation flexibility of the\ndiffusion model, which makes it possible to plan diverse trajectories for\nmulti-task decision-making. We demonstrate the proposed method across offline\nreinforcement learning (RL) benchmarks and an visual manipulation environment.\nThe results show that our approach outperforms offline RL methods in solving\nlong-horizon, sparse-reward tasks and multi-task problems, while also achieving\nthe state-of-the-art performance on the most challenging vision-based\nmanipulation benchmark.",
            "author": [
                "Mineui Hong",
                "Minjae Kang",
                "Songhwai Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03395v1",
                "http://arxiv.org/pdf/2312.03395v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03386v1",
            "title": "An Infinite-Width Analysis on the Jacobian-Regularised Training of a\n  Neural Network",
            "updated": "2023-12-06T09:52:18Z",
            "published": "2023-12-06T09:52:18Z",
            "summary": "The recent theoretical analysis of deep neural networks in their\ninfinite-width limits has deepened our understanding of initialisation, feature\nlearning, and training of those networks, and brought new practical techniques\nfor finding appropriate hyperparameters, learning network weights, and\nperforming inference. In this paper, we broaden this line of research by\nshowing that this infinite-width analysis can be extended to the Jacobian of a\ndeep neural network. We show that a multilayer perceptron (MLP) and its\nJacobian at initialisation jointly converge to a Gaussian process (GP) as the\nwidths of the MLP's hidden layers go to infinity and characterise this GP. We\nalso prove that in the infinite-width limit, the evolution of the MLP under the\nso-called robust training (i.e., training with a regulariser on the Jacobian)\nis described by a linear first-order ordinary differential equation that is\ndetermined by a variant of the Neural Tangent Kernel. We experimentally show\nthe relevance of our theoretical claims to wide finite networks, and\nempirically analyse the properties of kernel regression solution to obtain an\ninsight into Jacobian regularisation.",
            "author": [
                "Taeyoung Kim",
                "Hongseok Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03386v1",
                "http://arxiv.org/pdf/2312.03386v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03381v1",
            "title": "Geocoronal Solar Wind Charge Exchange Process Associated with the\n  2006-December-13 Coronal Mass Ejection Event",
            "updated": "2023-12-06T09:42:41Z",
            "published": "2023-12-06T09:42:41Z",
            "summary": "We report the discovery of a geocoronal solar wind charge exchange (SWCX)\nevent corresponding to the well-known 2006 December 13th coronal mass ejection\n(CME) event. Strong evidence for the charge exchange origin of this transient\ndiffuse emission is provided by prominent non-thermal emission lines at\nenergies of $\\rm O^{7+}$, $\\rm Ne^{9+}$, $\\rm Mg^{11+}$, $\\rm Si^{12+}$, $\\rm\nSi^{13+}$. Especially, a 0.53 keV emission line that most likely arises from\nthe $\\rm N^{5+}$ $1s^1 5p^1 \\to 1s^2$ transition is detected. Previously, the\nforecastability of SWCX occurrence with proton flares has been disputed. In\nthis particular event, we found that the SWCX signal coincided with the arrival\nof the magnetic cloud inside CME, triggered with a time delay after the proton\nflux fluctuation as the CME shock front passed through the Earth. Moreover, a\nspacecraft orbital modulation in SWCX light curve suggests that the emission\narises close to the Earth. The line of sight was found to always pass through\nthe northern magnetospheric cusp. The SWCX intensity was high when the line of\nsight passed the dusk side of the cusp, suggesting an azimuthal anisotropy in\nthe flow of solar-wind ions inside the cusp. An axisymmetric SWCX emission\nmodel is found to underestimate the observed peak intensity by a factor of\nabout 50. We suggest this discrepancy is related to the azimuthal anisotropy of\nthe solar-wind flow in the cusp.",
            "author": [
                "Yu Zhou",
                "Noriko Y. Yamasaki",
                "Shin Toriumi",
                "Kazuhisa Mitsuda"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03381v1",
                "http://arxiv.org/pdf/2312.03381v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP",
                "astro-ph.HE",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03380v1",
            "title": "Balade newtonienne entre analyse et arithm\u00e9tique (Newtonian promenade\n  between analysis and arithmetic)",
            "updated": "2023-12-06T09:41:57Z",
            "published": "2023-12-06T09:41:57Z",
            "summary": "Invented by Kurt Hensel at the very end of 19th century on the model of power\nseries in one indeterminate, the $p$-adic numbers have not only become an\nindispensable tool of contemporary arithmetic, but a research topic per se. In\nthis text, stemming out two talks at the 2023 X-UPS lectures, I shall explain\ntheir construction, how they fit in a vaster framework, between analysis and\narithmetic, where two constructions bearing the name of Isaac Newton play a\ncentral role : Newton's method and Newton's polygon.\n  Invent\\'es par Kurt Hensel \\`a la toute fin du 19e si\\`ecle sur le mod\\`ele\ndes s\\'eries formelles en une ind\\'etermin\\'ee, les nombres $p$-adiques sont\ndevenus non seulement un outil indispensable de l'arithm\\'etique contemporaine,\nmais un sujet d'\\'etude en soi. Dans ce texte, issu de deux expos\\'es aux\njourn\\'ees X-UPS 2023, j'expliquerai leur construction, comment ils\ns'ins\\`erent dans un cadre plus vaste, entre analyse et arithm\\'etique, o\\`u\ndeux constructions portant le nom d'Isaac Newton jouent un r\\^ole central: la\nm\\'ethode de Newton et la notion de polygone de Newton.",
            "author": [
                "Antoine Chambert-Loir"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03380v1",
                "http://arxiv.org/pdf/2312.03380v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "math.NT",
                "12J05, 12-02"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03379v1",
            "title": "A Text-to-Text Model for Multilingual Offensive Language Identification",
            "updated": "2023-12-06T09:37:27Z",
            "published": "2023-12-06T09:37:27Z",
            "summary": "The ubiquity of offensive content on social media is a growing cause for\nconcern among companies and government organizations. Recently,\ntransformer-based models such as BERT, XLNET, and XLM-R have achieved\nstate-of-the-art performance in detecting various forms of offensive content\n(e.g. hate speech, cyberbullying, and cyberaggression). However, the majority\nof these models are limited in their capabilities due to their encoder-only\narchitecture, which restricts the number and types of labels in downstream\ntasks. Addressing these limitations, this study presents the first pre-trained\nmodel with encoder-decoder architecture for offensive language identification\nwith text-to-text transformers (T5) trained on two large offensive language\nidentification datasets; SOLID and CCTK. We investigate the effectiveness of\ncombining two datasets and selecting an optimal threshold in semi-supervised\ninstances in SOLID in the T5 retraining step. Our pre-trained T5 model\noutperforms other transformer-based models fine-tuned for offensive language\ndetection, such as fBERT and HateBERT, in multiple English benchmarks.\nFollowing a similar approach, we also train the first multilingual pre-trained\nmodel for offensive language identification using mT5 and evaluate its\nperformance on a set of six different languages (German, Hindi, Korean,\nMarathi, Sinhala, and Spanish). The results demonstrate that this multilingual\nmodel achieves a new state-of-the-art on all the above datasets, showing its\nusefulness in multilingual scenarios. Our proposed T5-based models will be made\nfreely available to the community.",
            "author": [
                "Tharindu Ranasinghe",
                "Marcos Zampieri"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03379v1",
                "http://arxiv.org/pdf/2312.03379v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03374v1",
            "title": "Implementing Digital Twin in Field-Deployed Optical Networks: Uncertain\n  Factors, Operational Guidance, and Field-Trial Demonstration",
            "updated": "2023-12-06T09:21:48Z",
            "published": "2023-12-06T09:21:48Z",
            "summary": "Digital twin has revolutionized optical communication networks by enabling\ntheir full life-cycle management, including design, troubleshooting,\noptimization, upgrade, and prediction. While extensive literature exists on\nframeworks, standards, and applications of digital twin, there is a pressing\nneed in implementing digital twin in field-deployed optical networks operating\nin real-world environments, as opposed to controlled laboratory settings. This\npaper addresses this challenge by examining the uncertain factors behind the\ninaccuracy of digital twin in field-deployed optical networks from three main\nchallenges and proposing operational guidance for implementing accurate digital\ntwin in field-deployed optical networks. Through the proposed guidance, we\ndemonstrate the effective implementation of digital twin in a field-trial\nC+L-band optical transmission link, showcasing its capabilities in performance\nrecovery in a fiber cut scenario.",
            "author": [
                "Yuchen Song",
                "Min Zhang",
                "Yao Zhang",
                "Yan Shi",
                "Shikui Shen",
                "Bingli Guo",
                "Shanguo Huang",
                "Danshi Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MNET.2023.3332893",
                "http://arxiv.org/abs/2312.03374v1",
                "http://arxiv.org/pdf/2312.03374v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03371v1",
            "title": "Understanding Concepts in Graph Signal Processing for Neurophysiological\n  Signal Analysis",
            "updated": "2023-12-06T09:12:29Z",
            "published": "2023-12-06T09:12:29Z",
            "summary": "Multivariate signals, which are measured simultaneously over time and\nacquired by sensor networks, are becoming increasingly common. The emerging\nfield of graph signal processing (GSP) promises to analyse spectral\ncharacteristics of these multivariate signals, while at the same time taking\nthe spatial structure between the time signals into account. A central idea in\nGSP is the graph Fourier transform, which projects a multivariate signal onto\nfrequency-ordered graph Fourier modes, and can therefore be regarded as a\nspatial analog of the temporal Fourier transform. This chapter derives and\ndiscusses key concepts in GSP, with a specific focus on how the various\nconcepts relate to one another. The experimental section focuses on the role of\ngraph frequency in data classification, with applications to neuroimaging. To\naddress the limited sample size of neurophysiological datasets, we introduce a\nminimalist simulation framework that can generate arbitrary amounts of data.\nUsing this artificial data, we find that lower graph frequency signals are less\nsuitable for classifying neurophysiological data as compared to higher graph\nfrequency signals. Finally, we introduce a baseline testing framework for GSP.\nEmploying this framework, our results suggest that GSP applications may\nattenuate spectral characteristics in the signals, highlighting current\nlimitations of GSP for neuroimaging.",
            "author": [
                "Stephan Goerttler",
                "Fei He",
                "Min Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03371v1",
                "http://arxiv.org/pdf/2312.03371v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03370v1",
            "title": "Minimal slopes and bubbling for complex Hessian equations",
            "updated": "2023-12-06T09:11:36Z",
            "published": "2023-12-06T09:11:36Z",
            "summary": "The existence of smooth solutions to a broad class of complex Hessian\nequations is related to nonlinear Nakai type criteria on intersection numbers\non Kahler manifolds. Such a Nakai criteria can be interpreted as a slope\nstability condition analogous to the slope stability for Hermitian vector\nbundles over Kahler manifolds. In the present work, we initiate a program to\nfind canonical solutions to such equations in the unstable case when the Nakai\ncriteria fails. Conjecturally such solutions should arise as limits of natural\nparabolic flows and should be minimisers of the corresponding moment-map energy\nfunctionals. We implement our approach for the J-equation and the deformed\nHermitian Yang-Mills equation on surfaces and some examples with symmetry. We\nprove that there always exist unique canonical solutions to these two equations\non Kahler surfaces in the unstable cases. Such canonical solutions with\nsingularities are also shown to be the limits of the corresponding J-flow and\nthe cotangent flow on certain projective bundles. We further present the\nbubbling phenomena for the J-equation by constructing minimizing sequences of\nthe moment-map energy functionals, whose Gromov-Hausdorff limits are singular\nalgebraic spaces.",
            "author": [
                "Ved Datar",
                "Ramesh Mete",
                "Jian Song"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03370v1",
                "http://arxiv.org/pdf/2312.03370v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03369v1",
            "title": "Analysis of Linux-PRNG (Pseudo Random Number Generator)",
            "updated": "2023-12-06T09:10:25Z",
            "published": "2023-12-06T09:10:25Z",
            "summary": "The Linux pseudorandom number generator (PRNG) is a PRNG with entropy inputs\nand is widely used in many security-related applications and protocols. This\nPRNG is written as an open-source code which is subject to regular changes. It\nhas been analysed in the works of Gutterman et al., Lacharme et al., while in\nthe meantime, several changes have been applied to the code, to counter the\nattacks presented since then. Our work describes the Linux PRNG of kernel\nversions 5.3 and upwards. We discuss the PRNG architecture briefly and in\ndetail about the entropy mixing function.\n  Our goal is to study the entropy mixing function and analyse it over two\nproperties, namely, injectivity and length of the longest chain. For this\npurpose, we will be using SAT solving and model counting over targetted\nformulas involving multiple states of the Linux entropy store.",
            "author": [
                "Ayush Bansal",
                "Pramod Subramanyan",
                "Satyadev Nandakumar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03369v1",
                "http://arxiv.org/pdf/2312.03369v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03368v1",
            "title": "Bottom-Up Instance Segmentation of Catheters for Chest X-Rays",
            "updated": "2023-12-06T09:09:27Z",
            "published": "2023-12-06T09:09:27Z",
            "summary": "Chest X-ray (CXR) is frequently employed in emergency departments and\nintensive care units to verify the proper placement of central lines and tubes\nand to rule out related complications. The automation of the X-ray reading\nprocess can be a valuable support tool for non-specialist technicians and\nminimize reporting delays due to non-availability of experts. While existing\nsolutions for automated catheter segmentation and malposition detection show\npromising results, the disentanglement of individual catheters remains an open\nchallenge, especially in complex cases where multiple devices appear\nsuperimposed in the X-ray projection. Moreover, conventional top-down instance\nsegmentation methods are ineffective on such thin and long devices, that often\nextend through the entire image. In this paper, we propose a deep learning\napproach based on associative embeddings for catheter instance segmentation,\nable to overcome those limitations and effectively handle device intersections.",
            "author": [
                "Francesca Boccardi",
                "Axel Saalbach",
                "Heinrich Schulz",
                "Samuele Salti",
                "Ilyas Sirazitdinov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03368v1",
                "http://arxiv.org/pdf/2312.03368v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03367v1",
            "title": "Lazy-k: Decoding for Constrained Token Classification",
            "updated": "2023-12-06T09:08:32Z",
            "published": "2023-12-06T09:08:32Z",
            "summary": "We explore the possibility of improving probabilistic models in structured\nprediction. Specifically, we combine the models with constrained decoding\napproaches in the context of token classification for information extraction.\nThe decoding methods search for constraint-satisfying label-assignments while\nmaximizing the total probability. To do this, we evaluate several existing\napproaches, as well as propose a novel decoding method called Lazy-$k$. Our\nfindings demonstrate that constrained decoding approaches can significantly\nimprove the models' performances, especially when using smaller models. The\nLazy-$k$ approach allows for more flexibility between decoding time and\naccuracy. The code for using Lazy-$k$ decoding can be found here:\nhttps://github.com/ArthurDevNL/lazyk.",
            "author": [
                "Arthur Hemmer",
                "Micka\u00ebl Coustaty",
                "Nicola Bartolo",
                "J\u00e9r\u00f4me Brachat",
                "Jean-Marc Ogier"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03367v1",
                "http://arxiv.org/pdf/2312.03367v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03365v1",
            "title": "Demand response for residential building heating: Effective Monte Carlo\n  Tree Search control based on physics-informed neural networks",
            "updated": "2023-12-06T09:06:14Z",
            "published": "2023-12-06T09:06:14Z",
            "summary": "Controlling energy consumption in buildings through demand response (DR) has\nbecome increasingly important to reduce global carbon emissions and limit\nclimate change. In this paper, we specifically focus on controlling the heating\nsystem of a residential building to optimize its energy consumption while\nrespecting user's thermal comfort. Recent works in this area have mainly\nfocused on either model-based control, e.g., model predictive control (MPC), or\nmodel-free reinforcement learning (RL) to implement practical DR algorithms. A\nspecific RL method that recently has achieved impressive success in domains\nsuch as board games (go, chess) is Monte Carlo Tree Search (MCTS). Yet, for\nbuilding control it has remained largely unexplored. Thus, we study MCTS\nspecifically for building demand response. Its natural structure allows a\nflexible optimization that implicitly integrate exogenous constraints (as\nopposed, for example, to conventional RL solutions), making MCTS a promising\ncandidate for DR control problems. We demonstrate how to improve MCTS control\nperformance by incorporating a Physics-informed Neural Network (PiNN) model for\nits underlying thermal state prediction, as opposed to traditional purely\ndata-driven Black-Box approaches. Our MCTS implementation aligned with a PiNN\nmodel is able to obtain a 3% increment of the obtained reward compared to a\nrule-based controller; leading to a 10% cost reduction and 35% reduction on\ntemperature difference with the desired one when applied to an artificial price\nprofile. We further implemented a Deep Learning layer into the Monte Carlo Tree\nSearch technique using a neural network that leads the tree search through more\noptimal nodes. We then compared this addition with its Vanilla version, showing\nthe improvement in computational cost required.",
            "author": [
                "Fabio Pavirani",
                "Gargya Gokhale",
                "Bert Claessens",
                "Chris Develder"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03365v1",
                "http://arxiv.org/pdf/2312.03365v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03361v1",
            "title": "KhabarChin: Automatic Detection of Important News in the Persian\n  Language",
            "updated": "2023-12-06T09:01:21Z",
            "published": "2023-12-06T09:01:21Z",
            "summary": "Being aware of important news is crucial for staying informed and making\nwell-informed decisions efficiently. Natural Language Processing (NLP)\napproaches can significantly automate this process. This paper introduces the\ndetection of important news, in a previously unexplored area, and presents a\nnew benchmarking dataset (Khabarchin) for detecting important news in the\nPersian language. We define important news articles as those deemed significant\nfor a considerable portion of society, capable of influencing their mindset or\ndecision-making. The news articles are obtained from seven different prominent\nPersian news agencies, resulting in the annotation of 7,869 samples and the\ncreation of the dataset. Two challenges of high disagreement and imbalance\nbetween classes were faced, and solutions were provided for them. We also\npropose several learning-based models, ranging from conventional machine\nlearning to state-of-the-art transformer models, to tackle this task.\nFurthermore, we introduce the second task of important sentence detection in\nnews articles, as they often come with a significant contextual length that\nmakes it challenging for readers to identify important information. We identify\nthese sentences in a weakly supervised manner.",
            "author": [
                "Hamed Hematian Hemati",
                "Arash Lagzian",
                "Moein Salimi Sartakhti",
                "Hamid Beigy",
                "Ehsaneddin Asgari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03361v1",
                "http://arxiv.org/pdf/2312.03361v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03360v1",
            "title": "Teaching Specific Scientific Knowledge into Large Language Models\n  through Additional Training",
            "updated": "2023-12-06T08:55:55Z",
            "published": "2023-12-06T08:55:55Z",
            "summary": "Through additional training, we explore embedding specialized scientific\nknowledge into the Llama 2 Large Language Model (LLM). Key findings reveal that\neffective knowledge integration requires reading texts from multiple\nperspectives, especially in instructional formats. We utilize text augmentation\nto tackle the scarcity of specialized texts, including style conversions and\ntranslations. Hyperparameter optimization proves crucial, with different size\nmodels (7b, 13b, and 70b) reasonably undergoing additional training. Validating\nour methods, we construct a dataset of 65,000 scientific papers. Although we\nhave succeeded in partially embedding knowledge, the study highlights the\ncomplexities and limitations of incorporating specialized information into\nLLMs, suggesting areas for further improvement.",
            "author": [
                "Kan Hatakeyama-Sato",
                "Yasuhiko Igarashi",
                "Shun Katakami",
                "Yuta Nabae",
                "Teruaki Hayakawa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03360v1",
                "http://arxiv.org/pdf/2312.03360v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03358v1",
            "title": "On Geometries and Monodromies for Branes of Codimension Two",
            "updated": "2023-12-06T08:54:34Z",
            "published": "2023-12-06T08:54:34Z",
            "summary": "We study geometries for the NS5-, the KK5- and the $5^2_2$-branes of\ncodimension two in type II and heterotic string theories. The geometries are\nclassified by monodromies that each brane has. They are the $B$-, the general\ncoordinate and the $\\beta$-transformations of the spacetime metric, the\n$B$-field and the dilaton (and the gauge fields). We show that the monodromy\nnature appears also in the geometric quantities such as the curvature and the\ncomplex structures of spacetime. They are linearly realized in the doubled\n(generalized) structures in the doubled space.",
            "author": [
                "Tetsuji Kimura",
                "Shin Sasaki",
                "Kenta Shiozawa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03358v1",
                "http://arxiv.org/pdf/2312.03358v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03357v1",
            "title": "RING-NeRF: A Versatile Architecture based on Residual Implicit Neural\n  Grids",
            "updated": "2023-12-06T08:54:04Z",
            "published": "2023-12-06T08:54:04Z",
            "summary": "Since their introduction, Neural Fields have become very popular for 3D\nreconstruction and new view synthesis. Recent researches focused on\naccelerating the process, as well as improving the robustness to variation of\nthe observation distance and limited number of supervised viewpoints. However,\nthose approaches often led to dedicated solutions that cannot be easily\ncombined. To tackle this issue, we introduce a new simple but efficient\narchitecture named RING-NeRF, based on Residual Implicit Neural Grids, that\nprovides a control on the level of detail of the mapping function between the\nscene and the latent spaces. Associated with a distance-aware forward mapping\nmechanism and a continuous coarse-to-fine reconstruction process, our versatile\narchitecture demonstrates both fast training and state-of-the-art performances\nin terms of: (1) anti-aliased rendering, (2) reconstruction quality from few\nsupervised viewpoints, and (3) robustness in the absence of appropriate\nscene-specific initialization for SDF-based NeRFs. We also demonstrate that our\narchitecture can dynamically add grids to increase the details of the\nreconstruction, opening the way to adaptive reconstruction.",
            "author": [
                "Doriand Petit",
                "Steve Bourgeois",
                "Dumitru Pavel",
                "Vincent Gay-Bellile",
                "Florian Chabot",
                "Loic Barthe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03357v1",
                "http://arxiv.org/pdf/2312.03357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03356v1",
            "title": "Bile Duct Segmentation Methods Under 3D Slicer Applied to ERCP:\n  Advantages and Disadvantages",
            "updated": "2023-12-06T08:53:15Z",
            "published": "2023-12-06T08:53:15Z",
            "summary": "This article presents an evaluation of biliary tract segmentation methods\nused for 3D reconstruction, which may be very usefull in various critical\ninterventions, such as endoscopic retrograde cholangiopancreatography (ERCP),\nusing the 3D Slicer software. This article provides an assessment of biliary\ntract segmentation techniques employed for 3D reconstruction, which can prove\nhighly valuable in diverse critical procedures like endoscopic retrograde\ncholangiopancreatography (ERCP) through the utilization of 3D Slicer software.\nThree different methods, namely thresholding, flood filling, and region\ngrowing, were assessed in terms of their advantages and disadvantages. The\nstudy involved 10 patient cases and employed quantitative indices and\nqualitative evaluation to assess the segmentations obtained by the different\nsegmentation methods against ground truth. The results indicate that the\nthresholding method is almost manual and time-consuming, while the flood\nfilling method is semi-automatic and also time-consuming. Although both methods\nimprove segmentation quality, they are not reproducible. Therefore, an\nautomatic method based on region growing was developed to reduce segmentation\ntime, albeit at the expense of quality. These findings highlight the pros and\ncons of different conventional segmentation methods and underscore the need to\nexplore alternative approaches, such as deep learning, to optimize biliary\ntract segmentation in the context of ERCP.",
            "author": [
                "Abdelhadi Essamlali",
                "Vincent Millot-Maysounabe",
                "Marion Chartier",
                "Gr\u00e9goire Salin",
                "Aymeric Becq",
                "Lionel Arriv\u00e9",
                "Marine Duboc Camus",
                "J\u00e9r\u00f4me Szewczyk",
                "Isabelle Claude"
            ],
            "link": [
                "http://dx.doi.org/10.11648/j.ijbecs.20230904.11",
                "http://arxiv.org/abs/2312.03356v1",
                "http://arxiv.org/pdf/2312.03356v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03351v1",
            "title": "On the variants of SVM methods applied to GPR data to classify tack coat\n  characteristics in French pavements: two experimental case studies",
            "updated": "2023-12-06T08:50:01Z",
            "published": "2023-12-06T08:50:01Z",
            "summary": "Among the commonly used non-destructive techniques, the Ground Penetrating\nRadar (GPR) is one of the most widely adopted today for assessing pavement\nconditions in France. However, conventional radar systems and their forward\nprocessing methods have shown their limitations for the physical and\ngeometrical characterization of very thin layers such as tack coats. However,\nthe use of Machine Learning methods applied to GPR with an inverse approach\nshowed that it was numerically possible to identify the tack coat\ncharacteristics despite masking effects due to low timefrequency resolution\nnoted in the raw B-scans. Thus, we propose in this paper to apply the inverse\napproach based on Machine Learning, already validated in previous works on\nnumerical data, on two experimental cases with different pavement structures.\nThe first case corresponds to a validation on known pavement structures on the\nGustave Eiffel University (Nantes, France) with its pavement fatigue carousel\nand the second case focuses on a new real road in Vend{\\'e}e department\n(France). In both case studies, the performances of SVM/SVR methods showed the\nefficiency of supervised learning methods to classify and estimate the emulsion\nproportioning in the tack coats.",
            "author": [
                "Gr\u00e9gory Andreoli",
                "Amine Ihamouten",
                "Mai Lan Nguyen",
                "Yannick Fargier",
                "Cyrille Fauchard",
                "Jean-Michel Simonin",
                "Viktoriia Buliuk",
                "David Souriou",
                "Xavier D\u00e9robert"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IWAGPR57138.2023.10329070",
                "http://arxiv.org/abs/2312.03351v1",
                "http://arxiv.org/pdf/2312.03351v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03349v1",
            "title": "Gravitational Wave as a Probe of Light Feebly Interacting Dark Matter",
            "updated": "2023-12-06T08:46:57Z",
            "published": "2023-12-06T08:46:57Z",
            "summary": "Light feebly interacting dark matter is widely predicted in a plethora of new\nphysics models. However, due to very feeble couplings with the Standard Model\nparticles, its relic density produced via the relativistic thermal freeze-out\nprocess easily exceeds the observed value. The entropy dilution in an early\nmatter-dominated era provides an attractive mechanism for solving such an\noverabundance problem. In this work, we note that this dark matter dilution\nmechanism will lead to two distinctive kinks in the primordial GW spectrum,\nwhose frequencies strongly correlate with the DM mass. We show that the GW\ndetectors, such as Cosmic Explorer (CE) and Big Bang Observer (BBO), can\nmeasure the kinks in the primordial GW spectrum and will offer a new avenue to\nprobe light feebly interacting dark matter.",
            "author": [
                "Yuchao Gu",
                "Liangliang Su",
                "Lei Wu",
                "Yongcheng Wu",
                "Bin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03349v1",
                "http://arxiv.org/pdf/2312.03349v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03342v1",
            "title": "Topic and genre in dialogue",
            "updated": "2023-12-06T08:33:51Z",
            "published": "2023-12-06T08:33:51Z",
            "summary": "In this paper we argue that topic plays a fundamental role in conversations,\nand that the concept is needed in addition to that of genre to define\ninteractions. In particular, the concepts of genre and topic need to be\nseparated and orthogonally defined. This would enable modular, reliable and\ncontrollable flexible-domain dialogue systems.",
            "author": [
                "Amandine Decker",
                "Ellen Breitholtz",
                "Christine Howes",
                "Staffan Larsson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03342v1",
                "http://arxiv.org/pdf/2312.03342v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03339v1",
            "title": "PointJEM: Self-supervised Point Cloud Understanding for Reducing Feature\n  Redundancy via Joint Entropy Maximization",
            "updated": "2023-12-06T08:21:42Z",
            "published": "2023-12-06T08:21:42Z",
            "summary": "Most deep learning-based point cloud processing methods are supervised and\nrequire large scale of labeled data. However, manual labeling of point cloud\ndata is laborious and time-consuming. Self-supervised representation learning\ncan address the aforementioned issue by learning robust and generalized\nrepresentations from unlabeled datasets. Nevertheless, the embedded features\nobtained by representation learning usually contain redundant information, and\nmost current methods reduce feature redundancy by linear correlation\nconstraints. In this paper, we propose PointJEM, a self-supervised\nrepresentation learning method applied to the point cloud field. PointJEM\ncomprises an embedding scheme and a loss function based on joint entropy. The\nembedding scheme divides the embedding vector into different parts, each part\ncan learn a distinctive feature. To reduce redundant information in the\nfeatures, PointJEM maximizes the joint entropy between the different parts,\nthereby rendering the learned feature variables pairwise independent. To\nvalidate the effectiveness of our method, we conducted experiments on multiple\ndatasets. The results demonstrate that our method can significantly reduce\nfeature redundancy beyond linear correlation. Furthermore, PointJEM achieves\ncompetitive performance in downstream tasks such as classification and\nsegmentation.",
            "author": [
                "Xin Cao",
                "Huan Xia",
                "Xinxin Han",
                "Yifan Wang",
                "Kang Li",
                "Linzhi Su"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03339v1",
                "http://arxiv.org/pdf/2312.03339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03338v1",
            "title": "Modeling human activity-related spread of the spotted lanternfly\n  (Lycorma delicatula) in the US",
            "updated": "2023-12-06T08:20:59Z",
            "published": "2023-12-06T08:20:59Z",
            "summary": "The spotted lanternfly (Lycorma delicatula) has recently spread from its\nnative range to several other countries and forecasts predict that it may\nbecome a global invasive pest. In particular, since its confirmed presence in\nthe United States in 2014 it has established itself as a major invasive pest in\nthe Mid-Atlantic region where it is damaging both naturally occurring and\ncommercially important farmed plants. Quarantine zones have been introduced to\ncontain the infestation, but the spread to new areas continues. At present the\npathways and drivers of spread are not well-understood. In particular, several\nhuman activity related factors have been proposed to contribute to the spread;\nhowever, which features of the current spread can be attributed to these\nfactors remains unclear. Here we collect county level data on infestation\nstatus and four human activity related factors and use statistical methods to\ndetermine whether there is evidence for an association between the factors and\ninfestation. Then we construct a mechanistic network model based on the factors\nfound to be associated with infestation and use it to simulate local spread. We\nfind that the model reproduces key features of the spread 2014 to 2021. In\nparticular, the growth of the main infestation region and the opening of spread\ncorridors in the westward and southwestern directions is consistent with data\nand the model accurately forecasts the correct infestation status at the county\nlevel in 2021 with $81\\%$ accuracy. We then use the model to forecast the\nspread up to 2025 in a larger region. Given that this model is based on a few\nhuman activity related factors that can be targeted, it may prove useful in\ninforming management and further modeling efforts related to the current\nspotted lanternfly infestation in the US and potentially for current and future\ninvasions elsewhere globally.",
            "author": [
                "Daniel Str\u00f6mbom",
                "Autumn Sands",
                "Jason M. Graham",
                "Amanda Crocker",
                "Cameron Cloud",
                "Grace Tulevech",
                "Kelly Ward"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03338v1",
                "http://arxiv.org/pdf/2312.03338v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03332v1",
            "title": "Geometry from D-branes in Nonrelativistic String Theory",
            "updated": "2023-12-06T07:58:07Z",
            "published": "2023-12-06T07:58:07Z",
            "summary": "Nonrelativistic (NR) string theory was discovered as a framework that\nunderlies and unifies the various noncommutative open string (NCOS) theories,\nwhich were originally envisioned as surprising exceptions to the maxim that all\nstring theories are gravitational in nature. In that view, the fact that NCOS\nhas a gravitational dual was believed to be directly analogous to the AdS/CFT\ncorrespondence. When NCOS theories were understood to be simply the particular\nclasses of states of the underlying NR theory that include longitudinal\nD-branes, it was suggested that the duality between NCOS and the corresponding\ngravitational theory is not an instance of gauge/gravity-type duality, but of\nopen-string/closed-string duality between D-branes and black branes. The\npresent paper provides direct evidence in support of this perspective, by\nstarting from a stack of D-branes in NR string theory and deriving the\nlong-distance profile of the curved geometry in the corresponding black brane.",
            "author": [
                "Alberto Guijosa",
                "Igmar C. Rosas-L\u00f3pez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03332v1",
                "http://arxiv.org/pdf/2312.03332v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03330v1",
            "title": "Measuring Misogyny in Natural Language Generation: Preliminary Results\n  from a Case Study on two Reddit Communities",
            "updated": "2023-12-06T07:38:46Z",
            "published": "2023-12-06T07:38:46Z",
            "summary": "Generic `toxicity' classifiers continue to be used for evaluating the\npotential for harm in natural language generation, despite mounting evidence of\ntheir shortcomings. We consider the challenge of measuring misogyny in natural\nlanguage generation, and argue that generic `toxicity' classifiers are\ninadequate for this task. We use data from two well-characterised `Incel'\ncommunities on Reddit that differ primarily in their degrees of misogyny to\nconstruct a pair of training corpora which we use to fine-tune two language\nmodels. We show that an open source `toxicity' classifier is unable to\ndistinguish meaningfully between generations from these models. We contrast\nthis with a misogyny-specific lexicon recently proposed by feminist\nsubject-matter experts, demonstrating that, despite the limitations of simple\nlexicon-based approaches, this shows promise as a benchmark to evaluate\nlanguage models for misogyny, and that it is sensitive enough to reveal the\nknown differences in these Reddit communities. Our preliminary findings\nhighlight the limitations of a generic approach to evaluating harms, and\nfurther emphasise the need for careful benchmark design and selection in\nnatural language evaluation.",
            "author": [
                "Aaron J. Snoswell",
                "Lucinda Nelson",
                "Hao Xue",
                "Flora D. Salim",
                "Nicolas Suzor",
                "Jean Burgess"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03330v1",
                "http://arxiv.org/pdf/2312.03330v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03324v1",
            "title": "Lightweight Speaker Verification Using Transformation Module with\n  Feature Partition and Fusion",
            "updated": "2023-12-06T07:25:16Z",
            "published": "2023-12-06T07:25:16Z",
            "summary": "Although many efforts have been made on decreasing the model complexity for\nspeaker verification, it is still challenging to deploy speaker verification\nsystems with satisfactory result on low-resource terminals. We design a\ntransformation module that performs feature partition and fusion to implement\nlightweight speaker verification. The transformation module consists of\nmultiple simple but effective operations, such as convolution, pooling, mean,\nconcatenation, normalization, and element-wise summation. It works in a\nplug-and-play way, and can be easily implanted into a wide variety of models to\nreduce the model complexity while maintaining the model error. First, the input\nfeature is split into several low-dimensional feature subsets for decreasing\nthe model complexity. Then, each feature subset is updated by fusing it with\nthe inter-feature-subsets correlational information to enhance its\nrepresentational capability. Finally, the updated feature subsets are\nindependently fed into the block (one or several layers) of the model for\nfurther processing. The features that are output from current block of the\nmodel are processed according to the steps above before they are fed into the\nnext block of the model. Experimental data are selected from two public speech\ncorpora (namely VoxCeleb1 and VoxCeleb2). Results show that implanting the\ntransformation module into three models (namely AMCRN, ResNet34, and\nECAPA-TDNN) for speaker verification slightly increases the model error and\nsignificantly decreases the model complexity. Our proposed method outperforms\nbaseline methods on the whole in memory requirement and computational\ncomplexity with lower equal error rate. It also generalizes well across\ntruncated segments with various lengths.",
            "author": [
                "Yanxiong Li",
                "Zhongjie Jiang",
                "Qisheng Huang",
                "Wenchang Cao",
                "Jialong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03324v1",
                "http://arxiv.org/pdf/2312.03324v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03323v1",
            "title": "Triggering the magnetopause reconnection by solar wind discontinuities",
            "updated": "2023-12-06T07:17:18Z",
            "published": "2023-12-06T07:17:18Z",
            "summary": "Magnetic reconnection is one of the most universal processes in space plasma\nthat is responsible for charged particle acceleration, mixing and heating of\nplasma populations. In this paper we consider a triggering process of\nreconnection that is driven by interaction of two discontinuities: solar wind\nrotational discontinuity and tangential discontinuity at the Earth's\nmagnetospheric boundary, magnetopause. Combining the multispacecraft\nmeasurements and global hybrid simulations, we show that solar wind\ndiscontinuities may drive the magnetopause reconnection and cause the mixing of\nthe solar wind and magnetosphere plasmas around the magnetopause, well\ndownstream of the solar wind flow. Since large-amplitude discontinuities are\nfrequently observed in the solar wind and predicted for various stellar winds,\nour results of reconnection driven by the discontinuity-discontinuity\ninteraction may have a broad application beyond the magnetosphere.",
            "author": [
                "Alexander Lukin",
                "Zhifang Guo",
                "Yu Lin",
                "Evgeny Panov",
                "Anton Artemyev",
                "Xiaojia Zhang",
                "Anatoli Petrukovich"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03323v1",
                "http://arxiv.org/pdf/2312.03323v1"
            ],
            "primary_category": "physics.space-ph",
            "category": [
                "physics.space-ph",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03322v1",
            "title": "Background Clustering Pre-training for Few-shot Segmentation",
            "updated": "2023-12-06T07:16:32Z",
            "published": "2023-12-06T07:16:32Z",
            "summary": "Recent few-shot segmentation (FSS) methods introduce an extra pre-training\nstage before meta-training to obtain a stronger backbone, which has become a\nstandard step in few-shot learning. Despite the effectiveness, current\npre-training scheme suffers from the merged background problem: only base\nclasses are labelled as foregrounds, making it hard to distinguish between\nnovel classes and actual background. In this paper, we propose a new\npre-training scheme for FSS via decoupling the novel classes from background,\ncalled Background Clustering Pre-Training (BCPT). Specifically, we adopt online\nclustering to the pixel embeddings of merged background to explore the\nunderlying semantic structures, bridging the gap between pre-training and\nadaptation to novel classes. Given the clustering results, we further propose\nthe background mining loss and leverage base classes to guide the clustering\nprocess, improving the quality and stability of clustering results. Experiments\non PASCAL-5i and COCO-20i show that BCPT yields advanced performance. Code will\nbe available.",
            "author": [
                "Zhimiao Yu",
                "Tiancheng Lin",
                "Yi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03322v1",
                "http://arxiv.org/pdf/2312.03322v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03312v1",
            "title": "Optimizing Two-Pass Cross-Lingual Transfer Learning: Phoneme Recognition\n  and Phoneme to Grapheme Translation",
            "updated": "2023-12-06T06:37:24Z",
            "published": "2023-12-06T06:37:24Z",
            "summary": "This research optimizes two-pass cross-lingual transfer learning in\nlow-resource languages by enhancing phoneme recognition and phoneme-to-grapheme\ntranslation models. Our approach optimizes these two stages to improve speech\nrecognition across languages. We optimize phoneme vocabulary coverage by\nmerging phonemes based on shared articulatory characteristics, thus improving\nrecognition accuracy. Additionally, we introduce a global phoneme noise\ngenerator for realistic ASR noise during phoneme-to-grapheme training to reduce\nerror propagation. Experiments on the CommonVoice 12.0 dataset show significant\nreductions in Word Error Rate (WER) for low-resource languages, highlighting\nthe effectiveness of our approach. This research contributes to the\nadvancements of two-pass ASR systems in low-resource languages, offering the\npotential for improved cross-lingual transfer learning.",
            "author": [
                "Wonjun Lee",
                "Gary Geunbae Lee",
                "Yunsu Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03312v1",
                "http://arxiv.org/pdf/2312.03312v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03311v1",
            "title": "On the Nystrom Approximation for Preconditioning in Kernel Machines",
            "updated": "2023-12-06T06:33:25Z",
            "published": "2023-12-06T06:33:25Z",
            "summary": "Kernel methods are a popular class of nonlinear predictive models in machine\nlearning. Scalable algorithms for learning kernel models need to be iterative\nin nature, but convergence can be slow due to poor conditioning. Spectral\npreconditioning is an important tool to speed-up the convergence of such\niterative algorithms for training kernel models. However computing and storing\na spectral preconditioner can be expensive which can lead to large\ncomputational and storage overheads, precluding the application of kernel\nmethods to problems with large datasets. A Nystrom approximation of the\nspectral preconditioner is often cheaper to compute and store, and has\ndemonstrated success in practical applications. In this paper we analyze the\ntrade-offs of using such an approximated preconditioner. Specifically, we show\nthat a sample of logarithmic size (as a function of the size of the dataset)\nenables the Nystrom-based approximated preconditioner to accelerate gradient\ndescent nearly as well as the exact preconditioner, while also reducing the\ncomputational and storage overheads.",
            "author": [
                "Amirhesam Abedsoltan",
                "Mikhail Belkin",
                "Parthe Pandit",
                "Luis Rademacher"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03311v1",
                "http://arxiv.org/pdf/2312.03311v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03307v1",
            "title": "Balanced Marginal and Joint Distributional Learning via Mixture\n  Cramer-Wold Distance",
            "updated": "2023-12-06T06:15:48Z",
            "published": "2023-12-06T06:15:48Z",
            "summary": "In the process of training a generative model, it becomes essential to\nmeasure the discrepancy between two high-dimensional probability distributions:\nthe generative distribution and the ground-truth distribution of the observed\ndataset. Recently, there has been growing interest in an approach that involves\nslicing high-dimensional distributions, with the Cramer-Wold distance emerging\nas a promising method. However, we have identified that the Cramer-Wold\ndistance primarily focuses on joint distributional learning, whereas\nunderstanding marginal distributional patterns is crucial for effective\nsynthetic data generation. In this paper, we introduce a novel measure of\ndissimilarity, the mixture Cramer-Wold distance. This measure enables us to\ncapture both marginal and joint distributional information simultaneously, as\nit incorporates a mixture measure with point masses on standard basis vectors.\nBuilding upon the mixture Cramer-Wold distance, we propose a new generative\nmodel called CWDAE (Cramer-Wold Distributional AutoEncoder), which shows\nremarkable performance in generating synthetic data when applied to real\ntabular datasets. Furthermore, our model offers the flexibility to adjust the\nlevel of data privacy with ease.",
            "author": [
                "Seunghwan An",
                "Sungchul Hong",
                "Jong-June Jeon"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03307v1",
                "http://arxiv.org/pdf/2312.03307v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03303v1",
            "title": "Dyport: Dynamic Importance-based Hypothesis Generation Benchmarking\n  Technique",
            "updated": "2023-12-06T06:07:50Z",
            "published": "2023-12-06T06:07:50Z",
            "summary": "This paper presents a novel benchmarking framework Dyport for evaluating\nbiomedical hypothesis generation systems. Utilizing curated datasets, our\napproach tests these systems under realistic conditions, enhancing the\nrelevance of our evaluations. We integrate knowledge from the curated databases\ninto a dynamic graph, accompanied by a method to quantify discovery importance.\nThis not only assesses hypothesis accuracy but also their potential impact in\nbiomedical research which significantly extends traditional link prediction\nbenchmarks. Applicability of our benchmarking process is demonstrated on\nseveral link prediction systems applied on biomedical semantic knowledge\ngraphs. Being flexible, our benchmarking system is designed for broad\napplication in hypothesis generation quality verification, aiming to expand the\nscope of scientific discovery within the biomedical research community.\nAvailability and implementation: Dyport framework is fully open-source. All\ncode and datasets are available at: https://github.com/IlyaTyagin/Dyport",
            "author": [
                "Ilya Tyagin",
                "Ilya Safro"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03303v1",
                "http://arxiv.org/pdf/2312.03303v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03301v1",
            "title": "Masking Behaviors in Epidemiological Networks with Cognitively-plausible\n  Reinforcement Learning",
            "updated": "2023-12-06T05:57:27Z",
            "published": "2023-12-06T05:57:27Z",
            "summary": "The COVID-19 pandemic highlighted the critical role of human behavior in\ninfluencing infectious disease transmission and the need for models capturing\nthis complex dynamic. We present an agent-based model integrating an\nepidemiological simulation of disease spread with a cognitive architecture\ndriving individual mask-wearing decisions. Agents decide whether to mask based\non a utility function weighting factors like peer conformity, personal risk\ntolerance, and mask-wearing discomfort. By conducting experiments\nsystematically varying behavioral model parameters and social network\nstructures, we demonstrate how adaptive decision-making interacts with network\nconnectivity patterns to impact population-level infection outcomes. The model\nprovides a flexible computational framework for gaining insights into how\nbehavioral interventions like mask mandates may differentially influence\ndisease spread across communities with diverse social structures. Findings\nhighlight the importance of integrating realistic human decision processes in\nepidemiological models to inform policy decisions during public health crises.",
            "author": [
                "Konstantinos Mitsopoulos",
                "Lawrence Baker",
                "Christian Lebiere",
                "Peter Pirolli",
                "Mark Orr",
                "Raffaele Vardavas"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03301v1",
                "http://arxiv.org/pdf/2312.03301v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03299v1",
            "title": "Channel-Transferable Semantic Communications for Multi-User OFDM-NOMA\n  Systems",
            "updated": "2023-12-06T05:54:20Z",
            "published": "2023-12-06T05:54:20Z",
            "summary": "Semantic communications are expected to become the core new paradigms of the\nsixth generation (6G) wireless networks. Most existing works implicitly utilize\nchannel information for codecs training, which leads to poor communications\nwhen channel type or statistical characteristics change. To tackle this issue\nposed by various channels, a novel channel-transferable semantic communications\n(CT-SemCom) framework is proposed, which adapts the codecs learned on one type\nof channel to other types of channels. Furthermore, integrating the proposed\nframework and the orthogonal frequency division multiplexing systems\nintegrating non-orthogonal multiple access technologies, i.e., OFDM-NOMA\nsystems, a power allocation problem to realize the transfer from additive white\nGaussian noise (AWGN) channels to multi-subcarrier Rayleigh fading channels is\nformulated. We then design a semantics-similar dual transformation (SSDT)\nalgorithm to derive analytical solutions with low complexity. Simulation\nresults show that the proposed CT-SemCom framework with SSDT algorithm\nsignificantly outperforms the existing work w.r.t. channel transferability,\ne.g., the peak signal-to-noise ratio (PSNR) of image transmission improves by\n4.2-7.3 dB under different variances of Rayleigh fading channels.",
            "author": [
                "Lan Lin",
                "Wenjun Xu",
                "Fengyu Wang",
                "Yimeng Zhang",
                "Wei Zhang",
                "Ping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03299v1",
                "http://arxiv.org/pdf/2312.03299v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03298v1",
            "title": "DiffPMAE: Diffusion Masked Autoencoders for Point Cloud Reconstruction",
            "updated": "2023-12-06T05:39:00Z",
            "published": "2023-12-06T05:39:00Z",
            "summary": "Point cloud streaming is increasingly getting popular, evolving into the norm\nfor interactive service delivery and the future Metaverse. However, the\nsubstantial volume of data associated with point clouds presents numerous\nchallenges, particularly in terms of high bandwidth consumption and large\nstorage capacity. Despite various solutions proposed thus far, with a focus on\npoint cloud compression, upsampling, and completion, these\nreconstruction-related methods continue to fall short in delivering high\nfidelity point cloud output. As a solution, in DiffPMAE, we propose an\neffective point cloud reconstruction architecture. Inspired by self-supervised\nlearning concepts, we combine Masked Auto-Encoding and Diffusion Model\nmechanism to remotely reconstruct point cloud data. By the nature of this\nreconstruction process, DiffPMAE can be extended to many related downstream\ntasks including point cloud compression, upsampling and completion. Leveraging\nShapeNet-55 and ModelNet datasets with over 60000 objects, we validate the\nperformance of DiffPMAE exceeding many state-of-the-art methods in-terms of\nauto-encoding and downstream tasks considered.",
            "author": [
                "Yanlong Li",
                "Chamara Madarasingha",
                "Kanchana Thilakarathna"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03298v1",
                "http://arxiv.org/pdf/2312.03298v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03293v1",
            "title": "Securing Data Platforms: Strategic Masking Techniques for Privacy and\n  Security for B2B Enterprise Data",
            "updated": "2023-12-06T05:04:37Z",
            "published": "2023-12-06T05:04:37Z",
            "summary": "In today's digital age, the imperative to protect data privacy and security\nis a paramount concern, especially for business-to-business (B2B) enterprises\nthat handle sensitive information. These enterprises are increasingly\nconstructing data platforms, which are integrated suites of technology\nsolutions architected for the efficient management, processing, storage, and\ndata analysis. It has become critical to design these data platforms with\nmechanisms that inherently support data privacy and security, particularly as\nthey encounter the added complexity of safeguarding unstructured data types\nsuch as log files and text documents. Within this context, data masking stands\nout as a vital feature of data platform architecture. It proactively conceals\nsensitive elements, ensuring data privacy while preserving the information's\nvalue for business operations and analytics. This protective measure entails a\nstrategic two-fold process: firstly, accurately pinpointing the sensitive data\nthat necessitates concealment, and secondly, applying sophisticated methods to\ndisguise that data effectively within the data platform infrastructure. This\nresearch delves into the nuances of embedding advanced data masking techniques\nwithin the very fabric of data platforms and an in-depth exploration of how\nenterprises can adopt a comprehensive approach toward effective data masking\nimplementation by exploring different identification and anonymization\ntechniques.",
            "author": [
                "Mandar Khoje"
            ],
            "link": [
                "http://dx.doi.org/10.14445/22312803/IJCTT-V71I11P107",
                "http://arxiv.org/abs/2312.03293v1",
                "http://arxiv.org/pdf/2312.03293v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03290v1",
            "title": "Can language agents be alternatives to PPO? A Preliminary Empirical\n  Study On OpenAI Gym",
            "updated": "2023-12-06T04:48:26Z",
            "published": "2023-12-06T04:48:26Z",
            "summary": "The formidable capacity for zero- or few-shot decision-making in language\nagents encourages us to pose a compelling question: Can language agents be\nalternatives to PPO agents in traditional sequential decision-making tasks? To\ninvestigate this, we first take environments collected in OpenAI Gym as our\ntestbeds and ground them to textual environments that construct the TextGym\nsimulator. This allows for straightforward and efficient comparisons between\nPPO agents and language agents, given the widespread adoption of OpenAI Gym. To\nensure a fair and effective benchmarking, we introduce $5$ levels of scenario\nfor accurate domain-knowledge controlling and a unified RL-inspired framework\nfor language agents. Additionally, we propose an innovative\nexplore-exploit-guided language (EXE) agent to solve tasks within TextGym.\nThrough numerical experiments and ablation studies, we extract valuable\ninsights into the decision-making capabilities of language agents and make a\npreliminary evaluation of their potential to be alternatives to PPO in\nclassical sequential decision-making problems. This paper sheds light on the\nperformance of language agents and paves the way for future research in this\nexciting domain. Our code is publicly available\nat~\\url{https://github.com/mail-ecnu/Text-Gym-Agents}.",
            "author": [
                "Junjie Sheng",
                "Zixiao Huang",
                "Chuyun Shen",
                "Wenhao Li",
                "Yun Hua",
                "Bo Jin",
                "Hongyuan Zha",
                "Xiangfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03290v1",
                "http://arxiv.org/pdf/2312.03290v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03284v1",
            "title": "Adaptive Multi-band Modulation for Robust and Low-complexity\n  Faster-than-Nyquist Non-Orthogonal FDM IM-DD System",
            "updated": "2023-12-06T04:25:35Z",
            "published": "2023-12-06T04:25:35Z",
            "summary": "Faster-than-Nyquist non-orthogonal frequency-division multiplexing\n(FTN-NOFDM) is robust against the steep frequency roll-off by saving signal\nbandwidth. Among the FTN-NOFDM techniques, the non-orthogonal matrix precoding\n(NOM-p) based FTN has high compatibility with the conventional orthogonal\nfrequency division multiplexing (OFDM), in terms of the advanced digital signal\nprocessing already used in OFDM. In this work, by dividing the single band into\nmultiple sub-bands in the NOM-p-based FTN-NOFDM system, we propose a novel\nFTN-NOFDM scheme with adaptive multi-band modulation. The proposed scheme\nassigns different quadrature amplitude modulation (QAM) levels to different\nsub-bands, effectively utilizing the low-pass-like channel and reducing the\ncomplexity. The impacts of sub-band number and bandwidth compression factor on\nthe bit-error-rate (BER) performance and implementation complexity are\nexperimentally analyzed with a 32.23-Gb/s and 20-km intensity modulation-direct\ndetection (IM-DD) optical transmission system. Results show that the proposed\nscheme with proper sub-band numbers can lower BER and greatly reduce the\ncomplexity compared to the conventional single-band way.",
            "author": [
                "Peiji Song",
                "Zhouyi Hu",
                "Yizhan Dai",
                "Yuan Liu",
                "Chao Gao",
                "Chun-Kit Chan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03284v1",
                "http://arxiv.org/pdf/2312.03284v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03276v1",
            "title": "An inverter-chain link implementation of quantum teleportation and\n  superdense coding",
            "updated": "2023-12-06T04:03:11Z",
            "published": "2023-12-06T04:03:11Z",
            "summary": "A new perspective in terms of inverter-chain link (ICL) diagrams of quantum\nentanglement faithfully captures the fundamental concept of quantum\nteleportation and superdense coding. Here, we employ discrete phase space and\nICL analyses of quantum entanglement as a resource for quantum teleportation\nand superdense coding. We underscore the quantum superposition principle and\nHadamard transformation under a single qubit local operations. On the\nfundamental question posed by EPR, our result seems to lend support to the\ngeometric nature of quantum entanglement. In concluding remarks, we discuss\nvery briefly a bold conjecture in physics aiming to unify general relativity\nwith quantum mechanics, namely, ER=EPR.",
            "author": [
                "Felix A. Buot",
                "Roland E. S. Otadoy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03276v1",
                "http://arxiv.org/pdf/2312.03276v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03275v1",
            "title": "VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation",
            "updated": "2023-12-06T04:02:28Z",
            "published": "2023-12-06T04:02:28Z",
            "summary": "Understanding how humans leverage semantic knowledge to navigate unfamiliar\nenvironments and decide where to explore next is pivotal for developing robots\ncapable of human-like search behaviors. We introduce a zero-shot navigation\napproach, Vision-Language Frontier Maps (VLFM), which is inspired by human\nreasoning and designed to navigate towards unseen semantic objects in novel\nenvironments. VLFM builds occupancy maps from depth observations to identify\nfrontiers, and leverages RGB observations and a pre-trained vision-language\nmodel to generate a language-grounded value map. VLFM then uses this map to\nidentify the most promising frontier to explore for finding an instance of a\ngiven target object category. We evaluate VLFM in photo-realistic environments\nfrom the Gibson, Habitat-Matterport 3D (HM3D), and Matterport 3D (MP3D)\ndatasets within the Habitat simulator. Remarkably, VLFM achieves\nstate-of-the-art results on all three datasets as measured by success weighted\nby path length (SPL) for the Object Goal Navigation task. Furthermore, we show\nthat VLFM's zero-shot nature enables it to be readily deployed on real-world\nrobots such as the Boston Dynamics Spot mobile manipulation platform. We deploy\nVLFM on Spot and demonstrate its capability to efficiently navigate to target\nobjects within an office building in the real world, without any prior\nknowledge of the environment. The accomplishments of VLFM underscore the\npromising potential of vision-language models in advancing the field of\nsemantic navigation. Videos of real-world deployment can be viewed at\nnaoki.io/vlfm.",
            "author": [
                "Naoki Yokoyama",
                "Sehoon Ha",
                "Dhruv Batra",
                "Jiuguang Wang",
                "Bernadette Bucher"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03275v1",
                "http://arxiv.org/pdf/2312.03275v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03271v1",
            "title": "Freezing of sessile droplet and frost halo formation",
            "updated": "2023-12-06T03:56:11Z",
            "published": "2023-12-06T03:56:11Z",
            "summary": "The freezing of a sessile droplet unveils fascinating physics, characterised\nby the emergence of a frost halo on the underlying substrate, the progression\nof the liquid-ice interface, and the formation of a cusp-like morphology at the\ntip of the droplet. We investigate the freezing of a volatile sessile droplet,\nfocusing on the frost halo formation, which has not been theoretically\nexplored. The formation of the frost halo is associated with the inherent\nevaporation process in the early freezing stages. We observe a negative\nevaporation flux enveloping the droplet in the initial stages, which indicates\nthat vapour produced during freezing condenses on the substrate close to the\ncontact line, forming a frost halo. The condensate accumulation triggers\nre-evaporation, resulting in a temporal shift of the frost halo region away\nfrom the contact line. Eventually, it disappears due to the diffusive nature of\nthe water vapour far away from the droplet. We found that increasing the\nrelative humidity increases the lifetime of the frost halo due to a substantial\nreduction in evaporation that prolonged the presence of net condensate on the\nsubstrate. Increasing liquid volatility increases the evaporation flux, and\ncondensation occurs closer to the droplet, as a higher amount of vapour is in\nthe periphery of the droplet. We also found that decreasing the thermal\nconductivity of the substrate increases the total freezing time. The slower\nfreezing process is accompanied by increased vaporized liquid, resulting in\ncondensation with its concentration reaching supersaturation.",
            "author": [
                "Sivanandan Kavuri",
                "George Karapetsas",
                "Chander Shekhar Sharma",
                "Kirti Chandra Sahu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03271v1",
                "http://arxiv.org/pdf/2312.03271v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03266v1",
            "title": "SO-NeRF: Active View Planning for NeRF using Surrogate Objectives",
            "updated": "2023-12-06T03:31:13Z",
            "published": "2023-12-06T03:31:13Z",
            "summary": "Despite the great success of Neural Radiance Fields (NeRF), its\ndata-gathering process remains vague with only a general rule of thumb of\nsampling as densely as possible. The lack of understanding of what actually\nconstitutes good views for NeRF makes it difficult to actively plan a sequence\nof views that yield the maximal reconstruction quality. We propose Surrogate\nObjectives for Active Radiance Fields (SOAR), which is a set of interpretable\nfunctions that evaluates the goodness of views using geometric and photometric\nvisual cues - surface coverage, geometric complexity, textural complexity, and\nray diversity. Moreover, by learning to infer the SOAR scores from a deep\nnetwork, SOARNet, we are able to effectively select views in mere seconds\ninstead of hours, without the need for prior visits to all the candidate views\nor training any radiance field during such planning. Our experiments show\nSOARNet outperforms the baselines with $\\sim$80x speed-up while achieving\nbetter or comparable reconstruction qualities. We finally show that SOAR is\nmodel-agnostic, thus it generalizes across fully neural-implicit to fully\nexplicit approaches.",
            "author": [
                "Keifer Lee",
                "Shubham Gupta",
                "Sunglyoung Kim",
                "Bhargav Makwana",
                "Chao Chen",
                "Chen Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03266v1",
                "http://arxiv.org/pdf/2312.03266v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03263v1",
            "title": "Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying\n  Partially Observable Environment",
            "updated": "2023-12-06T03:20:42Z",
            "published": "2023-12-06T03:20:42Z",
            "summary": "Optimal decision-making presents a significant challenge for autonomous\nsystems operating in uncertain, stochastic and time-varying environments.\nEnvironmental variability over time can significantly impact the system's\noptimal decision making strategy for mission completion. To model such\nenvironments, our work combines the previous notion of Time-Varying Markov\nDecision Processes (TVMDP) with partial observability and introduces\nTime-Varying Partially Observable Markov Decision Processes (TV-POMDP). We\npropose a two-pronged approach to accurately estimate and plan within the\nTV-POMDP: 1) Memory Prioritized State Estimation (MPSE), which leverages\nweighted memory to provide more accurate time-varying transition estimates; and\n2) an MPSE-integrated planning strategy that optimizes long-term rewards while\naccounting for temporal constraint. We validate the proposed framework and\nalgorithms using simulations and hardware, with robots exploring a partially\nobservable, time-varying environments. Our results demonstrate superior\nperformance over standard methods, highlighting the framework's effectiveness\nin stochastic, uncertain, time-varying domains.",
            "author": [
                "Gokul Puthumanaillam",
                "Xiangyu Liu",
                "Negar Mehr",
                "Melkior Ornik"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03263v1",
                "http://arxiv.org/pdf/2312.03263v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03255v1",
            "title": "Densifying MIMO: Channel Modeling, Physical Constraints, and Performance\n  Evaluation for Holographic Communications",
            "updated": "2023-12-06T03:05:05Z",
            "published": "2023-12-06T03:05:05Z",
            "summary": "As the backbone of the fifth-generation (5G) cellular network, massive\nmultiple-input multiple-output (MIMO) encounters a significant challenge in\npractical applications: how to deploy a large number of antenna elements within\nlimited spaces. Recently, holographic communication has emerged as a potential\nsolution to this issue. It employs dense antenna arrays and provides a\ntractable model. Nevertheless, some challenges must be addressed to actualize\nthis innovative concept. One is the mutual coupling among antenna elements\nwithin an array. When the element spacing is small, near-field coupling becomes\nthe dominant factor that strongly restricts the array performance. Another is\nthe polarization of electromagnetic waves. As an intrinsic property, it was not\nfully considered in the previous channel modeling of holographic communication.\nThe third is the lack of real-world experiments to show the potential and\npossible defects of a holographic communication system. In this paper, we\npropose an electromagnetic channel model based on the characteristics of\nelectromagnetic waves. This model encompasses the impact of mutual coupling in\nthe transceiver sides and the depolarization in the propagation environment.\nFurthermore, by approximating an infinite array, the performance restrictions\nof large-scale dense antenna arrays are also studied theoretically to exploit\nthe potential of the proposed channel. In addition, numerical simulations and a\nchannel measurement experiment are conducted. The findings reveal that within\nlimited spaces, the coupling effect, particularly for element spacing smaller\nthan half of the wavelength, is the primary factor leading to the inflection\npoint for the performance of holographic communications.",
            "author": [
                "Y. Liu",
                "M. Zhang",
                "T. Wang",
                "A. Zhang",
                "M. Debbah"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03255v1",
                "http://arxiv.org/pdf/2312.03255v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03254v1",
            "title": "Efficiency of Terrestrial Laser Scanning in Survey Works: Assessment,\n  Modelling, and Monitoring",
            "updated": "2023-12-06T03:02:54Z",
            "published": "2023-12-06T03:02:54Z",
            "summary": "Nowadays, static, mobile, terrestrial, and airborne laser scanning\ntechnologies have become familiar data sources for engineering work, especially\nin the area of land surveying. The diversity of Light Detection and Ranging\n(LiDAR) data applications thanks to the accuracy and the high point density in\naddition to the 3D data processing high speed allow laser scanning to occupy an\nadvanced position among other spatial data acquisition technologies. Moreover,\nthe unmanned aerial vehicle drives the airborne scanning progress by solving\nthe flying complexity issues. However, before the employment of the laser\nscanning technique, it is unavoidable to assess the accuracy of the scanner\nbeing used under different circumstances. The key to success is determined by\nthe correct selection of suitable scanning tools for the project. In this\npaper, the terrestrial LiDAR data is tested and used for several laser scanning\nprojects having diverse goals and typology, e.g., road deformation monitoring,\nbuilding facade modelling, road modelling, and stockpile modelling and volume\nmeasuring. The accuracy of direct measurement on the LiDAR point cloud is\nestimated as 4mm which may open the door widely for LiDAR data to play an\nessential role in survey work applications.",
            "author": [
                "Fayez Tarsha Kurdi",
                "Paul Reed",
                "Zahra Gharineiat",
                "Mohammad Awrangjeb"
            ],
            "link": [
                "http://dx.doi.org/10.19080/IJESNR.2023.32.556334",
                "http://arxiv.org/abs/2312.03254v1",
                "http://arxiv.org/pdf/2312.03254v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "(Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03247v1",
            "title": "Principle of fundamental resonance in hypersonic boundary layers: an\n  asymptotic viewpoint",
            "updated": "2023-12-06T02:47:12Z",
            "published": "2023-12-06T02:47:12Z",
            "summary": "The fundamental resonance (FR) in the nonlinear phase of the boundary-layer\ntransition to turbulence appears when a dominant planar instability mode\nreaches a finite amplitude, and the low-amplitude oblique traveling modes with\nthe same frequency as the dominant mode, together with the stationary streak\nmodes, undergo the strongest amplification among all the Fourier components.\nThis regime may be the most efficient means to trigger the natural transition\nin hypersonic boundary layers. In this paper, we aim to reveal the intrinsic\nmechanism of the FR in the weakly nonlinear framework based on the\nlarge-Reynolds-number asymptotic technique. It is found that the FR is in\nprinciple a triad resonance among a dominant planar fundamental mode, a streak\nmode and an oblique mode. In the major part of the boundary layer, the\nnonlinear interaction of the fundamental mode and the streak mode seeds for the\ngrowth of the oblique mode, whereas the interaction of the oblique mode and the\nfundamental mode drives the roll components (transverse and lateral velocity)\nof the streak mode, which leads to a stronger amplification of the streamwise\ncomponent of the streak mode due to the lift-up mechanism. The main-layer\nsolution of the streamwise velocity, spanwise velocity and temperature of both\nthe streak and the oblique modes become singular as the wall is approached, and\nso a viscous wall layer appears underneath. The wall layer produces an outflux\nvelocity to the main-layer solution, inclusion of which leads to an improved\nasymptotic theory, whose accuracy is confirmed by comparing with the\ncalculations of the nonlinear parabolised stability equations (NPSE) at\nmoderate Reynolds numbers and the secondary instability analysis (SIA) at\nsufficiently high Reynolds numbers.",
            "author": [
                "Runjie Song",
                "Ming Dong",
                "Lei Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03247v1",
                "http://arxiv.org/pdf/2312.03247v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03236v1",
            "title": "Multicoated and Folded Graph Neural Networks with Strong Lottery Tickets",
            "updated": "2023-12-06T02:16:44Z",
            "published": "2023-12-06T02:16:44Z",
            "summary": "The Strong Lottery Ticket Hypothesis (SLTH) demonstrates the existence of\nhigh-performing subnetworks within a randomly initialized model, discoverable\nthrough pruning a convolutional neural network (CNN) without any weight\ntraining. A recent study, called Untrained GNNs Tickets (UGT), expanded SLTH\nfrom CNNs to shallow graph neural networks (GNNs). However, discrepancies\npersist when comparing baseline models with learned dense weights.\nAdditionally, there remains an unexplored area in applying SLTH to deeper GNNs,\nwhich, despite delivering improved accuracy with additional layers, suffer from\nexcessive memory requirements. To address these challenges, this work utilizes\nMulticoated Supermasks (M-Sup), a scalar pruning mask method, and implements it\nin GNNs by proposing a strategy for setting its pruning thresholds adaptively.\nIn the context of deep GNNs, this research uncovers the existence of untrained\nrecurrent networks, which exhibit performance on par with their trained\nfeed-forward counterparts. This paper also introduces the Multi-Stage Folding\nand Unshared Masks methods to expand the search space in terms of both\narchitecture and parameters. Through the evaluation of various datasets,\nincluding the Open Graph Benchmark (OGB), this work establishes a triple-win\nscenario for SLTH-based GNNs: by achieving high sparsity, competitive\nperformance, and high memory efficiency with up to 98.7\\% reduction, it\ndemonstrates suitability for energy-efficient graph processing.",
            "author": [
                "Jiale Yan",
                "Hiroaki Ito",
                "\u00c1ngel L\u00f3pez Garc\u00eda-Arias",
                "Yasuyuki Okoshi",
                "Hikari Otsuka",
                "Kazushi Kawamura",
                "Thiem Van Chu",
                "Masato Motomura"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03236v1",
                "http://arxiv.org/pdf/2312.03236v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03231v1",
            "title": "Deep Multimodal Fusion for Surgical Feedback Classification",
            "updated": "2023-12-06T01:59:47Z",
            "published": "2023-12-06T01:59:47Z",
            "summary": "Quantification of real-time informal feedback delivered by an experienced\nsurgeon to a trainee during surgery is important for skill improvements in\nsurgical training. Such feedback in the live operating room is inherently\nmultimodal, consisting of verbal conversations (e.g., questions and answers) as\nwell as non-verbal elements (e.g., through visual cues like pointing to\nanatomic elements). In this work, we leverage a clinically-validated\nfive-category classification of surgical feedback: \"Anatomic\", \"Technical\",\n\"Procedural\", \"Praise\" and \"Visual Aid\". We then develop a multi-label machine\nlearning model to classify these five categories of surgical feedback from\ninputs of text, audio, and video modalities. The ultimate goal of our work is\nto help automate the annotation of real-time contextual surgical feedback at\nscale. Our automated classification of surgical feedback achieves AUCs ranging\nfrom 71.5 to 77.6 with the fusion improving performance by 3.1%. We also show\nthat high-quality manual transcriptions of feedback audio from experts improve\nAUCs to between 76.5 and 96.2, which demonstrates a clear path toward future\nimprovements. Empirically, we find that the Staged training strategy, with\nfirst pre-training each modality separately and then training them jointly, is\nmore effective than training different modalities altogether. We also present\nintuitive findings on the importance of modalities for different feedback\ncategories. This work offers an important first look at the feasibility of\nautomated classification of real-world live surgical feedback based on text,\naudio, and video modalities.",
            "author": [
                "Rafal Kocielnik",
                "Elyssa Y. Wong",
                "Timothy N. Chu",
                "Lydia Lin",
                "De-An Huang",
                "Jiayun Wang",
                "Anima Anandkumar",
                "Andrew J. Hung"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03231v1",
                "http://arxiv.org/pdf/2312.03231v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.HC",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03227v1",
            "title": "Human Body Model based ID using Shape and Pose Parameters",
            "updated": "2023-12-06T01:51:54Z",
            "published": "2023-12-06T01:51:54Z",
            "summary": "We present a Human Body model based IDentification system (HMID) system that\nis jointly trained for shape, pose and biometric identification. HMID is based\non the Human Mesh Recovery (HMR) network and we propose additional losses to\nimprove and stabilize shape estimation and biometric identification while\nmaintaining the pose and shape output. We show that when our HMID network is\ntrained using additional shape and pose losses, it shows a significant\nimprovement in biometric identification performance when compared to an\nidentical model that does not use such losses. The HMID model uses raw images\ninstead of silhouettes and is able to perform robust recognition on images\ncollected at range and altitude as many anthropometric properties are\nreasonably invariant to clothing, view and range. We show results on the USF\ndataset as well as the BRIAR dataset which includes probes with both clothing\nand view changes. Our approach (using body model losses) shows a significant\nimprovement in Rank20 accuracy and True Accuracy Rate on the BRIAR evaluation\ndataset.",
            "author": [
                "Aravind Sundaresan",
                "Brian Burns",
                "Indranil Sur",
                "Yi Yao",
                "Xiao Lin",
                "Sujeong Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03227v1",
                "http://arxiv.org/pdf/2312.03227v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03226v1",
            "title": "Rethinking Object Saliency Ranking: A Novel Whole-flow Processing\n  Paradigm",
            "updated": "2023-12-06T01:51:03Z",
            "published": "2023-12-06T01:51:03Z",
            "summary": "Existing salient object detection methods are capable of predicting binary\nmaps that highlight visually salient regions. However, these methods are\nlimited in their ability to differentiate the relative importance of multiple\nobjects and the relationships among them, which can lead to errors and reduced\naccuracy in downstream tasks that depend on the relative importance of multiple\nobjects. To conquer, this paper proposes a new paradigm for saliency ranking,\nwhich aims to completely focus on ranking salient objects by their \"importance\norder\". While previous works have shown promising performance, they still face\nill-posed problems. First, the saliency ranking ground truth (GT) orders\ngeneration methods are unreasonable since determining the correct ranking order\nis not well-defined, resulting in false alarms. Second, training a ranking\nmodel remains challenging because most saliency ranking methods follow the\nmulti-task paradigm, leading to conflicts and trade-offs among different tasks.\nThird, existing regression-based saliency ranking methods are complex for\nsaliency ranking models due to their reliance on instance mask-based saliency\nranking orders. These methods require a significant amount of data to perform\naccurately and can be challenging to implement effectively. To solve these\nproblems, this paper conducts an in-depth analysis of the causes and proposes a\nwhole-flow processing paradigm of saliency ranking task from the perspective of\n\"GT data generation\", \"network structure design\" and \"training protocol\". The\nproposed approach outperforms existing state-of-the-art methods on the\nwidely-used SALICON set, as demonstrated by extensive experiments with fair and\nreasonable comparisons. The saliency ranking task is still in its infancy, and\nour proposed unified framework can serve as a fundamental strategy to guide\nfuture work.",
            "author": [
                "Mengke Song",
                "Linfeng Li",
                "Dunquan Wu",
                "Wenfeng Song",
                "Chenglizhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03226v1",
                "http://arxiv.org/pdf/2312.03226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03221v1",
            "title": "Random walk models for the propagation of signalling molecules in\n  one-dimensional spatial networks and their continuum limit",
            "updated": "2023-12-06T01:32:00Z",
            "published": "2023-12-06T01:32:00Z",
            "summary": "The propagation of signalling molecules within cellular networks is affected\nby network topology, but also by the spatial arrangement of cells in the\nnetworks. Understanding the collective reaction--diffusion behaviour in space\nof signals propagating through cellular networks is an important consideration\nfor example for regenerative signals that convey positional information. In\nthis work, we consider stochastic and deterministic random walk models of\nsignalling molecules propagating and reacting within one-dimensional spatial\nnetworks with arbitrary node placement and connectivity. By taking a continuum\nlimit of the random walk models, we derive an inhomogeneous\nreaction--diffusion--advection equation, where diffusivity and advective\nvelocity depend on local node density and connectivity within the network. Our\nresults show that large spatial variations of molecule concentrations can be\ninduced by heterogeneous node distributions. Furthermore, we find that noise\nwithin the stochastic random walk model is directly influenced by node density.\nWe apply our models to consider signal propagation within the osteocyte network\nof bone, where signals propagating to the bone surface regulate bone formation\nand resorption processes. We investigate signal-to-noise ratios for different\ndamage detection scenarios and show that the location of perturbations to the\nnetwork can be detected by signals received at the network boundaries.",
            "author": [
                "Adel Mehrpooya",
                "Vivien J. Challis",
                "Pascal R. Buenzli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03221v1",
                "http://arxiv.org/pdf/2312.03221v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03217v1",
            "title": "Rethinking E-Commerce Search",
            "updated": "2023-12-06T01:15:40Z",
            "published": "2023-12-06T01:15:40Z",
            "summary": "E-commerce search and recommendation usually operate on structured data such\nas product catalogs and taxonomies. However, creating better search and\nrecommendation systems often requires a large variety of unstructured data\nincluding customer reviews and articles on the web. Traditionally, the solution\nhas always been converting unstructured data into structured data through\ninformation extraction, and conducting search over the structured data.\nHowever, this is a costly approach that often has low quality. In this paper,\nwe envision a solution that does entirely the opposite. Instead of converting\nunstructured data (web pages, customer reviews, etc) to structured data, we\ninstead convert structured data (product inventory, catalogs, taxonomies, etc)\ninto textual data, which can be easily integrated into the text corpus that\ntrains LLMs. Then, search and recommendation can be performed through a Q/A\nmechanism through an LLM instead of using traditional information retrieval\nmethods over structured data.",
            "author": [
                "Haixun Wang",
                "Taesik Na"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03217v1",
                "http://arxiv.org/pdf/2312.03217v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03214v1",
            "title": "Optimistic Global Function Merger",
            "updated": "2023-12-06T01:05:44Z",
            "published": "2023-12-06T01:05:44Z",
            "summary": "Function merging is a pivotal technique for reducing code size by combining\nidentical or similar functions into a single function. While prior research has\nextensively explored this technique, it has not been assessed in conjunction\nwith function outlining and linker's identical code folding, despite\nsubstantial common ground. The traditional approaches necessitate the complete\nintermediate representation to compare functions. Consequently, none of these\napproaches offer a scalable solution compatible with separate compilations\nwhile achieving global function merging, which is critical for large app\ndevelopment. In this paper, we introduce our global function merger, leveraging\nglobal merge information from previous code generation runs to optimistically\ncreate merging instances within each module context independently. Notably, our\napproach remains sound even when intermediate representations change, making it\nwell-suited for distributed build environments. We present a comprehensive code\ngeneration framework that can run both the state-of-the-art global function\noutliner and our global function merger. These components complement each\nother, resulting in a positive impact on code size reduction. Our evaluation\ndemonstrates that when integrating the global function merger with a\nstate-of-the-art global function outliner that is fully optimized with ThinLTO,\na further reduction of up to 3.5% in code size can be attained. This is in\naddition to the initial average reduction of 17.3% achieved through global\nfunction outlining for real-world iOS apps, all with minimal extra build time.",
            "author": [
                "Kyungwoo Lee",
                "Manman Ren",
                "Ellis Hoag"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03214v1",
                "http://arxiv.org/pdf/2312.03214v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03212v1",
            "title": "Constrained Bayesian Optimization Under Partial Observations: Balanced\n  Improvements and Provable Convergence",
            "updated": "2023-12-06T01:00:07Z",
            "published": "2023-12-06T01:00:07Z",
            "summary": "The partially observable constrained optimization problems (POCOPs) impede\ndata-driven optimization techniques since an infeasible solution of POCOPs can\nprovide little information about the objective as well as the constraints. We\nendeavor to design an efficient and provable method for expensive POCOPs under\nthe framework of constrained Bayesian optimization. Our method consists of two\nkey components. Firstly, we present an improved design of the acquisition\nfunctions that introduces balanced exploration during optimization. We\nrigorously study the convergence properties of this design to demonstrate its\neffectiveness. Secondly, we propose a Gaussian process embedding different\nlikelihoods as the surrogate model for a partially observable constraint. This\nmodel leads to a more accurate representation of the feasible regions compared\nto traditional classification-based models. Our proposed method is empirically\nstudied on both synthetic and real-world problems. The results demonstrate the\ncompetitiveness of our method for solving POCOPs.",
            "author": [
                "Shengbo Wang",
                "Ke Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03212v1",
                "http://arxiv.org/pdf/2312.03212v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03209v1",
            "title": "Cache Me if You Can: Accelerating Diffusion Models through Block Caching",
            "updated": "2023-12-06T00:51:38Z",
            "published": "2023-12-06T00:51:38Z",
            "summary": "Diffusion models have recently revolutionized the field of image synthesis\ndue to their ability to generate photorealistic images. However, one of the\nmajor drawbacks of diffusion models is that the image generation process is\ncostly. A large image-to-image network has to be applied many times to\niteratively refine an image from random noise. While many recent works propose\ntechniques to reduce the number of required steps, they generally treat the\nunderlying denoising network as a black box. In this work, we investigate the\nbehavior of the layers within the network and find that 1) the layers' output\nchanges smoothly over time, 2) the layers show distinct patterns of change, and\n3) the change from step to step is often very small. We hypothesize that many\nlayer computations in the denoising network are redundant. Leveraging this, we\nintroduce block caching, in which we reuse outputs from layer blocks of\nprevious steps to speed up inference. Furthermore, we propose a technique to\nautomatically determine caching schedules based on each block's changes over\ntimesteps. In our experiments, we show through FID, human evaluation and\nqualitative analysis that Block Caching allows to generate images with higher\nvisual quality at the same computational cost. We demonstrate this for\ndifferent state-of-the-art models (LDM and EMU) and solvers (DDIM and DPM).",
            "author": [
                "Felix Wimbauer",
                "Bichen Wu",
                "Edgar Schoenfeld",
                "Xiaoliang Dai",
                "Ji Hou",
                "Zijian He",
                "Artsiom Sanakoyeu",
                "Peizhao Zhang",
                "Sam Tsai",
                "Jonas Kohler",
                "Christian Rupprecht",
                "Daniel Cremers",
                "Peter Vajda",
                "Jialiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03209v1",
                "http://arxiv.org/pdf/2312.03209v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03208v1",
            "title": "Successful $\u03bdp$-process in neutrino-driven outflows in core-collapse\n  supernovae",
            "updated": "2023-12-06T00:50:22Z",
            "published": "2023-12-06T00:50:22Z",
            "summary": "The origin of the solar system abundances of several proton-rich isotopes,\nespecially $^{92,94}$Mo and $^{96,98}$Ru, has been an enduring mystery in\nnuclear astrophysics. An attractive proposal to solve this problem is the $\\nu\np$-process, which can operate in neutrino-driven outflows in a core-collapse\nsupernova after the shock is launched. Years of detailed studies, however, have\ncast doubt over the ability of this process to generate sufficiently high\nabsolute and relative amounts of various $p$-nuclei. The $\\nu p$-process is\nalso thought to be excluded by arguments based on the long-lived radionuclide\n$^{92}$Nb. Here, we present explicit calculations, in which both the abundance\nratios and the absolute yields of the $p$-nuclei up to $A\\lesssim105$ are\nsuccessfully reproduced, even when using the modern (medium enhanced)\ntriple-$\\alpha$ reaction rates. The process is also shown to produce the\nnecessary amounts of $^{92}$Nb. The models are characterized by subsonic\noutflows and by the protoneutron star masses in the {$\\gtrsim1.7 M_\\odot$\nrange}. This suggests that the Mo and Ru $p$-nuclides observed in the Solar\nSystem were made in CCSN explosions characterized by an extended accretion\nstage.",
            "author": [
                "Alexander Friedland",
                "Payel Mukhopadhyay",
                "Amol V. Patwardhan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03208v1",
                "http://arxiv.org/pdf/2312.03208v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.SR",
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03206v2",
            "title": "Seamless monolithic three-dimensional integration of single-crystalline\n  films by growth",
            "updated": "2023-12-07T02:10:35Z",
            "published": "2023-12-06T00:48:04Z",
            "summary": "The demand for the three-dimensional (3D) integration of electronic\ncomponents is on a steady rise. The through-silicon-via (TSV) technique emerges\nas the only viable method for integrating single-crystalline device components\nin a 3D format, despite encountering significant processing challenges. While\nmonolithic 3D (M3D) integration schemes show promise, the seamless connection\nof single-crystalline semiconductors without intervening wafers has yet to be\ndemonstrated. This challenge arises from the inherent difficulty of growing\nsingle crystals on amorphous or polycrystalline surfaces post the\nback-end-of-the-line process at low temperatures to preserve the underlying\ncircuitry. Consequently, a practical growth-based solution for M3D of single\ncrystals remains elusive. Here, we present a method for growing\nsingle-crystalline channel materials, specifically composed of transition metal\ndichalcogenides, on amorphous and polycrystalline surfaces at temperatures\nlower than 400 {\\deg}C. Building on this developed technique, we demonstrate\nthe seamless monolithic integration of vertical single-crystalline logic\ntransistor arrays. This accomplishment leads to the development of\nunprecedented vertical CMOS arrays, thereby constructing vertical inverters.\nUltimately, this achievement sets the stage to pave the way for M3D integration\nof various electronic and optoelectronic hardware in the form of single\ncrystals.",
            "author": [
                "Ki Seok Kim",
                "Seunghwan Seo",
                "Junyoung Kwon",
                "Doyoon Lee",
                "Changhyun Kim",
                "Jung-El Ryu",
                "Jekyung Kim",
                "Min-Kyu Song",
                "Jun Min Suh",
                "Hang-Gyo Jung",
                "Youhwan Jo",
                "Hogeun Ahn",
                "Sangho Lee",
                "Kyeongjae Cho",
                "Jongwook Jeon",
                "Minsu Seol",
                "Jin-Hong Park",
                "Sang Won Kim",
                "Jeehwan Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03206v2",
                "http://arxiv.org/pdf/2312.03206v2"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03205v1",
            "title": "Who Leaked the Model? Tracking IP Infringers in Accountable Federated\n  Learning",
            "updated": "2023-12-06T00:47:55Z",
            "published": "2023-12-06T00:47:55Z",
            "summary": "Federated learning (FL) emerges as an effective collaborative learning\nframework to coordinate data and computation resources from massive and\ndistributed clients in training. Such collaboration results in non-trivial\nintellectual property (IP) represented by the model parameters that should be\nprotected and shared by the whole party rather than an individual user.\nMeanwhile, the distributed nature of FL endorses a malicious client the\nconvenience to compromise IP through illegal model leakage to unauthorized\nthird parties. To block such IP leakage, it is essential to make the IP\nidentifiable in the shared model and locate the anonymous infringer who first\nleaks it. The collective challenges call for \\emph{accountable federated\nlearning}, which requires verifiable ownership of the model and is capable of\nrevealing the infringer's identity upon leakage. In this paper, we propose\nDecodable Unique Watermarking (DUW) for complying with the requirements of\naccountable FL. Specifically, before a global model is sent to a client in an\nFL round, DUW encodes a client-unique key into the model by leveraging a\nbackdoor-based watermark injection. To identify the infringer of a leaked\nmodel, DUW examines the model and checks if the triggers can be decoded as the\ncorresponding keys. Extensive empirical results show that DUW is highly\neffective and robust, achieving over $99\\%$ watermark success rate for Digits,\nCIFAR-10, and CIFAR-100 datasets under heterogeneous FL settings, and\nidentifying the IP infringer with $100\\%$ accuracy even after common watermark\nremoval attempts.",
            "author": [
                "Shuyang Yu",
                "Junyuan Hong",
                "Yi Zeng",
                "Fei Wang",
                "Ruoxi Jia",
                "Jiayu Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03205v1",
                "http://arxiv.org/pdf/2312.03205v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03203v1",
            "title": "Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled\n  Feature Fields",
            "updated": "2023-12-06T00:46:30Z",
            "published": "2023-12-06T00:46:30Z",
            "summary": "3D scene representations have gained immense popularity in recent years.\nMethods that use Neural Radiance fields are versatile for traditional tasks\nsuch as novel view synthesis. In recent times, some work has emerged that aims\nto extend the functionality of NeRF beyond view synthesis, for semantically\naware tasks such as editing and segmentation using 3D feature field\ndistillation from 2D foundation models. However, these methods have two major\nlimitations: (a) they are limited by the rendering speed of NeRF pipelines, and\n(b) implicitly represented feature fields suffer from continuity artifacts\nreducing feature quality. Recently, 3D Gaussian Splatting has shown\nstate-of-the-art performance on real-time radiance field rendering. In this\nwork, we go one step further: in addition to radiance field rendering, we\nenable 3D Gaussian splatting on arbitrary-dimension semantic features via 2D\nfoundation model distillation. This translation is not straightforward: naively\nincorporating feature fields in the 3DGS framework leads to warp-level\ndivergence. We propose architectural and training changes to efficiently avert\nthis problem. Our proposed method is general, and our experiments showcase\nnovel view semantic segmentation, language-guided editing and segment anything\nthrough learning feature fields from state-of-the-art 2D foundation models such\nas SAM and CLIP-LSeg. Across experiments, our distillation method is able to\nprovide comparable or better results, while being significantly faster to both\ntrain and render. Additionally, to the best of our knowledge, we are the first\nmethod to enable point and bounding-box prompting for radiance field\nmanipulation, by leveraging the SAM model. Project website at:\nhttps://feature-3dgs.github.io/",
            "author": [
                "Shijie Zhou",
                "Haoran Chang",
                "Sicheng Jiang",
                "Zhiwen Fan",
                "Zehao Zhu",
                "Dejia Xu",
                "Pradyumna Chari",
                "Suya You",
                "Zhangyang Wang",
                "Achuta Kadambi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03203v1",
                "http://arxiv.org/pdf/2312.03203v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03202v1",
            "title": "Numerical Convergence of Electromagnetic Responses with the\n  Finite-Amplitude Method",
            "updated": "2023-12-06T00:44:12Z",
            "published": "2023-12-06T00:44:12Z",
            "summary": "The response of a nucleus to an electromagnetic probe is a key quantity to\nsimulate photabsorption or photodeexcitation processes. For large calculations\nat the scale of the entire mass table, this response can be estimated by linear\nresponse theory. Thanks to the introduction of the finite-amplitude method\n(FAM), calculations are computationally efficient. In this paper, we\ninvestigate in more details the convergence of FAM calculations of the response\nfunction as a function of the parameters controlling the numerical\nimplementation of the theory. We show that the response is much less sensitive\nto the details of the single-particle basis than, e.g., Hartree-Fock-Bogoliubov\ncalculations.",
            "author": [
                "Tong Li",
                "Nicolas Schunck"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03202v1",
                "http://arxiv.org/pdf/2312.03202v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03199v1",
            "title": "Search for charged-lepton flavor violation in the production and decay\n  of top quarks using trilepton final states in proton-proton collisions at\n  $\\sqrt{s}$ = 13 TeV",
            "updated": "2023-12-06T00:39:45Z",
            "published": "2023-12-06T00:39:45Z",
            "summary": "A search is performed for charged-lepton flavor violating processes in top\nquark (t) production and decay. The data were collected by the CMS experiment\nfrom proton-proton collisions at a center-of-mass energy of 13 TeV and\ncorrespond to an integrated luminosity of 138 fb$^{-1}$. The selected events\nare required to contain one opposite-sign electron-muon pair, a third charged\nlepton (electron or muon), and at least one jet of which no more than one is\nassociated with a bottom quark. Boosted decision trees are used to distinguish\nsignal from background, exploiting differences in the kinematics of the final\nstates particles. The data are consistent with the standard model expectation.\nUpper limits at 95% confidence level are placed in the context of effective\nfield theory on the Wilson coefficients, which range between 0.024-0.424\nTeV$^{-2}$ depending on the flavor of the associated light quark and the\nLorentz structure of the interaction. These limits are converted to upper\nlimits on branching fractions involving up (charm) quarks, t$\\to$e$\\mu$u\n(t$\\to$e$\\mu$c), of 0.032 (0.498)$\\times$10$^{-6}$, 0.022\n(0.369)$\\times$10$^{-6}$, and 0.012 (0.216)$\\times$10$^{-6}$ for tensor-like,\nvector-like, and scalar-like interactions, respectively.",
            "author": [
                "CMS Collaboration"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03199v1",
                "http://arxiv.org/pdf/2312.03199v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03196v2",
            "title": "Domain Invariant Representation Learning and Sleep Dynamics Modeling for\n  Automatic Sleep Staging",
            "updated": "2023-12-07T01:58:54Z",
            "published": "2023-12-06T00:28:08Z",
            "summary": "Sleep staging has become a critical task in diagnosing and treating sleep\ndisorders to prevent sleep related diseases. With rapidly growing large scale\npublic sleep databases and advances in machine learning, significant progress\nhas been made toward automatic sleep staging. However, previous studies face\nsome critical problems in sleep studies; the heterogeneity of subjects'\nphysiological signals, the inability to extract meaningful information from\nunlabeled sleep signal data to improve predictive performances, the difficulty\nin modeling correlations between sleep stages, and the lack of an effective\nmechanism to quantify predictive uncertainty. In this study, we propose a\nneural network based automatic sleep staging model, named DREAM, to learn\ndomain generalized representations from physiological signals and models sleep\ndynamics. DREAM learns sleep related and subject invariant representations from\ndiverse subjects' sleep signal segments and models sleep dynamics by capturing\ninteractions between sequential signal segments and between sleep stages. In\nthe experiments, we demonstrate that DREAM outperforms the existing sleep\nstaging methods on three datasets. The case study demonstrates that our model\ncan learn the generalized decision function resulting in good prediction\nperformances for the new subjects, especially in case there are differences\nbetween testing and training subjects. The usage of unlabeled data shows the\nbenefit of leveraging unlabeled EEG data. Further, uncertainty quantification\ndemonstrates that DREAM provides prediction uncertainty, making the model\nreliable and helping sleep experts in real world applications.",
            "author": [
                "Seungyeon Lee",
                "Thai-Hoang Pham",
                "Zhao Cheng",
                "Ping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03196v2",
                "http://arxiv.org/pdf/2312.03196v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03195v1",
            "title": "Detecting Rumor Veracity with Only Textual Information by Double-Channel\n  Structure",
            "updated": "2023-12-06T00:08:44Z",
            "published": "2023-12-06T00:08:44Z",
            "summary": "Kyle (1985) proposes two types of rumors: informed rumors which are based on\nsome private information and uninformed rumors which are not based on any\ninformation (i.e. bluffing). Also, prior studies find that when people have\ncredible source of information, they are likely to use a more confident textual\ntone in their spreading of rumors. Motivated by these theoretical findings, we\npropose a double-channel structure to determine the ex-ante veracity of rumors\non social media. Our ultimate goal is to classify each rumor into true, false,\nor unverifiable category. We first assign each text into either certain\n(informed rumor) or uncertain (uninformed rumor) category. Then, we apply lie\ndetection algorithm to informed rumors and thread-reply agreement detection\nalgorithm to uninformed rumors. Using the dataset of SemEval 2019 Task 7, which\nrequires ex-ante threefold classification (true, false, or unverifiable) of\nsocial media rumors, our model yields a macro-F1 score of 0.4027, outperforming\nall the baseline models and the second-place winner (Gorrell et al., 2019).\nFurthermore, we empirically validate that the double-channel structure\noutperforms single-channel structures which use either lie detection or\nagreement detection algorithm to all posts.",
            "author": [
                "Alex Kim",
                "Sangwon Yoon"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2022.socialnlp-1.3",
                "http://arxiv.org/abs/2312.03195v1",
                "http://arxiv.org/pdf/2312.03195v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03194v1",
            "title": "Corporate Bankruptcy Prediction with Domain-Adapted BERT",
            "updated": "2023-12-06T00:05:25Z",
            "published": "2023-12-06T00:05:25Z",
            "summary": "This study performs BERT-based analysis, which is a representative\ncontextualized language model, on corporate disclosure data to predict\nimpending bankruptcies. Prior literature on bankruptcy prediction mainly\nfocuses on developing more sophisticated prediction methodologies with\nfinancial variables. However, in our study, we focus on improving the quality\nof input dataset. Specifically, we employ BERT model to perform sentiment\nanalysis on MD&A disclosures. We show that BERT outperforms dictionary-based\npredictions and Word2Vec-based predictions in terms of adjusted R-square in\nlogistic regression, k-nearest neighbor (kNN-5), and linear kernel support\nvector machine (SVM). Further, instead of pre-training the BERT model from\nscratch, we apply self-learning with confidence-based filtering to corporate\ndisclosure data (10-K). We achieve the accuracy rate of 91.56% and demonstrate\nthat the domain adaptation procedure brings a significant improvement in\nprediction accuracy.",
            "author": [
                "Alex Kim",
                "Sangwon Yoon"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2021.econlp-1.4",
                "http://arxiv.org/abs/2312.03194v1",
                "http://arxiv.org/pdf/2312.03194v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03186v1",
            "title": "Data-Driven Traffic Reconstruction and Kernel Methods for Identifying\n  Stop-and-Go Congestion",
            "updated": "2023-12-05T23:32:48Z",
            "published": "2023-12-05T23:32:48Z",
            "summary": "Identifying stop-and-go events (SAGs) in traffic flow presents an important\navenue for advancing data-driven research for climate change mitigation and\nsustainability, owing to their substantial impact on carbon emissions, travel\ntime, fuel consumption, and roadway safety. In fact, SAGs are estimated to\naccount for 33-50% of highway driving externalities. However, insufficient\nattention has been paid to precisely quantifying where, when, and how much\nthese SAGs take place -necessary for downstream decision making, such as\nintervention design and policy analysis. A key challenge is that the data\navailable to researchers and governments are typically sparse and aggregated to\na granularity that obscures SAGs. To overcome such data limitations, this study\nthus explores the use of traffic reconstruction techniques for SAG\nidentification. In particular, we introduce a kernel-based method for\nidentifying spatio-temporal features in traffic and leverage bootstrapping to\nquantify the uncertainty of the reconstruction process. Experimental results on\nCalifornia highway data demonstrate the promise of the method for capturing\nSAGs. This work contributes to a foundation for data-driven decision making to\nadvance sustainability of traffic systems.",
            "author": [
                "Edgar Ramirez Sanchez",
                "Shreyaa Raghavan",
                "Cathy Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03186v1",
                "http://arxiv.org/pdf/2312.03186v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03185v1",
            "title": "Lung Cancer Detection from CT Scan Images based on Genetic-Independent\n  Recurrent Deep Learning",
            "updated": "2023-12-05T23:31:05Z",
            "published": "2023-12-05T23:31:05Z",
            "summary": "Lung cancer is one of the prevalence diseases in the world which cause many\ndeaths. Detecting early stages of lung cancer is so necessary. So, modeling and\nsimulating some intelligent medical systems is an essential which can help\nspecialist to accurately determine and diagnose the disease. So this paper\ncontributes a new lung cancer detection model in CT images which use machine\nlearning methods. There are three steps in this model: noise reduction\n(pre-processing), segmentation (middle-processing) and optimize segmentation\nfor detect exact are of nodules. This article use some filters for noise\nreduction and then use Independent Recurrent Neural Networks (IndRNN) as deep\nlearning methods for segmentation which optimize and tune by Genetic Algorithm.\nThe results represented that the proposed method can detect exact area of\nnodules in CT images.",
            "author": [
                "Ehsan Sadeghi Pour",
                "Mahdi Esmaeili"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03185v1",
                "http://arxiv.org/pdf/2312.03185v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03182v1",
            "title": "Investigating Technology Usage Span by Analyzing Users' Q&A Traces in\n  Stack Overflow",
            "updated": "2023-12-05T23:17:48Z",
            "published": "2023-12-05T23:17:48Z",
            "summary": "Choosing an appropriate software development technology (e.g., programming\nlanguage) is challenging due to the proliferation of diverse options. The\nselection of inappropriate technologies for development may have a far-reaching\neffect on software developers' career growth. Switching to a different\ntechnology after working with one may lead to a complex learning curve and,\nthus, be more challenging. Therefore, it is crucial for software developers to\nfind technologies that have a high usage span. Intuitively, the usage span of a\ntechnology can be determined by the time span developers have used that\ntechnology. Existing literature focuses on the technology landscape to explore\nthe complex and implicit dependencies among technologies but lacks formal\nstudies to draw insights about their usage span. This paper investigates the\ntechnology usage span by analyzing the question and answering (Q&A) traces of\nStack Overflow (SO), the largest technical Q&A website available to date. In\nparticular, we analyze 6.7 million Q&A traces posted by about 97K active SO\nusers and see what technologies have appeared in their questions or answers\nover 15 years. According to our analysis, C# and Java programming languages\nhave a high usage span, followed by JavaScript. Besides, developers used the\n.NET framework, iOS & Windows Operating Systems (OS), and SQL query language\nfor a long time (on average). Our study also exposes the emerging (i.e., newly\ngrowing) technologies. For example, usages of technologies such as SwiftUI,\n.NET-6.0, Visual Studio 2022, and Blazor WebAssembly framework are increasing.\nThe findings from our study can assist novice developers, startup software\nindustries, and software users in determining appropriate technologies. This\nalso establishes an initial benchmark for future investigation on the use span\nof software technologies.",
            "author": [
                "Saikat Mondal",
                "Debajyoti Mondal",
                "Chanchal K. Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03182v1",
                "http://arxiv.org/pdf/2312.03182v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03180v1",
            "title": "Image reconstructions using sparse dictionary representations and\n  implicit, non-negative mappings",
            "updated": "2023-12-05T23:07:21Z",
            "published": "2023-12-05T23:07:21Z",
            "summary": "Many imaging science tasks can be modeled as a discrete linear inverse\nproblem. Solving linear inverse problems is often challenging, with\nill-conditioned operators and potentially non-unique solutions. Embedding prior\nknowledge, such as smoothness, into the solution can overcome these challenges.\nIn this work, we encode prior knowledge using a non-negative patch dictionary,\nwhich effectively learns a basis from a training set of natural images. In this\ndictionary basis, we desire solutions that are non-negative and sparse (i.e.,\ncontain many zero entries). With these constraints, standard methods for\nsolving discrete linear inverse problems are not directly applicable. One such\napproach is the modified residual norm steepest descent (MRNSD), which produces\nnon-negative solutions but does not induce sparsity. In this paper, we provide\ntwo methods based on MRNSD that promote sparsity. In our first method, we add\nan $\\ell_1$-regularization term with a new, optimal step size. In our second\nmethod, we propose a new non-negative, sparsity-promoting mapping of the\nsolution. We compare the performance of our proposed methods on a number of\nnumerical experiments, including deblurring, image completion, computer\ntomography, and superresolution. Our results show that these methods\neffectively solve discrete linear inverse problems with non-negativity and\nsparsity constraints.",
            "author": [
                "Elizabeth Newman",
                "Jack Michael Solomon",
                "Matthias Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03180v1",
                "http://arxiv.org/pdf/2312.03180v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65F10, 65F22",
                "G.1.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03177v1",
            "title": "Using Curiosity for an Even Representation of Tasks in Continual Offline\n  Reinforcement Learning",
            "updated": "2023-12-05T22:53:05Z",
            "published": "2023-12-05T22:53:05Z",
            "summary": "In this work, we investigate the means of using curiosity on replay buffers\nto improve offline multi-task continual reinforcement learning when tasks,\nwhich are defined by the non-stationarity in the environment, are non labeled\nand not evenly exposed to the learner in time. In particular, we investigate\nthe use of curiosity both as a tool for task boundary detection and as a\npriority metric when it comes to retaining old transition tuples, which we\nrespectively use to propose two different buffers. Firstly, we propose a Hybrid\nReservoir Buffer with Task Separation (HRBTS), where curiosity is used to\ndetect task boundaries that are not known due to the task agnostic nature of\nthe problem. Secondly, by using curiosity as a priority metric when it comes to\nretaining old transition tuples, a Hybrid Curious Buffer (HCB) is proposed. We\nultimately show that these buffers, in conjunction with regular reinforcement\nlearning algorithms, can be used to alleviate the catastrophic forgetting issue\nsuffered by the state of the art on replay buffers when the agent's exposure to\ntasks is not equal along time. We evaluate catastrophic forgetting and the\nefficiency of our proposed buffers against the latest works such as the Hybrid\nReservoir Buffer (HRB) and the Multi-Time Scale Replay Buffer (MTR) in three\ndifferent continual reinforcement learning settings. Experiments were done on\nclassical control tasks and Metaworld environment. Experiments show that our\nproposed replay buffers display better immunity to catastrophic forgetting\ncompared to existing works in most of the settings.",
            "author": [
                "Pankayaraj Pathmanathan",
                "Natalia D\u00edaz-Rodr\u00edguez",
                "Javier Del Ser"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03177v1",
                "http://arxiv.org/pdf/2312.03177v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03176v1",
            "title": "Active Learning for Abrupt Shifts Change-point Detection via\n  Derivative-Aware Gaussian Processes",
            "updated": "2023-12-05T22:44:05Z",
            "published": "2023-12-05T22:44:05Z",
            "summary": "Change-point detection (CPD) is crucial for identifying abrupt shifts in\ndata, which influence decision-making and efficient resource allocation across\nvarious domains. To address the challenges posed by the costly and\ntime-intensive data acquisition in CPD, we introduce the Derivative-Aware\nChange Detection (DACD) method. It leverages the derivative process of a\nGaussian process (GP) for Active Learning (AL), aiming to pinpoint change-point\nlocations effectively. DACD balances the exploitation and exploration of\nderivative processes through multiple data acquisition functions (AFs). By\nutilizing GP derivative mean and variance as criteria, DACD sequentially\nselects the next sampling data point, thus enhancing algorithmic efficiency and\nensuring reliable and accurate results. We investigate the effectiveness of\nDACD method in diverse scenarios and show it outperforms other active learning\nchange-point detection approaches.",
            "author": [
                "Hao Zhao",
                "Rong Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03176v1",
                "http://arxiv.org/pdf/2312.03176v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03173v1",
            "title": "A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in\n  Programming Education",
            "updated": "2023-12-05T22:29:43Z",
            "published": "2023-12-05T22:29:43Z",
            "summary": "There is a constant need for educators to develop and maintain effective\nup-to-date assessments. While there is a growing body of research in computing\neducation on utilizing large language models (LLMs) in generation and\nengagement with coding exercises, the use of LLMs for generating programming\nMCQs has not been extensively explored. We analyzed the capability of GPT-4 to\nproduce multiple-choice questions (MCQs) aligned with specific learning\nobjectives (LOs) from Python programming classes in higher education.\nSpecifically, we developed an LLM-powered (GPT-4) system for generation of MCQs\nfrom high-level course context and module-level LOs. We evaluated 651\nLLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python\ncourses. We found that GPT-4 was capable of producing MCQs with clear language,\na single correct choice, and high-quality distractors. We also observed that\nthe generated MCQs appeared to be well-aligned with the LOs. Our findings can\nbe leveraged by educators wishing to take advantage of the state-of-the-art\ngenerative models to support MCQ authoring efforts.",
            "author": [
                "Jacob Doughty",
                "Zipiao Wan",
                "Anishka Bompelli",
                "Jubahed Qayum",
                "Taozhi Wang",
                "Juran Zhang",
                "Yujia Zheng",
                "Aidan Doyle",
                "Pragnya Sridhar",
                "Arav Agarwal",
                "Christopher Bogart",
                "Eric Keylor",
                "Can Kultur",
                "Jaromir Savelka",
                "Majd Sakr"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3636243.3636256",
                "http://arxiv.org/abs/2312.03173v1",
                "http://arxiv.org/pdf/2312.03173v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03171v1",
            "title": "Combining Counting Processes and Classification Improves a Stopping Rule\n  for Technology Assisted Review",
            "updated": "2023-12-05T22:28:42Z",
            "published": "2023-12-05T22:28:42Z",
            "summary": "Technology Assisted Review (TAR) stopping rules aim to reduce the cost of\nmanually assessing documents for relevance by minimising the number of\ndocuments that need to be examined to ensure a desired level of recall. This\npaper extends an effective stopping rule using information derived from a text\nclassifier that can be trained without the need for any additional annotation.\nExperiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal\nand RCV1) showed that the proposed approach consistently improves performance\nand outperforms several alternative methods.",
            "author": [
                "Reem Bin-Hezam",
                "Mark Stevenson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03171v1",
                "http://arxiv.org/pdf/2312.03171v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03166v1",
            "title": "Deep Learning for Fast Inference of Mechanistic Models' Parameters",
            "updated": "2023-12-05T22:16:54Z",
            "published": "2023-12-05T22:16:54Z",
            "summary": "Inferring parameters of macro-kinetic growth models, typically represented by\nOrdinary Differential Equations (ODE), from the experimental data is a crucial\nstep in bioprocess engineering. Conventionally, estimates of the parameters are\nobtained by fitting the mechanistic model to observations. Fitting, however,\nrequires a significant computational power. Specifically, during the\ndevelopment of new bioprocesses that use previously unknown organisms or\nstrains, efficient, robust, and computationally cheap methods for parameter\nestimation are of great value. In this work, we propose using Deep Neural\nNetworks (NN) for directly predicting parameters of mechanistic models given\nobservations. The approach requires spending computational resources for\ntraining a NN, nonetheless, once trained, such a network can provide parameter\nestimates orders of magnitude faster than conventional methods. We consider a\ntraining procedure that combines Neural Networks and mechanistic models. We\ndemonstrate the performance of the proposed algorithms on data sampled from\nseveral mechanistic models used in bioengineering describing a typical\nindustrial batch process and compare the proposed method, a typical\ngradient-based fitting procedure, and the combination of the two. We find that,\nwhile Neural Network estimates are slightly improved by further fitting, these\nestimates are measurably better than the fitting procedure alone.",
            "author": [
                "Maxim Borisyak",
                "Stefan Born",
                "Peter Neubauer",
                "Mariano Nicolas Cruz-Bournazou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03166v1",
                "http://arxiv.org/pdf/2312.03166v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03156v1",
            "title": "Optical coherence storage in dark exciton states using spin-dependent\n  three-pulse photon echo",
            "updated": "2023-12-05T21:44:11Z",
            "published": "2023-12-05T21:44:11Z",
            "summary": "Extension of coherent response time is a desired goal in the field of\nall-optical information processing implemented in classical and quantum ways.\nHere we demonstrate how spin-dependent stimulated photon echo can be used to\nextend decay time of coherent signal from exciton ensemble. We experimentally\nstudied photon echoes from excitons in a model single InGaAs/GaAs quantum well\nsubject to transverse magnetic field. Field-induced quantum beats lead to\noscillation of exciton population between bright and long-lived dark excitons.\nAs a result, photon echo decays much longer with decay time attaining dark\nexciton lifetime in case of non-oscillatory regime.",
            "author": [
                "I. A. Solovev",
                "R. S. Nazarov",
                "A. A. Butiugina",
                "S. A. Eliseev",
                "V. A. Lovcjus",
                "Yu. P. Efimov",
                "Yu. V. Kapitonov",
                "I. A. Yugova"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03156v1",
                "http://arxiv.org/pdf/2312.03156v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03769v1",
            "title": "GPT vs Human for Scientific Reviews: A Dual Source Review on\n  Applications of ChatGPT in Science",
            "updated": "2023-12-05T21:41:52Z",
            "published": "2023-12-05T21:41:52Z",
            "summary": "The new polymath Large Language Models (LLMs) can speed-up greatly scientific\nreviews, possibly using more unbiased quantitative metrics, facilitating\ncross-disciplinary connections, and identifying emerging trends and research\ngaps by analyzing large volumes of data. However, at the present time, they\nlack the required deep understanding of complex methodologies, they have\ndifficulty in evaluating innovative claims, and they are unable to assess\nethical issues and conflicts of interest. Herein, we consider 13 GPT-related\npapers across different scientific domains, reviewed by a human reviewer and\nSciSpace, a large language model, with the reviews evaluated by three distinct\ntypes of evaluators, namely GPT-3.5, a crowd panel, and GPT-4. We found that\n50% of SciSpace's responses to objective questions align with those of a human\nreviewer, with GPT-4 (informed evaluator) often rating the human reviewer\nhigher in accuracy, and SciSpace higher in structure, clarity, and\ncompleteness. In subjective questions, the uninformed evaluators (GPT-3.5 and\ncrowd panel) showed varying preferences between SciSpace and human responses,\nwith the crowd panel showing a preference for the human responses. However,\nGPT-4 rated them equally in accuracy and structure but favored SciSpace for\ncompleteness.",
            "author": [
                "Chenxi Wu",
                "Alan John Varghese",
                "Vivek Oommen",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03769v1",
                "http://arxiv.org/pdf/2312.03769v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03151v1",
            "title": "Multitask Learning Can Improve Worst-Group Outcomes",
            "updated": "2023-12-05T21:38:24Z",
            "published": "2023-12-05T21:38:24Z",
            "summary": "In order to create machine learning systems that serve a variety of users\nwell, it is vital to not only achieve high average performance but also ensure\nequitable outcomes across diverse groups. However, most machine learning\nmethods are designed to improve a model's average performance on a chosen end\ntask without consideration for their impact on worst group error. Multitask\nlearning (MTL) is one such widely used technique. In this paper, we seek not\nonly to understand the impact of MTL on worst-group accuracy but also to\nexplore its potential as a tool to address the challenge of group-wise\nfairness. We primarily consider the common setting of fine-tuning a pre-trained\nmodel, where, following recent work (Gururangan et al., 2020; Dery et al.,\n2023), we multitask the end task with the pre-training objective constructed\nfrom the end task data itself. In settings with few or no group annotations, we\nfind that multitasking often, but not always, achieves better worst-group\naccuracy than Just-Train-Twice (JTT; Liu et al. (2021)) -- a representative\ndistributionally robust optimization (DRO) method. Leveraging insights from\nsynthetic data experiments, we propose to modify standard MTL by regularizing\nthe joint multitask representation space. We run a large number of fine-tuning\nexperiments across computer vision and natural language and find that our\nregularized MTL approach consistently outperforms JTT on both worst and average\ngroup outcomes. Our official code can be found here:\nhttps://github.com/atharvajk98/MTL-group-robustness.",
            "author": [
                "Atharva Kulkarni",
                "Lucio Dery",
                "Amrith Setlur",
                "Aditi Raghunathan",
                "Ameet Talwalkar",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03151v1",
                "http://arxiv.org/pdf/2312.03151v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03150v1",
            "title": "Strongly coupled edge states in a graphene quantum Hall interferometer",
            "updated": "2023-12-05T21:38:09Z",
            "published": "2023-12-05T21:38:09Z",
            "summary": "Electronic interferometers using the chiral, one-dimensional (1D) edge\nchannels of the quantum Hall effect (QHE) can demonstrate a wealth of\nfundamental phenomena. The recent observation of phase jumps in a single edge\nchannel Fabry-P\\'erot (FP) interferometer revealed anyonic quasiparticle\nexchange statistics in the fractional QHE. When multiple edge channels are\ninvolved, FP interferometers have exhibited anomalous Aharonov-Bohm (AB)\ninterference frequency doubling, suggesting interference of 2e quasiparticles.\nHere, we use a highly tunable graphene-based QHE FP interferometer to observe\nthe connection between integer QHE interference phase jumps and AB frequency\ndoubling, unveiling the intricate nature of inter edge state coupling in a\nmultichannel QHE interferometer. By tuning the electron density continuously\nfrom the QHE filling factor {\\nu}<2 to {\\nu}>7, we observe periodic\ninterference phase jumps leading to AB frequency doubling. Our observations\nclearly demonstrate that in our samples the combination of repulsive Coulomb\ninteraction between the spin-split, copropagating edge channels and charge\nquantization explains the frequency-doubled regime without electron pairing,\nvia a near-perfect anti-correlation between the two edge channels. Our results\nshow that interferometers are sensitive probes of microscopic interactions\nbetween edge states, which can cause strong correlations between chiral 1D\nchannels even in the integer QHE regime.",
            "author": [
                "Thomas Werkmeister",
                "James R. Ehrets",
                "Yuval Ronen",
                "Marie E. Wesson",
                "Danial Najafabadi",
                "Zezhu Wei",
                "Kenji Watanabe",
                "Takashi Taniguchi",
                "D. E. Feldman",
                "Bertrand I. Halperin",
                "Amir Yacoby",
                "Philip Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03150v1",
                "http://arxiv.org/pdf/2312.03150v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03146v1",
            "title": "LRMP: Layer Replication with Mixed Precision for Spatial In-memory DNN\n  Accelerators",
            "updated": "2023-12-05T21:31:20Z",
            "published": "2023-12-05T21:31:20Z",
            "summary": "In-memory computing (IMC) with non-volatile memories (NVMs) has emerged as a\npromising approach to address the rapidly growing computational demands of Deep\nNeural Networks (DNNs). Mapping DNN layers spatially onto NVM-based IMC\naccelerators achieves high degrees of parallelism. However, two challenges that\narise in this approach are the highly non-uniform distribution of layer\nprocessing times and high area requirements. We propose LRMP, a method to\njointly apply layer replication and mixed precision quantization to improve the\nperformance of DNNs when mapped to area-constrained NVM-based IMC accelerators.\nLRMP uses a combination of reinforcement learning and integer linear\nprogramming to search the replication-quantization design space using a model\nthat is closely informed by the target hardware architecture. Across five DNN\nbenchmarks, LRMP achieves 2.8-9$\\times$ latency and 11.8-19$\\times$ throughput\nimprovement at iso-accuracy.",
            "author": [
                "Abinand Nallathambi",
                "Christin David Bose",
                "Wilfried Haensch",
                "Anand Raghunathan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03146v1",
                "http://arxiv.org/pdf/2312.03146v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03141v1",
            "title": "In-Storage Acceleration of Graph-Traversal-Based Approximate Nearest\n  Neighbor Search",
            "updated": "2023-12-05T21:21:01Z",
            "published": "2023-12-05T21:21:01Z",
            "summary": "Approximate nearest neighbor search (ANNS) is a key retrieval technique for\nvector database and many data center applications, such as person\nre-identification and recommendation systems. Among all the ANNS algorithms,\ngraph-traversal-based ANNS achieves the highest recall rate. However, as the\nsize of dataset increases, the graph may require hundreds of gigabytes of\nmemory, exceeding the main memory capacity of a single workstation node.\nAlthough we can do partitioning and use solid-state drive (SSD) as the backing\nstorage, the limited SSD I/O bandwidth severely degrades the performance of the\nsystem. To address this challenge, we present NDSearch, a near-data processing\n(NDP) solution for ANNS processing. NDSearch consists of a novel in-storage\ncomputing architecture, namely, SEARSSD, that supports the ANNS kernels and\nleverages logic unit (LUN)-level parallelism inside the NAND flash chips.\nNDSearch also includes a processing model that is customized for NDP and\ncooperates with SEARSSD. The processing model enables us to apply a two-level\nscheduling to improve the data locality and exploit the internal bandwidth in\nNDSEARCH, and a speculative searching mechanism to further accelerate the ANNS\nworkload. Our results show that NDSearch improves the throughput by up to\n31.7x, 14.6x, 7.4x, 2.9x over CPU, GPU, a state-of-the-art SmartSSD-only\ndesign, and DeepStore, respectively. NDSEARCH also achieves two\norders-of-magnitude higher energy efficiency than CPU and GPU.",
            "author": [
                "Yitu Wang",
                "Shiyu Li",
                "Qilin Zheng",
                "Linghao Song",
                "Zongwang Li",
                "Andrew Chang",
                "Hai \"Helen\" Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03141v1",
                "http://arxiv.org/pdf/2312.03141v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03140v1",
            "title": "FlexModel: A Framework for Interpretability of Distributed Large\n  Language Models",
            "updated": "2023-12-05T21:19:33Z",
            "published": "2023-12-05T21:19:33Z",
            "summary": "With the growth of large language models, now incorporating billions of\nparameters, the hardware prerequisites for their training and deployment have\nseen a corresponding increase. Although existing tools facilitate model\nparallelization and distributed training, deeper model interactions, crucial\nfor interpretability and responsible AI techniques, still demand thorough\nknowledge of distributed computing. This often hinders contributions from\nresearchers with machine learning expertise but limited distributed computing\nbackground. Addressing this challenge, we present FlexModel, a software package\nproviding a streamlined interface for engaging with models distributed across\nmulti-GPU and multi-node configurations. The library is compatible with\nexisting model distribution libraries and encapsulates PyTorch models. It\nexposes user-registerable HookFunctions to facilitate straightforward\ninteraction with distributed model internals, bridging the gap between\ndistributed and single-device model paradigms. Primarily, FlexModel enhances\naccessibility by democratizing model interactions and promotes more inclusive\nresearch in the domain of large-scale neural networks. The package is found at\nhttps://github.com/VectorInstitute/flex_model.",
            "author": [
                "Matthew Choi",
                "Muhammad Adil Asif",
                "John Willes",
                "David Emerson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03140v1",
                "http://arxiv.org/pdf/2312.03140v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03137v1",
            "title": "The Role of Net-Zero Energy Residential Buildings in Florida's Energy\n  Transition: Economic Analysis and Technical Benefits",
            "updated": "2023-12-05T21:09:09Z",
            "published": "2023-12-05T21:09:09Z",
            "summary": "Net-zero emission policies, coupled with declining costs of renewables,\nbattery storage, and electric vehicles, require both direct and indirect\nelectrification (such as green hydrogen) of the energy infrastructure to\naddress climate change impacts, improve resilience, and lower energy expenses.\nIn this paper, a comprehensive techno-economic analysis was performed that\nintegrated net-zero energy buildings within the context of Florida energy\ntransition by the year 2050. The analysis compares the monthly cost savings of\nowning photovoltaic (PV) on the roof, battery storage, and Electric Vehicle\n(EV) to the cost of buying electricity from the grid for both existing and\nnewly built Orlando homes. The impact of income tax credits (ITC) and energy\nefficiency improvements on monthly savings was taken into account. The\nlevelized cost of electricity for residential PV and PV + battery systems was\ndetermined and extended to provide a cost equivalent to gasoline for an average\nEV. Rooftop solar fueling an EV for 10,000 miles saves \\$100 per month over\npurchasing gasoline. Today, Florida residents can save on their monthly costs\nof electricity and gasoline if they have both PV on their roof and a battery\nsystem (sized for average daily residence load), and benefit from the federal\nITC. Florida residents can cost-effectively transition to their own solar,\nbattery storage, and electric vehicle to home systems. Allowing utility-scale\nsolar to be used for on-site EV fast-charging and hydrogen production through\nelectrolysis for fuel cell vehicles or blending with natural gas, minimizing\nthe need for electricity transmission and distribution costs across the power\ngrids.",
            "author": [
                "Hamed Haggi",
                "James M. Fenton"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03137v1",
                "http://arxiv.org/pdf/2312.03137v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03134v1",
            "title": "A Hardware Evaluation Framework for Large Language Model Inference",
            "updated": "2023-12-05T21:01:33Z",
            "published": "2023-12-05T21:01:33Z",
            "summary": "The past year has witnessed the increasing popularity of Large Language\nModels (LLMs). Their unprecedented scale and associated high hardware cost have\nimpeded their broader adoption, calling for efficient hardware designs. With\nthe large hardware needed to simply run LLM inference, evaluating different\nhardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM\ninference workloads. LLMCompass is fast, accurate, versatile, and able to\ndescribe and evaluate different hardware designs. LLMCompass includes a mapper\nto automatically find performance-optimal mapping and scheduling. It also\nincorporates an area-based cost model to help architects reason about their\ndesign choices. Compared to real-world hardware, LLMCompass' estimated latency\nachieves an average 10.4% error rate across various operators with various\ninput sizes and an average 4.1% error rate for LLM inference. With LLMCompass,\nsimulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done\nwithin 16 minutes on commodity hardware, including 26,400 rounds of the\nmapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and\nexplores new cost-effective hardware designs. By reducing the compute\ncapability or replacing High Bandwidth Memory (HBM) with traditional DRAM,\nthese new designs can achieve as much as 3.41x improvement in performance/cost\ncompared to an NVIDIA A100, making them promising choices for democratizing\nLLMs.\n  LLMCompass is planned to be fully open-source.",
            "author": [
                "Hengrui Zhang",
                "August Ning",
                "Rohan Prabhakar",
                "David Wentzlaff"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03134v1",
                "http://arxiv.org/pdf/2312.03134v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03133v1",
            "title": "Predicting Bone Degradation Using Vision Transformer and Synthetic\n  Cellular Microstructures Dataset",
            "updated": "2023-12-05T21:00:08Z",
            "published": "2023-12-05T21:00:08Z",
            "summary": "Bone degradation, especially for astronauts in microgravity conditions, is\ncrucial for space exploration missions since the lower applied external forces\naccelerate the diminution in bone stiffness and strength substantially.\nAlthough existing computational models help us understand this phenomenon and\npossibly restrict its effect in the future, they are time-consuming to simulate\nthe changes in the bones, not just the bone microstructures, of each individual\nin detail. In this study, a robust yet fast computational method to predict and\nvisualize bone degradation has been developed. Our deep-learning method,\nTransVNet, can take in different 3D voxelized images and predict their\nevolution throughout months utilizing a hybrid 3D-CNN-VisionTransformer\nautoencoder architecture. Because of limited available experimental data and\nchallenges of obtaining new samples, a digital twin dataset of diverse and\ninitial bone-like microstructures was generated to train our TransVNet on the\nevolution of the 3D images through a previously developed degradation model for\nmicrogravity.",
            "author": [
                "Mohammad Saber Hashemi",
                "Azadeh Sheidaei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03133v1",
                "http://arxiv.org/pdf/2312.03133v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03129v1",
            "title": "Leveraging Laryngograph Data for Robust Voicing Detection in Speech",
            "updated": "2023-12-05T20:57:00Z",
            "published": "2023-12-05T20:57:00Z",
            "summary": "Accurately detecting voiced intervals in speech signals is a critical step in\npitch tracking and has numerous applications. While conventional signal\nprocessing methods and deep learning algorithms have been proposed for this\ntask, their need to fine-tune threshold parameters for different datasets and\nlimited generalization restrict their utility in real-world applications. To\naddress these challenges, this study proposes a supervised voicing detection\nmodel that leverages recorded laryngograph data. The model is based on a\ndensely-connected convolutional recurrent neural network (DC-CRN), and trained\non data with reference voicing decisions extracted from laryngograph data sets.\nPretraining is also investigated to improve the generalization ability of the\nmodel. The proposed model produces robust voicing detection results,\noutperforming other strong baseline methods, and generalizes well to unseen\ndatasets. The source code of the proposed model with pretraining is provided\nalong with the list of used laryngograph datasets to facilitate further\nresearch in this area.",
            "author": [
                "Yixuan Zhang",
                "Heming Wang",
                "DeLiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03129v1",
                "http://arxiv.org/pdf/2312.03129v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03122v1",
            "title": "Assertion Enhanced Few-Shot Learning: Instructive Technique for Large\n  Language Models to Generate Educational Explanations",
            "updated": "2023-12-05T20:41:34Z",
            "published": "2023-12-05T20:41:34Z",
            "summary": "Human educators possess an intrinsic ability to anticipate and seek\neducational explanations from students, which drives them to pose\nthought-provoking questions when students cannot articulate these explanations\nindependently. We aim to imbue Intelligent Tutoring Systems with this ability\nusing few-shot learning capability of Large Language Models. Our work proposes\na novel prompting technique, Assertion Enhanced Few-Shot Learning, to\nfacilitate the generation of accurate, detailed oriented educational\nexplanations. Our central hypothesis is that, in educational domain, few-shot\ndemonstrations are necessary but not a sufficient condition for quality\nexplanation generation. We conducted a study involving 12 in-service teachers,\ncomparing our approach to Traditional Few-Shot Learning. The results show that\nAssertion Enhanced Few-Shot Learning improves explanation accuracy by 15% and\nyields higher-quality explanations, as evaluated by teachers. We also conduct a\nqualitative ablation study to factor the impact of assertions to provide\neducator-friendly prompting guidelines for generating explanations in their\ndomain of interest.",
            "author": [
                "Tasmia Shahriar",
                "Noboru Matsuda",
                "Kelly Ramos"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03122v1",
                "http://arxiv.org/pdf/2312.03122v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03121v2",
            "title": "Evaluating Agents using Social Choice Theory",
            "updated": "2023-12-07T02:16:24Z",
            "published": "2023-12-05T20:40:37Z",
            "summary": "We argue that many general evaluation problems can be viewed through the lens\nof voting theory. Each task is interpreted as a separate voter, which requires\nonly ordinal rankings or pairwise comparisons of agents to produce an overall\nevaluation. By viewing the aggregator as a social welfare function, we are able\nto leverage centuries of research in social choice theory to derive principled\nevaluation frameworks with axiomatic foundations. These evaluations are\ninterpretable and flexible, while avoiding many of the problems currently\nfacing cross-task evaluation. We apply this Voting-as-Evaluation (VasE)\nframework across multiple settings, including reinforcement learning, large\nlanguage models, and humans. In practice, we observe that VasE can be more\nrobust than popular evaluation frameworks (Elo and Nash averaging), discovers\nproperties in the evaluation data not evident from scores alone, and can\npredict outcomes better than Elo in a complex seven-player game. We identify\none particular approach, maximal lotteries, that satisfies important\nconsistency properties relevant to evaluation, is computationally efficient\n(polynomial in the size of the evaluation data), and identifies game-theoretic\ncycles.",
            "author": [
                "Marc Lanctot",
                "Kate Larson",
                "Yoram Bachrach",
                "Luke Marris",
                "Zun Li",
                "Avishkar Bhoopchand",
                "Thomas Anthony",
                "Brian Tanner",
                "Anna Koop"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03121v2",
                "http://arxiv.org/pdf/2312.03121v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.GT",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03118v1",
            "title": "Longitudinal (curvature) couplings of an $N$-level qudit to a\n  superconducting resonator at the adiabatic limit and beyond",
            "updated": "2023-12-05T20:33:59Z",
            "published": "2023-12-05T20:33:59Z",
            "summary": "Understanding how and to what magnitude solid-state qubits couple to metallic\nwires is crucial to the design of quantum systems such as quantum computers.\nHere, we investigate the coupling between a multi-level system, or qudit, and a\nsuperconducting (SC) resonator's electromagnetic field, focusing on the\ninteraction involving both the transition and diagonal dipole moments of the\nqudit. Specifically, we explore the effective dynamical (time-dependent)\nlongitudinal coupling that arises when a solid-state qudit is adiabatically\nmodulated at small gate frequencies and amplitudes, in addition to a static\ndispersive interaction with the SC resonator. For the first time, we derive\nHamiltonians describing the longitudinal multi-level interactions in a general\ndispersive regime, encompassing both dynamical longitudinal and dispersive\ninteractions. These Hamiltonians smoothly transition between their adiabatic\nvalues, where the couplings of the n-th level are proportional to the level's\nenergy curvature concerning a qudit gate voltage, and the substantially larger\ndispersive values, which occur due to a resonant form factor. We provide\nseveral examples illustrating the transition from adiabatic to dispersive\ncoupling in different qubit systems, including the charge (1e DQD) qubit, the\ntransmon, the double quantum dot singlet-triplet qubit, and the triple quantum\ndot exchange-only qubit. In some of these qubits, higher energy levels play a\ncritical role, particularly when their qubit's dipole moment is minimal or\nzero. For an experimentally relevant scenario involving a spin-charge qubit\nwith magnetic field gradient coupled capacitively to a SC resonator, we\nshowcase the potential of these interactions. They enable\nclose-to-quantum-limited quantum non-demolition (QND) measurements and remote\ngeometric phase gates, demonstrating their practical utility in quantum\ninformation processing.",
            "author": [
                "Rusko Ruskov",
                "Charles Tahan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03118v1",
                "http://arxiv.org/pdf/2312.03118v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03117v1",
            "title": "Fractal packing of nanomaterials",
            "updated": "2023-12-05T20:33:38Z",
            "published": "2023-12-05T20:33:38Z",
            "summary": "Cohesive particles form agglomerates that are usually very porous. Their\ngeometry, particularly their fractal dimension, depends on the agglomeration\nprocess (diffusion-limited or ballistic growth by adding single particles or\ncluster-cluster aggregation). However, in practice, the packing structure\ndepends not only on the initial formation but also on the mechanical processing\nof the agglomerate after it has grown. Surprisingly, the packing converges to a\nstatistically invariant structure under certain process conditions, independent\nof the initial growth process. We consider the repeated fragmentation on a\ngiven length scale, followed by ballistic agglomeration. Examples of\nfragmentation are sieving with a given mesh size or dispersion in a turbulent\nfluid. We model the agglomeration by gravitational sedimentation. The\nasymptotic structure is fractal up to the fragmentation length scale, and the\nfragments have a power-law size distribution. A scaling relation connects the\npower law and the fractal dimension.",
            "author": [
                "Dietrich E. Wolf",
                "Thorsten P\u00f6schel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03117v1",
                "http://arxiv.org/pdf/2312.03117v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "nlin.AO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03115v1",
            "title": "Mitigation of the Brighter-Fatter Effect in the LSST Camera",
            "updated": "2023-12-05T20:22:11Z",
            "published": "2023-12-05T20:22:11Z",
            "summary": "Thick, fully depleted charge-coupled devices (CCDs) are known to exhibit\nnon-linear behavior at high signal levels due to the dynamic behavior of\ncharges collecting in the potential wells of pixels, called the brighter-fatter\neffect (BFE). This particularly impacts bright calibration stars, which appear\nlarger than their intrinsic shape, creating a flux-dependent point-spread\nfunction (PSF) that if left unmitigated, could make up a large fraction of the\nerror budget in Stage IV weak-lensing (WL) surveys such as the Legacy Survey of\nSpace and Time (LSST). In this paper, we analyze image measurements of flat\nfields and artificial stars taken at different illumination levels with the\nLSST Camera (LSSTCam) at SLAC National Accelerator Laboratory in order to\nquantify this effect in the LSST Camera before and after a previously\nintroduced correction technique. We observe that the BFE evolves\nanisotropically as a function of flux due to higher-order BFEs, which violates\nthe fundamental assumption of this correction method. We then introduce a new\nsampling method based on a physically motivated model to account these\nhigher-order terms in the correction, and then we test the modified correction\non both datasets. We find that the new method corrects the effect in flat\nfields better than it corrects the effect in artificial stars which we conclude\nis the result of a unmodeled curl component of the deflection field by the\ncorrection. We use these results to define a new metric for the full-well\ncapacity of our sensors and advise image processing strategies to further limit\nthe impact of the effect on LSST WL science pathways.",
            "author": [
                "Alex Broughton",
                "Yousuke Utsumi",
                "Andr\u00e9s Plazas Malag\u00f3n",
                "Christopher Waters",
                "Craig Lage",
                "Adam Snyder",
                "Andrew Rasmussen",
                "Stuart Marshall",
                "Jim Chiang",
                "Simona Murgia",
                "Aaron Roodman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03115v1",
                "http://arxiv.org/pdf/2312.03115v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03113v1",
            "title": "GPU Graph Processing on CXL-Based Microsecond-Latency External Memory",
            "updated": "2023-12-05T20:17:38Z",
            "published": "2023-12-05T20:17:38Z",
            "summary": "In GPU graph analytics, the use of external memory such as the host DRAM and\nsolid-state drives is a cost-effective approach to processing large graphs\nbeyond the capacity of the GPU onboard memory. This paper studies the use of\nCompute Express Link (CXL) memory as alternative external memory for GPU graph\nprocessing in order to see if this emerging memory expansion technology enables\ngraph processing that is as fast as using the host DRAM. Through analysis and\nevaluation using FPGA prototypes, we show that representative GPU graph\ntraversal algorithms involving fine-grained random access can tolerate an\nexternal memory latency of up to a few microseconds introduced by the CXL\ninterface as well as by the underlying memory devices. This insight indicates\nthat microsecond-latency flash memory may be used as CXL memory devices to\nrealize even more cost-effective GPU graph processing while still achieving\nperformance close to using the host DRAM.",
            "author": [
                "Shintaro Sano",
                "Yosuke Bando",
                "Kazuhiro Hiwada",
                "Hirotsugu Kajihara",
                "Tomoya Suzuki",
                "Yu Nakanishi",
                "Daisuke Taki",
                "Akiyuki Kaneko",
                "Tatsuo Shiozawa"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3624062.3624173",
                "http://arxiv.org/abs/2312.03113v1",
                "http://arxiv.org/pdf/2312.03113v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03766v1",
            "title": "Mismatch Quest: Visual and Textual Feedback for Image-Text Misalignment",
            "updated": "2023-12-05T20:07:34Z",
            "published": "2023-12-05T20:07:34Z",
            "summary": "While existing image-text alignment models reach high quality binary\nassessments, they fall short of pinpointing the exact source of misalignment.\nIn this paper, we present a method to provide detailed textual and visual\nexplanation of detected misalignments between text-image pairs. We leverage\nlarge language models and visual grounding models to automatically construct a\ntraining set that holds plausible misaligned captions for a given image and\ncorresponding textual explanations and visual indicators. We also publish a new\nhuman curated test set comprising ground-truth textual and visual misalignment\nannotations. Empirical results show that fine-tuning vision language models on\nour training set enables them to articulate misalignments and visually indicate\nthem within images, outperforming strong baselines both on the binary alignment\nclassification and the explanation generation tasks. Our method code and human\ncurated test set are available at: https://mismatch-quest.github.io/",
            "author": [
                "Brian Gordon",
                "Yonatan Bitton",
                "Yonatan Shafir",
                "Roopal Garg",
                "Xi Chen",
                "Dani Lischinski",
                "Daniel Cohen-Or",
                "Idan Szpektor"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03766v1",
                "http://arxiv.org/pdf/2312.03766v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03107v2",
            "title": "Short-lived repeating fast radio bursts from tidal disruption of white\n  dwarfs by intermediate-mass black holes",
            "updated": "2023-12-07T13:42:18Z",
            "published": "2023-12-05T20:06:01Z",
            "summary": "The origin of repeating fast radio bursts (RFRBs) is still a mystery. We\npropose that short-lived RFRBs might be triggered from the tidal disruption of\nwhite dwarfs (WDs) by intermediate-mass black holes (BHs). In this model, we\nshow that the remnant WD clusters after tidal collapse cuts the magnetic lines\non the BH accretion discs, and during each fall of the clump, so that electrons\nare torn from the surface of the mass and instantly accelerated to the\nrelativistic energy. The subsequent movement of these electrons along magnetic\nfield lines will result in coherent curvature radiation. This short-lived radio\ntransients might accompany with the accretion process. The luminosity and the\ntimescale can be estimated to be $L_\\mathrm{tot}\\sim 1.96\\times10^{40}~{\\rm\nerg~s^{-1}}$ and $\\Delta t\\sim1.14~{\\rm ms}$, respectively, which are\nconsistent with the typical properties of RFRBs. Moreover, the total event rate\nof our model for generating RFRBs might be as high as $\\sim 10~\\rm\n{yr^{-1}~Gpc^{-3}}$.",
            "author": [
                "Jing-Tong Xing",
                "Tong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03107v2",
                "http://arxiv.org/pdf/2312.03107v2"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03103v2",
            "title": "Chemical strategies to mitigate electrostatic charging during coffee\n  grinding",
            "updated": "2023-12-07T02:14:14Z",
            "published": "2023-12-05T19:49:14Z",
            "summary": "The process of grinding coffee generates particles with high levels of\nelectrostatic charge, causing a number of detrimental effects such as clumping,\nparticle dispersal, and spark discharges. At the brewing level, electrostatic\naggregation between particles affects liquid-solid accessibility, leading to\nvariable extraction quality. In this study, we quantify the effectiveness of\nfour charge mitigation strategies. Our data suggests that adding small amounts\nof water to whole beans pre-grinding, or bombarding the grounds with ions\nproduced from a high-voltage ionizer, are capable of de-electrifying the\ngranular flows. While these techniques helped reduce visible mess, only the\nstatic reduction through water inclusion was found to impact the brewing\nparameters in espresso format coffee. There, wetting coffee with less than 0.05\nmL / g resulted in a marked shift in particle size distribution, in part due to\npreventing clump formation and also liberating fine particles from sticking to\nthe grinder. With all other variables kept constant, this shift resulted at\nleast 15% higher coffee concentration for espresso prepared with darker roasts.\nThese findings have significant financial and sustainability implications, and\nencourage the widespread implementation of water use to de-electrify coffee\nduring grinding.",
            "author": [
                "Joshua M\u00e9ndez Harper",
                "Christopher H. Hendon"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03103v2",
                "http://arxiv.org/pdf/2312.03103v2"
            ],
            "primary_category": "physics.pop-ph",
            "category": [
                "physics.pop-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03102v1",
            "title": "Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI",
            "updated": "2023-12-05T19:45:44Z",
            "published": "2023-12-05T19:45:44Z",
            "summary": "In magnetic resonance imaging (MRI), slice-to-volume reconstruction (SVR)\nrefers to computational reconstruction of an unknown 3D magnetic resonance\nvolume from stacks of 2D slices corrupted by motion. While promising, current\nSVR methods require multiple slice stacks for accurate 3D reconstruction,\nleading to long scans and limiting their use in time-sensitive applications\nsuch as fetal fMRI. Here, we propose a SVR method that overcomes the\nshortcomings of previous work and produces state-of-the-art reconstructions in\nthe presence of extreme inter-slice motion. Inspired by the recent success of\nsingle-view depth estimation methods, we formulate SVR as a single-stack motion\nestimation task and train a fully convolutional network to predict a motion\nstack for a given slice stack, producing a 3D reconstruction as a byproduct of\nthe predicted motion. Extensive experiments on the SVR of adult and fetal\nbrains demonstrate that our fully convolutional method is twice as accurate as\nprevious SVR methods. Our code is available at github.com/seannz/svr.",
            "author": [
                "Sean I. Young",
                "Ya\u00ebl Balbastre",
                "Bruce Fischl",
                "Polina Golland",
                "Juan Eugenio Iglesias"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03102v1",
                "http://arxiv.org/pdf/2312.03102v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03098v1",
            "title": "ST-Distributive and ST-Modular Lattices",
            "updated": "2023-12-05T19:33:25Z",
            "published": "2023-12-05T19:33:25Z",
            "summary": "For two subsets S and T of a given lattice L, we define a relative\ndistributive (modular) property over L, that underlies a large family including\nthe usual class of distributive (modular) lattices. Our proposed class will be\ncalled ST-distributive (ST-modular) lattices. In this paper, we explore\nelemental properties of ST-distributivity (ST-modularity) and find examples of\nmaximal S and T to form ST-distributive lattices for some non-distributive\nfinite lattices of small order. We also characterize the maximal pairs of\nsubsets (S,T), subject to certain constraints, that induce ST-distributivity in\nthe lattice family M_n,n for all natural numbers n greater than or equal to 3.\nAfterwards, we present an application of ST-modular to convex sets and\npolytopes. This application has been the first example found and the main\nguiding light for our new definitions. The aforementioned definitions are\nclosely related to distributive elements of Birkhoff-Gratzer and Stanley's\nSS-lattices.",
            "author": [
                "M. R. Emamy-K.",
                "Gustavo A. Melendez Rios"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03098v1",
                "http://arxiv.org/pdf/2312.03098v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "Primary: 06D75, Secondary: 06C99, 52A99, 52B99"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03097v1",
            "title": "State of Health Estimation for Battery Modules with Parallel-Connected\n  Cells Under Cell-to-Cell Variations",
            "updated": "2023-12-05T19:33:03Z",
            "published": "2023-12-05T19:33:03Z",
            "summary": "State of health (SOH) estimation for lithium-ion battery modules with cells\nconnected in parallel is a challenging problem, especially with cell-to-cell\nvariations. Incremental capacity analysis (ICA) and differential voltage\nanalysis (DVA) are effective at the cell level, but they cannot be directly\napplied to module-level SOH estimation, when only module-level measurements are\navailable. This paper proposes a new method and demonstrates that, with\nmultiple features systematically selected from the module-level ICA and DVA,\nthe module-level SOH can be estimated with high accuracy and confidence in the\npresence of cell-to-cell variations. First, a new information theory-based\nfeature selection algorithm is proposed to find an optimal set of features for\nmodule-level SOH estimation. Second, a new relevance vector regression\n(RVR)-based module-level SOH estimation model is proposed to provide both point\nestimates and three-sigma credible intervals while maintaining model sparsity.\nExperimental datasets are used to illustrate and evaluate the proposed method.\nWith more selected features incorporated, the proposed method achieves better\nestimation accuracy and higher confidence at the expense of higher model\ncomplexity. This trade-off is explored through a case study. When applied to a\nlarge experimental dataset, the proposed method and the resulting sparse model\nlead to module-level SOH estimates with 0.5% root-mean-square errors and 1.5%\naverage three-sigma values. With all the optimization and training processes\ncompleted offboard, the proposed method has low computational complexity for\nonboard implementations.",
            "author": [
                "Qinan Zhou",
                "Dyche Anderson",
                "Jing Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03097v1",
                "http://arxiv.org/pdf/2312.03097v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03096v1",
            "title": "Incidental Polysemanticity",
            "updated": "2023-12-05T19:29:54Z",
            "published": "2023-12-05T19:29:54Z",
            "summary": "Polysemantic neurons (neurons that activate for a set of unrelated features)\nhave been seen as a significant obstacle towards interpretability of\ntask-optimized deep networks, with implications for AI safety. The classic\norigin story of polysemanticity is that the data contains more \"features\" than\nneurons, such that learning to perform a task forces the network to co-allocate\nmultiple unrelated features to the same neuron, endangering our ability to\nunderstand the network's internal processing. In this work, we present a second\nand non-mutually exclusive origin story of polysemanticity. We show that\npolysemanticity can arise incidentally, even when there are ample neurons to\nrepresent all features in the data, using a combination of theory and\nexperiments. This second type of polysemanticity occurs because random\ninitialization can, by chance alone, initially assign multiple features to the\nsame neuron, and the training dynamics then strengthen such overlap. Due to its\norigin, we term this \\textit{incidental polysemanticity}.",
            "author": [
                "Victor Lecomte",
                "Kushal Thaman",
                "Trevor Chow",
                "Rylan Schaeffer",
                "Sanmi Koyejo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03096v1",
                "http://arxiv.org/pdf/2312.03096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03095v1",
            "title": "Understanding Environmental Posts: Sentiment and Emotion Analysis of\n  Social Media Data",
            "updated": "2023-12-05T19:26:28Z",
            "published": "2023-12-05T19:26:28Z",
            "summary": "Social media is now the predominant source of information due to the\navailability of immediate public response. As a result, social media data has\nbecome a valuable resource for comprehending public sentiments. Studies have\nshown that it can amplify ideas and influence public sentiments. This study\nanalyzes the public perception of climate change and the environment over a\ndecade from 2014 to 2023. Using the Pointwise Mutual Information (PMI)\nalgorithm, we identify sentiment and explore prevailing emotions expressed\nwithin environmental tweets across various social media platforms, namely\nTwitter, Reddit, and YouTube. Accuracy on a human-annotated dataset was 0.65,\nhigher than Vader score but lower than that of an expert rater (0.90). Our\nfindings suggest that negative environmental tweets are far more common than\npositive or neutral ones. Climate change, air quality, emissions, plastic, and\nrecycling are the most discussed topics on all social media platforms,\nhighlighting its huge global concern. The most common emotions in environmental\ntweets are fear, trust, and anticipation, demonstrating public reactions wide\nand complex nature. By identifying patterns and trends in opinions related to\nthe environment, we hope to provide insights that can help raise awareness\nregarding environmental issues, inform the development of interventions, and\nadapt further actions to meet environmental challenges.",
            "author": [
                "Daniyar Amangeldi",
                "Aida Usmanova",
                "Pakizar Shamoi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03095v1",
                "http://arxiv.org/pdf/2312.03095v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03764v1",
            "title": "Similarity-based Knowledge Transfer for Cross-Domain Reinforcement\n  Learning",
            "updated": "2023-12-05T19:26:01Z",
            "published": "2023-12-05T19:26:01Z",
            "summary": "Transferring knowledge in cross-domain reinforcement learning is a\nchallenging setting in which learning is accelerated by reusing knowledge from\na task with different observation and/or action space. However, it is often\nnecessary to carefully select the source of knowledge for the receiving end to\nbenefit from the transfer process. In this article, we study how to measure the\nsimilarity between cross-domain reinforcement learning tasks to select a source\nof knowledge that will improve the performance of the learning agent. We\ndeveloped a semi-supervised alignment loss to match different spaces with a set\nof encoder-decoders, and use them to measure similarity and transfer policies\nacross tasks. In comparison to prior works, our method does not require data to\nbe aligned, paired or collected by expert policies. Experimental results, on a\nset of varied Mujoco control tasks, show the robustness of our method in\neffectively selecting and transferring knowledge, without the supervision of a\ntailored set of source tasks.",
            "author": [
                "Sergio A. Serrano",
                "Jose Martinez-Carranza",
                "L. Enrique Sucar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03764v1",
                "http://arxiv.org/pdf/2312.03764v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T37, 68T42, 68T07, 68T05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03093v1",
            "title": "RESIN-EDITOR: A Schema-guided Hierarchical Event Graph Visualizer and\n  Editor",
            "updated": "2023-12-05T19:25:38Z",
            "published": "2023-12-05T19:25:38Z",
            "summary": "In this paper, we present RESIN-EDITOR, an interactive event graph visualizer\nand editor designed for analyzing complex events. Our RESIN-EDITOR system\nallows users to render and freely edit hierarchical event graphs extracted from\nmultimedia and multi-document news clusters with guidance from human-curated\nevent schemas. RESIN-EDITOR's unique features include hierarchical graph\nvisualization, comprehensive source tracing, and interactive user editing,\nwhich is more powerful and versatile than existing Information Extraction (IE)\nvisualization tools. In our evaluation of RESIN-EDITOR, we demonstrate ways in\nwhich our tool is effective in understanding complex events and enhancing\nsystem performance. The source code, a video demonstration, and a live website\nfor RESIN-EDITOR have been made publicly available.",
            "author": [
                "Khanh Duy Nguyen",
                "Zixuan Zhang",
                "Reece Suchocki",
                "Sha Li",
                "Martha Palmer",
                "Susan Brown",
                "Jiawei Han",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03093v1",
                "http://arxiv.org/pdf/2312.03093v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03088v1",
            "title": "LLMs for Multi-Modal Knowledge Extraction and Analysis in\n  Intelligence/Safety-Critical Applications",
            "updated": "2023-12-05T19:04:50Z",
            "published": "2023-12-05T19:04:50Z",
            "summary": "Large Language Models have seen rapid progress in capability in recent years;\nthis progress has been accelerating and their capabilities, measured by various\nbenchmarks, are beginning to approach those of humans. There is a strong demand\nto use such models in a wide variety of applications but, due to unresolved\nvulnerabilities and limitations, great care needs to be used before applying\nthem to intelligence and safety-critical applications. This paper reviews\nrecent literature related to LLM assessment and vulnerabilities to synthesize\nthe current research landscape and to help understand what advances are most\ncritical to enable use of of these technologies in intelligence and\nsafety-critical applications. The vulnerabilities are broken down into ten\nhigh-level categories and overlaid onto a high-level life cycle of an LLM. Some\ngeneral categories of mitigations are reviewed.",
            "author": [
                "Brett Israelsen",
                "Soumalya Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03088v1",
                "http://arxiv.org/pdf/2312.03088v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03077v1",
            "title": "Clinical Notes Reveal Physician Fatigue",
            "updated": "2023-12-05T19:00:18Z",
            "published": "2023-12-05T19:00:18Z",
            "summary": "Physicians write notes about patients. In doing so, they reveal much about\nthemselves. Using data from 129,228 emergency room visits, we train a model to\nidentify notes written by fatigued physicians -- those who worked 5 or more of\nthe prior 7 days. In a hold-out set, the model accurately identifies notes\nwritten by these high-workload physicians, and also flags notes written in\nother high-fatigue settings: on overnight shifts, and after high patient\nvolumes. Model predictions also correlate with worse decision-making on at\nleast one important metric: yield of testing for heart attack is 18% lower with\neach standard deviation increase in model-predicted fatigue. Finally, the model\nindicates that notes written about Black and Hispanic patients have 12% and 21%\nhigher predicted fatigue than Whites -- larger than overnight vs. daytime\ndifferences. These results have an important implication for large language\nmodels (LLMs). Our model indicates that fatigued doctors write more predictable\nnotes. Perhaps unsurprisingly, because word prediction is the core of how LLMs\nwork, we find that LLM-written notes have 17% higher predicted fatigue than\nreal physicians' notes. This indicates that LLMs may introduce distortions in\ngenerated text that are not yet fully understood.",
            "author": [
                "Chao-Chun Hsu",
                "Ziad Obermeyer",
                "Chenhao Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03077v1",
                "http://arxiv.org/pdf/2312.03077v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03075v1",
            "title": "Monitoring the X-ray Variability of Bright X-ray Sources in M33",
            "updated": "2023-12-05T19:00:13Z",
            "published": "2023-12-05T19:00:13Z",
            "summary": "We present a new five-epoch Chandra X-ray Observatory monitoring survey of\nthe nearby spiral galaxy M33 which probes X-ray variability with time sampling\nbetween two weeks and four months. We characterize the X-ray variability of 55\nbright point sources outside of the nucleus, many of which are expected to be\nhigh-mass X-ray binaries (HMXBs). We detect eight new candidate transients not\ndetected in previous X-ray catalogs of M33 and discuss their possible nature.\nThe final catalog includes 26 known HMXB candidates identified in the\nliterature. We extend the baseline of the X-ray light curves up to 21 years by\nincluding archival X-ray observations of these sources. We compare the\ndetection and non-detection epochs of the sources to suites of simulated source\nduty cycles and infer that most of our detected sources have duty cycles > 30%.\nWe find only four sources whose detection patterns are consistent with having\nduty cycles below 30%. This large fraction of sources with high duty cycles is\nunexpected for a population of HMXBs, thus more frequent X-ray monitoring will\nlikely reveal many more low duty cycle HMXBs in M33.",
            "author": [
                "Rebecca Kyer",
                "Shelby Albrecht",
                "Benjamin F. Williams",
                "Kyros Hinton",
                "Breanna Binder",
                "Margaret Lazzarini",
                "Kristen Garofali",
                "Bret Lehmer",
                "Michael Eracleous",
                "Paul P. Plucinsky",
                "Vallia Antoniou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03075v1",
                "http://arxiv.org/pdf/2312.03075v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03065v1",
            "title": "Deciphering the JWST spectrum of a 'little red dot' at $z \\sim 4.53$: An\n  obscured AGN and its star-forming host",
            "updated": "2023-12-05T19:00:02Z",
            "published": "2023-12-05T19:00:02Z",
            "summary": "JWST has revealed a class of numerous, extremely compact sources, with\nrest-frame red optical/near-infrared (NIR) and blue ultraviolet (UV) colours,\nnicknamed \"little red dots\". We present one of the highest signal-to-noise\nratio JWST NIRSpec/PRISM spectra of a little red dot, J0647_1045 at $z = 4.5321\n\\pm 0.0001$, and examine its NIRCam morphology, to differentiate the origin of\nthe UV and optical/NIR emission, and elucidate the nature of the little red dot\nphenomenon. J0647_1045 is unresolved ($r_e < 0.17$ kpc) in the three NIRCam\nlong-wavelength filters, but significantly extended ($r_e = 0.45 \\pm 0.06$ kpc)\nin the three short-wavelength filters, indicating a red compact source in a\nblue star-forming galaxy. The spectral continuum shows a clear change in slope,\nfrom blue in the optical/UV, to red in the restframe optical/NIR, consistent\nwith two distinct components, fit by power-laws with different attenuation:\n$A_V = 0.54 \\pm 0.01$ (UV) and $A_V = 5.7 \\pm 0.2$ (optical/NIR). Fitting the\nH$\\alpha$ line requires both broad (full width at half-maximum $\\sim 4300 \\pm\n300 km s^{-1}$) and narrow components, but none of the other emission lines,\nincluding H$\\beta$, show evidence of broadness. We calculate $A_V = 1.1 \\pm\n0.2$ from the Balmer decrement using narrow H$\\alpha$ and H$\\beta$, and $A_V >\n4.1 \\pm 0.2$ from broad H$\\alpha$ and upper limit on broad H$\\beta$, consistent\nwith the blue and red continuum attenuation respectively. Based on single-epoch\nH$\\alpha$ linewidth, the mass of the central black hole is $8 \\pm 1 \\times 10^8\nM_\\odot$. Our findings are consistent with a multi-component model, where the\noptical/NIR and broad lines arise from a highly obscured, spatially unresolved\nregion, likely a relatively massive active galactic nucleus, while the less\nobscured UV continuum and narrow lines arise, at least partly, from a small but\nspatially resolved star-forming host galaxy.",
            "author": [
                "Meghana Killi",
                "Darach Watson",
                "Gabriel Brammer",
                "Conor McPartland",
                "Jacqueline Antwi-Danso",
                "Rosa Newshore",
                "Dan Coe",
                "Natalie Allen",
                "Johan P. U. Fynbo",
                "Katriona Gould",
                "Kasper E. Heintz",
                "Vadim Rusakov",
                "Simone Vejlgaard"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03065v1",
                "http://arxiv.org/pdf/2312.03065v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02983v1",
            "title": "Probing supermassive black hole seed scenarios with gravitational wave\n  measurements",
            "updated": "2023-12-05T18:59:59Z",
            "published": "2023-12-05T18:59:59Z",
            "summary": "The process whereby the supermassive black holes populating the centers of\ngalaxies have been assembled remains to be established, with the relative\nimportance of seeds provided by collapsed Population-III stars, black holes\nformed in nuclear star clusters via repeated mergers, or direct collapses of\nprotogalactic disks yet to be determined. In this paper we study the prospects\nfor casting light on this issue by future measurements of gravitational waves\nemitted during the inspirals and mergers of pairs of intermediate-mass black\nholes, discussing in particular the roles of prospective measurements by LISA\nand the proposed atom interferometers AION and AEDGE. We find that, the\nexpected number of detectable IMBH binaries is $O(100)$ for LISA and AEDGE and\n$O(10)$ for AION in low-mass seeds scenarios and goes down to $O(10)$ for LISA\nand below one for AEDGE and AION in high-mass seed scenarios. This allows all\nof these observatories to probe the parameters of the seed model, in particular\nif at least a fraction of the SMBHs arise from a low-mass seed population. We\nalso show that the measurement accuracy of the binary parameters is, in\ngeneral, best for AEDGE that sees very precisely the merger of the binary.",
            "author": [
                "John Ellis",
                "Malcolm Fairbairn",
                "Juan Urrutia",
                "Ville Vaskonen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02983v1",
                "http://arxiv.org/pdf/2312.02983v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.HE",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02981v1",
            "title": "ReconFusion: 3D Reconstruction with Diffusion Priors",
            "updated": "2023-12-05T18:59:58Z",
            "published": "2023-12-05T18:59:58Z",
            "summary": "3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at\nrendering photorealistic novel views of complex scenes. However, recovering a\nhigh-quality NeRF typically requires tens to hundreds of input images,\nresulting in a time-consuming capture process. We present ReconFusion to\nreconstruct real-world scenes using only a few photos. Our approach leverages a\ndiffusion prior for novel view synthesis, trained on synthetic and multiview\ndatasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel\ncamera poses beyond those captured by the set of input images. Our method\nsynthesizes realistic geometry and texture in underconstrained regions while\npreserving the appearance of observed regions. We perform an extensive\nevaluation across various real-world datasets, including forward-facing and\n360-degree scenes, demonstrating significant performance improvements over\nprevious few-view NeRF reconstruction approaches.",
            "author": [
                "Rundi Wu",
                "Ben Mildenhall",
                "Philipp Henzler",
                "Keunhong Park",
                "Ruiqi Gao",
                "Daniel Watson",
                "Pratul P. Srinivasan",
                "Dor Verbin",
                "Jonathan T. Barron",
                "Ben Poole",
                "Aleksander Holynski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02981v1",
                "http://arxiv.org/pdf/2312.02981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02980v1",
            "title": "GPT4Point: A Unified Framework for Point-Language Understanding and\n  Generation",
            "updated": "2023-12-05T18:59:55Z",
            "published": "2023-12-05T18:59:55Z",
            "summary": "Multimodal Large Language Models (MLLMs) have excelled in 2D image-text\ncomprehension and image generation, but their understanding of the 3D world is\nnotably deficient, limiting progress in 3D language understanding and\ngeneration. To solve this problem, we introduce GPT4Point, an innovative\ngroundbreaking point-language multimodal model designed specifically for\nunified 3D object understanding and generation within the MLLM framework.\nGPT4Point as a powerful 3D MLLM seamlessly can execute a variety of point-text\nreference tasks such as point-cloud captioning and Q&A. Additionally, GPT4Point\nis equipped with advanced capabilities for controllable 3D generation, it can\nget high-quality results through a low-quality point-text feature maintaining\nthe geometric shapes and colors. To support the expansive needs of 3D\nobject-text pairs, we develop Pyramid-XL, a point-language dataset annotation\nengine. It constructs a large-scale database over 1M objects of varied text\ngranularity levels from the Objaverse-XL dataset, essential for training\nGPT4Point. A comprehensive benchmark has been proposed to evaluate 3D\npoint-language understanding capabilities. In extensive evaluations, GPT4Point\nhas demonstrated superior performance in understanding and generation.",
            "author": [
                "Zhangyang Qi",
                "Ye Fang",
                "Zeyi Sun",
                "Xiaoyang Wu",
                "Tong Wu",
                "Jiaqi Wang",
                "Dahua Lin",
                "Hengshuang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02980v1",
                "http://arxiv.org/pdf/2312.02980v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02976v1",
            "title": "Imitating Shortest Paths in Simulation Enables Effective Navigation and\n  Manipulation in the Real World",
            "updated": "2023-12-05T18:59:45Z",
            "published": "2023-12-05T18:59:45Z",
            "summary": "Reinforcement learning (RL) with dense rewards and imitation learning (IL)\nwith human-generated trajectories are the most widely used approaches for\ntraining modern embodied agents. RL requires extensive reward shaping and\nauxiliary losses and is often too slow and ineffective for long-horizon tasks.\nWhile IL with human supervision is effective, collecting human trajectories at\nscale is extremely expensive. In this work, we show that imitating\nshortest-path planners in simulation produces agents that, given a language\ninstruction, can proficiently navigate, explore, and manipulate objects in both\nsimulation and in the real world using only RGB sensors (no depth map or GPS\ncoordinates). This surprising result is enabled by our end-to-end,\ntransformer-based, SPOC architecture, powerful visual encoders paired with\nextensive image augmentation, and the dramatic scale and diversity of our\ntraining data: millions of frames of shortest-path-expert trajectories\ncollected inside approximately 200,000 procedurally generated houses containing\n40,000 unique 3D assets. Our models, data, training code, and newly proposed\n10-task benchmarking suite CHORES will be open-sourced.",
            "author": [
                "Kiana Ehsani",
                "Tanmay Gupta",
                "Rose Hendrix",
                "Jordi Salvador",
                "Luca Weihs",
                "Kuo-Hao Zeng",
                "Kunal Pratap Singh",
                "Yejin Kim",
                "Winson Han",
                "Alvaro Herrasti",
                "Ranjay Krishna",
                "Dustin Schwenk",
                "Eli VanderBilt",
                "Aniruddha Kembhavi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02976v1",
                "http://arxiv.org/pdf/2312.02976v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03053v1",
            "title": "DiffusionPCR: Diffusion Models for Robust Multi-Step Point Cloud\n  Registration",
            "updated": "2023-12-05T18:59:41Z",
            "published": "2023-12-05T18:59:41Z",
            "summary": "Point Cloud Registration (PCR) estimates the relative rigid transformation\nbetween two point clouds. We propose formulating PCR as a denoising diffusion\nprobabilistic process, mapping noisy transformations to the ground truth.\nHowever, using diffusion models for PCR has nontrivial challenges, such as\nadapting a generative model to a discriminative task and leveraging the\nestimated nonlinear transformation from the previous step. Instead of training\na diffusion model to directly map pure noise to ground truth, we map the\npredictions of an off-the-shelf PCR model to ground truth. The predictions of\noff-the-shelf models are often imperfect, especially in challenging cases where\nthe two points clouds have low overlap, and thus could be seen as noisy\nversions of the real rigid transformation. In addition, we transform the\nrotation matrix into a spherical linear space for interpolation between samples\nin the forward process, and convert rigid transformations into auxiliary\ninformation to implicitly exploit last-step estimations in the reverse process.\nAs a result, conditioned on time step, the denoising model adapts to the\nincreasing accuracy across steps and refines registrations. Our extensive\nexperiments showcase the effectiveness of our DiffusionPCR, yielding\nstate-of-the-art registration recall rates (95.3%/81.6%) on 3DMatch and\n3DLoMatch. The code will be made public upon publication.",
            "author": [
                "Zhi Chen",
                "Yufan Ren",
                "Tong Zhang",
                "Zheng Dang",
                "Wenbing Tao",
                "Sabine S\u00fcsstrunk",
                "Mathieu Salzmann"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03053v1",
                "http://arxiv.org/pdf/2312.03053v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02974v1",
            "title": "Describing Differences in Image Sets with Natural Language",
            "updated": "2023-12-05T18:59:16Z",
            "published": "2023-12-05T18:59:16Z",
            "summary": "How do two sets of images differ? Discerning set-level differences is crucial\nfor understanding model behaviors and analyzing datasets, yet manually sifting\nthrough thousands of images is impractical. To aid in this discovery process,\nwe explore the task of automatically describing the differences between two\n$\\textbf{sets}$ of images, which we term Set Difference Captioning. This task\ntakes in image sets $D_A$ and $D_B$, and outputs a description that is more\noften true on $D_A$ than $D_B$. We outline a two-stage approach that first\nproposes candidate difference descriptions from image sets and then re-ranks\nthe candidates by checking how well they can differentiate the two sets. We\nintroduce VisDiff, which first captions the images and prompts a language model\nto propose candidate descriptions, then re-ranks these descriptions using CLIP.\nTo evaluate VisDiff, we collect VisDiffBench, a dataset with 187 paired image\nsets with ground truth difference descriptions. We apply VisDiff to various\ndomains, such as comparing datasets (e.g., ImageNet vs. ImageNetV2), comparing\nclassification models (e.g., zero-shot CLIP vs. supervised ResNet), summarizing\nmodel failure modes (supervised ResNet), characterizing differences between\ngenerative models (e.g., StableDiffusionV1 and V2), and discovering what makes\nimages memorable. Using VisDiff, we are able to find interesting and previously\nunknown differences in datasets and models, demonstrating its utility in\nrevealing nuanced insights.",
            "author": [
                "Lisa Dunlap",
                "Yuhui Zhang",
                "Xiaohan Wang",
                "Ruiqi Zhong",
                "Trevor Darrell",
                "Jacob Steinhardt",
                "Joseph E. Gonzalez",
                "Serena Yeung-Levy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02974v1",
                "http://arxiv.org/pdf/2312.02974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02971v2",
            "title": "Resolving Multiphoton Coincidences in Single-Photon Detector Arrays with\n  Row-Column Readouts",
            "updated": "2023-12-06T04:01:57Z",
            "published": "2023-12-05T18:58:43Z",
            "summary": "Row-column multiplexing has proven to be an effective strategy in scaling\nsingle-photon detector arrays to kilopixel and megapixel spatial resolutions.\nHowever, with this readout mechanism, multiphoton coincidences on the array\ncannot be easily resolved due to ambiguities concerning their spatial locations\nof incidence. In this work, we propose a method to resolve up to 4-photon\ncoincidences in single-photon detector arrays with row-column readouts. By\nutilizing unambiguous single-photon measurements to estimate probabilities of\ndetection at each pixel, we redistribute the ambiguous multiphoton counts among\ncandidate pixel locations such that the peak signal-to-noise-ratio of the\nreconstruction is increased between 3 and 4 dB compared to conventional methods\nat optimal operating conditions. We also show that our method allows the\noperation of these arrays at higher incident photon fluxes as compared to\nprevious methods. The application of this technique to imaging natural scenes\nis demonstrated using Monte Carlo experiments.",
            "author": [
                "Shashwath Bharadwaj",
                "Ruangrawee Kitichotkul",
                "Akshay Agarwal",
                "Vivek K Goyal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02971v2",
                "http://arxiv.org/pdf/2312.02971v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03052v1",
            "title": "Visual Program Distillation: Distilling Tools and Programmatic Reasoning\n  into Vision-Language Models",
            "updated": "2023-12-05T18:58:37Z",
            "published": "2023-12-05T18:58:37Z",
            "summary": "Solving complex visual tasks such as \"Who invented the musical instrument on\nthe right?\" involves a composition of skills: understanding space, recognizing\ninstruments, and also retrieving prior knowledge. Recent work shows promise by\ndecomposing such tasks using a large language model (LLM) into an executable\nprogram that invokes specialized vision models. However, generated programs are\nerror-prone: they omit necessary steps, include spurious ones, and are unable\nto recover when the specialized models give incorrect outputs. Moreover, they\nrequire loading multiple models, incurring high latency and computation costs.\nWe propose Visual Program Distillation (VPD), an instruction tuning framework\nthat produces a vision-language model (VLM) capable of solving complex visual\ntasks with a single forward pass. VPD distills the reasoning ability of LLMs by\nusing them to sample multiple candidate programs, which are then executed and\nverified to identify a correct one. It translates each correct program into a\nlanguage description of the reasoning steps, which are then distilled into a\nVLM. Extensive experiments show that VPD improves the VLM's ability to count,\nunderstand spatial relations, and reason compositionally. Our VPD-trained\nPaLI-X outperforms all prior VLMs, achieving state-of-the-art performance\nacross complex vision tasks, including MMBench, OK-VQA, A-OKVQA, TallyQA, POPE,\nand Hateful Memes. An evaluation with human annotators also confirms that VPD\nimproves model response factuality and consistency. Finally, experiments on\ncontent moderation demonstrate that VPD is also helpful for adaptation to\nreal-world applications with limited data.",
            "author": [
                "Yushi Hu",
                "Otilia Stretcu",
                "Chun-Ta Lu",
                "Krishnamurthy Viswanathan",
                "Kenji Hata",
                "Enming Luo",
                "Ranjay Krishna",
                "Ariel Fuxman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03052v1",
                "http://arxiv.org/pdf/2312.03052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02969v1",
            "title": "Rank-without-GPT: Building GPT-Independent Listwise Rerankers on\n  Open-Source Large Language Models",
            "updated": "2023-12-05T18:57:40Z",
            "published": "2023-12-05T18:57:40Z",
            "summary": "Listwise rerankers based on large language models (LLM) are the zero-shot\nstate-of-the-art. However, current works in this direction all depend on the\nGPT models, making it a single point of failure in scientific reproducibility.\nMoreover, it raises the concern that the current research findings only hold\nfor GPT models but not LLM in general. In this work, we lift this pre-condition\nand build for the first time effective listwise rerankers without any form of\ndependency on GPT. Our passage retrieval experiments show that our best list se\nreranker surpasses the listwise rerankers based on GPT-3.5 by 13% and achieves\n97% effectiveness of the ones built on GPT-4. Our results also show that the\nexisting training datasets, which were expressly constructed for pointwise\nranking, are insufficient for building such listwise rerankers. Instead,\nhigh-quality listwise ranking data is required and crucial, calling for further\nwork on building human-annotated listwise data resources.",
            "author": [
                "Xinyu Zhang",
                "Sebastian Hofst\u00e4tter",
                "Patrick Lewis",
                "Raphael Tang",
                "Jimmy Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02969v1",
                "http://arxiv.org/pdf/2312.02969v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02967v1",
            "title": "AmbiGen: Generating Ambigrams from Pre-trained Diffusion Model",
            "updated": "2023-12-05T18:56:06Z",
            "published": "2023-12-05T18:56:06Z",
            "summary": "Ambigrams are calligraphic designs that have different meanings depending on\nthe viewing orientation. Creating ambigrams is a challenging task even for\nskilled artists, as it requires maintaining the meaning under two different\nviewpoints at the same time. In this work, we propose to generate ambigrams by\ndistilling a large-scale vision and language diffusion model, namely DeepFloyd\nIF, to optimize the letters' outline for legibility in the two viewing\norientations. Empirically, we demonstrate that our approach outperforms\nexisting ambigram generation methods. On the 500 most common words in English,\nour method achieves more than an 11.6% increase in word accuracy and at least a\n41.9% reduction in edit distance.",
            "author": [
                "Boheng Zhao",
                "Rana Hanocka",
                "Raymond A. Yeh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02967v1",
                "http://arxiv.org/pdf/2312.02967v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03761v1",
            "title": "Learning High-Dimensional Differential Graphs From Multi-Attribute Data",
            "updated": "2023-12-05T18:54:46Z",
            "published": "2023-12-05T18:54:46Z",
            "summary": "We consider the problem of estimating differences in two Gaussian graphical\nmodels (GGMs) which are known to have similar structure. The GGM structure is\nencoded in its precision (inverse covariance) matrix. In many applications one\nis interested in estimating the difference in two precision matrices to\ncharacterize underlying changes in conditional dependencies of two sets of\ndata. Existing methods for differential graph estimation are based on\nsingle-attribute (SA) models where one associates a scalar random variable with\neach node. In multi-attribute (MA) graphical models, each node represents a\nrandom vector. In this paper, we analyze a group lasso penalized D-trace loss\nfunction approach for differential graph learning from multi-attribute data. An\nalternating direction method of multipliers (ADMM) algorithm is presented to\noptimize the objective function. Theoretical analysis establishing consistency\nin support recovery and estimation in high-dimensional settings is provided.\nNumerical results based on synthetic as well as real data are presented.",
            "author": [
                "Jitendra K Tugnait"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03761v1",
                "http://arxiv.org/pdf/2312.03761v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02966v1",
            "title": "Diffusion-SS3D: Diffusion Model for Semi-supervised 3D Object Detection",
            "updated": "2023-12-05T18:54:03Z",
            "published": "2023-12-05T18:54:03Z",
            "summary": "Semi-supervised object detection is crucial for 3D scene understanding,\nefficiently addressing the limitation of acquiring large-scale 3D bounding box\nannotations. Existing methods typically employ a teacher-student framework with\npseudo-labeling to leverage unlabeled point clouds. However, producing reliable\npseudo-labels in a diverse 3D space still remains challenging. In this work, we\npropose Diffusion-SS3D, a new perspective of enhancing the quality of\npseudo-labels via the diffusion model for semi-supervised 3D object detection.\nSpecifically, we include noises to produce corrupted 3D object size and class\nlabel distributions, and then utilize the diffusion model as a denoising\nprocess to obtain bounding box outputs. Moreover, we integrate the diffusion\nmodel into the teacher-student framework, so that the denoised bounding boxes\ncan be used to improve pseudo-label generation, as well as the entire\nsemi-supervised learning process. We conduct experiments on the ScanNet and SUN\nRGB-D benchmark datasets to demonstrate that our approach achieves\nstate-of-the-art performance against existing methods. We also present\nextensive analysis to understand how our diffusion model design affects\nperformance in semi-supervised learning.",
            "author": [
                "Cheng-Ju Ho",
                "Chen-Hsuan Tai",
                "Yen-Yu Lin",
                "Ming-Hsuan Yang",
                "Yi-Hsuan Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02966v1",
                "http://arxiv.org/pdf/2312.02966v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02963v1",
            "title": "MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human\n  Captures",
            "updated": "2023-12-05T18:50:12Z",
            "published": "2023-12-05T18:50:12Z",
            "summary": "In this era, the success of large language models and text-to-image models\ncan be attributed to the driving force of large-scale datasets. However, in the\nrealm of 3D vision, while remarkable progress has been made with models trained\non large-scale synthetic and real-captured object data like Objaverse and\nMVImgNet, a similar level of progress has not been observed in the domain of\nhuman-centric tasks partially due to the lack of a large-scale human dataset.\nExisting datasets of high-fidelity 3D human capture continue to be mid-sized\ndue to the significant challenges in acquiring large-scale high-quality 3D\nhuman data. To bridge this gap, we present MVHumanNet, a dataset that comprises\nmulti-view human action sequences of 4,500 human identities. The primary focus\nof our work is on collecting human data that features a large number of diverse\nidentities and everyday clothing using a multi-view human capture system, which\nfacilitates easily scalable data collection. Our dataset contains 9,000 daily\noutfits, 60,000 motion sequences and 645 million frames with extensive\nannotations, including human masks, camera parameters, 2D and 3D keypoints,\nSMPL/SMPLX parameters, and corresponding textual descriptions. To explore the\npotential of MVHumanNet in various 2D and 3D visual tasks, we conducted pilot\nstudies on view-consistent action recognition, human NeRF reconstruction,\ntext-driven view-unconstrained human image generation, as well as 2D\nview-unconstrained human image and 3D avatar generation. Extensive experiments\ndemonstrate the performance improvements and effective applications enabled by\nthe scale provided by MVHumanNet. As the current largest-scale 3D human\ndataset, we hope that the release of MVHumanNet data with annotations will\nfoster further innovations in the domain of 3D human-centric tasks at scale.",
            "author": [
                "Zhangyang Xiong",
                "Chenghong Li",
                "Kenkun Liu",
                "Hongjie Liao",
                "Jianqiao Hu",
                "Junyi Zhu",
                "Shuliang Ning",
                "Lingteng Qiu",
                "Chongjie Wang",
                "Shijie Wang",
                "Shuguang Cui",
                "Xiaoguang Han"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02963v1",
                "http://arxiv.org/pdf/2312.02963v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03049v1",
            "title": "Architectural Approaches to Overcome Challenges in the Development of\n  Data-Intensive Systems",
            "updated": "2023-12-05T18:42:25Z",
            "published": "2023-12-05T18:42:25Z",
            "summary": "Orientation of modern software systems towards data-intensive processing\nraises new difficulties in software engineering on how to build and maintain\nsuch systems. Some of the important challenges concern the design of software\narchitecture. In this article, we survey the fundamental challenges when\ndesigning data-intensive computing systems and present some of the most popular\nsoftware architectural styles together with their potential to tackle these\nchallenges.",
            "author": [
                "Aleksandar Dimov",
                "Simeon Emanuilov",
                "Boyan Bontchev",
                "Yavor Dankov",
                "Tasos Papapostolu"
            ],
            "link": [
                "http://dx.doi.org/10.54941/ahfe1002521",
                "http://arxiv.org/abs/2312.03049v1",
                "http://arxiv.org/pdf/2312.03049v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02956v1",
            "title": "Choroidalyzer: An open-source, end-to-end pipeline for choroidal\n  analysis in optical coherence tomography",
            "updated": "2023-12-05T18:40:40Z",
            "published": "2023-12-05T18:40:40Z",
            "summary": "Purpose: To develop Choroidalyzer, an open-source, end-to-end pipeline for\nsegmenting the choroid region, vessels, and fovea, and deriving choroidal\nthickness, area, and vascular index.\n  Methods: We used 5,600 OCT B-scans (233 subjects, 6 systemic disease cohorts,\n3 device types, 2 manufacturers). To generate region and vessel ground-truths,\nwe used state-of-the-art automatic methods following manual correction of\ninaccurate segmentations, with foveal positions manually annotated. We trained\na U-Net deep-learning model to detect the region, vessels, and fovea to\ncalculate choroid thickness, area, and vascular index in a fovea-centred region\nof interest. We analysed segmentation agreement (AUC, Dice) and choroid metrics\nagreement (Pearson, Spearman, mean absolute error (MAE)) in internal and\nexternal test sets. We compared Choroidalyzer to two manual graders on a small\nsubset of external test images and examined cases of high error.\n  Results: Choroidalyzer took 0.299 seconds per image on a standard laptop and\nachieved excellent region (Dice: internal 0.9789, external 0.9749), very good\nvessel segmentation performance (Dice: internal 0.8817, external 0.8703) and\nexcellent fovea location prediction (MAE: internal 3.9 pixels, external 3.4\npixels). For thickness, area, and vascular index, Pearson correlations were\n0.9754, 0.9815, and 0.8285 (internal) / 0.9831, 0.9779, 0.7948 (external),\nrespectively (all p<0.0001). Choroidalyzer's agreement with graders was\ncomparable to the inter-grader agreement across all metrics.\n  Conclusions: Choroidalyzer is an open-source, end-to-end pipeline that\naccurately segments the choroid and reliably extracts thickness, area, and\nvascular index. Especially choroidal vessel segmentation is a difficult and\nsubjective task, and fully-automatic methods like Choroidalyzer could provide\nobjectivity and standardisation.",
            "author": [
                "Justin Engelmann",
                "Jamie Burke",
                "Charlene Hamid",
                "Megan Reid-Schachter",
                "Dan Pugh",
                "Neeraj Dhaun",
                "Diana Moukaddem",
                "Lyle Gray",
                "Niall Strang",
                "Paul McGraw",
                "Amos Storkey",
                "Paul J. Steptoe",
                "Stuart King",
                "Tom MacGillivray",
                "Miguel O. Bernabeu",
                "Ian J. C. MacCormick"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02956v1",
                "http://arxiv.org/pdf/2312.02956v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02952v1",
            "title": "Simple evolving random graphs",
            "updated": "2023-12-05T18:38:44Z",
            "published": "2023-12-05T18:38:44Z",
            "summary": "We study the evolution of graphs with $N$ vertices densifying by adding\nedges. Two vertices are chosen randomly, with rate $(2N)^{-1}$, and an edge is\n(i) established if each vertex belongs to a tree; (ii) established with\nprobability $p$ if only one vertex belongs to a tree; (iii) an attempt fails if\nboth vertices belong to unicyclic components. This densification process\ngenerates random graphs with simple components, viz., trees and unicycles. In\nthe $N\\to\\infty$ limit, the fraction of vertices in unicycles vanishes when\n$t\\leq 1$ and becomes positive when $t>1$. A similar phase transition occurs in\nclassical random graphs where all attempts to add an edge are successful. When\n$N\\to\\infty$ and $t<1$, classical random graphs are simple. In the\nsupercritical phase, a classical random graph contains a (complex) giant\ncomponent that eventually engulfs all finite components and continues to\ndensify forever, or until the graph becomes complete if loops and multiple\nedges are forbidden. The evolution of simple random graphs freezes when trees\ndisappear, and only unicycles remain.",
            "author": [
                "P. L. Krapivsky"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02952v1",
                "http://arxiv.org/pdf/2312.02952v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02949v1",
            "title": "LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models",
            "updated": "2023-12-05T18:29:31Z",
            "published": "2023-12-05T18:29:31Z",
            "summary": "With the recent significant advancements in large multi-modal models (LMMs),\nthe importance of their grounding capability in visual chat is increasingly\nrecognized. Despite recent efforts to enable LMMs to support grounding, their\ncapabilities for grounding and chat are usually separate, and their chat\nperformance drops dramatically when asked to ground. The problem is the lack of\na dataset for grounded visual chat (GVC). Existing grounding datasets only\ncontain short captions. To address this issue, we have created GVC data that\nallows for the combination of grounding and chat capabilities. To better\nevaluate the GVC capabilities, we have introduced a benchmark called\nGrounding-Bench. Additionally, we have proposed a model design that can support\nGVC and various types of visual prompts by connecting segmentation models with\nlanguage models. Experimental results demonstrate that our model outperforms\nother LMMs on Grounding-Bench. Furthermore, our model achieves competitive\nperformance on classic grounding benchmarks like RefCOCO/+/g and Flickr30K\nEntities. Our code will be released at\nhttps://github.com/UX-Decoder/LLaVA-Grounding .",
            "author": [
                "Hao Zhang",
                "Hongyang Li",
                "Feng Li",
                "Tianhe Ren",
                "Xueyan Zou",
                "Shilong Liu",
                "Shijia Huang",
                "Jianfeng Gao",
                "Lei Zhang",
                "Chunyuan Li",
                "Jianwei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02949v1",
                "http://arxiv.org/pdf/2312.02949v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02944v1",
            "title": "An alternating peak-optimization method for optimal trajectory\n  generation of quadrotor drones",
            "updated": "2023-12-05T18:10:46Z",
            "published": "2023-12-05T18:10:46Z",
            "summary": "In this paper, we propose an alternating optimization method to address a\ntime-optimal trajectory generation problem. Different from the existing\nsolutions, our approach introduces a new formulation that minimizes the overall\ntrajectory running time while maintaining the polynomial smoothness constraints\nand incorporating hard limits on motion derivatives to ensure feasibility. To\naddress this problem, an alternating peak-optimization method is developed,\nwhich splits the optimization process into two sub-optimizations: the first\nsub-optimization optimizes polynomial coefficients for smoothness, and the\nsecond sub-optimization adjusts the time allocated to each trajectory segment.\nThese are alternated until a feasible minimum-time solution is found. We offer\na comprehensive set of simulations and experiments to showcase the superior\nperformance of our approach in comparison to existing methods.\n  A collection of demonstration videos with real drone flying experiments can\nbe accessed at\nhttps://www.youtube.com/playlist?list=PLQGtPFK17zUYkwFT-fr0a8E49R8Uq712l .",
            "author": [
                "Wytze A. B. de Vries",
                "Ming Li",
                "Qirui Song",
                "Zhiyong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02944v1",
                "http://arxiv.org/pdf/2312.02944v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02941v1",
            "title": "Fast CT anatomic localization algorithm",
            "updated": "2023-12-05T18:09:47Z",
            "published": "2023-12-05T18:09:47Z",
            "summary": "Automatically determining the position of every slice in a CT scan is a basic\nyet powerful capability allowing fast retrieval of region of interest for\nvisual inspection and automated analysis. Unlike conventional localization\napproaches which work at the slice level, we directly localize only a fraction\nof the slices and and then fit a linear model which maps slice index to its\nestimated axial anatomical position based on those slices. The model is then\nused to assign axial position to every slices of the scan. This approach proves\nto be both computationally efficient, with a typical processing time of less\nthan a second per scan (regardless of its size), accurate, with a typical\nmedian localization error of 1 cm, and robust to different noise sources,\nimaging protocols, metal induced artifacts, anatomical deformations etc.\nAnother key element of our approach is the introduction of a mapping confidence\nscore. This score acts as a fail safe mechanism which allows a rejection of\nunreliable localization results in rare cases of anomalous scans. Our algorithm\nsets new State Of The Art results in terms of localization accuracy. It also\noffers a decrease of two orders of magnitude in processing time with respect to\nall published processing times. It was designed to be invariant to various scan\nresolutions, scan protocols, patient orientations, strong artifacts and various\ndeformations and abnormalities. Additionally, our algorithm is the first one to\nthe best of our knowledge which supports the entire body from head to feet and\nis not confined to specific anatomical region. This algorithm was tested on\nthousands of scans and proves to be very reliable and useful as a preprocessing\nstage for many applications.",
            "author": [
                "Amit Oved"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02941v1",
                "http://arxiv.org/pdf/2312.02941v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02935v1",
            "title": "From Augmentation to Decomposition: A New Look at CUPED in 2023",
            "updated": "2023-12-05T18:05:38Z",
            "published": "2023-12-05T18:05:38Z",
            "summary": "Ten years ago, CUPED (Controlled Experiments Utilizing Pre-Experiment Data)\nmainstreamed the idea of variance reduction leveraging pre-experiment\ncovariates. Since its introduction, it has been implemented, extended, and\nmodernized by major online experimentation platforms. Many researchers and\npractitioners often interpret CUPED as a regression adjustment. In this\narticle, we clarify its similarities and differences to regression adjustment\nand present CUPED as a more general augmentation framework which is closer to\nthe spirit of the 2013 paper. We show that the augmentation view naturally\nleads to cleaner developments of variance reduction beyond simple average\nmetrics, including ratio metrics and percentile metrics. Moreover, the\naugmentation view can go beyond using pre-experiment data and leverage\nin-experiment data, leading to significantly larger variance reduction. We\nfurther introduce metric decomposition using approximate null augmentation\n(ANA) as a mental model for in-experiment variance reduction. We study it under\nboth a Bayesian framework and a frequentist optimal proxy metric framework.\nMetric decomposition arises naturally in conversion funnels, so this work has\nbroad applicability.",
            "author": [
                "Alex Deng",
                "Luke Hagar",
                "Nathaniel Stevens",
                "Tatiana Xifara",
                "Lo-Hua Yuan",
                "Amit Gandhi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02935v1",
                "http://arxiv.org/pdf/2312.02935v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02931v2",
            "title": "WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words",
            "updated": "2023-12-07T00:37:29Z",
            "published": "2023-12-05T18:03:13Z",
            "summary": "Training on multiple modalities of input can augment the capabilities of a\nlanguage model. Here, we ask whether such a training regime can improve the\nquality and efficiency of these systems as well. We focus on text--audio and\nintroduce Whisbert, which is inspired by the text--image approach of FLAVA\n(Singh et al., 2022). In accordance with Babylm guidelines (Warstadt et al.,\n2023), we pretrain Whisbert on a dataset comprising only 100 million words plus\ntheir corresponding speech from the word-aligned version of the People's Speech\ndataset (Galvez et al., 2021). To assess the impact of multimodality, we\ncompare versions of the model that are trained on text only and on both audio\nand text simultaneously. We find that while Whisbert is able to perform well on\nmultimodal masked modeling and surpasses the Babylm baselines in most benchmark\ntasks, it struggles to optimize its complex objective and outperform its\ntext-only Whisbert baseline.",
            "author": [
                "Lukas Wolf",
                "Greta Tuckute",
                "Klemen Kotar",
                "Eghbal Hosseini",
                "Tamar Regev",
                "Ethan Wilcox",
                "Alex Warstadt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02931v2",
                "http://arxiv.org/pdf/2312.02931v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02919v1",
            "title": "Fine-grained Controllable Video Generation via Object Appearance and\n  Context",
            "updated": "2023-12-05T17:47:33Z",
            "published": "2023-12-05T17:47:33Z",
            "summary": "Text-to-video generation has shown promising results. However, by taking only\nnatural languages as input, users often face difficulties in providing detailed\ninformation to precisely control the model's output. In this work, we propose\nfine-grained controllable video generation (FACTOR) to achieve detailed\ncontrol. Specifically, FACTOR aims to control objects' appearances and context,\nincluding their location and category, in conjunction with the text prompt. To\nachieve detailed control, we propose a unified framework to jointly inject\ncontrol signals into the existing text-to-video model. Our model consists of a\njoint encoder and adaptive cross-attention layers. By optimizing the encoder\nand the inserted layer, we adapt the model to generate videos that are aligned\nwith both text prompts and fine-grained control. Compared to existing methods\nrelying on dense control signals such as edge maps, we provide a more intuitive\nand user-friendly interface to allow object-level fine-grained control. Our\nmethod achieves controllability of object appearances without finetuning, which\nreduces the per-subject optimization efforts for the users. Extensive\nexperiments on standard benchmark datasets and user-provided inputs validate\nthat our model obtains a 70% improvement in controllability metrics over\ncompetitive baselines.",
            "author": [
                "Hsin-Ping Huang",
                "Yu-Chuan Su",
                "Deqing Sun",
                "Lu Jiang",
                "Xuhui Jia",
                "Yukun Zhu",
                "Ming-Hsuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02919v1",
                "http://arxiv.org/pdf/2312.02919v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02914v2",
            "title": "Unsupervised Video Domain Adaptation with Masked Pre-Training and\n  Collaborative Self-Training",
            "updated": "2023-12-06T19:12:32Z",
            "published": "2023-12-05T17:39:19Z",
            "summary": "In this work, we tackle the problem of unsupervised domain adaptation (UDA)\nfor video action recognition. Our approach, which we call UNITE, uses an image\nteacher model to adapt a video student model to the target domain. UNITE first\nemploys self-supervised pre-training to promote discriminative feature learning\non target domain videos using a teacher-guided masked distillation objective.\nWe then perform self-training on masked target data, using the video student\nmodel and image teacher model together to generate improved pseudolabels for\nunlabeled target videos. Our self-training process successfully leverages the\nstrengths of both models to achieve strong transfer performance across domains.\nWe evaluate our approach on multiple video domain adaptation benchmarks and\nobserve significant improvements upon previously reported results.",
            "author": [
                "Arun Reddy",
                "William Paul",
                "Corban Rivera",
                "Ketul Shah",
                "Celso M. de Melo",
                "Rama Chellappa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02914v2",
                "http://arxiv.org/pdf/2312.02914v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02913v1",
            "title": "Let the LLMs Talk: Simulating Human-to-Human Conversational QA via\n  Zero-Shot LLM-to-LLM Interactions",
            "updated": "2023-12-05T17:38:02Z",
            "published": "2023-12-05T17:38:02Z",
            "summary": "Conversational question-answering (CQA) systems aim to create interactive\nsearch systems that effectively retrieve information by interacting with users.\nTo replicate human-to-human conversations, existing work uses human annotators\nto play the roles of the questioner (student) and the answerer (teacher).\nDespite its effectiveness, challenges exist as human annotation is\ntime-consuming, inconsistent, and not scalable. To address this issue and\ninvestigate the applicability of large language models (LLMs) in CQA\nsimulation, we propose a simulation framework that employs zero-shot learner\nLLMs for simulating teacher-student interactions. Our framework involves two\nLLMs interacting on a specific topic, with the first LLM acting as a student,\ngenerating questions to explore a given search topic. The second LLM plays the\nrole of a teacher by answering questions and is equipped with additional\ninformation, including a text on the given topic. We implement both the student\nand teacher by zero-shot prompting the GPT-4 model. To assess the effectiveness\nof LLMs in simulating CQA interactions and understand the disparities between\nLLM- and human-generated conversations, we evaluate the simulated data from\nvarious perspectives. We begin by evaluating the teacher's performance through\nboth automatic and human assessment. Next, we evaluate the performance of the\nstudent, analyzing and comparing the disparities between questions generated by\nthe LLM and those generated by humans. Furthermore, we conduct extensive\nanalyses to thoroughly examine the LLM performance by benchmarking\nstate-of-the-art reading comprehension models on both datasets. Our results\nreveal that the teacher LLM generates lengthier answers that tend to be more\naccurate and complete. The student LLM generates more diverse questions,\ncovering more aspects of a given topic.",
            "author": [
                "Zahra Abbasiantaeb",
                "Yifei Yuan",
                "Evangelos Kanoulas",
                "Mohammad Aliannejadi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02913v1",
                "http://arxiv.org/pdf/2312.02913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02911v1",
            "title": "Accretion processes onto black holes: theoretical problems,\n  observational constraints",
            "updated": "2023-12-05T17:36:06Z",
            "published": "2023-12-05T17:36:06Z",
            "summary": "We shortly summarize the standard current knowledge on the structure of the\naccretion flow onto black holes in galactic binary systems and in active\ngalactic nuclei. We stress the similarities and differences between the two\ntypes of systems, and we highlight the complementarity of the data caused by\nthese differences. We highlight some new developments and list the unsolved\nproblems.",
            "author": [
                "Bozena Czerny",
                "Marzena Sniegowska",
                "Agnieszka Janiuk",
                "Bei You"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02911v1",
                "http://arxiv.org/pdf/2312.02911v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02906v1",
            "title": "Uncovering Patterns of Participant-Invariant Influence in Networks",
            "updated": "2023-12-05T17:26:28Z",
            "published": "2023-12-05T17:26:28Z",
            "summary": "In this paper, we explore the nature of influence in a network. The concept\nof participant-invariant influence is derived from an influence matrix M\nspecifically designed to explore this phenomenon. Through nonnegative matrix\nfactorization approximation, we managed to extract a participant-invariant\nmatrix H representing a shared pattern that all participants must obey. The\nacquired H is highly field-related and can be further utilized to cluster\nfactual networks. Our discovery of the unveiled participant-independent\ninfluence within network dynamics opens up new avenues for further research on\nnetwork behavior and its implications.",
            "author": [
                "Min Shaojie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02906v1",
                "http://arxiv.org/pdf/2312.02906v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02903v1",
            "title": "Miniaturized Double-Wing Delta-E Effect Sensors",
            "updated": "2023-12-05T17:19:43Z",
            "published": "2023-12-05T17:19:43Z",
            "summary": "Magnetoelastic composites are integral elements of sensors and actuators\nutilizing magnetostriction for their functionality. Their sensitivity typically\nscales with the saturation magnetostriction and inversely with magnetic\nanisotropy. However, this makes the devices prone to minuscule residual\nanisotropic stress from the fabrication process, impairing their performance\nand reproducibility, hence limiting their suitability for arrays. This study\npresents a shadow mask deposition technology combined with a free-free\nmagnetoelectric microresonator design intended to minimize residual stress and\ninhomogeneity in the magnetoelastic layer. Resonators are experimentally and\ntheoretically analyzed regarding local stress anisotropy, magnetic anisotropy,\nand the {\\Delta}E effect in several resonance modes. Further, the sensitivity\nis analyzed in the example of {\\Delta}E-effect sensors. The results demonstrate\na device-to-device variation of the resonance frequency < 0.2 % with\nsensitivities comparable with macroscopic {\\Delta}E-effect sensors. The\nreproducibility is drastically improved over previous magnetoelastic device\narrays. This development marks a step forward in the reproducibility and\nhomogeneity of magnetoelastic resonators and contributes to the feasibility of\nlarge-scale, integrated sensor arrays.",
            "author": [
                "Fatih Ilgaz",
                "Elizaveta Spetzler",
                "Patrick Wiegand",
                "Franz Faupel",
                "Robert Rieger",
                "Jeffrey McCord",
                "Benjamin Spetzler"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02903v1",
                "http://arxiv.org/pdf/2312.02903v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03046v1",
            "title": "Diversified in-domain synthesis with efficient fine-tuning for few-shot\n  classification",
            "updated": "2023-12-05T17:18:09Z",
            "published": "2023-12-05T17:18:09Z",
            "summary": "Few-shot image classification aims to learn an image classifier using only a\nsmall set of labeled examples per class. A recent research direction for\nimproving few-shot classifiers involves augmenting the labelled samples with\nsynthetic images created by state-of-the-art text-to-image generation models.\nFollowing this trend, we propose Diversified in-domain synthesis with efficient\nfine-tuning (DISEF), a novel approach which addresses the generalization\nchallenge in few-shot learning using synthetic data. DISEF consists of two main\ncomponents. First, we propose a novel text-to-image augmentation pipeline that,\nby leveraging the real samples and their rich semantics coming from an advanced\ncaptioning model, promotes in-domain sample diversity for better\ngeneralization. Second, we emphasize the importance of effective model\nfine-tuning in few-shot recognition, proposing to use Low-Rank Adaptation\n(LoRA) for joint adaptation of the text and image encoders in a Vision Language\nModel. We validate our method in ten different benchmarks, consistently\noutperforming baselines and establishing a new state-of-the-art for few-shot\nclassification. Code is available at \\url{https://github.com/vturrisi/disef}",
            "author": [
                "Victor G. Turrisi da Costa",
                "Nicola Dall'Asen",
                "Yiming Wang",
                "Nicu Sebe",
                "Elisa Ricci"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03046v1",
                "http://arxiv.org/pdf/2312.03046v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02901v1",
            "title": "Concept Drift Adaptation in Text Stream Mining Settings: A Comprehensive\n  Review",
            "updated": "2023-12-05T17:15:16Z",
            "published": "2023-12-05T17:15:16Z",
            "summary": "Due to the advent and increase in the popularity of the Internet, people have\nbeen producing and disseminating textual data in several ways, such as reviews,\nsocial media posts, and news articles. As a result, numerous researchers have\nbeen working on discovering patterns in textual data, especially because social\nmedia posts function as social sensors, indicating peoples' opinions,\ninterests, etc. However, most tasks regarding natural language processing are\naddressed using traditional machine learning methods and static datasets. This\nsetting can lead to several problems, such as an outdated dataset, which may\nnot correspond to reality, and an outdated model, which has its performance\ndegrading over time. Concept drift is another aspect that emphasizes these\nissues, which corresponds to data distribution and pattern changes. In a text\nstream scenario, it is even more challenging due to its characteristics, such\nas the high speed and data arriving sequentially. In addition, models for this\ntype of scenario must adhere to the constraints mentioned above while learning\nfrom the stream by storing texts for a limited time and consuming low memory.\nIn this study, we performed a systematic literature review regarding concept\ndrift adaptation in text stream scenarios. Considering well-defined criteria,\nwe selected 40 papers to unravel aspects such as text drift categories, types\nof text drift detection, model update mechanism, the addressed stream mining\ntasks, types of text representations, and text representation update mechanism.\nIn addition, we discussed drift visualization and simulation and listed\nreal-world datasets used in the selected papers. Therefore, this paper\ncomprehensively reviews the concept drift adaptation in text stream mining\nscenarios.",
            "author": [
                "Cristiano Mesquita Garcia",
                "Ramon Simoes Abilio",
                "Alessandro Lameiras Koerich",
                "Alceu de Souza Britto Jr.",
                "Jean Paul Barddal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02901v1",
                "http://arxiv.org/pdf/2312.02901v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02900v1",
            "title": "A complexity measure identifying the accumulation of stresses before\n  major earthquakes",
            "updated": "2023-12-05T17:14:58Z",
            "published": "2023-12-05T17:14:58Z",
            "summary": "Here we suggest a new procedure through which one can identify when the\naccumulation of stresses before major earthquakes (EQs) (of magnitude M8.2 or\nlarger) occurs. By analyzing the seismicity in the frame of natural time, which\nis a new concept of time introduced in 2001, we study the evolution of the\nfluctuations of the entropy change of seismicity under time reversal for\nvarious scales of different length i (number of events). We find that anomalous\nintersections between scales of different lengths i are observed upon\napproaching an extraordinary major EQ occurrence. The investigation is\npresented for the seismicity in Japan during the last 39 years including the M9\nTohoku EQ on 11 March 2011, which is the largest EQ ever recorded there.",
            "author": [
                "Panayiotis A. Varotsos",
                "Toshiyasu Nagao",
                "Nicholas V. Sarlis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02900v1",
                "http://arxiv.org/pdf/2312.02900v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02898v1",
            "title": "Madgraph5_aMC@NLO on GPUs and vector CPUs Experience with the first\n  alpha release",
            "updated": "2023-12-05T17:12:03Z",
            "published": "2023-12-05T17:12:03Z",
            "summary": "Madgraph5_aMC@NLO is one of the most-frequently used Monte-Carlo event\ngenerators at the LHC, and an important consumer of compute resources. The\nsoftware has been reengineered to maintain the overall look and feel of the\nuser interface while speeding up event generation on CPUs and GPUs. The most\ncomputationally intensive part, the calculation of \"matrix elements\", is\noffloaded to new implementations optimised for GPUs and for CPU vector\ninstructions, using event-level data parallelism. We present the work to\nsupport accelerated leading-order QCD processes, and discuss how this work is\ngoing to be released to Madgraph5_aMC@NLO's users.",
            "author": [
                "Stephan Hageboeck",
                "Taylor Childers",
                "Walter Hopkins",
                "Olivier Mattelaer",
                "Nathan Nichols",
                "Stefan Roiser",
                "J\u00f8rgen Teig",
                "Andrea Valassi",
                "Carl Vuosalo",
                "Zenny Wettersten"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02898v1",
                "http://arxiv.org/pdf/2312.02898v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02897v1",
            "title": "Perspectives from Naive Participants and Experienced Social Science\n  Researchers on Addressing Embodiment in a Virtual Cyberball Task",
            "updated": "2023-12-05T17:09:59Z",
            "published": "2023-12-05T17:09:59Z",
            "summary": "We describe the design of an immersive virtual Cyberball task that included\navatar customization, and user feedback on this design. We first created a\nprototype of an avatar customization template and added it to a Cyberball\nprototype built in the Unity3D game engine. Then, we conducted in-depth user\ntesting and feedback sessions with 15 Cyberball stakeholders: five naive\nparticipants with no prior knowledge of Cyberball and ten experienced\nresearchers with extensive experience using the Cyberball paradigm. We report\nthe divergent perspectives of the two groups on the following design insights;\ndesigning for intuitive use, inclusivity, and realistic experiences versus\nminimalism. Participant responses shed light on how system design problems may\ncontribute to or perpetuate negative experiences when customizing avatars. They\nalso demonstrate the value of considering multiple stakeholders' feedback in\nthe design process for virtual reality, presenting a more comprehensive view in\ndesigning future Cyberball prototypes and interactive systems for social\nscience research.",
            "author": [
                "Tao Long",
                "Swati Pandita",
                "Andrea Stevenson Won"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02897v1",
                "http://arxiv.org/pdf/2312.02897v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02892v1",
            "title": "Safe Stabilization with Model Uncertainties: A Universal Formula with\n  Gaussian Process Learning",
            "updated": "2023-12-05T17:03:01Z",
            "published": "2023-12-05T17:03:01Z",
            "summary": "A combination of control Lyapunov functions (CLFs) and control barrier\nfunctions (CBFs) forms an efficient framework for addressing control challenges\nin safe stabilization. In our previous research, we developed an analytical\ncontrol strategy, namely the universal formula, that incorporates CLF and CBF\nconditions for safe stabilization. However, successful implementation of this\nuniversal formula relies on an accurate model, as any mismatch between the\nmodel and the actual system can compromise stability and safety. In this paper,\nwe propose a new universal formula that leverages Gaussian processes (GPs)\nlearning to address safe stabilization in the presence of model uncertainty. By\nutilizing the results related to bounded learning errors, we achieve a high\nprobability of stability and safety guarantees with the proposed universal\nformula. Additionally, we introduce a probabilistic compatibility condition to\nevaluate conflicts between the modified CLF and CBF conditions with GP learning\nresults. In cases where compatibility assumptions fail and control system\nlimits are present, we propose a modified universal formula that relaxes\nstability constraints and a projection-based method accommodating control\nlimits. We illustrate the effectiveness of our approach through a simulation of\nadaptive cruise control (ACC), highlighting its potential for practical\napplications in real-world scenarios.",
            "author": [
                "Ming Li",
                "Zhiyong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02892v1",
                "http://arxiv.org/pdf/2312.02892v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02890v1",
            "title": "On Matrices Arising in Finite Field Hypergeometric Functions",
            "updated": "2023-12-05T17:02:38Z",
            "published": "2023-12-05T17:02:38Z",
            "summary": "Lehmer constructs four classes of matrices constructed from roots of unity\nfor which the characteristic polynomials and the $k$-th powers can be\ndetermined explicitly. Here we study a class of matrices which arise naturally\nin transformation formulas of finite field hypergeometric functions and whose\nentries are roots of unity and zeroes. We determine the characteristic\npolynomial, eigenvalues, eigenvectors, and $k$-th powers of these matrices. In\nparticular, the eigenvalues are natural systems of products of Jacobi sums.",
            "author": [
                "Satoshi Kumabe",
                "Hasan Saad"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02890v1",
                "http://arxiv.org/pdf/2312.02890v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02891v1",
            "title": "Inexact linear solves in the low-rank ADI iteration for large Sylvester\n  equations",
            "updated": "2023-12-05T17:02:38Z",
            "published": "2023-12-05T17:02:38Z",
            "summary": "We consider the low-rank alternating directions implicit (ADI) iteration for\napproximately solving large-scale algebraic Sylvester equations. Inside every\niteration step of this iterative process a pair of linear systems of equations\nhas to be solved. We investigate the situation when those inner linear systems\nare solved inexactly by an iterative methods such as, for example,\npreconditioned Krylov subspace methods. The main contribution of this work are\nthresholds for the required accuracies regarding the inner linear systems which\ndictate when the employed inner Krylov subspace methods can be safely\nterminated. The goal is to save computational effort by solving the inner\nlinear system as inaccurate as possible without endangering the functionality\nof the low-rank Sylvester-ADI method. Ideally, the inexact ADI method mimics\nthe convergence behaviour of the more expensive exact ADI method, where the\nlinear systems are solved directly. Alongside the theoretical results, also\nstrategies for an actual practical implementation of the stopping criteria are\ndeveloped. Numerical experiments confirm the effectiveness of the proposed\nstrategies.",
            "author": [
                "Patrick K\u00fcrschner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02891v1",
                "http://arxiv.org/pdf/2312.02891v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "15A06, 15A24, 65F45, 65F55"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02888v1",
            "title": "Compensation of front-end and modulation delays in phase and ranging\n  measurements for time-delay interferometry",
            "updated": "2023-12-05T17:01:35Z",
            "published": "2023-12-05T17:01:35Z",
            "summary": "In the context of the Laser Interferometer Space Antenna (LISA), the laser\nsubsystems exhibit frequency fluctuations that introduce significant levels of\nnoise into the measurements, surpassing the gravitational wave signal by\nseveral orders of magnitude. Mitigation is achieved via time-shifting\nindividual measurements in a data processing step known as time-delay\ninterferometry (TDI). The suppression performance of TDI relies on accurate\nknowledge and consideration of the delays experienced by the interfering\nlasers. While considerable efforts have been dedicated to the accurate\ndetermination of inter-spacecraft ranging delays, the sources for onboard\ndelays have been either neglected or assumed to be known. Contrary to these\nassumptions, analog delays of the phasemeter front end and the laser modulator\nare not only large but also prone to change with temperature and heterodyne\nfrequency. This motivates our proposal for a novel method enabling a\ncalibration of these delays on-ground and in-space, based on minimal functional\nadditions to the receiver architecture. Specifically, we establish a set of\ncalibration measurements and elucidate how these measurements are utilized in\ndata processing, leading to the mitigation of the delays in the TDI Michelson\nvariables. Following a performance analysis of the calibration measurements,\nproposed calibration scheme is assessed through numerical simulations. We find\nthat in the absence of the calibration scheme, the assumed drifts of the analog\ndelays increase residual laser noise at high frequencies of the LISA\nmeasurement band. A single, on-ground calibration of the analog delays leads to\nan improvement by roughly one order of magnitude, while re-calibration in space\nmay improve performance by yet another order of magnitude. Towards lower\nfrequencies, ranging error is always found to be the limiting factor for which\ncountermeasures are discussed.",
            "author": [
                "Philipp Euringer",
                "Niklas Houba",
                "Gerald Hechenblaikner",
                "Oliver Mandel",
                "Francis Soualle",
                "Walter Fichter"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02888v1",
                "http://arxiv.org/pdf/2312.02888v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02884v1",
            "title": "Last passage percolation and limit theorems in Barak-Erd\u0151s directed\n  random graphs and related models",
            "updated": "2023-12-05T16:56:49Z",
            "published": "2023-12-05T16:56:49Z",
            "summary": "We consider directed random graphs, the prototype of which being the\nBarak-Erd\\H{o}s graph $\\overrightarrow G(\\mathbb Z, p)$, and study the way that\nlong (or heavy, if weights are present) paths grow. This is done by relating\nthe graphs to certain particle systems that we call Infinite Bin Models (IBM).\nA number of limit theorems are shown. The goal of this paper is to present\nresults along with techniques that have been used in this area. In the case of\n$\\overrightarrow G(\\mathbb Z, p)$ the last passage percolation constant $C(p)$\nis studied in great detail. It is shown that $C(p)$ is analytic for $p>0$, has\nan interesting asymptotic expansion at $p=1$ and that $C(p)/p$ converges to $e$\nlike $1/(\\log p)^2$ as $p \\to 0$. The paper includes the study of IBMs as\nmodels on their own as well as their connections to stochastic models of\nbranching processes in continuous or discrete time with selection. Several\nproofs herein are new or simplified versions of published ones. Regenerative\ntechniques are used where possible, exhibiting random sets of vertices over\nwhich the graphs regenerate. When edges have random weights we show how the\nlast passage percolation constants behave and when central limit theorems\nexist. When the underlying vertex set is partially ordered, new phenomena\noccur, e.g., there are relations with last passage Brownian percolation. We\nalso look at weights that may possibly take negative values and study in detail\nsome special cases that require combinatorial/graph theoretic techniques that\nexhibit some interesting non-differentiability properties of the last passage\npercolation constant. We also explain how to approach the problem of estimation\nof last passage percolation constants by means of perfect simulation.",
            "author": [
                "Sergey Foss",
                "Takis Konstantopoulos",
                "Bastien Mallein",
                "Sanjay Ramassamy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02884v1",
                "http://arxiv.org/pdf/2312.02884v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03045v1",
            "title": "Customization Assistant for Text-to-image Generation",
            "updated": "2023-12-05T16:54:42Z",
            "published": "2023-12-05T16:54:42Z",
            "summary": "Customizing pre-trained text-to-image generation model has attracted massive\nresearch interest recently, due to its huge potential in real-world\napplications. Although existing methods are able to generate creative content\nfor a novel concept contained in single user-input image, their capability are\nstill far from perfection. Specifically, most existing methods require\nfine-tuning the generative model on testing images. Some existing methods do\nnot require fine-tuning, while their performance are unsatisfactory.\nFurthermore, the interaction between users and models are still limited to\ndirective and descriptive prompts such as instructions and captions. In this\nwork, we build a customization assistant based on pre-trained large language\nmodel and diffusion model, which can not only perform customized generation in\na tuning-free manner, but also enable more user-friendly interactions: users\ncan chat with the assistant and input either ambiguous text or clear\ninstruction. Specifically, we propose a new framework consists of a new model\ndesign and a novel training strategy. The resulting assistant can perform\ncustomized generation in 2-5 seconds without any test time fine-tuning.\nExtensive experiments are conducted, competitive results have been obtained\nacross different domains, illustrating the effectiveness of the proposed\nmethod.",
            "author": [
                "Yufan Zhou",
                "Ruiyi Zhang",
                "Jiuxiang Gu",
                "Tong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03045v1",
                "http://arxiv.org/pdf/2312.03045v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02880v1",
            "title": "PULSAR: Simultaneous Many-Row Activation for Reliable and\n  High-Performance Computing in Off-the-Shelf DRAM Chips",
            "updated": "2023-12-05T16:52:20Z",
            "published": "2023-12-05T16:52:20Z",
            "summary": "Data movement between the processor and the main memory is a first-order\nobstacle against improving performance and energy efficiency in modern systems.\nTo address this obstacle, Processing-using-Memory (PuM) is a promising approach\nwhere bulk-bitwise operations are performed leveraging intrinsic analog\nproperties within the DRAM array and massive parallelism across DRAM columns.\nUnfortunately, 1) modern off-the-shelf DRAM chips do not officially support PuM\noperations, and 2) existing techniques of performing PuM operations on\noff-the-shelf DRAM chips suffer from two key limitations. First, these\ntechniques have low success rates, i.e., only a small fraction of DRAM columns\ncan correctly execute PuM operations because they operate beyond\nmanufacturer-recommended timing constraints, causing these operations to be\nhighly susceptible to noise and process variation. Second, these techniques\nhave limited compute primitives, preventing them from fully leveraging\nparallelism across DRAM columns and thus hindering their performance benefits.\n  We propose PULSAR, a new technique to enable high-success-rate and\nhigh-performance PuM operations in off-the-shelf DRAM chips. PULSAR leverages\nour new observation that a carefully crafted sequence of DRAM commands\nsimultaneously activates up to 32 DRAM rows. PULSAR overcomes the limitations\nof existing techniques by 1) replicating the input data to improve the success\nrate and 2) enabling new bulk bitwise operations (e.g., many-input majority,\nMulti-RowInit, and Bulk-Write) to improve the performance.\n  Our analysis on 120 off-the-shelf DDR4 chips from two major manufacturers\nshows that PULSAR achieves a 24.18% higher success rate and 121% higher\nperformance over seven arithmetic-logic operations compared to FracDRAM, a\nstate-of-the-art off-the-shelf DRAM-based PuM technique.",
            "author": [
                "Ismail Emir Yuksel",
                "Yahya Can Tugrul",
                "F. Nisa Bostanci",
                "Abdullah Giray Yaglikci",
                "Ataberk Olgun",
                "Geraldo F. Oliveira",
                "Melina Soysal",
                "Haocong Luo",
                "Juan Gomez Luna",
                "Mohammad Sadrosadati",
                "Onur Mutlu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02880v1",
                "http://arxiv.org/pdf/2312.02880v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02877v1",
            "title": "A Dynamic Network for Efficient Point Cloud Registration",
            "updated": "2023-12-05T16:47:46Z",
            "published": "2023-12-05T16:47:46Z",
            "summary": "For the point cloud registration task, a significant challenge arises from\nnon-overlapping points that consume extensive computational resources while\nnegatively affecting registration accuracy. In this paper, we introduce a\ndynamic approach, widely utilized to improve network efficiency in computer\nvision tasks, to the point cloud registration task. We employ an iterative\nregistration process on point cloud data multiple times to identify regions\nwhere matching points cluster, ultimately enabling us to remove noisy points.\nSpecifically, we begin with deep global sampling to perform coarse global\nregistration. Subsequently, we employ the proposed refined node proposal module\nto further narrow down the registration region and perform local registration.\nFurthermore, we utilize a spatial consistency-based classifier to evaluate the\nresults of each registration stage. The model terminates once it reaches\nsufficient confidence, avoiding unnecessary computations. Extended experiments\ndemonstrate that our model significantly reduces time consumption compared to\nother methods with similar results, achieving a speed improvement of over 41%\non indoor dataset (3DMatch) and 33% on outdoor datasets (KITTI) while\nmaintaining competitive registration recall requirements.",
            "author": [
                "Yang Ai",
                "Xi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02877v1",
                "http://arxiv.org/pdf/2312.02877v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02873v1",
            "title": "Toward autocorrection of chemical process flowsheets using large\n  language models",
            "updated": "2023-12-05T16:39:41Z",
            "published": "2023-12-05T16:39:41Z",
            "summary": "The process engineering domain widely uses Process Flow Diagrams (PFDs) and\nProcess and Instrumentation Diagrams (P&IDs) to represent process flows and\nequipment configurations. However, the P&IDs and PFDs, hereafter called\nflowsheets, can contain errors causing safety hazards, inefficient operation,\nand unnecessary expenses. Correcting and verifying flowsheets is a tedious,\nmanual process. We propose a novel generative AI methodology for automatically\nidentifying errors in flowsheets and suggesting corrections to the user, i.e.,\nautocorrecting flowsheets. Inspired by the breakthrough of Large Language\nModels (LLMs) for grammatical autocorrection of human language, we investigate\nLLMs for the autocorrection of flowsheets. The input to the model is a\npotentially erroneous flowsheet and the output of the model are suggestions for\na corrected flowsheet. We train our autocorrection model on a synthetic dataset\nin a supervised manner. The model achieves a top-1 accuracy of 80% and a top-5\naccuracy of 84% on an independent test dataset of synthetically generated\nflowsheets. The results suggest that the model can learn to autocorrect the\nsynthetic flowsheets. We envision that flowsheet autocorrection will become a\nuseful tool for chemical engineers.",
            "author": [
                "Lukas Schulze Balhorn",
                "Marc Caballero",
                "Artur M. Schweidtmann"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02873v1",
                "http://arxiv.org/pdf/2312.02873v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02872v1",
            "title": "Experimental Insights Towards Explainable and Interpretable Pedestrian\n  Crossing Prediction",
            "updated": "2023-12-05T16:39:32Z",
            "published": "2023-12-05T16:39:32Z",
            "summary": "In the context of autonomous driving, pedestrian crossing prediction is a key\ncomponent for improving road safety. Presently, the focus of these predictions\nextends beyond achieving trustworthy results; it is shifting towards the\nexplainability and interpretability of these predictions. This research\nintroduces a novel neuro-symbolic approach that combines deep learning and\nfuzzy logic for an explainable and interpretable pedestrian crossing\nprediction. We have developed an explainable predictor (ExPedCross), which\nutilizes a set of explainable features and employs a fuzzy inference system to\npredict whether the pedestrian will cross or not. Our approach was evaluated on\nboth the PIE and JAAD datasets. The results offer experimental insights into\nachieving explainability and interpretability in the pedestrian crossing\nprediction task. Furthermore, the testing results yield a set of guidelines and\nrecommendations regarding the process of dataset selection, feature selection,\nand explainability.",
            "author": [
                "Angie Nataly Melo",
                "Carlota Salinas",
                "Miguel Angel Sotelo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02872v1",
                "http://arxiv.org/pdf/2312.02872v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02869v1",
            "title": "Can a Tabula Recta provide security in the XXI century?",
            "updated": "2023-12-05T16:36:27Z",
            "published": "2023-12-05T16:36:27Z",
            "summary": "In the not so unlikely scenario of total compromise of computers accessible\nto a group of users, they might be tempted to resort to human-computable\npaper-and-pencil cryptographic methods aided by a classic Tabula Recta, which\nhelps to perform addition and subtraction directly with letters. But do these\nclassic algorithms, or some new ones using the same simple tools, have any\nchance against computer-aided cryptanalysis? In this paper I discuss how some\nhuman-computable algorithms can indeed afford sufficient security in this\nsituation, drawing conclusions from computer-based statistical analysis. Three\nkinds of algorithms are discussed: those that concentrate entropy from shared\ntext sources, stream ciphers based on arithmetic of non-binary spaces, and\nhash-like algorithms that may be used to generate a password from a challenge\ntext.",
            "author": [
                "Francisco Ruiz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02869v1",
                "http://arxiv.org/pdf/2312.02869v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03043v1",
            "title": "Navigating the Synthetic Realm: Harnessing Diffusion-based Models for\n  Laparoscopic Text-to-Image Generation",
            "updated": "2023-12-05T16:20:22Z",
            "published": "2023-12-05T16:20:22Z",
            "summary": "Recent advances in synthetic imaging open up opportunities for obtaining\nadditional data in the field of surgical imaging. This data can provide\nreliable supplements supporting surgical applications and decision-making\nthrough computer vision. Particularly the field of image-guided surgery, such\nas laparoscopic and robotic-assisted surgery, benefits strongly from synthetic\nimage datasets and virtual surgical training methods. Our study presents an\nintuitive approach for generating synthetic laparoscopic images from short text\nprompts using diffusion-based generative models. We demonstrate the usage of\nstate-of-the-art text-to-image architectures in the context of laparoscopic\nimaging with regard to the surgical removal of the gallbladder as an example.\nResults on fidelity and diversity demonstrate that diffusion-based models can\nacquire knowledge about the style and semantics in the field of image-guided\nsurgery. A validation study with a human assessment survey underlines the\nrealistic nature of our synthetic data, as medical personnel detects actual\nimages in a pool with generated images causing a false-positive rate of 66%. In\naddition, the investigation of a state-of-the-art machine learning model to\nrecognize surgical actions indicates enhanced results when trained with\nadditional generated images of up to 5.20%. Overall, the achieved image quality\ncontributes to the usage of computer-generated images in surgical applications\nand enhances its path to maturity.",
            "author": [
                "Simeon Allmendinger",
                "Patrick Hemmer",
                "Moritz Queisner",
                "Igor Sauer",
                "Leopold M\u00fcller",
                "Johannes Jakubik",
                "Michael V\u00f6ssing",
                "Niklas K\u00fchl"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03043v1",
                "http://arxiv.org/pdf/2312.03043v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02862v1",
            "title": "Constraints on non-local gravity from binary pulsars gravitational\n  emission",
            "updated": "2023-12-05T16:15:39Z",
            "published": "2023-12-05T16:15:39Z",
            "summary": "Non-local theories of gravity are considered extended theories of gravity,\nmeaning that when the non-local terms are canceled out, the limit of General\nRelativity (GR) is obtained. Several reasons have led us to consider this\ntheory with increasing interest, but primarily non-locality emerges in a\nnatural way as a side effect of the introduction of quantum corrections to GR,\nthe purpose of which was to cure the singularity problem, both at astrophysical\nand cosmological level. In this paper we studied a peculiar case of the so\ncalled Deser-Woodard theory consisting in the addition of a non-local term to\nthe Hilbert-Einstein lagrangian, and we derived for the first time contraints\non the dimensionaless non-local parameter A by exploiting the predicted\ngravitational wave emission in three binary pulsars, namely PSR J1012+5307, PSR\nJ0348+0432 and PSR $J1738+0333. We discovered that the instantaneous flux\nstrongly depends on A and that the best constraints (0.12 < A < 0.16) come from\nPSR J1012+5307, for which the GR prediction is outside the observational\nranges. However, since for PSR J1012 + 5307 scintillation is suspected, as\nemerged in a recent census by LOFAR, corruptions in pulsar timing could be\nhidden. We finally comment on the usability and reliability of this type of\ntest for extended theories of gravity.",
            "author": [
                "Amodio Carleo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02862v1",
                "http://arxiv.org/pdf/2312.02862v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02861v1",
            "title": "Skein and cluster algebras with coefficients for unpunctured surfaces",
            "updated": "2023-12-05T16:14:52Z",
            "published": "2023-12-05T16:14:52Z",
            "summary": "We propose a skein model for the quantum cluster algebras of surface type\nwith coefficients. We introduce a skein algebra\n$\\mathscr{S}_{\\Sigma,\\mathbb{W}}^{A}$ of a walled surface\n$(\\Sigma,\\mathbb{W})$, and prove that it has a quantum cluster structure. The\nwalled surfaces naturally generalize the marked surfaces with\nmulti-laminations, which have been used to describe the quantum cluster\nalgebras of geometric type for marked surfaces by Fomin--Thurston [FT18].\nMoreover, we give skein theoretic interpretation for some of\nquasi-homomorphisms [Fra16] between these quantum cluster algebras.",
            "author": [
                "Tsukasa Ishibashi",
                "Shunsuke Kano",
                "Wataru Yuasa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02861v1",
                "http://arxiv.org/pdf/2312.02861v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.QA",
                "13F60, 57K31 (Primary), 57K20 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02859v1",
            "title": "Lessons from Usable ML Deployments and Application to Wind Turbine\n  Monitoring",
            "updated": "2023-12-05T16:13:50Z",
            "published": "2023-12-05T16:13:50Z",
            "summary": "Through past experiences deploying what we call usable ML (one step beyond\nexplainable ML, including both explanations and other augmenting information)\nto real-world domains, we have learned three key lessons. First, many\norganizations are beginning to hire people who we call ``bridges'' because they\nbridge the gap between ML developers and domain experts, and these people fill\na valuable role in developing usable ML applications. Second, a configurable\nsystem that enables easily iterating on usable ML interfaces during\ncollaborations with bridges is key. Finally, there is a need for continuous,\nin-deployment evaluations to quantify the real-world impact of usable ML.\nThroughout this paper, we apply these lessons to the task of wind turbine\nmonitoring, an essential task in the renewable energy domain. Turbine engineers\nand data analysts must decide whether to perform costly in-person\ninvestigations on turbines to prevent potential cases of brakepad failure, and\nwell-tuned usable ML interfaces can aid with this decision-making process.\nThrough the applications of our lessons to this task, we hope to demonstrate\nthe potential real-world impact of usable ML in the renewable energy domain.",
            "author": [
                "Alexandra Zytek",
                "Wei-En Wang",
                "Sofia Koukoura",
                "Kalyan Veeramachaneni"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02859v1",
                "http://arxiv.org/pdf/2312.02859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02856v2",
            "title": "Comparative study of quantum emitter fabrication in wide bandgap\n  materials using localized electron irradiation",
            "updated": "2023-12-07T11:13:17Z",
            "published": "2023-12-05T16:12:37Z",
            "summary": "Quantum light sources are crucial foundational components for various quantum\ntechnology applications. With the rapid development of quantum technology,\nthere has been a growing demand for materials that are capable of hosting\nquantum emitters. One such material platform are fluorescent defects in\nhexagonal boron nitride (hBN) inducing deep sub-levels within the band gap. The\nquestion arises if other layered wide bandgap (2D) materials offer similar\nsingle photon emitting defects. Here, we investigate and compare the\nfabrication of quantum emitters in exfoliated multi-layer mica flakes with hBN\nand other wide bandgap 3D crystals (silicon carbide and gallium nitride) which\nare known to host quantum emitters. We use our primary fabrication technique of\nlocalized electron irradiation using a standard scanning electron microscope.\nTo complement our experimental work, we employ density functional theory\nsimulations to study the atomic structures of intrinsic defects and their\nphotophysical properties. While our fabrication technique can create hBN\nquantum emitters with a high yield and high single photon purity, it is unable\nto fabricate emitters in the other solid-state crystals under investigation.\nThis allows us to draw conclusions on the emitter fabrication mechanism, which\ncould be relying on the activation of already present defects by charge state\nmanipulation. We therefore provide an important step toward the identification\nof hBN emitters and their formation process.",
            "author": [
                "Anand Kumar",
                "Chanaprom Cholsuk",
                "Mohammad N. Mishuk",
                "Mouli Hazra",
                "Clotilde Pillot",
                "Tjorben Matthes",
                "Tanveer A. Shaik",
                "Asli Cakan",
                "Volker Deckert",
                "Sujin Suwanna",
                "Tobias Vogl"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02856v2",
                "http://arxiv.org/pdf/2312.02856v2"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02852v1",
            "title": "Expert-guided Bayesian Optimisation for Human-in-the-loop Experimental\n  Design of Known Systems",
            "updated": "2023-12-05T16:09:31Z",
            "published": "2023-12-05T16:09:31Z",
            "summary": "Domain experts often possess valuable physical insights that are overlooked\nin fully automated decision-making processes such as Bayesian optimisation. In\nthis article we apply high-throughput (batch) Bayesian optimisation alongside\nanthropological decision theory to enable domain experts to influence the\nselection of optimal experiments. Our methodology exploits the hypothesis that\nhumans are better at making discrete choices than continuous ones and enables\nexperts to influence critical early decisions. At each iteration we solve an\naugmented multi-objective optimisation problem across a number of alternate\nsolutions, maximising both the sum of their utility function values and the\ndeterminant of their covariance matrix, equivalent to their total variability.\nBy taking the solution at the knee point of the Pareto front, we return a set\nof alternate solutions at each iteration that have both high utility values and\nare reasonably distinct, from which the expert selects one for evaluation. We\ndemonstrate that even in the case of an uninformed practitioner, our algorithm\nrecovers the regret of standard Bayesian optimisation.",
            "author": [
                "Tom Savage",
                "Ehecatl Antonio del Rio Chanona"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02852v1",
                "http://arxiv.org/pdf/2312.02852v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03042v1",
            "title": "Inherent limitations of LLMs regarding spatial information",
            "updated": "2023-12-05T16:02:20Z",
            "published": "2023-12-05T16:02:20Z",
            "summary": "Despite the significant advancements in natural language processing\ncapabilities demonstrated by large language models such as ChatGPT, their\nproficiency in comprehending and processing spatial information, especially\nwithin the domains of 2D and 3D route planning, remains notably underdeveloped.\nThis paper investigates the inherent limitations of ChatGPT and similar models\nin spatial reasoning and navigation-related tasks, an area critical for\napplications ranging from autonomous vehicle guidance to assistive technologies\nfor the visually impaired. In this paper, we introduce a novel evaluation\nframework complemented by a baseline dataset, meticulously crafted for this\nstudy. This dataset is structured around three key tasks: plotting spatial\npoints, planning routes in two-dimensional (2D) spaces, and devising pathways\nin three-dimensional (3D) environments. We specifically developed this dataset\nto assess the spatial reasoning abilities of ChatGPT. Our evaluation reveals\nkey insights into the model's capabilities and limitations in spatial\nunderstanding.",
            "author": [
                "He Yan",
                "Xinyao Hu",
                "Xiangpeng Wan",
                "Chengyu Huang",
                "Kai Zou",
                "Shiqi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03042v1",
                "http://arxiv.org/pdf/2312.03042v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02844v2",
            "title": "Modeling of SCADA and PMU Measurement Chains",
            "updated": "2023-12-06T17:04:23Z",
            "published": "2023-12-05T15:54:46Z",
            "summary": "In this document, the supervisory control and data acquisition (SCADA) and\nphasor measurement unit (PMU) measurement chain modeling will be studied, where\nthe measurement error sources of each component in the SCADA and PMU\nmeasurement chains and the reasons leading to measurement errors exhibiting\nnon-zero-mean, non-Gaussian, and time-varying statistical characteristic are\nsummarized and analyzed. This document provides a few equations, figures, and\ndiscussions about the details of the SCADA and PMU measurement error chain\nmodeling, which are intended to facilitate the understanding of how the\nmeasurement errors are designed for each component in the SCADA and PMU\nmeasurement chains. The measurement chain models described here are also used\nfor synthesizing measurement errors with realistic characteristics in\nsimulation cases to test the developed algorithms or methodologies.",
            "author": [
                "Gang Cheng",
                "Yuzhang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02844v2",
                "http://arxiv.org/pdf/2312.02844v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02843v1",
            "title": "Are Vision Transformers More Data Hungry Than Newborn Visual Systems?",
            "updated": "2023-12-05T15:53:24Z",
            "published": "2023-12-05T15:53:24Z",
            "summary": "Vision transformers (ViTs) are top performing models on many computer vision\nbenchmarks and can accurately predict human behavior on object recognition\ntasks. However, researchers question the value of using ViTs as models of\nbiological learning because ViTs are thought to be more data hungry than\nbrains, with ViTs requiring more training data to reach similar levels of\nperformance. To test this assumption, we directly compared the learning\nabilities of ViTs and animals, by performing parallel controlled rearing\nexperiments on ViTs and newborn chicks. We first raised chicks in impoverished\nvisual environments containing a single object, then simulated the training\ndata available in those environments by building virtual animal chambers in a\nvideo game engine. We recorded the first-person images acquired by agents\nmoving through the virtual chambers and used those images to train self\nsupervised ViTs that leverage time as a teaching signal, akin to biological\nvisual systems. When ViTs were trained through the eyes of newborn chicks, the\nViTs solved the same view invariant object recognition tasks as the chicks.\nThus, ViTs were not more data hungry than newborn visual systems: both learned\nview invariant object representations in impoverished visual environments. The\nflexible and generic attention based learning mechanism in ViTs combined with\nthe embodied data streams available to newborn animals appears sufficient to\ndrive the development of animal-like object recognition.",
            "author": [
                "Lalit Pandey",
                "Samantha M. W. Wood",
                "Justin N. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02843v1",
                "http://arxiv.org/pdf/2312.02843v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02839v1",
            "title": "Low-complexity Linear Multicast Beamforming for Cache-aided MIMO\n  Communications",
            "updated": "2023-12-05T15:45:19Z",
            "published": "2023-12-05T15:45:19Z",
            "summary": "A practical and scalable multicast beamformer design in multi-input\nmulti-output~(MIMO) coded caching~(CC) systems is introduced in this paper. The\nproposed approach allows multicast transmission to multiple groups with\npartially overlapping user sets using receiver dimensions to distinguish\nbetween different group-specific streams. Additionally, it provides flexibility\nin accommodating various parameter configurations of the MIMO-CC setup and\novercomes practical limitations, such as the requirement to use successive\ninterference cancellation~(SIC) at the receiver, while achieving the same\ndegrees-of-freedom~(DoF). To evaluate the proposed scheme, we define the\nsymmetric rate as the sum rate of the partially overlapping streams received\nper user, comprising a linear multistream multicast transmission vector and the\nlinear minimum mean square error~(LMMSE) receiver. The resulting non-convex\nsymmetric rate maximization problem is solved using alternative optimization\nand successive convex approximation~(SCA). Moreover, a fast iterative\nLagrangian-based algorithm is developed, significantly reducing the\ncomputational overhead compared to previous designs. The effectiveness of our\nproposed method is demonstrated by extensive simulations.",
            "author": [
                "Mohammad NaseriTehrani",
                "MohammadJavad Salehi",
                "Antti T\u00f6lli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02839v1",
                "http://arxiv.org/pdf/2312.02839v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02838v1",
            "title": "The $2\\times 2$-upper triangular matrix algebra and its generalized\n  polynomial identities",
            "updated": "2023-12-05T15:44:54Z",
            "published": "2023-12-05T15:44:54Z",
            "summary": "Let $UT_2$ be the algebra of $2\\times 2$ upper triangular matrices over a\nfield $F$ of characteristic zero. Here we study the generalized polynomial\nidentities of $UT_2$, i.e., identical relations holding for $UT_2$ regarded as\n$UT_2$-algebra. We determine a set of two generators of the $T_{UT_2}$-ideal of\ngeneralized polynomial identities of $UT_2$ and compute the exact values of the\ncorresponding sequence of generalized codimensions. Moreover, we give a\ncomplete description of the space of multilinear generalized identities in $n$\nvariables in the language of Young diagrams through the representation theory\nof the symmetric group $S_n$. Finally, we prove that, unlike in the ordinary\ncase, the generalized variety of $UT_2$-algebras generated by $UT_2$ has no\nalmost polynomial growth; nevertheless, we exhibit two distinct generalized\nvarieties of almost polynomial growth.",
            "author": [
                "F. Martino",
                "C. Rizzo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02838v1",
                "http://arxiv.org/pdf/2312.02838v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA",
                "16R10, 16R50 (Primary) 16P90, 20C30 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02834v1",
            "title": "The optimization, design and performance of the FBCM23 ASIC for the\n  upgraded CMS beam monitoring system",
            "updated": "2023-12-05T15:36:40Z",
            "published": "2023-12-05T15:36:40Z",
            "summary": "We present the development of the FBCM23 ASIC designed for the Phase-II\nupgrade of the Fast Beam Condition Monitoring (FBCM) system built at the CMS\nexperiment which will replace the present luminometer based on the BCM1F ASIC\n[1]. The FBCM system should provide reliable luminosity measurement with 1 ns\ntime resolution enabling the detection of beam-induced background. The FBCM23\nASIC comprises 6 channels of the fast front-end amplifier working in\ntransimpedance configuration followed by CR-RC$^3$ shaper and leading edge\ndiscriminator. The paper will show the optimization of the design, overall\narchitecture, and the detailed implementation in a CMOS 65 nm process as well\nas preliminary electrical performance.",
            "author": [
                "Jan Kaplon",
                "Grzegorz Wegrzyn",
                "Konstantin Shibin",
                "Marnix Barendregt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02834v1",
                "http://arxiv.org/pdf/2312.02834v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02832v1",
            "title": "Indefinite causal order for quantum phase estimation with Pauli noise",
            "updated": "2023-12-05T15:30:31Z",
            "published": "2023-12-05T15:30:31Z",
            "summary": "This letter further explores the recent scheme of switched quantum channels\nwith indefinite causal order applied to the reference metrological task of\nquantum phase estimation in the presence of noise. We especially extend the\nexplorations, previously reported with depolarizing noise and thermal noise, to\nthe class of Pauli noises, important to the qubit and not previously addressed.\nNonstandard capabilities, not accessible with standard quantum phase\nestimation, are exhibited and analyzed, with significant properties that are\nspecific to the Pauli noises, while other properties are found in common with\nthe depolarizing noise or the thermal noise. The results show that the presence\nand the type of quantum noise are both crucial to the determination of the\nnonstandard capabilities from the switched channel with indefinite causal\norder, with a constructive action of noise reminiscent of stochastic resonance\nphenomena. The study contributes to a more comprehensive and systematic\ncharacterization of the roles and specificities of quantum noise in the\noperation of the novel devices of switched quantum channels with indefinite\ncausal order.",
            "author": [
                "Francois Chapeau-Blondeau"
            ],
            "link": [
                "http://dx.doi.org/10.1142/S0219477523500360",
                "http://arxiv.org/abs/2312.02832v1",
                "http://arxiv.org/pdf/2312.02832v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02829v1",
            "title": "MIMONets: Multiple-Input-Multiple-Output Neural Networks Exploiting\n  Computation in Superposition",
            "updated": "2023-12-05T15:25:45Z",
            "published": "2023-12-05T15:25:45Z",
            "summary": "With the advent of deep learning, progressively larger neural networks have\nbeen designed to solve complex tasks. We take advantage of these capacity-rich\nmodels to lower the cost of inference by exploiting computation in\nsuperposition. To reduce the computational burden per input, we propose\nMultiple-Input-Multiple-Output Neural Networks (MIMONets) capable of handling\nmany inputs at once. MIMONets augment various deep neural network architectures\nwith variable binding mechanisms to represent an arbitrary number of inputs in\na compositional data structure via fixed-width distributed representations.\nAccordingly, MIMONets adapt nonlinear neural transformations to process the\ndata structure holistically, leading to a speedup nearly proportional to the\nnumber of superposed input items in the data structure. After processing in\nsuperposition, an unbinding mechanism recovers each transformed input of\ninterest. MIMONets also provide a dynamic trade-off between accuracy and\nthroughput by an instantaneous on-demand switching between a set of\naccuracy-throughput operating points, yet within a single set of fixed\nparameters. We apply the concept of MIMONets to both CNN and Transformer\narchitectures resulting in MIMOConv and MIMOFormer, respectively. Empirical\nevaluations show that MIMOConv achieves about 2-4 x speedup at an accuracy\ndelta within [+0.68, -3.18]% compared to WideResNet CNNs on CIFAR10 and\nCIFAR100. Similarly, MIMOFormer can handle 2-4 inputs at once while maintaining\na high average accuracy within a [-1.07, -3.43]% delta on the long range arena\nbenchmark. Finally, we provide mathematical bounds on the interference between\nsuperposition channels in MIMOFormer. Our code is available at\nhttps://github.com/IBM/multiple-input-multiple-output-nets.",
            "author": [
                "Nicolas Menet",
                "Michael Hersche",
                "Geethan Karunaratne",
                "Luca Benini",
                "Abu Sebastian",
                "Abbas Rahimi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02829v1",
                "http://arxiv.org/pdf/2312.02829v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02826v1",
            "title": "Calibrated Adaptive Teacher for Domain Adaptive Intelligent Fault\n  Diagnosis",
            "updated": "2023-12-05T15:19:29Z",
            "published": "2023-12-05T15:19:29Z",
            "summary": "Intelligent Fault Diagnosis (IFD) based on deep learning has proven to be an\neffective and flexible solution, attracting extensive research. Deep neural\nnetworks can learn rich representations from vast amounts of representative\nlabeled data for various applications. In IFD, they achieve high classification\nperformance from signals in an end-to-end manner, without requiring extensive\ndomain knowledge. However, deep learning models usually only perform well on\nthe data distribution they have been trained on. When applied to a different\ndistribution, they may experience performance drops. This is also observed in\nIFD, where assets are often operated in working conditions different from those\nin which labeled data have been collected. Unsupervised domain adaptation (UDA)\ndeals with the scenario where labeled data are available in a source domain,\nand only unlabeled data are available in a target domain, where domains may\ncorrespond to operating conditions. Recent methods rely on training with\nconfident pseudo-labels for target samples. However, the confidence-based\nselection of pseudo-labels is hindered by poorly calibrated confidence\nestimates in the target domain, primarily due to over-confident predictions,\nwhich limits the quality of pseudo-labels and leads to error accumulation. In\nthis paper, we propose a novel UDA method called Calibrated Adaptive Teacher\n(CAT), where we propose to calibrate the predictions of the teacher network\nthroughout the self-training process, leveraging post-hoc calibration\ntechniques. We evaluate CAT on domain-adaptive IFD and perform extensive\nexperiments on the Paderborn benchmark for bearing fault diagnosis under\nvarying operating conditions. Our proposed method achieves state-of-the-art\nperformance on most transfer tasks.",
            "author": [
                "Florent Forest",
                "Olga Fink"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02826v1",
                "http://arxiv.org/pdf/2312.02826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP",
                "stat.ML",
                "68T07, 62H30",
                "I.2.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03039v1",
            "title": "Insights into the first and second hydrostatic core stages from\n  numerical simulations",
            "updated": "2023-12-05T15:12:59Z",
            "published": "2023-12-05T15:12:59Z",
            "summary": "The theory of how low mass stars form from the collapse of a dense molecular\ncloud core has been well-established for decades. Thanks to significant\nprogress in computing and numerical modelling, more physical models have been\ndeveloped and a wider parameter space explored to understand the early stages\nof star formation more fully. In this review, I describe the expected physical\nproperties of the first and second core stages and how the inclusion of\ndifferent physics affects those predicted characteristics. I provide an\noverview of chemical models and synthetic observations, looking towards the\npositive identification of the first core in nature, which remains elusive.\nHowever, there are a few likely candidate first cores, which are listed, and I\nbriefly discuss the recent progress in characterising the youngest protostellar\nsources. Chemistry will be instrumental in the firm identification of the first\ncore so we require robust theoretical predictions of the chemical evolution of\nprotostellar cores, especially of the first and second core outflows. Looking\nahead, simulations can shed light on how the protostellar collapse phase shapes\nthe evolution of the protostellar disc. Simulations of dust evolution during\nprotostellar core collapse show there is significant enhancement in grain size\nand abundance towards the centre of the core. Chemical models show that the\nwarm, dense conditions of the first core drive chemical evolution. There is a\nwide scope for further study of the role that the first and second core stages\nplay in determining the structure and composition of the protostellar disc and\nenvelope and, of course, the eventual influence on the formation of planets.",
            "author": [
                "Alison K. Young"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03039v1",
                "http://arxiv.org/pdf/2312.03039v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02820v1",
            "title": "Clustering Pseudo Language Family in Multilingual Translation Models\n  with Fisher Information Matrix",
            "updated": "2023-12-05T15:03:27Z",
            "published": "2023-12-05T15:03:27Z",
            "summary": "In multilingual translation research, the comprehension and utilization of\nlanguage families are of paramount importance. Nevertheless, clustering\nlanguages based solely on their ancestral families can yield suboptimal results\ndue to variations in the datasets employed during the model's training phase.\nTo mitigate this challenge, we introduce an innovative method that leverages\nthe fisher information matrix (FIM) to cluster language families, anchored on\nthe multilingual translation model's characteristics. We hypothesize that\nlanguage pairs with similar effects on model parameters exhibit a considerable\ndegree of linguistic congruence and should thus be grouped cohesively. This\nconcept has led us to define pseudo language families. We provide an in-depth\ndiscussion regarding the inception and application of these pseudo language\nfamilies. Empirical evaluations reveal that employing these pseudo language\nfamilies enhances performance over conventional language families in adapting a\nmultilingual translation model to unfamiliar language pairs. The proposed\nmethodology may also be extended to scenarios requiring language similarity\nmeasurements. The source code and associated scripts can be accessed at\nhttps://github.com/ecoli-hit/PseudoFamily.",
            "author": [
                "Xinyu Ma",
                "Xuebo Liu",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02820v1",
                "http://arxiv.org/pdf/2312.02820v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02819v1",
            "title": "Deterministic Guidance Diffusion Model for Probabilistic Weather\n  Forecasting",
            "updated": "2023-12-05T15:03:15Z",
            "published": "2023-12-05T15:03:15Z",
            "summary": "Weather forecasting requires not only accuracy but also the ability to\nperform probabilistic prediction. However, deterministic weather forecasting\nmethods do not support probabilistic predictions, and conversely, probabilistic\nmodels tend to be less accurate. To address these challenges, in this paper, we\nintroduce the \\textbf{\\textit{D}}eterministic \\textbf{\\textit{G}}uidance\n\\textbf{\\textit{D}}iffusion \\textbf{\\textit{M}}odel (DGDM) for probabilistic\nweather forecasting, integrating benefits of both deterministic and\nprobabilistic approaches. During the forward process, both the deterministic\nand probabilistic models are trained end-to-end. In the reverse process,\nweather forecasting leverages the predicted result from the deterministic\nmodel, using as an intermediate starting point for the probabilistic model. By\nfusing deterministic models with probabilistic models in this manner, DGDM is\ncapable of providing accurate forecasts while also offering probabilistic\npredictions. To evaluate DGDM, we assess it on the global weather forecasting\ndataset (WeatherBench) and the common video frame prediction benchmark (Moving\nMNIST). We also introduce and evaluate the Pacific Northwest Windstorm\n(PNW)-Typhoon weather satellite dataset to verify the effectiveness of DGDM in\nhigh-resolution regional forecasting. As a result of our experiments, DGDM\nachieves state-of-the-art results not only in global forecasting but also in\nregional forecasting. The code is available at:\n\\url{https://github.com/DongGeun-Yoon/DGDM}.",
            "author": [
                "Donggeun Yoon",
                "Minseok Seo",
                "Doyi Kim",
                "Yeji Choi",
                "Donghyeon Cho"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02819v1",
                "http://arxiv.org/pdf/2312.02819v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02818v1",
            "title": "Optimally combined incentive for cooperation among interacting agents in\n  population games",
            "updated": "2023-12-05T15:01:57Z",
            "published": "2023-12-05T15:01:57Z",
            "summary": "Combined prosocial incentives, integrating reward for cooperators and\npunishment for defectors, are effective tools to promote cooperation among\ncompeting agents in population games. Existing research concentrated on how to\nadjust reward or punishment, as two mutually exclusive tools, during the\nevolutionary process to achieve the desired proportion of cooperators in the\npopulation, and less attention has been given to exploring a combined\nincentive-based control policy that can steer the system to the full\ncooperation state at the lowest cost. In this work we propose a combined\nincentive scheme in a population of agents whose conflicting interactions are\ndescribed by the prisoner's dilemma game on complete graphs and regular\nnetworks, respectively. By devising an index function for quantifying the\nimplementation cost of the combined incentives, we analytically construct the\noptimally combined incentive protocol by using optimal control theory. By means\nof theoretical analysis, we identify the mathematical conditions, under which\nthe optimally combined incentive scheme requires the minimal amount of cost. In\naddition to numerical calculations, we further perform computer simulations to\nverify our theoretical results and explore their robustness on different types\nof network structures.",
            "author": [
                "Shengxian Wang",
                "Ming Cao",
                "Xiaojie Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02818v1",
                "http://arxiv.org/pdf/2312.02818v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02816v1",
            "title": "The Great Dimming of Betelgeuse: the photosphere as revealed by\n  tomography during the past 15 years",
            "updated": "2023-12-05T14:57:49Z",
            "published": "2023-12-05T14:57:49Z",
            "summary": "Betelgeuse, a red supergiant star of semi-regular variability, underwent a\nhistorical minimum of brightness in February 2020, the Great Dimming. Even\nthough the brightness has returned to the values prior to the Great Dimming by\nnow, it continues to exhibit highly unusual behavior. Understanding the\nlong-term atmospheric motions of Betelgeuse and its variability could be a clue\nto the nature of the Great Dimming and the mass-loss process in red\nsupergiants. Our goal is to study long-term dynamics of the photosphere. We\napplied the tomographic method, which allows different layers in the stellar\natmosphere to be probed in order to reconstruct depth-dependent velocity\nfields. The method is based on the construction of spectral masks by grouping\nspectral lines from specific optical depths. These masks are cross-correlated\nwith the observed spectra to recover the velocity field inside each atmospheric\nlayer. We obtained about 2700 spectra during the past 15 years, observed with\nthe STELLA robotic telescope in Tenerife. We analysed the variability of 5\ndifferent layers of Betelgeuses photosphere. We found phase shift between the\nlayers, as well as between the variability of velocity and photometry. The time\nvariations of the widths of the cross-correlation function reveal propagation\nof two shock waves during the Great Dimming. For about 2 years after the\nDimming, the time scale of variability was different between the inner and\nouter photospheric layers. By 2022, all the layers seemingly started to follow\na similar behavior as before the Dimming, but pulsating with higher frequency\ncorresponding with the first overtone. Combination of the extensive\nhigh-resolution spectroscopic data set with the tomographic method revealed the\nvariable velocity fields in the photosphere of Betelgeuse, for the first time\nin such detail.",
            "author": [
                "Daniel Jadlovsk\u00fd",
                "Thomas Granzer",
                "Michael Weber",
                "Kateryna Kravchenko",
                "Ji\u0159\u00ed Krti\u010dka",
                "K. Andrea Dupree",
                "Andrea Chiavassa",
                "G. Klaus Strassmeier",
                "Katja Poppenh\u00e4ger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02816v1",
                "http://arxiv.org/pdf/2312.02816v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02810v2",
            "title": "Using the SP!CE Framework to Code Influence Campaign Activity on Social\n  Media: Case Study on the 2022 Brazilian Presidential Election",
            "updated": "2023-12-06T14:34:28Z",
            "published": "2023-12-05T14:52:33Z",
            "summary": "We describe a case study in the use of the Structured Process for Information\nCampaign Enhancement (SP!CE, version 2.1) to evaluate influence campaigns\npresent in the 2nd round of the Brazilian presidential election in 2022\nOctober. SP!CE is a US-military focused framework for describing both friendly\nand adversary actions in influence campaigns, and is inter-operable with the\nDisinformation Analysis and Risk Management (DISARM) framework. The purpose of\nthe case study is to demonstrate how SP!CE can be used to describe influence\ncampaign behaviors. We selected the Brazilian election as the target of the\ncase study as it is known that there were significant amounts of mis- and\ndisinformation present on social media during the campaigns. Our goal was to\ndemonstrate how SP!CE could be applied in such a context, showing how social\nmedia content could be aligned with information campaign behaviors and how such\nan alignment can be used to analyze which mis- and disinformation narratives\nwere in play. Additionally, we aim to provide insights on best practices\nregarding how to apply the framework in further research. We release the coding\nand screenshots of the relevant social media posts to support future research.",
            "author": [
                "Alexander Gocso",
                "Claudia Perez Brito",
                "Bryan Ruesca",
                "Allen Mendes",
                "Mark A. Finlayson"
            ],
            "link": [
                "http://dx.doi.org/10.34703/gzx1-9v95/8PC8JY",
                "http://arxiv.org/abs/2312.02810v2",
                "http://arxiv.org/pdf/2312.02810v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02809v1",
            "title": "Semi-implicit Continuous Newton Method for Power Flow Analysis",
            "updated": "2023-12-05T14:52:06Z",
            "published": "2023-12-05T14:52:06Z",
            "summary": "This paper proposes a semi-implicit version of continuous Newton method (CNM)\nfor power flow analysis. The proposed method succeeds the numerical robustness\nfrom the implicit CNM (ICNM) framework while prevents the iterative solution of\nnonlinear systems, hence revealing higher convergence speed and computation\nefficiency. The intractability of ICNM consists in its nonlinear implicit\nordinary-differential-equation (ODE) nature. We circumvent this by introducing\nintermediate variables, hence converting the implicit ODEs into differential\nalgebraic equations (DAEs), and solve the DAEs with a linear scheme, the\nstiffly accurate Rosenbrock type method (SARM). A new 4-stage 3rd-order\nhyper-stable SARM, together with a 2nd-order embedded formula to control the\nstep size, is constructed. Case studies on system 9241pegase verified the\nalleged performance.",
            "author": [
                "Ruizhi Yu",
                "Wei Gu",
                "Shuai Lu",
                "Yijun Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02809v1",
                "http://arxiv.org/pdf/2312.02809v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02807v1",
            "title": "Online Change Detection in SAR Time-Series with Kronecker Product\n  Structured Scaled Gaussian Models",
            "updated": "2023-12-05T14:49:53Z",
            "published": "2023-12-05T14:49:53Z",
            "summary": "We develop the information geometry of scaled Gaussian distributions for\nwhich the covariance matrix exhibits a Kronecker product structure. This model\nand its geometry are then used to propose an online change detection (CD)\nalgorithm for multivariate image times series (MITS). The proposed approach\nrelies mainly on the online estimation of the structured covariance matrix\nunder the null hypothesis, which is performed through a recursive (natural)\nRiemannian gradient descent. This approach exhibits a practical interest\ncompared to the corresponding offline version, as its computational cost\nremains constant for each new image added in the time series. Simulations show\nthat the proposed recursive estimators reach the Intrinsic Cram\\'er-Rao bound.\nThe interest of the proposed online CD approach is demonstrated on both\nsimulated and real data.",
            "author": [
                "Ammar Mian",
                "Guillaume Ginolhac",
                "Florent Bouchard",
                "Arnaud Breloy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02807v1",
                "http://arxiv.org/pdf/2312.02807v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02804v1",
            "title": "Score-Aware Policy-Gradient Methods and Performance Guarantees using\n  Local Lyapunov Conditions: Applications to Product-Form Stochastic Networks\n  and Queueing Systems",
            "updated": "2023-12-05T14:44:58Z",
            "published": "2023-12-05T14:44:58Z",
            "summary": "Stochastic networks and queueing systems often lead to Markov decision\nprocesses (MDPs) with large state and action spaces as well as nonconvex\nobjective functions, which hinders the convergence of many reinforcement\nlearning (RL) algorithms. Policy-gradient methods perform well on MDPs with\nlarge state and action spaces, but they sometimes experience slow convergence\ndue to the high variance of the gradient estimator. In this paper, we show that\nsome of these difficulties can be circumvented by exploiting the structure of\nthe underlying MDP. We first introduce a new family of gradient estimators\ncalled score-aware gradient estimators (SAGEs). When the stationary\ndistribution of the MDP belongs to an exponential family parametrized by the\npolicy parameters, SAGEs allow us to estimate the policy gradient without\nrelying on value-function estimation, contrary to classical policy-gradient\nmethods like actor-critic. To demonstrate their applicability, we examine two\ncommon control problems arising in stochastic networks and queueing systems\nwhose stationary distributions have a product-form, a special case of\nexponential families. As a second contribution, we show that, under appropriate\nassumptions, the policy under a SAGE-based policy-gradient method has a large\nprobability of converging to an optimal policy, provided that it starts\nsufficiently close to it, even with a nonconvex objective function and multiple\nmaximizers. Our key assumptions are that, locally around a maximizer, a\nnondegeneracy property of the Hessian of the objective function holds and a\nLyapunov function exists. Finally, we conduct a numerical comparison between a\nSAGE-based policy-gradient method and an actor-critic algorithm. The results\ndemonstrate that the SAGE-based method finds close-to-optimal policies more\nrapidly, highlighting its superior performance over the traditional\nactor-critic method.",
            "author": [
                "C\u00e9line Comte",
                "Matthieu Jonckheere",
                "Jaron Sanders",
                "Albert Senen-Cerda"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02804v1",
                "http://arxiv.org/pdf/2312.02804v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PF",
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02803v1",
            "title": "Leveraging Domain Adaptation and Data Augmentation to Improve Qur'anic\n  IR in English and Arabic",
            "updated": "2023-12-05T14:44:08Z",
            "published": "2023-12-05T14:44:08Z",
            "summary": "In this work, we approach the problem of Qur'anic information retrieval (IR)\nin Arabic and English. Using the latest state-of-the-art methods in neural IR,\nwe research what helps to tackle this task more efficiently. Training retrieval\nmodels requires a lot of data, which is difficult to obtain for training\nin-domain. Therefore, we commence with training on a large amount of general\ndomain data and then continue training on in-domain data. To handle the lack of\nin-domain data, we employed a data augmentation technique, which considerably\nimproved results in MRR@10 and NDCG@5 metrics, setting the state-of-the-art in\nQur'anic IR for both English and Arabic. The absence of an Islamic corpus and\ndomain-specific model for IR task in English motivated us to address this lack\nof resources and take preliminary steps of the Islamic corpus compilation and\ndomain-specific language model (LM) pre-training, which helped to improve the\nperformance of the retrieval models that use the domain-specific LM as the\nshared backbone. We examined several language models (LMs) in Arabic to select\none that efficiently deals with the Qur'anic IR task. Besides transferring\nsuccessful experiments from English to Arabic, we conducted additional\nexperiments with retrieval task in Arabic to amortize the scarcity of general\ndomain datasets used to train the retrieval models. Handling Qur'anic IR task\ncombining English and Arabic allowed us to enhance the comparison and share\nvaluable insights across models and languages.",
            "author": [
                "Vera Pavlova"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02803v1",
                "http://arxiv.org/pdf/2312.02803v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02800v1",
            "title": "Current-controlled periodic double-polarity reversals in a spin-torque\n  vortex oscillator",
            "updated": "2023-12-05T14:36:19Z",
            "published": "2023-12-05T14:36:19Z",
            "summary": "Micromagnetic simulations are used to study a spin-torque vortex oscillator\nexcited by an out-of-plane dc current. The vortex core gyration amplitude is\nconfined between two orbits due to periodical vortex core polarity reversals.\nThe upper limit corresponds to the orbit where the vortex core reaches its\ncritical velocity triggering the first polarity reversal which is immediately\nfollowed by a second one. After this double polarity reversal, the vortex core\nis on a smaller orbit that defines the lower limit of the vortex core gyration\namplitude. This double reversal process is a periodic phenomenon and its\nfrequency as well as the upper and lower limits of the vortex core gyration are\ncontrolled by the input current density while the vortex chirality determines\nthe onset of this confinement regime. In this non-linear regime, the vortex\ncore never reaches a stable orbit and thus, it may be of interest for\nneuromorphic application, for example as a leaky integrate-and-fire neuron.",
            "author": [
                "Chlo\u00e9 Chopin",
                "Simon de Wergifosse",
                "Anatole Moureaux",
                "Flavio Abreu Araujo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02800v1",
                "http://arxiv.org/pdf/2312.02800v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02798v1",
            "title": "Weakly Supervised Detection of Hallucinations in LLM Activations",
            "updated": "2023-12-05T14:35:11Z",
            "published": "2023-12-05T14:35:11Z",
            "summary": "We propose an auditing method to identify whether a large language model\n(LLM) encodes patterns such as hallucinations in its internal states, which may\npropagate to downstream tasks. We introduce a weakly supervised auditing\ntechnique using a subset scanning approach to detect anomalous patterns in LLM\nactivations from pre-trained models. Importantly, our method does not need\nknowledge of the type of patterns a-priori. Instead, it relies on a reference\ndataset devoid of anomalies during testing. Further, our approach enables the\nidentification of pivotal nodes responsible for encoding these patterns, which\nmay offer crucial insights for fine-tuning specific sub-networks for bias\nmitigation. We introduce two new scanning methods to handle LLM activations for\nanomalous sentences that may deviate from the expected distribution in either\ndirection. Our results confirm prior findings of BERT's limited internal\ncapacity for encoding hallucinations, while OPT appears capable of encoding\nhallucination information internally. Importantly, our scanning approach,\nwithout prior exposure to false statements, performs comparably to a fully\nsupervised out-of-distribution classifier.",
            "author": [
                "Miriam Rateike",
                "Celia Cintas",
                "John Wamburu",
                "Tanya Akumu",
                "Skyler Speakman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02798v1",
                "http://arxiv.org/pdf/2312.02798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02796v1",
            "title": "Materials Expert-Artificial Intelligence for Materials Discovery",
            "updated": "2023-12-05T14:29:18Z",
            "published": "2023-12-05T14:29:18Z",
            "summary": "The advent of material databases provides an unprecedented opportunity to\nuncover predictive descriptors for emergent material properties from vast data\nspace. However, common reliance on high-throughput ab initio data necessarily\ninherits limitations of such data: mismatch with experiments. On the other\nhand, experimental decisions are often guided by an expert's intuition honed\nfrom experiences that are rarely articulated. We propose using machine learning\nto \"bottle\" such operational intuition into quantifiable descriptors using\nexpertly curated measurement-based data. We introduce \"Materials\nExpert-Artificial Intelligence\" (ME-AI) to encapsulate and articulate this\nhuman intuition. As a first step towards such a program, we focus on the\ntopological semimetal (TSM) among square-net materials as the property inspired\nby the expert-identified descriptor based on structural information: the\ntolerance factor. We start by curating a dataset encompassing 12 primary\nfeatures of 879 square-net materials, using experimental data whenever\npossible. We then use Dirichlet-based Gaussian process regression using a\nspecialized kernel to reveal composite descriptors for square-net topological\nsemimetals. The ME-AI learned descriptors independently reproduce expert\nintuition and expand upon it. Specifically, new descriptors point to\nhypervalency as a critical chemical feature predicting TSM within square-net\ncompounds. Our success with a carefully defined problem points to the \"machine\nbottling human insight\" approach as promising for machine learning-aided\nmaterial discovery.",
            "author": [
                "Yanjun Liu",
                "Milena Jovanovic",
                "Krishnanand Mallayya",
                "Wesley J. Maddox",
                "Andrew Gordon Wilson",
                "Sebastian Klemenz",
                "Leslie M. Schoop",
                "Eun-Ah Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02796v1",
                "http://arxiv.org/pdf/2312.02796v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.str-el",
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02795v1",
            "title": "Regular immersions directed by algebraically elliptic cones",
            "updated": "2023-12-05T14:26:40Z",
            "published": "2023-12-05T14:26:40Z",
            "summary": "Let $M$ be an open Riemann surface and $A$ be the punctured cone in\n$\\mathbb{C}^n\\setminus\\{0\\}$ on a smooth projective variety $Y$ in\n$\\mathbb{P}^{n-1}$. Recently, Runge approximation theorems with interpolation\nfor holomorphic immersions $M\\to\\mathbb{C}^n$, directed by $A$, have been\nproved under the assumption that $A$ is an Oka manifold. We prove analogous\nresults in the algebraic setting, for regular immersions directed by $A$ from a\nsmooth affine curve $M$ into $\\mathbb{C}^n$. The Oka property is naturally\nreplaced by the stronger assumption that $A$ is algebraically elliptic, which\nit is if $Y$ is uniformly rational. Under this assumption, a homotopy-theoretic\nnecessary and sufficient condition for approximation and interpolation emerges.\nWe show that this condition is satisfied in many cases of interest.",
            "author": [
                "Antonio Alarcon",
                "Finnur Larusson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02795v1",
                "http://arxiv.org/pdf/2312.02795v1"
            ],
            "primary_category": "math.CV",
            "category": [
                "math.CV",
                "math.AG",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02791v1",
            "title": "Unsupervised learning on spontaneous retinal activity leads to efficient\n  neural representation geometry",
            "updated": "2023-12-05T14:22:46Z",
            "published": "2023-12-05T14:22:46Z",
            "summary": "Prior to the onset of vision, neurons in the developing mammalian retina\nspontaneously fire in correlated activity patterns known as retinal waves.\nExperimental evidence suggests that retinal waves strongly influence the\nemergence of sensory representations before visual experience. We aim to model\nthis early stage of functional development by using movies of neurally active\ndeveloping retinas as pre-training data for neural networks. Specifically, we\npre-train a ResNet-18 with an unsupervised contrastive learning objective\n(SimCLR) on both simulated and experimentally-obtained movies of retinal waves,\nthen evaluate its performance on image classification tasks. We find that\npre-training on retinal waves significantly improves performance on tasks that\ntest object invariance to spatial translation, while slightly improving\nperformance on more complex tasks like image classification. Notably, these\nperformance boosts are realized on held-out natural images even though the\npre-training procedure does not include any natural image data. We then propose\na geometrical explanation for the increase in network performance, namely that\nthe spatiotemporal characteristics of retinal waves facilitate the formation of\nseparable feature representations. In particular, we demonstrate that networks\npre-trained on retinal waves are more effective at separating image manifolds\nthan randomly initialized networks, especially for manifolds defined by sets of\nspatial translations. These findings indicate that the broad spatiotemporal\nproperties of retinal waves prepare networks for higher order feature\nextraction.",
            "author": [
                "Andrew Ligeralde",
                "Yilun Kuang",
                "Thomas Edward Yerxa",
                "Miah N. Pitcher",
                "Marla Feller",
                "SueYeon Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02791v1",
                "http://arxiv.org/pdf/2312.02791v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02786v1",
            "title": "Machine Learning Driven Sensitivity Analysis of E3SM Land Model\n  Parameters for Wetland Methane Emissions",
            "updated": "2023-12-05T14:16:13Z",
            "published": "2023-12-05T14:16:13Z",
            "summary": "Methane (CH4) is the second most critical greenhouse gas after carbon\ndioxide, contributing to 16-25% of the observed atmospheric warming. Wetlands\nare the primary natural source of methane emissions globally. However, wetland\nmethane emission estimates from biogeochemistry models contain considerable\nuncertainty. One of the main sources of this uncertainty arises from the\nnumerous uncertain model parameters within various physical, biological, and\nchemical processes that influence methane production, oxidation, and transport.\nSensitivity Analysis (SA) can help identify critical parameters for methane\nemission and achieve reduced biases and uncertainties in future projections.\nThis study performs SA for 19 selected parameters responsible for critical\nbiogeochemical processes in the methane module of the Energy Exascale Earth\nSystem Model (E3SM) land model (ELM). The impact of these parameters on various\nCH4 fluxes is examined at 14 FLUXNET- CH4 sites with diverse vegetation types.\nGiven the extensive number of model simulations needed for global\nvariance-based SA, we employ a machine learning (ML) algorithm to emulate the\ncomplex behavior of ELM methane biogeochemistry. ML enables the computational\ntime to be shortened significantly from 6 CPU hours to 0.72 milliseconds,\nachieving reduced computational costs. We found that parameters linked to CH4\nproduction and diffusion generally present the highest sensitivities despite\napparent seasonal variation. Comparing simulated emissions from perturbed\nparameter sets against FLUXNET-CH4 observations revealed that better\nperformances can be achieved at each site compared to the default parameter\nvalues. This presents a scope for further improving simulated emissions using\nparameter calibration with advanced optimization techniques like Bayesian\noptimization.",
            "author": [
                "Sandeep Chinta",
                "Xiang Gao",
                "Qing Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02786v1",
                "http://arxiv.org/pdf/2312.02786v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02783v1",
            "title": "Large Language Models on Graphs: A Comprehensive Survey",
            "updated": "2023-12-05T14:14:27Z",
            "published": "2023-12-05T14:14:27Z",
            "summary": "Large language models (LLMs), such as ChatGPT and LLaMA, are creating\nsignificant advancements in natural language processing, due to their strong\ntext encoding/decoding ability and newly found emergent capability (e.g.,\nreasoning). While LLMs are mainly designed to process pure texts, there are\nmany real-world scenarios where text data are associated with rich structure\ninformation in the form of graphs (e.g., academic networks, and e-commerce\nnetworks) or scenarios where graph data are paired with rich textual\ninformation (e.g., molecules with descriptions). Besides, although LLMs have\nshown their pure text-based reasoning ability, it is underexplored whether such\nability can be generalized to graph scenarios (i.e., graph-based reasoning). In\nthis paper, we provide a systematic review of scenarios and techniques related\nto large language models on graphs. We first summarize potential scenarios of\nadopting LLMs on graphs into three categories, namely pure graphs, text-rich\ngraphs, and text-paired graphs. We then discuss detailed techniques for\nutilizing LLMs on graphs, including LLM as Predictor, LLM as Encoder, and LLM\nas Aligner, and compare the advantages and disadvantages of different schools\nof models. Furthermore, we mention the real-world applications of such methods\nand summarize open-source codes and benchmark datasets. Finally, we conclude\nwith potential future research directions in this fast-growing field. The\nrelated source can be found at\nhttps://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs.",
            "author": [
                "Bowen Jin",
                "Gang Liu",
                "Chi Han",
                "Meng Jiang",
                "Heng Ji",
                "Jiawei Han"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02783v1",
                "http://arxiv.org/pdf/2312.02783v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02780v1",
            "title": "Scaling Laws for Adversarial Attacks on Language Model Activations",
            "updated": "2023-12-05T14:12:15Z",
            "published": "2023-12-05T14:12:15Z",
            "summary": "We explore a class of adversarial attacks targeting the activations of\nlanguage models. By manipulating a relatively small subset of model\nactivations, $a$, we demonstrate the ability to control the exact prediction of\na significant number (in some cases up to 1000) of subsequent tokens $t$. We\nempirically verify a scaling law where the maximum number of target tokens\n$t_\\mathrm{max}$ predicted depends linearly on the number of tokens $a$ whose\nactivations the attacker controls as $t_\\mathrm{max} = \\kappa a$. We find that\nthe number of bits of control in the input space needed to control a single bit\nin the output space (what we call attack resistance $\\chi$) is remarkably\nconstant between $\\approx 16$ and $\\approx 25$ over 2 orders of magnitude of\nmodel sizes for different language models. Compared to attacks on tokens,\nattacks on activations are predictably much stronger, however, we identify a\nsurprising regularity where one bit of input steered either via activations or\nvia tokens is able to exert control over a similar amount of output bits. This\ngives support for the hypothesis that adversarial attacks are a consequence of\ndimensionality mismatch between the input and output spaces. A practical\nimplication of the ease of attacking language model activations instead of\ntokens is for multi-modal and selected retrieval models, where additional data\nsources are added as activations directly, sidestepping the tokenized input.\nThis opens up a new, broad attack surface. By using language models as a\ncontrollable test-bed to study adversarial attacks, we were able to experiment\nwith input-output dimensions that are inaccessible in computer vision,\nespecially where the output dimension dominates.",
            "author": [
                "Stanislav Fort"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02780v1",
                "http://arxiv.org/pdf/2312.02780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02776v1",
            "title": "On Age of Information and Energy-Transfer in a STAR-RIS-assisted System",
            "updated": "2023-12-05T14:10:00Z",
            "published": "2023-12-05T14:10:00Z",
            "summary": "Battery-limited devices and time-sensitive applications are considered as key\nplayers in the forthcoming wireless sensor network. Therefore, the main goal of\nthe network is two-fold; Charge battery-limited devices, and provide status\nupdates to users where information-freshness matters. In this paper, a\nmulti-antenna base station (BS) in assistance of\nsimultaneously-transmitting-and-reflecting reconfigurable intelligent surface\n(STAR-RIS) transmits power to energy-harvesting devices while controlling\nstatus update performance at information-users by analyzing age of information\n(AoI) metric. Therefore, we derive a scheduling policy at BS, and analyze joint\ntransmit beamforming and amplitude-phase optimization at BS and STAR-RIS,\nrespectively, to reduce average sum-AoI for the time-sensitive\ninformation-users while satisfying minimum required energy at energy-harvesting\nusers. Moreover, two different energy-splitting and mode switching policies at\nSTAR-RIS are studied. Then, by use of an alternating optimization algorithm,\nthe optimization problem is studied and non-convexity of the problem is tackled\nby using the successive convex approximation technique. Through numerical\nresults, AoI-metric and energy harvesting requirements of the network are\nanalyzed versus different parameters such as number of antennas at BS, size of\nSTAR-RIS, and transmitted power to highlight how we can improve two fold\nperformance of the system by utilizing STAR-RIS compared to the conventional\nRIS structure.",
            "author": [
                "Mohammad Reza Kavianinia",
                "Mohammad Mehdi Setoode",
                "Mohammad Javad Emadi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02776v1",
                "http://arxiv.org/pdf/2312.02776v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02773v1",
            "title": "Integrating Plug-and-Play Data Priors with Weighted Prediction Error for\n  Speech Dereverberation",
            "updated": "2023-12-05T14:03:11Z",
            "published": "2023-12-05T14:03:11Z",
            "summary": "Speech dereverberation aims to alleviate the detrimental effects of\nlate-reverberant components. While the weighted prediction error (WPE) method\nhas shown superior performance in dereverberation, there is still room for\nfurther improvement in terms of performance and robustness in complex and noisy\nenvironments. Recent research has highlighted the effectiveness of integrating\nphysics-based and data-driven methods, enhancing the performance of various\nsignal processing tasks while maintaining interpretability. Motivated by these\nadvancements, this paper presents a novel dereverberation frame-work, which\nincorporates data-driven methods for capturing speech priors within the WPE\nframework. The plug-and-play strategy (PnP), specifically the regularization by\ndenoising (RED) strategy, is utilized to incorporate speech prior information\nlearnt from data during the optimization problem solving iterations.\nExperimental results validate the effectiveness of the proposed approach.",
            "author": [
                "Ziye Yang",
                "Wenxing Yang",
                "Kai Xie",
                "Jie Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02773v1",
                "http://arxiv.org/pdf/2312.02773v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02772v1",
            "title": "Generating Fine-Grained Human Motions Using ChatGPT-Refined Descriptions",
            "updated": "2023-12-05T14:01:43Z",
            "published": "2023-12-05T14:01:43Z",
            "summary": "Recently, significant progress has been made in text-based motion generation,\nenabling the generation of diverse and high-quality human motions that conform\nto textual descriptions. However, it remains challenging to generate\nfine-grained or stylized motions due to the lack of datasets annotated with\ndetailed textual descriptions. By adopting a divide-and-conquer strategy, we\npropose a new framework named Fine-Grained Human Motion Diffusion Model\n(FG-MDM) for human motion generation. Specifically, we first parse previous\nvague textual annotation into fine-grained description of different body parts\nby leveraging a large language model (GPT-3.5). We then use these fine-grained\ndescriptions to guide a transformer-based diffusion model. FG-MDM can generate\nfine-grained and stylized motions even outside of the distribution of the\ntraining data. Our experimental results demonstrate the superiority of FG-MDM\nover previous methods, especially the strong generalization capability. We will\nrelease our fine-grained textual annotations for HumanML3D and KIT.",
            "author": [
                "Xu Shi",
                "Chuanchen Luo",
                "Junran Peng",
                "Hongwen Zhang",
                "Yunlian Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02772v1",
                "http://arxiv.org/pdf/2312.02772v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02771v1",
            "title": "Scaling-up Memristor Monte Carlo with magnetic domain-wall physics",
            "updated": "2023-12-05T14:01:28Z",
            "published": "2023-12-05T14:01:28Z",
            "summary": "By exploiting the intrinsic random nature of nanoscale devices, Memristor\nMonte Carlo (MMC) is a promising enabler of edge learning systems. However, due\nto multiple algorithmic and device-level limitations, existing demonstrations\nhave been restricted to very small neural network models and datasets. We\ndiscuss these limitations, and describe how they can be overcome, by mapping\nthe stochastic gradient Langevin dynamics (SGLD) algorithm onto the physics of\nmagnetic domain-wall Memristors to scale-up MMC models by five orders of\nmagnitude. We propose the push-pull pulse programming method that realises SGLD\nin-physics, and use it to train a domain-wall based ResNet18 on the CIFAR-10\ndataset. On this task, we observe no performance degradation relative to a\nfloating point model down to an update precision of between 6 and 7-bits,\nindicating we have made a step towards a large-scale edge learning system\nleveraging noisy analogue devices.",
            "author": [
                "Thomas Dalgaty",
                "Shogo Yamada",
                "Anca Molnos",
                "Eiji Kawasaki",
                "Thomas Mesquida",
                "Fran\u00e7ois Rummens",
                "Tatsuo Shibata",
                "Yukihiro Urakawa",
                "Yukio Terasaki",
                "Tomoyuki Sasaki",
                "Marc Duranton"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02771v1",
                "http://arxiv.org/pdf/2312.02771v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02769v1",
            "title": "Blockchain Participation Games",
            "updated": "2023-12-05T13:59:07Z",
            "published": "2023-12-05T13:59:07Z",
            "summary": "We study game-theoretic models for capturing participation in blockchain\nsystems. Permissionless blockchains can be naturally viewed as games, where a\nset of potentially interested users is faced with the dilemma of whether to\nengage with the protocol or not. Engagement here implies that the user will be\nasked to complete certain tasks, whenever they are selected to contribute\n(typically according to some stochastic process) and be rewarded if they choose\nto do so. Apart from the basic dilemma of engaging or not, even more strategic\nconsiderations arise in settings where users may be able to declare\nparticipation and then retract before completing their tasks (but are still\nable to receive rewards) or are rewarded independently of whether they\ncontribute. Such variations occur naturally in the blockchain setting due to\nthe complexity of tracking ``on-chain'' the behavior of the participants.\n  We capture these participation considerations offering a series of models\nthat enable us to reason about the basic dilemma, the case where retraction\neffects influence the outcome and the case when payments are given universally\nirrespective of the stochastic process. In all cases we provide\ncharacterization results or necessary conditions on the structure of Nash\nequilibria. Our findings reveal that appropriate reward mechanisms can be used\nto stimulate participation and avoid negative effects of free riding, results\nthat are in line but also can inform real world blockchain system deployments.",
            "author": [
                "Pyrros Chaidos",
                "Aggelos Kiayias",
                "Evangelos Markakis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02769v1",
                "http://arxiv.org/pdf/2312.02769v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02768v1",
            "title": "Reflective modular varieties and their cusps",
            "updated": "2023-12-05T13:57:36Z",
            "published": "2023-12-05T13:57:36Z",
            "summary": "We classify reflective automorphic products of singular weight under certain\nregularity assumptions. Using obstruction theory we show that there are exactly\n11 such functions. They are naturally related to certain conjugacy classes in\nConway's group $\\text{Co}_0$. The corresponding modular varieties have a very\nrich geometry. We establish a bijection between their $1$-dimensional type-$0$\ncusps and the root systems in Schellekens' list. We also describe a\n$1$-dimensional cusp along which the restriction of the automorphic product is\ngiven by the eta product of the corresponding class in $\\text{Co}_0$. Finally\nwe apply our results to give a complex-geometric proof of Schellekens' list.",
            "author": [
                "Thomas Driscoll-Spittler",
                "Nils R. Scheithauer",
                "Janik Wilhelm"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02768v1",
                "http://arxiv.org/pdf/2312.02768v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.AG",
                "math.QA",
                "32J05, 11F55, 17B69"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03035v1",
            "title": "SEVA: Leveraging sketches to evaluate alignment between human and\n  machine visual abstraction",
            "updated": "2023-12-05T13:54:55Z",
            "published": "2023-12-05T13:54:55Z",
            "summary": "Sketching is a powerful tool for creating abstract images that are sparse but\nmeaningful. Sketch understanding poses fundamental challenges for\ngeneral-purpose vision algorithms because it requires robustness to the\nsparsity of sketches relative to natural visual inputs and because it demands\ntolerance for semantic ambiguity, as sketches can reliably evoke multiple\nmeanings. While current vision algorithms have achieved high performance on a\nvariety of visual tasks, it remains unclear to what extent they understand\nsketches in a human-like way. Here we introduce SEVA, a new benchmark dataset\ncontaining approximately 90K human-generated sketches of 128 object concepts\nproduced under different time constraints, and thus systematically varying in\nsparsity. We evaluated a suite of state-of-the-art vision algorithms on their\nability to correctly identify the target concept depicted in these sketches and\nto generate responses that are strongly aligned with human response patterns on\nthe same sketch recognition task. We found that vision algorithms that better\npredicted human sketch recognition performance also better approximated human\nuncertainty about sketch meaning, but there remains a sizable gap between model\nand human response patterns. To explore the potential of models that emulate\nhuman visual abstraction in generative tasks, we conducted further evaluations\nof a recently developed sketch generation algorithm (Vinker et al., 2022)\ncapable of generating sketches that vary in sparsity. We hope that public\nrelease of this dataset and evaluation protocol will catalyze progress towards\nalgorithms with enhanced capacities for human-like visual abstraction.",
            "author": [
                "Kushin Mukherjee",
                "Holly Huey",
                "Xuanchen Lu",
                "Yael Vinker",
                "Rio Aguina-Kang",
                "Ariel Shamir",
                "Judith E. Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03035v1",
                "http://arxiv.org/pdf/2312.03035v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02764v1",
            "title": "Experimental multi-scale characterization of mode-II interlaminar\n  fracture in geometrically scaled stitched and unstitched resin-infused\n  composites",
            "updated": "2023-12-05T13:52:16Z",
            "published": "2023-12-05T13:52:16Z",
            "summary": "This work is focused on investigating the impact of out-of-plane stitches on\nenhancing mode-II interlaminar fracture toughness (or energy) and\ncharacterizing damage progression and crack arrestment in stitched\nresin-infused composites. For the experimental work, End-Notched Flexure (ENF)\nquasi-isotropic specimens were manufactured using +/-45 non-crimp carbon-fiber\nfabrics through a resin-infusion process. Both stitched and unstitched specimen\nsets were designed for comparison. For a size effect study, the ENF specimens\nwere geometrically scaled with three scaling levels. Based on the\nload-displacement data (i.e., global analysis), the fracture energy of the\nspecimen material was analyzed using the compliance calibration method and a\nsize effect theory. The fracture energy values were compared between the\nstitched and unstitched cases to characterize the enhanced fracture toughness\nof stitched composites. For local analysis, two types of digital image\ncorrelation (DIC) systems were employed: microscopic and macroscopic (i.e.,\ncoupon-scale) DIC systems. By analyzing in-plane displacement through the\nthickness, separation development was characterized along predicted fracture\nprocess zones. The impact of out-of-plane stitches on separation propagation\nalong fracture process zones was discussed based on the DIC analysis. This work\nwill contribute to developing a high-fidelity damage model for stitched\nresin-infused composites in the form of a traction-separation for high-speed\naircraft applications.",
            "author": [
                "Dawson Ozborn",
                "Jackob Black",
                "Wayne Huberty",
                "Christopher Bounds",
                "Han-Gyu Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02764v1",
                "http://arxiv.org/pdf/2312.02764v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02762v1",
            "title": "Learning Cortical Anomaly through Masked Encoding for Unsupervised\n  Heterogeneity Mapping",
            "updated": "2023-12-05T13:44:25Z",
            "published": "2023-12-05T13:44:25Z",
            "summary": "The detection of heterogeneous mental disorders based on brain readouts\nremains challenging due to the complexity of symptoms and the absence of\nreliable biomarkers. This paper introduces CAM (Cortical Anomaly Detection\nthrough Masked Image Modeling), a novel self-supervised framework designed for\nthe unsupervised detection of complex brain disorders using cortical surface\nfeatures. We employ this framework for the detection of individuals on the\npsychotic spectrum and demonstrate its capabilities compared to state-ofthe-art\nmethods, achieving an AUC of 0.696 for Schizoaffective and 0.769 for\nSchizophreniform, without the need for any labels. Furthermore, the analysis of\natypical cortical regions includes Pars Triangularis and several frontal areas,\noften implicated in schizophrenia, provide further confidence in our approach.\nAltogether, we demonstrate a scalable approach for anomaly detection of complex\nbrain disorders based on cortical abnormalities.",
            "author": [
                "Hao-Chun Yang",
                "Ole Andreassen",
                "Lars Tjelta Westlye",
                "Andre F. Marquand",
                "Christian F. Beckmann",
                "Thomas Wolfers"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02762v1",
                "http://arxiv.org/pdf/2312.02762v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02755v1",
            "title": "Vector Beams with Parabolic and Elliptic Cross-Sections for Laser\n  Material Processing Applications",
            "updated": "2023-12-05T13:31:30Z",
            "published": "2023-12-05T13:31:30Z",
            "summary": "Beam profile engineering, where a desired optical intensity distribution can\nbe generated by an array of phase shifting (or amplitude changing) elements is\na promising approach in laser material processing. For example, a spatial light\nmodulator (SLM) is a dynamic diffractive optical element allowing for\nexperimental implementations of controllable beam profile. Scalar Mathieu beams\nhave elliptical intensity distribution perceivable as optical knives in the\ntransverse plane and scalar Weber beams have a parabolic distribution, which\nenables us to call them optical shovels. Here, we introduce vector versions of\nscalar Mathieu and Weber beams and use those vector beams as a basis to\nconstruct controllable on-axis phase and amplitude distributions with\npolarization control. Further, we generate individual components of optical\nknife and shovel beams experimentally using SLMs as a toy model and report on\nour achievements in the control over the beam shape, dimensions and\npolarization along the propagation axis.",
            "author": [
                "Sergej Orlov",
                "Vitalis Vosylius",
                "Pavel Gotovski",
                "Art\u016bras Grabusovas",
                "Justas Baltrukonis",
                "Titas Gertus"
            ],
            "link": [
                "http://dx.doi.org/10.2961/jlmn.2018.03.0023",
                "http://arxiv.org/abs/2312.02755v1",
                "http://arxiv.org/pdf/2312.02755v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02753v1",
            "title": "C3: High-performance and low-complexity neural compression from a single\n  image or video",
            "updated": "2023-12-05T13:28:59Z",
            "published": "2023-12-05T13:28:59Z",
            "summary": "Most neural compression models are trained on large datasets of images or\nvideos in order to generalize to unseen data. Such generalization typically\nrequires large and expressive architectures with a high decoding complexity.\nHere we introduce C3, a neural compression method with strong rate-distortion\n(RD) performance that instead overfits a small model to each image or video\nseparately. The resulting decoding complexity of C3 can be an order of\nmagnitude lower than neural baselines with similar RD performance. C3 builds on\nCOOL-CHIC (Ladune et al.) and makes several simple and effective improvements\nfor images. We further develop new methodology to apply C3 to videos. On the\nCLIC2020 image benchmark, we match the RD performance of VTM, the reference\nimplementation of the H.266 codec, with less than 3k MACs/pixel for decoding.\nOn the UVG video benchmark, we match the RD performance of the Video\nCompression Transformer (Mentzer et al.), a well-established neural video\ncodec, with less than 5k MACs/pixel for decoding.",
            "author": [
                "Hyunjik Kim",
                "Matthias Bauer",
                "Lucas Theis",
                "Jonathan Richard Schwarz",
                "Emilien Dupont"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02753v1",
                "http://arxiv.org/pdf/2312.02753v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02751v1",
            "title": "C-NERF: Representing Scene Changes as Directional Consistency\n  Difference-based NeRF",
            "updated": "2023-12-05T13:27:12Z",
            "published": "2023-12-05T13:27:12Z",
            "summary": "In this work, we aim to detect the changes caused by object variations in a\nscene represented by the neural radiance fields (NeRFs). Given an arbitrary\nview and two sets of scene images captured at different timestamps, we can\npredict the scene changes in that view, which has significant potential\napplications in scene monitoring and measuring. We conducted preliminary\nstudies and found that such an exciting task cannot be easily achieved by\nutilizing existing NeRFs and 2D change detection methods with many false or\nmissing detections. The main reason is that the 2D change detection is based on\nthe pixel appearance difference between spatial-aligned image pairs and\nneglects the stereo information in the NeRF. To address the limitations, we\npropose the C-NERF to represent scene changes as directional consistency\ndifference-based NeRF, which mainly contains three modules. We first perform\nthe spatial alignment of two NeRFs captured before and after changes. Then, we\nidentify the change points based on the direction-consistent constraint; that\nis, real change points have similar change representations across view\ndirections, but fake change points do not. Finally, we design the change map\nrendering process based on the built NeRFs and can generate the change map of\nan arbitrarily specified view direction. To validate the effectiveness, we\nbuild a new dataset containing ten scenes covering diverse scenarios with\ndifferent changing objects. Our approach surpasses state-of-the-art 2D change\ndetection and NeRF-based methods by a significant margin.",
            "author": [
                "Rui Huang",
                "Binbin Jiang",
                "Qingyi Zhao",
                "William Wang",
                "Yuxiang Zhang",
                "Qing Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02751v1",
                "http://arxiv.org/pdf/2312.02751v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02748v1",
            "title": "Compositional Generalization for Data-to-Text Generation",
            "updated": "2023-12-05T13:23:15Z",
            "published": "2023-12-05T13:23:15Z",
            "summary": "Data-to-text generation involves transforming structured data, often\nrepresented as predicate-argument tuples, into coherent textual descriptions.\nDespite recent advances, systems still struggle when confronted with unseen\ncombinations of predicates, producing unfaithful descriptions (e.g.\nhallucinations or omissions). We refer to this issue as compositional\ngeneralisation, and it encouraged us to create a benchmark for assessing the\nperformance of different approaches on this specific problem. Furthermore, we\npropose a novel model that addresses compositional generalization by clustering\npredicates into groups. Our model generates text in a sentence-by-sentence\nmanner, relying on one cluster of predicates at a time. This approach\nsignificantly outperforms T5~baselines across all evaluation metrics.Notably,\nit achieved a 31% improvement over T5 in terms of a metric focused on\nmaintaining faithfulness to the input.",
            "author": [
                "Xinnuo Xu",
                "Ivan Titov",
                "Mirella Lapata"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02748v1",
                "http://arxiv.org/pdf/2312.02748v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03034v1",
            "title": "Distributed Speech Dereverberation Using Weighted Prediction Error",
            "updated": "2023-12-05T13:22:58Z",
            "published": "2023-12-05T13:22:58Z",
            "summary": "Speech dereverberation aims to alleviate the negative impact of late\nreverberant reflections. The weighted prediction error (WPE) method is a\nwell-established technique known for its superior performance in\ndereverberation. However, in scenarios where microphone nodes are dispersed,\nthe centralized approach of the WPE method requires aggregating all\nobservations for inverse filtering, resulting in a significant computational\nburden. This paper introduces a distributed speech dereverberation method that\nemphasizes low computational complexity at each node. Specifically, we leverage\nthe distributed adaptive node-specific signal estimation (DANSE) algorithm\nwithin the multichannel linear prediction (MCLP) process. This approach\nempowers each node to perform local operations with reduced complexity while\nachieving the global performance through inter-node cooperation. Experimental\nresults validate the effectiveness of our proposed method, showcasing its\nability to achieve efficient speech dereverberation in dispersed microphone\nnode scenarios.",
            "author": [
                "Ziye Yang",
                "Mengfei Zhang",
                "Jie Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03034v1",
                "http://arxiv.org/pdf/2312.03034v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02746v1",
            "title": "Empowering the 6G Cellular Architecture with Open RAN",
            "updated": "2023-12-05T13:20:04Z",
            "published": "2023-12-05T13:20:04Z",
            "summary": "Innovation and standardization in 5G have brought advancements to every facet\nof the cellular architecture. This ranges from the introduction of new\nfrequency bands and signaling technologies for the radio access network (RAN),\nto a core network underpinned by micro-services and network function\nvirtualization (NFV). However, like any emerging technology, the pace of\nreal-world deployments does not instantly match the pace of innovation. To\naddress this discrepancy, one of the key aspects under continuous development\nis the RAN with the aim of making it more open, adaptive, functional, and easy\nto manage. In this paper, we highlight the transformative potential of\nembracing novel cellular architectures by transitioning from conventional\nsystems to the progressive principles of Open RAN. This promises to make 6G\nnetworks more agile, cost-effective, energy-efficient, and resilient. It opens\nup a plethora of novel use cases, ranging from ubiquitous support for\nautonomous devices to cost-effective expansions in regions previously\nunderserved. The principles of Open RAN encompass: (i) a disaggregated\narchitecture with modular and standardized interfaces; (ii) cloudification,\nprogrammability and orchestration; and (iii) AI-enabled data-centric\nclosed-loop control and automation. We first discuss the transformative role\nOpen RAN principles have played in the 5G era. Then, we adopt a system-level\napproach and describe how these Open RAN principles will support 6G RAN and\narchitecture innovation. We qualitatively discuss potential performance gains\nthat Open RAN principles yield for specific 6G use cases. For each principle,\nwe outline the steps that research, development and standardization communities\nought to take to make Open RAN principles central to next-generation cellular\nnetwork designs.",
            "author": [
                "Michele Polese",
                "Mischa Dohler",
                "Falko Dressler",
                "Melike Erol-Kantarci",
                "Rittwik Jana",
                "Raymond Knopp",
                "Tommaso Melodia"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JSAC.2023.3334610",
                "http://arxiv.org/abs/2312.02746v1",
                "http://arxiv.org/pdf/2312.02746v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02745v1",
            "title": "Upper tail large deviation for the one-dimensional frog model",
            "updated": "2023-12-05T13:19:38Z",
            "published": "2023-12-05T13:19:38Z",
            "summary": "In this paper, we study the upper tail large deviation for the\none-dimensional frog model. In this model, sleeping and active frogs are\nassigned to vertices on $\\mathbb Z$. While sleeping frogs do not move, the\nactive ones move as independent simple random walks and activate any sleeping\nfrogs. The main object of interest in this model is the asymptotic behavior of\nthe first passage time ${\\rm T}(0,n)$, which is the time needed to activate the\nfrog at the vertex $n$, assuming there is only one active frog at $0$ at the\nbeginning. While the law of large numbers and central limit theorems have been\nwell established, the intricacies of large deviations remain elusive. Using\nrenewal theory, B\\'erard and Ram\\'irez have pointed out a slowdown phenomenon\nwhere the probability that the first passage time ${\\rm T}(0,n)$ is\nsignificantly larger than its expectation decays sub-exponentially and lies\nbetween $\\exp(-n^{1/2+o(1)})$ and $\\exp(-n^{1/3+o(1)})$. In this article, using\na novel covering process approach, we confirm that $1/2$ is the correct\nexponent, i.e., the rate of upper large deviations is given by $n^{1/2}$.\nMoreover, we obtain an explicit rate function that is characterized by\nproperties of Brownian motion and is strictly concave.",
            "author": [
                "Van Hao Can",
                "Naoki Kubota",
                "Shuta Nakajima"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02745v1",
                "http://arxiv.org/pdf/2312.02745v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP",
                "Primary 60K37, secondary 60K35, 82A51, 82D30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02744v1",
            "title": "p-Adic Quantum Mechanics, the Dirac Equation, and the violation of\n  Einstein causality",
            "updated": "2023-12-05T13:17:41Z",
            "published": "2023-12-05T13:17:41Z",
            "summary": "We introduce a new p-adic Dirac equation that predicts the existence of\nparticles and antiparticles and charge conjugation like the standard one. The\nnew equation shares many properties with the old one. However, the space's\ndiscrete (p-adic) nature imposes substantial restrictions on the solutions of\nthe new equation. This equation admits localized solutions, which is impossible\nin the standard case. Finally, we show that a quantum system whose evolution is\ncontrolled by the p-adic Dirac equation does not satisfy the Einstein\ncausality.",
            "author": [
                "W. A. Z\u00fa\u00f1iga-Galindo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02744v1",
                "http://arxiv.org/pdf/2312.02744v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02742v1",
            "title": "Search for the edge-on galaxies using an artificial neural network",
            "updated": "2023-12-05T13:08:40Z",
            "published": "2023-12-05T13:08:40Z",
            "summary": "We present an application of an artificial neural network methodology to a\nmodern wide-field sky survey Pan-STARRS1 in order to build a high-quality\nsample of disk galaxies visible in edge-on orientation. Such galaxies play an\nimportant role in the study of the vertical distribution of stars, gas and\ndust, which is usually not available to study in other galaxies outside the\nMilky Way. We give a detailed description of the network architecture and the\nlearning process. The method demonstrates good effectiveness with detection\nrate about 97\\% and it works equally well for galaxies over a wide range of\nbrightnesses and sizes, which resulted in a creation of a catalogue of edge-on\ngalaxies with $10^5$ of objects. The catalogue is published on-line with an\nopen access.",
            "author": [
                "S. S. Savchenko",
                "D. I. Makarov",
                "A. V. Antipova",
                "I. S. Tikhonenko"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.ascom.2023.100771",
                "http://arxiv.org/abs/2312.02742v1",
                "http://arxiv.org/pdf/2312.02742v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02740v1",
            "title": "Observable imprints of primordial gravitational waves on the temperature\n  anisotropies of the Cosmic Microwave Background",
            "updated": "2023-12-05T13:06:44Z",
            "published": "2023-12-05T13:06:44Z",
            "summary": "We examine the contribution of tensor modes, in addition to the dominant\nscalar ones, on the temperature anisotropies of the cosmic microwave background\n(CMB). To this end, we analyze in detail the temperature two-point angular\ncorrelation function $C(\\theta)$ from the Planck 2018 dataset, focusing on\nlarge angles ($\\theta \\gtrsim 120^{\\circ}$) corresponding to small $\\ell$\nmultipoles. A hierarchical set of infrared cutoffs are naturally introduced to\nthe scalar and tensor power spectra of the CMB by invoking an extra\nKaluza-Klein dimension compactifying at about the GUT scale between the Planck\nepoch and the start of inflation. We associate this set of lower scalar and\ntensor cutoffs with the parity of the multipole expansion of the $C(\\theta)$\nfunction. By fitting the Planck 2018 data we compute the multipole coefficients\nthereby reproducing the well-known odd-parity preference in angular\ncorrelations seen by all three satellite missions COBE, WMAP and Planck. Our\nfits improve significantly once tensor modes are included in the analysis,\nhence providing a hint of the imprints of primordial gravitational waves on the\ntemperature correlations observed in the CMB today. To conclude we suggest a\nrelationship between, on the one hand, the lack of (positive) large-angle\ncorrelations and the odd-parity dominance in the CMB and, on the other hand,\nthe effect of primordial gravitational waves on the CMB temperature\nanisotropies.",
            "author": [
                "Miguel-Angel Sanchis-Lozano",
                "Veronica Sanz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02740v1",
                "http://arxiv.org/pdf/2312.02740v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02738v1",
            "title": "A Melnikov analysis on a class of second order discontinuous\n  differential equations",
            "updated": "2023-12-05T13:02:40Z",
            "published": "2023-12-05T13:02:40Z",
            "summary": "This paper focuses in providing a Melnikov-like function that controls the\nexistence of periodic solutions bifurcating from period annuli present in some\nfamilies of the second-order discontinuous differential equation given by\n$\\ddot{x}+\\alpha\\; \\text{sgn}(x)=\\eta x+\\varepsilon \\;f(t,x,\\dot{x})$. This\nfamily has garnered extensive attention from various researchers, especially\nwhen considering specific instances of $f(t,x,\\dot{x})$. The interest in\nstudying this type of differential equation is due to its relevance in modeling\nsystems with abrupt state changes in both natural and engineering contexts.",
            "author": [
                "Douglas D. Novaes",
                "Luan V. M. F. Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02738v1",
                "http://arxiv.org/pdf/2312.02738v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "34A36, 34C15, 34C25, 37G15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02737v1",
            "title": "Track finding with deep neural networks",
            "updated": "2023-12-05T13:01:41Z",
            "published": "2023-12-05T13:01:41Z",
            "summary": "High-energy physics experiments require fast and efficient methods for\nreconstructing the tracks of charged particles. The commonly used algorithms\nare sequential, and the required CPU power increases rapidly with the number of\ntracks. Neural networks can speed up the process due to their capability of\nmodeling complex non-linear data dependencies and finding all tracks in\nparallel. In this paper, we describe the application of a deep neural network\nfor reconstructing straight tracks in a toy two-dimensional model. It is\nplanned to apply this method to the experimental data obtained by the MUonE\nexperiment at CERN.",
            "author": [
                "Marcin Kucharczyk",
                "Marcin Wolter"
            ],
            "link": [
                "http://dx.doi.org/10.7494/csci.2019.20.4.3376",
                "http://arxiv.org/abs/2312.02737v1",
                "http://arxiv.org/pdf/2312.02737v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02733v1",
            "title": "Giant natural optical rotation from chiral electromagnons in a collinear\n  antiferromagnet",
            "updated": "2023-12-05T12:56:02Z",
            "published": "2023-12-05T12:56:02Z",
            "summary": "In NiTe$_3$O$_6$ with a chiral crystal structure, we report on a giant\nnatural optical rotation of the lowest-energy magnon. This polarization\nrotation, as large as 140 deg/mm, corresponds to a path difference between\nright and left circular polarizations that is comparable to the sample\nthickness. Natural optical rotation, being a measure of structural chirality,\nis highly unusual for long-wavelength magnons. The collinear antiferromagnetic\norder of NiTe$_3$O$_6$ makes this giant effect even more peculiar: Chirality of\nthe crystal structure does not affect the magnetic ground state but is strongly\nmanifested in the lowest excited state. We show that the dynamic\nmagnetoelectric effect, turning this magnon to a magnetic- and electric-dipole\nactive hybrid mode, generates the giant natural optical rotation. In finite\nmagnetic fields, it also leads to a strong optical magnetochiral effect.",
            "author": [
                "D. Maluski",
                "M. Langenbach",
                "D. Szaller",
                "S. Reschke",
                "L. Prodan",
                "I. C\u00e1mara Mayorga",
                "S. -W. Cheong",
                "V. Tsurkan",
                "I. K\u00e9zsm\u00e1rki",
                "J. Hemberger",
                "M. Gr\u00fcninger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02733v1",
                "http://arxiv.org/pdf/2312.02733v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02730v1",
            "title": "Towards Measuring Representational Similarity of Large Language Models",
            "updated": "2023-12-05T12:48:04Z",
            "published": "2023-12-05T12:48:04Z",
            "summary": "Understanding the similarity of the numerous released large language models\n(LLMs) has many uses, e.g., simplifying model selection, detecting illegal\nmodel reuse, and advancing our understanding of what makes LLMs perform well.\nIn this work, we measure the similarity of representations of a set of LLMs\nwith 7B parameters. Our results suggest that some LLMs are substantially\ndifferent from others. We identify challenges of using representational\nsimilarity measures that suggest the need of careful study of similarity scores\nto avoid false conclusions.",
            "author": [
                "Max Klabunde",
                "Mehdi Ben Amor",
                "Michael Granitzer",
                "Florian Lemmerich"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02730v1",
                "http://arxiv.org/pdf/2312.02730v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03033v1",
            "title": "LiDAR-based Person Re-identification",
            "updated": "2023-12-05T12:44:17Z",
            "published": "2023-12-05T12:44:17Z",
            "summary": "Camera-based person re-identification (ReID) systems have been widely applied\nin the field of public security. However, cameras often lack the perception of\n3D morphological information of human and are susceptible to various\nlimitations, such as inadequate illumination, complex background, and personal\nprivacy. In this paper, we propose a LiDAR-based ReID framework, ReID3D, that\nutilizes pre-training strategy to retrieve features of 3D body shape and\nintroduces Graph-based Complementary Enhancement Encoder for extracting\ncomprehensive features. Due to the lack of LiDAR datasets, we build LReID, the\nfirst LiDAR-based person ReID dataset, which is collected in several outdoor\nscenes with variations in natural conditions. Additionally, we introduce\nLReID-sync, a simulated pedestrian dataset designed for pre-training encoders\nwith tasks of point cloud completion and shape parameter learning. Extensive\nexperiments on LReID show that ReID3D achieves exceptional performance with a\nrank-1 accuracy of 94.0, highlighting the significant potential of LiDAR in\naddressing person ReID tasks. To the best of our knowledge, we are the first to\npropose a solution for LiDAR-based ReID. The code and datasets will be released\nsoon.",
            "author": [
                "Wenxuan Guo",
                "Zhiyu Pan",
                "Yingping Liang",
                "Ziheng Xi",
                "Zhi Chen Zhong",
                "Jianjiang Feng",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03033v1",
                "http://arxiv.org/pdf/2312.03033v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02724v1",
            "title": "RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a\n  Breeze!",
            "updated": "2023-12-05T12:39:00Z",
            "published": "2023-12-05T12:39:00Z",
            "summary": "In information retrieval, proprietary large language models (LLMs) such as\nGPT-4 and open-source counterparts such as LLaMA and Vicuna have played a vital\nrole in reranking. However, the gap between open-source and closed models\npersists, with reliance on proprietary, non-transparent models constraining\nreproducibility. Addressing this gap, we introduce RankZephyr, a\nstate-of-the-art, open-source LLM for listwise zero-shot reranking. RankZephyr\nnot only bridges the effectiveness gap with GPT-4 but in some cases surpasses\nthe proprietary model. Our comprehensive evaluations across several datasets\n(TREC Deep Learning Tracks; NEWS and COVID from BEIR) showcase this ability.\nRankZephyr benefits from strategic training choices and is resilient against\nvariations in initial document ordering and the number of documents reranked.\nAdditionally, our model outperforms GPT-4 on the NovelEval test set, comprising\nqueries and passages past its training period, which addresses concerns about\ndata contamination. To foster further research in this rapidly evolving field,\nwe provide all code necessary to reproduce our results at\nhttps://github.com/castorini/rank_llm.",
            "author": [
                "Ronak Pradeep",
                "Sahel Sharifymoghaddam",
                "Jimmy Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02724v1",
                "http://arxiv.org/pdf/2312.02724v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02721v1",
            "title": "Resolved properties of classical bulge and pseudo-bulge galaxies",
            "updated": "2023-12-05T12:34:55Z",
            "published": "2023-12-05T12:34:55Z",
            "summary": "We compare properties of classical and pseudo-bulges and properties of their\nhosting galaxies selected from the MaNGA survey. Bulge types are identified\nbased on the S$\\mathrm{\\acute{e}}$rsic index n of bulge component and the\nposition of bulges on the Kormandy diagram. For the 393 classical bulges and\n422 pseudo-bulges selected and their hosting galaxies, we study their kinematic\nproperties including a proxy for specific angular momentum and central velocity\ndispersion, their stellar population properties including stellar age,\nmetallicity, and specific star formation rate, as well as HI fractions of the\ngalaxies. Our results show that at given stellar mass, disc components of\npseudo-bulge galaxies are younger, have more active star formation, rotate\nmore, and may contain more HI content compared with those of classical bulge\ngalaxies, and the differences are larger than those between bulges themselves.\nThe correlations between bulge types and disc properties indicate that\ndifferent types of bulges are shaped by different processes that may regulate\nboth growth of central components and evolution of outer discs in galaxies. In\naddition, we propose a stellar mass dependent divider of central velocity\ndispersion to separate galaxies with classical bulges from those with\npseudo-bulges in galaxy mass range of $10.4<\\mathrm{log}(M_*/M_\\odot)<11.4$:\n$\\mathrm{log}(\\sigma_0) = 0.23 \\times \\mathrm{log}(M_*/M_\\odot)-0.46$. Galaxies\nwith larger/smaller $\\sigma_0$ can be classified as hosts of\nclassical/pseudo-bulges.",
            "author": [
                "Jia Hu",
                "Lan wang",
                "Junqiang Ge",
                "Kai Zhu",
                "Guangquan Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02721v1",
                "http://arxiv.org/pdf/2312.02721v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02720v1",
            "title": "Towards the Inferrence of Structural Similarity of Combinatorial\n  Landscapes",
            "updated": "2023-12-05T12:34:51Z",
            "published": "2023-12-05T12:34:51Z",
            "summary": "One of the most common problem-solving heuristics is by analogy. For a given\nproblem, a solver can be viewed as a strategic walk on its fitness landscape.\nThus if a solver works for one problem instance, we expect it will also be\neffective for other instances whose fitness landscapes essentially share\nstructural similarities with each other. However, due to the black-box nature\nof combinatorial optimization, it is far from trivial to infer such similarity\nin real-world scenarios. To bridge this gap, by using local optima network as a\nproxy of fitness landscapes, this paper proposed to leverage graph data mining\ntechniques to conduct qualitative and quantitative analyses to explore the\nlatent topological structural information embedded in those landscapes. By\nconducting large-scale empirical experiments on three classic combinatorial\noptimization problems, we gain concrete evidence to support the existence of\nstructural similarity between landscapes of the same classes within neighboring\ndimensions. We also interrogated the relationship between landscapes of\ndifferent problem classes.",
            "author": [
                "Mingyu Huang",
                "Ke Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02720v1",
                "http://arxiv.org/pdf/2312.02720v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02715v1",
            "title": "A queueing-based approach for integrated routing and appointment\n  scheduling",
            "updated": "2023-12-05T12:22:12Z",
            "published": "2023-12-05T12:22:12Z",
            "summary": "This paper aims to address the integrated routing and appointment scheduling\n(RAS) problem for a single service provider. The RAS problem is an operational\nchallenge faced by operators that provide services requiring home attendance,\nsuch as grocery delivery, home healthcare, or maintenance services. While\nconsidering the inherently random nature of service and travel times, the goal\nis to minimize a weighted sum of the operator's travel times and idle time, and\nthe client's waiting times. To handle the complex search space of routing and\nappointment scheduling decisions, we propose a queueing-based approach to\neffectively deal with the appointment scheduling decisions. We use two\nwell-known approximations from queueing theory: first, we use an approach based\non phase-type distributions to accurately approximate the objective function,\nand second, we use an heavy-traffic approximation to derive an efficient\nprocedure to obtain good appointment schedules. Combining these two approaches\nresults in a fast and sufficiently accurate hybrid approximation, thus\nessentially reducing RAS to a routing problem. Moreover, we propose the use a\nsimple yet effective large neighborhood search metaheuristic to explore the\nspace of routing decisions. The effectiveness of our proposed methodology is\ntested on benchmark instances with up to 40 clients, demonstrating an efficient\nand accurate methodology for integrated routing and appointment scheduling.",
            "author": [
                "Ren\u00e9 Bekker",
                "Bharti Bharti",
                "Leon Lan",
                "Michel Mandjes"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02715v1",
                "http://arxiv.org/pdf/2312.02715v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02713v1",
            "title": "Three-dimensional modelling of polygonal ridges in salt playas",
            "updated": "2023-12-05T12:16:51Z",
            "published": "2023-12-05T12:16:51Z",
            "summary": "Salt playas with their tessellated surface of polygonal salt ridges are\nbeautiful and intriguing, but the scientific community lacks a realistic and\nphysically meaningful model that thoroughly explains their formation. In this\nwork, we investigated the formation phenomena via suitable three-dimensional\nmodelling and simulation of the dynamical processes that are responsible. We\nemployed fracture mechanics, principles of energy minimization, fluid and mass\ntransport in fracture channels and processes of crystallization and self\norganisation to finally replicate the almost Voronoidal pattern of salt ridges\nthat tessellate salt playas. The model is applicable to playas having different\nsalt compositions, as the effect of the salt diffusion coefficient and critical\nsalinity at supersaturation for a particular ambient condition are factored in.\nThe model closely reproduces the height distribution and geometry of the salt\nridges reported in the literature. Further, we prove that the final stable\npolygonal geometry of the salt playas is an effort towards the total\nminimization of system energy.",
            "author": [
                "R. A. I. Haque",
                "A. J. Mitra",
                "T. Dutta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02713v1",
                "http://arxiv.org/pdf/2312.02713v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02706v1",
            "title": "Large Knowledge Model: Perspectives and Challenges",
            "updated": "2023-12-05T12:07:30Z",
            "published": "2023-12-05T12:07:30Z",
            "summary": "Humankind's understanding of the world is fundamentally linked to our\nperception and cognition, with \\emph{human languages} serving as one of the\nmajor carriers of \\emph{world knowledge}. In this vein, \\emph{Large Language\nModels} (LLMs) like ChatGPT epitomize the pre-training of extensive,\nsequence-based world knowledge into neural networks, facilitating the\nprocessing and manipulation of this knowledge in a parametric space. This\narticle explores large models through the lens of ``knowledge''. We initially\ninvestigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in\nenhancing LLMs, covering aspects like knowledge-augmented language model,\nstructure-inducing pre-training, knowledgeable prompts, structured CoT,\nknowledge editing, semantic tools for LLM and knowledgeable AI agents.\nSubsequently, we examine how LLMs can amplify traditional symbolic knowledge\nbases, encompassing aspects like using LLM as KG builder and controller,\nstructured knowledge pretraining, LLM-enhanced symbolic reasoning, and the\namalgamation of perception with cognition. Considering the intricate nature of\nhuman knowledge, we advocate for the creation of \\emph{Large Knowledge Models}\n(LKM), specifically engineered to manage diversified spectrum of knowledge\nstructures. This ambitious undertaking could entail several key challenges,\nsuch as disentangling knowledge representation from language models,\nrestructuring pre-training with structured knowledge, and building large\ncommonsense models, among others. We finally propose a five-``A'' principle to\ndistinguish the concept of LKM.",
            "author": [
                "Huajun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02706v1",
                "http://arxiv.org/pdf/2312.02706v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02702v1",
            "title": "Neural Sign Actors: A diffusion model for 3D sign language production\n  from text",
            "updated": "2023-12-05T12:04:34Z",
            "published": "2023-12-05T12:04:34Z",
            "summary": "Sign Languages (SL) serve as the predominant mode of communication for the\nDeaf and Hard of Hearing communities. The advent of deep learning has aided\nnumerous methods in SL recognition and translation, achieving remarkable\nresults. However, Sign Language Production (SLP) poses a challenge for the\ncomputer vision community as the motions generated must be realistic and have\nprecise semantic meanings. Most SLP methods rely on 2D data, thus impeding\ntheir ability to attain a necessary level of realism. In this work, we propose\na diffusion-based SLP model trained on a curated large-scale dataset of 4D\nsigning avatars and their corresponding text transcripts. The proposed method\ncan generate dynamic sequences of 3D avatars from an unconstrained domain of\ndiscourse using a diffusion process formed on a novel and anatomically informed\ngraph neural network defined on the SMPL-X body skeleton. Through a series of\nquantitative and qualitative experiments, we show that the proposed method\nconsiderably outperforms previous methods of SLP. We believe that this work\npresents an important and necessary step towards realistic neural sign avatars,\nbridging the communication gap between Deaf and hearing communities. The code,\nmethod and generated data will be made publicly available.",
            "author": [
                "Vasileios Baltatzis",
                "Rolandos Alexandros Potamias",
                "Evangelos Ververas",
                "Guanxiong Sun",
                "Jiankang Deng",
                "Stefanos Zafeiriou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02702v1",
                "http://arxiv.org/pdf/2312.02702v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02699v1",
            "title": "Enhancing Vehicle Entrance and Parking Management: Deep Learning\n  Solutions for Efficiency and Security",
            "updated": "2023-12-05T12:02:53Z",
            "published": "2023-12-05T12:02:53Z",
            "summary": "The auto-management of vehicle entrance and parking in any organization is a\ncomplex challenge encompassing record-keeping, efficiency, and security\nconcerns. Manual methods for tracking vehicles and finding parking spaces are\nslow and a waste of time. To solve the problem of auto management of vehicle\nentrance and parking, we have utilized state-of-the-art deep learning models\nand automated the process of vehicle entrance and parking into any\norganization. To ensure security, our system integrated vehicle detection,\nlicense number plate verification, and face detection and recognition models to\nensure that the person and vehicle are registered with the organization. We\nhave trained multiple deep-learning models for vehicle detection, license\nnumber plate detection, face detection, and recognition, however, the YOLOv8n\nmodel outperformed all the other models. Furthermore, License plate recognition\nis facilitated by Google's Tesseract-OCR Engine. By integrating these\ntechnologies, the system offers efficient vehicle detection, precise\nidentification, streamlined record keeping, and optimized parking slot\nallocation in buildings, thereby enhancing convenience, accuracy, and security.\nFuture research opportunities lie in fine-tuning system performance for a wide\nrange of real-world applications.",
            "author": [
                "Muhammad Umer Ramzan",
                "Usman Ali",
                "Syed Haider Abbas Naqvi",
                "Zeeshan Aslam",
                "Tehseen",
                "Husnain Ali",
                "Muhammad Faheem"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02699v1",
                "http://arxiv.org/pdf/2312.02699v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02695v1",
            "title": "The impact of interface modification on the behavior of phenyl alcohols\n  within silica templates",
            "updated": "2023-12-05T11:54:02Z",
            "published": "2023-12-05T11:54:02Z",
            "summary": "Herein, thermal, dynamical properties, host-guest intermolecular\ninteractions, and wettability of a series of monohydroxy phenyl-substituted\nalcohols (PhAs) infiltrated into native and silanized silica mesopores (d = 4\nnm) were investigated by means of Dielectric and Infrared (IR) Spectroscopy,\nDifferential Scanning Calorimetry as well as the contact angle measurements.\nCalorimetric data showed the occurrence of the two glass transition\ntemperatures, Tg. Importantly, around the one detected at higher temperatures\n(Tg interfacial), strong deviation in the temperature evolution of the\nrelaxation time of the main process was observed for all systems. Moreover, an\nadditional process unrelated to the mobility of interface layer and core\nmolecules was revealed most likely connected to either SAP or \"new\"\nconfinement-induced nanoassociates. Further, IR investigations showed that the\napplied nanoconfinement had little impact on hydrogen bonds' strength, but it\ninfluenced the HBs distribution (including \"new\" population of HB) and the\ndegree of association. Additionally, for the first time, we calculated the\nactivation energy values of the dissociation process for PhAs in mesopores,\nwhich turned out to be lower with respect to those estimated for bulk samples.\nThus, our research clearly showed the impact of the spatial geometrical\nrestriction on the association process in alcohols having significant steric\nhindrance.",
            "author": [
                "Natalia Soszka",
                "Magdalena Tarnacka",
                "Barbara Hachula",
                "Monika Geppert-Rybczynska",
                "Krystian Prusik",
                "Kamil Kaminski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02695v1",
                "http://arxiv.org/pdf/2312.02695v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02692v1",
            "title": "Gate-tunable graphene Josephson diode effect due to magnetochiral\n  anisotropy",
            "updated": "2023-12-05T11:52:21Z",
            "published": "2023-12-05T11:52:21Z",
            "summary": "Usually the magnetochiral anisotropy related Josephson diode effect is\nassumed to be based on conventional two-dimensional electron gas, such as the\nInAs quantum well. Here we propose a graphene-based Josephson junction as a\nbroadly gate-tunable platform for achieving nonreciprocal supercurrent within\nthe context of magnetochiral anisotropy. We show that the resulting\nnonreciprocal supercurrents will exhibit a sign reversal when the graphene\nswitches from $n$-type doping to $p$-type doping. Particularly, the magnitude\nof the nonreciprocity is highly sensitive to the electrostatic doping level of\ngraphene, enabling gate control of the diode efficiency from zero up to\napproximately $40\\%$. This giant gate-tunability stems from the chiral nature\nof the pseudo-relativistic carriers in grapehe, allowing the graphene Josephson\ndiode emerges as a promising element for advanced superconducting circuits and\ncomputation devices. Moreover, we have also obtained the so-called $0-\\pi$-like\nphase transitions in the current-phase relation, in coincidence with recent\nexperimental finding.",
            "author": [
                "Chuan-Shuai Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02692v1",
                "http://arxiv.org/pdf/2312.02692v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02689v1",
            "title": "Limit theorems for Birkhoff sums and local times of the periodic Lorentz\n  gas with infinite horizon",
            "updated": "2023-12-05T11:45:49Z",
            "published": "2023-12-05T11:45:49Z",
            "summary": "This work is a contribution to the study of the ergodic and stochastic\nproperties of Z^d-periodic dynamical systems preserving an infinite measure. We\nestablish functional limit theorems for natural Birkhoff sums related to local\ntimes of the Z^d-periodic Lorentz gas with infinite horizon, for both the\ncollision map and the flow. In particular, our results apply to the difference\nbetween the numbers of collisions in two different cells. Because of the\nZ^d-periodicity of the model we are interested in, these Birkhoff sums can be\nrewritten as additive functionals of a Birkhoff sum of the Sinai billiard. For\ncompletness and in view of future studies, we state a general result of\nconvergence of additive functionals of Birkhoff sums of chaotic probability\npreserving dynamical systems under general assumptions.",
            "author": [
                "Fran\u00e7oise P\u00e8ne"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02689v1",
                "http://arxiv.org/pdf/2312.02689v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02685v1",
            "title": "On the differential equations of frozen Calogero-Moser-Sutherland\n  particle models",
            "updated": "2023-12-05T11:42:42Z",
            "published": "2023-12-05T11:42:42Z",
            "summary": "Multivariate Bessel and Jacobi processes describe Calogero-Moser-Sutherland\nparticle models. They depend on a parameter $k$ and are related to\ntime-dependent classical random matrix models like Dysom Brownian motions,\nwhere $k$ has the interpretation of an inverse temperature. There are several\nstochastic limit theorems for $k\\to\\infty$ were the limits depend on the\nsolutions of associated ODEs where these ODEs admit particular simple solutions\nwhich are connected with the zeros of the classical orthogonal polynomials. In\nthis paper we show that these solutions attract all solutions. Moreover we\npresent a connection between the solutions of these ODEs with associated\ninverse heat equations. These inverse heat equations are used to compute the\nexpectations of some determinantal formulas for the Bessel and Jacobi\nprocesses.",
            "author": [
                "Michael Voit"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02685v1",
                "http://arxiv.org/pdf/2312.02685v1"
            ],
            "primary_category": "math.CA",
            "category": [
                "math.CA",
                "math.PR",
                "70F10, 34F05, 60J60, 60B20, 82C22, 33C67"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02683v1",
            "title": "Diffusion-Based Speech Enhancement in Matched and Mismatched Conditions\n  Using a Heun-Based Sampler",
            "updated": "2023-12-05T11:40:38Z",
            "published": "2023-12-05T11:40:38Z",
            "summary": "Diffusion models are a new class of generative models that have recently been\napplied to speech enhancement successfully. Previous works have demonstrated\ntheir superior performance in mismatched conditions compared to state-of-the\nart discriminative models. However, this was investigated with a single\ndatabase for training and another one for testing, which makes the results\nhighly dependent on the particular databases. Moreover, recent developments\nfrom the image generation literature remain largely unexplored for speech\nenhancement. These include several design aspects of diffusion models, such as\nthe noise schedule or the reverse sampler. In this work, we systematically\nassess the generalization performance of a diffusion-based speech enhancement\nmodel by using multiple speech, noise and binaural room impulse response (BRIR)\ndatabases to simulate mismatched acoustic conditions. We also experiment with a\nnoise schedule and a sampler that have not been applied to speech enhancement\nbefore. We show that the proposed system substantially benefits from using\nmultiple databases for training, and achieves superior performance compared to\nstate-of-the-art discriminative models in both matched and mismatched\nconditions. We also show that a Heun-based sampler achieves superior\nperformance at a smaller computational cost compared to a sampler commonly used\nfor speech enhancement.",
            "author": [
                "Philippe Gonzalez",
                "Zheng-Hua Tan",
                "Jan \u00d8stergaard",
                "Jesper Jensen",
                "Tommy Sonne Alstr\u00f8m",
                "Tobias May"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02683v1",
                "http://arxiv.org/pdf/2312.02683v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02681v1",
            "title": "On the tulip flame formation: the effect of pressure waves",
            "updated": "2023-12-05T11:35:42Z",
            "published": "2023-12-05T11:35:42Z",
            "summary": "The effects of pressure waves on the tulip flame formation in closed and\nsemi-open tubes were studied using numerical simulations of the fully\ncompressible Navier-Stokes equations coupled to a detailed chemical model for\nstoichiometric hydrogen air mixture. Rarefaction waves generated by the\ndecelerating flame are shown to be the primary physical process leading to the\nflame front inversion and the tulip flame formation for spark and for planar\nignited flames in closed tubes. In the case of a spark ignited flame, the first\nrarefaction wave is generated by the flame, which is decelerating due to the\nreduction in flame surface area as the flame skirt touches the tube walls.\nFlame collisions with pressure waves in a closed tube result in additional\ndeceleration stages and rarefaction waves that shorten the time of the tulip\nflame formation.",
            "author": [
                "Chengeng Qian",
                "Mikhail A. Liberman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02681v1",
                "http://arxiv.org/pdf/2312.02681v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02673v1",
            "title": "Robust Backdoor Detection for Deep Learning via Topological Evolution\n  Dynamics",
            "updated": "2023-12-05T11:29:12Z",
            "published": "2023-12-05T11:29:12Z",
            "summary": "A backdoor attack in deep learning inserts a hidden backdoor in the model to\ntrigger malicious behavior upon specific input patterns. Existing detection\napproaches assume a metric space (for either the original inputs or their\nlatent representations) in which normal samples and malicious samples are\nseparable. We show that this assumption has a severe limitation by introducing\na novel SSDT (Source-Specific and Dynamic-Triggers) backdoor, which obscures\nthe difference between normal samples and malicious samples.\n  To overcome this limitation, we move beyond looking for a perfect metric\nspace that would work for different deep-learning models, and instead resort to\nmore robust topological constructs. We propose TED (Topological Evolution\nDynamics) as a model-agnostic basis for robust backdoor detection. The main\nidea of TED is to view a deep-learning model as a dynamical system that evolves\ninputs to outputs. In such a dynamical system, a benign input follows a natural\nevolution trajectory similar to other benign inputs. In contrast, a malicious\nsample displays a distinct trajectory, since it starts close to benign samples\nbut eventually shifts towards the neighborhood of attacker-specified target\nsamples to activate the backdoor.\n  Extensive evaluations are conducted on vision and natural language datasets\nacross different network architectures. The results demonstrate that TED not\nonly achieves a high detection rate, but also significantly outperforms\nexisting state-of-the-art detection approaches, particularly in addressing the\nsophisticated SSDT attack. The code to reproduce the results is made public on\nGitHub.",
            "author": [
                "Xiaoxing Mo",
                "Yechao Zhang",
                "Leo Yu Zhang",
                "Wei Luo",
                "Nan Sun",
                "Shengshan Hu",
                "Shang Gao",
                "Yang Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02673v1",
                "http://arxiv.org/pdf/2312.02673v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02670v1",
            "title": "Qubit-environment entanglement in time-dependent pure dephasing",
            "updated": "2023-12-05T11:23:25Z",
            "published": "2023-12-05T11:23:25Z",
            "summary": "We show that the methods for quantification of system-environment\nentanglement that were recently developed for interactions that lead to pure\ndecoherence of the system can be straightforwardly generalized to\ntime-dependent Hamiltonians of the same type. This includes the if-and-only-if\ncriteria of separability, as well as the entanglement measure applicable to\nqubit systems, and methods of detection of entanglement by operations and\nmeasurements performed solely on the system without accessing the environment.\nWe use these methods to study the nature of the decoherence of a\nqubit-oscillator system. Qubit-oscillator entanglement is essential for\ndeveloping bosonic quantum technology with quantum non-Gaussian states and its\napplications in quantum sensing and computing. The dominating bosonic\nplatforms, trapped ions, electromechanics, and superconducting circuits, are\nbased on the time-dependent gates that use such entanglement to achieve new\nquantum sensors and quantum error correction. The step-like time-dependence of\nthe Hamiltonian that is taken into account allows us to capture complex\ninterplay between the build-up of classical and quantum correlations, which\ncould not be replicated in time-independent scenarios.",
            "author": [
                "Ma\u0142gorzata Strza\u0142ka",
                "Radim Filip",
                "Katarzyna Roszak"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02670v1",
                "http://arxiv.org/pdf/2312.02670v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02669v1",
            "title": "Deep-learning-driven end-to-end metalens imaging",
            "updated": "2023-12-05T11:22:09Z",
            "published": "2023-12-05T11:22:09Z",
            "summary": "Recent advances in metasurface lenses (metalenses) have shown great potential\nfor opening a new era in compact imaging, photography, light detection and\nranging (LiDAR), and virtual reality/augmented reality (VR/AR) applications.\nHowever, the fundamental trade-off between broadband focusing efficiency and\noperating bandwidth limits the performance of broadband metalenses, resulting\nin chromatic aberration, angular aberration, and a relatively low efficiency.\nIn this study, a deep-learning-based image restoration framework is proposed to\novercome these limitations and realize end-to-end metalens imaging, thereby\nachieving aberration-free full-color imaging for massproduced metalenses with\n10-mm diameter. Neural network-assisted metalens imaging achieved a high\nresolution comparable to that of the ground truth image.",
            "author": [
                "Joonhyuk Seo",
                "Jaegang Jo",
                "Joohoon Kim",
                "Joonho Kang",
                "Chanik Kang",
                "Seongwon Moon",
                "Eunji Lee",
                "Jehyeong Hong",
                "Junsuk Rho",
                "Haejun Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02669v1",
                "http://arxiv.org/pdf/2312.02669v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02664v1",
            "title": "Domain-Specific Tensor Languages",
            "updated": "2023-12-05T11:09:54Z",
            "published": "2023-12-05T11:09:54Z",
            "summary": "The tensor notation used in several areas of mathematics is a useful one, but\nit is not widely available to the functional programming community. In a\npractical sense, the (embedded) domain-specific languages (DSLs) that are\ncurrently in use for tensor algebra are either 1. array-oriented languages that\ndo not enforce or take advantage of tensor properties and algebraic structure\nor 2. follow the categorical structure of tensors but require the programmer to\nmanipulate tensors in an unwieldy point-free notation. A deeper issue is that\nfor tensor calculus, the dominant pedagogical paradigm assumes an audience\nwhich is either comfortable with notational liberties which programmers cannot\nafford, or focus on the applied mathematics of tensors, largely leaving their\nlinguistic aspects (behaviour of variable binding, syntax and semantics, etc.)\nfor the reader to figure out by themselves. This state of affairs is hardly\nsurprising, because, as we highlight, several properties of standard tensor\nnotation are somewhat exotic from the perspective of lambda calculi. We bridge\nthe gap by defining a DSL, embedded in Haskell, whose syntax closely captures\nthe index notation for tensors in wide use in the literature. The semantics of\nthis EDSL is defined in terms of the algebraic structures which define tensors\nin their full generality. This way, we believe that our EDSL can be used both\nas a tool for scientific computing, but also as a vehicle to express and\npresent the theory and applications of tensors.",
            "author": [
                "Jean-Philippe Bernardy",
                "Patrik Jansson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02664v1",
                "http://arxiv.org/pdf/2312.02664v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02663v2",
            "title": "FaceStudio: Put Your Face Everywhere in Seconds",
            "updated": "2023-12-06T12:23:36Z",
            "published": "2023-12-05T11:02:45Z",
            "summary": "This study investigates identity-preserving image synthesis, an intriguing\ntask in image generation that seeks to maintain a subject's identity while\nadding a personalized, stylistic touch. Traditional methods, such as Textual\nInversion and DreamBooth, have made strides in custom image creation, but they\ncome with significant drawbacks. These include the need for extensive resources\nand time for fine-tuning, as well as the requirement for multiple reference\nimages. To overcome these challenges, our research introduces a novel approach\nto identity-preserving synthesis, with a particular focus on human images. Our\nmodel leverages a direct feed-forward mechanism, circumventing the need for\nintensive fine-tuning, thereby facilitating quick and efficient image\ngeneration. Central to our innovation is a hybrid guidance framework, which\ncombines stylized images, facial images, and textual prompts to guide the image\ngeneration process. This unique combination enables our model to produce a\nvariety of applications, such as artistic portraits and identity-blended\nimages. Our experimental results, including both qualitative and quantitative\nevaluations, demonstrate the superiority of our method over existing baseline\nmodels and previous works, particularly in its remarkable efficiency and\nability to preserve the subject's identity with high fidelity.",
            "author": [
                "Yuxuan Yan",
                "Chi Zhang",
                "Rui Wang",
                "Yichao Zhou",
                "Gege Zhang",
                "Pei Cheng",
                "Gang Yu",
                "Bin Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02663v2",
                "http://arxiv.org/pdf/2312.02663v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02661v1",
            "title": "A Self-Commissioning Edge Computing Method for Data-Driven Anomaly\n  Detection in Power Electronic Systems",
            "updated": "2023-12-05T10:56:25Z",
            "published": "2023-12-05T10:56:25Z",
            "summary": "Ensuring the reliability of power electronic converters is a matter of great\nimportance, and data-driven condition monitoring techniques are cementing\nthemselves as an important tool for this purpose. However, translating methods\nthat work well in controlled lab environments to field applications presents\nsignificant challenges, notably because of the limited diversity and accuracy\nof the lab training data. By enabling the use of field data, online machine\nlearning can be a powerful tool to overcome this problem, but it introduces\nadditional challenges in ensuring the stability and predictability of the\ntraining processes. This work presents an edge computing method that mitigates\nthese shortcomings with minimal additional memory usage, by employing an\nautonomous algorithm that prioritizes the storage of training samples with\nlarger prediction errors. The method is demonstrated on the use case of a\nself-commissioning condition monitoring system, in the form of a thermal\nanomaly detection scheme for a variable frequency motor drive, where the\nalgorithm self-learned to distinguish normal and anomalous operation with\nminimal prior knowledge. The obtained results, based on experimental data, show\na significant improvement in prediction accuracy and training speed, when\ncompared to equivalent models trained online without the proposed data\nselection process.",
            "author": [
                "Pere Izquierdo Gomez",
                "Miguel E. Lopez Gajardo",
                "Nenad Mijatovic",
                "Tomislav Dragicevic"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02661v1",
                "http://arxiv.org/pdf/2312.02661v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03028v1",
            "title": "Double Integral Enhanced Zeroing Neural Network Optimized with ALSOA\n  fostered Lung Cancer Classification using CT Images",
            "updated": "2023-12-05T10:53:35Z",
            "published": "2023-12-05T10:53:35Z",
            "summary": "Lung cancer is one of the deadliest diseases and the leading cause of illness\nand death. Since lung cancer cannot predicted at premature stage, it able to\nonly be discovered more broadly once it has spread to other lung parts. The\nrisk grows when radiologists and other specialists determine whether lung\ncancer is current. Owing to significance of determining type of treatment and\nits depth based on severity of the illness, critical to develop smart and\nautomatic cancer prediction scheme is precise, at which stage of cancer. In\nthis paper, Double Integral Enhanced Zeroing Neural Network Optimized with\nALSOA fostered Lung Cancer Classification using CT Images (LCC-DIEZNN-ALSO-CTI)\nis proposed. Initially, input CT image is amassed from lung cancer dataset. The\ninput CT image is pre-processing via Unscented Trainable Kalman Filtering\n(UTKF) technique. In pre-processing stage unwanted noise are removed from CT\nimages. Afterwards, grayscale statistic features and Haralick texture features\nextracted by Adaptive and Concise Empirical Wavelet Transform (ACEWT). The\nproposed model is implemented on MATLAB. The performance of the proposed method\nis analyzed through existing techniques. The proposed method attains 18.32%,\n27.20%, and 34.32% higher accuracy analyzed with existing method likes Deep\nLearning Assisted Predict of Lung Cancer on Computed Tomography Images\nUtilizing AHHMM (LCC-AHHMM-CT), Convolutional neural networks based pulmonary\nnodule malignancy assessment in pipeline for classifying lung cancer\n(LCC-ICNN-CT), Automated Decision Support Scheme for Lung Cancer Identification\nwith Categorization (LCC-RFCN-MLRPN-CT) methods respectively.",
            "author": [
                "V S Priya Sumitha",
                "V. Keerthika",
                "A. Geetha"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03028v1",
                "http://arxiv.org/pdf/2312.03028v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02653v1",
            "title": "Using the motion of S2 to constrain vector clouds around SgrA*",
            "updated": "2023-12-05T10:46:57Z",
            "published": "2023-12-05T10:46:57Z",
            "summary": "The dark compact object at the centre of the Milky Way is well established to\nbe a supermassive black hole with mass $M_{\\bullet} \\sim 4.3 \\cdot 10^6 \\,\nM_{\\odot}$, but the nature of its environment is still under debate. In this\nwork, we used astrometric and spectroscopic measurements of the motion of the\nstar S2, one of the closest stars to the massive black hole, to determine an\nupper limit on an extended mass composed of a massive vector field around\nSagittarius A*. For a vector with effective mass $10^{-19} \\, \\rm eV \\lesssim\nm_s \\lesssim 10^{-18} \\, \\rm eV$, our Markov Chain Monte Carlo analysis shows\nno evidence for such a cloud, placing an upper bound $M_{\\rm cloud} \\lesssim\n0.1\\% M_{\\bullet}$ at $3\\sigma$ confidence level. We show that dynamical\nfriction exerted by the medium on S2 motion plays no role in the analysis\nperformed in this and previous works, and can be neglected thus.",
            "author": [
                "GRAVITY Collaboration",
                "A. Foschi",
                "R. Abuter",
                "K. Abd El Dayem",
                "N. Aimar",
                "P. Amaro Seoane",
                "A. Amorim",
                "J. P. Berger",
                "H. Bonnet",
                "G. Bourdarot",
                "W. Brandner",
                "R. Davies",
                "P. T. de Zeeuw",
                "D. Defr\u00e8re",
                "J. Dexter",
                "A. Drescher",
                "A. Eckart",
                "F. Eisenhauer",
                "N. M. F\u00f6rster Schreiber",
                "P. J. V. Garcia",
                "R. Genzel",
                "S. Gillessen",
                "T. Gomes",
                "X. Haubois",
                "G. Hei\u00dfel",
                "Th. Henning",
                "L. Jochum",
                "L. Jocou",
                "A. Kaufer",
                "L. Kreidberg",
                "S. Lacour",
                "V. Lapeyr\u00e8re",
                "J. -B. Le Bouquin",
                "P. L\u00e9na",
                "D. Lutz",
                "F. Mang",
                "F. Millour",
                "T. Ott",
                "T. Paumard",
                "K. Perraut",
                "G. Perrin",
                "O. Pfuhl",
                "S. Rabien",
                "D. C. Ribeiro",
                "M. Sadun Bordoni",
                "S. Scheithauer",
                "J. Shangguan",
                "T. Shimizu",
                "J. Stadler",
                "C. Straubmeier",
                "E. Sturm",
                "M. Subroweit",
                "L. J. Tacconi",
                "F. Vincent",
                "S. von Fellenberg",
                "J. Woillez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02653v1",
                "http://arxiv.org/pdf/2312.02653v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03759v1",
            "title": "How should the advent of large language models affect the practice of\n  science?",
            "updated": "2023-12-05T10:45:12Z",
            "published": "2023-12-05T10:45:12Z",
            "summary": "Large language models (LLMs) are being increasingly incorporated into\nscientific workflows. However, we have yet to fully grasp the implications of\nthis integration. How should the advent of large language models affect the\npractice of science? For this opinion piece, we have invited four diverse\ngroups of scientists to reflect on this query, sharing their perspectives and\nengaging in debate. Schulz et al. make the argument that working with LLMs is\nnot fundamentally different from working with human collaborators, while Bender\net al. argue that LLMs are often misused and over-hyped, and that their\nlimitations warrant a focus on more specialized, easily interpretable tools.\nMarelli et al. emphasize the importance of transparent attribution and\nresponsible use of LLMs. Finally, Botvinick and Gershman advocate that humans\nshould retain responsibility for determining the scientific roadmap. To\nfacilitate the discussion, the four perspectives are complemented with a\nresponse from each group. By putting these different perspectives in\nconversation, we aim to bring attention to important considerations within the\nacademic community regarding the adoption of LLMs and their impact on both\ncurrent and future scientific practices.",
            "author": [
                "Marcel Binz",
                "Stephan Alaniz",
                "Adina Roskies",
                "Balazs Aczel",
                "Carl T. Bergstrom",
                "Colin Allen",
                "Daniel Schad",
                "Dirk Wulff",
                "Jevin D. West",
                "Qiong Zhang",
                "Richard M. Shiffrin",
                "Samuel J. Gershman",
                "Ven Popov",
                "Emily M. Bender",
                "Marco Marelli",
                "Matthew M. Botvinick",
                "Zeynep Akata",
                "Eric Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03759v1",
                "http://arxiv.org/pdf/2312.03759v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02649v1",
            "title": "A Q-learning approach to the continuous control problem of robot\n  inverted pendulum balancing",
            "updated": "2023-12-05T10:40:48Z",
            "published": "2023-12-05T10:40:48Z",
            "summary": "This study evaluates the application of a discrete action space reinforcement\nlearning method (Q-learning) to the continuous control problem of robot\ninverted pendulum balancing. To speed up the learning process and to overcome\ntechnical difficulties related to the direct learning on the real robotic\nsystem, the learning phase is performed in simulation environment. A\nmathematical model of the system dynamics is implemented, deduced by curve\nfitting on data acquired from the real system. The proposed approach\ndemonstrated feasible, featuring its application on a real world robot that\nlearned to balance an inverted pendulum. This study also reinforces and\ndemonstrates the importance of an accurate representation of the physical world\nin simulation to achieve a more efficient implementation of reinforcement\nlearning algorithms in real world, even when using a discrete action space\nalgorithm to control a continuous action.",
            "author": [
                "Mohammad Safeea",
                "Pedro Neto"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.iswa.2023.200313",
                "http://arxiv.org/abs/2312.02649v1",
                "http://arxiv.org/pdf/2312.02649v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02648v1",
            "title": "The Ebb and Flow Phenomenon: Pitfall of Intuitive Strategy",
            "updated": "2023-12-05T10:40:02Z",
            "published": "2023-12-05T10:40:02Z",
            "summary": "In decision-making, individuals often rely on intuition, which can\noccasionally yield suboptimal outcomes. This study examines the impact of\nintuitive decision-making in the job application process. Our model posits that\nindividuals' decisions to apply or withdraw from limited job positions are\ndetermined by the relative ratio between the previous year's admission rate and\nthe intuitively perceived application rate sampled from the current year's\npopulation. Our investigation uncovers the emergence of the ``ebb and flow''\nphenomenon: When competition is intense in a preceding year, it tends to wane\nin the subsequent year, and vice versa. This phenomenon can result in\nsignificant inefficiencies in resource allocation. Empirical experiments also\nunveil variations in individuals' reliance on intuition, indicating the\npresence of inherent adventurous and conservative inclinations. To navigate\nthese intricate dynamics, we introduce a modification factor that enhances our\nmodel's ability to capture a spectrum of individual behaviors within the\napplication process. This study yields valuable insights into resource\nallocation, particularly within the context of the competitive job market.",
            "author": [
                "Hui Xiao",
                "Fanyuan Meng",
                "Xinlin Wu",
                "Xiaojun Hu",
                "Xiaojie Niu",
                "Sheng Chen",
                "Yu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02648v1",
                "http://arxiv.org/pdf/2312.02648v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02626v1",
            "title": "Predicting Network Congestion by Extending Betweenness Centrality to\n  Interacting Agents",
            "updated": "2023-12-05T10:01:28Z",
            "published": "2023-12-05T10:01:28Z",
            "summary": "We present a simple model to predict network activity at the edge level, by\nextending a known approximation method to compute Betweenness Centrality (BC)\nwith a repulsive mechanism to prevent unphysical densities. By taking into\naccount the strong interaction effects often observed in real phenomena, we aim\nto obtain an improved measure of edge usage during rush hours as traffic\ncongestion patterns emerge in urban networks. In this approach, the network is\niteratively populated by agents following dynamically evolving fastest paths,\nthat are progressively attracted towards uncongested parts of the network, as\nthe global traffic volume increases. Following the transition of the network\nstate from empty to saturated, we study the emergence of congestion and the\nprogressive disruption of global connectivity due to a relatively small\nfraction of crowded edges.\n  We assess the predictive power of our model by comparing the speed\ndistribution against a large experimental dataset for the London area with\nremarkable results, which also translate into a qualitative similarity of the\ncongestion maps. Also, percolation analysis confirms a quantitative agreement\nof the model with the real data for London. For seven other topologically\ndifferent cities we performed simulations to obtain the Fisher critical\nexponent $\\tau$ that showed no common functional dependence on the traffic\nlevel. The critical exponent $\\gamma$, studied to assess the power-law decay of\nspatial correlation, was found inversely proportional to the number of vehicles\nboth for real and simulated traffic.\n  This simulation approach seems particularly fit to describe qualitative and\nquantitative properties of the network loading process, culminating in\npeak-hour congestion, by using only topological and geographical network\nfeatures.",
            "author": [
                "Marco Cogoni",
                "Giovanni Busonera"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02626v1",
                "http://arxiv.org/pdf/2312.02626v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02625v1",
            "title": "Diffusion Noise Feature: Accurate and Fast Generated Image Detection",
            "updated": "2023-12-05T10:01:11Z",
            "published": "2023-12-05T10:01:11Z",
            "summary": "Generative models have reached an advanced stage where they can produce\nremarkably realistic images. However, this remarkable generative capability\nalso introduces the risk of disseminating false or misleading information.\nNotably, existing image detectors for generated images encounter challenges\nsuch as low accuracy and limited generalization. This paper seeks to address\nthis issue by seeking a representation with strong generalization capabilities\nto enhance the detection of generated images. Our investigation has revealed\nthat real and generated images display distinct latent Gaussian representations\nwhen subjected to an inverse diffusion process within a pre-trained diffusion\nmodel. Exploiting this disparity, we can amplify subtle artifacts in generated\nimages. Building upon this insight, we introduce a novel image representation\nknown as Diffusion Noise Feature (DNF). DNF is an ensemble representation that\nestimates the noise generated during the inverse diffusion process. A simple\nclassifier, e.g., ResNet, trained on DNF achieves high accuracy, robustness,\nand generalization capabilities for detecting generated images, even from\npreviously unseen classes or models. We conducted experiments using a widely\nrecognized and standard dataset, achieving state-of-the-art effects of\nDetection.",
            "author": [
                "Yichi Zhang",
                "Xiaogang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02625v1",
                "http://arxiv.org/pdf/2312.02625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02622v1",
            "title": "On the Initialization of Graph Neural Networks",
            "updated": "2023-12-05T09:55:49Z",
            "published": "2023-12-05T09:55:49Z",
            "summary": "Graph Neural Networks (GNNs) have displayed considerable promise in graph\nrepresentation learning across various applications. The core learning process\nrequires the initialization of model weight matrices within each GNN layer,\nwhich is typically accomplished via classic initialization methods such as\nXavier initialization. However, these methods were originally motivated to\nstabilize the variance of hidden embeddings and gradients across layers of\nFeedforward Neural Networks (FNNs) and Convolutional Neural Networks (CNNs) to\navoid vanishing gradients and maintain steady information flow. In contrast,\nwithin the GNN context classical initializations disregard the impact of the\ninput graph structure and message passing on variance. In this paper, we\nanalyze the variance of forward and backward propagation across GNN layers and\nshow that the variance instability of GNN initializations comes from the\ncombined effect of the activation function, hidden dimension, graph structure\nand message passing. To better account for these influence factors, we propose\na new initialization method for Variance Instability Reduction within GNN\nOptimization (Virgo), which naturally tends to equate forward and backward\nvariances across successive layers. We conduct comprehensive experiments on 15\ndatasets to show that Virgo can lead to superior model performance and more\nstable variance at initialization on node classification, link prediction and\ngraph classification tasks. Codes are in\nhttps://github.com/LspongebobJH/virgo_icml2023.",
            "author": [
                "Jiahang Li",
                "Yakun Song",
                "Xiang Song",
                "David Paul Wipf"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02622v1",
                "http://arxiv.org/pdf/2312.02622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02618v1",
            "title": "Bottom's Dream and the amplification of filamentary gas structures and\n  stellar spiral arms",
            "updated": "2023-12-05T09:48:34Z",
            "published": "2023-12-05T09:48:34Z",
            "summary": "Theories of spiral structure traditionally separate into tight-winding\nLin-Shu spiral density waves and the swing-amplified material patterns of\nGoldreich & Lynden-Bell and Julian & Toomre. In this paper we consolidate these\ntwo types of spirals into a unified description, treating density waves beyond\nthe tight-winding limit, in the regime of shearing and non-steady open spirals.\nThis 'shearing wave' scenario novelly captures swing amplification that enables\nstructure formation above conventional Q thresholds. However, it also\nhighlights the fundamental role of spiral forcing on the amplification process\nin general, whether the wave is shearing or not. Thus it captures resonant and\nnon-resonant mode growth through the donkey effect described by Lynden-Bell &\nKalnajs and, critically, the cessation of growth when donkey behavior is no\nlonger permitted. Our calculations predict growth exclusive to trailing spirals\nabove the Jeans length, the prominence of spirals across a range of\norientations that increases with decreasing arm multiplicity, and a critical\norientation where growth is fastest that is the same for both modes and\nmaterial patterns. Predicted structures are consistent with highly regular,\nhigh-multiplicity gaseous spur features and long filaments spaced close to the\nJeans scale in spirals and bars. Applied to stellar disks, conditions favor low\nmultiplicity (m<5) open trailing spirals with pitch angles in the observed\nrange $10 deg$<$i_p$<$50 deg$. The results of this work serve as a basis for\ndescribing spirals as a unified class of transient waves, abundantly stimulated\nbut narrowly selected for growth depending on local conditions.",
            "author": [
                "Sharon E. Meidt",
                "Arjen van der Wel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02618v1",
                "http://arxiv.org/pdf/2312.02618v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02616v1",
            "title": "Facilitating the Production of Well-tailored Video Summaries for Sharing\n  on Social Media",
            "updated": "2023-12-05T09:47:28Z",
            "published": "2023-12-05T09:47:28Z",
            "summary": "This paper presents a web-based tool that facilitates the production of\ntailored summaries for online sharing on social media. Through an interactive\nuser interface, it supports a ``one-click'' video summarization process. Based\non the integrated AI models for video summarization and aspect ratio\ntransformation, it facilitates the generation of multiple summaries of a\nfull-length video according to the needs of target platforms with regard to the\nvideo's length and aspect ratio.",
            "author": [
                "Evlampios Apostolidis",
                "Konstantinos Apostolidis",
                "Vasileios Mezaris"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02616v1",
                "http://arxiv.org/pdf/2312.02616v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02614v1",
            "title": "Prompt Optimization via Adversarial In-Context Learning",
            "updated": "2023-12-05T09:44:45Z",
            "published": "2023-12-05T09:44:45Z",
            "summary": "We propose a new method, Adversarial In-Context Learning (adv-ICL), to\noptimize prompt for in-context learning (ICL) by employing one LLM as a\ngenerator, another as a discriminator, and a third as a prompt modifier. As in\ntraditional adversarial learning, adv-ICL is implemented as a two-player game\nbetween the generator and discriminator, where the generator tries to generate\nrealistic enough output to fool the discriminator. In each round, given an\ninput prefixed by task instructions and several exemplars, the generator\nproduces an output. The discriminator is then tasked with classifying the\ngenerator input-output pair as model-generated or real data. Based on the\ndiscriminator loss, the prompt modifier proposes possible edits to the\ngenerator and discriminator prompts, and the edits that most improve the\nadversarial loss are selected. We show that adv-ICL results in significant\nimprovements over state-of-the-art prompt optimization techniques for both open\nand closed-source models on 11 generation and classification tasks including\nsummarization, arithmetic reasoning, machine translation, data-to-text\ngeneration, and the MMLU and big-bench hard benchmarks. In addition, because\nour method uses pre-trained models and updates only prompts rather than model\nparameters, it is computationally efficient, easy to extend to any LLM and\ntask, and effective in low-resource settings.",
            "author": [
                "Xuan Long Do",
                "Yiran Zhao",
                "Hannah Brown",
                "Yuxi Xie",
                "James Xu Zhao",
                "Nancy F. Chen",
                "Kenji Kawaguchi",
                "Michael Qizhe Xie",
                "Junxian He"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02614v1",
                "http://arxiv.org/pdf/2312.02614v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02610v1",
            "title": "Quasi-isomorphism of grid chain complexes for a connected sum of knots",
            "updated": "2023-12-05T09:38:29Z",
            "published": "2023-12-05T09:38:29Z",
            "summary": "We give a purely combinatorial proof of the K\\\"{u}nneth formula for the knot\nFloer homology of connected sums by constructing a quasi-isomorphism of grid\nchain complexes. This proof is complete within the framework of the knot grid\nhomology. The construction of the quasi-isomorphism naturally deduces that the\nLegendrian and transverse invariants behave functorially with respect to the\nconnected sum operation.",
            "author": [
                "Hajime Kubota"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02610v1",
                "http://arxiv.org/pdf/2312.02610v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.AT",
                "57K18"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02608v1",
            "title": "Panoptica -- instance-wise evaluation of 3D semantic and instance\n  segmentation maps",
            "updated": "2023-12-05T09:34:56Z",
            "published": "2023-12-05T09:34:56Z",
            "summary": "This paper introduces panoptica, a versatile and performance-optimized\npackage designed for computing instance-wise segmentation quality metrics from\n2D and 3D segmentation maps. panoptica addresses the limitations of existing\nmetrics and provides a modular framework that complements the original\nintersection over union-based panoptic quality with other metrics, such as the\ndistance metric Average Symmetric Surface Distance. The package is open-source,\nimplemented in Python, and accompanied by comprehensive documentation and\ntutorials. panoptica employs a three-step metrics computation process to cover\ndiverse use cases. The efficacy of panoptica is demonstrated on various\nreal-world biomedical datasets, where an instance-wise evaluation is\ninstrumental for an accurate representation of the underlying clinical task.\nOverall, we envision panoptica as a valuable tool facilitating in-depth\nevaluation of segmentation methods.",
            "author": [
                "Florian Kofler",
                "Hendrik M\u00f6ller",
                "Josef A. Buchner",
                "Ezequiel de la Rosa",
                "Ivan Ezhov",
                "Marcel Rosier",
                "Isra Mekki",
                "Suprosanna Shit",
                "Moritz Negwer",
                "Rami Al-Maskari",
                "Ali Ert\u00fcrk",
                "Shankeeth Vinayahalingam",
                "Fabian Isensee",
                "Sarthak Pati",
                "Daniel Rueckert",
                "Jan S. Kirschke",
                "Stefan K. Ehrlich",
                "Annika Reinke",
                "Bjoern Menze",
                "Benedikt Wiestler",
                "Marie Piraud"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02608v1",
                "http://arxiv.org/pdf/2312.02608v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02605v1",
            "title": "Accelerating Learnt Video Codecs with Gradient Decay and Layer-wise\n  Distillation",
            "updated": "2023-12-05T09:26:09Z",
            "published": "2023-12-05T09:26:09Z",
            "summary": "In recent years, end-to-end learnt video codecs have demonstrated their\npotential to compete with conventional coding algorithms in term of compression\nefficiency. However, most learning-based video compression models are\nassociated with high computational complexity and latency, in particular at the\ndecoder side, which limits their deployment in practical applications. In this\npaper, we present a novel model-agnostic pruning scheme based on gradient decay\nand adaptive layer-wise distillation. Gradient decay enhances parameter\nexploration during sparsification whilst preventing runaway sparsity and is\nsuperior to the standard Straight-Through Estimation. The adaptive layer-wise\ndistillation regulates the sparse training in various stages based on the\ndistortion of intermediate features. This stage-wise design efficiently updates\nparameters with minimal computational overhead. The proposed approach has been\napplied to three popular end-to-end learnt video codecs, FVC, DCVC, and\nDCVC-HEM. Results confirm that our method yields up to 65% reduction in MACs\nand 2x speed-up with less than 0.3dB drop in BD-PSNR. Supporting code and\nsupplementary material can be downloaded from:\nhttps://jasminepp.github.io/lightweightdvc/",
            "author": [
                "Tianhao Peng",
                "Ge Gao",
                "Heming Sun",
                "Fan Zhang",
                "David Bull"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02605v1",
                "http://arxiv.org/pdf/2312.02605v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02604v1",
            "title": "Shedding light on charmonium",
            "updated": "2023-12-05T09:25:35Z",
            "published": "2023-12-05T09:25:35Z",
            "summary": "We investigate E1 radiative transitions within charmonium in a relativistic\napproach based on light-front QCD. In quantum field theory, two sets of\nprocesses are pure E1: $\\chi_{c0} \\to J/\\psi \\gamma$ ($\\psi\\to\n\\chi_{c0}\\gamma$) and $h_c \\to \\eta_c\\gamma$ ($\\eta_c' \\to h_c\\gamma$), both\ninvolving the $P$-wave charmonia. We compute the E1 radiative decay widths as\nwell as the corresponding transition form factors of various processes\nincluding those involving $2P$ states. These observables provide an access to\nthe microscopic structures of the $P$-wave charmonium. We show that our\nparameter-free predictions are in excellent agreement with the experimental\nmeasurements as well as lattice simulations whenever available.",
            "author": [
                "Zhiguo Wang",
                "Meijian Li",
                "Yang Li",
                "James P. Vary"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02604v1",
                "http://arxiv.org/pdf/2312.02604v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02603v1",
            "title": "Automatic Robot Path Planning for Visual Inspection from Object Shape",
            "updated": "2023-12-05T09:21:34Z",
            "published": "2023-12-05T09:21:34Z",
            "summary": "Visual inspection is a crucial yet time-consuming task across various\nindustries. Numerous established methods employ machine learning in inspection\ntasks, necessitating specific training data that includes predefined inspection\nposes and training images essential for the training of models. The acquisition\nof such data and their integration into an inspection framework is challenging\ndue to the variety in objects and scenes involved and due to additional\nbottlenecks caused by the manual collection of training data by humans, thereby\nhindering the automation of visual inspection across diverse domains. This work\nproposes a solution for automatic path planning using a single depth camera\nmounted on a robot manipulator. Point clouds obtained from the depth images are\nprocessed and filtered to extract object profiles and transformed to inspection\ntarget paths for the robot end-effector. The approach relies on the geometry of\nthe object and generates an inspection path that follows the shape normal to\nthe surface. Depending on the object size and shape, inspection paths can be\ndefined as single or multi-path plans. Results are demonstrated in both\nsimulated and real-world environments, yielding promising inspection paths for\nobjects with varying sizes and shapes. Code and video are open-source available\nat: https://github.com/CuriousLad1000/Auto-Path-Planner",
            "author": [
                "O. Tasneem",
                "R. Pieters"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02603v1",
                "http://arxiv.org/pdf/2312.02603v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02601v1",
            "title": "A Neural Receiver for 5G NR Multi-user MIMO",
            "updated": "2023-12-05T09:19:26Z",
            "published": "2023-12-05T09:19:26Z",
            "summary": "We introduce a neural network (NN)-based multiuser multiple-input\nmultiple-output (MU-MIMO) receiver with 5G New Radio (5G NR) physical uplink\nshared channel (PUSCH) compatibility. The NN architecture is based on\nconvolution layers to exploit the time and frequency correlation of the channel\nand a graph neural network (GNN) to handle multiple users. The proposed\narchitecture adapts to an arbitrary number of sub-carriers and supports a\nvarying number of multiple-input multiple-output (MIMO) layers and users\nwithout the need for any retraining. The receiver operates on an entire 5G NR\nslot, i.e., processes the entire received orthogonal frequency division\nmultiplexing (OFDM) time-frequency resource grid by jointly performing channel\nestimation, equalization, and demapping. The proposed architecture operates\nless than 1 dB away from a baseline using linear minimum mean square error\n(LMMSE) channel estimation with K-best detection but benefits from a\nsignificantly lower computational complexity. We show the importance of a\ncarefully designed training process such that the trained receiver is universal\nfor a wide range of different unseen channel conditions. Finally, we\ndemonstrate the results of a hardware-in-the-loop verification based on 3GPP\ncompliant conformance test scenarios.",
            "author": [
                "Sebastian Cammerer",
                "Fay\u00e7al A\u00eft Aoudia",
                "Jakob Hoydis",
                "Andreas Oeldemann",
                "Andreas Roessler",
                "Timo Mayer",
                "Alexander Keller"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02601v1",
                "http://arxiv.org/pdf/2312.02601v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02599v1",
            "title": "MAINS: A Magnetic Field Aided Inertial Navigation System for Indoor\n  Positioning",
            "updated": "2023-12-05T09:18:12Z",
            "published": "2023-12-05T09:18:12Z",
            "summary": "A Magnetic field Aided Inertial Navigation System (MAINS) for indoor\nnavigation is proposed in this paper. MAINS leverages an array of magnetometers\nto measure spatial variations in the magnetic field, which are then used to\nestimate the displacement and orientation changes of the system, thereby aiding\nthe inertial navigation system (INS). Experiments show that MAINS significantly\noutperforms the stand-alone INS, demonstrating a remarkable two orders of\nmagnitude reduction in position error. Furthermore, when compared to the\nstate-of-the-art magnetic-field-aided navigation approach, the proposed method\nexhibits slightly improved horizontal position accuracy. On the other hand, it\nhas noticeably larger vertical error on datasets with large magnetic field\nvariations. However, one of the main advantages of MAINS compared to the\nstate-of-the-art is that it enables flexible sensor configurations. The\nexperimental results show that the position error after 2 minutes of navigation\nin most cases is less than 3 meters when using an array of 30 magnetometers.\nThus, the proposed navigation solution has the potential to solve one of the\nkey challenges faced with current magnetic-field simultaneous localization and\nmapping (SLAM) solutions: the very limited allowable length of the exploration\nphase during which unvisited areas are mapped.",
            "author": [
                "Chuan Huang",
                "Gustaf Hendeby",
                "Hassen Fourati",
                "Christophe Prieur",
                "Isaac Skog"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02599v1",
                "http://arxiv.org/pdf/2312.02599v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02598v1",
            "title": "Impact of Tokenization on LLaMa Russian Adaptation",
            "updated": "2023-12-05T09:16:03Z",
            "published": "2023-12-05T09:16:03Z",
            "summary": "Latest instruction-tuned large language models (LLM) show great results on\nvarious tasks, however, they often face performance degradation for non-English\ninput. There is evidence that the reason lies in inefficient tokenization\ncaused by low language representation in pre-training data which hinders the\ncomprehension of non-English instructions, limiting the potential of target\nlanguage instruction-tuning. In this work we investigate the possibility of\naddressing the issue with vocabulary substitution in the context of LLaMa\nRussian language adaptation. We explore three variants of vocabulary adaptation\nand test their performance on Saiga instruction-tuning and fine-tuning on\nRussian Super Glue benchmark. The results of automatic evaluation show that\nvocabulary substitution not only improves the model's quality in Russian but\nalso accelerates fine-tuning (35%) and inference (up to 60%) while reducing\nmemory consumption. Additional human evaluation of the instruction-tuned models\ndemonstrates that models with Russian-adapted vocabulary generate answers with\nhigher user preference than the original Saiga-LLaMa model.",
            "author": [
                "Mikhail Tikhomirov",
                "Daniil Chernyshev"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02598v1",
                "http://arxiv.org/pdf/2312.02598v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02597v1",
            "title": "Mitigating noise of residual electric fields for single Rydberg atoms\n  with electron photodesorption",
            "updated": "2023-12-05T09:15:23Z",
            "published": "2023-12-05T09:15:23Z",
            "summary": "Rydberg atoms as versatile tools for quantum applications are extremely\nsensitive to electric fields. When utilizing these atoms, it becomes imperative\nto comprehensively characterize and mitigate any residual electric fields\npresent in the environment. Particularly for single Rydberg atoms trapped in\noptical tweezers in a compact quartz vacuum cell, we have identified that a\nsignificant source of background electric fields originates from electrons\nbound to the cell surface. These electrons are generated by the 297-nm light\nused for single-photon Rydberg excitation. Furthermore, once the electrons are\ndesorbed from the surface through exposure to ultraviolet light, the incoherent\nground-Rydberg transition undergoes a transformation into coherent excitation,\nsince the noise of residual electric fields are effectively mitigated. Our\nstudies promote enhanced control and reliable performance of Rydberg atom-based\nsystems, thereby paving the way for advancements in quantum information\nprocessing, the realization of high-fidelity quantum gates, and the development\nof precise quantum sensors.",
            "author": [
                "Bahtiyar Mamat",
                "Cheng Sheng",
                "Xiaodong He",
                "Jiayi Hou",
                "Peng Xu",
                "Kunpeng Wang",
                "Jun Zhuang",
                "Mingrui Wei",
                "Min Liu",
                "Jin Wang",
                "Mingsheng Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02597v1",
                "http://arxiv.org/pdf/2312.02597v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02592v1",
            "title": "FRAPP\u00c9: A Post-Processing Framework for Group Fairness Regularization",
            "updated": "2023-12-05T09:09:21Z",
            "published": "2023-12-05T09:09:21Z",
            "summary": "Post-processing mitigation techniques for group fairness generally adjust the\ndecision threshold of a base model in order to improve fairness. Methods in\nthis family exhibit several advantages that make them appealing in practice:\npost-processing requires no access to the model training pipeline, is agnostic\nto the base model architecture, and offers a reduced computation cost compared\nto in-processing. Despite these benefits, existing methods face other\nchallenges that limit their applicability: they require knowledge of the\nsensitive attributes at inference time and are oftentimes outperformed by\nin-processing. In this paper, we propose a general framework to transform any\nin-processing method with a penalized objective into a post-processing\nprocedure. The resulting method is specifically designed to overcome the\naforementioned shortcomings of prior post-processing approaches. Furthermore,\nwe show theoretically and through extensive experiments on real-world data that\nthe resulting post-processing method matches or even surpasses the\nfairness-error trade-off offered by the in-processing counterpart.",
            "author": [
                "Alexandru \u0162ifrea",
                "Preethi Lahoti",
                "Ben Packer",
                "Yoni Halpern",
                "Ahmad Beirami",
                "Flavien Prost"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02592v1",
                "http://arxiv.org/pdf/2312.02592v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02590v1",
            "title": "Text Intimacy Analysis using Ensembles of Multilingual Transformers",
            "updated": "2023-12-05T09:04:22Z",
            "published": "2023-12-05T09:04:22Z",
            "summary": "Intimacy estimation of a given text has recently gained importance due to the\nincrease in direct interaction of NLP systems with humans. Intimacy is an\nimportant aspect of natural language and has a substantial impact on our\neveryday communication. Thus the level of intimacy can provide us with deeper\ninsights and richer semantics of conversations. In this paper, we present our\nwork on the SemEval shared task 9 on predicting the level of intimacy for the\ngiven text. The dataset consists of tweets in ten languages, out of which only\nsix are available in the training dataset. We conduct several experiments and\nshow that an ensemble of multilingual models along with a language-specific\nmonolingual model has the best performance. We also evaluate other data\naugmentation methods such as translation and present the results. Lastly, we\nstudy the results thoroughly and present some noteworthy insights into this\nproblem.",
            "author": [
                "Tanmay Chavan",
                "Ved Patwardhan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02590v1",
                "http://arxiv.org/pdf/2312.02590v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02581v2",
            "title": "Auralization based on multi-perspective ambisonic room impulse responses",
            "updated": "2023-12-06T08:57:34Z",
            "published": "2023-12-05T08:54:34Z",
            "summary": "Most often, virtual acoustic rendering employs real-time updated room\nacoustic simulations to accomplish auralization for a variable listener\nperspective. As an alternative, we propose and test a technique to interpolate\nroom impulse responses, specifically Ambisonic room impulse responses (ARIRs)\navailable at a grid of spatially distributed receiver perspectives, measured or\nsimulated in a desired acoustic environment. In particular, we extrapolate a\ntriplet of neighboring ARIRs to the variable listener perspective, preceding\ntheir linear interpolation. The extrapolation is achieved by decomposing each\nARIR into localized sound events and re-assigning their direction, time, and\nlevel to what could be observed at the listener perspective, with as much\ntemporal, directional, and perspective context as possible. We propose to\nundertake this decomposition in two levels: Peaks in the early ARIRs are\ndecomposed into jointly localized sound events, based on time differences of\narrival observed in either an ARIR triplet, or all ARIRs observing the direct\nsound. Sound events that could not be jointly localized are treated as\nresiduals whose less precise localization utilizes direction-of-arrival\ndetection and the estimated time of arrival. For the interpolated rendering,\nsuitable parameter settings are found by evaluating the proposed method in a\nlistening experiment, using both measured and simulated ARIR data sets, under\nstatic and time-varying conditions.",
            "author": [
                "Kaspar M\u00fcller",
                "Franz Zotter"
            ],
            "link": [
                "http://dx.doi.org/10.1051/aacus/2020024",
                "http://arxiv.org/abs/2312.02581v2",
                "http://arxiv.org/pdf/2312.02581v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02578v1",
            "title": "Empathy and Distress Detection using Ensembles of Transformer Models",
            "updated": "2023-12-05T08:50:34Z",
            "published": "2023-12-05T08:50:34Z",
            "summary": "This paper presents our approach for the WASSA 2023 Empathy, Emotion and\nPersonality Shared Task. Empathy and distress are human feelings that are\nimplicitly expressed in natural discourses. Empathy and distress detection are\ncrucial challenges in Natural Language Processing that can aid our\nunderstanding of conversations. The provided dataset consists of several\nlong-text examples in the English language, with each example associated with a\nnumeric score for empathy and distress. We experiment with several BERT-based\nmodels as a part of our approach. We also try various ensemble methods. Our\nfinal submission has a Pearson's r score of 0.346, placing us third in the\nempathy and distress detection subtask.",
            "author": [
                "Tanmay Chavan",
                "Kshitij Deshpande",
                "Sheetal Sonawane"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02578v1",
                "http://arxiv.org/pdf/2312.02578v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02575v1",
            "title": "A Bayesian neural network approach to Multi-fidelity surrogate modelling",
            "updated": "2023-12-05T08:47:24Z",
            "published": "2023-12-05T08:47:24Z",
            "summary": "This paper deals with surrogate modelling of a computer code output in a\nhierarchical multi-fidelity context, i.e., when the output can be evaluated at\ndifferent levels of accuracy and computational cost. Using observations of the\noutput at low- and high-fidelity levels, we propose a method that combines\nGaussian process (GP) regression and Bayesian neural network (BNN), in a method\ncalled GPBNN. The low-fidelity output is treated as a single-fidelity code\nusing classical GP regression. The high-fidelity output is approximated by a\nBNN that incorporates, in addition to the high-fidelity observations,\nwell-chosen realisations of the low-fidelity output emulator. The predictive\nuncertainty of the final surrogate model is then quantified by a complete\ncharacterisation of the uncertainties of the different models and their\ninteraction. GPBNN is compared with most of the multi-fidelity regression\nmethods allowing to quantify the prediction uncertainty.",
            "author": [
                "Baptiste Kerleguer",
                "Claire Cannamela",
                "Josselin Garnier"
            ],
            "link": [
                "http://dx.doi.org/10.1615/Int.J.UncertaintyQuantification.2023044584",
                "http://arxiv.org/abs/2312.02575v1",
                "http://arxiv.org/pdf/2312.02575v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02573v1",
            "title": "UTBoost: A Tree-boosting based System for Uplift Modeling",
            "updated": "2023-12-05T08:41:23Z",
            "published": "2023-12-05T08:41:23Z",
            "summary": "Uplift modeling refers to the set of machine learning techniques that a\nmanager may use to estimate customer uplift, that is, the net effect of an\naction on some customer outcome. By identifying the subset of customers for\nwhom a treatment will have the greatest effect, uplift models assist\ndecision-makers in optimizing resource allocations and maximizing overall\nreturns. Accurately estimating customer uplift poses practical challenges, as\nit requires assessing the difference between two mutually exclusive outcomes\nfor each individual. In this paper, we propose two innovative adaptations of\nthe well-established Gradient Boosting Decision Trees (GBDT) algorithm, which\nlearn the causal effect in a sequential way and overcome the counter-factual\nnature. Both approaches innovate existing techniques in terms of ensemble\nlearning method and learning objectives, respectively. Experiments on\nlarge-scale datasets demonstrate the usefulness of the proposed methods, which\noften yielding remarkable improvements over base models. To facilitate the\napplication, we develop the UTBoost, an end-to-end tree boosting system\nspecifically designed for uplift modeling. The package is open source and has\nbeen optimized for training speed to meet the needs of real industrial\napplications.",
            "author": [
                "Junjie Gao",
                "Xiangyu Zheng",
                "DongDong Wang",
                "Zhixiang Huang",
                "Bangqi Zheng",
                "Kai Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02573v1",
                "http://arxiv.org/pdf/2312.02573v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02568v1",
            "title": "Prompt2NeRF-PIL: Fast NeRF Generation via Pretrained Implicit Latent",
            "updated": "2023-12-05T08:32:46Z",
            "published": "2023-12-05T08:32:46Z",
            "summary": "This paper explores promptable NeRF generation (e.g., text prompt or single\nimage prompt) for direct conditioning and fast generation of NeRF parameters\nfor the underlying 3D scenes, thus undoing complex intermediate steps while\nproviding full 3D generation with conditional control. Unlike previous\ndiffusion-CLIP-based pipelines that involve tedious per-prompt optimizations,\nPrompt2NeRF-PIL is capable of generating a variety of 3D objects with a single\nforward pass, leveraging a pre-trained implicit latent space of NeRF\nparameters. Furthermore, in zero-shot tasks, our experiments demonstrate that\nthe NeRFs produced by our method serve as semantically informative\ninitializations, significantly accelerating the inference process of existing\nprompt-to-NeRF methods. Specifically, we will show that our approach speeds up\nthe text-to-NeRF model DreamFusion and the 3D reconstruction speed of the\nimage-to-NeRF method Zero-1-to-3 by 3 to 5 times.",
            "author": [
                "Jianmeng Liu",
                "Yuyao Zhang",
                "Zeyuan Meng",
                "Yu-Wing Tai",
                "Chi-Keung Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02568v1",
                "http://arxiv.org/pdf/2312.02568v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03026v1",
            "title": "Uni3DL: Unified Model for 3D and Language Understanding",
            "updated": "2023-12-05T08:30:27Z",
            "published": "2023-12-05T08:30:27Z",
            "summary": "In this work, we present Uni3DL, a unified model for 3D and Language\nunderstanding. Distinct from existing unified vision-language models in 3D\nwhich are limited in task variety and predominantly dependent on projected\nmulti-view images, Uni3DL operates directly on point clouds. This approach\nsignificantly expands the range of supported tasks in 3D, encompassing both\nvision and vision-language tasks in 3D. At the core of Uni3DL, a query\ntransformer is designed to learn task-agnostic semantic and mask outputs by\nattending to 3D visual features, and a task router is employed to selectively\ngenerate task-specific outputs required for diverse tasks. With a unified\narchitecture, our Uni3DL model enjoys seamless task decomposition and\nsubstantial parameter sharing across tasks. Uni3DL has been rigorously\nevaluated across diverse 3D vision-language understanding tasks, including\nsemantic segmentation, object detection, instance segmentation, visual\ngrounding, 3D captioning, and text-3D cross-modal retrieval. It demonstrates\nperformance on par with or surpassing state-of-the-art (SOTA) task-specific\nmodels. We hope our benchmark and Uni3DL model will serve as a solid step to\nease future research in unified models in the realm of 3D and language\nunderstanding. Project page: https://uni3dl.github.io.",
            "author": [
                "Xiang Li",
                "Jian Ding",
                "Zhaoyang Chen",
                "Mohamed Elhoseiny"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03026v1",
                "http://arxiv.org/pdf/2312.03026v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03025v1",
            "title": "Training on Synthetic Data Beats Real Data in Multimodal Relation\n  Extraction",
            "updated": "2023-12-05T08:11:34Z",
            "published": "2023-12-05T08:11:34Z",
            "summary": "The task of multimodal relation extraction has attracted significant research\nattention, but progress is constrained by the scarcity of available training\ndata. One natural thought is to extend existing datasets with cross-modal\ngenerative models. In this paper, we consider a novel problem setting, where\nonly unimodal data, either text or image, are available during training. We aim\nto train a multimodal classifier from synthetic data that perform well on real\nmultimodal test data. However, training with synthetic data suffers from two\nobstacles: lack of data diversity and label information loss. To alleviate the\nissues, we propose Mutual Information-aware Multimodal Iterated Relational dAta\nGEneration (MI2RAGE), which applies Chained Cross-modal Generation (CCG) to\npromote diversity in the generated data and exploits a teacher network to\nselect valuable training samples with high mutual information with the\nground-truth labels. Comparing our method to direct training on synthetic data,\nwe observed a significant improvement of 24.06% F1 with synthetic text and\n26.42% F1 with synthetic images. Notably, our best model trained on completely\nsynthetic images outperforms prior state-of-the-art models trained on real\nmultimodal data by a margin of 3.76% in F1. Our codebase will be made available\nupon acceptance.",
            "author": [
                "Zilin Du",
                "Haoxin Li",
                "Xu Guo",
                "Boyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03025v1",
                "http://arxiv.org/pdf/2312.03025v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02561v1",
            "title": "DanZero+: Dominating the GuanDan Game through Reinforcement Learning",
            "updated": "2023-12-05T08:07:32Z",
            "published": "2023-12-05T08:07:32Z",
            "summary": "The utilization of artificial intelligence (AI) in card games has been a\nwell-explored subject within AI research for an extensive period. Recent\nadvancements have propelled AI programs to showcase expertise in intricate card\ngames such as Mahjong, DouDizhu, and Texas Hold'em. In this work, we aim to\ndevelop an AI program for an exceptionally complex and popular card game called\nGuanDan. This game involves four players engaging in both competitive and\ncooperative play throughout a long process to upgrade their level, posing great\nchallenges for AI due to its expansive state and action space, long episode\nlength, and complex rules. Employing reinforcement learning techniques,\nspecifically Deep Monte Carlo (DMC), and a distributed training framework, we\nfirst put forward an AI program named DanZero for this game. Evaluation against\nbaseline AI programs based on heuristic rules highlights the outstanding\nperformance of our bot. Besides, in order to further enhance the AI's\ncapabilities, we apply policy-based reinforcement learning algorithm to\nGuanDan. To address the challenges arising from the huge action space, which\nwill significantly impact the performance of policy-based algorithms, we adopt\nthe pre-trained model to facilitate the training process and the achieved AI\nprogram manages to achieve a superior performance.",
            "author": [
                "Youpeng Zhao",
                "Yudong Lu",
                "Jian Zhao",
                "Wengang Zhou",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02561v1",
                "http://arxiv.org/pdf/2312.02561v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02557v1",
            "title": "BOgen: Generating Part-Level 3D Designs Based on User Intention\n  Inference through Bayesian Optimization and Variational Autoencoder",
            "updated": "2023-12-05T07:55:19Z",
            "published": "2023-12-05T07:55:19Z",
            "summary": "Advancements in generative artificial intelligence (AI) have introduced\nvarious AI models capable of producing impressive visual design outputs.\nHowever, when it comes to AI models in the design process, prioritizing outputs\nthat align with designers' needs over mere visual craftsmanship becomes even\nmore crucial. Furthermore, designers often intricately combine parts of various\ndesigns to create novel designs. The ability to generate designs that align\nwith the designers' intentions at the part level is pivotal for assisting\ndesigners. Hence, we introduced BOgen, which empowers designers to proactively\ngenerate and explore part-level designs through Bayesian optimization and\nvariational autoencoders, thereby enhancing their overall user experience. We\nassessed BOgen's performance using a study involving 30 designers. The results\nrevealed that, compared to the baseline, BOgen fulfilled the designer\nrequirements for part recommendations and design exploration space guidance.\nBOgen assists designers in navigation and development, offering valuable design\nsuggestions and fosters proactive design exploration and creation.",
            "author": [
                "Seung Won Lee",
                "Jiin Choi",
                "Kyung Hoon Hyun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02557v1",
                "http://arxiv.org/pdf/2312.02557v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "H.5.2; I.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02554v1",
            "title": "ULMA: Unified Language Model Alignment with Demonstration and Point-wise\n  Human Preference",
            "updated": "2023-12-05T07:52:12Z",
            "published": "2023-12-05T07:52:12Z",
            "summary": "Language model alignment is a cutting-edge technique in large language model\ntraining to align the model output to user's intent, e.g., being helpful and\nharmless. Recent alignment framework consists of two steps: supervised\nfine-tuning with demonstration data and preference learning with human\npreference data. Previous preference learning methods, such as RLHF and DPO,\nmainly focus on pair-wise preference data. However, in many real-world\nscenarios where human feedbacks are intrinsically point-wise, these methods\nwill suffer from information loss or even fail. To fill this gap, in this\npaper, we first develop a preference learning method called point-wise DPO to\ntackle point-wise preference data. Further revelation on the connection between\nsupervised fine-tuning and point-wise preference learning enables us to develop\na unified framework for both human demonstration and point-wise preference\ndata, which sheds new light on the construction of preference dataset.\nExtensive experiments on point-wise datasets with binary or continuous labels\ndemonstrate the superior performance and efficiency of our proposed methods. A\nnew dataset with high-quality demonstration samples on harmlessness is\nconstructed and made publicly available.",
            "author": [
                "Tianchi Cai",
                "Xierui Song",
                "Jiyan Jiang",
                "Fei Teng",
                "Jinjie Gu",
                "Guannan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02554v1",
                "http://arxiv.org/pdf/2312.02554v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02551v1",
            "title": "Soft X-ray Energy Spectra in the Wide-Field Galactic Disk Area Revealed\n  with HaloSat",
            "updated": "2023-12-05T07:43:06Z",
            "published": "2023-12-05T07:43:06Z",
            "summary": "We analyzed data from HaloSat observations for five fields in the Galactic\ndisk located far away from the Galactic center (135$^{\\circ}$ $<$ $l$ $<$\n254$^{\\circ}$) to understand the nature of soft X-ray energy emission in the\nGalactic disk. The fields have 14$^{\\circ}$ diameter and were selected to\ncontain no significant high-flux X-ray sources. All five HaloSat soft X-ray\nenergy spectra (0.4--7 keV with energy resolution of $<$100 eV below 1 keV)\nshow a possibility of the presence of unresolved high-temperature plasma in the\nGalactic disk (UHTPGD) with a temperature of 0.8--1.0 keV and an emission\nmeasure of (8--11)$\\times10^{-4} \\rm cm^{-6} pc$ in addition to the soft X-ray\ndiffuse background components mainly studied at higher galactic latitudes\n(solar wind charge exchange emission, local hot bubble, Milky Way halo\nemission, and the cosmic X-ray background). This suggests that the UHTPGD is\npresent across the whole Galactic disk. We also observed UHTPGD emission in a\nregion with no bright sources in an {\\it XMM-Newton} field contained within one\nof the {\\it HaloSat} fields. The temperature and emission measure are\nconsistent with those measured with {\\it HaloSat}. Moreover, the stacked\nspectra of the X-ray point-like sources and NIR-identified point sources such\nas stars in the {\\it XMM-Newton} field also show a spectral feature similar to\nthe UHTPGD emission. This suggests that the UHTPGD may partly originate from\npoint-like sources such as stars.",
            "author": [
                "Kazuki Ampuku",
                "Ikuyuki Mitsuishi",
                "Koki Sakuta",
                "Philip Kaaret",
                "Daniel M. LaRocca",
                "Lorella Angelini"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02551v1",
                "http://arxiv.org/pdf/2312.02551v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02549v1",
            "title": "DemaFormer: Damped Exponential Moving Average Transformer with\n  Energy-Based Modeling for Temporal Language Grounding",
            "updated": "2023-12-05T07:37:21Z",
            "published": "2023-12-05T07:37:21Z",
            "summary": "Temporal Language Grounding seeks to localize video moments that semantically\ncorrespond to a natural language query. Recent advances employ the attention\nmechanism to learn the relations between video moments and the text query.\nHowever, naive attention might not be able to appropriately capture such\nrelations, resulting in ineffective distributions where target video moments\nare difficult to separate from the remaining ones. To resolve the issue, we\npropose an energy-based model framework to explicitly learn moment-query\ndistributions. Moreover, we propose DemaFormer, a novel Transformer-based\narchitecture that utilizes exponential moving average with a learnable damping\nfactor to effectively encode moment-query inputs. Comprehensive experiments on\nfour public temporal language grounding datasets showcase the superiority of\nour methods over the state-of-the-art baselines.",
            "author": [
                "Thong Nguyen",
                "Xiaobao Wu",
                "Xinshuai Dong",
                "Cong-Duy Nguyen",
                "See-Kiong Ng",
                "Luu Anh Tuan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02549v1",
                "http://arxiv.org/pdf/2312.02549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02548v1",
            "title": "GeNIe: Generative Hard Negative Images Through Diffusion",
            "updated": "2023-12-05T07:34:30Z",
            "published": "2023-12-05T07:34:30Z",
            "summary": "Data augmentation is crucial in training deep models, preventing them from\noverfitting to limited data. Common data augmentation methods are effective,\nbut recent advancements in generative AI, such as diffusion models for image\ngeneration, enable more sophisticated augmentation techniques that produce data\nresembling natural images. We recognize that augmented samples closer to the\nideal decision boundary of a classifier are particularly effective and\nefficient in guiding the learning process. We introduce GeNIe which leverages a\ndiffusion model conditioned on a text prompt to merge contrasting data points\n(an image from the source category and a text prompt from the target category)\nto generate challenging samples for the target category. Inspired by recent\nimage editing methods, we limit the number of diffusion iterations and the\namount of noise. This ensures that the generated image retains low-level and\ncontextual features from the source image, potentially conflicting with the\ntarget category. Our extensive experiments, in few-shot and also long-tail\ndistribution settings, demonstrate the effectiveness of our novel augmentation\nmethod, especially benefiting categories with a limited number of examples.",
            "author": [
                "Soroush Abbasi Koohpayegani",
                "Anuj Singh",
                "K L Navaneet",
                "Hadi Jamali-Rad",
                "Hamed Pirsiavash"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02548v1",
                "http://arxiv.org/pdf/2312.02548v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02546v1",
            "title": "Machine Vision Therapy: Multimodal Large Language Models Can Enhance\n  Visual Robustness via Denoising In-Context Learning",
            "updated": "2023-12-05T07:29:14Z",
            "published": "2023-12-05T07:29:14Z",
            "summary": "Although vision models such as Contrastive Language-Image Pre-Training (CLIP)\nshow impressive generalization performance, their zero-shot robustness is still\nlimited under Out-of-Distribution (OOD) scenarios without fine-tuning. Instead\nof undesirably providing human supervision as commonly done, it is possible to\ntake advantage of Multi-modal Large Language Models (MLLMs) that hold powerful\nvisual understanding abilities. However, MLLMs are shown to struggle with\nvision problems due to the incompatibility of tasks, thus hindering their\nutilization. In this paper, we propose to effectively leverage MLLMs to conduct\nMachine Vision Therapy which aims to rectify the noisy predictions from vision\nmodels. By fine-tuning with the denoised labels, the learning model performance\ncan be boosted in an unsupervised manner. To solve the incompatibility issue,\nwe propose a novel Denoising In-Context Learning (DICL) strategy to align\nvision tasks with MLLMs. Concretely, by estimating a transition matrix that\ncaptures the probability of one class being confused with another, an\ninstruction containing a correct exemplar and an erroneous one from the most\nprobable noisy class can be constructed. Such an instruction can help any MLLMs\nwith ICL ability to detect and rectify incorrect predictions of vision models.\nThrough extensive experiments on ImageNet, WILDS, DomainBed, and other OOD\ndatasets, we carefully validate the quantitative and qualitative effectiveness\nof our method. Our code is available at\nhttps://github.com/tmllab/Machine_Vision_Therapy.",
            "author": [
                "Zhuo Huang",
                "Chang Liu",
                "Yinpeng Dong",
                "Hang Su",
                "Shibao Zheng",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02546v1",
                "http://arxiv.org/pdf/2312.02546v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03022v1",
            "title": "Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph\n  Construction",
            "updated": "2023-12-05T07:27:08Z",
            "published": "2023-12-05T07:27:08Z",
            "summary": "Knowledge graph construction (KGC) is a multifaceted undertaking involving\nthe extraction of entities, relations, and events. Traditionally, large\nlanguage models (LLMs) have been viewed as solitary task-solving agents in this\ncomplex landscape. However, this paper challenges this paradigm by introducing\na novel framework, CooperKGC. Departing from the conventional approach,\nCooperKGC establishes a collaborative processing network, assembling a KGC\ncollaboration team capable of concurrently addressing entity, relation, and\nevent extraction tasks. Our experiments unequivocally demonstrate that\nfostering collaboration and information interaction among diverse agents within\nCooperKGC yields superior results compared to individual cognitive processes\noperating in isolation. Importantly, our findings reveal that the collaboration\nfacilitated by CooperKGC enhances knowledge selection, correction, and\naggregation capabilities across multiple rounds of interactions.",
            "author": [
                "Hongbin Ye",
                "Honghao Gui",
                "Aijia Zhang",
                "Tong Liu",
                "Wei Hua",
                "Weiqiang Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03022v1",
                "http://arxiv.org/pdf/2312.03022v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02541v1",
            "title": "Explainable Severity ranking via pairwise n-hidden comparison: a case\n  study of glaucoma",
            "updated": "2023-12-05T07:12:05Z",
            "published": "2023-12-05T07:12:05Z",
            "summary": "Primary open-angle glaucoma (POAG) is a chronic and progressive optic nerve\ncondition that results in an acquired loss of optic nerve fibers and potential\nblindness. The gradual onset of glaucoma results in patients progressively\nlosing their vision without being consciously aware of the changes. To diagnose\nPOAG and determine its severity, patients must undergo a comprehensive dilated\neye examination. In this work, we build a framework to rank, compare, and\ninterpret the severity of glaucoma using fundus images. We introduce a\nsiamese-based severity ranking using pairwise n-hidden comparisons. We\nadditionally have a novel approach to explaining why a specific image is deemed\nmore severe than others. Our findings indicate that the proposed severity\nranking model surpasses traditional ones in terms of diagnostic accuracy and\ndelivers improved saliency explanations.",
            "author": [
                "Hong Nguyen",
                "Cuong V. Nguyen",
                "Shrikanth Narayanan",
                "Benjamin Y. Xu",
                "Michael Pazzani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02541v1",
                "http://arxiv.org/pdf/2312.02541v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02538v1",
            "title": "A Multi-Granularity-Aware Aspect Learning Model for Multi-Aspect Dense\n  Retrieval",
            "updated": "2023-12-05T07:08:08Z",
            "published": "2023-12-05T07:08:08Z",
            "summary": "Dense retrieval methods have been mostly focused on unstructured text and\nless attention has been drawn to structured data with various aspects, e.g.,\nproducts with aspects such as category and brand. Recent work has proposed two\napproaches to incorporate the aspect information into item representations for\neffective retrieval by predicting the values associated with the item aspects.\nDespite their efficacy, they treat the values as isolated classes (e.g., \"Smart\nHomes\", \"Home, Garden & Tools\", and \"Beauty & Health\") and ignore their\nfine-grained semantic relation. Furthermore, they either enforce the learning\nof aspects into the CLS token, which could confuse it from its designated use\nfor representing the entire content semantics, or learn extra aspect embeddings\nonly with the value prediction objective, which could be insufficient\nespecially when there are no annotated values for an item aspect. Aware of\nthese limitations, we propose a MUlti-granulaRity-aware Aspect Learning model\n(MURAL) for multi-aspect dense retrieval. It leverages aspect information\nacross various granularities to capture both coarse and fine-grained semantic\nrelations between values. Moreover, MURAL incorporates separate aspect\nembeddings as input to transformer encoders so that the masked language model\nobjective can assist implicit aspect learning even without aspect-value\nannotations. Extensive experiments on two real-world datasets of products and\nmini-programs show that MURAL outperforms state-of-the-art baselines\nsignificantly.",
            "author": [
                "Xiaojie Sun",
                "Keping Bi",
                "Jiafeng Guo",
                "Sihui Yang",
                "Qishen Zhang",
                "Zhongyi Liu",
                "Guannan Zhang",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02538v1",
                "http://arxiv.org/pdf/2312.02538v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02537v1",
            "title": "Asymmetric leader-laggard cluster synchronization for collective\n  decision-making with laser network",
            "updated": "2023-12-05T07:04:21Z",
            "published": "2023-12-05T07:04:21Z",
            "summary": "Photonic accelerators have recently attracted soaring interest, harnessing\nthe ultimate nature of light for information processing. Collective\ndecision-making with a laser network, employing the chaotic and synchronous\ndynamics of optically interconnected lasers to address the competitive\nmulti-armed bandit (CMAB) problem, is a highly compelling approach due to its\nscalability and experimental feasibility. We investigated essential network\nstructures for collective decision-making through quantitative stability\nanalysis. Moreover, we demonstrated the asymmetric preferences of players in\nthe CMAB problem, extending its functionality to more practical applications.\nOur study highlights the capability and significance of machine learning built\nupon chaotic lasers and photonic devices.",
            "author": [
                "Shun Kotoku",
                "Takatomo Mihana",
                "Andr\u00e9 R\u00f6hm",
                "Ryoichi Horisaki",
                "Makoto Naruse"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02537v1",
                "http://arxiv.org/pdf/2312.02537v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.LG",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03020v1",
            "title": "Enhanced Breast Cancer Tumor Classification using MobileNetV2: A\n  Detailed Exploration on Image Intensity, Error Mitigation, and\n  Streamlit-driven Real-time Deployment",
            "updated": "2023-12-05T06:58:14Z",
            "published": "2023-12-05T06:58:14Z",
            "summary": "This research introduces a sophisticated transfer learning model based on\nGoogle's MobileNetV2 for breast cancer tumor classification into normal,\nbenign, and malignant categories, utilizing a dataset of 1576 ultrasound images\n(265 normal, 891 benign, 420 malignant). The model achieves an accuracy of\n0.82, precision of 0.83, recall of 0.81, ROC-AUC of 0.94, PR-AUC of 0.88, and\nMCC of 0.74. It examines image intensity distributions and misclassification\nerrors, offering improvements for future applications. Addressing dataset\nimbalances, the study ensures a generalizable model. This work, using a dataset\nfrom Baheya Hospital, Cairo, Egypt, compiled by Walid Al-Dhabyani et al.,\nemphasizes MobileNetV2's potential in medical imaging, aiming to improve\ndiagnostic precision in oncology. Additionally, the paper explores\nStreamlit-based deployment for real-time tumor classification, demonstrating\nMobileNetV2's applicability in medical imaging and setting a benchmark for\nfuture research in oncology diagnostics.",
            "author": [
                "Aaditya Surya",
                "Aditya Shah",
                "Jarnell Kabore",
                "Subash Sasikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03020v1",
                "http://arxiv.org/pdf/2312.03020v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02532v1",
            "title": "DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework",
            "updated": "2023-12-05T06:28:45Z",
            "published": "2023-12-05T06:28:45Z",
            "summary": "With the growing volume of diverse information, the demand for classifying\narbitrary topics has become increasingly critical. To address this challenge,\nwe introduce DRAFT, a simple framework designed to train a classifier for\nfew-shot topic classification. DRAFT uses a few examples of a specific topic as\nqueries to construct Customized dataset with a dense retriever model.\nMulti-query retrieval (MQR) algorithm, which effectively handles multiple\nqueries related to a specific topic, is applied to construct the Customized\ndataset. Subsequently, we fine-tune a classifier using the Customized dataset\nto identify the topic. To demonstrate the efficacy of our proposed approach, we\nconduct evaluations on both widely used classification benchmark datasets and\nmanually constructed datasets with 291 diverse topics, which simulate diverse\ncontents encountered in real-world applications. DRAFT shows competitive or\nsuperior performance compared to baselines that use in-context learning, such\nas GPT-3 175B and InstructGPT 175B, on few-shot topic classification tasks\ndespite having 177 times fewer parameters, demonstrating its effectiveness.",
            "author": [
                "Keonwoo Kim",
                "Younggun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02532v1",
                "http://arxiv.org/pdf/2312.02532v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02529v1",
            "title": "A study of photometric errors on two different photographic plate scans",
            "updated": "2023-12-05T06:24:30Z",
            "published": "2023-12-05T06:24:30Z",
            "summary": "A considerable number of photographic plate archives exist world wide and\ndigitization is in progress or already has been finished. Not only different\ntype of scanners were used but also spatial resolution and dynamic range often\nwere limited due to process duration and storage space. The open question is\nthe effect of these limitations on the results. 61 high resolution photographic\nplates of the Gamma Cyg field from the Bruce astrograph at Landessternwarte\nHeidelberg--K\\\"onigstuhl (aperture 40~cm, focal length 200~cm) had been\ndigitized both in Heidelberg and Sonneberg. Both scanners were set to 16 bit\ndynamic range. The Heidelberg scanner was operated at 2540 dpi resolution,\nresulting in a scale of 1 arcsec/pixel, while the Sonneberg scanner was\noperated at 1200 dpi, yielding a scale of 2.1 arsec/pixel.\n  In the presented study the standard deviation of non--variable star light\ncurves were examined in dependence of brightness and plate coordinates in both\nseries. No evident differences could be found. A comparison of the analysis of\nboth scan series will be presented.",
            "author": [
                "M. Spasovic",
                "C. Dersch",
                "A. Schrimpf",
                "P. Kroll"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02529v1",
                "http://arxiv.org/pdf/2312.02529v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02520v1",
            "title": "Towards More Unified In-context Visual Understanding",
            "updated": "2023-12-05T06:02:21Z",
            "published": "2023-12-05T06:02:21Z",
            "summary": "The rapid advancement of large language models (LLMs) has accelerated the\nemergence of in-context learning (ICL) as a cutting-edge approach in the\nnatural language processing domain. Recently, ICL has been employed in visual\nunderstanding tasks, such as semantic segmentation and image captioning,\nyielding promising results. However, existing visual ICL framework can not\nenable producing content across multiple modalities, which limits their\npotential usage scenarios. To address this issue, we present a new ICL\nframework for visual understanding with multi-modal output enabled. First, we\nquantize and embed both text and visual prompt into a unified representational\nspace, structured as interleaved in-context sequences. Then a decoder-only\nsparse transformer architecture is employed to perform generative modeling on\nthem, facilitating in-context learning. Thanks to this design, the model is\ncapable of handling in-context vision understanding tasks with multimodal\noutput in a unified pipeline. Experimental results demonstrate that our model\nachieves competitive performance compared with specialized models and previous\nICL baselines. Overall, our research takes a further step toward unified\nmultimodal in-context learning.",
            "author": [
                "Dianmo Sheng",
                "Dongdong Chen",
                "Zhentao Tan",
                "Qiankun Liu",
                "Qi Chu",
                "Jianmin Bao",
                "Tao Gong",
                "Bin Liu",
                "Shengwei Xu",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02520v1",
                "http://arxiv.org/pdf/2312.02520v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02519v1",
            "title": "Creative Agents: Empowering Agents with Imagination for Creative Tasks",
            "updated": "2023-12-05T06:00:52Z",
            "published": "2023-12-05T06:00:52Z",
            "summary": "We study building embodied agents for open-ended creative tasks. While\nexisting methods build instruction-following agents that can perform diverse\nopen-ended tasks, none of them demonstrates creativity -- the ability to give\nnovel and diverse task solutions implicit in the language instructions. This\nlimitation comes from their inability to convert abstract language instructions\ninto concrete task goals in the environment and perform long-horizon planning\nfor such complicated goals. Given the observation that humans perform creative\ntasks with the help of imagination, we propose a class of solutions for\ncreative agents, where the controller is enhanced with an imaginator that\ngenerates detailed imaginations of task outcomes conditioned on language\ninstructions. We introduce several approaches to implementing the components of\ncreative agents. We implement the imaginator with either a large language model\nfor textual imagination or a diffusion model for visual imagination. The\ncontroller can either be a behavior-cloning policy learned from data or a\npre-trained foundation model generating executable codes in the environment. We\nbenchmark creative tasks with the challenging open-world game Minecraft, where\nthe agents are asked to create diverse buildings given free-form language\ninstructions. In addition, we propose novel evaluation metrics for open-ended\ncreative tasks utilizing GPT-4V, which holds many advantages over existing\nmetrics. We perform a detailed experimental analysis of creative agents,\nshowing that creative agents are the first AI agents accomplishing diverse\nbuilding creation in the survival mode of Minecraft. Our benchmark and models\nare open-source for future research on creative agents\n(https://github.com/PKU-RL/Creative-Agents).",
            "author": [
                "Chi Zhang",
                "Penglin Cai",
                "Yuhui Fu",
                "Haoqi Yuan",
                "Zongqing Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02519v1",
                "http://arxiv.org/pdf/2312.02519v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02515v1",
            "title": "ASPEN: High-Throughput LoRA Fine-Tuning of Large Language Models with a\n  Single GPU",
            "updated": "2023-12-05T05:38:38Z",
            "published": "2023-12-05T05:38:38Z",
            "summary": "Transformer-based large language models (LLMs) have demonstrated outstanding\nperformance across diverse domains, particularly when fine-turned for specific\ndomains. Recent studies suggest that the resources required for fine-tuning\nLLMs can be economized through parameter-efficient methods such as Low-Rank\nAdaptation (LoRA). While LoRA effectively reduces computational burdens and\nresource demands, it currently supports only a single-job fine-tuning setup.\n  In this paper, we present ASPEN, a high-throughput framework for fine-tuning\nLLMs. ASPEN efficiently trains multiple jobs on a single GPU using the LoRA\nmethod, leveraging shared pre-trained model and adaptive scheduling. ASPEN is\ncompatible with transformer-based language models like LLaMA and ChatGLM, etc.\nExperiments show that ASPEN saves 53% of GPU memory when training multiple\nLLaMA-7B models on NVIDIA A100 80GB GPU and boosts training throughput by about\n17% compared to existing methods when training with various pre-trained models\non different GPUs. The adaptive scheduling algorithm reduces turnaround time by\n24%, end-to-end training latency by 12%, prioritizing jobs and preventing\nout-of-memory issues.",
            "author": [
                "Zhengmao Ye",
                "Dengchun Li",
                "Jingqi Tian",
                "Tingfeng Lan",
                "Jie Zuo",
                "Lei Duan",
                "Hui Lu",
                "Yexi Jiang",
                "Jian Sha",
                "Ke Zhang",
                "Mingjie Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02515v1",
                "http://arxiv.org/pdf/2312.02515v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02512v1",
            "title": "AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation\n  with Unified Audio-Visual Speech Representation",
            "updated": "2023-12-05T05:36:44Z",
            "published": "2023-12-05T05:36:44Z",
            "summary": "This paper proposes a novel direct Audio-Visual Speech to Audio-Visual Speech\nTranslation (AV2AV) framework, where the input and output of the system are\nmultimodal (i.e., audio and visual speech). With the proposed AV2AV, two key\nadvantages can be brought: 1) We can perform real-like conversations with\nindividuals worldwide in a virtual meeting by utilizing our own primary\nlanguages. In contrast to Speech-to-Speech Translation (A2A), which solely\ntranslates between audio modalities, the proposed AV2AV directly translates\nbetween audio-visual speech. This capability enhances the dialogue experience\nby presenting synchronized lip movements along with the translated speech. 2)\nWe can improve the robustness of the spoken language translation system. By\nemploying the complementary information of audio-visual speech, the system can\neffectively translate spoken language even in the presence of acoustic noise,\nshowcasing robust performance. To mitigate the problem of the absence of a\nparallel AV2AV translation dataset, we propose to train our spoken language\ntranslation system with the audio-only dataset of A2A. This is done by learning\nunified audio-visual speech representations through self-supervised learning in\nadvance to train the translation system. Moreover, we propose an AV-Renderer\nthat can generate raw audio and video in parallel. It is designed with\nzero-shot speaker modeling, thus the speaker in source audio-visual speech can\nbe maintained at the target translated audio-visual speech. The effectiveness\nof AV2AV is evaluated with extensive experiments in a many-to-many language\ntranslation setting. The demo page is available on\nhttps://choijeongsoo.github.io/av2av.",
            "author": [
                "Jeongsoo Choi",
                "Se Jin Park",
                "Minsu Kim",
                "Yong Man Ro"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02512v1",
                "http://arxiv.org/pdf/2312.02512v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02503v1",
            "title": "SAVE: Protagonist Diversification with Structure Agnostic Video Editing",
            "updated": "2023-12-05T05:13:20Z",
            "published": "2023-12-05T05:13:20Z",
            "summary": "Driven by the upsurge progress in text-to-image (T2I) generation models,\ntext-to-video (T2V) generation has experienced a significant advance as well.\nAccordingly, tasks such as modifying the object or changing the style in a\nvideo have been possible. However, previous works usually work well on trivial\nand consistent shapes, and easily collapse on a difficult target that has a\nlargely different body shape from the original one. In this paper, we spot the\nbias problem in the existing video editing method that restricts the range of\nchoices for the new protagonist and attempt to address this issue using the\nconventional image-level personalization method. We adopt motion\npersonalization that isolates the motion from a single source video and then\nmodifies the protagonist accordingly. To deal with the natural discrepancy\nbetween image and video, we propose a motion word with an inflated textual\nembedding to properly represent the motion in a source video. We also regulate\nthe motion word to attend to proper motion-related areas by introducing a novel\npseudo optical flow, efficiently computed from the pre-calculated attention\nmaps. Finally, we decouple the motion from the appearance of the source video\nwith an additional pseudo word. Extensive experiments demonstrate the editing\ncapability of our method, taking a step toward more diverse and extensive video\nediting.",
            "author": [
                "Yeji Song",
                "Wonsik Shin",
                "Junsoo Lee",
                "Jeesoo Kim",
                "Nojun Kwak"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02503v1",
                "http://arxiv.org/pdf/2312.02503v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02496v1",
            "title": "MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative\n  Models on Medical Conversation Tasks",
            "updated": "2023-12-05T04:55:54Z",
            "published": "2023-12-05T04:55:54Z",
            "summary": "Using natural language processing (NLP) technologies to develop medical\nchatbots makes the diagnosis of the patient more convenient and efficient,\nwhich is a typical application in healthcare AI. Because of its importance,\nlots of research have been come out. Recently, the neural generative models\nhave shown their impressive ability as the core of chatbot, while it cannot\nscale well when directly applied to medical conversation due to the lack of\nmedical-specific knowledge. To address the limitation, a scalable Medical\nKnowledge Assisted mechanism, MKA, is proposed in this paper. The mechanism\naims to assist general neural generative models to achieve better performance\non the medical conversation task. The medical-specific knowledge graph is\ndesigned within the mechanism, which contains 6 types of medical-related\ninformation, including department, drug, check, symptom, disease, food.\nBesides, the specific token concatenation policy is defined to effectively\ninject medical information into the input data. Evaluation of our method is\ncarried out on two typical medical datasets, MedDG and MedDialog-CN. The\nevaluation results demonstrate that models combined with our mechanism\noutperform original methods in multiple automatic evaluation metrics. Besides,\nMKA-Bert-GPT achieves state-of-the-art performance. The open-sourced codes are\npublic:\nhttps://github.com/LIANGKE23/Knowledge_Assisted_Medical_Dialogue_Generation_Mechanism",
            "author": [
                "Ke Liang",
                "Sifan Wu",
                "Jiayi Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02496v1",
                "http://arxiv.org/pdf/2312.02496v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02494v1",
            "title": "ReconU-Net: a direct PET image reconstruction using U-Net architecture\n  with back projection-induced skip connection",
            "updated": "2023-12-05T04:51:42Z",
            "published": "2023-12-05T04:51:42Z",
            "summary": "[Objective] This study aims to introduce a novel back projection-induced\nU-Net-shaped architecture, called ReconU-Net, for deep learning-based direct\npositron emission tomography (PET) image reconstruction. Additionally, our\nobjective is to analyze the behavior of direct PET image reconstruction and\ngain deeper insights by comparing the proposed ReconU-Net architecture with\nother encoder-decoder architectures without skip connections. [Approach] The\nproposed ReconU-Net architecture uniquely integrates the physical model of the\nback projection operation into the skip connection. This distinctive feature\nfacilitates the effective transfer of intrinsic spatial information from the\ninput sinogram to the reconstructed image via an embedded physical model. The\nproposed ReconU-Net was trained using Monte Carlo simulation data from the\nBrainweb phantom and tested on both simulated and real Hoffman brain phantom\ndata. [Main results] The proposed ReconU-Net method generated a reconstructed\nimage with a more accurate structure compared to other deep learning-based\ndirect reconstruction methods. Further analysis showed that the proposed\nReconU-Net architecture has the ability to transfer features of multiple\nresolutions, especially non-abstract high-resolution information, through skip\nconnections. Despite limited training on simulated data, the proposed\nReconU-Net successfully reconstructed the real Hoffman brain phantom, unlike\nother deep learning-based direct reconstruction methods, which failed to\nproduce a reconstructed image. [Significance] The proposed ReconU-Net can\nimprove the fidelity of direct PET image reconstruction, even when dealing with\nsmall training datasets, by leveraging the synergistic relationship between\ndata-driven modeling and the physics model of the imaging process.",
            "author": [
                "Fumio Hashimoto",
                "Kibo Ote"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02494v1",
                "http://arxiv.org/pdf/2312.02494v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02491v1",
            "title": "Pseudo Replay-based Class Continual Learning for Online New Category\n  Anomaly Detection in Additive Manufacturing",
            "updated": "2023-12-05T04:43:23Z",
            "published": "2023-12-05T04:43:23Z",
            "summary": "The incorporation of advanced sensors and machine learning techniques has\nenabled modern manufacturing enterprises to perform data-driven in-situ quality\nmonitoring based on the sensor data collected in manufacturing processes.\nHowever, one critical challenge is that newly presented defect category may\nmanifest as the manufacturing process continues, resulting in monitoring\nperformance deterioration of previously trained machine learning models. Hence,\nthere is an increasing need for empowering machine learning model to learn\ncontinually. Among all continual learning methods, memory-based continual\nlearning has the best performance but faces the constraints of data storage\ncapacity. To address this issue, this paper develops a novel pseudo\nreplay-based continual learning by integrating class incremental learning and\noversampling-based data generation. Without storing all the data, the developed\nframework could generate high-quality data representing previous classes to\ntrain machine learning model incrementally when new category anomaly occurs. In\naddition, it could even enhance the monitoring performance since it also\neffectively improves the data quality. The effectiveness of the proposed\nframework is validated in an additive manufacturing process, which leverages\nsupervised classification problem for anomaly detection. The experimental\nresults show that the developed method is very promising in detecting novel\nanomaly while maintaining a good performance on the previous task and brings up\nmore flexibility in model architecture.",
            "author": [
                "Zhangyue Shi",
                "Tianxin Xie",
                "Chenang Liu",
                "Yuxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02491v1",
                "http://arxiv.org/pdf/2312.02491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02487v1",
            "title": "Metasurface Sensing Approach to DOA Estimation of Coherent Signals",
            "updated": "2023-12-05T04:30:05Z",
            "published": "2023-12-05T04:30:05Z",
            "summary": "The DOA estimation method of coherent signals based on periodical coding\nmetasurface is proposed. After periodical coding, the DOA information of\nincident signals in the time domain is represented as the amplitude and phase\ninformation at different frequency points in the frequency domain. Finite time\nFourier transform (FTFT) is performed on the received signal and appropriate\nfrequency points are selected to reconstruct the frequency domain snapshot,\nthen pattern smoothing (PS) technique is applied to execute DOA estimation.\nCompared with conventional DOA estimation methods, the proposed method has two\nmain advantages: one is that only a single receiving channel is needed to avoid\nthe appearance of channel mismatch errors, the other is that it can process\nwith multiple coherent signals. The performance curves of the proposed method\nare analyzed under different conditions and compared with existing methods.\nSimulation results show the effectiveness of the proposed method.",
            "author": [
                "Yishuo Zhao",
                "Yan Hu",
                "Yougen Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02487v1",
                "http://arxiv.org/pdf/2312.02487v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02483v1",
            "title": "EtC: Temporal Boundary Expand then Clarify for Weakly Supervised Video\n  Grounding with Multimodal Large Language Model",
            "updated": "2023-12-05T04:15:56Z",
            "published": "2023-12-05T04:15:56Z",
            "summary": "Early weakly supervised video grounding (WSVG) methods often struggle with\nincomplete boundary detection due to the absence of temporal boundary\nannotations. To bridge the gap between video-level and boundary-level\nannotation, explicit-supervision methods, i.e., generating pseudo-temporal\nboundaries for training, have achieved great success. However, data\naugmentations in these methods might disrupt critical temporal information,\nyielding poor pseudo boundaries. In this paper, we propose a new perspective\nthat maintains the integrity of the original temporal content while introducing\nmore valuable information for expanding the incomplete boundaries. To this end,\nwe propose EtC (Expand then Clarify), first use the additional information to\nexpand the initial incomplete pseudo boundaries, and subsequently refine these\nexpanded ones to achieve precise boundaries. Motivated by video continuity,\ni.e., visual similarity across adjacent frames, we use powerful multimodal\nlarge language models (MLLMs) to annotate each frame within initial pseudo\nboundaries, yielding more comprehensive descriptions for expanded boundaries.\nTo further clarify the noise of expanded boundaries, we combine mutual learning\nwith a tailored proposal-level contrastive objective to use a learnable\napproach to harmonize a balance between incomplete yet clean (initial) and\ncomprehensive yet noisy (expanded) boundaries for more precise ones.\nExperiments demonstrate the superiority of our method on two challenging WSVG\ndatasets.",
            "author": [
                "Guozhang Li",
                "Xinpeng Ding",
                "De Cheng",
                "Jie Li",
                "Nannan Wang",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02483v1",
                "http://arxiv.org/pdf/2312.02483v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02480v1",
            "title": "Differentiable Point-based Inverse Rendering",
            "updated": "2023-12-05T04:13:31Z",
            "published": "2023-12-05T04:13:31Z",
            "summary": "We present differentiable point-based inverse rendering, DPIR, an\nanalysis-by-synthesis method that processes images captured under diverse\nilluminations to estimate shape and spatially-varying BRDF. To this end, we\nadopt point-based rendering, eliminating the need for multiple samplings per\nray, typical of volumetric rendering, thus significantly enhancing the speed of\ninverse rendering. To realize this idea, we devise a hybrid point-volumetric\nrepresentation for geometry and a regularized basis-BRDF representation for\nreflectance. The hybrid geometric representation enables fast rendering through\npoint-based splatting while retaining the geometric details and stability\ninherent to SDF-based representations. The regularized basis-BRDF mitigates the\nill-posedness of inverse rendering stemming from limited light-view angular\nsamples. We also propose an efficient shadow detection method using point-based\nshadow map rendering. Our extensive evaluations demonstrate that DPIR\noutperforms prior works in terms of reconstruction accuracy, computational\nefficiency, and memory footprint. Furthermore, our explicit point-based\nrepresentation and rendering enables intuitive geometry and reflectance\nediting. The code will be publicly available.",
            "author": [
                "Hoon-Gyu Chung",
                "Seokjun Choi",
                "Seung-Hwan Baek"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02480v1",
                "http://arxiv.org/pdf/2312.02480v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02473v1",
            "title": "NeutronStream: A Dynamic GNN Training Framework with Sliding Window for\n  Graph Streams",
            "updated": "2023-12-05T03:58:05Z",
            "published": "2023-12-05T03:58:05Z",
            "summary": "Existing Graph Neural Network (GNN) training frameworks have been designed to\nhelp developers easily create performant GNN implementations. However, most\nexisting GNN frameworks assume that the input graphs are static, but ignore\nthat most real-world graphs are constantly evolving. Though many dynamic GNN\nmodels have emerged to learn from evolving graphs, the training process of\nthese dynamic GNNs is dramatically different from traditional GNNs in that it\ncaptures both the spatial and temporal dependencies of graph updates. This\nposes new challenges for designing dynamic GNN training frameworks. First, the\ntraditional batched training method fails to capture real-time structural\nevolution information. Second, the time-dependent nature makes parallel\ntraining hard to design. Third, it lacks system supports for users to\nefficiently implement dynamic GNNs. In this paper, we present NeutronStream, a\nframework for training dynamic GNN models. NeutronStream abstracts the input\ndynamic graph into a chronologically updated stream of events and processes the\nstream with an optimized sliding window to incrementally capture the\nspatial-temporal dependencies of events. Furthermore, NeutronStream provides a\nparallel execution engine to tackle the sequential event processing challenge\nto achieve high performance. NeutronStream also integrates a built-in graph\nstorage structure that supports dynamic updates and provides a set of\neasy-to-use APIs that allow users to express their dynamic GNNs. Our\nexperimental results demonstrate that, compared to state-of-the-art dynamic GNN\nimplementations, NeutronStream achieves speedups ranging from 1.48X to 5.87X\nand an average accuracy improvement of 3.97%.",
            "author": [
                "Chaoyi Chen",
                "Dechao Gao",
                "Yanfeng Zhang",
                "Qiange Wang",
                "Zhenbo Fu",
                "Xuecang Zhang",
                "Junhua Zhu",
                "Yu Gu",
                "Ge Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02473v1",
                "http://arxiv.org/pdf/2312.02473v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02471v1",
            "title": "Congestion-aware Distributed Task Offloading in Wireless Multi-hop\n  Networks Using Graph Neural Networks",
            "updated": "2023-12-05T03:46:30Z",
            "published": "2023-12-05T03:46:30Z",
            "summary": "Computational offloading has become an enabling component for edge\nintelligence in mobile and smart devices. Existing offloading schemes mainly\nfocus on mobile devices and servers, while ignoring the potential network\ncongestion caused by tasks from multiple mobile devices, especially in wireless\nmulti-hop networks. To fill this gap, we propose a low-overhead,\ncongestion-aware distributed task offloading scheme by augmenting a distributed\ngreedy framework with graph-based machine learning. In simulated wireless\nmulti-hop networks with 20-110 nodes and a resource allocation scheme based on\nshortest path routing and contention-based link scheduling, our approach is\ndemonstrated to be effective in reducing congestion or unstable queues under\nthe context-agnostic baseline, while improving the execution latency over local\ncomputing.",
            "author": [
                "Zhongyuan Zhao",
                "Jake Perazzone",
                "Gunjan Verma",
                "Santiago Segarra"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02471v1",
                "http://arxiv.org/pdf/2312.02471v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "eess.SP",
                "05C90",
                "C.2.1; C.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02470v1",
            "title": "Generator Born from Classifier",
            "updated": "2023-12-05T03:41:17Z",
            "published": "2023-12-05T03:41:17Z",
            "summary": "In this paper, we make a bold attempt toward an ambitious task: given a\npre-trained classifier, we aim to reconstruct an image generator, without\nrelying on any data samples. From a black-box perspective, this challenge seems\nintractable, since it inevitably involves identifying the inverse function for\na classifier, which is, by nature, an information extraction process. As such,\nwe resort to leveraging the knowledge encapsulated within the parameters of the\nneural network. Grounded on the theory of Maximum-Margin Bias of gradient\ndescent, we propose a novel learning paradigm, in which the generator is\ntrained to ensure that the convergence conditions of the network parameters are\nsatisfied over the generated distribution of the samples. Empirical validation\nfrom various image generation tasks substantiates the efficacy of our strategy.",
            "author": [
                "Runpeng Yu",
                "Xinchao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02470v1",
                "http://arxiv.org/pdf/2312.02470v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02463v1",
            "title": "Pairwise annihilation of Weyl nodes by magnetic fields in the Hofstadter\n  regime",
            "updated": "2023-12-05T03:28:37Z",
            "published": "2023-12-05T03:28:37Z",
            "summary": "Weyl semimetal, which does not require any symmetry except translation for\nprotection, is a robust gapless state of quantum matters in three dimensions.\nWhen translation symmetry is preserved, the only way to destroy a Weyl\nsemimetal state is to bring two Weyl nodes of opposite chirality close to each\nother to annihilate pairwise. An external magnetic field can destroy a pair of\nWeyl nodes (which are separated by a momentum space distance $2k_0$) of\nopposite chirality, when the magnetic length $l_B$ becomes close to or smaller\nthan the inverse separation $1/2k_0$. In this work, we investigate pairwise\nannihilation of Weyl nodes by external magnetic field which ranges all the way\nfrom small to a very large value in the Hofstadter regime $l_B \\sim a$. We show\nthat this pairwise annihilation in a WSM featuring two Weyl nodes leads to the\nemergence of either a normal insulator or a layered Chern insulator. In the\ncase of a Weyl semimetal with multiple Weyl nodes, the potential for generating\na variety of states through external magnetic fields emerges. Our study\nintroduces a straightforward and intuitive representation of the pairwise\nannihilation process induced by magnetic fields, enabling accurate predictions\nof the phases that may appear after pairwise annihilation of Weyl nodes.",
            "author": [
                "Faruk Abdulla"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02463v1",
                "http://arxiv.org/pdf/2312.02463v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03018v1",
            "title": "DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention\n  and Text Guidance",
            "updated": "2023-12-05T03:16:31Z",
            "published": "2023-12-05T03:16:31Z",
            "summary": "Image-to-video generation, which aims to generate a video starting from a\ngiven reference image, has drawn great attention. Existing methods try to\nextend pre-trained text-guided image diffusion models to image-guided video\ngeneration models. Nevertheless, these methods often result in either low\nfidelity or flickering over time due to their limitation to shallow image\nguidance and poor temporal consistency. To tackle these problems, we propose a\nhigh-fidelity image-to-video generation method by devising a frame retention\nbranch on the basis of a pre-trained video diffusion model, named DreamVideo.\nInstead of integrating the reference image into the diffusion process in a\nsemantic level, our DreamVideo perceives the reference image via convolution\nlayers and concatenate the features with the noisy latents as model input. By\nthis means, the details of the reference image can be preserved to the greatest\nextent. In addition, by incorporating double-condition classifier-free\nguidance, a single image can be directed to videos of different actions by\nproviding varying prompt texts. This has significant implications for\ncontrollable video generation and holds broad application prospects. We conduct\ncomprehensive experiments on the public dataset, both quantitative and\nqualitative results indicate that our method outperforms the state-of-the-art\nmethod. Especially for fidelity, our model has powerful image retention ability\nand result in high FVD in UCF101 compared to other image-to-video models. Also,\nprecise control can be achieved by giving different text prompts. Further\ndetails and comprehensive results of our model will be presented in\nhttps://anonymous0769.github.io/DreamVideo/.",
            "author": [
                "Cong Wang",
                "Jiaxi Gu",
                "Panwen Hu",
                "Songcen Xu",
                "Hang Xu",
                "Xiaodan Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03018v1",
                "http://arxiv.org/pdf/2312.03018v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02456v1",
            "title": "Watermarking for Neural Radiation Fields by Invertible Neural Network",
            "updated": "2023-12-05T03:14:44Z",
            "published": "2023-12-05T03:14:44Z",
            "summary": "To protect the copyright of the 3D scene represented by the neural radiation\nfield, the embedding and extraction of the neural radiation field watermark are\nconsidered as a pair of inverse problems of image transformations. A scheme for\nprotecting the copyright of the neural radiation field is proposed using\ninvertible neural network watermarking, which utilizes watermarking techniques\nfor 2D images to achieve the protection of the 3D scene. The scheme embeds the\nwatermark in the training image of the neural radiation field through the\nforward process in the invertible network and extracts the watermark from the\nimage rendered by the neural radiation field using the inverse process to\nrealize the copyright protection of both the neural radiation field and the 3D\nscene. Since the rendering process of the neural radiation field can cause the\nloss of watermark information, the scheme incorporates an image quality\nenhancement module, which utilizes a neural network to recover the rendered\nimage and then extracts the watermark. The scheme embeds a watermark in each\ntraining image to train the neural radiation field and enables the extraction\nof watermark information from multiple viewpoints. Simulation experimental\nresults demonstrate the effectiveness of the method.",
            "author": [
                "Wenquan Sun",
                "Jia Liu",
                "Weina Dong",
                "Lifeng Chen",
                "Ke Niu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02456v1",
                "http://arxiv.org/pdf/2312.02456v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02455v1",
            "title": "Boundary Harnack principle for non-local operators on metric measure\n  spaces",
            "updated": "2023-12-05T03:12:30Z",
            "published": "2023-12-05T03:12:30Z",
            "summary": "In this paper, a necessary and sufficient condition is obtained for the scale\ninvariant boundary Harnack inequality (BHP in abbreviation) for a large class\nof Hunt processes on metric measure spaces that are in weak duality with\nanother Hunt process. We next consider a discontinuous subordinate Brownian\nmotion with Gaussian component $X_t=W_{S_t}$ in ${\\bf R}^d$ for which the\nL\\'evy density of the subordinator $S$ satisfies some mild comparability\ncondition. We show that the scale invariant BHP holds for the subordinate\nBrownian motion $X$ in any Lipschitz domain satisfying the interior cone\ncondition with common angle $\\theta\\in (\\cos^{-1}(1/\\sqrt d), \\pi)$, but fails\nin any truncated circular cone with angle $\\theta \\leq \\cos^{-1}(1/\\sqrt d)$, a\nLipschitz domain whose Lipschitz constant is larger than or equal to\n$1/\\sqrt{d-1}.$",
            "author": [
                "Zhen-Qing Chen",
                "Jie-Ming Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02455v1",
                "http://arxiv.org/pdf/2312.02455v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "31B25, 47G20, 60J45, 60J76"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02454v1",
            "title": "Pole determination of $X(3960)$ and $X_0(4140)$ in decay $B^+\\to\n  K^+D_s^+D_s^-$",
            "updated": "2023-12-05T03:07:37Z",
            "published": "2023-12-05T03:07:37Z",
            "summary": "Two near-threshold peaking structures with spin-parities $J^{PC}=0^{++}$ were\nrecently discovered by the LHCb Collaboration in the $D_s^+D_s^-$ invariant\nmass distribution of the decay process $B^+\\to D_s^+D_s^-K^+$. In our study, we\nemployed a coupled-channel model to fit the experimental results published by\nthe LHCb collaboration, simultaneously fitting the model to the invariant mass\ndistributions of $M_{D_s^+D_s^-}$, $M_{D_s^+K^+}$, and $M_{D_s^-K^+}$. We\nutilized a coupled-channel model to search for the poles of $X(3960)$ and\n$X_0(4140)$. The determination of the poles is meaningful in itself, and it\nalso lays an foundation for the future research on $X(3960)$ and $X_0(4140)$.\nUpon turning off the coupled-channel and performing another fit, we observed a\nchange in the fitting quality, the effect was almost entirely due to the peak\nof $X(3960)$, so we suggest that $X(3960)$ may not be a kinematic effect.",
            "author": [
                "Jialiang Lu",
                "Xuan Luo",
                "Mao Song",
                "Gang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02454v1",
                "http://arxiv.org/pdf/2312.02454v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02445v1",
            "title": "LLaRA: Aligning Large Language Models with Sequential Recommenders",
            "updated": "2023-12-05T02:53:46Z",
            "published": "2023-12-05T02:53:46Z",
            "summary": "Sequential recommendation aims to predict the subsequent items matching user\npreference based on her/his historical interactions. With the development of\nLarge Language Models (LLMs), there is growing interest in exploring the\npotential of LLMs for sequential recommendation by framing it as a language\nmodeling task. Prior works represent items in the textual prompts using either\nID indexing or text indexing and feed the prompts into LLMs, but falling short\nof either encapsulating comprehensive world knowledge or exhibiting sufficient\nsequential understanding. To harness the complementary strengths of traditional\nrecommenders (which encode user behavioral knowledge) and LLMs (which possess\nworld knowledge about items), we propose LLaRA -- a Large Language and\nRecommendation Assistant framework. Specifically, LLaRA represents items in\nLLM's input prompts using a novel hybrid approach that integrates ID-based item\nembeddings from traditional recommenders with textual item features. Viewing\nthe ``sequential behavior of the user'' as a new modality in recommendation, we\nemploy an adapter to bridge the modality gap between ID embeddings of the\ntraditional recommenders and the input space of LLMs. Furthermore, instead of\ndirectly exposing the hybrid prompt to LLMs, we apply a curriculum learning\napproach to gradually ramp up training complexity. We first warm up the LLM\nwith text-only prompting, which aligns more naturally with the LLM's language\nmodeling capabilities. Thereafter, we progressively transition to hybrid\nprompting, training the adapter to incorporate behavioral knowledge from the\ntraditional sequential recommender into the LLM. Extensive experiments\ndemonstrate the efficacy of LLaRA framework. Our code and data are available at\nhttps://github.com/ljy0ustc/LLaRA .",
            "author": [
                "Jiayi Liao",
                "Sihang Li",
                "Zhengyi Yang",
                "Jiancan Wu",
                "Yancheng Yuan",
                "Xiang Wang",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02445v1",
                "http://arxiv.org/pdf/2312.02445v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02443v1",
            "title": "E4SRec: An Elegant Effective Efficient Extensible Solution of Large\n  Language Models for Sequential Recommendation",
            "updated": "2023-12-05T02:50:18Z",
            "published": "2023-12-05T02:50:18Z",
            "summary": "The recent advancements in Large Language Models (LLMs) have sparked interest\nin harnessing their potential within recommender systems. Since LLMs are\ndesigned for natural language tasks, existing recommendation approaches have\npredominantly transformed recommendation tasks into open-domain natural\nlanguage generation tasks. However, this approach necessitates items to possess\nrich semantic information, often generates out-of-range results, and suffers\nfrom notably low efficiency and limited extensibility. Furthermore, practical\nID-based recommendation strategies, reliant on a huge number of unique\nidentities (IDs) to represent users and items, have gained prominence in\nreal-world recommender systems due to their effectiveness and efficiency.\nNevertheless, the incapacity of LLMs to model IDs presents a formidable\nchallenge when seeking to leverage LLMs for personalized recommendations. In\nthis paper, we introduce an Elegant Effective Efficient Extensible solution for\nlarge language models for Sequential Recommendation (E4SRec), which seamlessly\nintegrates LLMs with traditional recommender systems that exclusively utilize\nIDs to represent items. Specifically, E4SRec takes ID sequences as inputs,\nensuring that the generated outputs fall within the candidate lists.\nFurthermore, E4SRec possesses the capability to generate the entire ranking\nlist in a single forward process, and demands only a minimal set of pluggable\nparameters, which are trained for each dataset while keeping the entire LLM\nfrozen. We substantiate the effectiveness, efficiency, and extensibility of our\nproposed E4SRec through comprehensive experiments conducted on four widely-used\nreal-world datasets. The implementation code is accessible at\nhttps://github.com/HestiaSky/E4SRec/.",
            "author": [
                "Xinhang Li",
                "Chong Chen",
                "Xiangyu Zhao",
                "Yong Zhang",
                "Chunxiao Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02443v1",
                "http://arxiv.org/pdf/2312.02443v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02442v1",
            "title": "A Comparative Study Between M30 and M92 : M92 Is A Merger Remnant With A\n  Large Helium Enhancement",
            "updated": "2023-12-05T02:49:09Z",
            "published": "2023-12-05T02:49:09Z",
            "summary": "We perform a comparative study of the ex--situ second--parameter pair\nglobular clusters (GCs) M30 and M92, having similar metallicities but different\nhorizontal branch morphologies. We obtain the similar mean primordial carbon\nabundances for both clusters. However, M92 shows a large dispersion in carbon\ndue to a more extended C--N anticorrelation, while M30 exhibits a higher\nprimordial nitrogen abundance, suggesting that they have different chemical\nenrichment histories. Our new results confirm our previous result that M92 is a\nmetal--complex GC showing a bimodal metallicity distribution. We also find that\nthe metal--rich group of stars in M92 shows a helium enhancement as large as\n$\\Delta Y$ $\\sim$ 0.05 from the red giant branch bump (RGBB) $V$ magnitudes,\nwhich can also be supported by (i) a lack of bright RGB stars, (ii) synthetic\nevolutionary HB population models and (iii) the more extended spatial\ndistribution due to different degree of the diffusion process from their lower\nmasses. We reinterpret the [Eu/Fe] measurements by other, finding that the two\nmetallicity groups of stars in M92 have significantly different [Eu/Fe]\nabundances with small scatters. This strongly suggests that they formed\nindependently out of well mixed interstellar media in different environments.\nWe suggest that M92 is a more complex system than a normal GC, most likely a\nmerger remnant of two GCs or a even more complex system. In Appendix, we\naddress the problems with the recently developed color--temperature relations\nand the usage of broadband photometry in the populational taggings.",
            "author": [
                "Jae-Woo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02442v1",
                "http://arxiv.org/pdf/2312.02442v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02441v1",
            "title": "MedDM:LLM-executable clinical guidance tree for clinical decision-making",
            "updated": "2023-12-05T02:44:07Z",
            "published": "2023-12-05T02:44:07Z",
            "summary": "It is becoming increasingly emphasis on the importance of LLM participating\nin clinical diagnosis decision-making. However, the low specialization refers\nto that current medical LLMs can not provide specific medical advice, which are\nmore like a medical Q\\&A. And there is no suitable clinical guidance tree data\nset that can be used directly with LLM. To address this issue, we first propose\nLLM-executavle clinical guidance tree(CGT), which can be directly used by large\nlanguage models, and construct medical diagnostic decision-making dataset\n(MedDM), from flowcharts in clinical practice guidelines. We propose an\napproach to screen flowcharts from medical literature, followed by their\nidentification and conversion into standardized diagnostic decision trees.\nConstructed a knowledge base with 1202 decision trees, which came from 5000\nmedical literature and covered 12 hospital departments, including internal\nmedicine, surgery, psychiatry, and over 500 diseases.Moreover, we propose a\nmethod for reasoning on LLM-executable CGT and a Patient-LLM multi-turn\ndialogue framework.",
            "author": [
                "Binbin Li",
                "Tianxin Meng",
                "Xiaoming Shi",
                "Jie Zhai",
                "Tong Ruan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02441v1",
                "http://arxiv.org/pdf/2312.02441v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02440v1",
            "title": "Beam Operation for Particle Physics and Photon Science with\n  Pulse-to-Pulse Modulation at KEK injector LINAC",
            "updated": "2023-12-05T02:42:38Z",
            "published": "2023-12-05T02:42:38Z",
            "summary": "The electron and positron accelerator complex at KEK offers unique\nexperimental opportunities in the fields of elementary particle physics with\nSuperKEKB collider and photon science with two light sources. In order to\nmaximize the experimental performances at those facilities the injector LINAC\nemploys pulse-to-pulse modulation at 50 Hz, injecting beams with diverse\nproperties. The event-based control system effectively manages different beam\nconfigurations. This injection scheme was initially designed 15 years ago and\nhas been in full operation since 2019. Over the years, quite a few enhancements\nhave been implemented. As the event-based controls are tightly coupled with\nmicrowave systems, machine protection systems and so on, their modifications\nrequire meticulous planning. However, the diverse requirements from particle\nphysics and photon science, stemming from the distinct nature of those\nexperiments, often necessitate patient negotiation to meet the demands of both\nfields. This presentation discusses those operational aspects of the\nmultidisciplinary facility.",
            "author": [
                "Kazuro Furukawa",
                "Masanori Satoh",
                "Injector LINAC group"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02440v1",
                "http://arxiv.org/pdf/2312.02440v1"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02439v2",
            "title": "Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language\n  Models with Creative Humor Generation",
            "updated": "2023-12-06T03:20:29Z",
            "published": "2023-12-05T02:41:57Z",
            "summary": "Chain-of-Thought (CoT) guides large language models (LLMs) to reason\nstep-by-step, and can motivate their logical reasoning ability. While effective\nfor logical tasks, CoT is not conducive to creative problem-solving which often\nrequires out-of-box thoughts and is crucial for innovation advancements. In\nthis paper, we explore the Leap-of-Thought (LoT) abilities within LLMs -- a\nnon-sequential, creative paradigm involving strong associations and knowledge\nleaps. To this end, we study LLMs on the popular Oogiri game which needs\nparticipants to have good creativity and strong associative thinking for\nresponding unexpectedly and humorously to the given image, text, or both, and\nthus is suitable for LoT study. Then to investigate LLMs' LoT ability in the\nOogiri game, we first build a multimodal and multilingual Oogiri-GO dataset\nwhich contains over 130,000 samples from the Oogiri game, and observe the\ninsufficient LoT ability or failures of most existing LLMs on the Oogiri game.\nAccordingly, we introduce a creative Leap-of-Thought (CLoT) paradigm to improve\nLLM's LoT ability. CLoT first formulates the Oogiri-GO dataset into\nLoT-oriented instruction tuning data to train pretrained LLM for achieving\ncertain LoT humor generation and discrimination abilities. Then CLoT designs an\nexplorative self-refinement that encourages the LLM to generate more creative\nLoT data via exploring parallels between seemingly unrelated concepts and\nselects high-quality data to train itself for self-refinement. CLoT not only\nexcels in humor generation in the Oogiri game but also boosts creative\nabilities in various tasks like cloud guessing game and divergent association\ntask. These findings advance our understanding and offer a pathway to improve\nLLMs' creative capacities for innovative applications across domains. The\ndataset, code, and models will be released online.\nhttps://zhongshsh.github.io/CLoT/.",
            "author": [
                "Shanshan Zhong",
                "Zhongzhan Huang",
                "Shanghua Gao",
                "Wushao Wen",
                "Liang Lin",
                "Marinka Zitnik",
                "Pan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02439v2",
                "http://arxiv.org/pdf/2312.02439v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02436v1",
            "title": "MUFFIN: Curating Multi-Faceted Instructions for Improving\n  Instruction-Following",
            "updated": "2023-12-05T02:32:08Z",
            "published": "2023-12-05T02:32:08Z",
            "summary": "In the realm of large language models (LLMs), enhancing instruction-following\ncapability often involves curating expansive training data. This is achieved\nthrough two primary schemes: i) Scaling-Inputs: Amplifying (input, output)\npairs per task instruction, aiming for better instruction adherence. ii)\nScaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,\noutput) pair (without requiring a separate input anymore). However, LLMs under\nScaling-Inputs tend to be overly sensitive to inputs, leading to\nmisinterpretation or non-compliance with instructions. Conversely, Scaling\nInput-Free Tasks demands a substantial number of tasks but is less effective in\ninstruction following when dealing with instances in Scaling-Inputs. This work\nintroduces MUFFIN, a new scheme of instruction-following dataset curation.\nSpecifically, we automatically Scale Tasks per Input by diversifying these\ntasks with various input facets. Experimental results across four zero-shot\nbenchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,\nreveal that LLMs, at various scales, trained on MUFFIN generally demonstrate\nsuperior instruction-following capabilities compared to those trained on the\ntwo aforementioned schemes.",
            "author": [
                "Renze Lou",
                "Kai Zhang",
                "Jian Xie",
                "Yuxuan Sun",
                "Janice Ahn",
                "Hanzi Xu",
                "Yu Su",
                "Wenpeng Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02436v1",
                "http://arxiv.org/pdf/2312.02436v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02434v1",
            "title": "FINER: Flexible spectral-bias tuning in Implicit NEural Representation\n  by Variable-periodic Activation Functions",
            "updated": "2023-12-05T02:23:41Z",
            "published": "2023-12-05T02:23:41Z",
            "summary": "Implicit Neural Representation (INR), which utilizes a neural network to map\ncoordinate inputs to corresponding attributes, is causing a revolution in the\nfield of signal processing. However, current INR techniques suffer from a\nrestricted capability to tune their supported frequency set, resulting in\nimperfect performance when representing complex signals with multiple\nfrequencies. We have identified that this frequency-related problem can be\ngreatly alleviated by introducing variable-periodic activation functions, for\nwhich we propose FINER. By initializing the bias of the neural network within\ndifferent ranges, sub-functions with various frequencies in the\nvariable-periodic function are selected for activation. Consequently, the\nsupported frequency set of FINER can be flexibly tuned, leading to improved\nperformance in signal representation. We demonstrate the capabilities of FINER\nin the contexts of 2D image fitting, 3D signed distance field representation,\nand 5D neural radiance fields optimization, and we show that it outperforms\nexisting INRs.",
            "author": [
                "Zhen Liu",
                "Hao Zhu",
                "Qi Zhang",
                "Jingde Fu",
                "Weibing Deng",
                "Zhan Ma",
                "Yanwen Guo",
                "Xun Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02434v1",
                "http://arxiv.org/pdf/2312.02434v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02433v1",
            "title": "Lenna: Language Enhanced Reasoning Detection Assistant",
            "updated": "2023-12-05T02:19:35Z",
            "published": "2023-12-05T02:19:35Z",
            "summary": "With the fast-paced development of multimodal large language models (MLLMs),\nwe can now converse with AI systems in natural languages to understand images.\nHowever, the reasoning power and world knowledge embedded in the large language\nmodels have been much less investigated and exploited for image perception\ntasks. In this paper, we propose Lenna, a language-enhanced reasoning detection\nassistant, which utilizes the robust multimodal feature representation of\nMLLMs, while preserving location information for detection. This is achieved by\nincorporating an additional <DET> token in the MLLM vocabulary that is free of\nexplicit semantic context but serves as a prompt for the detector to identify\nthe corresponding position. To evaluate the reasoning capability of Lenna, we\nconstruct a ReasonDet dataset to measure its performance on reasoning-based\ndetection. Remarkably, Lenna demonstrates outstanding performance on ReasonDet\nand comes with significantly low training costs. It also incurs minimal\ntransferring overhead when extended to other tasks. Our code and model will be\navailable at https://git.io/Lenna.",
            "author": [
                "Fei Wei",
                "Xinyu Zhang",
                "Ailing Zhang",
                "Bo Zhang",
                "Xiangxiang Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02433v1",
                "http://arxiv.org/pdf/2312.02433v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02431v1",
            "title": "Visually Grounded Language Learning: a review of language games,\n  datasets, tasks, and models",
            "updated": "2023-12-05T02:17:29Z",
            "published": "2023-12-05T02:17:29Z",
            "summary": "In recent years, several machine learning models have been proposed. They are\ntrained with a language modelling objective on large-scale text-only data. With\nsuch pretraining, they can achieve impressive results on many Natural Language\nUnderstanding and Generation tasks. However, many facets of meaning cannot be\nlearned by ``listening to the radio\" only. In the literature, many\nVision+Language (V+L) tasks have been defined with the aim of creating models\nthat can ground symbols in the visual modality. In this work, we provide a\nsystematic literature review of several tasks and models proposed in the V+L\nfield. We rely on Wittgenstein's idea of `language games' to categorise such\ntasks into 3 different families: 1) discriminative games, 2) generative games,\nand 3) interactive games. Our analysis of the literature provides evidence that\nfuture work should be focusing on interactive games where communication in\nNatural Language is important to resolve ambiguities about object referents and\naction plans and that physical embodiment is essential to understand the\nsemantics of situations and events. Overall, these represent key requirements\nfor developing grounded meanings in neural models.",
            "author": [
                "Alessandro Suglia",
                "Ioannis Konstas",
                "Oliver Lemon"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02431v1",
                "http://arxiv.org/pdf/2312.02431v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02429v2",
            "title": "PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval\n  Models",
            "updated": "2023-12-06T03:08:31Z",
            "published": "2023-12-05T02:08:48Z",
            "summary": "Embedding-based Retrieval Models (ERMs) have emerged as a promising framework\nfor large-scale text retrieval problems due to powerful large language models.\nNevertheless, fine-tuning ERMs to reach state-of-the-art results can be\nexpensive due to the extreme scale of data as well as the complexity of\nmulti-stages pipelines (e.g., pre-training, fine-tuning, distillation). In this\nwork, we propose the PEFA framework, namely ParamEter-Free Adapters, for fast\ntuning of ERMs without any backward pass in the optimization. At index building\nstage, PEFA equips the ERM with a non-parametric k-nearest neighbor (kNN)\ncomponent. At inference stage, PEFA performs a convex combination of two\nscoring functions, one from the ERM and the other from the kNN. Based on the\nneighborhood definition, PEFA framework induces two realizations, namely\nPEFA-XL (i.e., extra large) using double ANN indices and PEFA-XS (i.e., extra\nsmall) using a single ANN index. Empirically, PEFA achieves significant\nimprovement on two retrieval applications. For document retrieval, regarding\nRecall@100 metric, PEFA improves not only pre-trained ERMs on Trivia-QA by an\naverage of 13.2%, but also fine-tuned ERMs on NQ-320K by an average of 5.5%,\nrespectively. For product search, PEFA improves the Recall@100 of the\nfine-tuned ERMs by an average of 5.3% and 14.5%, for PEFA-XS and PEFA-XL,\nrespectively. Our code is available at\nhttps://github.com/amzn/pecos/tree/mainline/examples/pefa-wsdm24.",
            "author": [
                "Wei-Cheng Chang",
                "Jyun-Yu Jiang",
                "Jiong Zhang",
                "Mutasem Al-Darabsah",
                "Choon Hui Teo",
                "Cho-Jui Hsieh",
                "Hsiang-Fu Yu",
                "S. V. N. Vishwanathan"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3616855.3635791",
                "http://arxiv.org/abs/2312.02429v2",
                "http://arxiv.org/pdf/2312.02429v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02423v1",
            "title": "Exceptional Points in a $\\mathcal{PT}$-symmetrical quantum system: a\n  Scattering matrix approach",
            "updated": "2023-12-05T01:52:36Z",
            "published": "2023-12-05T01:52:36Z",
            "summary": "We analyze the behavior of a non-Hermitian opened one-dimensional quantum\nsystem with Parity-Time ($\\mathcal{PT}$) symmetry. This system is built by a\ndimer, which has balanced gains and losses described by a parameter $\\gamma$.\nBy varying $\\gamma$ the system resonances, which are naturally separated,\ncoalesce at the exceptional point (EP). The transmission spectrum is obteined\nby means of the scattering matrix ($S$ matrix) formalism and we examine the\nwave functions corresponding to the resonances as a function of $\\gamma$.\nSpecifically, we look for the behavior and distribution of the phases of the S\nmatrix before, at and after the exceptional point.",
            "author": [
                "J. Col\u00edn-G\u00e1lvez",
                "E. Casta\u00f1o",
                "G. B\u00e1ez",
                "V. Dom\u00ednguez-Rocha"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02423v1",
                "http://arxiv.org/pdf/2312.02423v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03017v1",
            "title": "AI-driven emergence of frequency information non-uniform distribution\n  via THz metasurface spectrum prediction",
            "updated": "2023-12-05T01:48:58Z",
            "published": "2023-12-05T01:48:58Z",
            "summary": "Recently, artificial intelligence has been extensively deployed across\nvarious scientific disciplines, optimizing and guiding the progression of\nexperiments through the integration of abundant datasets, whilst continuously\nprobing the vast theoretical space encapsulated within the data. Particularly,\ndeep learning models, due to their end-to-end adaptive learning capabilities,\nare capable of autonomously learning intrinsic data features, thereby\ntranscending the limitations of traditional experience to a certain extent.\nHere, we unveil previously unreported information characteristics pertaining to\ndifferent frequencies emerged during our work on predicting the terahertz\nspectral modulation effects of metasurfaces based on AI-prediction. Moreover,\nwe have substantiated that our proposed methodology of simply adding\nsupplementary multi-frequency inputs to the existing dataset during the target\nspectral prediction process can significantly enhance the predictive accuracy\nof the network. This approach effectively optimizes the utilization of existing\ndatasets and paves the way for interdisciplinary research and applications in\nartificial intelligence, chemistry, composite material design, biomedicine, and\nother fields.",
            "author": [
                "Xiaohua Xing",
                "Yuqi Ren",
                "Die Zou",
                "Qiankun Zhang",
                "Bingxuan Mao",
                "Jianquan Yao",
                "Deyi Xiong",
                "Shuang Zhang",
                "Liang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03017v1",
                "http://arxiv.org/pdf/2312.03017v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03016v1",
            "title": "Protein Language Model-Powered 3D Ligand Binding Site Prediction from\n  Protein Sequence",
            "updated": "2023-12-05T01:47:38Z",
            "published": "2023-12-05T01:47:38Z",
            "summary": "Prediction of ligand binding sites of proteins is a fundamental and important\ntask for understanding the function of proteins and screening potential drugs.\nMost existing methods require experimentally determined protein holo-structures\nas input. However, such structures can be unavailable on novel or less-studied\nproteins. To tackle this limitation, we propose LaMPSite, which only takes\nprotein sequences and ligand molecular graphs as input for ligand binding site\npredictions. The protein sequences are used to retrieve residue-level\nembeddings and contact maps from the pre-trained ESM-2 protein language model.\nThe ligand molecular graphs are fed into a graph neural network to compute\natom-level embeddings. Then we compute and update the protein-ligand\ninteraction embedding based on the protein residue-level embeddings and ligand\natom-level embeddings, and the geometric constraints in the inferred protein\ncontact map and ligand distance map. A final pooling on protein-ligand\ninteraction embedding would indicate which residues belong to the binding\nsites. Without any 3D coordinate information of proteins, our proposed model\nachieves competitive performance compared to baseline methods that require 3D\nprotein structures when predicting binding sites. Given that less than 50% of\nproteins have reliable structure information in the current stage, LaMPSite\nwill provide new opportunities for drug discovery.",
            "author": [
                "Shuo Zhang",
                "Lei Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03016v1",
                "http://arxiv.org/pdf/2312.03016v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02422v1",
            "title": "ChatGPT in the Classroom: Boon or Bane for Physics Students' Academic\n  Performance?",
            "updated": "2023-12-05T01:46:28Z",
            "published": "2023-12-05T01:46:28Z",
            "summary": "This study investigates the influence of ChatGPT, an AI-based language model,\non student performance in a physics course. We conducted an experimental\nanalysis with two cohorts of students in a second-semester engineering physics\ncourse. The control group (Physics 2 2022B) used traditional teaching methods,\nwhile the experimental group (Physics 2 2023A) integrated ChatGPT as a learning\ntool. Our results indicate that the use of ChatGPT led to a significant\ndecrease in student performance, as evidenced by lower grades and negative Hake\nfactors compared to the control group. In addition, a survey of students\nrevealed conflicting perceptions of the usefulness of ChatGPT in teaching\nphysics. While most recognized its usefulness in understanding concepts and\nproviding information, concerns were raised about its potential to reduce\ncritical thinking and independent learning. These findings suggest that while\nChatGPT can be a useful tool, it should be used with caution and as a\nsupplement to traditional teaching methods, rather than as a stand-alone\nsolution. The study underlines the importance of critical and reflective use of\nAI tools in educational settings and highlights the irreplaceable role of\nteachers in providing comprehensive educational support.",
            "author": [
                "Manuel G. Forero",
                "H. J. Herrera-Su\u00e1rez"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02422v1",
                "http://arxiv.org/pdf/2312.02422v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02420v1",
            "title": "Towards Granularity-adjusted Pixel-level Semantic Annotation",
            "updated": "2023-12-05T01:37:18Z",
            "published": "2023-12-05T01:37:18Z",
            "summary": "Recent advancements in computer vision predominantly rely on learning-based\nsystems, leveraging annotations as the driving force to develop specialized\nmodels. However, annotating pixel-level information, particularly in semantic\nsegmentation, presents a challenging and labor-intensive task, prompting the\nneed for autonomous processes. In this work, we propose GranSAM which\ndistinguishes itself by providing semantic segmentation at the user-defined\ngranularity level on unlabeled data without the need for any manual\nsupervision, offering a unique contribution in the realm of semantic mask\nannotation method. Specifically, we propose an approach to enable the Segment\nAnything Model (SAM) with semantic recognition capability to generate\npixel-level annotations for images without any manual supervision. For this, we\naccumulate semantic information from synthetic images generated by the Stable\nDiffusion model or web crawled images and employ this data to learn a mapping\nfunction between SAM mask embeddings and object class labels. As a result, SAM,\nenabled with granularity-adjusted mask recognition, can be used for pixel-level\nsemantic annotation purposes. We conducted experiments on the PASCAL VOC 2012\nand COCO-80 datasets and observed a +17.95% and +5.17% increase in mIoU,\nrespectively, compared to existing state-of-the-art methods when evaluated\nunder our problem setting.",
            "author": [
                "Rohit Kundu",
                "Sudipta Paul",
                "Rohit Lal",
                "Amit K. Roy-Chowdhury"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02420v1",
                "http://arxiv.org/pdf/2312.02420v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02419v1",
            "title": "Human Demonstrations are Generalizable Knowledge for Robots",
            "updated": "2023-12-05T01:35:39Z",
            "published": "2023-12-05T01:35:39Z",
            "summary": "Learning from human demonstrations is an emerging trend for designing\nintelligent robotic systems. However, previous methods typically regard videos\nas instructions, simply dividing them into action sequences for robotic\nrepetition, which poses obstacles to generalization to diverse tasks or object\ninstances. In this paper, we propose a different perspective, considering human\ndemonstration videos not as mere instructions, but as a source of knowledge for\nrobots. Motivated by this perspective and the remarkable comprehension and\ngeneralization capabilities exhibited by large language models (LLMs), we\npropose DigKnow, a method that DIstills Generalizable KNOWledge with a\nhierarchical structure. Specifically, DigKnow begins by converting human\ndemonstration video frames into observation knowledge. This knowledge is then\nsubjected to analysis to extract human action knowledge and further distilled\ninto pattern knowledge compassing task and object instances, resulting in the\nacquisition of generalizable knowledge with a hierarchical structure. In\nsettings with different tasks or object instances, DigKnow retrieves relevant\nknowledge for the current task and object instances. Subsequently, the\nLLM-based planner conducts planning based on the retrieved knowledge, and the\npolicy executes actions in line with the plan to achieve the designated task.\nUtilizing the retrieved knowledge, we validate and rectify planning and\nexecution outcomes, resulting in a substantial enhancement of the success rate.\nExperimental results across a range of tasks and scenes demonstrate the\neffectiveness of this approach in facilitating real-world robots to accomplish\ntasks with the knowledge derived from human demonstrations.",
            "author": [
                "Guangyan Chen",
                "Te Cui",
                "Tianxing Zhou",
                "Zicai Peng",
                "Mengxiao Hu",
                "Meiling Wang",
                "Yi Yang",
                "Yufeng Yue"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02419v1",
                "http://arxiv.org/pdf/2312.02419v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03015v1",
            "title": "PartSLIP++: Enhancing Low-Shot 3D Part Segmentation via Multi-View\n  Instance Segmentation and Maximum Likelihood Estimation",
            "updated": "2023-12-05T01:33:04Z",
            "published": "2023-12-05T01:33:04Z",
            "summary": "Open-world 3D part segmentation is pivotal in diverse applications such as\nrobotics and AR/VR. Traditional supervised methods often grapple with limited\n3D data availability and struggle to generalize to unseen object categories.\nPartSLIP, a recent advancement, has made significant strides in zero- and\nfew-shot 3D part segmentation. This is achieved by harnessing the capabilities\nof the 2D open-vocabulary detection module, GLIP, and introducing a heuristic\nmethod for converting and lifting multi-view 2D bounding box predictions into\n3D segmentation masks. In this paper, we introduce PartSLIP++, an enhanced\nversion designed to overcome the limitations of its predecessor. Our approach\nincorporates two major improvements. First, we utilize a pre-trained 2D\nsegmentation model, SAM, to produce pixel-wise 2D segmentations, yielding more\nprecise and accurate annotations than the 2D bounding boxes used in PartSLIP.\nSecond, PartSLIP++ replaces the heuristic 3D conversion process with an\ninnovative modified Expectation-Maximization algorithm. This algorithm\nconceptualizes 3D instance segmentation as unobserved latent variables, and\nthen iteratively refines them through an alternating process of 2D-3D matching\nand optimization with gradient descent. Through extensive evaluations, we show\nthat PartSLIP++ demonstrates better performance over PartSLIP in both low-shot\n3D semantic and instance-based object part segmentation tasks. Code released at\nhttps://github.com/zyc00/PartSLIP2.",
            "author": [
                "Yuchen Zhou",
                "Jiayuan Gu",
                "Xuanlin Li",
                "Minghua Liu",
                "Yunhao Fang",
                "Hao Su"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03015v1",
                "http://arxiv.org/pdf/2312.03015v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02418v1",
            "title": "Decoding Data Quality via Synthetic Corruptions: Embedding-guided\n  Pruning of Code Data",
            "updated": "2023-12-05T01:19:30Z",
            "published": "2023-12-05T01:19:30Z",
            "summary": "Code datasets, often collected from diverse and uncontrolled sources such as\nGitHub, potentially suffer from quality issues, thereby affecting the\nperformance and training efficiency of Large Language Models (LLMs) optimized\nfor code generation. Previous studies demonstrated the benefit of using\nembedding spaces for data pruning, but they mainly focused on duplicate removal\nor increasing variety, and in other modalities, such as images. Our work\nfocuses on using embeddings to identify and remove \"low-quality\" code data.\nFirst, we explore features of \"low-quality\" code in embedding space, through\nthe use of synthetic corruptions. Armed with this knowledge, we devise novel\npruning metrics that operate in embedding space to identify and remove\nlow-quality entries in the Stack dataset. We demonstrate the benefits of this\nsynthetic corruption informed pruning (SCIP) approach on the well-established\nHumanEval and MBPP benchmarks, outperforming existing embedding-based methods.\nImportantly, we achieve up to a 3% performance improvement over no pruning,\nthereby showing the promise of insights from synthetic corruptions for data\npruning.",
            "author": [
                "Yu Yang",
                "Aaditya K. Singh",
                "Mostafa Elhoushi",
                "Anas Mahmoud",
                "Kushal Tirumala",
                "Fabian Gloeckle",
                "Baptiste Rozi\u00e8re",
                "Carole-Jean Wu",
                "Ari S. Morcos",
                "Newsha Ardalani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02418v1",
                "http://arxiv.org/pdf/2312.02418v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02415v1",
            "title": "Almost Exact Recovery in Gossip Opinion Dynamics over Stochastic Block\n  Models",
            "updated": "2023-12-05T01:11:44Z",
            "published": "2023-12-05T01:11:44Z",
            "summary": "We study community detection based on state observations from gossip opinion\ndynamics over stochastic block models (SBM). It is assumed that a network is\ngenerated from a two-community SBM where each agent has a community label and\neach edge exists with probability depending on its endpoints' labels. A gossip\nprocess then evolves over the sampled network. We propose two algorithms to\ndetect the communities out of a single trajectory of the process. It is shown\nthat, when the influence of stubborn agents is small and the link probability\nwithin communities is large, an algorithm based on clustering transient agent\nstates can achieve almost exact recovery of the communities. That is, the\nalgorithm can recover all but a vanishing part of community labels with high\nprobability. In contrast, when the influence of stubborn agents is large,\nanother algorithm based on clustering time average of agent states can achieve\nalmost exact recovery. Numerical experiments are given for illustration of the\ntwo algorithms and the theoretical results of the paper.",
            "author": [
                "Yu Xing",
                "Karl H. Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02415v1",
                "http://arxiv.org/pdf/2312.02415v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03014v1",
            "title": "Foundation Models for Weather and Climate Data Understanding: A\n  Comprehensive Survey",
            "updated": "2023-12-05T01:10:54Z",
            "published": "2023-12-05T01:10:54Z",
            "summary": "As artificial intelligence (AI) continues to rapidly evolve, the realm of\nEarth and atmospheric sciences is increasingly adopting data-driven models,\npowered by progressive developments in deep learning (DL). Specifically, DL\ntechniques are extensively utilized to decode the chaotic and nonlinear aspects\nof Earth systems, and to address climate challenges via understanding weather\nand climate data. Cutting-edge performance on specific tasks within narrower\nspatio-temporal scales has been achieved recently through DL. The rise of large\nmodels, specifically large language models (LLMs), has enabled fine-tuning\nprocesses that yield remarkable outcomes across various downstream tasks,\nthereby propelling the advancement of general AI. However, we are still\nnavigating the initial stages of crafting general AI for weather and climate.\nIn this survey, we offer an exhaustive, timely overview of state-of-the-art AI\nmethodologies specifically engineered for weather and climate data, with a\nspecial focus on time series and text data. Our primary coverage encompasses\nfour critical aspects: types of weather and climate data, principal model\narchitectures, model scopes and applications, and datasets for weather and\nclimate. Furthermore, in relation to the creation and application of foundation\nmodels for weather and climate data understanding, we delve into the field's\nprevailing challenges, offer crucial insights, and propose detailed avenues for\nfuture research. This comprehensive approach equips practitioners with the\nrequisite knowledge to make substantial progress in this domain. Our survey\nencapsulates the most recent breakthroughs in research on large, data-driven\nmodels for weather and climate data understanding, emphasizing robust\nfoundations, current advancements, practical applications, crucial resources,\nand prospective research opportunities.",
            "author": [
                "Shengchao Chen",
                "Guodong Long",
                "Jing Jiang",
                "Dikai Liu",
                "Chengqi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03014v1",
                "http://arxiv.org/pdf/2312.03014v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02412v1",
            "title": "A Turing Incomputable Coloring Function",
            "updated": "2023-12-05T01:03:53Z",
            "published": "2023-12-05T01:03:53Z",
            "summary": "This paper describes a sequence of natural numbers that grows faster than any\nTuring computable function. This sequence is generated from a version of the\ntiling problem, called a coloring system. In our proof that generates the\nsequence, we use the notions of a chain and an unbounded sequence property,\nwhich resemble the methods of point set topology. From this sequence, we define\na Turing incomputable coloring function.",
            "author": [
                "Michael Stephen Fiske"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02412v1",
                "http://arxiv.org/pdf/2312.02412v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.LO",
                "math.CO",
                "math.LO",
                "03D15, 52C20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02406v1",
            "title": "Efficient Online Data Mixing For Language Model Pre-Training",
            "updated": "2023-12-05T00:42:35Z",
            "published": "2023-12-05T00:42:35Z",
            "summary": "The data used to pretrain large language models has a decisive impact on a\nmodel's downstream performance, which has led to a large body of work on data\nselection methods that aim to automatically determine the most suitable data to\nuse for pretraining. Existing data selection methods suffer from slow and\ncomputationally expensive processes, a problem amplified by the increasing size\nof models and of pretraining datasets. Data mixing, on the other hand, reduces\nthe complexity of data selection by grouping data points together and\ndetermining sampling probabilities across entire groups. However, data mixing\nproportions are typically fixed before training and therefore cannot adapt to\nchanging training dynamics. To address these limitations, we develop an\nefficient algorithm for Online Data Mixing (ODM) that combines elements from\nboth data selection and data mixing. Based on multi-armed bandit algorithms,\nour online approach optimizes the data mixing proportions during training.\nRemarkably, our method trains a model that reaches the final perplexity of the\nnext best method with 19\\% fewer training iterations, and improves performance\non the 5-shot MMLU benchmark by 1.9% relative accuracy, while adding negligible\nwall-clock time during pretraining.",
            "author": [
                "Alon Albalak",
                "Liangming Pan",
                "Colin Raffel",
                "William Yang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02406v1",
                "http://arxiv.org/pdf/2312.02406v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03013v1",
            "title": "Breast Ultrasound Report Generation using LangChain",
            "updated": "2023-12-05T00:28:26Z",
            "published": "2023-12-05T00:28:26Z",
            "summary": "Breast ultrasound (BUS) is a critical diagnostic tool in the field of breast\nimaging, aiding in the early detection and characterization of breast\nabnormalities. Interpreting breast ultrasound images commonly involves creating\ncomprehensive medical reports, containing vital information to promptly assess\nthe patient's condition. However, the ultrasound imaging system necessitates\ncapturing multiple images of various parts to compile a single report,\npresenting a time-consuming challenge. To address this problem, we propose the\nintegration of multiple image analysis tools through a LangChain using Large\nLanguage Models (LLM), into the breast reporting process. Through a combination\nof designated tools and text generation through LangChain, our method can\naccurately extract relevant features from ultrasound images, interpret them in\na clinical context, and produce comprehensive and standardized reports. This\napproach not only reduces the burden on radiologists and healthcare\nprofessionals but also enhances the consistency and quality of reports. The\nextensive experiments shows that each tools involved in the proposed method can\noffer qualitatively and quantitatively significant results. Furthermore,\nclinical evaluation on the generated reports demonstrates that the proposed\nmethod can make report in clinically meaningful way.",
            "author": [
                "Jaeyoung Huh",
                "Hyun Jeong Park",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03013v1",
                "http://arxiv.org/pdf/2312.03013v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02401v1",
            "title": "Harmonizing Global Voices: Culturally-Aware Models for Enhanced Content\n  Moderation",
            "updated": "2023-12-05T00:11:09Z",
            "published": "2023-12-05T00:11:09Z",
            "summary": "Content moderation at scale faces the challenge of considering local cultural\ndistinctions when assessing content. While global policies aim to maintain\ndecision-making consistency and prevent arbitrary rule enforcement, they often\noverlook regional variations in interpreting natural language as expressed in\ncontent. In this study, we are looking into how moderation systems can tackle\nthis issue by adapting to local comprehension nuances. We train large language\nmodels on extensive datasets of media news and articles to create culturally\nattuned models. The latter aim to capture the nuances of communication across\ngeographies with the goal of recognizing cultural and societal variations in\nwhat is considered offensive content. We further explore the capability of\nthese models to generate explanations for instances of content violation,\naiming to shed light on how policy guidelines are perceived when cultural and\nsocietal contexts change. We find that training on extensive media datasets\nsuccessfully induced cultural awareness and resulted in improvements in\nhandling content violations on a regional basis. Additionally, these\nadvancements include the ability to provide explanations that align with the\nspecific local norms and nuances as evidenced by the annotators' preference in\nour conducted study. This multifaceted success reinforces the critical role of\nan adaptable content moderation approach in keeping pace with the ever-evolving\nnature of the content it oversees.",
            "author": [
                "Alex J. Chan",
                "Jos\u00e9 Luis Redondo Garc\u00eda",
                "Fabrizio Silvestri",
                "Colm O'Donnel",
                "Konstantina Palla"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02401v1",
                "http://arxiv.org/pdf/2312.02401v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02395v1",
            "title": "Time-reversibility during the aging of materials",
            "updated": "2023-12-04T23:21:51Z",
            "published": "2023-12-04T23:21:51Z",
            "summary": "Physical aging is the generic term for irreversible processes in glassy\nmaterials resulting from molecular rearrangements. We present multi-speckle\ndynamic light-scattering data on an aging sample of the molecular glass former\n1-phenyl-1-propanol following temperature jumps close to the glass transition,\nstarting from and ending in thermal equilibrium. It is demonstrated that the\nmaterial time of the Tool-Narayanaswamy aging formalism can be determined from\nthe time-autocorrelation function of the scattered-light intensity\nfluctuations. These fluctuations are shown to be stationary and reversible when\nregarded as a function of the material time. The glass-forming colloidal\nsynthetic clay Laponite, as well as a chemically aging curing epoxy, are shown\nalso to have material-time-reversible scattered-light intensity fluctuations.\nOur findings, besides showing direct measurements of the material time,\nidentify a fundamental property of aging in quite different contexts, which\npresents a challenge to the current theories of aging.",
            "author": [
                "Till B\u00f6hmer",
                "Jan P. Gabriel",
                "Jan-Niklas Kociok",
                "Tina Hecksher",
                "Jeppe C. Dyre",
                "Thomas Blochowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02395v1",
                "http://arxiv.org/pdf/2312.02395v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02394v1",
            "title": "Evidence for the $VH, H\\rightarrow \u03c4\u03c4$ process with the ATLAS\n  detector in Run 2",
            "updated": "2023-12-04T23:21:43Z",
            "published": "2023-12-04T23:21:43Z",
            "summary": "A search for the Standard Model Higgs boson produced in association with a\n$W$ or $Z$ boson and decaying into a pair of $\\tau$-leptons is presented. This\nsearch is based on proton-proton collision data collected at $\\sqrt{s}=13$ TeV\nby the ATLAS experiment at the LHC corresponding to an integrated luminosity of\n140 fb$^{-1}$. For the Higgs boson candidate, only final states with at least\none $\\tau$ decaying hadronically ($\\tau\\rightarrow \\mathrm{hadrons} +\n\\nu_\\tau$) are considered. For the vector bosons, only leptonic decay channels\nare considered: $Z \\rightarrow \\ell\\ell$ and $W\\rightarrow \\ell\\nu_\\ell$, with\n$\\ell=e,\\mu$. An excess of events over the expected background is found with an\nobserved (expected) significance of 4.2 (3.6) standard deviations, providing\nevidence of the Higgs boson produced in association with a vector boson and\ndecaying into a pair of $\\tau$-leptons. The ratio of the measured cross-section\nto the Standard Model prediction is $\\mu_{\\text{VH}}^{\\tau\\tau} = 1.28\\\n^{+0.30}_{-0.29}\\ (\\mathrm{stat.})\\ ^{+0.25}_{-0.21}\\ (\\mathrm{syst.})$.",
            "author": [
                "ATLAS Collaboration"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02394v1",
                "http://arxiv.org/pdf/2312.02394v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02393v1",
            "title": "Lecture Notes on Computerized Tomography",
            "updated": "2023-12-04T23:18:13Z",
            "published": "2023-12-04T23:18:13Z",
            "summary": "These lecture notes give an introduction to the mathematics of computer(ized)\ntomography (CT). Treated are the imaging principle of X-ray tomography, the\nRadon transform as mathematical model for the measurement process and its\nproperties, the ill-posedness of the underlying mathematical reconstruction\nproblem and classical reconstruction techniques. The required background from\nFourier analysis is also briefly summarized.",
            "author": [
                "Matthias Beckmann"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02393v1",
                "http://arxiv.org/pdf/2312.02393v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02389v1",
            "title": "Multi-messenger particles as a probe for UHECR luminosity",
            "updated": "2023-12-04T23:07:50Z",
            "published": "2023-12-04T23:07:50Z",
            "summary": "Very-high energy (GeV-TeV) gamma rays in the universe suggest the presence of\nan accelerator in the source. Neutrinos and gamma rays are intriguing\nastrophysical messengers. Multi-messenger particle emission produced by\ninteractions of cosmic rays with radiation fields and interstellar matter is a\nprobe of luminosity of sources of cosmic rays with EeV energies, known as\nUltra-High Energy Cosmic Rays (UHECRs). In this study, we estimate the neutrino\nflux, positing that the gamma-ray emission mainly arises from these cosmic-ray\ninteractions during propagation. This work provides UHECR luminosity of\ngalaxies from multi-messenger particles. These findings not only highlight the\npotential of certain galaxies as sources of UHECR, but also underscore the\nintricate interplay of various astrophysical processes within them. By\nunderstanding the luminosity patterns and multi-messenger particle emissions,\nwe can gain valuable insights into the environmental conditions, acceleration\nmechanisms, and other intrinsic properties that position these galaxies as\ncandidates for UHECR production.",
            "author": [
                "Rodrigo Sasse",
                "Adriel G. B. Mocellin",
                "Rita C. dos Anjos",
                "Carlos H. Coimbra-Araujo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02389v1",
                "http://arxiv.org/pdf/2312.02389v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02388v1",
            "title": "Insights to Molecular and Bulk Mechanical Properties of Glassy Carbon\n  Through Molecular Dynamics Simulation and Mechanical Tensile Testing",
            "updated": "2023-12-04T23:04:52Z",
            "published": "2023-12-04T23:04:52Z",
            "summary": "With increasing interest in the use of glassy carbon (GC) for a wide variety\nof application areas, the need for developing fundamental understanding of its\nmechanical properties has come to the forefront. Further, recent theoretical\nand modeling works that shed some light on the synthesis of GC through the\nprocess of pyrolysis of polymer precursors have highlighted the possibilities\nof a revisit to investigation of its mechanical properties at a fundamental\nlevel. While there are isolated reports on the experimental determination of\nits elastic modulus, insights into stress-strain behavior of GC material under\ntension and compression obtained through simulation, either at molecular level\nor for the bulk material is missing. This current study fills the gap at the\nmolecular level and investigates the mechanical properties of GC using\nmolecular dynamics (MD) simulations which model the atomistic level formation\nand breaking of bonds using bond-order based reactive force field formulations.\nThe molecular model considered for this simulation has a characteristics 3D\ncagey structure of 5-, 6-, and 7-membered carbon rings and graphitic domain of\na flat graphene-like structure. The GC molecular model was subjected to loading\nunder varying strain rates (0.4/ns, 0.6/ns, 1.25/ns, and 2.5/ns) and varying\ntemperatures (300 - 800 K) in each of the three axes x, y, and z. The\nsimulation showed that GC molecule has distinct stress-strain curves under\ntension and compression. In tension, MD modeling predicted mean elastic modulus\nof 5.71 GPa for a single GC molecule with some dependency on strain rates and\ntemperature, while in compression, the elastic modulus was also found to depend\non the strain rates as well as temperature and was predicted to have a mean\nvalue of 35 GPa",
            "author": [
                "Manali Kuntea",
                "Luc\u00eda Carballo Chanf\u00f3na",
                "Surabhi Nimbalkara",
                "James Bunnell",
                "Emanuel Rodriguez Barajasa",
                "Mario Enrique Vazquez",
                "David Trejo-Rodriguez",
                "Carter Faucher",
                "Skelly Smitha",
                "Sam Kassegne"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02388v1",
                "http://arxiv.org/pdf/2312.02388v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02382v1",
            "title": "New Evaluation Metrics Capture Quality Degradation due to LLM\n  Watermarking",
            "updated": "2023-12-04T22:56:31Z",
            "published": "2023-12-04T22:56:31Z",
            "summary": "With the increasing use of large-language models (LLMs) like ChatGPT,\nwatermarking has emerged as a promising approach for tracing machine-generated\ncontent. However, research on LLM watermarking often relies on simple\nperplexity or diversity-based measures to assess the quality of watermarked\ntext, which can mask important limitations in watermarking. Here we introduce\ntwo new easy-to-use methods for evaluating watermarking algorithms for LLMs: 1)\nevaluation by LLM-judger with specific guidelines; and 2) binary classification\non text embeddings to distinguish between watermarked and unwatermarked text.\nWe apply these methods to characterize the effectiveness of current\nwatermarking techniques. Our experiments, conducted across various datasets,\nreveal that current watermarking methods are detectable by even simple\nclassifiers, challenging the notion of watermarking subtlety. We also found,\nthrough the LLM judger, that watermarking impacts text quality, especially in\ndegrading the coherence and depth of the response. Our findings underscore the\ntrade-off between watermark robustness and text quality and highlight the\nimportance of having more informative metrics to assess watermarking quality.",
            "author": [
                "Karanpartap Singh",
                "James Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02382v1",
                "http://arxiv.org/pdf/2312.02382v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02380v1",
            "title": "FaultFormer: Transformer-based Prediction of Bearing Faults",
            "updated": "2023-12-04T22:51:02Z",
            "published": "2023-12-04T22:51:02Z",
            "summary": "The growth of deep learning in the past decade has motivated important\napplications to smart manufacturing and machine health monitoring. In\nparticular, vibration data offers a rich and reliable source to provide\nmeaningful insights into machine health and predictive maintenance. In this\nwork, we present a Transformer based framework for analyzing vibration signals\nto predict different types of bearing faults (FaultFormer). In particular, we\nprocess signal data using data augmentations and extract their Fourier modes to\ntrain a transformer encoder to achieve state of the art accuracies. The\nattention mechanism as well as model outputs were analyzed to confirm the\ntransformer's ability to automatically extract features within signals and\nlearn both global and local relationships to make classifications. Lastly, two\npretraining strategies were proposed to pave the way for large, generalizable\ntransformers that could adapt to new data, situations, or machinery on the\nproduction floor.",
            "author": [
                "Anthony Zhou",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02380v1",
                "http://arxiv.org/pdf/2312.02380v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02377v1",
            "title": "Clifford Manipulations of Stabilizer States: A graphical rule book for\n  Clifford unitaries and measurements on cluster states, and application to\n  photonic quantum computing",
            "updated": "2023-12-04T22:40:24Z",
            "published": "2023-12-04T22:40:24Z",
            "summary": "Stabilizer states along with Clifford manipulations (unitary transformations\nand measurements) thereof -- despite being efficiently simulable on a classical\ncomputer -- are an important tool in quantum information processing, with\napplications to quantum computing, error correction and networking. Cluster\nstates, defined on a graph, are a special class of stabilizer states that are\ncentral to measurement based quantum computing, all-photonic quantum repeaters,\ndistributed quantum computing, and entanglement distribution in a network. All\ncluster states are local-Clifford equivalent to a stabilizer state. In this\npaper, we review the stabilizer framework, and extend it, by: incorporating\ngeneral stabilizer measurements such as multi-qubit fusions, and providing an\nexplicit procedure -- using Karnaugh maps from Boolean algebra -- for\nconverting arbitrary stabilizer gates into tableau operations of the CHP\nformalism for efficient stabilizer manipulations. Using these tools, we develop\na graphical rule-book and a MATLAB simulator with a graphical user interface\nfor arbitrary stabilizer manipulations of cluster states, a user of which,\ne.g., for research in quantum networks, will not require any background in\nquantum information or the stabilizer framework. We extend our graphical\nrule-book to include dual-rail photonic-qubit cluster state manipulations with\nprobabilistically-heralded linear-optical circuits for various rotated Bell\nmeasurements, i.e., fusions (including new `Type-I' fusions we propose, where\nonly one of the two fused qubits is destructively measured), by incorporating\ngraphical rules for their success and failure modes. Finally, we show how\nstabilizer descriptions of multi-qubit fusions can be mapped to linear optical\ncircuits.",
            "author": [
                "Ashlesha Patil",
                "Saikat Guha"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02377v1",
                "http://arxiv.org/pdf/2312.02377v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03758v1",
            "title": "Stock Movement and Volatility Prediction from Tweets, Macroeconomic\n  Factors and Historical Prices",
            "updated": "2023-12-04T22:27:43Z",
            "published": "2023-12-04T22:27:43Z",
            "summary": "Predicting stock market is vital for investors and policymakers, acting as a\nbarometer of the economic health. We leverage social media data, a potent\nsource of public sentiment, in tandem with macroeconomic indicators as\ngovernment-compiled statistics, to refine stock market predictions. However,\nprior research using tweet data for stock market prediction faces three\nchallenges. First, the quality of tweets varies widely. While many are filled\nwith noise and irrelevant details, only a few genuinely mirror the actual\nmarket scenario. Second, solely focusing on the historical data of a particular\nstock without considering its sector can lead to oversight. Stocks within the\nsame industry often exhibit correlated price behaviors. Lastly, simply\nforecasting the direction of price movement without assessing its magnitude is\nof limited value, as the extent of the rise or fall truly determines\nprofitability. In this paper, diverging from the conventional methods, we\npioneer an ECON. The framework has following advantages: First, ECON has an\nadept tweets filter that efficiently extracts and decodes the vast array of\ntweet data. Second, ECON discerns multi-level relationships among stocks,\nsectors, and macroeconomic factors through a self-aware mechanism in semantic\nspace. Third, ECON offers enhanced accuracy in predicting substantial stock\nprice fluctuations by capitalizing on stock price movement. We showcase the\nstate-of-the-art performance of our proposed model using a dataset,\nspecifically curated by us, for predicting stock market movements and\nvolatility.",
            "author": [
                "Shengkun Wang",
                "YangXiao Bai",
                "Taoran Ji",
                "Kaiqun Fu",
                "Linhan Wang",
                "Chang-Tien Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03758v1",
                "http://arxiv.org/pdf/2312.03758v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02374v1",
            "title": "Prospects for constraining quasar ages with fiber spectrographs:\n  Quasar-induced Ly$\u03b1$ emission from the intergalactic medium",
            "updated": "2023-12-04T22:16:33Z",
            "published": "2023-12-04T22:16:33Z",
            "summary": "We present a theoretical framework for linking quasar properties, such as\nquasar age, to the surrounding Ly$\\alpha$ emission intensity. In particular, we\nfocus on a method for mapping the large-scale structure of Ly$\\alpha$ emission\nintensity with galaxy spectra from wide-field spectroscopic surveys, e.g., the\nSubaru Prime Focus Spectrograph (PFS) or the Dark Energy Spectroscopic\nInstrument (DESI), and consider the quasar-induced Ly$\\alpha$ emission from the\nintergalactic medium (IGM). To do this, we construct a theoretical model based\non two physical processes: resonant scattering of quasar Ly$\\alpha$ photons and\nfluorescence due to quasar ionizing photons, finding that the fluorescence\ncontribution due to optically thick gas clouds is dominant. Taking into account\nthe light cone effect and assuming a typical quasar spectrum, we calculate the\nfluorescence contribution to the spectrum stacked within each bin of the\nseparation angle from the quasar as a function of quasar age. Furthermore, we\ncompute the quasar-Ly$\\alpha$ emission cross-correlation and its SNR for the\nplanned PFS survey. The predicted signal can account for $\\sim10\\%$ of the\nmeasurements indicated from the BOSS and eBOSS surveys in the outer region of\n$>10\\ \\rm{cMpc}\\ \\rm{h}^{-1}$. The predicted SNR is not enough to detect the\nquasar-induced contribution, while it is enhanced by including contributions\nfrom other Ly$\\alpha$ emission sources, e.g., star-forming galaxies. We discuss\nother possible contributions to the Ly$\\alpha$ emission excess around quasars,\nthe efficiency of using spectroscopic fibers, and the redshift dependence of\nour model.",
            "author": [
                "Ryuichiro Hada",
                "Masahiro Takada",
                "Akio K. Inoue"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02374v1",
                "http://arxiv.org/pdf/2312.02374v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02372v1",
            "title": "On the Trade-Off between Stability and Representational Capacity in\n  Graph Neural Networks",
            "updated": "2023-12-04T22:07:17Z",
            "published": "2023-12-04T22:07:17Z",
            "summary": "Analyzing the stability of graph neural networks (GNNs) under topological\nperturbations is key to understanding their transferability and the role of\neach architecture component. However, stability has been investigated only for\nparticular architectures, questioning whether it holds for a broader spectrum\nof GNNs or only for a few instances. To answer this question, we study the\nstability of EdgeNet: a general GNN framework that unifies more than twenty\nsolutions including the convolutional and attention-based classes, as well as\ngraph isomorphism networks and hybrid architectures. We prove that all GNNs\nwithin the EdgeNet framework are stable to topological perturbations. By\nstudying the effect of different EdgeNet categories on the stability, we show\nthat GNNs with fewer degrees of freedom in their parameter space, linked to a\nlower representational capacity, are more stable. The key factor yielding this\ntrade-off is the eigenvector misalignment between the EdgeNet parameter\nmatrices and the graph shift operator. For example, graph convolutional neural\nnetworks that assign a single scalar per signal shift (hence, with a perfect\nalignment) are more stable than the more involved node or edge-varying\ncounterparts. Extensive numerical results corroborate our theoretical findings\nand highlight the role of different architecture components in the trade-off.",
            "author": [
                "Zhan Gao",
                "Amanda Prorok",
                "Elvin Isufi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02372v1",
                "http://arxiv.org/pdf/2312.02372v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02368v1",
            "title": "RINAS: Training with Dataset Shuffling Can Be General and Fast",
            "updated": "2023-12-04T21:50:08Z",
            "published": "2023-12-04T21:50:08Z",
            "summary": "Deep learning datasets are expanding at an unprecedented pace, creating new\nchallenges for data processing in model training pipelines. A crucial aspect of\nthese pipelines is dataset shuffling, which significantly improves unbiased\nlearning and convergence accuracy by adhering to the principles of random\nsampling. However, loading shuffled data for large datasets incurs significant\noverhead in the deep learning pipeline and severely impacts the end-to-end\ntraining throughput. To mitigate this, current deep learning systems often\nresort to partial dataset shuffling, sacrificing global randomness to maintain\nacceptable training throughput on large datasets, still leaving global\nshuffling efficiency issues not fully explored.\n  In this work, we present RINAS, a data loading framework that systematically\naddresses the performance bottleneck of loading global shuffled datasets. Our\nkey contribution is to offer an intra-batch unordered data fetching approach,\nwhich unleashes unexplored parallelism of data loading. We implement RINAS\nunder the PyTorch framework for common dataset libraries HuggingFace and\nTorchVision. Our experimental results show that RINAS improves the throughput\nof general language model training and vision model training by up to 59% and\n89%, respectively.",
            "author": [
                "Tianle Zhong",
                "Jiechen Zhao",
                "Xindi Guo",
                "Qiang Su",
                "Geoffrey Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02368v1",
                "http://arxiv.org/pdf/2312.02368v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DC",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02366v1",
            "title": "Towards General Purpose Vision Foundation Models for Medical Image\n  Analysis: An Experimental Study of DINOv2 on Radiology Benchmarks",
            "updated": "2023-12-04T21:47:10Z",
            "published": "2023-12-04T21:47:10Z",
            "summary": "The integration of deep learning systems into the medical domain has been\nhindered by the resource-intensive process of data annotation and the inability\nof these systems to generalize to different data distributions. Foundation\nmodels, which are models pre-trained on large datasets, have emerged as a\nsolution to reduce reliance on annotated data and enhance model\ngeneralizability and robustness. DINOv2, an open-source foundation model\npre-trained with self-supervised learning on 142 million curated natural\nimages, excels in extracting general-purpose visual representations, exhibiting\npromising capabilities across various vision tasks. Nevertheless, a critical\nquestion remains unanswered regarding DINOv2's adaptability to radiological\nimaging, and the clarity on whether its features are sufficiently general to\nbenefit radiology image analysis is yet to be established. Therefore, this\nstudy comprehensively evaluates DINOv2 for radiology, conducting over 100\nexperiments across diverse modalities (X-ray, CT, and MRI). Tasks include\ndisease classification and organ segmentation on both 2D and 3D images,\nevaluated under different settings like kNN, few-shot learning, linear-probing,\nend-to-end fine-tuning, and parameter-efficient fine-tuning, to measure the\neffectiveness and generalizability of the DINOv2 feature embeddings.\nComparative analyses with established medical image analysis models, U-Net and\nTransUnet for segmentation, and CNN and ViT models pre-trained via supervised,\nweakly supervised, and self-supervised learning for classification, reveal\nDINOv2's superior performance in segmentation tasks and competitive results in\ndisease classification. The findings contribute insights to potential avenues\nfor optimizing pre-training strategies for medical imaging and enhancing the\nbroader understanding of DINOv2's role in bridging the gap between natural and\nradiological image analysis.",
            "author": [
                "Mohammed Baharoon",
                "Waseem Qureshi",
                "Jiahong Ouyang",
                "Yanwu Xu",
                "Kilian Phol",
                "Abdulrhman Aljouie",
                "Wei Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02366v1",
                "http://arxiv.org/pdf/2312.02366v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02365v1",
            "title": "MEDPSeg: End-to-end segmentation of pulmonary structures and lesions in\n  computed tomography",
            "updated": "2023-12-04T21:46:39Z",
            "published": "2023-12-04T21:46:39Z",
            "summary": "The COVID-19 pandemic response highlighted the potential of deep learning\nmethods in facilitating the diagnosis and prognosis of lung diseases through\nautomated segmentation of normal and abnormal tissue in computed tomography\n(CT). Such methods not only have the potential to aid in clinical\ndecision-making but also contribute to the comprehension of novel diseases. In\nlight of the labor-intensive nature of manual segmentation for large chest CT\ncohorts, there is a pressing need for reliable automated approaches that enable\nefficient analysis of chest CT anatomy in vast research databases, especially\nin more scarcely annotated targets such as pneumonia consolidations. A limiting\nfactor for the development of such methods is that most current models optimize\na fixed annotation format per network output. To tackle this problem,\npolymorphic training is used to optimize a network with a fixed number of\noutput channels to represent multiple hierarchical anatomic structures,\nindirectly optimizing more complex labels with simpler annotations. We combined\nover 6000 volumetric CT scans containing varying formats of manual and\nautomated labels from different sources, and used polymorphic training along\nwith multitask learning to develop MEDPSeg, an end-to-end method for the\nsegmentation of lungs, airways, pulmonary artery, and lung lesions with\nseparation of ground glass opacities, and parenchymal consolidations, all in a\nsingle forward prediction. We achieve state-of-the-art performance in multiple\ntargets, particularly in the segmentation of ground glass opacities and\nconsolidations, a challenging problem with limited manual annotation\navailability. In addition, we provide an open-source implementation with a\ngraphical user interface at https://github.com/MICLab-Unicamp/medpseg.",
            "author": [
                "Diedre S. Carmo",
                "Jean Ribeiro",
                "Alejandro P. Comellas",
                "Joseph M. Reinhardt",
                "Sarah E. Gerard",
                "Let\u00edcia Rittner",
                "Roberto A. Lotufo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02365v1",
                "http://arxiv.org/pdf/2312.02365v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02363v1",
            "title": "General Numerical Framework to Derive Structure Preserving Reduced Order\n  Models for Thermodynamically Consistent Reversible-Irreversible PDEs",
            "updated": "2023-12-04T21:43:18Z",
            "published": "2023-12-04T21:43:18Z",
            "summary": "In this paper, we propose a general numerical framework to derive\nstructure-preserving reduced order models for thermodynamically consistent\nPDEs. Our numerical framework has two primary features: (a) a systematic way to\nextract reduced order models for thermodynamically consistent PDE systems while\nmaintaining their inherent thermodynamic principles and (b) a strategic process\nto devise accurate, efficient, and structure-preserving numerical algorithms to\nsolve the forehead reduced-order models. The platform's generality extends to\nvarious PDE systems governed by embedded thermodynamic laws. The proposed\nnumerical platform is unique from several perspectives. First, it utilizes the\ngeneralized Onsager principle to transform the thermodynamically consistent PDE\nsystem into an equivalent one, where the transformed system's free energy\nadopts a quadratic form of the state variables. This transformation is named\nenergy quadratization (EQ). Through EQ, we gain a novel perspective on deriving\nreduced order models. The reduced order models derived through our method\ncontinue to uphold the energy dissipation law. Secondly, our proposed numerical\napproach automatically provides numerical algorithms to discretize the reduced\norder models. The proposed algorithms are always linear, easy to implement and\nsolve, and uniquely solvable. Furthermore, these algorithms inherently ensure\nthe thermodynamic laws. In essence, our platform offers a distinctive approach\nto derive structure-preserving reduced-order models for a wide range of PDE\nsystems abiding by thermodynamic principles.",
            "author": [
                "Zengyan Zhang",
                "Jia Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02363v1",
                "http://arxiv.org/pdf/2312.02363v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02359v1",
            "title": "Quest Complete: the Holy Grail of Gradual Security",
            "updated": "2023-12-04T21:37:31Z",
            "published": "2023-12-04T21:37:31Z",
            "summary": "Languages with gradual information-flow control combine static and dynamic\ntechniques to prevent security leaks. Gradual languages should satisfy the\ngradual guarantee: programs that only differ in the precision of their type\nannotations should behave the same modulo cast errors. Unfortunately, Toro et\nal. [2018] identify a tension between the gradual guarantee and information\nsecurity; they were unable to satisfy both properties in the language\n$\\mathrm{GSL}_\\mathsf{Ref}$ and had to settle for only satisfying\ninformation-flow security. Azevedo de Amorim et al. [2020] show that by\nsacrificing type-guided classification, one obtains a language that satisfies\nboth noninterference and the gradual guarantee. Bichhawat et al. [2021] show\nthat both properties can be satisfied by sacrificing the no-sensitive-upgrade\nmechanism, replacing it with a static analysis.\n  In this paper we present a language design, $\\lambda_{\\mathtt{IFC}}^\\star$,\nthat satisfies both noninterference and the gradual guarantee without making\nany sacrifices. We keep the type-guided classification of\n$\\mathrm{GSL}_\\mathsf{Ref}$ and use the standard no-sensitive-upgrade mechanism\nto prevent implicit flows through mutable references. The key to the design of\n$\\lambda_{\\mathtt{IFC}}^\\star$ is to walk back the unusual decision in\n$\\mathrm{GSL}_\\mathsf{Ref}$ to include the unknown label $\\star$ among the\nruntime security labels. We mechanize the definition of\n$\\lambda_{\\mathtt{IFC}}^\\star$ in Agda and prove the gradual guarantee. On the\ntechnical side, the semantics of $\\lambda_{\\mathtt{IFC}}^\\star$ is the first\ngradual information-flow control language to be specified using coercion\ncalculi (a la Henglein), thereby expanding the coercion-based theory of gradual\ntyping.",
            "author": [
                "Tianyu Chen",
                "Jeremy G. Siek"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02359v1",
                "http://arxiv.org/pdf/2312.02359v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "68N15",
                "D.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02353v1",
            "title": "Efficient 2D Graph SLAM for Sparse Sensing",
            "updated": "2023-12-04T21:32:33Z",
            "published": "2023-12-04T21:32:33Z",
            "summary": "Simultaneous localization and mapping (SLAM) plays a vital role in mapping\nunknown spaces and aiding autonomous navigation. Virtually all state-of-the-art\nsolutions today for 2D SLAM are designed for dense and accurate sensors such as\nlaser range-finders (LiDARs). However, these sensors are not suitable for\nresource-limited nano robots, which become increasingly capable and ubiquitous\nnowadays, and these robots tend to mount economical and low-power sensors that\ncan only provide sparse and noisy measurements. This introduces a challenging\nproblem called SLAM with sparse sensing. This work addresses the problem by\nadopting the form of the state-of-the-art graph-based SLAM pipeline with a\nnovel frontend and an improvement for loop closing in the backend, both of\nwhich are designed to work with sparse and uncertain range data. Experiments\nshow that the maps constructed by our algorithm have superior quality compared\nto prior works on sparse sensing. Furthermore, our method is capable of running\nin real-time on a modern PC with an average processing time of 1/100th the\ninput interval time.",
            "author": [
                "Hanzhi Zhou",
                "Zichao Hu",
                "Sihang Liu",
                "Samira Khan"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IROS47612.2022.9981200",
                "http://arxiv.org/abs/2312.02353v1",
                "http://arxiv.org/pdf/2312.02353v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02352v1",
            "title": "Working Backwards: Learning to Place by Picking",
            "updated": "2023-12-04T21:32:00Z",
            "published": "2023-12-04T21:32:00Z",
            "summary": "We present Learning to Place by Picking (LPP), a method capable of\nautonomously collecting demonstrations for a family of placing tasks in which\nobjects must be manipulated to specific locations. With LPP, we approach the\nlearning of robotic object placement policies by reversing the grasping process\nand exploiting the inherent symmetry of the pick and place problems.\nSpecifically, we obtain placing demonstrations from a set of grasp sequences of\nobjects that are initially located at their target placement locations. Our\nsystem is capable of collecting hundreds of demonstrations without human\nintervention by using a combination of tactile sensing and compliant control\nfor grasps. We train a policy directly from visual observations through\nbehaviour cloning, using the autonomously-collected demonstrations. By doing\nso, the policy can generalize to object placement scenarios outside of the\ntraining environment without privileged information (e.g., placing a plate\npicked up from a table and not at the original placement location). We validate\nour approach on home robotic scenarios that include dishwasher loading and\ntable setting. Our approach yields robotic placing policies that outperform\npolicies trained with kinesthetic teaching, both in terms of performance and\ndata efficiency, while requiring no human supervision.",
            "author": [
                "Oliver Limoyo",
                "Abhisek Konar",
                "Trevor Ablett",
                "Jonathan Kelly",
                "Francois R. Hogan",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02352v1",
                "http://arxiv.org/pdf/2312.02352v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02345v1",
            "title": "CLIPDrawX: Primitive-based Explanations for Text Guided Sketch Synthesis",
            "updated": "2023-12-04T21:11:42Z",
            "published": "2023-12-04T21:11:42Z",
            "summary": "With the goal of understanding the visual concepts that CLIP associates with\ntext prompts, we show that the latent space of CLIP can be visualized solely in\nterms of linear transformations on simple geometric primitives like circles and\nstraight lines. Although existing approaches achieve this by\nsketch-synthesis-through-optimization, they do so on the space of B\\'ezier\ncurves, which exhibit a wastefully large set of structures that they can evolve\ninto, as most of them are non-essential for generating meaningful sketches. We\npresent CLIPDrawX, an algorithm that provides significantly better\nvisualizations for CLIP text embeddings, using only simple primitive shapes\nlike straight lines and circles. This constrains the set of possible outputs to\nlinear transformations on these primitives, thereby exhibiting an inherently\nsimpler mathematical form. The synthesis process of CLIPDrawX can be tracked\nend-to-end, with each visual concept being explained exclusively in terms of\nprimitives. Implementation will be released upon acceptance. Project Page:\n$\\href{https://clipdrawx.github.io/}{\\text{https://clipdrawx.github.io/}}$.",
            "author": [
                "Nityanand Mathur",
                "Shyam Marjit",
                "Abhra Chaudhuri",
                "Anjan Dutta"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02345v1",
                "http://arxiv.org/pdf/2312.02345v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02343v1",
            "title": "Time-based vs. Fingerprinting-based Positioning Using Artificial Neural\n  Networks",
            "updated": "2023-12-04T21:01:51Z",
            "published": "2023-12-04T21:01:51Z",
            "summary": "High-accuracy positioning has gained significant interest for many use-cases\nacross various domains such as industrial internet of things (IIoT), healthcare\nand entertainment. Radio frequency (RF) measurements are widely utilized for\nuser localization. However, challenging radio conditions such as\nnon-line-of-sight (NLOS) and multipath propagation can deteriorate the\npositioning accuracy. Machine learning (ML)-based estimators have been proposed\nto overcome these challenges. RF measurements can be utilized for positioning\nin multiple ways resulting in time-based, angle-based and fingerprinting-based\nmethods. Different methods, however, impose different implementation\nrequirements to the system, and may perform differently in terms of accuracy\nfor a given setting. In this paper, we use artificial neural networks (ANNs) to\nrealize time-of-arrival (ToA)-based and channel impulse response (CIR)\nfingerprinting-based positioning. We compare their performance for different\nindoor environments based on real-world ultra-wideband (UWB) measurements. We\nfirst show that using ML techniques helps to improve the estimation accuracy\ncompared to conventional techniques for time-based positioning. When comparing\ntime-based and fingerprinting schemes using ANNs, we show that the favorable\nmethod in terms of positioning accuracy is different for different\nenvironments, where the accuracy is affected not only by the radio propagation\nconditions but also the density and distribution of reference user locations\nused for fingerprinting.",
            "author": [
                "Anil Kirmaz",
                "Taylan Sahin",
                "Diomidis S. Michalopoulos",
                "Wolfgang Gerstacker"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02343v1",
                "http://arxiv.org/pdf/2312.02343v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02337v1",
            "title": "Measuring Distributional Shifts in Text: The Advantage of Language\n  Model-Based Embeddings",
            "updated": "2023-12-04T20:46:48Z",
            "published": "2023-12-04T20:46:48Z",
            "summary": "An essential part of monitoring machine learning models in production is\nmeasuring input and output data drift. In this paper, we present a system for\nmeasuring distributional shifts in natural language data and highlight and\ninvestigate the potential advantage of using large language models (LLMs) for\nthis problem. Recent advancements in LLMs and their successful adoption in\ndifferent domains indicate their effectiveness in capturing semantic\nrelationships for solving various natural language processing problems. The\npower of LLMs comes largely from the encodings (embeddings) generated in the\nhidden layers of the corresponding neural network. First we propose a\nclustering-based algorithm for measuring distributional shifts in text data by\nexploiting such embeddings. Then we study the effectiveness of our approach\nwhen applied to text embeddings generated by both LLMs and classical embedding\nalgorithms. Our experiments show that general-purpose LLM-based embeddings\nprovide a high sensitivity to data drift compared to other embedding methods.\nWe propose drift sensitivity as an important evaluation metric to consider when\ncomparing language models. Finally, we present insights and lessons learned\nfrom deploying our framework as part of the Fiddler ML Monitoring platform over\na period of 18 months.",
            "author": [
                "Gyandev Gupta",
                "Bashir Rastegarpanah",
                "Amalendu Iyer",
                "Joshua Rubin",
                "Krishnaram Kenthapadi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02337v1",
                "http://arxiv.org/pdf/2312.02337v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02335v1",
            "title": "Role of shape in particle-lipid membrane interactions: from surfing to\n  full engulfment",
            "updated": "2023-12-04T20:42:59Z",
            "published": "2023-12-04T20:42:59Z",
            "summary": "Understanding and manipulating the interactions between foreign bodies and\ncell membranes during endo- and phagocytosis is of paramount importance, not\nonly for the fate of living cells but also for numerous biomedical\napplications. This study aims to elucidate the role of variables such as\nanisotropic particle shape, curvature, orientation, membrane tension, and\nadhesive strength in this essential process, using a minimal experimental\nbiomimetic system comprising giant unilamellar vesicles and rod-like particles\nwith different curvatures and aspect ratios. We find that the particle wrapping\nprocess is dictated by the balance between the elastic energy penalty and\nadhesion energy gain, leading to two distinct engulfment pathways, tip-first\nand side-first, emphasizing the significance of the particle orientation in\ndetermining the pathway. Moreover, our experimental results are consistent with\ntheoretical predictions in a state diagram, showcasing how to control the\nwrapping pathway from surfing to partial to complete wrapping by the interplay\nbetween membrane tension and adhesive strength. At moderate particle\nconcentrations, we observed the formation of rod clusters, which exhibited\ncooperative and sequential wrapping. Our study not only contributes to a\ncomprehensive understanding of the mechanistic intricacies of endocytosis by\nhighlighting how the interplay between the anisotropic particle shape,\ncurvature, orientation, membrane tension, and adhesive strength can influence\nthe engulfment pathway but also provides a foundational base for future\nresearch in the field.",
            "author": [
                "Stijn van der Ham",
                "Jaime Agudo-Canalejo",
                "Hanumantha Rao Vutukuri"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02335v1",
                "http://arxiv.org/pdf/2312.02335v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02334v1",
            "title": "An Evaluation Framework for Mapping News Headlines to Event Classes in a\n  Knowledge Graph",
            "updated": "2023-12-04T20:42:26Z",
            "published": "2023-12-04T20:42:26Z",
            "summary": "Mapping ongoing news headlines to event-related classes in a rich knowledge\nbase can be an important component in a knowledge-based event analysis and\nforecasting solution. In this paper, we present a methodology for creating a\nbenchmark dataset of news headlines mapped to event classes in Wikidata, and\nresources for the evaluation of methods that perform the mapping. We use the\ndataset to study two classes of unsupervised methods for this task: 1)\nadaptations of classic entity linking methods, and 2) methods that treat the\nproblem as a zero-shot text classification problem. For the first approach, we\nevaluate off-the-shelf entity linking systems. For the second approach, we\nexplore a) pre-trained natural language inference (NLI) models, and b)\npre-trained large generative language models. We present the results of our\nevaluation, lessons learned, and directions for future work. The dataset and\nscripts for evaluation are made publicly available.",
            "author": [
                "Steve Fonin Mbouadeu",
                "Martin Lorenzo",
                "Ken Barker",
                "Oktie Hassanzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02334v1",
                "http://arxiv.org/pdf/2312.02334v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03011v1",
            "title": "InstructBooth: Instruction-following Personalized Text-to-Image\n  Generation",
            "updated": "2023-12-04T20:34:46Z",
            "published": "2023-12-04T20:34:46Z",
            "summary": "Personalizing text-to-image models using a limited set of images for a\nspecific object has been explored in subject-specific image generation.\nHowever, existing methods often encounter challenges in aligning with text\nprompts due to overfitting to the limited training images. In this work, we\nintroduce InstructBooth, a novel method designed to enhance image-text\nalignment in personalized text-to-image models. Our approach first personalizes\ntext-to-image models with a small number of subject-specific images using a\nunique identifier. After personalization, we fine-tune personalized\ntext-to-image models using reinforcement learning to maximize a reward that\nquantifies image-text alignment. Additionally, we propose complementary\ntechniques to increase the synergy between these two processes. Our method\ndemonstrates superior image-text alignment compared to baselines while\nmaintaining personalization ability. In human evaluations, InstructBooth\noutperforms DreamBooth when considering all comprehensive factors.",
            "author": [
                "Daewon Chae",
                "Nokyung Park",
                "Jinkyu Kim",
                "Kimin Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03011v1",
                "http://arxiv.org/pdf/2312.03011v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02331v1",
            "title": "Revisiting Topic-Guided Language Models",
            "updated": "2023-12-04T20:33:24Z",
            "published": "2023-12-04T20:33:24Z",
            "summary": "A recent line of work in natural language processing has aimed to combine\nlanguage models and topic models. These topic-guided language models augment\nneural language models with topic models, unsupervised learning methods that\ncan discover document-level patterns of word use. This paper compares the\neffectiveness of these methods in a standardized setting. We study four\ntopic-guided language models and two baselines, evaluating the held-out\npredictive performance of each model on four corpora. Surprisingly, we find\nthat none of these methods outperform a standard LSTM language model baseline,\nand most fail to learn good topics. Further, we train a probe of the neural\nlanguage model that shows that the baseline's hidden states already encode\ntopic information. We make public all code used for this study.",
            "author": [
                "Carolina Zheng",
                "Keyon Vafa",
                "David M. Blei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02331v1",
                "http://arxiv.org/pdf/2312.02331v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02321v1",
            "title": "Reorganization energy from charge transport measurements in a\n  monolithically$-$integrated molecular device",
            "updated": "2023-12-04T20:07:00Z",
            "published": "2023-12-04T20:07:00Z",
            "summary": "Intermolecular charge transfer reactions are key processes in physical\nchemistry. The electron-transfer rates depend on a few system's parameters,\nsuch as temperature, electromagnetic field, distance between adsorbates and,\nespecially, the molecular reorganization energy. This microscopic greatness is\nthe energetic cost to rearrange each single$-$molecule and its surrounding\nenvironment when a charge is transferred. Reorganization energies are measured\nby electrochemistry and spectroscopy techniques as well as at the\nsingle-molecule limit using atomic force microscopy approaches, but not from\ntemperature$-$dependent charge transport measurements nor in a\nmonolithically$-$integrated molecular device. Nowadays self$-$rolling\nnanomembrane (rNM) devices, with strain$-$engineered mechanical properties,\non$-$a$-$chip monolithic integration, and operable in distinct environments,\novercome those challenges. Here, we investigate the charge transfer reactions\noccurring within a ca. 6 nm thick copper$-$phthalocyanine (CuPc) film employed\nas electrode-spacer in a monolithically integrated nanocapacitor. Employing the\nrNM technology allows us to measure the molecules' charge$-$transport\ndependence on temperature for different electric fields. Thereby, the CuPc\nreorganization energy is determined as (930 $\\pm$ 40) meV, whereas density\nfunctional theory (DFT) calculations support our findings with the atomistic\npicture of the CuPc charge transfer reaction. Our approach presents a\nconsistent route towards electron transfer reaction characterization using\ncurrent$-$voltage spectroscopy and provides insight into the role of the\nmolecular reorganization energy when it comes to electrochemical nanodevices.",
            "author": [
                "Leandro Merces",
                "Grazi\u00e2ni Candiotto",
                "Let\u00edcia M. M. Ferro",
                "Anerise de Barros",
                "Carlos V. S. Batista",
                "Ali Nawaz",
                "Antonio Riul Jr",
                "Rodrigo B. Capaz",
                "Carlos C. Bof Bufon"
            ],
            "link": [
                "http://dx.doi.org/10.1002/smll.202103897",
                "http://arxiv.org/abs/2312.02321v1",
                "http://arxiv.org/pdf/2312.02321v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02319v1",
            "title": "Kernel Diffusion: An Alternate Approach to Blind Deconvolution",
            "updated": "2023-12-04T20:00:22Z",
            "published": "2023-12-04T20:00:22Z",
            "summary": "Blind deconvolution problems are severely ill-posed because neither the\nunderlying signal nor the forward operator are not known exactly.\nConventionally, these problems are solved by alternating between estimation of\nthe image and kernel while keeping the other fixed. In this paper, we show that\nthis framework is flawed because of its tendency to get trapped in local minima\nand, instead, suggest the use of a kernel estimation strategy with a non-blind\nsolver. This framework is employed by a diffusion method which is trained to\nsample the blur kernel from the conditional distribution with guidance from a\npre-trained non-blind solver. The proposed diffusion method leads to\nstate-of-the-art results on both synthetic and real blur datasets.",
            "author": [
                "Yash Sanghvi",
                "Yiheng Chi",
                "Stanley H. Chan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02319v1",
                "http://arxiv.org/pdf/2312.02319v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02317v1",
            "title": "GNN2R: Weakly-Supervised Rationale-Providing Question Answering over\n  Knowledge Graphs",
            "updated": "2023-12-04T19:58:07Z",
            "published": "2023-12-04T19:58:07Z",
            "summary": "Most current methods for multi-hop question answering (QA) over knowledge\ngraphs (KGs) only provide final conclusive answers without explanations, such\nas a set of KG entities that is difficult for normal users to review and\ncomprehend. This issue severely limits the application of KG-based QA in\nreal-world scenarios. However, it is non-trivial to solve due to two\nchallenges: First, annotations of reasoning chains of multi-hop questions,\nwhich could serve as supervision for explanation generation, are usually\nlacking. Second, it is difficult to maintain high efficiency when explicit KG\ntriples need to be retrieved to generate explanations. In this paper, we\npropose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to\nsolve this issue. GNN2R can provide both final answers and reasoning subgraphs\nas a rationale behind final answers efficiently with only weak supervision that\nis available through question-final answer pairs. We extensively evaluated\nGNN2R with detailed analyses in experiments. The results demonstrate that, in\nterms of effectiveness, efficiency, and quality of generated explanations,\nGNN2R outperforms existing state-of-the-art methods that are applicable to this\ntask. Our code and pre-trained models are available at\nhttps://github.com/ruijie-wang-uzh/GNN2R.",
            "author": [
                "Ruijie Wang",
                "Luca Rossetto",
                "Michael Cochez",
                "Abraham Bernstein"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02317v1",
                "http://arxiv.org/pdf/2312.02317v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02315v1",
            "title": "Hydrogen induces chiral conduction channels in the topological magnet",
            "updated": "2023-12-04T19:56:44Z",
            "published": "2023-12-04T19:56:44Z",
            "summary": "Chirality, a characteristic handedness that distinguishes 'left' from\n'right', cuts widely across all of nature$^1$, from the structure of DNA$^2$ to\nopposite chirality of particles and antiparticles$^3$. In condensed matter\nchiral fermions have been identified in Weyl semimetals$^4$ through their\nunconventional electrodynamics arising from 'axial' charge imbalance between\nchiral Weyl nodes of topologically nontrivial electronic bands. Up to now it\nhas been challenging or impossible to create transport channels of Weyl\nfermions in a single material that could be easily configured for advancing\nchiral logic or spintronics$^{5,6}$. Here we generate chirality-directed\nconduction channels in inversion-symmetric Weyl ferromagnet (FM) $MnSb_2Te_4$,\nemergent from a deep connection between chirality in reciprocal and real space.\nWe alter the bandstructure on-demand with an intake and a subsequent release of\nionic hydrogen ($H^+$) $-$ a process we show to induce the tilt and rotation of\nWeyl bands. The transformed Weyl FM states feature a doubled Curie temperature\n$\\geq50K$ and an enhanced angular transport chirality synchronous with a rare\nfield-antisymmetric longitudinal resistance $-$ a low-field tunable 'chiral\nswitch' that roots in the interplay of Berry curvature$^7$, chiral anomaly$^8$\nand hydrogen-engendered mutation of Weyl nodes.",
            "author": [
                "Afrin N. Tamanna",
                "Ayesha Lakra",
                "Xiaxin Ding",
                "Entela Buzi",
                "Kyungwha Park",
                "Kamil Sobczak",
                "Haiming Deng",
                "Gargee Sharma",
                "Sumanta Tewari",
                "Lia Krusin-Elbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02315v1",
                "http://arxiv.org/pdf/2312.02315v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02314v1",
            "title": "Fine-tuning pre-trained extractive QA models for clinical document\n  parsing",
            "updated": "2023-12-04T19:52:56Z",
            "published": "2023-12-04T19:52:56Z",
            "summary": "Electronic health records (EHRs) contain a vast amount of high-dimensional\nmulti-modal data that can accurately represent a patient's medical history.\nUnfortunately, most of this data is either unstructured or semi-structured,\nrendering it unsuitable for real-time and retrospective analyses. A remote\npatient monitoring (RPM) program for Heart Failure (HF) patients needs to have\naccess to clinical markers like EF (Ejection Fraction) or LVEF (Left\nVentricular Ejection Fraction) in order to ascertain eligibility and\nappropriateness for the program. This paper explains a system that can parse\nechocardiogram reports and verify EF values. This system helps identify\neligible HF patients who can be enrolled in such a program. At the heart of\nthis system is a pre-trained extractive QA transformer model that is fine-tuned\non custom-labeled data. The methods used to prepare such a model for deployment\nare illustrated by running experiments on a public clinical dataset like\nMIMIC-IV-Note. The pipeline can be used to generalize solutions to similar\nproblems in a low-resource setting. We found that the system saved over 1500\nhours for our clinicians over 12 months by automating the task at scale.",
            "author": [
                "Ashwyn Sharma",
                "David I. Feldman",
                "Aneesh Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02314v1",
                "http://arxiv.org/pdf/2312.02314v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02310v1",
            "title": "VaQuitA: Enhancing Alignment in LLM-Assisted Video Understanding",
            "updated": "2023-12-04T19:48:02Z",
            "published": "2023-12-04T19:48:02Z",
            "summary": "Recent advancements in language-model-based video understanding have been\nprogressing at a remarkable pace, spurred by the introduction of Large Language\nModels (LLMs). However, the focus of prior research has been predominantly on\ndevising a projection layer that maps video features to tokens, an approach\nthat is both rudimentary and inefficient. In our study, we introduce a\ncutting-edge framework, VaQuitA, designed to refine the synergy between video\nand textual information. At the data level, instead of sampling frames\nuniformly, we implement a sampling method guided by CLIP-score rankings, which\nenables a more aligned selection of frames with the given question. At the\nfeature level, we integrate a trainable Video Perceiver alongside a\nVisual-Query Transformer (abbreviated as VQ-Former), which bolsters the\ninterplay between the input question and the video features. We also discover\nthat incorporating a simple prompt, \"Please be critical\", into the LLM input\ncan substantially enhance its video comprehension capabilities. Our\nexperimental results indicate that VaQuitA consistently sets a new benchmark\nfor zero-shot video question-answering tasks and is adept at producing\nhigh-quality, multi-turn video dialogues with users.",
            "author": [
                "Yizhou Wang",
                "Ruiyi Zhang",
                "Haoliang Wang",
                "Uttaran Bhattacharya",
                "Yun Fu",
                "Gang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02310v1",
                "http://arxiv.org/pdf/2312.02310v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02309v1",
            "title": "Training Reinforcement Learning Agents and Humans With\n  Difficulty-Conditioned Generators",
            "updated": "2023-12-04T19:45:06Z",
            "published": "2023-12-04T19:45:06Z",
            "summary": "We adapt Parameterized Environment Response Model (PERM), a method for\ntraining both Reinforcement Learning (RL) Agents and human learners in\nparameterized environments by directly modeling difficulty and ability.\nInspired by Item Response Theory (IRT), PERM aligns environment difficulty with\nindividual ability, creating a Zone of Proximal Development-based curriculum.\nRemarkably, PERM operates without real-time RL updates and allows for offline\ntraining, ensuring its adaptability across diverse students. We present a\ntwo-stage training process that capitalizes on PERM's adaptability, and\ndemonstrate its effectiveness in training RL agents and humans in an empirical\nstudy.",
            "author": [
                "Sidney Tio",
                "Jimmy Ho",
                "Pradeep Varakantham"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02309v1",
                "http://arxiv.org/pdf/2312.02309v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02308v1",
            "title": "AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse\n  Catalysts Design",
            "updated": "2023-12-04T19:44:04Z",
            "published": "2023-12-04T19:44:04Z",
            "summary": "A central challenge of the clean energy transition is the development of\ncatalysts for low-emissions technologies. Recent advances in Machine Learning\nfor quantum chemistry drastically accelerate the computation of catalytic\nactivity descriptors such as adsorption energies. Here we introduce AdsorbRL, a\nDeep Reinforcement Learning agent aiming to identify potential catalysts given\na multi-objective binding energy target, trained using offline learning on the\nOpen Catalyst 2020 and Materials Project data sets. We experiment with Deep\nQ-Network agents to traverse the space of all ~160,000 possible unary, binary\nand ternary compounds of 55 chemical elements, with very sparse rewards based\non adsorption energy known for only between 2,000 and 3,000 catalysts per\nadsorbate. To constrain the actions space, we introduce Random Edge Traversal\nand train a single-objective DQN agent on the known states subgraph, which we\nfind strengthens target binding energy by an average of 4.1 eV. We extend this\napproach to multi-objective, goal-conditioned learning, and train a DQN agent\nto identify materials with the highest (respectively lowest) adsorption\nenergies for multiple simultaneous target adsorbates. We experiment with\nObjective Sub-Sampling, a novel training scheme aimed at encouraging\nexploration in the multi-objective setup, and demonstrate simultaneous\nadsorption energy improvement across all target adsorbates, by an average of\n0.8 eV. Overall, our results suggest strong potential for Deep Reinforcement\nLearning applied to the inverse catalysts design problem.",
            "author": [
                "Romain Lacombe",
                "Lucas Hendren",
                "Khalid El-Awady"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02308v1",
                "http://arxiv.org/pdf/2312.02308v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02305v1",
            "title": "Effects of a mixed reality headset on the delay of visually evoked\n  potentials",
            "updated": "2023-12-04T19:39:32Z",
            "published": "2023-12-04T19:39:32Z",
            "summary": "Virtual and mixed reality (VR, MR) technologies offer a powerful solution for\non-the-ground flight training curricula. While these technologies offer safer\nand cheaper instructional programs, it is still unclear how they impact\nneuronal brain dynamics. Indeed, MR simulations engage students in a strange\nmix of incongruous visual, somatosensory and vestibular sensory input.\nCharacterizing brain dynamics during MR simulation is important for\nunderstanding cognitive processes during virtual flight training. To this end,\nwe studies the delays introduced in the neuronal stream from the retina to the\nvisual cortex when presented with visual stimuli using a Varjo-XR3 headset. We\nrecorded cortical visual evoked potentials (VEPs) from 6 subjects under two\nconditions. First, we recorded normal VEPs triggered by short flashes. Second,\nwe recorded VEPs triggered by an internal image of the flashes produced by the\nVarjo-XR3 headset. All subjects had used the headset before and were familiar\nwith immersive experiences. Our results show mixed-reality stimulation imposes\na small, but consistent, 4 [ms] processing delay in the N2-VEP component during\nMR stimulation as compared to direct stimulation. Also we found that VEP\namplitudes during MR stimulation were also decreased. These results suggest\nthat visual cognition during mixed-reality training is delayed, not only by the\nunavoidalbe hardware/software processing delays of the headset and the attached\ncomputer, but also by an extra biological delay induced by the headset's\nlimited visual display in terms of the image intensity and contrast. As flight\ntraining is a demanding task, this study measures visual signal latency to\nbetter understand how MR affects the sensation of immersion.",
            "author": [
                "V\u00edctor Manuel Hidalgo",
                "Carlos Andr\u00e9s Bazaes",
                "Juan-Carlos Letelier"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02305v1",
                "http://arxiv.org/pdf/2312.02305v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02304v1",
            "title": "Numerical Analysis of a Highly Sensitive SOI MRR Refractive Index Sensor\n  with Performance Enhancement using Graphene and Gold",
            "updated": "2023-12-04T19:39:28Z",
            "published": "2023-12-04T19:39:28Z",
            "summary": "This study proposes a simulation-based design for a Silicon-On-Insulator\n(SOI) ring resonator with a Figure of Merit (FOM) of 56.15 and a high\nsensitivity of up to 730 nm/RIU. The Finite-Difference Time-Domain (FDTD)\ntechnique was used to assess and evaluate the design quantitatively. Our design\ndemonstrates higher sensitivity compared to many recent studies conducted on\nSOI-based sensors. The device structure follows a conventional ring resonator\narrangement with a single waveguide, incorporating a 2D graphene layer on top\nof the SiO2 wafer and a gold nano-disc positioned at the center of the ring.\nOur findings highlight the device's susceptibility to refractive index\nvariations, making it a desirable choice for various sensing applications. We\nhave investigated the sensor's capabilities for sensing different\nconcentrations of milkmilk. Graphene and gold materials enhance the device's\nresponse to light and provide comparatively higher sensitivity. The suggested\ndesign can serve as a blueprint for device fabrication, considering the\npracticality of implementing an SOI-based device using standard techniques for\nsilicon processing.",
            "author": [
                "Tasin Intisar",
                "Ahmed Shadman Alam",
                "Ishtiaqul Hoque",
                "Md Omar Faruque"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02304v1",
                "http://arxiv.org/pdf/2312.02304v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03756v1",
            "title": "LineConGraphs: Line Conversation Graphs for Effective Emotion\n  Recognition using Graph Neural Networks",
            "updated": "2023-12-04T19:36:58Z",
            "published": "2023-12-04T19:36:58Z",
            "summary": "Emotion Recognition in Conversations (ERC) is a critical aspect of affective\ncomputing, and it has many practical applications in healthcare, education,\nchatbots, and social media platforms. Earlier approaches for ERC analysis\ninvolved modeling both speaker and long-term contextual information using graph\nneural network architectures. However, it is ideal to deploy\nspeaker-independent models for real-world applications. Additionally, long\ncontext windows can potentially create confusion in recognizing the emotion of\nan utterance in a conversation. To overcome these limitations, we propose novel\nline conversation graph convolutional network (LineConGCN) and graph attention\n(LineConGAT) models for ERC analysis. These models are speaker-independent and\nbuilt using a graph construction strategy for conversations -- line\nconversation graphs (LineConGraphs). The conversational context in\nLineConGraphs is short-term -- limited to one previous and future utterance,\nand speaker information is not part of the graph. We evaluate the performance\nof our proposed models on two benchmark datasets, IEMOCAP and MELD, and show\nthat our LineConGAT model outperforms the state-of-the-art methods with an\nF1-score of 64.58% and 76.50%. Moreover, we demonstrate that embedding\nsentiment shift information into line conversation graphs further enhances the\nERC performance in the case of GCN models.",
            "author": [
                "Gokul S Krishnan",
                "Sarala Padi",
                "Craig S. Greenberg",
                "Balaraman Ravindran",
                "Dinesh Manoch",
                "Ram D. Sriram"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03756v1",
                "http://arxiv.org/pdf/2312.03756v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02301v1",
            "title": "Aerosols are not Spherical Cows: Using Discrete Dipole Approximation to\n  Model the Properties of Fractal Particles",
            "updated": "2023-12-04T19:34:43Z",
            "published": "2023-12-04T19:34:43Z",
            "summary": "The optical properties of particulate-matter aerosols, within the context of\nexoplanet and brown dwarf atmospheres, are compared using three different\nmodels: Mie theory, Modified Mean Field (MMF) Theory, and Discrete Dipole\nApproximation (DDA). Previous results have demonstrated that fractal haze\nparticles (MMF and DDA) absorb much less long-wavelength radiation than their\nspherical counterparts (Mie), however it is shown here that the opposite can\nalso be true if a more varying refractive index profile is used. Additionally,\nit is demonstrated that absorption and scattering cross-sections, as well as\nthe asymmetry parameter, are underestimated if Mie theory is used. Although DDA\ncan be used to obtain more accurate results, it is known to be much more\ncomputationally intensive; to avoid this, the use of low-resolution aerosol\nmodels is explored, which could dramatically speed up the process of obtaining\naccurate computations of optical cross-sections within a certain parameter\nspace. The validity of DDA is probed for wavelengths of interest for\nobservations of aerosols within exoplanet and brown dwarf atmospheres (0.2 to\n15 micrometres). Finally, novel code is presented to compare the results of\nMie, MMF and DDA theories (CORAL: Comparison Of Radiative AnaLyses), as well as\nto increase and decrease the resolution of DDA shape files accordingly\n(SPHERIFY). Both codes can be applied to a range of other interesting\nastrophysical environments in addition to exoplanet atmospheres, for example\ndust grains within protoplanetary disks.",
            "author": [
                "Matt G. Lodge",
                "Hannah R. Wakeford",
                "Zoe M. Leinhardt"
            ],
            "link": [
                "http://dx.doi.org/10.1093/mnras/stad3743",
                "http://arxiv.org/abs/2312.02301v1",
                "http://arxiv.org/pdf/2312.02301v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02300v1",
            "title": "Reconsideration on evaluation of machine learning models in continuous\n  monitoring using wearables",
            "updated": "2023-12-04T19:34:08Z",
            "published": "2023-12-04T19:34:08Z",
            "summary": "This paper explores the challenges in evaluating machine learning (ML) models\nfor continuous health monitoring using wearable devices beyond conventional\nmetrics. We state the complexities posed by real-world variability, disease\ndynamics, user-specific characteristics, and the prevalence of false\nnotifications, necessitating novel evaluation strategies. Drawing insights from\nlarge-scale heart studies, the paper offers a comprehensive guideline for\nrobust ML model evaluation on continuous health monitoring.",
            "author": [
                "Cheng Ding",
                "Zhicheng Guo",
                "Cynthia Rudin",
                "Ran Xiao",
                "Fadi B Nahab",
                "Xiao Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02300v1",
                "http://arxiv.org/pdf/2312.02300v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02299v1",
            "title": "Cotton Yield Prediction Using Random Forest",
            "updated": "2023-12-04T19:33:29Z",
            "published": "2023-12-04T19:33:29Z",
            "summary": "The cotton industry in the United States is committed to sustainable\nproduction practices that minimize water, land, and energy use while improving\nsoil health and cotton output. Climate-smart agricultural technologies are\nbeing developed to boost yields while decreasing operating expenses. Crop yield\nprediction, on the other hand, is difficult because of the complex and\nnonlinear impacts of cultivar, soil type, management, pest and disease,\nclimate, and weather patterns on crops. To solve this issue, we employ machine\nlearning (ML) to forecast production while considering climate change, soil\ndiversity, cultivar, and inorganic nitrogen levels. From the 1980s to the\n1990s, field data were gathered across the southern cotton belt of the United\nStates. To capture the most current effects of climate change over the previous\nsix years, a second data source was produced using the process-based crop\nmodel, GOSSYM. We concentrated our efforts on three distinct areas inside each\nof the three southern states: Texas, Mississippi, and Georgia. To simplify the\namount of computations, accumulated heat units (AHU) for each set of\nexperimental data were employed as an analogy to use time-series weather data.\nThe Random Forest Regressor yielded a 97.75% accuracy rate, with a root mean\nsquare error of 55.05 kg/ha and an R2 of around 0.98. These findings\ndemonstrate how an ML technique may be developed and applied as a reliable and\neasy-to-use model to support the cotton climate-smart initiative.",
            "author": [
                "Alakananda Mitra",
                "Sahila Beegum",
                "David Fleisher",
                "Vangimalla R. Reddy",
                "Wenguang Sun",
                "Chittaranjan Ray",
                "Dennis Timlin",
                "Arindam Malakar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02299v1",
                "http://arxiv.org/pdf/2312.02299v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02298v1",
            "title": "MoE-AMC: Enhancing Automatic Modulation Classification Performance Using\n  Mixture-of-Experts",
            "updated": "2023-12-04T19:31:15Z",
            "published": "2023-12-04T19:31:15Z",
            "summary": "Automatic Modulation Classification (AMC) plays a vital role in time series\nanalysis, such as signal classification and identification within wireless\ncommunications. Deep learning-based AMC models have demonstrated significant\npotential in this domain. However, current AMC models inadequately consider the\ndisparities in handling signals under conditions of low and high\nSignal-to-Noise Ratio (SNR), resulting in an unevenness in their performance.\nIn this study, we propose MoE-AMC, a novel Mixture-of-Experts (MoE) based model\nspecifically crafted to address AMC in a well-balanced manner across varying\nSNR conditions. Utilizing the MoE framework, MoE-AMC seamlessly combines the\nstrengths of LSRM (a Transformer-based model) for handling low SNR signals and\nHSRM (a ResNet-based model) for high SNR signals. This integration empowers\nMoE-AMC to achieve leading performance in modulation classification, showcasing\nits efficacy in capturing distinctive signal features under diverse SNR\nscenarios. We conducted experiments using the RML2018.01a dataset, where\nMoE-AMC achieved an average classification accuracy of 71.76% across different\nSNR levels, surpassing the performance of previous SOTA models by nearly 10%.\nThis study represents a pioneering application of MoE techniques in the realm\nof AMC, offering a promising avenue for elevating signal classification\naccuracy within wireless communication systems.",
            "author": [
                "Jiaxin Gao",
                "Qinglong Cao",
                "Yuntian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02298v1",
                "http://arxiv.org/pdf/2312.02298v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02296v1",
            "title": "LLMs Accelerate Annotation for Medical Information Extraction",
            "updated": "2023-12-04T19:26:13Z",
            "published": "2023-12-04T19:26:13Z",
            "summary": "The unstructured nature of clinical notes within electronic health records\noften conceals vital patient-related information, making it challenging to\naccess or interpret. To uncover this hidden information, specialized Natural\nLanguage Processing (NLP) models are required. However, training these models\nnecessitates large amounts of labeled data, a process that is both\ntime-consuming and costly when relying solely on human experts for annotation.\nIn this paper, we propose an approach that combines Large Language Models\n(LLMs) with human expertise to create an efficient method for generating ground\ntruth labels for medical text annotation. By utilizing LLMs in conjunction with\nhuman annotators, we significantly reduce the human annotation burden, enabling\nthe rapid creation of labeled datasets. We rigorously evaluate our method on a\nmedical information extraction task, demonstrating that our approach not only\nsubstantially cuts down on human intervention but also maintains high accuracy.\nThe results highlight the potential of using LLMs to improve the utilization of\nunstructured clinical data, allowing for the swift deployment of tailored NLP\nsolutions in healthcare.",
            "author": [
                "Akshay Goel",
                "Almog Gueta",
                "Omry Gilon",
                "Chang Liu",
                "Sofia Erell",
                "Lan Huong Nguyen",
                "Xiaohong Hao",
                "Bolous Jaber",
                "Shashir Reddy",
                "Rupesh Kartha",
                "Jean Steiner",
                "Itay Laish",
                "Amir Feder"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02296v1",
                "http://arxiv.org/pdf/2312.02296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02295v1",
            "title": "Higher Memory Effects in Numerical Simulations of Binary Black Hole\n  Mergers",
            "updated": "2023-12-04T19:18:51Z",
            "published": "2023-12-04T19:18:51Z",
            "summary": "Gravitational memory effects are predictions of general relativity that are\ncharacterized by an observable effect that persists after the passage of\ngravitational waves. In recent years, they have garnered particular interest,\nboth due to their connection to asymptotic symmetries and soft theorems and\nbecause their observation would serve as a unique test of the nonlinear nature\nof general relativity. Apart from the more commonly known displacement and spin\nmemories, however, there are other memory effects predicted by Einstein's\nequations that are associated with more subleading terms in the asymptotic\nexpansion of the Bondi-Sachs metric. In this paper, we write explicit\nexpressions for these higher memory effects in terms of their charge and flux\ncontributions. Further, by using a numerical relativity simulation of a binary\nblack hole merger, we compute the magnitude and morphology of these terms and\ncompare them to those of the displacement and spin memory. We find that,\nalthough these terms are interesting from a theoretical perspective, due to\ntheir small magnitude they will be particularly challenging to observe with\ncurrent and future detectors.",
            "author": [
                "Alexander M. Grant",
                "Keefe Mitman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02295v1",
                "http://arxiv.org/pdf/2312.02295v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02292v2",
            "title": "de Sitter local thermodynamics in $f(R)$ gravity",
            "updated": "2023-12-06T13:12:17Z",
            "published": "2023-12-04T19:13:35Z",
            "summary": "We consider the local thermodynamics of the de Sitter state in the $f({\\cal\nR})$ gravity. The local temperature, which is the same for all points of the de\nSitter space, is $T=H/\\pi$, where $H$ is the Hubble parameter. It is twice\nlarger than the Gibbons-Hawking temperature of the cosmological horizon,\n$T_{\\rm GH}=H/2\\pi$. The local temperature is not related to the cosmological\nhorizon. It determines the rate of the activation processes, which are possible\nin the de Sitter environment. The typical example is the process of the\nionization of the atom in the de Sitter environment, which rate is determined\nby temperature $T=H/\\pi$. The local temperature determines the local entropy of\nthe de Sitter vacuum state, and this allows to calculate the total entropy\ninside the cosmological horizon. The result reproduces the Gibbons-Hawking area\nlaw, $S_{\\rm hor}=4\\pi KA$. But in the $f({\\cal R})$ theory it is the Wald\nentropy, which is determined by the effective gravitational coupling\n$K=df/d{\\cal R}$. In the local thermodynamic approach, $K$ is the thermodynamic\nvariable, which is conjugate to the Ricci scalar curvature ${\\cal R}$. The\nagreement with the Wald entropy supports the suggestion that the de Sitter\nquantum vacuum is characterized by the local thermodynamics of the quantum\nvacuum with the local temperature $T=H/\\pi$.",
            "author": [
                "G. E. Volovik"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02292v2",
                "http://arxiv.org/pdf/2312.02292v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "cond-mat.other"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02287v1",
            "title": "331 Models and Bilepton Searches at LHC",
            "updated": "2023-12-04T19:05:24Z",
            "published": "2023-12-04T19:05:24Z",
            "summary": "Despite being remarkable predictive, the Standard Model leaves unanswered\nseveral important issues, which motivate an ongoing search for its extensions.\nOne fashionable possibility are the so-called 331 models, where the electroweak\ngauge group is extended to $SU_L(3)\\times U(1)$. We discuss these models and\nprovide a classification. As a second step, we focus on a minimal extension\nwhich includes vector-like quarks (VLQs) and new gauge bosons. We investigate\nthe phenomenology and perform a consistent analysis of the production at the\nLHC of a pair of doubly charged bileptons, including processes where VLQs\ncontribute, and in particular the associate production VLQ-bilepton. Finally,\nwe extract the bound on the bilepton mass, $m_Y>$ 1300 GeV, from a\nreinterpretation of a recent ATLAS search for doubly-charged Higgs bosons in\nmulti-lepton final states.",
            "author": [
                "Roberta Calabrese",
                "Alberto Orso Maria Iorio",
                "Stefano Morisi",
                "Giulia Ricciardi",
                "Natascia Vignaroli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02287v1",
                "http://arxiv.org/pdf/2312.02287v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02285v1",
            "title": "Axiomatizing modal inclusion logic and its variants",
            "updated": "2023-12-04T19:03:31Z",
            "published": "2023-12-04T19:03:31Z",
            "summary": "We provide a complete axiomatization of modal inclusion logic - team-based\nmodal logic extended with inclusion atoms. We review and refine an expressive\ncompleteness and normal form theorem for the logic, define a natural deduction\nproof system, and use the normal form to prove completeness of the\naxiomatization. Complete axiomatizations are also provided for two other\nextensions of modal logic with the same expressive power as modal inclusion\nlogic: one augmented with a might operator and the other with a single-world\nvariant of the might operator.",
            "author": [
                "Aleksi Anttila",
                "Matilda H\u00e4ggblom",
                "Fan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02285v1",
                "http://arxiv.org/pdf/2312.02285v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "03B60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02284v1",
            "title": "PatchFusion: An End-to-End Tile-Based Framework for High-Resolution\n  Monocular Metric Depth Estimation",
            "updated": "2023-12-04T19:03:12Z",
            "published": "2023-12-04T19:03:12Z",
            "summary": "Single image depth estimation is a foundational task in computer vision and\ngenerative modeling. However, prevailing depth estimation models grapple with\naccommodating the increasing resolutions commonplace in today's consumer\ncameras and devices. Existing high-resolution strategies show promise, but they\noften face limitations, ranging from error propagation to the loss of\nhigh-frequency details. We present PatchFusion, a novel tile-based framework\nwith three key components to improve the current state of the art: (1) A\npatch-wise fusion network that fuses a globally-consistent coarse prediction\nwith finer, inconsistent tiled predictions via high-level feature guidance, (2)\nA Global-to-Local (G2L) module that adds vital context to the fusion network,\ndiscarding the need for patch selection heuristics, and (3) A Consistency-Aware\nTraining (CAT) and Inference (CAI) approach, emphasizing patch overlap\nconsistency and thereby eradicating the necessity for post-processing.\nExperiments on UnrealStereo4K, MVS-Synth, and Middleburry 2014 demonstrate that\nour framework can generate high-resolution depth maps with intricate details.\nPatchFusion is independent of the base model for depth estimation. Notably, our\nframework built on top of SOTA ZoeDepth brings improvements for a total of\n17.3% and 29.4% in terms of the root mean squared error (RMSE) on\nUnrealStereo4K and MVS-Synth, respectively.",
            "author": [
                "Zhenyu Li",
                "Shariq Farooq Bhat",
                "Peter Wonka"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02284v1",
                "http://arxiv.org/pdf/2312.02284v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02283v1",
            "title": "Jet reorientation in central galaxies of clusters and groups: insights\n  from VLBA and Chandra data",
            "updated": "2023-12-04T19:01:28Z",
            "published": "2023-12-04T19:01:28Z",
            "summary": "Recent observations of galaxy clusters and groups with misalignments between\ntheir central AGN jets and X-ray cavities, or with multiple misaligned\ncavities, have raised concerns about the jet - bubble connection in cooling\ncores, and the processes responsible for jet realignment. To investigate the\nfrequency and causes of such misalignments, we construct a sample of 16 cool\ncore galaxy clusters and groups. Using VLBA radio data we measure the\nparsec-scale position angle of the jets, and compare it with the position angle\nof the X-ray cavities detected in Chandra data. Using the overall sample and\nselected subsets, we consistently find that there is a 30% - 38% chance to find\na misalignment larger than $\\Delta\\Psi = 45^{\\circ}$ when observing a\ncluster/group with a detected jet and at least one cavity. We determine that\nprojection may account for an apparently large $\\Delta\\Psi$ only in a fraction\nof objects ($\\sim$35%), and given that gas dynamical disturbances (as sloshing)\nare found in both aligned and misaligned systems, we exclude environmental\nperturbation as the main driver of cavity - jet misalignment. Moreover, we find\nthat large misalignments (up to $\\sim90^{\\circ}$) are favored over smaller ones\n($45^{\\circ}\\leq\\Delta\\Psi\\leq70^{\\circ}$), and that the change in jet\ndirection can occur on timescales between one and a few tens of Myr. We\nconclude that misalignments are more likely related to actual reorientation of\nthe jet axis, and we discuss several engine-based mechanisms that may cause\nthese dramatic changes.",
            "author": [
                "Francesco Ubertosi",
                "Gerrit Schellenberger",
                "Ewan O'Sullivan",
                "Jan Vrtilek",
                "Simona Giacintucci",
                "Laurence P. David",
                "William Forman",
                "Myriam Gitti",
                "Tiziana Venturi",
                "Christine Jones",
                "Fabrizio Brighenti"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02283v1",
                "http://arxiv.org/pdf/2312.02283v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02281v1",
            "title": "Casimir Forces in CFT with Defects and Boundaries",
            "updated": "2023-12-04T19:00:57Z",
            "published": "2023-12-04T19:00:57Z",
            "summary": "We investigate the quantum forces occurring between the defects and/or\nboundaries of a conformal field theory (CFT). We propose to model imperfect\ndefects and boundaries as localized relevant double-trace operators that deform\nthe CFT. Our focus is on pointlike and codimension-one planar defects. In the\ncase of two parallel membranes, we point out that the CFT 2-point function\ntends to get confined and develops a tower of resonances with constant decay\nrate when the operator dimension approaches the free field dimension. Using a\nfunctional formalism, we compute the quantum forces induced by the CFT between\na variety of configurations of pointlike defects, infinite plates and\nmembranes. Consistency arguments imply that these quantum forces are attractive\nat any distance. Forces of Casimir-Polder type appear in the UV, while forces\nof Casimir type appear in the IR, in which case the CFT gets repelled from the\ndefects. Most of the forces behave as a non-integer power of the separation,\ncontrolled by the dimension of the double-trace deformation. In the Casimir\nregime of the membrane-membrane configuration, the quantum pressure behaves\nuniversally as $1/\\ell^d$, however information about the double-trace nature of\nthe defects still remains encoded in the strength of the pressure.",
            "author": [
                "Philippe Brax",
                "Sylvain Fichet"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02281v1",
                "http://arxiv.org/pdf/2312.02281v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02279v1",
            "title": "Quantum Optimization: Potential, Challenges, and the Path Forward",
            "updated": "2023-12-04T19:00:44Z",
            "published": "2023-12-04T19:00:44Z",
            "summary": "Recent advances in quantum computers are demonstrating the ability to solve\nproblems at a scale beyond brute force classical simulation. As such, a\nwidespread interest in quantum algorithms has developed in many areas, with\noptimization being one of the most pronounced domains. Across computer science\nand physics, there are a number of algorithmic approaches, often with little\nlinkage. This is further complicated by the fragmented nature of the field of\nmathematical optimization, where major classes of optimization problems, such\nas combinatorial optimization, convex optimization, non-convex optimization,\nand stochastic extensions, have devoted communities. With these aspects in\nmind, this work draws on multiple approaches to study quantum optimization.\nProvably exact versus heuristic settings are first explained using\ncomputational complexity theory - highlighting where quantum advantage is\npossible in each context. Then, the core building blocks for quantum\noptimization algorithms are outlined to subsequently define prominent problem\nclasses and identify key open questions that, if answered, will advance the\nfield. The effects of scaling relevant problems on noisy quantum devices are\nalso outlined in detail, alongside meaningful benchmarking problems. We\nunderscore the importance of benchmarking by proposing clear metrics to conduct\nappropriate comparisons with classical optimization techniques. Lastly, we\nhighlight two domains - finance and sustainability - as rich sources of\noptimization problems that could be used to benchmark, and eventually validate,\nthe potential real-world impact of quantum optimization.",
            "author": [
                "Amira Abbas",
                "Andris Ambainis",
                "Brandon Augustino",
                "Andreas B\u00e4rtschi",
                "Harry Buhrman",
                "Carleton Coffrin",
                "Giorgio Cortiana",
                "Vedran Dunjko",
                "Daniel J. Egger",
                "Bruce G. Elmegreen",
                "Nicola Franco",
                "Filippo Fratini",
                "Bryce Fuller",
                "Julien Gacon",
                "Constantin Gonciulea",
                "Sander Gribling",
                "Swati Gupta",
                "Stuart Hadfield",
                "Raoul Heese",
                "Gerhard Kircher",
                "Thomas Kleinert",
                "Thorsten Koch",
                "Georgios Korpas",
                "Steve Lenk",
                "Jakub Marecek",
                "Vanio Markov",
                "Guglielmo Mazzola",
                "Stefano Mensa",
                "Naeimeh Mohseni",
                "Giacomo Nannicini",
                "Corey O'Meara",
                "Elena Pe\u00f1a Tapia",
                "Sebastian Pokutta",
                "Manuel Proissl",
                "Patrick Rebentrost",
                "Emre Sahin",
                "Benjamin C. B. Symons",
                "Sabine Tornow",
                "Victor Valls",
                "Stefan Woerner",
                "Mira L. Wolf-Bauwens",
                "Jon Yard",
                "Sheir Yarkoni",
                "Dirk Zechiel",
                "Sergiy Zhuk",
                "Christa Zoufal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02279v1",
                "http://arxiv.org/pdf/2312.02279v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02272v1",
            "title": "Entanglement production from scattering of fermionic wave packets: a\n  quantum computing approach",
            "updated": "2023-12-04T19:00:04Z",
            "published": "2023-12-04T19:00:04Z",
            "summary": "We propose a method to prepare Gaussian wave packets with momentum on top of\nthe interacting ground state of a fermionic Hamiltonian. Using Givens rotation,\nwe show how to efficiently obtain expectation values of observables throughout\nthe evolution of the wave packets on digital quantum computers. We demonstrate\nour technique by applying it to the staggered lattice formulation of the\nThirring model and studying the scattering of two wave packets. Monitoring the\nthe particle density and the entropy produced during the scattering process, we\ncharacterize the phenomenon and provide a first step towards studying more\ncomplicated collision processes on digital quantum computers. In addition, we\nperform a small-scale demonstration on IBM's quantum hardware, showing that our\nmethod is suitable for current and near-term quantum devices.",
            "author": [
                "Yahui Chai",
                "Arianna Crippa",
                "Karl Jansen",
                "Stefan K\u00fchn",
                "Vincent R. Pascuzzi",
                "Francesco Tacchino",
                "Ivano Tavernelli"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02272v1",
                "http://arxiv.org/pdf/2312.02272v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02265v1",
            "title": "Programmable Simulations of Molecules and Materials with Reconfigurable\n  Quantum Processors",
            "updated": "2023-12-04T19:00:01Z",
            "published": "2023-12-04T19:00:01Z",
            "summary": "Simulations of quantum chemistry and quantum materials are believed to be\namong the most important potential applications of quantum information\nprocessors, but realizing practical quantum advantage for such problems is\nchallenging. Here, we introduce a simulation framework for strongly correlated\nquantum systems that can be represented by model spin Hamiltonians. Our\napproach leverages reconfigurable qubit architectures to programmably simulate\nreal-time dynamics and introduces an algorithm for extracting chemically\nrelevant spectral properties via classical co-processing of quantum measurement\nresults. We develop a digital-analog simulation toolbox for efficient\nHamiltonian time evolution utilizing digital Floquet engineering and\nhardware-optimized multi-qubit operations to accurately realize complex\nspin-spin interactions, and as an example present an implementation proposal\nbased on Rydberg atom arrays. Then, we show how detailed spectral information\ncan be extracted from these dynamics through snapshot measurements and\nsingle-ancilla control, enabling the evaluation of excitation energies and\nfinite-temperature susceptibilities from a single-dataset. To illustrate the\napproach, we show how this method can be used to compute key properties of a\npolynuclear transition-metal catalyst and 2D magnetic materials.",
            "author": [
                "Nishad Maskara",
                "Stefan Ostermann",
                "James Shee",
                "Marcin Kalinowski",
                "Abigail McClain Gomez",
                "Rodrigo Araiza Bravo",
                "Derek S. Wang",
                "Anna I. Krylov",
                "Norman Y. Yao",
                "Martin Head-Gordon",
                "Mikhail D. Lukin",
                "Susanne F. Yelin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02265v1",
                "http://arxiv.org/pdf/2312.02265v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mtrl-sci",
                "cond-mat.str-el",
                "physics.atom-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02260v1",
            "title": "Kepler-discovered Multiple-planet Systems Near Period Ratios Suggestive\n  of Mean-motion Resonances Are Young",
            "updated": "2023-12-04T19:00:00Z",
            "published": "2023-12-04T19:00:00Z",
            "summary": "Before the launch of the Kepler Space Telescope, models of low-mass planet\nformation predicted that convergent Type I migration would often produce\nsystems of low-mass planets in low-order mean-motion resonances. Instead,\nKepler discovered that systems of small planets frequently have period ratios\nlarger than those associated with mean-motion resonances and rarely have period\nratios smaller than those associated with mean-motion resonances. Both\nshort-timescale processes related to the formation or early evolution of\nplanetary systems and long-timescale secular processes have been proposed as\nexplanations for these observations. Using a thin disk stellar population's\nGalactic velocity dispersion as a relative age proxy, we find that\nKepler-discovered multiple-planet systems with at least one planet pair near a\nperiod ratio suggestive of a second-order mean-motion resonance have a colder\nGalactic velocity dispersion and are therefore younger than both\nsingle-transiting and multiple-planet systems that lack planet pairs consistent\nwith mean-motion resonances. We argue that a non-tidal secular process with a\ncharacteristic timescale no less than a few hundred Myr is responsible for\nmoving systems of low-mass planets away from second-order mean-motion\nresonances. Among systems with at least one planet pair near a period ratio\nsuggestive of a first-order mean-motion resonance, only the population of\nsystems likely affected by tidal dissipation inside their innermost planets has\na small Galactic velocity dispersion and is therefore young. We predict that\nperiod ratios suggestive of mean-motion resonances are more common in young\nsystems with 10 Myr $\\lesssim \\tau \\lesssim 100$ Myr and become less common as\nplanetary systems age.",
            "author": [
                "Jacob H. Hamer",
                "Kevin C. Schlaufman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02260v1",
                "http://arxiv.org/pdf/2312.02260v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02263v1",
            "title": "Young, wild and free: the early expansion of star clusters",
            "updated": "2023-12-04T19:00:00Z",
            "published": "2023-12-04T19:00:00Z",
            "summary": "Early expansion plays a fundamental role in the dynamical evolution of young\nstar clusters. However, until very recently most of our understanding of\ncluster expansion was based only on indirect evidence or on statistically\nlimited samples of clusters. Here we present a comprehensive kinematic analysis\nof virtually all known young ($t<300$ Myr) Galactic clusters based on the\nimproved astrometric quality of the Gaia DR3 data. Such a large sample provides\nthe unprecedented opportunity to robustly constrain the fraction of clusters\nand the timescale during which expansion has a prominent impact on the overall\nkinematics. We find that a remarkable fraction (up to $80\\%$) of clusters\nyounger than $\\sim30$ Myr is currently experiencing significant expansion,\nwhereas older systems are mostly compatible with equilibrium configurations. We\nobserve a trend where the expansion speed increases with the clustercentric\ndistance, suggesting that clusters undergoing expansion will likely lose a\nfraction of their present-day mass. Also, most young expanding clusters show\nlarge sizes, possibly due to the expansion itself. A comparison with a set of\nN-body simulations of young star clusters shows that the observed expansion\npattern is in general qualitative agreement with that found for systems\nundergoing violent relaxation and evolving toward a final virial equilibrium\nstate. However, we also note that additional processes likely associated with\nresidual gas expulsion and mass loss due to stellar evolution are also likely\nto play a key role in driving the observed expansion.",
            "author": [
                "Alessandro Della Croce",
                "Emanuele Dalessandro",
                "Alexander R. Livernois",
                "Enrico Vesperini"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02263v1",
                "http://arxiv.org/pdf/2312.02263v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02264v1",
            "title": "Scaling Laws in Jet Classification",
            "updated": "2023-12-04T19:00:00Z",
            "published": "2023-12-04T19:00:00Z",
            "summary": "We demonstrate the emergence of scaling laws in the benchmark top versus QCD\njet classification problem in collider physics. Six distinct\nphysically-motivated classifiers exhibit power-law scaling of the binary\ncross-entropy test loss as a function of training set size, with distinct power\nlaw indices. This result highlights the importance of comparing classifiers as\na function of dataset size rather than for a fixed training set, as the optimal\nclassifier may change considerably as the dataset is scaled up. We speculate on\nthe interpretation of our results in terms of previous models of scaling laws\nobserved in natural language and image datasets.",
            "author": [
                "Joshua Batson",
                "Yonatan Kahn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02264v1",
                "http://arxiv.org/pdf/2312.02264v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02156v1",
            "title": "Latent Feature-Guided Diffusion Models for Shadow Removal",
            "updated": "2023-12-04T18:59:55Z",
            "published": "2023-12-04T18:59:55Z",
            "summary": "Recovering textures under shadows has remained a challenging problem due to\nthe difficulty of inferring shadow-free scenes from shadow images. In this\npaper, we propose the use of diffusion models as they offer a promising\napproach to gradually refine the details of shadow regions during the diffusion\nprocess. Our method improves this process by conditioning on a learned latent\nfeature space that inherits the characteristics of shadow-free images, thus\navoiding the limitation of conventional methods that condition on degraded\nimages only. Additionally, we propose to alleviate potential local optima\nduring training by fusing noise features with the diffusion network. We\ndemonstrate the effectiveness of our approach which outperforms the previous\nbest method by 13% in terms of RMSE on the AISTD dataset. Further, we explore\ninstance-level shadow removal, where our model outperforms the previous best\nmethod by 82% in terms of RMSE on the DESOBA dataset.",
            "author": [
                "Kangfu Mei",
                "Luis Figueroa",
                "Zhe Lin",
                "Zhihong Ding",
                "Scott Cohen",
                "Vishal M. Patel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02156v1",
                "http://arxiv.org/pdf/2312.02156v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02153v1",
            "title": "Aligning and Prompting Everything All at Once for Universal Visual\n  Perception",
            "updated": "2023-12-04T18:59:50Z",
            "published": "2023-12-04T18:59:50Z",
            "summary": "Vision foundation models have been explored recently to build general-purpose\nvision systems. However, predominant paradigms, driven by casting\ninstance-level tasks as an object-word alignment, bring heavy cross-modality\ninteraction, which is not effective in prompting object detection and visual\ngrounding. Another line of work that focuses on pixel-level tasks often\nencounters a large annotation gap of things and stuff, and suffers from mutual\ninterference between foreground-object and background-class segmentation. In\nstark contrast to the prevailing methods, we present APE, a universal visual\nperception model for aligning and prompting everything all at once in an image\nto perform diverse tasks, i.e., detection, segmentation, and grounding, as an\ninstance-level sentence-object matching paradigm. Specifically, APE advances\nthe convergence of detection and grounding by reformulating language-guided\ngrounding as open-vocabulary detection, which efficiently scales up model\nprompting to thousands of category vocabularies and region descriptions while\nmaintaining the effectiveness of cross-modality fusion. To bridge the\ngranularity gap of different pixel-level tasks, APE equalizes semantic and\npanoptic segmentation to proxy instance learning by considering any isolated\nregions as individual instances. APE aligns vision and language representation\non broad data with natural and challenging characteristics all at once without\ntask-specific fine-tuning. The extensive experiments on over 160 datasets\ndemonstrate that, with only one-suit of weights, APE outperforms (or is on par\nwith) the state-of-the-art models, proving that an effective yet universal\nperception for anything aligning and prompting is indeed feasible. Codes and\ntrained models are released at https://github.com/shenyunhang/APE.",
            "author": [
                "Yunhang Shen",
                "Chaoyou Fu",
                "Peixian Chen",
                "Mengdan Zhang",
                "Ke Li",
                "Xing Sun",
                "Yunsheng Wu",
                "Shaohui Lin",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02153v1",
                "http://arxiv.org/pdf/2312.02153v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02150v1",
            "title": "Readout Guidance: Learning Control from Diffusion Features",
            "updated": "2023-12-04T18:59:32Z",
            "published": "2023-12-04T18:59:32Z",
            "summary": "We present Readout Guidance, a method for controlling text-to-image diffusion\nmodels with learned signals. Readout Guidance uses readout heads, lightweight\nnetworks trained to extract signals from the features of a pre-trained, frozen\ndiffusion model at every timestep. These readouts can encode single-image\nproperties, such as pose, depth, and edges; or higher-order properties that\nrelate multiple images, such as correspondence and appearance similarity.\nFurthermore, by comparing the readout estimates to a user-defined target, and\nback-propagating the gradient through the readout head, these estimates can be\nused to guide the sampling process. Compared to prior methods for conditional\ngeneration, Readout Guidance requires significantly fewer added parameters and\ntraining samples, and offers a convenient and simple recipe for reproducing\ndifferent forms of conditional control under a single framework, with a single\narchitecture and sampling procedure. We showcase these benefits in the\napplications of drag-based manipulation, identity-consistent generation, and\nspatially aligned control. Project page: https://readout-guidance.github.io.",
            "author": [
                "Grace Luo",
                "Trevor Darrell",
                "Oliver Wang",
                "Dan B Goldman",
                "Aleksander Holynski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02150v1",
                "http://arxiv.org/pdf/2312.02150v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02149v1",
            "title": "Generative Powers of Ten",
            "updated": "2023-12-04T18:59:25Z",
            "published": "2023-12-04T18:59:25Z",
            "summary": "We present a method that uses a text-to-image model to generate consistent\ncontent across multiple image scales, enabling extreme semantic zooms into a\nscene, e.g., ranging from a wide-angle landscape view of a forest to a macro\nshot of an insect sitting on one of the tree branches. We achieve this through\na joint multi-scale diffusion sampling approach that encourages consistency\nacross different scales while preserving the integrity of each individual\nsampling process. Since each generated scale is guided by a different text\nprompt, our method enables deeper levels of zoom than traditional\nsuper-resolution methods that may struggle to create new contextual structure\nat vastly different scales. We compare our method qualitatively with\nalternative techniques in image super-resolution and outpainting, and show that\nour method is most effective at generating consistent multi-scale content.",
            "author": [
                "Xiaojuan Wang",
                "Janne Kontkanen",
                "Brian Curless",
                "Steve Seitz",
                "Ira Kemelmacher",
                "Ben Mildenhall",
                "Pratul Srinivasan",
                "Dor Verbin",
                "Aleksander Holynski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02149v1",
                "http://arxiv.org/pdf/2312.02149v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02143v2",
            "title": "Competition-Level Problems are Effective LLM Evaluators",
            "updated": "2023-12-05T03:44:19Z",
            "published": "2023-12-04T18:58:57Z",
            "summary": "Large language models (LLMs) have demonstrated impressive reasoning\ncapabilities, yet there is ongoing debate about these abilities and the\npotential data contamination problem recently. This paper aims to evaluate the\nreasoning capacities of LLMs, specifically in solving recent competition-level\nprogramming problems in Codeforces, which are expert-crafted and unique,\nrequiring deep understanding and robust reasoning skills. We first provide a\ncomprehensive evaluation of GPT-4's peiceived zero-shot performance on this\ntask, considering various aspects such as problems' release time, difficulties,\nand types of errors encountered. Surprisingly, the peiceived performance of\nGPT-4 has experienced a cliff like decline in problems after September 2021\nconsistently across all the difficulties and types of problems, which shows the\npotential data contamination, as well as the challenges for any existing LLM to\nsolve unseen complex reasoning problems. We further explore various approaches\nsuch as fine-tuning, Chain-of-Thought prompting and problem description\nsimplification, unfortunately none of them is able to consistently mitigate the\nchallenges. Through our work, we emphasis the importance of this excellent data\nsource for assessing the genuine reasoning capabilities of LLMs, and foster the\ndevelopment of LLMs with stronger reasoning abilities and better generalization\nin the future.",
            "author": [
                "Yiming Huang",
                "Zhenghao Lin",
                "Xiao Liu",
                "Yeyun Gong",
                "Shuai Lu",
                "Fangyu Lei",
                "Yaobo Liang",
                "Yelong Shen",
                "Chen Lin",
                "Nan Duan",
                "Weizhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02143v2",
                "http://arxiv.org/pdf/2312.02143v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02142v1",
            "title": "Object Recognition as Next Token Prediction",
            "updated": "2023-12-04T18:58:40Z",
            "published": "2023-12-04T18:58:40Z",
            "summary": "We present an approach to pose object recognition as next token prediction.\nThe idea is to apply a language decoder that auto-regressively predicts the\ntext tokens from image embeddings to form labels. To ground this prediction\nprocess in auto-regression, we customize a non-causal attention mask for the\ndecoder, incorporating two key features: modeling tokens from different labels\nto be independent, and treating image tokens as a prefix. This masking\nmechanism inspires an efficient method - one-shot sampling - to simultaneously\nsample tokens of multiple labels in parallel and rank generated labels by their\nprobabilities during inference. To further enhance the efficiency, we propose a\nsimple strategy to construct a compact decoder by simply discarding the\nintermediate blocks of a pretrained language model. This approach yields a\ndecoder that matches the full model's performance while being notably more\nefficient. The code is available at https://github.com/kaiyuyue/nxtp",
            "author": [
                "Kaiyu Yue",
                "Bor-Chun Chen",
                "Jonas Geiping",
                "Hengduo Li",
                "Tom Goldstein",
                "Ser-Nam Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02142v1",
                "http://arxiv.org/pdf/2312.02142v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02256v1",
            "title": "EMDM: Efficient Motion Diffusion Model for Fast, High-Quality Motion\n  Generation",
            "updated": "2023-12-04T18:58:38Z",
            "published": "2023-12-04T18:58:38Z",
            "summary": "We introduce Efficient Motion Diffusion Model (EMDM) for fast and\nhigh-quality human motion generation. Although previous motion diffusion models\nhave shown impressive results, they struggle to achieve fast generation while\nmaintaining high-quality human motions. Motion latent diffusion has been\nproposed for efficient motion generation. However, effectively learning a\nlatent space can be non-trivial in such a two-stage manner. Meanwhile,\naccelerating motion sampling by increasing the step size, e.g., DDIM, typically\nleads to a decline in motion quality due to the inapproximation of complex data\ndistributions when naively increasing the step size. In this paper, we propose\nEMDM that allows for much fewer sample steps for fast motion generation by\nmodeling the complex denoising distribution during multiple sampling steps.\nSpecifically, we develop a Conditional Denoising Diffusion GAN to capture\nmultimodal data distributions conditioned on both control signals, i.e.,\ntextual description and denoising time step. By modeling the complex data\ndistribution, a larger sampling step size and fewer steps are achieved during\nmotion synthesis, significantly accelerating the generation process. To\neffectively capture the human dynamics and reduce undesired artifacts, we\nemploy motion geometric loss during network training, which improves the motion\nquality and training efficiency. As a result, EMDM achieves a remarkable\nspeed-up at the generation stage while maintaining high-quality motion\ngeneration in terms of fidelity and diversity.",
            "author": [
                "Wenyang Zhou",
                "Zhiyang Dou",
                "Zeyu Cao",
                "Zhouyingcheng Liao",
                "Jingbo Wang",
                "Wenjia Wang",
                "Yuan Liu",
                "Taku Komura",
                "Wenping Wang",
                "Lingjie Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02256v1",
                "http://arxiv.org/pdf/2312.02256v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02139v1",
            "title": "DiffiT: Diffusion Vision Transformers for Image Generation",
            "updated": "2023-12-04T18:57:01Z",
            "published": "2023-12-04T18:57:01Z",
            "summary": "Diffusion models with their powerful expressivity and high sample quality\nhave enabled many new applications and use-cases in various domains. For sample\ngeneration, these models rely on a denoising neural network that generates\nimages by iterative denoising. Yet, the role of denoising network architecture\nis not well-studied with most efforts relying on convolutional residual U-Nets.\nIn this paper, we study the effectiveness of vision transformers in\ndiffusion-based generative learning. Specifically, we propose a new model,\ndenoted as Diffusion Vision Transformers (DiffiT), which consists of a hybrid\nhierarchical architecture with a U-shaped encoder and decoder. We introduce a\nnovel time-dependent self-attention module that allows attention layers to\nadapt their behavior at different stages of the denoising process in an\nefficient manner. We also introduce latent DiffiT which consists of transformer\nmodel with the proposed self-attention layers, for high-resolution image\ngeneration. Our results show that DiffiT is surprisingly effective in\ngenerating high-fidelity images, and it achieves state-of-the-art (SOTA)\nbenchmarks on a variety of class-conditional and unconditional synthesis tasks.\nIn the latent space, DiffiT achieves a new SOTA FID score of 1.73 on\nImageNet-256 dataset. Repository: https://github.com/NVlabs/DiffiT",
            "author": [
                "Ali Hatamizadeh",
                "Jiaming Song",
                "Guilin Liu",
                "Jan Kautz",
                "Arash Vahdat"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02139v1",
                "http://arxiv.org/pdf/2312.02139v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02133v1",
            "title": "Style Aligned Image Generation via Shared Attention",
            "updated": "2023-12-04T18:55:35Z",
            "published": "2023-12-04T18:55:35Z",
            "summary": "Large-scale Text-to-Image (T2I) models have rapidly gained prominence across\ncreative fields, generating visually compelling outputs from textual prompts.\nHowever, controlling these models to ensure consistent style remains\nchallenging, with existing methods necessitating fine-tuning and manual\nintervention to disentangle content and style. In this paper, we introduce\nStyleAligned, a novel technique designed to establish style alignment among a\nseries of generated images. By employing minimal `attention sharing' during the\ndiffusion process, our method maintains style consistency across images within\nT2I models. This approach allows for the creation of style-consistent images\nusing a reference style through a straightforward inversion operation. Our\nmethod's evaluation across diverse styles and text prompts demonstrates\nhigh-quality synthesis and fidelity, underscoring its efficacy in achieving\nconsistent style across various inputs.",
            "author": [
                "Amir Hertz",
                "Andrey Voynov",
                "Shlomi Fruchter",
                "Daniel Cohen-Or"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02133v1",
                "http://arxiv.org/pdf/2312.02133v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02130v1",
            "title": "Fundamental Physics Opportunities with the Next-Generation Event Horizon\n  Telescope",
            "updated": "2023-12-04T18:53:55Z",
            "published": "2023-12-04T18:53:55Z",
            "summary": "The Event Horizon Telescope (EHT) Collaboration recently published the first\nimages of the supermassive black holes in the cores of the Messier 87 and Milky\nWay galaxies. These observations have provided a new means to study\nsupermassive black holes and probe physical processes occurring in the\nstrong-field regime. We review the prospects of future observations and\ntheoretical studies of supermassive black hole systems with the next-generation\nEvent Horizon Telescope (ngEHT), which will greatly enhance the capabilities of\nthe existing EHT array. These enhancements will open up several previously\ninaccessible avenues of investigation, thereby providing important new insights\ninto the properties of supermassive black holes and their environments. This\nreview describes the current state of knowledge for five key science cases,\nsummarising the unique challenges and opportunities for fundamental physics\ninvestigations that the ngEHT will enable.",
            "author": [
                "Dimitry Ayzenberg",
                "Lindy Blackburn",
                "Richard Brito",
                "Silke Britzen",
                "Avery E. Broderick",
                "Ra\u00fal Carballo-Rubio",
                "Vitor Cardoso",
                "Andrew Chael",
                "Koushik Chatterjee",
                "Yifan Chen",
                "Pedro V. P. Cunha",
                "Hooman Davoudiasl",
                "Peter B. Denton",
                "Sheperd S. Doeleman",
                "Astrid Eichhorn",
                "Marshall Eubanks",
                "Yun Fang",
                "Arianna Foschi",
                "Christian M. Fromm",
                "Peter Galison",
                "Sushant G. Ghosh",
                "Roman Gold",
                "Leonid I. Gurvits",
                "Shahar Hadar",
                "Aaron Held",
                "Janice Houston",
                "Yichao Hu",
                "Michael D. Johnson",
                "Prashant Kocherlakota",
                "Priyamvada Natarajan",
                "H\u00e9ctor Olivares",
                "Daniel Palumbo",
                "Dominic W. Pesce",
                "Surjeet Rajendran",
                "Rittick Roy",
                "Saurabh",
                "Lijing Shao",
                "Shammi Tahura",
                "Aditya Tamar",
                "Paul Tiede",
                "Fr\u00e9d\u00e9ric H. Vincent",
                "Luca Visinelli",
                "Zhiren Wang",
                "Maciek Wielgus",
                "Xiao Xue",
                "Kadri Yakut",
                "Huan Yang",
                "Ziri Younsi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02130v1",
                "http://arxiv.org/pdf/2312.02130v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM",
                "gr-qc",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02129v1",
            "title": "Meromorphic CFTs have central charges c = 8$\\mathbb{N}$: a proof by the\n  MLDE approach",
            "updated": "2023-12-04T18:53:51Z",
            "published": "2023-12-04T18:53:51Z",
            "summary": "In this short note, we present a simple and elementary proof that meromorphic\nconformal field theories (CFTs) have central charges of the form: $c=8N$ with\n$N\\in\\mathbb{N}$ (the set of natural numbers) using the modular linear\ndifferential equations (MLDEs) approach. We first set up the 1-character MLDE\nfor arbitrary value of the Wronskian index: $\\ell$. From this we get the\ngeneral form of the meromorphic CFT's character. We then study its modular\ntransformations and the asymptotic value of it's Fourier coefficients to\nconclude that odd values of $\\ell$ make the character in-admissible implying\nthat the central charge for admissible character has to be a multiple of 8.",
            "author": [
                "Arpit Das"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02129v1",
                "http://arxiv.org/pdf/2312.02129v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.str-el",
                "math-ph",
                "math.MP",
                "math.NT",
                "math.QA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02125v2",
            "title": "TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and\n  Advanced Decoding Techniques",
            "updated": "2023-12-06T05:19:11Z",
            "published": "2023-12-04T18:52:26Z",
            "summary": "Recent advances in language models (LMs), have demonstrated significant\nefficacy in tasks related to the arts and humanities. While LMs have exhibited\nexceptional performance across a wide range of natural language processing\ntasks, there are notable challenges associated with their utilization on small\ndatasets and their ability to replicate more creative human capacities. In this\nstudy, we aim to address these challenges by training a Persian classical\npoetry generation model using a transformer architecture on a specialized\ndataset with no pretraining. Additionally, we propose a novel decoding method\nto enhance coherence and meaningfulness in the generated poetry, effectively\nmanaging the tradeoff between diversity and quality. Furthermore, the results\nof our training approach and the proposed decoding method are evaluated through\ncomprehensive set of automatic and human evaluations and showed its superior\ncapability to generate coherent and meaningful poetry in compare to other\ndecoding methods and an existing Persian large language model (LLM).",
            "author": [
                "Amir Panahandeh",
                "Hanie Asemi",
                "Esmaeil Nourani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02125v2",
                "http://arxiv.org/pdf/2312.02125v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02120v1",
            "title": "Magicoder: Source Code Is All You Need",
            "updated": "2023-12-04T18:50:35Z",
            "published": "2023-12-04T18:50:35Z",
            "summary": "We introduce Magicoder, a series of fully open-source (code, weights, and\ndata) Large Language Models (LLMs) for code that significantly closes the gap\nwith top code models while having no more than 7B parameters. Magicoder models\nare trained on 75K synthetic instruction data using OSS-Instruct, a novel\napproach to enlightening LLMs with open-source code snippets to generate\nhigh-quality instruction data for code. Our main motivation is to mitigate the\ninherent bias of the synthetic data generated by LLMs by empowering them with a\nwealth of open-source references for the production of more diverse, realistic,\nand controllable data. The orthogonality of OSS-Instruct and other data\ngeneration methods like Evol-Instruct further enables us to build an enhanced\nMagicoderS. Both Magicoder and MagicoderS substantially outperform\nstate-of-the-art code models with similar or even larger sizes on a wide range\nof coding benchmarks, including Python text-to-code generation, multilingual\ncoding, and data-science program completion. Notably, MagicoderS-CL-7B based on\nCodeLlama even surpasses the prominent ChatGPT on HumanEval+ (66.5 vs. 65.9 in\npass@1). Overall, OSS-Instruct opens a new direction for low-bias and\nhigh-quality instruction tuning using abundant open-source references.",
            "author": [
                "Yuxiang Wei",
                "Zhe Wang",
                "Jiawei Liu",
                "Yifeng Ding",
                "Lingming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02120v1",
                "http://arxiv.org/pdf/2312.02120v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02119v1",
            "title": "Tree of Attacks: Jailbreaking Black-Box LLMs Automatically",
            "updated": "2023-12-04T18:49:23Z",
            "published": "2023-12-04T18:49:23Z",
            "summary": "While Large Language Models (LLMs) display versatile functionality, they\ncontinue to generate harmful, biased, and toxic content, as demonstrated by the\nprevalence of human-designed jailbreaks. In this work, we present Tree of\nAttacks with Pruning (TAP), an automated method for generating jailbreaks that\nonly requires black-box access to the target LLM. TAP utilizes an LLM to\niteratively refine candidate (attack) prompts using tree-of-thoughts reasoning\nuntil one of the generated prompts jailbreaks the target. Crucially, before\nsending prompts to the target, TAP assesses them and prunes the ones unlikely\nto result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate\na large search space of prompts and pruning reduces the total number of queries\nsent to the target. In empirical evaluations, we observe that TAP generates\nprompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo)\nfor more than 80% of the prompts using only a small number of queries. This\nsignificantly improves upon the previous state-of-the-art black-box method for\ngenerating jailbreaks.",
            "author": [
                "Anay Mehrotra",
                "Manolis Zampetakis",
                "Paul Kassianik",
                "Blaine Nelson",
                "Hyrum Anderson",
                "Yaron Singer",
                "Amin Karbasi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02119v1",
                "http://arxiv.org/pdf/2312.02119v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02118v1",
            "title": "When it Rains, it Pours: Modeling Media Storms and the News Ecosystem",
            "updated": "2023-12-04T18:49:06Z",
            "published": "2023-12-04T18:49:06Z",
            "summary": "Most events in the world receive at most brief coverage by the news media.\nOccasionally, however, an event will trigger a media storm, with voluminous and\nwidespread coverage lasting for weeks instead of days. In this work, we develop\nand apply a pairwise article similarity model, allowing us to identify story\nclusters in corpora covering local and national online news, and thereby create\na comprehensive corpus of media storms over a nearly two year period. Using\nthis corpus, we investigate media storms at a new level of granularity,\nallowing us to validate claims about storm evolution and topical distribution,\nand provide empirical support for previously hypothesized patterns of influence\nof storms on media coverage and intermedia agenda setting.",
            "author": [
                "Benjamin Litterer",
                "David Jurgens",
                "Dallas Card"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02118v1",
                "http://arxiv.org/pdf/2312.02118v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02115v1",
            "title": "Exact solutions of Cotton Gravity",
            "updated": "2023-12-04T18:47:36Z",
            "published": "2023-12-04T18:47:36Z",
            "summary": "We examine various exact solutions in \"Cotton Gravity\" (CG), a new gravity\ntheory that provides an extension of General Relativity (GR) based on the\nCotton tensor. Using an alternative formulation of the field equations in terms\nof a Codazzi tensor, we obtain various non-trivial CG exact solutions that\ngeneralize known GR solutions: FLRW cosmologies, Lemaitre-Tolman-Bondi (LTB)\nand Szekeres dust solutions, as well as static perfect fluid spheres and\nsolutions with a shear-free 4 velocity. We show that CG modifies the spatial\ncurvature of the nonstatic GR solutions. Demanding a well posed initial value\nformulation keeps the same dynamics of FLRW models of GR, but with the\ncosmological constant interpreted as constant spatial curvature. In other\nsolutions the modification of spatial curvature allows for self-consistent\nsignificant changes in the dynamics, an time and spece dependent evolution from\ndecelerated to accelerated expansion driven by negative spatial curvature and\nwithout necessarily assuming a dark energy source or imposing a cosmological\nconstant. The $\\Lambda$CDM model naturally emerges as the unique FLRW dust\nmodel of CG with constant negative spatial curvature. Static fluid spheres in\nthe weak field regime of CG allow for modeling the flattening of rotation\nvelocities in galactic systems without assuming dark matter. The methods we\nhave presented can be improved to be able to obtain more general solutions that\nwill facilitate the application of CG to current open problems in gravitational\nsystems in general.",
            "author": [
                "Roberto A Sussman",
                "Sebastian Najera"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02115v1",
                "http://arxiv.org/pdf/2312.02115v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02112v1",
            "title": "Distributed Optimization with Feasible Set Privacy",
            "updated": "2023-12-04T18:45:04Z",
            "published": "2023-12-04T18:45:04Z",
            "summary": "We consider the setup of a constrained optimization problem with two agents\n$E_1$ and $E_2$ who jointly wish to learn the optimal solution set while\nkeeping their feasible sets $\\mathcal{P}_1$ and $\\mathcal{P}_2$ private from\neach other. The objective function $f$ is globally known and each feasible set\nis a collection of points from a global alphabet. We adopt a sequential\nsymmetric private information retrieval (SPIR) framework where one of the\nagents (say $E_1$) privately checks in $\\mathcal{P}_2$, the presence of\ncandidate solutions of the problem constrained to $\\mathcal{P}_1$ only, while\nlearning no further information on $\\mathcal{P}_2$ than the solution alone.\nFurther, we extract an information theoretically private threshold PSI (ThPSI)\nprotocol from our scheme and characterize its download cost. We show that,\ncompared to privately acquiring the feasible set $\\mathcal{P}_1\\cap\n\\mathcal{P}_2$ using an SPIR-based private set intersection (PSI) protocol, and\nfinding the optimum, our scheme is better as it incurs less information leakage\nand less download cost than the former. Over all possible uniform mappings of\n$f$ to a fixed range of values, our scheme outperforms the former with a high\nprobability.",
            "author": [
                "Shreya Meel",
                "Sennur Ulukus"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02112v1",
                "http://arxiv.org/pdf/2312.02112v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CR",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02253v1",
            "title": "Diversify, Don't Fine-Tune: Scaling Up Visual Recognition Training with\n  Synthetic Images",
            "updated": "2023-12-04T18:35:27Z",
            "published": "2023-12-04T18:35:27Z",
            "summary": "Recent advances in generative deep learning have enabled the creation of\nhigh-quality synthetic images in text-to-image generation. Prior work shows\nthat fine-tuning a pretrained diffusion model on ImageNet and generating\nsynthetic training images from the finetuned model can enhance an ImageNet\nclassifier's performance. However, performance degrades as synthetic images\noutnumber real ones. In this paper, we explore whether generative fine-tuning\nis essential for this improvement and whether it is possible to further scale\nup training using more synthetic data. We present a new framework leveraging\noff-the-shelf generative models to generate synthetic training images,\naddressing multiple challenges: class name ambiguity, lack of diversity in\nnaive prompts, and domain shifts. Specifically, we leverage large language\nmodels (LLMs) and CLIP to resolve class name ambiguity. To diversify images, we\npropose contextualized diversification (CD) and stylized diversification (SD)\nmethods, also prompted by LLMs. Finally, to mitigate domain shifts, we leverage\ndomain adaptation techniques with auxiliary batch normalization for synthetic\nimages. Our framework consistently enhances recognition model performance with\nmore synthetic data, up to 6x of original ImageNet size showcasing the\npotential of synthetic data for improved recognition models and strong\nout-of-domain generalization.",
            "author": [
                "Zhuoran Yu",
                "Chenchen Zhu",
                "Sean Culatana",
                "Raghuraman Krishnamoorthi",
                "Fanyi Xiao",
                "Yong Jae Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02253v1",
                "http://arxiv.org/pdf/2312.02253v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02106v1",
            "title": "On the Multiplicity One Conjecture for Mean Curvature Flows of surfaces",
            "updated": "2023-12-04T18:34:47Z",
            "published": "2023-12-04T18:34:47Z",
            "summary": "We prove the Multiplicity One Conjecture for mean curvature flows of surfaces\nin $\\mathbb{R}^3$. Specifically, we show that any blow-up limit of such mean\ncurvature flows has multiplicity one. This has several applications. First,\ncombining our work with results of Brendle and\nChoi-Haslhofer-Hershkovits-White, we show that any level set flow starting from\nan embedded surface diffeomorphic to a 2-spheres does not fatten. In fact, we\nobtain that the problem of evolving embedded 2-spheres via the mean curvature\nflow equation is well-posed within a natural class of singular solutions.\nSecond, we use our result to remove an additional condition in recent work of\nChodosh-Choi-Mantoulidis-Schulze. This shows that mean curvature flows starting\nfrom any generic embedded surface only incur cylindrical or spherical\nsingularities. Third, our approach offers a new regularity theory for solutions\nof mean curvature flows that flow through singularities. Among other things,\nthis theory also applies to the innermost and outermost flow of any embedded\nsurface and shows that all singularity models of such flows must have\nmultiplicity one. It also establishes equality of the fattening time with the\ndiscrepancy time. Lastly, we obtain a number of further results characterizing\na separation phenomenon of mean curvature flows of surfaces.",
            "author": [
                "Richard H Bamler",
                "Bruce Kleiner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02106v1",
                "http://arxiv.org/pdf/2312.02106v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02105v1",
            "title": "Authoring Worked Examples for Java Programming with Human-AI\n  Collaboration",
            "updated": "2023-12-04T18:32:55Z",
            "published": "2023-12-04T18:32:55Z",
            "summary": "Worked examples (solutions to typical programming problems presented as a\nsource code in a certain language and are used to explain the topics from a\nprogramming class) are among the most popular types of learning content in\nprogramming classes. Most approaches and tools for presenting these examples to\nstudents are based on line-by-line explanations of the example code. However,\ninstructors rarely have time to provide line-by-line explanations for a large\nnumber of examples typically used in a programming class. In this paper, we\nexplore and assess a human-AI collaboration approach to authoring worked\nexamples for Java programming. We introduce an authoring system for creating\nJava worked examples that generates a starting version of code explanations and\npresents it to the instructor to edit if necessary. We also present a study\nthat assesses the quality of explanations created with this approach.",
            "author": [
                "Mohammad Hassany",
                "Peter Brusilovsky",
                "Jiaze Ke",
                "Kamil Akhuseyinoglu",
                "Arun Balajiee Lekshmi Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02105v1",
                "http://arxiv.org/pdf/2312.02105v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02103v1",
            "title": "Learning Pseudo-Labeler beyond Noun Concepts for Open-Vocabulary Object\n  Detection",
            "updated": "2023-12-04T18:29:03Z",
            "published": "2023-12-04T18:29:03Z",
            "summary": "Open-vocabulary object detection (OVOD) has recently gained significant\nattention as a crucial step toward achieving human-like visual intelligence.\nExisting OVOD methods extend target vocabulary from pre-defined categories to\nopen-world by transferring knowledge of arbitrary concepts from vision-language\npre-training models to the detectors. While previous methods have shown\nremarkable successes, they suffer from indirect supervision or limited\ntransferable concepts. In this paper, we propose a simple yet effective method\nto directly learn region-text alignment for arbitrary concepts. Specifically,\nthe proposed method aims to learn arbitrary image-to-text mapping for\npseudo-labeling of arbitrary concepts, named Pseudo-Labeling for Arbitrary\nConcepts (PLAC). The proposed method shows competitive performance on the\nstandard OVOD benchmark for noun concepts and a large improvement on referring\nexpression comprehension benchmark for arbitrary concepts.",
            "author": [
                "Sunghun Kang",
                "Junbum Cha",
                "Jonghwan Mun",
                "Byungseok Roh",
                "Chang D. Yoo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02103v1",
                "http://arxiv.org/pdf/2312.02103v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02102v1",
            "title": "Mitigating Data Injection Attacks on Federated Learning",
            "updated": "2023-12-04T18:26:31Z",
            "published": "2023-12-04T18:26:31Z",
            "summary": "Federated learning is a technique that allows multiple entities to\ncollaboratively train models using their data without compromising data\nprivacy. However, despite its advantages, federated learning can be susceptible\nto false data injection attacks. In these scenarios, a malicious entity with\ncontrol over specific agents in the network can manipulate the learning\nprocess, leading to a suboptimal model. Consequently, addressing these data\ninjection attacks presents a significant research challenge in federated\nlearning systems. In this paper, we propose a novel technique to detect and\nmitigate data injection attacks on federated learning systems. Our mitigation\nmethod is a local scheme, performed during a single instance of training by the\ncoordinating node, allowing the mitigation during the convergence of the\nalgorithm. Whenever an agent is suspected to be an attacker, its data will be\nignored for a certain period, this decision will often be re-evaluated. We\nprove that with probability 1, after a finite time, all attackers will be\nignored while the probability of ignoring a trustful agent becomes 0, provided\nthat there is a majority of truthful agents. Simulations show that when the\ncoordinating node detects and isolates all the attackers, the model recovers\nand converges to the truthful model.",
            "author": [
                "Or Shalom",
                "Amir Leshem",
                "Waheed U. Bajwa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02102v1",
                "http://arxiv.org/pdf/2312.02102v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02101v1",
            "title": "Golden parachutes under the threat of accidents",
            "updated": "2023-12-04T18:23:42Z",
            "published": "2023-12-04T18:23:42Z",
            "summary": "This paper addresses a continuous-time contracting model that extends the\nproblem introduced by Sannikov and later rigorously analysed by Possama\\\"{i}\nand Touzi. In our model, a principal hires a risk-averse agent to carry out a\nproject. Specifically, the agent can perform two different tasks, namely to\nincrease the instantaneous growth rate of the project's value, and to reduce\nthe likelihood of accidents occurring. In order to compensate for these costly\nactions, the principal offers a continuous stream of payments throughout the\nentire duration of a contract, which concludes at a random time, potentially\nresulting in a lump-sum payment. We examine the consequences stemming from the\nintroduction of accidents, modelled by a compound Poisson process that\nnegatively impact the project's value. Furthermore, we investigate whether\ncertain economic scenarii are still characterised by a golden parachute as in\nSannikov's model. A golden parachute refers to a situation where the agent\nstops working and subsequently receives a compensation, which may be either a\nlump-sum payment leading to termination of the contract or a continuous stream\nof payments, thereby corresponding to a pension.",
            "author": [
                "Dylan Possama\u00ef",
                "Chiara Rossato"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02101v1",
                "http://arxiv.org/pdf/2312.02101v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "econ.GN",
                "math.OC",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02099v1",
            "title": "Persistent Directed Flag Laplacian",
            "updated": "2023-12-04T18:20:19Z",
            "published": "2023-12-04T18:20:19Z",
            "summary": "Topological data analysis (TDA) has had enormous success in science and\nengineering in the past decade. Persistent topological Laplacians (PTLs)\novercome some limitations of persistent homology, a key technique in TDA, and\nprovide substantial insight to the behavior of various geometric and\ntopological objects. This work extends PTLs to directed flag complexes, which\nare an exciting generalization to flag complexes, also known as clique\ncomplexes, that arise naturally in many situations. We introduce the directed\nflag Laplacian and show that the proposed persistent directed flag Laplacian\n(PDFL) is a distinct way of analyzing these flag complexes. Example\ncalculations are provided to demonstrate the potential of the proposed PDFL in\nreal world applications.",
            "author": [
                "Benjamin Jones",
                "Guowei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02099v1",
                "http://arxiv.org/pdf/2312.02099v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02096v1",
            "title": "Interacting Urns on Directed Networks with Node-Dependent Sampling and\n  Reinforcement",
            "updated": "2023-12-04T18:15:01Z",
            "published": "2023-12-04T18:15:01Z",
            "summary": "We consider interacting urns on a finite directed network, where both\nsampling and reinforcement processes depend on the nodes of the network. This\nextends previous research by incorporating node-dependent sampling\n(preferential or de-preferential) and reinforcement. We classify the\nreinforcement schemes and the networks on which the proportion of balls of\neither colour in each urn converges almost surely to a deterministic limit. We\nshow that in case the reinforcement at all nodes is of P\\'olya-type, the\nlimiting behaviour is very different from the node-independent sampling and a\ndeterministic limit exists for certain networks classified by the distribution\nof preferential and de-preferential nodes across the network. We also\ninvestigate conditions for achieving synchronisation of the colour proportions\nacross the urns. Further, we analyse fluctuations around the limit, under\nspecific conditions on the reinforcement matrices and network structure.",
            "author": [
                "Gursharn Kaur",
                "Neeraja Sahasrabudhe"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02096v1",
                "http://arxiv.org/pdf/2312.02096v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02252v1",
            "title": "Large Language Models as Consistent Story Visualizers",
            "updated": "2023-12-04T18:14:29Z",
            "published": "2023-12-04T18:14:29Z",
            "summary": "Recent generative models have demonstrated impressive capabilities in\ngenerating realistic and visually pleasing images grounded on textual prompts.\nNevertheless, a significant challenge remains in applying these models for the\nmore intricate task of story visualization. Since it requires resolving\npronouns (he, she, they) in the frame descriptions, i.e., anaphora resolution,\nand ensuring consistent characters and background synthesis across frames. Yet,\nthe emerging Large Language Model (LLM) showcases robust reasoning abilities to\nnavigate through ambiguous references and process extensive sequences.\nTherefore, we introduce \\textbf{StoryGPT-V}, which leverages the merits of the\nlatent diffusion (LDM) and LLM to produce images with consistent and\nhigh-quality characters grounded on given story descriptions. First, we train a\ncharacter-aware LDM, which takes character-augmented semantic embedding as\ninput and includes the supervision of the cross-attention map using character\nsegmentation masks, aiming to enhance character generation accuracy and\nfaithfulness. In the second stage, we enable an alignment between the output of\nLLM and the character-augmented embedding residing in the input space of the\nfirst-stage model. This harnesses the reasoning ability of LLM to address\nambiguous references and the comprehension capability to memorize the context.\nWe conduct comprehensive experiments on two visual story visualization\nbenchmarks. Our model reports superior quantitative results and consistently\ngenerates accurate characters of remarkable quality with low memory\nconsumption. Our code will be made publicly available.",
            "author": [
                "Xiaoqian Shen",
                "Mohamed Elhoseiny"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02252v1",
                "http://arxiv.org/pdf/2312.02252v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02091v1",
            "title": "Physics simulation capabilities of LLMs",
            "updated": "2023-12-04T18:06:41Z",
            "published": "2023-12-04T18:06:41Z",
            "summary": "[Abridged abstract] Large Language Models (LLMs) can solve some\nundergraduate-level to graduate-level physics textbook problems and are\nproficient at coding. Combining these two capabilities could one day enable AI\nsystems to simulate and predict the physical world.\n  We present an evaluation of state-of-the-art (SOTA) LLMs on PhD-level to\nresearch-level computational physics problems. We condition LLM generation on\nthe use of well-documented and widely-used packages to elicit coding\ncapabilities in the physics and astrophysics domains. We contribute $\\sim 50$\noriginal and challenging problems in celestial mechanics (with REBOUND),\nstellar physics (with MESA), 1D fluid dynamics (with Dedalus) and non-linear\ndynamics (with SciPy). Since our problems do not admit unique solutions, we\nevaluate LLM performance on several soft metrics: counts of lines that contain\ndifferent types of errors (coding, physics, necessity and sufficiency) as well\nas a more \"educational\" Pass-Fail metric focused on capturing the salient\nphysical ingredients of the problem at hand.\n  As expected, today's SOTA LLM (GPT4) zero-shot fails most of our problems,\nalthough about 40\\% of the solutions could plausibly get a passing grade. About\n$70-90 \\%$ of the code lines produced are necessary, sufficient and correct\n(coding \\& physics). Physics and coding errors are the most common, with some\nunnecessary or insufficient lines. We observe significant variations across\nproblem class and difficulty. We identify several failure modes of GPT4 in the\ncomputational physics domain.\n  Our reconnaissance work provides a snapshot of current computational\ncapabilities in classical physics and points to obvious improvement targets if\nAI systems are ever to reach a basic level of autonomy in physics simulation\ncapabilities.",
            "author": [
                "Mohamad Ali-Dib",
                "Kristen Menou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02091v1",
                "http://arxiv.org/pdf/2312.02091v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "astro-ph.EP",
                "astro-ph.IM",
                "astro-ph.SR",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02251v1",
            "title": "Fine-Tuning Language Models for Context-Specific SQL Query Generation",
            "updated": "2023-12-04T18:04:27Z",
            "published": "2023-12-04T18:04:27Z",
            "summary": "The ability to generate SQL queries from natural language has significant\nimplications for making data accessible to non-specialists. This paper presents\na novel approach to fine-tuning open-source large language models (LLMs) for\nthe task of transforming natural language into SQL queries within the retail\ndomain. We introduce models specialized in generating SQL queries, trained on\nsynthetic datasets tailored to the Snowflake SQL and GoogleSQL dialects. Our\nmethodology involves generating a context-specific dataset using GPT-4, then\nfine-tuning three open-source LLMs(Starcoder Plus, Code-Llama, and Mistral)\nemploying the LoRa technique to optimize for resource constraints. The\nfine-tuned models demonstrate superior performance in zero-shot settings\ncompared to the baseline GPT-4, with Code-Llama achieving the highest accuracy\nrates, at 81.58% for Snowflake SQL and 82.66% for GoogleSQL. These results\nunderscore the effectiveness of fine-tuning LLMs on domain-specific tasks and\nsuggest a promising direction for enhancing the accessibility of relational\ndatabases through natural language interfaces.",
            "author": [
                "Amine Rebei"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02251v1",
                "http://arxiv.org/pdf/2312.02251v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02089v1",
            "title": "Sequential Sweeps and High Dimensional Expansion",
            "updated": "2023-12-04T18:02:18Z",
            "published": "2023-12-04T18:02:18Z",
            "summary": "It is well known that the spectral gap of the down-up walk over an\n$n$-partite simplicial complex (also known as Glauber dynamics) cannot be\nbetter than $O(1/n)$ due to natural obstructions such as coboundaries. We study\nan alternative random walk over partite simplicial complexes known as the\nsequential sweep or the systematic scan Glauber dynamics: Whereas the down-up\nwalk at each step selects a random coordinate and updates it based on the\nremaining coordinates, the sequential sweep goes through each of the\ncoordinates one by one in a deterministic order and applies the same update\noperation. It is natural, thus, to compare $n$-steps of the down-up walk with a\nsingle step of the sequential sweep. Interestingly, while the spectral gap of\nthe $n$-th power of the down-up walk is still bounded from above by a constant,\nunder a strong enough local spectral assumption (in the sense of Gur,\nLifschitz, Liu, STOC 2022) we can show that the spectral gap of this walk can\nbe arbitrarily close to 1. We also study other isoperimetric inequalities for\nthese walks, and show that under the assumptions of local entropy contraction\n(related to the considerations of Gur, Lifschitz, Liu), these walks satisfy an\nentropy contraction inequality.",
            "author": [
                "Vedat Levi Alev",
                "Ori Parzanchevski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02089v1",
                "http://arxiv.org/pdf/2312.02089v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02086v1",
            "title": "Ruling out models of vector dark matter in asymptotically safe quantum\n  gravity",
            "updated": "2023-12-04T17:54:53Z",
            "published": "2023-12-04T17:54:53Z",
            "summary": "The nature of dark matter is a problem with too many potential solutions. We\ninvestigate whether a consistent embedding into quantum gravity can decimate\nthe number of solutions to the dark-matter problem. Concretely, we focus on a\nhidden sector composed of a gauge field and a charged scalar, with gauge group\nU(1)$_{\\textmd{D}}$ or SU(2)$_\\textmd{D}$. The gauge field is the dark-matter\ncandidate, if the gauge symmetry is broken spontaneously. Phenomenological\nconstraints on the couplings in this model arise from requiring that the\ncorrect dark matter relic density is produced via thermal freeze-out and that\nrecent bounds from direct-detection experiments are respected. We find that the\nconsistent embedding into asymptotically safe quantum gravity gives rise to\nadditional constraints on the couplings at the Planck scale, from which we\ncalculate corresponding constraints at low energy scales. We discover that\nphenomenological constraints cannot be satisfied simultaneously with\ntheoretical constraints from asymptotically safe quantum gravity, ruling out\nthese dark-matter models.",
            "author": [
                "Gustavo P. de Brito",
                "Astrid Eichhorn",
                "Mads T. Frandsen",
                "Martin Rosenlyst",
                "Mattias E. Thing",
                "Arthur F. Vieira"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02086v1",
                "http://arxiv.org/pdf/2312.02086v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02082v1",
            "title": "Joint State and Input Estimation for Linear Dynamical Systems with\n  Sparse Control",
            "updated": "2023-12-04T17:49:21Z",
            "published": "2023-12-04T17:49:21Z",
            "summary": "Sparsity constraints on the control inputs of a linear dynamical system\nnaturally arise in several practical applications such as networked control,\ncomputer vision, seismic signal processing, and cyber-physical systems. In this\nwork, we consider the problem of jointly estimating the states and sparse\ninputs of such systems from low-dimensional (compressive) measurements. Due to\nthe low-dimensional measurements, conventional Kalman filtering and smoothing\nalgorithms fail to accurately estimate the states and inputs. We present a\nBayesian approach that exploits the input sparsity to significantly improve\nestimation accuracy. Sparsity in the input estimates is promoted by using\ndifferent prior distributions on the input. We investigate two main approaches:\nregularizer-based MAP, and {Bayesian learning-based estimation}. We also extend\nthe approaches to handle control inputs with common support and analyze the\ntime and memory complexities of the presented algorithms. Finally, using\nnumerical simulations, we show that our algorithms outperform the\nstate-of-the-art methods in terms of accuracy and time/memory complexities,\nespecially in the low-dimensional measurement regime.",
            "author": [
                "Rupam Kalyan Chakraborty",
                "Geethu Joseph",
                "Chandra R. Murthy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02082v1",
                "http://arxiv.org/pdf/2312.02082v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02080v2",
            "title": "Fixed-point methods for long-term power control and beamforming design\n  in large-scale MIMO",
            "updated": "2023-12-07T11:56:53Z",
            "published": "2023-12-04T17:47:27Z",
            "summary": "This study presents novel applications of fixed-point methods to solve\npreviously open joint power control and beamforming design problems in modern\nlarge-scale MIMO systems, e.g., based on the cell-free massive MIMO and XL-MIMO\nconcepts. In particular, motivated by the need for scalable system\narchitectures, we revisit the classical sum power minimization and max-min fair\ndesign criteria by considering long-term power control and beamforming design\nbased on channel statistics and possibly limited channel state information\n(CSI) sharing across distributed processing units. This approach is believed to\nmitigate the severe scalability issues of competing short-term optimal\nalgorithms in the literature, which must be executed for every channel\nrealization by a central controller endowed with global CSI, hence imposing\nvery demanding requirements in terms of computation and interconnection\ncapabilities. The obtained optimal algorithms are then illustrated and compared\nagainst existing short-term and long-term approaches via numerical simulations\nin a cell-free massive MIMO setup.",
            "author": [
                "Lorenzo Miretti",
                "Renato L. G. Cavalcante",
                "S\u0142awomir Sta\u0144czak"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02080v2",
                "http://arxiv.org/pdf/2312.02080v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02079v2",
            "title": "Deep Set Neural Networks for forecasting asynchronous bioprocess\n  timeseries",
            "updated": "2023-12-05T22:20:50Z",
            "published": "2023-12-04T17:46:57Z",
            "summary": "Cultivation experiments often produce sparse and irregular time series.\nClassical approaches based on mechanistic models, like Maximum Likelihood\nfitting or Monte-Carlo Markov chain sampling, can easily account for sparsity\nand time-grid irregularities, but most statistical and Machine Learning tools\nare not designed for handling sparse data out-of-the-box. Among popular\napproaches there are various schemes for filling missing values (imputation)\nand interpolation into a regular grid (alignment). However, such methods\ntransfer the biases of the interpolation or imputation models to the target\nmodel. We show that Deep Set Neural Networks equipped with triplet encoding of\nthe input data can successfully handle bio-process data without any need for\nimputation or alignment procedures. The method is agnostic to the particular\nnature of the time series and can be adapted for any task, for example, online\nmonitoring, predictive control, design of experiments, etc. In this work, we\nfocus on forecasting. We argue that such an approach is especially suitable for\ntypical cultivation processes, demonstrate the performance of the method on\nseveral forecasting tasks using data generated from macrokinetic growth models\nunder realistic conditions, and compare the method to a conventional fitting\nprocedure and methods based on imputation and alignment.",
            "author": [
                "Maxim Borisyak",
                "Stefan Born",
                "Peter Neubauer",
                "Mariano Nicolas Cruz-Bournazou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02079v2",
                "http://arxiv.org/pdf/2312.02079v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02078v1",
            "title": "Integrating AI into CCTV Systems: A Comprehensive Evaluation of Smart\n  Video Surveillance in Community Space",
            "updated": "2023-12-04T17:41:52Z",
            "published": "2023-12-04T17:41:52Z",
            "summary": "This article presents an AI-enabled Smart Video Surveillance (SVS) designed\nto enhance safety in community spaces such as educational and recreational\nareas, and small businesses. The proposed system innovatively integrates with\nexisting CCTV and wired camera networks, simplifying its adoption across\nvarious community cases to leverage recent AI advancements. Our SVS system,\nfocusing on privacy, uses metadata instead of pixel data for activity\nrecognition, aligning with ethical standards. It features cloud-based\ninfrastructure and a mobile app for real-time, privacy-conscious alerts in\ncommunities.\n  This article notably pioneers a comprehensive real-world evaluation of the\nSVS system, covering AI-driven visual processing, statistical analysis,\ndatabase management, cloud communication, and user notifications. It's also the\nfirst to assess an end-to-end anomaly detection system's performance, vital for\nidentifying potential public safety incidents.\n  For our evaluation, we implemented the system in a community college, serving\nas an ideal model to exemplify the proposed system's capabilities. Our findings\nin this setting demonstrate the system's robustness, with throughput, latency,\nand scalability effectively managing 16 CCTV cameras. The system maintained a\nconsistent 16.5 frames per second (FPS) over a 21-hour operation. The average\nend-to-end latency for detecting behavioral anomalies and alerting users was\n26.76 seconds.",
            "author": [
                "Shanle Yao",
                "Babak Rahimi Ardabili",
                "Armin Danesh Pazho",
                "Ghazal Alinezhad Noghre",
                "Christopher Neff",
                "Hamed Tabkhi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02078v1",
                "http://arxiv.org/pdf/2312.02078v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02075v1",
            "title": "Non-Gaussian Likelihoods for Type Ia Supernovae Cosmology: Implications\n  for Dark Energy and $H_0$",
            "updated": "2023-12-04T17:39:47Z",
            "published": "2023-12-04T17:39:47Z",
            "summary": "The latest improvements in the scale and calibration of Type Ia supernovae\ncatalogues allow us to constrain the specific nature and evolution of dark\nenergy through its effect on the expansion history of the universe. We present\nthe results of Bayesian cosmological model comparison on the SNe~Ia catalogue\nPantheon+, where Flat $\\Lambda$CDM is preferred by the data over all other\nmodels and we find moderate evidence ($\\Delta \\log \\mathcal{Z} \\sim 2.5$) to\nreject a number of the alternate dark energy models. The effect of peculiar\nvelocity corrections on model comparison is analysed, where we show that\nremoving the peculiar velocity corrections results in a varying fit on\nnon-$\\Lambda$CDM parameters. As well as comparing cosmological models, the\nBayesian methodology is extended to comparing the scatter model of the data,\ntesting for non-gaussianity in the Pantheon+ Hubble residuals. We find that\nadding a scale parameter to the Pantheon+ covariances, or alternately using a\nmultivariate Student's t-distribution fits the data better than the fiducial\nanalysis, producing a cosmology independent evidence increase of $\\Delta \\log\n\\mathcal{Z} = 2.29 $ and $2.46$ respectively. This improved treatment of the\nscatter decreases the uncertainty in the constraint on the Hubble constant,\nfinding $H_0 = 73.67 \\pm 0.99 $ km s$^{-1}$ Mpc$^{-1}$, in $ 5.7 \\sigma$\ntension with Planck. We also explore $M_B$ transition models as a potential\nsolution for the Hubble tension, finding no evidence to support these models\namong the SNe data.",
            "author": [
                "Toby Lovick",
                "Suhail Dhawan",
                "Will Handley"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02075v1",
                "http://arxiv.org/pdf/2312.02075v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02074v1",
            "title": "Federated Learning is Better with Non-Homomorphic Encryption",
            "updated": "2023-12-04T17:37:41Z",
            "published": "2023-12-04T17:37:41Z",
            "summary": "Traditional AI methodologies necessitate centralized data collection, which\nbecomes impractical when facing problems with network communication, data\nprivacy, or storage capacity. Federated Learning (FL) offers a paradigm that\nempowers distributed AI model training without collecting raw data. There are\ndifferent choices for providing privacy during FL training. One of the popular\nmethodologies is employing Homomorphic Encryption (HE) - a breakthrough in\nprivacy-preserving computation from Cryptography. However, these methods have a\nprice in the form of extra computation and memory footprint. To resolve these\nissues, we propose an innovative framework that synergizes permutation-based\ncompressors with Classical Cryptography, even though employing Classical\nCryptography was assumed to be impossible in the past in the context of FL. Our\nframework offers a way to replace HE with cheaper Classical Cryptography\nprimitives which provides security for the training process. It fosters\nasynchronous communication and provides flexible deployment options in various\ncommunication topologies.",
            "author": [
                "Konstantin Burlachenko",
                "Abdulmajeed Alrowithi",
                "Fahad Ali Albalawi",
                "Peter Richtarik"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3630048.3630182",
                "http://arxiv.org/abs/2312.02074v1",
                "http://arxiv.org/pdf/2312.02074v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "math.OC",
                "G.1.6; E.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02250v1",
            "title": "Valuing Post-Revenue Biopharmaceutical Assets with Pfizer's Current\n  Portfolio as a Case Study",
            "updated": "2023-12-04T17:37:27Z",
            "published": "2023-12-04T17:37:27Z",
            "summary": "This research paper addresses the critical challenge of accurately valuing\npost-revenue drug assets in the biotechnology and pharmaceutical sectors, a key\nfactor influencing a wide range of strategic operations and investment\ndecisions. Recognizing the importance of reliable valuations for stakeholders\nsuch as pharmaceutical companies, venture capitalists, and private equity\nfirms, this study introduces a novel model for forecasting future sales of\npost-revenue biopharmaceutical assets. The proposed model leverages historical\nsales data, a resource known for its high quality and availability in company\nfinancial records, to produce distributional estimates of cumulative sales for\nindividual assets. These estimates are instrumental in calculating the Net\nPresent Value of each asset, thereby facilitating more informed and strategic\ninvestment decisions. A practical application of this model is demonstrated\nthrough its implementation in analyzing Pfizer's portfolio of post-revenue\nassets. This precision highlights the model's potential as a valuable tool in\nthe financial assessment and decision-making processes within the biotech and\npharmaceutical industries, offering a methodical approach to identifying\ninvestment opportunities and optimizing capital allocation.",
            "author": [
                "Yongzhuo Chen",
                "Yixuan Liang",
                "Yiran Liu",
                "Brian Hobbs",
                "Michael Kane"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02250v1",
                "http://arxiv.org/pdf/2312.02250v1"
            ],
            "primary_category": "q-fin.PR",
            "category": [
                "q-fin.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02073v1",
            "title": "A Glitch in the Matrix? Locating and Detecting Language Model Grounding\n  with Fakepedia",
            "updated": "2023-12-04T17:35:42Z",
            "published": "2023-12-04T17:35:42Z",
            "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\nstoring and recalling factual knowledge, but also in adapting to novel\nin-context information. Yet, the mechanisms underlying their in-context\ngrounding remain unknown, especially in situations where in-context information\ncontradicts factual knowledge embedded in the parameters. This is critical for\nretrieval-augmented generation methods, which enrich the context with\nup-to-date information, hoping that grounding can rectify the outdated\nparametric knowledge. In this study, we introduce Fakepedia, a counterfactual\ndataset designed to evaluate grounding abilities when the parametric knowledge\nclashes with the in-context information. We benchmark various LLMs with\nFakepedia and discover that GPT-4-turbo has a strong preference for its\nparametric knowledge. Mistral-7B, on the contrary, is the model that most\nrobustly chooses the grounded answer. Then, we conduct causal mediation\nanalysis on LLM components when answering Fakepedia queries. We demonstrate\nthat inspection of the computational graph alone can predict LLM grounding with\n92.8% accuracy, especially because few MLPs in the Transformer can predict\nnon-grounded behavior. Our results, together with existing findings about\nfactual recall mechanisms, provide a coherent narrative of how grounding and\nfactual recall mechanisms interact within LLMs.",
            "author": [
                "Giovanni Monea",
                "Maxime Peyrard",
                "Martin Josifoski",
                "Vishrav Chaudhary",
                "Jason Eisner",
                "Emre K\u0131c\u0131man",
                "Hamid Palangi",
                "Barun Patra",
                "Robert West"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02073v1",
                "http://arxiv.org/pdf/2312.02073v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02249v1",
            "title": "Recursive Visual Programming",
            "updated": "2023-12-04T17:27:24Z",
            "published": "2023-12-04T17:27:24Z",
            "summary": "Visual Programming (VP) has emerged as a powerful framework for Visual\nQuestion Answering (VQA). By generating and executing bespoke code for each\nquestion, these methods demonstrate impressive compositional and reasoning\ncapabilities, especially in few-shot and zero-shot scenarios. However, existing\nVP methods generate all code in a single function, resulting in code that is\nsuboptimal in terms of both accuracy and interpretability. Inspired by human\ncoding practices, we propose Recursive Visual Programming (RVP), which\nsimplifies generated routines, provides more efficient problem solving, and can\nmanage more complex data structures. RVP is inspired by human coding practices\nand approaches VQA tasks with an iterative recursive code generation approach,\nallowing decomposition of complicated problems into smaller parts. Notably, RVP\nis capable of dynamic type assignment, i.e., as the system recursively\ngenerates a new piece of code, it autonomously determines the appropriate\nreturn type and crafts the requisite code to generate that output. We show\nRVP's efficacy through extensive experiments on benchmarks including VSR, COVR,\nGQA, and NextQA, underscoring the value of adopting human-like recursive and\nmodular programming techniques for solving VQA tasks through coding.",
            "author": [
                "Jiaxin Ge",
                "Sanjay Subramanian",
                "Baifeng Shi",
                "Roei Herzig",
                "Trevor Darrell"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02249v1",
                "http://arxiv.org/pdf/2312.02249v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02065v1",
            "title": "Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?",
            "updated": "2023-12-04T17:19:53Z",
            "published": "2023-12-04T17:19:53Z",
            "summary": "Large language models (LLMs) offer a range of new possibilities, including\nadapting the text to different audiences and their reading needs. But how well\ndo they adapt? We evaluate the readability of answers generated by four\nstate-of-the-art LLMs (commercial and open-source) to science questions when\nprompted to target different age groups and education levels. To assess the\nadaptability of LLMs to diverse audiences, we compare the readability scores of\nthe generated responses against the recommended comprehension level of each age\nand education group. We find large variations in the readability of the answers\nby different LLMs. Our results suggest LLM answers need to be better adapted to\nthe intended audience demographics to be more comprehensible. They underline\nthe importance of enhancing the adaptability of LLMs in education settings to\ncater to diverse age and education levels. Overall, current LLMs have set\nreadability ranges and do not adapt well to different audiences, even when\nprompted. That limits their potential for educational purposes.",
            "author": [
                "Donya Rooein",
                "Amanda Cercas Curry",
                "Dirk Hovy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02065v1",
                "http://arxiv.org/pdf/2312.02065v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02063v1",
            "title": "The GPU Phase Folding and Deep Learning Method for Detecting Exoplanet\n  Transits",
            "updated": "2023-12-04T17:19:37Z",
            "published": "2023-12-04T17:19:37Z",
            "summary": "This paper presents GPFC, a novel Graphics Processing Unit (GPU) Phase\nFolding and Convolutional Neural Network (CNN) system to detect exoplanets\nusing the transit method. We devise a fast folding algorithm parallelized on a\nGPU to amplify low signal-to-noise ratio transit signals, allowing a search at\nhigh precision and speed. A CNN trained on two million synthetic light curves\nreports a score indicating the likelihood of a planetary signal at each period.\nGPFC improves on speed by three orders of magnitude over the predominant\nBox-fitting Least Squares (BLS) method. Our simulation results show GPFC\nachieves 97% training accuracy, higher true positive rate at the same false\npositive rate of detection, and higher precision at the same recall rate when\ncompared to BLS. GPFC recovers 100% of known ultra-short-period planets in\nKepler light curves from a blind search. These results highlight the promise of\nGPFC as an alternative approach to the traditional BLS algorithm for finding\nnew transiting exoplanets in data taken with Kepler and other space transit\nmissions such as K2, TESS and future PLATO and Earth 2.0.",
            "author": [
                "Kaitlyn Wang",
                "Kevin Wang",
                "Jian Ge",
                "Yinan Zhao",
                "Kevin Willis"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02063v1",
                "http://arxiv.org/pdf/2312.02063v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02062v1",
            "title": "Ultraviolet H$_2$ luminescence in molecular clouds induced by cosmic\n  rays",
            "updated": "2023-12-04T17:19:21Z",
            "published": "2023-12-04T17:19:21Z",
            "summary": "Galactic cosmic rays (CRs) play a crucial role in ionisation, dissociation,\nand excitation processes within dense cloud regions where UV radiation is\nabsorbed by dust grains and gas species. CRs regulate the abundance of ions and\nradicals, leading to the formation of more and more complex molecular species,\nand determine the charge distribution on dust grains. A quantitative analysis\nof these effects is essential for understanding the dynamical and chemical\nevolution of star-forming regions. The CR-induced photon flux has a significant\nimpact on the evolution of the dense molecular medium in its gas and dust\ncomponents. This study is intended to evaluate the flux of UV photons generated\nby CRs to calculate the photon-induced dissociation and ionisation rates of a\nvast number of atomic and molecular species, as well as the integrated UV\nphoton flux. Our study takes advantage of recent developments in the\ndetermination of the spectra of secondary electrons, in the calculation of\nstate-resolved excitation cross sections of H$_2$ by electron impact, and of\nphotodissociation and photoionisation cross sections. We calculate the H$_2$\nlevel population of each rovibrational level of the $X$, $B$, $C$, $B'$, $D$,\n$B''$, $D'$ and $a$ states. We then compute the UV photon spectrum of H$_2$ in\nits line and continuum components between 72 and 700 nm, with unprecedented\naccuracy as a function of the CR spectrum incident on a molecular cloud, the\nH$_2$ column density, the isomeric H$_2$ composition, and the dust properties.\nThe resulting photodissociation and photoionisation rates are, on average,\nsmaller than previous determinations by a factor of about 2, with deviations up\nto a factor of 5. A special focus is given to the photoionisation rates of\nH$_2$, HF, and H$_2$, as well as to the photodissociation of H$_2$, which we\nfind to be orders of magnitude higher than previous estimates.",
            "author": [
                "Marco Padovani",
                "Daniele Galli",
                "Liam H. Scarlett",
                "Tommaso Grassi",
                "Una S. Rehill",
                "Mark C. Zammit",
                "Igor Bray",
                "Dmitry V. Fursa"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02062v1",
                "http://arxiv.org/pdf/2312.02062v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02060v1",
            "title": "Right-sizing compute resource allocations for bioinformatics tools with\n  Total Perspective Vortex",
            "updated": "2023-12-04T17:18:24Z",
            "published": "2023-12-04T17:18:24Z",
            "summary": "In biomedical research, computational methods have become indispensable and\ntheir use is increasing, making the efficient allocation of computing resources\nparamount. Practitioners routinely allocate resources far in excess of what is\nrequired for batch processing jobs, leading to not just inflated wait times and\ncosts, but also unnecessary carbon emissions. This is not without reason\nhowever, as accurately determining resource needs is complex, affected by the\nnature of tools, data size, and analysis parameters, especially on popular\nservers that handle numerous jobs. The Galaxy platform, a web-based hub for\nbiomedical analysis used globally by scientists, exemplifies this challenge.\nServing nearly half a million registered users and managing around 2 million\nmonthly jobs, Galaxy's growth outpaces the resources at its disposal. This is\nnecessitating smarter resource utilization. To address this, we have developed\na tool named Total Perspective Vortex (TPV) - a software package that\nright-sizes resource allocations for each job. TPV is able to dynamically set\nresource requirements for individual jobs and perform meta-scheduling across\nheterogeneous resources. It also includes a first-ever community-curated\ndatabase of default resource requirements for nearly 1,000 popular\nbioinformatics tools. Deployments in Galaxy Australia and Europe demonstrate\nits effectiveness with meta-scheduling user jobs and an improved experience for\nsystems administrators managing Galaxy servers.",
            "author": [
                "Nuwan Goonasekera",
                "Catherine Bromhead",
                "Simon Gladman",
                "Nate Coraor",
                "Bjorn Gruning",
                "Enis Afgan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02060v1",
                "http://arxiv.org/pdf/2312.02060v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02059v1",
            "title": "On the Contact Process with Modified Border",
            "updated": "2023-12-04T17:17:40Z",
            "published": "2023-12-04T17:17:40Z",
            "summary": "We study a one-dimensional contact process with two infection parameters. One\ngiving the infection rates at the boundaries of a finite infected region and\nthe other one the rates within that region. We prove that the critical value of\neach of these parameters is a strictly monotone continuous function of the\nother parameter. We also show that if one of these parameters is equal to the\ncritical value of the standard contact process and the other parameter is\nstrictly larger, then the infection starting from a single point has positive\nprobability of surviving.",
            "author": [
                "Enrique Andjel",
                "Leonardo T. Rolla"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02059v1",
                "http://arxiv.org/pdf/2312.02059v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02056v1",
            "title": "A Method for Finding All Permutiples with a Fixed Set of Digits from a\n  Single Known Example",
            "updated": "2023-12-04T17:14:19Z",
            "published": "2023-12-04T17:14:19Z",
            "summary": "A permutiple is a natural number that is a nontrivial multiple of a\npermutation of its digits in some base. Special cases of permutiples include\ncyclic numbers (multiples of cyclic permutations of their digits) and\npalintiple numbers (multiples of their digit reversals). While cyclic numbers\nhave a fairly straightforward description, palintiple numbers admit many\nvarieties and cases. A previous paper attempts to get a better handle on the\ngeneral case by constructing new examples of permutiples with the same set of\ndigits, multiplier, and length as a known example. However, the results are not\nsufficient for finding all possible examples except when the multiplier divides\nthe base. Using an approach based on the methods of this previous paper, we\ndevelop a new method which enables us to find all examples under any\nconditions.",
            "author": [
                "Benjamin V. Holt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02056v1",
                "http://arxiv.org/pdf/2312.02056v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02054v1",
            "title": "From High to Low: Simulating Nondeterminism and State with State",
            "updated": "2023-12-04T17:13:17Z",
            "published": "2023-12-04T17:13:17Z",
            "summary": "Some effects are considered to be higher-level than others. High-level\neffects provide expressive and succinct abstraction of programming concepts,\nwhile low-level effects allow more fine-grained control over program execution\nand resources. Yet, often it is desirable to write programs using the\nconvenient abstraction offered by high-level effects, and meanwhile still\nbenefit from the optimisations enabled by low-level effects. One solution is to\ntranslate high-level effects to low-level ones.\n  This paper studies how algebraic effects and handlers allow us to simulate\nhigh-level effects in terms of low-level effects. In particular, we focus on\nthe interaction between state and nondeterminism known as the local state, as\nprovided by Prolog. We map this high-level semantics in successive steps onto a\nlow-level composite state effect, similar to that managed by Prolog's Warren\nAbstract Machine. We first give a translation from the high-level local-state\nsemantics to the low-level global-state semantics, by explicitly restoring\nstate updates on backtracking. Next, we eliminate nondeterminsm altogether in\nfavor of a lower-level state containing a choicepoint stack. Then we avoid\ncopying the state by restricting ourselves to incremental, reversible state\nupdates. We show how these updates can be stored on a trail stack with another\nstate effect. We prove the correctness of all our steps using program\ncalculation where the fusion laws of effect handlers play a central role.",
            "author": [
                "Wenhao Tang",
                "Tom Schrijvers"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02054v1",
                "http://arxiv.org/pdf/2312.02054v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02053v1",
            "title": "Tensions in $e^+e^-\\to\u03c0^+\u03c0^-(\u03b3)$ measurements: the new\n  landscape of data-driven hadronic vacuum polarization predictions for the\n  muon $g-2$",
            "updated": "2023-12-04T17:12:20Z",
            "published": "2023-12-04T17:12:20Z",
            "summary": "The situation of the experimental data used in the dispersive evaluation of\nthe hadronic vacuum polarization contribution to the anomalous magnetic moment\nof the muon is assessed in view of two recent measurements: $e^+e^- \\to\n\\pi^+\\pi^-$ cross sections in the $\\rho$ resonance region by CMD-3 and a study\nof higher-order radiative effects in the initial-state-radiation processes\n$e^+e^- \\to \\mu^+\\mu^-\\gamma$ and $e^+e^- \\to \\pi^+\\pi^-\\gamma$ by BABAR. The\nimpact of the latter study on the KLOE and BESIII cross-section measurements is\nevaluated and found to be indicative of larger systematic effects than\nuncertainties assigned. The new situation also warrants a reappraisal of the\nindependent information provided by hadronic $\\tau$ decays, including\nstate-of-the-art isospin-breaking corrections. The findings cast a new light on\nthe longstanding deviation between the muon $g-2$ measurement and the Standard\nModel prediction using the data-driven dispersive approach, and the comparison\nwith lattice QCD calculations.",
            "author": [
                "M. Davier",
                "A. Hoecker",
                "A. M. Lutz",
                "B. Malaescu",
                "Z. Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02053v1",
                "http://arxiv.org/pdf/2312.02053v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02052v1",
            "title": "DUCK: Distance-based Unlearning via Centroid Kinematics",
            "updated": "2023-12-04T17:10:25Z",
            "published": "2023-12-04T17:10:25Z",
            "summary": "Machine Unlearning is rising as a new field, driven by the pressing necessity\nof ensuring privacy in modern artificial intelligence models. This technique\nprimarily aims to eradicate any residual influence of a specific subset of data\nfrom the knowledge acquired by a neural model during its training. This work\nintroduces a novel unlearning algorithm, denoted as Distance-based Unlearning\nvia Centroid Kinematics (DUCK), which employs metric learning to guide the\nremoval of samples matching the nearest incorrect centroid in the embedding\nspace. Evaluation of the algorithm's performance is conducted across various\nbenchmark datasets in two distinct scenarios, class removal, and homogeneous\nsampling removal, obtaining state-of-the-art performance. We introduce a novel\nmetric, called Adaptive Unlearning Score (AUS), encompassing not only the\nefficacy of the unlearning process in forgetting target data but also\nquantifying the performance loss relative to the original model. Moreover, we\npropose a novel membership inference attack to assess the algorithm's capacity\nto erase previously acquired knowledge, designed to be adaptable to future\nmethodologies.",
            "author": [
                "Marco Cotogni",
                "Jacopo Bonato",
                "Luigi Sabetta",
                "Francesco Pelosin",
                "Alessandro Nicolosi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02052v1",
                "http://arxiv.org/pdf/2312.02052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03755v1",
            "title": "Near-real-time Earthquake-induced Fatality Estimation using Crowdsourced\n  Data and Large-Language Models",
            "updated": "2023-12-04T17:09:58Z",
            "published": "2023-12-04T17:09:58Z",
            "summary": "When a damaging earthquake occurs, immediate information about casualties is\ncritical for time-sensitive decision-making by emergency response and aid\nagencies in the first hours and days. Systems such as Prompt Assessment of\nGlobal Earthquakes for Response (PAGER) by the U.S. Geological Survey (USGS)\nwere developed to provide a forecast within about 30 minutes of any significant\nearthquake globally. Traditional systems for estimating human loss in disasters\noften depend on manually collected early casualty reports from global media, a\nprocess that's labor-intensive and slow with notable time delays. Recently,\nsome systems have employed keyword matching and topic modeling to extract\nrelevant information from social media. However, these methods struggle with\nthe complex semantics in multilingual texts and the challenge of interpreting\never-changing, often conflicting reports of death and injury numbers from\nvarious unverified sources on social media platforms. In this work, we\nintroduce an end-to-end framework to significantly improve the timeliness and\naccuracy of global earthquake-induced human loss forecasting using\nmulti-lingual, crowdsourced social media. Our framework integrates (1) a\nhierarchical casualty extraction model built upon large language models, prompt\ndesign, and few-shot learning to retrieve quantitative human loss claims from\nsocial media, (2) a physical constraint-aware, dynamic-truth discovery model\nthat discovers the truthful human loss from massive noisy and potentially\nconflicting human loss claims, and (3) a Bayesian updating loss projection\nmodel that dynamically updates the final loss estimation using discovered\ntruths. We test the framework in real-time on a series of global earthquake\nevents in 2021 and 2022 and show that our framework streamlines casualty data\nretrieval, achieving speed and accuracy comparable to manual methods by USGS.",
            "author": [
                "Chenguang Wang",
                "Davis Engler",
                "Xuechun Li",
                "James Hou",
                "David J. Wald",
                "Kishor Jaiswal",
                "Susu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03755v1",
                "http://arxiv.org/pdf/2312.03755v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02051v1",
            "title": "TimeChat: A Time-sensitive Multimodal Large Language Model for Long\n  Video Understanding",
            "updated": "2023-12-04T17:09:52Z",
            "published": "2023-12-04T17:09:52Z",
            "summary": "This work proposes TimeChat, a time-sensitive multimodal large language model\nspecifically designed for long video understanding. Our model incorporates two\nkey architectural contributions: (1) a timestamp-aware frame encoder that binds\nvisual content with the timestamp of each frame, and (2) a sliding video\nQ-Former that produces a video token sequence of varying lengths to accommodate\nvideos of various durations. Additionally, we construct an instruction-tuning\ndataset, encompassing 6 tasks and a total of 125K instances, to further enhance\nTimeChat's instruction-following performance. Experiment results across various\nvideo understanding tasks, such as dense captioning, temporal grounding, and\nhighlight detection, demonstrate TimeChat's strong zero-shot temporal\nlocalization and reasoning capabilities. For example, it achieves +9.2 F1 score\nand +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5)\non Charades-STA, compared to state-of-the-art video large language models,\nholding the potential to serve as a versatile video assistant for long-form\nvideo comprehension tasks and satisfy realistic user requirements.",
            "author": [
                "Shuhuai Ren",
                "Linli Yao",
                "Shicheng Li",
                "Xu Sun",
                "Lu Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02051v1",
                "http://arxiv.org/pdf/2312.02051v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02050v1",
            "title": "Optimal Dual-Polarized Planar Arrays for Massive Capacity Over\n  Point-to-Point MIMO Channels",
            "updated": "2023-12-04T17:07:15Z",
            "published": "2023-12-04T17:07:15Z",
            "summary": "Future wireless networks must provide ever higher data rates. The available\nbandwidth increases roughly linearly as we increase the carrier frequency, but\nthe range shrinks drastically. This paper explores if we can instead reach\nmassive capacities using spatial multiplexing over multiple-input\nmultiple-output (MIMO) channels. In line-of-sight (LOS) scenarios, therank of\nthe MIMO channel matrix depends on the polarization and antenna arrangement. We\noptimize the rank and condition number by identifying the optimal antenna\nspacing in dual-polarized planar antenna arrays with imperfect isolation. The\nresult is sparely spaced antenna arrays that exploit radiative near-field\nproperties. We further optimize the array geometry for minimum aperture length\nand aperture area, which leads to different configurations. Moreover, we prove\nanalytically that for fixed-sized arrays, the MIMO rank grows quadratically\nwith the carrier frequency in LOS scenarios, if the antennas are appropriately\ndesigned. Hence, MIMO technology contributes more to the capacity growth than\nthe bandwidth. The numerical results show that massive data rates, far beyond 1\nTbps, can be reached both over fixed point-to-point links. It is also possible\nfor a large base station to serve a practically-sized mobile device.",
            "author": [
                "Amna Irshad",
                "Alva Kosasih",
                "Emil Bj\u00f6rnson",
                "Luca Sanguinetti"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02050v1",
                "http://arxiv.org/pdf/2312.02050v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02042v1",
            "title": "Kirchhoff Meets Johnson: In Pursuit of Unconditionally Secure\n  Communication",
            "updated": "2023-12-04T16:59:24Z",
            "published": "2023-12-04T16:59:24Z",
            "summary": "Noise: an enemy to be dealt with and a major factor limiting communication\nsystem performance. However, what if there is gold in that garbage? In\nconventional engineering, our focus is primarily on eliminating, suppressing,\ncombating, or even ignoring noise and its detrimental impacts. Conversely,\ncould we exploit it similarly to biology, which utilizes noise-alike carrier\nsignals to convey information? In this context, the utilization of noise, or\nnoise-alike signals in general, has been put forward as a means to realize\nunconditionally secure communication systems in the future. In this tutorial\narticle, we begin by tracing the origins of thermal noise-based communication\nand highlighting one of its significant applications for ensuring\nunconditionally secure networks: the Kirchhoff-law-Johnson-noise (KLJN) secure\nkey exchange scheme. We then delve into the inherent challenges tied to secure\ncommunication and discuss the imperative need for physics-based key\ndistribution schemes in pursuit of unconditional security. Concurrently, we\nprovide a concise overview of quantum key distribution (QKD) schemes and draw\ncomparisons with their KLJN-based counterparts. Finally, extending beyond wired\ncommunication loops, we explore the transmission of noise signals over-the-air\nand evaluate their potential for stealth and secure wireless communication\nsystems.",
            "author": [
                "Ertugrul Basar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02042v1",
                "http://arxiv.org/pdf/2312.02042v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CR",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02040v1",
            "title": "Unbounded matroids",
            "updated": "2023-12-04T16:58:31Z",
            "published": "2023-12-04T16:58:31Z",
            "summary": "A matroid base polytope is a polytope in which each vertex has 0,1\ncoordinates and each edge is parallel to a difference of two coordinate\nvectors. Matroid base polytopes are described combinatorially by integral\nsubmodular functions on a boolean lattice, satisfying the unit increase\nproperty. We define a more general class of unbounded matroids, or U-matroids,\nby replacing the boolean lattice with an arbitrary distributive lattice.\nU-matroids thus serve as a combinatorial model for polyhedra that satisfy the\nvertex and edge conditions of matroid base polytopes, but may be unbounded.\nLike polymatroids, U-matroids generalize matroids and arise as a special case\nof submodular systems. We prove that every U-matroid admits a canonical largest\nextension to a matroid, which we call the generous extension; the analogous\ngeometric statement is that every U-matroid base polyhedron contains a unique\nlargest matroid base polytope. We show that the supports of vertices of a\nU-matroid base polyhedron span a shellable simplicial complex, and we\ncharacterize U-matroid basis systems in terms of shelling orders, generalizing\nBj\\\"orner's and Gale's criteria for a simplicial complex to be a matroid\nindependence complex. Finally, we present an application of our theory to\nsubspace arrangements and show that the generous extension has a natural\ngeometric interpretation in this setting.",
            "author": [
                "Jonah Berggren",
                "Jeremy L. Martin",
                "Jos\u00e9 A. Samper"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02040v1",
                "http://arxiv.org/pdf/2312.02040v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "05B35, 52B40, 52C35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02025v1",
            "title": "Self-Synchronized Trichel Pulse Trains in Multi-Point Corona Discharge\n  Systems",
            "updated": "2023-12-04T16:49:01Z",
            "published": "2023-12-04T16:49:01Z",
            "summary": "Evidence of self-synchronization has been observed in multi-electrode corona\ndischarge systems, where the application of high negative DC voltages induces a\nself-sustained mode of current pulse trains. These pulses, historically\nreferred to as Trichel pulses, characterize the operation of a two-electrode\nsystem where the discharge electrode is subjected to a high negative DC\nvoltage. The numerical algorithm reveals that in a two electrode discharge\nsystem, each of which is composed of a pair of electrodes operating in a pulsed\nmode, synchronization occurs due to weak yet significant interactions. These\ninteractions arise from the mutual influence of electric fields and space\ncharges generated by each discharge pair. This influence extends beyond\nindividual systems, leading to a synchronization between both pairs, both in a\npulsed mode. A three-species model of discharge was employed to simulate this\nprocess and it was based on the finite element method formulation. Two\ndifferent numerical models were investigated, a 2D model, consisting of two\ndischarge electrodes and a third grounded electrode, and two 1D-axisymmetric\nmodels, consisting dual and triple pairs of discharge systems. Experiments show\na multi-stable nature of the coupled pulsed discharge systems, indicating that\nunder appropriate conditions the pulse trains exhibit two distinct modes of\nsynchronization: in-phase synchronization and anti-phase synchronization. The\noccurrence of each mode depends on factors such as interaction strength,\napplied voltage level, and various system parameters. Furthermore, variations\nin these factors can lead to additional outcomes, including out of phase\nsynchronization, as well as scenarios involving near-harmonic oscillations and\nquenching.",
            "author": [
                "Afshin Shaygani",
                "Kazimierz Adamiak"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02025v1",
                "http://arxiv.org/pdf/2312.02025v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.SY",
                "eess.SY",
                "nlin.AO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02021v1",
            "title": "VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations\n  for Domain Generalized Semantic Segmentation",
            "updated": "2023-12-04T16:46:38Z",
            "published": "2023-12-04T16:46:38Z",
            "summary": "Domain generalization (DG) remains a significant challenge for perception\nbased on deep neural networks (DNN), where domain shifts occur due to lighting,\nweather, or geolocation changes. In this work, we propose VLTSeg to enhance\ndomain generalization in semantic segmentation, where the network is solely\ntrained on the source domain and evaluated on unseen target domains. Our method\nleverages the inherent semantic robustness of vision-language models. First, by\nsubstituting traditional vision-only backbones with pre-trained encoders from\nCLIP and EVA-CLIP as transfer learning setting we find that in the field of DG,\nvision-language pre-training significantly outperforms supervised and\nself-supervised vision pre-training. We thus propose a new vision-language\napproach for domain generalized segmentation, which improves the domain\ngeneralization SOTA by 7.6% mIoU when training on the synthetic GTA5 dataset.\nWe further show the superior generalization capabilities of vision-language\nsegmentation models by reaching 76.48% mIoU on the popular Cityscapes-to-ACDC\nbenchmark, outperforming the previous SOTA approach by 6.9% mIoU on the test\nset at the time of writing. Additionally, our approach shows strong in-domain\ngeneralization capabilities indicated by 86.1% mIoU on the Cityscapes test set,\nresulting in a shared first place with the previous SOTA on the current\nleaderboard at the time of submission.",
            "author": [
                "Christoph H\u00fcmmer",
                "Manuel Schwonberg",
                "Liangwei Zhong",
                "Hu Cao",
                "Alois Knoll",
                "Hanno Gottschalk"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02021v1",
                "http://arxiv.org/pdf/2312.02021v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02017v1",
            "title": "A multi-channel cycleGAN for CBCT to CT synthesis",
            "updated": "2023-12-04T16:40:53Z",
            "published": "2023-12-04T16:40:53Z",
            "summary": "Image synthesis is used to generate synthetic CTs (sCTs) from on-treatment\ncone-beam CTs (CBCTs) with a view to improving image quality and enabling\naccurate dose computation to facilitate a CBCT-based adaptive radiotherapy\nworkflow. As this area of research gains momentum, developments in sCT\ngeneration methods are difficult to compare due to the lack of large public\ndatasets and sizeable variation in training procedures. To compare and assess\nthe latest advancements in sCT generation, the SynthRAD2023 challenge provides\na public dataset and evaluation framework for both MR and CBCT to sCT\nsynthesis. Our contribution focuses on the second task, CBCT-to-sCT synthesis.\nBy leveraging a multi-channel input to emphasize specific image features, our\napproach effectively addresses some of the challenges inherent in CBCT imaging,\nwhilst restoring the contrast necessary for accurate visualisation of patients'\nanatomy. Additionally, we introduce an auxiliary fusion network to further\nenhance the fidelity of generated sCT images.",
            "author": [
                "Chelsea A. H. Sargeant",
                "Edward G. A. Henderson",
                "D\u00f3nal M. McSweeney",
                "Aaron G. Rankin",
                "Denis Page"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02017v1",
                "http://arxiv.org/pdf/2312.02017v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02012v1",
            "title": "Optimal Data Generation in Multi-Dimensional Parameter Spaces, using\n  Bayesian Optimization",
            "updated": "2023-12-04T16:36:29Z",
            "published": "2023-12-04T16:36:29Z",
            "summary": "Acquiring a substantial number of data points for training accurate machine\nlearning (ML) models is a big challenge in scientific fields where data\ncollection is resource-intensive. Here, we propose a novel approach for\nconstructing a minimal yet highly informative database for training ML models\nin complex multi-dimensional parameter spaces. To achieve this, we mimic the\nunderlying relation between the output and input parameters using Gaussian\nprocess regression (GPR). Using a set of known data, GPR provides predictive\nmeans and standard deviation for the unknown data. Given the predicted standard\ndeviation by GPR, we select data points using Bayesian optimization to obtain\nan efficient database for training ML models. We compare the performance of ML\nmodels trained on databases obtained through this method, with databases\nobtained using traditional approaches. Our results demonstrate that the ML\nmodels trained on the database obtained using Bayesian optimization approach\nconsistently outperform the other two databases, achieving high accuracy with a\nsignificantly smaller number of data points. Our work contributes to the\nresource-efficient collection of data in high-dimensional complex parameter\nspaces, to achieve high precision machine learning predictions.",
            "author": [
                "M. R. Mahani",
                "Igor A. Nechepurenko",
                "Yasmin Rahimof",
                "Andreas Wicht"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02012v1",
                "http://arxiv.org/pdf/2312.02012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.app-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02011v1",
            "title": "What is the disinformation problem? Reviewing the dominant paradigm and\n  motivating an alternative sociopolitical view",
            "updated": "2023-12-04T16:34:31Z",
            "published": "2023-12-04T16:34:31Z",
            "summary": "Disinformation research has proliferated in reaction to widespread false,\nproblematic beliefs purported to explain major social phenomena. Yet while the\neffects of disinformation are well-known, there is less consensus about its\ncauses; the research spans several disciplines, each focusing on different\npieces. This article contributes to this growing field by reviewing prevalent\nU.S. disinformation discourse (academic writing, media, and corporate and\ngovernment narrative) and outlining the dominant understanding, or paradigm, of\nthe disinformation problem by analyzing cross-disciplinary discourse about the\ncontent, individual, group, and institutional layers of the problem. The result\nis an individualistic explanation largely blaming social media, malicious\nindividuals or nations, and irrational people. Yet this understanding has\nshortcomings: notably, that its limited, individualistic views of truth and\nrationality obscures the influence of oppressive ideologies and media or\ndomestic actors in creating flawed worldviews and spreading disinformation. The\narticle then concludes by putting forth an alternative, sociopolitical paradigm\nthat allows subjective models of the world to govern rationality and\ninformation processing -- largely informed by social and group identity --\nwhich are being formed and catered to by institutional actors (corporations,\nmedia, political parties, and the government) to maintain or gain legitimacy\nfor their actions.",
            "author": [
                "Nicholas Rabb"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02011v1",
                "http://arxiv.org/pdf/2312.02011v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02005v1",
            "title": "Remote sensing of backward reflection from stimulated axion decay",
            "updated": "2023-12-04T16:26:04Z",
            "published": "2023-12-04T16:26:04Z",
            "summary": "We propose a method for remotely detecting backward reflection via induced\ndecay of cold dark matter such as axion in the background of a propagating\ncoherent photon field. This method can be particularly useful for probing\nconcentrated dark matter streams by Earth's gravitational lensing effect.\nFormulae for the stimulated reflection process and the expected sensitivities\nin local and remote experimental approaches are provided for testing eV scale\naxion models using broad band lasers. The generic axion-photon coupling is\nexpected to be explorable up to ${\\cal O}(10^{-12})$ GeV${}^{-1}$ and ${\\cal\nO}(10^{-22})$ GeV${}^{-1}$ for the idealized local and remote setups,\nrespectively.",
            "author": [
                "Kensuke Homma"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02005v1",
                "http://arxiv.org/pdf/2312.02005v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02003v1",
            "title": "A Survey on Large Language Model (LLM) Security and Privacy: The Good,\n  the Bad, and the Ugly",
            "updated": "2023-12-04T16:25:18Z",
            "published": "2023-12-04T16:25:18Z",
            "summary": "Large Language Models (LLMs), such as GPT-3 and BERT, have revolutionized\nnatural language understanding and generation. They possess deep language\ncomprehension, human-like text generation capabilities, contextual awareness,\nand robust problem-solving skills, making them invaluable in various domains\n(e.g., search engines, customer support, translation). In the meantime, LLMs\nhave also gained traction in the security community, revealing security\nvulnerabilities and showcasing their potential in security-related tasks. This\npaper explores the intersection of LLMs with security and privacy.\nSpecifically, we investigate how LLMs positively impact security and privacy,\npotential risks and threats associated with their use, and inherent\nvulnerabilities within LLMs. Through a comprehensive literature review, the\npaper categorizes findings into \"The Good\" (beneficial LLM applications), \"The\nBad\" (offensive applications), and \"The Ugly\" (vulnerabilities and their\ndefenses). We have some interesting findings. For example, LLMs have proven to\nenhance code and data security, outperforming traditional methods. However,\nthey can also be harnessed for various attacks (particularly user-level\nattacks) due to their human-like reasoning abilities. We have identified areas\nthat require further research efforts. For example, research on model and\nparameter extraction attacks is limited and often theoretical, hindered by LLM\nparameter scale and confidentiality. Safe instruction tuning, a recent\ndevelopment, requires more exploration. We hope that our work can shed light on\nthe LLMs' potential to both bolster and jeopardize cybersecurity.",
            "author": [
                "Yifan Yao",
                "Jinhao Duan",
                "Kaidi Xu",
                "Yuanfang Cai",
                "Eric Sun",
                "Yue Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02003v1",
                "http://arxiv.org/pdf/2312.02003v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02000v1",
            "title": "The polarisation properties of the HD 181327 debris ring. Evidence for\n  sub-micron particles from scattered light observations",
            "updated": "2023-12-04T16:23:42Z",
            "published": "2023-12-04T16:23:42Z",
            "summary": "Polarisation is a powerful remote-sensing tool to study the nature of\nparticles scattering the starlight. It is widely used to characterise\ninterplanetary dust particles in the Solar System and increasingly employed to\ninvestigate extrasolar dust in debris discs' systems. We aim to measure the\nscattering properties of the dust from the debris ring around HD 181327 at\nnear-infrared wavelengths. We obtained high-contrast polarimetric images of HD\n181327 in the H band with the SPHERE / IRDIS instrument on the Very Large\nTelescope (ESO). We complemented them with archival data from HST / NICMOS in\nthe F110W filter reprocessed in the context of the Archival Legacy\nInvestigations of Circumstellar Environments (ALICE) project. We developed a\ncombined forward-modelling framework to simultaneously retrieve the scattering\nphase function in polarisation and intensity. We detected the debris disc\naround HD 181327 in polarised light and total intensity. We measured the\nscattering phase function and the degree of linear polarisation of the dust at\n1.6 micron in the birth ring. The maximum polarisation is 23.6% +/- 2.6% and\noccurs between a scattering angle of 70 deg and 82 deg. We show that compact\nspherical particles made of a highly refractive and relatively absorbing\nmaterial in a differential power-law size distribution of exponent $-3.5$ can\nsimultaneously reproduce the polarimetric and total intensity scattering\nproperties of the dust. This type of material cannot be obtained with a mixture\nof silicates, amorphous carbon, water ice, and porosity, and requires a more\nrefracting component such as iron-bearing minerals. We reveal a striking\nanalogy between the near-infrared polarisation of comets and that of HD 181327.\nThe methodology developed here combining VLT/SPHERE and HST/NICMOS may be\napplicable in the future to combine the polarimetric capabilities of SPHERE\nwith the sensitivity of JWST.",
            "author": [
                "Julien Milli",
                "Elodie Choquet",
                "Ryo Tazaki",
                "Fran\u00e7ois M\u00e9nard",
                "Jean-Charles Augereau",
                "Johan Olofsson",
                "Philippe Th\u00e9bault",
                "Olivier Poch",
                "Anny-Chantal Levasseur-Regourd",
                "J\u00e9r\u00e9mie Lasue",
                "Jean-Baptiste Renard",
                "Edith Hadamcik",
                "Cl\u00e9ment Baruteau",
                "Hans Martin Schmid",
                "Natalia Engler",
                "Rob G. van Holstein",
                "Evgenij Zubko",
                "Anne-Marie Lagrange",
                "Sebastian Marino",
                "Chirstophe Pinte",
                "Carsten Dominik",
                "Anthony Boccaletti",
                "Maud Langlois",
                "Alice Zurlo",
                "C\u00e9lia Desgrange",
                "Laurence Gluck",
                "David Mouillet",
                "Anne Costille",
                "Jean-Fran\u00e7ois Sauvage"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02000v1",
                "http://arxiv.org/pdf/2312.02000v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01999v1",
            "title": "SRTransGAN: Image Super-Resolution using Transformer based Generative\n  Adversarial Network",
            "updated": "2023-12-04T16:22:39Z",
            "published": "2023-12-04T16:22:39Z",
            "summary": "Image super-resolution aims to synthesize high-resolution image from a\nlow-resolution image. It is an active area to overcome the resolution\nlimitations in several applications like low-resolution object-recognition,\nmedical image enhancement, etc. The generative adversarial network (GAN) based\nmethods have been the state-of-the-art for image super-resolution by utilizing\nthe convolutional neural networks (CNNs) based generator and discriminator\nnetworks. However, the CNNs are not able to exploit the global information very\neffectively in contrast to the transformers, which are the recent breakthrough\nin deep learning by exploiting the self-attention mechanism. Motivated from the\nsuccess of transformers in language and vision applications, we propose a\nSRTransGAN for image super-resolution using transformer based GAN.\nSpecifically, we propose a novel transformer-based encoder-decoder network as a\ngenerator to generate 2x images and 4x images. We design the discriminator\nnetwork using vision transformer which uses the image as sequence of patches\nand hence useful for binary classification between synthesized and real\nhigh-resolution images. The proposed SRTransGAN outperforms the existing\nmethods by 4.38 % on an average of PSNR and SSIM scores. We also analyze the\nsaliency map to understand the learning ability of the proposed method.",
            "author": [
                "Neeraj Baghel",
                "Shiv Ram Dubey",
                "Satish Kumar Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01999v1",
                "http://arxiv.org/pdf/2312.01999v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01998v1",
            "title": "Language-only Efficient Training of Zero-shot Composed Image Retrieval",
            "updated": "2023-12-04T16:22:06Z",
            "published": "2023-12-04T16:22:06Z",
            "summary": "Composed image retrieval (CIR) task takes a composed query of image and text,\naiming to search relative images for both conditions. Conventional CIR\napproaches need a training dataset composed of triplets of query image, query\ntext, and target image, which is very expensive to collect. Several recent\nworks have worked on the zero-shot (ZS) CIR paradigm to tackle the issue\nwithout using pre-collected triplets. However, the existing ZS-CIR methods show\nlimited backbone scalability and generalizability due to the lack of diversity\nof the input texts during training. We propose a novel CIR framework, only\nusing language for its training. Our LinCIR (Language-only training for CIR)\ncan be trained only with text datasets by a novel self-supervision named\nself-masking projection (SMP). We project the text latent embedding to the\ntoken embedding space and construct a new text by replacing the keyword tokens\nof the original text. Then, we let the new and original texts have the same\nlatent embedding vector. With this simple strategy, LinCIR is surprisingly\nefficient and highly effective; LinCIR with CLIP ViT-G backbone is trained in\n48 minutes and shows the best ZS-CIR performances on four different CIR\nbenchmarks, CIRCO, GeneCIS, FashionIQ, and CIRR, even outperforming supervised\nmethod on FashionIQ. Code is available at https://github.com/navervision/lincir",
            "author": [
                "Geonmo Gu",
                "Sanghyuk Chun",
                "Wonjae Kim",
                "Yoohoon Kang",
                "Sangdoo Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01998v1",
                "http://arxiv.org/pdf/2312.01998v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01995v1",
            "title": "The Waste-to-Biomethane Logistic Problem: A mathematical optimization\n  approach",
            "updated": "2023-12-04T16:15:37Z",
            "published": "2023-12-04T16:15:37Z",
            "summary": "In this paper, we propose a new mathematical optimization approach to make\ndecisions on the optimal design of a logistic system to produce biogas from\nwaste. We provide an integrated model that allows decision makers to optimally\ndetermine the locations of different types of plants and pipelines involved in\nthe logistic process, as well as the most efficient distribution of the\nproducts (from waste to biomethane) along the supply chain. We analyze the\nmathematical model and reduce its size, being able to solve realistic instances\nin reasonable CPU times. The results of our computational experiments, both in\nsynthetic and in a case study instance, prove the validity of our proposal in\npractical applications.",
            "author": [
                "V\u00edctor Blanco",
                "Yolanda Hinojosa",
                "Victor Zavala"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01995v1",
                "http://arxiv.org/pdf/2312.01995v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01994v1",
            "title": "A Generative Self-Supervised Framework using Functional Connectivity in\n  fMRI Data",
            "updated": "2023-12-04T16:14:43Z",
            "published": "2023-12-04T16:14:43Z",
            "summary": "Deep neural networks trained on Functional Connectivity (FC) networks\nextracted from functional Magnetic Resonance Imaging (fMRI) data have gained\npopularity due to the increasing availability of data and advances in model\narchitectures, including Graph Neural Network (GNN). Recent research on the\napplication of GNN to FC suggests that exploiting the time-varying properties\nof the FC could significantly improve the accuracy and interpretability of the\nmodel prediction. However, the high cost of acquiring high-quality fMRI data\nand corresponding phenotypic labels poses a hurdle to their application in\nreal-world settings, such that a model na\\\"ively trained in a supervised\nfashion can suffer from insufficient performance or a lack of generalization on\na small number of data. In addition, most Self-Supervised Learning (SSL)\napproaches for GNNs to date adopt a contrastive strategy, which tends to lose\nappropriate semantic information when the graph structure is perturbed or does\nnot leverage both spatial and temporal information simultaneously. In light of\nthese challenges, we propose a generative SSL approach that is tailored to\neffectively harness spatio-temporal information within dynamic FC. Our\nempirical results, experimented with large-scale (>50,000) fMRI datasets,\ndemonstrate that our approach learns valuable representations and enables the\nconstruction of accurate and robust models when fine-tuned for downstream\ntasks.",
            "author": [
                "Jungwon Choi",
                "Seongho Keum",
                "EungGu Yun",
                "Byung-Hoon Kim",
                "Juho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01994v1",
                "http://arxiv.org/pdf/2312.01994v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01992v1",
            "title": "Whence Nonlocality? Removing spooky action at a distance from the de\n  Broglie Bohm pilot-wave theory using a time-symmetric version of de Broglie\n  double solution",
            "updated": "2023-12-04T16:10:52Z",
            "published": "2023-12-04T16:10:52Z",
            "summary": "In this work, we review and extend a version of the old attempt made by Louis\nde broglie for interpreting quantum mechanics in realistic terms, namely the\ndouble solution. In this theory quantum particles are localized waves, i.e,\nsolitons, that are solutions of relativistic nonlinear field equations. The\ntheory that we present here is the natural extension of this old work and\nrelies on a strong time-symmetry requiring the presence of advanced and\nretarded waves converging on particles. Using this method, we are able to\njustify wave-particle duality and to explain the violations of Bell's\ninequalities. Moreover, the theory recovers the predictions of the pilot-wave\ntheory of de Borglie and Bohm, often known as Bohmian mechanics. As a direct\nconsequence, we reinterpret the nonlocal action at a distance presents in the\npilot-wave theory. In the double solution developed here there is fundamentally\nno action at a distance but the theory requires a form of superdeterminism\ndriven by time-symmetry.",
            "author": [
                "Aur\u00e9lien Drezet"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01992v1",
                "http://arxiv.org/pdf/2312.01992v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.hist-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01990v1",
            "title": "SARA-RT: Scaling up Robotics Transformers with Self-Adaptive Robust\n  Attention",
            "updated": "2023-12-04T16:08:47Z",
            "published": "2023-12-04T16:08:47Z",
            "summary": "We present Self-Adaptive Robust Attention for Robotics Transformers\n(SARA-RT): a new paradigm for addressing the emerging challenge of scaling up\nRobotics Transformers (RT) for on-robot deployment. SARA-RT relies on the new\nmethod of fine-tuning proposed by us, called up-training. It converts\npre-trained or already fine-tuned Transformer-based robotic policies of\nquadratic time complexity (including massive billion-parameter\nvision-language-action models or VLAs), into their efficient linear-attention\ncounterparts maintaining high quality. We demonstrate the effectiveness of\nSARA-RT by speeding up: (a) the class of recently introduced RT-2 models, the\nfirst VLA robotic policies pre-trained on internet-scale data, as well as (b)\nPoint Cloud Transformer (PCT) robotic policies operating on large point clouds.\nWe complement our results with the rigorous mathematical analysis providing\ndeeper insight into the phenomenon of SARA.",
            "author": [
                "Isabel Leal",
                "Krzysztof Choromanski",
                "Deepali Jain",
                "Avinava Dubey",
                "Jake Varley",
                "Michael Ryoo",
                "Yao Lu",
                "Frederick Liu",
                "Vikas Sindhwani",
                "Quan Vuong",
                "Tamas Sarlos",
                "Ken Oslund",
                "Karol Hausman",
                "Kanishka Rao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01990v1",
                "http://arxiv.org/pdf/2312.01990v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01987v1",
            "title": "Bootstrapping SparseFormers from Vision Foundation Models",
            "updated": "2023-12-04T16:04:41Z",
            "published": "2023-12-04T16:04:41Z",
            "summary": "The recently proposed SparseFormer architecture provides an alternative\napproach to visual understanding by utilizing a significantly lower number of\nvisual tokens via adjusting RoIs, greatly reducing computational costs while\nstill achieving promising performance. However, training SparseFormers from\nscratch is still expensive, and scaling up the number of parameters can be\nchallenging. In this paper, we propose to bootstrap SparseFormers from\nViT-based vision foundation models in a simple and efficient way. Since the\nmajority of SparseFormer blocks are the standard transformer ones, we can\ninherit weights from large-scale pre-trained vision transformers and freeze\nthem as much as possible. Therefore, we only need to train the\nSparseFormer-specific lightweight focusing transformer to adjust token RoIs and\nfine-tune a few early pre-trained blocks to align the final token\nrepresentation. In such a way, we can bootstrap SparseFormer architectures from\nvarious large-scale pre-trained models (e.g., IN-21K pre-trained AugRegs or\nCLIPs) using a rather smaller amount of training samples (e.g., IN-1K) and\nwithout labels or captions within just a few hours. As a result, the\nbootstrapped unimodal SparseFormer (from AugReg-ViT-L/16-384) can reach 84.9%\naccuracy on IN-1K with only 49 tokens, and the multimodal SparseFormer from\nCLIPs also demonstrates notable zero-shot performance with highly reduced\ncomputational cost without seeing any caption during the bootstrapping\nprocedure. In addition, CLIP-bootstrapped SparseFormers, which align the output\nspace with language without seeing a word, can serve as efficient vision\nencoders in multimodal large language models. Code will be publicly available\nat https://github.com/showlab/sparseformer",
            "author": [
                "Ziteng Gao",
                "Zhan Tong",
                "Kevin Qinghong Lin",
                "Joya Chen",
                "Mike Zheng Shou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01987v1",
                "http://arxiv.org/pdf/2312.01987v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01981v1",
            "title": "Unveiling Competition Dynamics in Mobile App Markets through User\n  Reviews",
            "updated": "2023-12-04T15:50:16Z",
            "published": "2023-12-04T15:50:16Z",
            "summary": "User reviews published in mobile app repositories are essential for\nunderstanding user satisfaction and engagement within a specific market\nsegment. Manual analysis of these reviews is impractical due to the large\nvolume of available data, while automatic analysis poses several challenges,\nincluding data synthesis and effective reporting. These challenges complicate\nthe task for app providers in identifying hidden patterns and significant\nevents related to app acceptance, especially in assessing the influence of\ncompetitor apps. Furthermore, review-based analysis is mostly limited to a\nsingle app or a single app provider, excluding potential market and competition\nanalysis. Following a case-study research method in the microblogging app\nmarket, we introduce an automatic, novel approach to support mobile app market\nanalysis processes through quantitative metrics and event detection techniques\nbased on newly published user reviews. Significant events are proactively\nidentified and summarized by comparing metric deviations with historical\nbaseline indicators within the lifecycle of a mobile app. Results from our case\nstudy show empirical evidence of the detection of relevant events within the\nselected market segment, including software- or release-based events,\ncontextual events and the emergence of new competitors.",
            "author": [
                "Quim Motger",
                "Xavier Franch",
                "Vincenzo Gervasi",
                "Jordi Marco"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01981v1",
                "http://arxiv.org/pdf/2312.01981v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01980v1",
            "title": "Cut-and-paste for impulsive gravitational waves with $\u039b$: The\n  mathematical analysis",
            "updated": "2023-12-04T15:49:12Z",
            "published": "2023-12-04T15:49:12Z",
            "summary": "Impulsive gravitational waves are theoretical models of short but violent\nbursts of gravitational radiation. They are commonly described by two distinct\nspacetime metrics, one of local Lipschitz regularity, the other one even\ndistributional. These two metrics are thought to be `physically equivalent'\nsince they can be formally related by a `discontinuous coordinate\ntransformation'. In this paper we provide a mathematical analysis of this issue\nfor the entire class of nonexpanding impulsive gravitational waves propagating\nin a background spacetime of constant curvature. We devise a natural geometric\nregularisation procedure to show that the notorious change of variables arises\nas the distributional limit of a family of smooth coordinate transformations.\nIn other words, we establish that both spacetimes arise as distributional\nlimits of a smooth sandwich wave taken in different coordinate systems which\nare diffeomorphically related.",
            "author": [
                "Clemens S\u00e4mann",
                "Benedict Schinnerl",
                "Roland Steinbauer",
                "Robert \u0160varc"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01980v1",
                "http://arxiv.org/pdf/2312.01980v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "math-ph",
                "math.MP",
                "83C15, 83C35, 46F30, 46F10, 83C10, 34A36"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01973v1",
            "title": "Computing Repairs Under Functional and Inclusion Dependencies via\n  Argumentation",
            "updated": "2023-12-04T15:41:41Z",
            "published": "2023-12-04T15:41:41Z",
            "summary": "We discover a connection between finding subset-maximal repairs for sets of\nfunctional and inclusion dependencies, and computing extensions within\nargumentation frameworks (AFs). We study the complexity of the existence of a\nrepair and deciding whether a given tuple belongs to some (or every) repair, by\nsimulating the instances of these problems via AFs. We prove that\nsubset-maximal repairs under functional dependencies correspond to the naive\nextensions, which also coincide with the preferred and stable extensions in the\nresulting AFs. For inclusion dependencies, one needs a pre-processing step on\nthe resulting AFs in order for the extensions to coincide. Allowing both types\nof dependencies breaks this relationship between extensions, and only preferred\nsemantics captures the repairs. Finally, we establish that the complexities of\nthe above decision problems are NP-complete and Pi_2^P-complete, when both\nfunctional and inclusion dependencies are allowed.",
            "author": [
                "Yasir Mahmood",
                "Jonni Virtema",
                "Timon Barlag",
                "Axel-Cyrille Ngonga Ngomo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01973v1",
                "http://arxiv.org/pdf/2312.01973v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01971v1",
            "title": "Directional spontaneous emission in photonic crystal slabs",
            "updated": "2023-12-04T15:35:41Z",
            "published": "2023-12-04T15:35:41Z",
            "summary": "Spontaneous emission is one of the most fundamental out-of-equilibrium\nprocesses in which an excited quantum emitter relaxes to the ground state due\nto quantum fluctuations. In this process, a photon is emitted that can interact\nwith other nearby emitters and establish quantum correlations between them,\ne.g., via super and subradiance effects. One way to modify these\nphoton-mediated interactions is to alter the dipole radiation patterns of the\nemitter, e.g., by placing photonic crystals near them. One recent example is\nthe generation of strong directional emission patterns-key to enhancing super\nand subradiance effects-in two dimensions by employing photonic crystals with\nband structures characterized by linear isofrequency contours and\nsaddle-points. However, these studies have predominantly used oversimplified\ntoy models, overlooking the electromagnetic field's intricacies in actual\nmaterials, including aspects like geometrical dependencies, emitter positions,\nand polarization. Our study delves into the interaction between these\ndirectional emission patterns and the aforementioned variables, revealing the\nuntapped potential to fine-tune collective quantum optical phenomena.",
            "author": [
                "Erik Petrovish Navarro-Bar\u00f3n",
                "Herbert Vinck-Posada",
                "Alejandro Gonz\u00e1lez-Tudela"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01971v1",
                "http://arxiv.org/pdf/2312.01971v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01969v1",
            "title": "FDR Control for Online Anomaly Detection",
            "updated": "2023-12-04T15:28:55Z",
            "published": "2023-12-04T15:28:55Z",
            "summary": "The goal of anomaly detection is to identify observations generated by a\nprocess that is different from a reference one. An accurate anomaly detector\nmust ensure low false positive and false negative rates. However in the online\ncontext such a constraint remains highly challenging due to the usual lack of\ncontrol of the False Discovery Rate (FDR). In particular the online framework\nmakes it impossible to use classical multiple testing approaches such as the\nBenjamini-Hochberg (BH) procedure. Our strategy overcomes this difficulty by\nexploiting a local control of the ``modified FDR'' (mFDR). An important\ningredient in this control is the cardinality of the calibration set used for\ncomputing empirical $p$-values, which turns out to be an influential parameter.\nIt results a new strategy for tuning this parameter, which yields the desired\nFDR control over the whole time series. The statistical performance of this\nstrategy is analyzed by theoretical guarantees and its practical behavior is\nassessed by simulation experiments which support our conclusions.",
            "author": [
                "Etienne Kr\u00f6nert",
                "Alain C\u00e9lisse",
                "Dalila Hattab"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01969v1",
                "http://arxiv.org/pdf/2312.01969v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "Anomaly detection, Time series"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01968v1",
            "title": "Augmenting Channel Charting with Classical Wireless Source Localization\n  Techniques",
            "updated": "2023-12-04T15:26:46Z",
            "published": "2023-12-04T15:26:46Z",
            "summary": "Channel Charting aims to construct a map of the radio environment by\nleveraging similarity relationships found in high-dimensional channel state\ninformation. Although resulting channel charts usually accurately represent\nlocal neighborhood relationships, even under conditions with strong multipath\npropagation, they often fall short in capturing global geometric features. On\nthe other hand, classical model-based localization methods, such as\ntriangulation and multilateration, can easily localize signal sources in the\nglobal coordinate frame. However, these methods rely heavily on the assumption\nof line-of-sight channels and distributed antenna deployments. Based on\nmeasured data, we compare classical source localization techniques to channel\ncharts with respect to localization performance. We suggest and evaluate\nmethods to enhance Channel Charting with model-based localization approaches:\nOne approach involves using information derived from classical localization\nmethods to map channel chart locations to physical positions after conventional\ntraining of the forward charting function. Foremost, though, we suggest to\nincorporate information from model-based approaches during the training of the\nforward charting function in what we call \"augmented Channel Charting\". We\ndemonstrate that Channel Charting can outperform classical localization methods\non the considered dataset.",
            "author": [
                "Florian Euchner",
                "Phillip Stephan",
                "Stephan ten Brink"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01968v1",
                "http://arxiv.org/pdf/2312.01968v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01964v1",
            "title": "Semantics-aware Motion Retargeting with Vision-Language Models",
            "updated": "2023-12-04T15:23:49Z",
            "published": "2023-12-04T15:23:49Z",
            "summary": "Capturing and preserving motion semantics is essential to motion retargeting\nbetween animation characters. However, most of the previous works neglect the\nsemantic information or rely on human-designed joint-level representations.\nHere, we present a novel Semantics-aware Motion reTargeting (SMT) method with\nthe advantage of vision-language models to extract and maintain meaningful\nmotion semantics. We utilize a differentiable module to render 3D motions. Then\nthe high-level motion semantics are incorporated into the motion retargeting\nprocess by feeding the vision-language model with the rendered images and\naligning the extracted semantic embeddings. To ensure the preservation of\nfine-grained motion details and high-level semantics, we adopt a two-stage\npipeline consisting of skeleton-aware pre-training and fine-tuning with\nsemantics and geometry constraints. Experimental results show the effectiveness\nof the proposed method in producing high-quality motion retargeting results\nwhile accurately preserving motion semantics. Project page can be found at\nhttps://sites.google.com/view/smtnet.",
            "author": [
                "Haodong Zhang",
                "ZhiKe Chen",
                "Haocheng Xu",
                "Lei Hao",
                "Xiaofei Wu",
                "Songcen Xu",
                "Zhensong Zhang",
                "Yue Wang",
                "Rong Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01964v1",
                "http://arxiv.org/pdf/2312.01964v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01963v1",
            "title": "Model Reduction on Manifolds: A differential geometric framework",
            "updated": "2023-12-04T15:23:42Z",
            "published": "2023-12-04T15:23:42Z",
            "summary": "Using nonlinear projections and preserving structure in model order reduction\n(MOR) are currently active research fields. In this paper, we provide a novel\ndifferential geometric framework for model reduction on smooth manifolds, which\nemphasizes the geometric nature of the objects involved. The crucial ingredient\nis the construction of an embedding for the low-dimensional submanifold and a\ncompatible reduction map, for which we discuss several options. Our general\nframework allows capturing and generalizing several existing MOR techniques,\nsuch as structure preservation for Lagrangian- or Hamiltonian dynamics, and\nusing nonlinear projections that are, for instance, relevant in\ntransport-dominated problems. The joint abstraction can be used to derive\nshared theoretical properties for different methods, such as an exact\nreproduction result. To connect our framework to existing work in the field, we\ndemonstrate that various techniques for data-driven construction of nonlinear\nprojections can be included in our framework.",
            "author": [
                "Patrick Buchfink",
                "Silke Glas",
                "Bernard Haasdonk",
                "Benjamin Unger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01963v1",
                "http://arxiv.org/pdf/2312.01963v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "34A26, 34C20, 37C05, 37N30, 65P10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01957v1",
            "title": "Distilled Self-Critique of LLMs with Synthetic Data: a Bayesian\n  Perspective",
            "updated": "2023-12-04T15:16:12Z",
            "published": "2023-12-04T15:16:12Z",
            "summary": "This paper proposes an interpretation of RLAIF as Bayesian inference by\nintroducing distilled Self-Critique (dSC), which refines the outputs of a LLM\nthrough a Gibbs sampler that is later distilled into a fine-tuned model. Only\nrequiring synthetic data, dSC is exercised in experiments regarding safety,\nsentiment, and privacy control, showing it can be a viable and cheap\nalternative to align LLMs. Code released at\n\\url{https://github.com/vicgalle/distilled-self-critique}.",
            "author": [
                "Victor Gallego"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01957v1",
                "http://arxiv.org/pdf/2312.01957v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01954v1",
            "title": "Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large\n  Language Models",
            "updated": "2023-12-04T15:12:04Z",
            "published": "2023-12-04T15:12:04Z",
            "summary": "In this work, we tested the Triplet Extraction (TE) capabilities of a variety\nof Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots\nsettings. In detail, we proposed a pipeline that dynamically gathers contextual\ninformation from a Knowledge Base (KB), both in the form of context triplets\nand of (sentence, triplets) pairs as examples, and provides it to the LLM\nthrough a prompt. The additional context allowed the LLMs to be competitive\nwith all the older fully trained baselines based on the Bidirectional Long\nShort-Term Memory (BiLSTM) Network architecture. We further conducted a\ndetailed analysis of the quality of the gathered KB context, finding it to be\nstrongly correlated with the final TE performance of the model. In contrast,\nthe size of the model appeared to only logarithmically improve the TE\ncapabilities of the LLMs.",
            "author": [
                "Andrea Papaluca",
                "Daniel Krefl",
                "Sergio Mendez Rodriguez",
                "Artem Lensky",
                "Hanna Suominen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01954v1",
                "http://arxiv.org/pdf/2312.01954v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01953v1",
            "title": "An extensive analysis of the sub-parsec region of 3C84",
            "updated": "2023-12-04T15:11:10Z",
            "published": "2023-12-04T15:11:10Z",
            "summary": "The study of jet launching in AGN is an important research method to better\nunderstand supermassive black holes (SMBHs) and their immediate surroundings.\nThe main theoretical jet launching scenarios invoke either magnetic field lines\nanchored to the black hole's (BH) accretion disc (Blandford & Payne 1982) or a\nmagnetic field, which is directly connected to its rotating ergosphere\n(Blandford & Znajek 1977). The nearby and bright radio galaxy 3C84 (NGC1275) is\na very suitable target for testing different jet launching mechanisms, as well\nas for the study of the innermost, sub-parsec scale AGN structure and the jet\norigin. Very long baseline interferometry (VLBI) - specifically at millimetre\nwavelengths - offers an unparalleled view into the physical processes in\naction, in the close vicinity of SMBHs. Utilising such mm-VLBI observations of\n3C84, we study the jet kinematics of the VLBI core region of 3C84 by employing\nall available, high sensitivity 3 mm-VLBI data sets of this source. As part of\nthis analysis we associate the component ejection events with the variability\nlight-curves at different radio frequencies and in the $\\gamma$-rays.\nFurthermore, by cross-correlating these light-curves, we determine their\ntime-lags and draw conclusions regarding the location of the high energy\nemission close to the jet base.",
            "author": [
                "G. F. Paraschos",
                "J. -Y. Kim",
                "T. P. Krichbaum",
                "J. Oh",
                "J. A. Hodgson",
                "M. A. Gurwell",
                "J. A. Zensus"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01953v1",
                "http://arxiv.org/pdf/2312.01953v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01952v1",
            "title": "Fragmentation processes and the convex hull of the Brownian motion in a\n  disk",
            "updated": "2023-12-04T15:11:03Z",
            "published": "2023-12-04T15:11:03Z",
            "summary": "Motivated by the study of the convex hull of the trajectory of a Brownian\nmotion in the unit disk reflected orthogonally at its boundary, we study\ninhomogeneous fragmentation processes in which particles of mass $m \\in (0,1)$\nsplit at a rate proportional to $|\\log m|^{-1}$. These processes do not belong\nto the well-studied family of self-similar fragmentation processes. Our main\nresults characterize the Laplace transform of the typical fragment of such a\nprocess, at any time, and its large time behavior.\n  We connect this asymptotic behavior to the prediction obtained by physicists\nin \\cite{DBBM22} for the growth of the perimeter of the convex hull of a\nBrownian motion in the disc reflected at its boundary. We also describe the\nlarge time asymptotic behavior of the whole fragmentation process. In order to\nimplement our results, we make a detailed study of a time-changed subordinator,\nwhich may be of independent interest.",
            "author": [
                "B\u00e9n\u00e9dicte Haas",
                "Bastien Mallein"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01952v1",
                "http://arxiv.org/pdf/2312.01952v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60J25, 60D05, 60G51, 60J80"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01951v1",
            "title": "DFTWS for blockchain: Deterministic, Fair and Transparent Winner\n  Selection",
            "updated": "2023-12-04T15:10:44Z",
            "published": "2023-12-04T15:10:44Z",
            "summary": "This publication describes the block winner selection process that will be\nused in a novel Proof-of-Useful-Work blockchain for High Energy Physics that\nthe authors are currently working on. Instead of spamming hashing operations to\nmine blocks, miners will be running Monte Carlo simulations to support a\nreal-world HEP experiment with useful data. The block problems will be defined\nby a Root Authority which is represented by a HEP experiment like CBM. The\nfocus in this publication is a mechanism that allows the Root Authority to\nselect a winner from a list of nodes that solved a block problem. The mechanism\nis designed so that winner selection is deterministic, fair and transparent.\nThis mechanism allows every node to verify the fairness of the winner selection\nprocess without giving the nodes a tool to be able to improve their own winning\nchances.",
            "author": [
                "Felix Hoffmann",
                "Udo Kebschull"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01951v1",
                "http://arxiv.org/pdf/2312.01951v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "94A60",
                "I.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01949v1",
            "title": "Integrality of mirror maps and arithmetic homological mirror symmetry\n  for Greene--Plesser mirrors",
            "updated": "2023-12-04T15:07:56Z",
            "published": "2023-12-04T15:07:56Z",
            "summary": "We prove the `integrality of Taylor coefficients of mirror maps' conjecture\nfor Greene--Plesser mirror pairs as a natural byproduct of an arithmetic\nrefinement of homological mirror symmetry. We also prove homological mirror\nsymmetry for Greene--Plesser mirror pairs in all characteristics such that the\nB-side family has good reduction, generalizing work of the fifth author and\nSmith over the complex numbers. A key technical ingredient is a new versality\nargument which allows us to work throughout over a Novikov-type ring with\ninteger coefficients.",
            "author": [
                "Sheel Ganatra",
                "Andrew Hanlon",
                "Jeff Hicks",
                "Daniel Pomerleano",
                "Nick Sheridan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01949v1",
                "http://arxiv.org/pdf/2312.01949v1"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "math.AG",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01943v1",
            "title": "Instance-guided Cartoon Editing with a Large-scale Dataset",
            "updated": "2023-12-04T15:00:15Z",
            "published": "2023-12-04T15:00:15Z",
            "summary": "Cartoon editing, appreciated by both professional illustrators and hobbyists,\nallows extensive creative freedom and the development of original narratives\nwithin the cartoon domain. However, the existing literature on cartoon editing\nis complex and leans heavily on manual operations, owing to the challenge of\nautomatic identification of individual character instances. Therefore, an\nautomated segmentation of these elements becomes imperative to facilitate a\nvariety of cartoon editing applications such as visual style editing, motion\ndecomposition and transfer, and the computation of stereoscopic depths for an\nenriched visual experience. Unfortunately, most current segmentation methods\nare designed for natural photographs, failing to recognize from the intricate\naesthetics of cartoon subjects, thus lowering segmentation quality. The major\nchallenge stems from two key shortcomings: the rarity of high-quality cartoon\ndedicated datasets and the absence of competent models for high-resolution\ninstance extraction on cartoons. To address this, we introduce a high-quality\ndataset of over 100k paired high-resolution cartoon images and their instance\nlabeling masks. We also present an instance-aware image segmentation model that\ncan generate accurate, high-resolution segmentation masks for characters in\ncartoon images. We present that the proposed approach enables a range of\nsegmentation-dependent cartoon editing applications like 3D Ken Burns parallax\neffects, text-guided cartoon style editing, and puppet animation from\nillustrations and manga.",
            "author": [
                "Jian Lin",
                "Chengze Li",
                "Xueting Liu",
                "Zhongping Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01943v1",
                "http://arxiv.org/pdf/2312.01943v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "I.4.6; I.3.3; I.3.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01942v1",
            "title": "Search for the decay of the Higgs boson to a $Z$ boson and a light\n  pseudoscalar particle decaying to two photons",
            "updated": "2023-12-04T14:58:35Z",
            "published": "2023-12-04T14:58:35Z",
            "summary": "A search for the decay of the Higgs boson to a $Z$ boson and a light,\npseudoscalar particle, $a$, decaying respectively to two leptons and to two\nphotons is reported. The search uses the full LHC Run 2 proton-proton collision\ndata at $\\sqrt{s}=13$ TeV, corresponding to 139 fb$^{-1}$ collected by the\nATLAS detector. This is one of the first searches for this specific decay mode\nof the Higgs boson, and it probes unexplored parameter space in models with\naxion-like particles (ALPs) and extended scalar sectors. The mass of the $a$\nparticle is assumed to be in the range 0.1-33 GeV. The data are analysed in two\ncategories: a merged category where the photons from the $a$ decay are\nreconstructed in the ATLAS calorimeter as a single cluster, and a resolved\ncategory in which two separate photons are detected. The main background\nprocesses are from Standard Model $Z$ boson production in association with\nphotons or jets. The data are in agreement with the background predictions, and\nupper limits on the branching ratio of the Higgs boson decay to $Za$ times the\nbranching ratio $a\\to\\gamma\\gamma$ are derived at the 95% confidence level and\nthey range from 0.08% to 2% depending on the mass of the $a$ particle. The\nresults are also interpreted in the context of ALP models.",
            "author": [
                "ATLAS Collaboration"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01942v1",
                "http://arxiv.org/pdf/2312.01942v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01941v1",
            "title": "Intrusion Detection System with Machine Learning and Multiple Datasets",
            "updated": "2023-12-04T14:58:19Z",
            "published": "2023-12-04T14:58:19Z",
            "summary": "As Artificial Intelligence (AI) technologies continue to gain traction in the\nmodern-day world, they ultimately pose an immediate threat to current\ncybersecurity systems via exploitative methods. Prompt engineering is a\nrelatively new field that explores various prompt designs that can hijack large\nlanguage models (LLMs). If used by an unethical attacker, it can enable an AI\nsystem to offer malicious insights and code to them. In this paper, an enhanced\nintrusion detection system (IDS) that utilizes machine learning (ML) and\nhyperparameter tuning is explored, which can improve a model's performance in\nterms of accuracy and efficacy. Ultimately, this improved system can be used to\ncombat the attacks made by unethical hackers. A standard IDS is solely\nconfigured with pre-configured rules and patterns; however, with the\nutilization of machine learning, implicit and different patterns can be\ngenerated through the models' hyperparameter settings and parameters. In\naddition, the IDS will be equipped with multiple datasets so that the accuracy\nof the models improves. We evaluate the performance of multiple ML models and\ntheir respective hyperparameter settings through various metrics to compare\ntheir results to other models and past research work. The results of the\nproposed multi-dataset integration method yielded an accuracy score of 99.9%\nwhen equipped with the XGBoost and random forest classifiers and\nRandomizedSearchCV hyperparameter technique.",
            "author": [
                "Haiyan Xuan",
                "Mohith Manohar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01941v1",
                "http://arxiv.org/pdf/2312.01941v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01940v1",
            "title": "Intelligent Reflecting Surface-Aided Electromagnetic Stealth Against\n  Radar Detection",
            "updated": "2023-12-04T14:58:05Z",
            "published": "2023-12-04T14:58:05Z",
            "summary": "While traditional electromagnetic stealth materials/metasurfaces can render a\ntarget virtually invisible to some extent, they lack flexibility and\nadaptability, and can only operate within a limited frequency and\nangle/direction range, making it challenging to ensure the expected stealth\nperformance. In view of this, we propose in this paper a new intelligent\nreflecting surface (IRS)-aided electromagnetic stealth system mounted on\ntargets to evade radar detection, by utilizing the tunable passive reflecting\nelements of IRS to achieve flexible and adaptive electromagnetic stealth in a\ncost-effective manner. Specifically, we optimize the IRS's reflection at the\ntarget to minimize the sum received signal power of all adversary radars. We\nfirst address the IRS's reflection optimization problem using the Lagrange\nmultiplier method and derive a semi-closed-form optimal solution for the\nsingle-radar setup, which is then generalized to the multi-radar case. To meet\nreal-time processing requirements, we further propose low-complexity\nclosed-form solutions based on the reverse alignment/cancellation and minimum\nmean-square error (MMSE) criteria for the single-radar and multi-radar cases,\nrespectively. Additionally, we propose practical low-complexity estimation\nschemes at the target to acquire angle-of-arrival (AoA) and/or path gain\ninformation via a small number of receive sensing devices. Simulation results\nvalidate the performance advantages of our proposed IRS-aided electromagnetic\nstealth system with the proposed IRS reflection designs.",
            "author": [
                "Beixiong Zheng",
                "Xue Xiong",
                "Jie Tang",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01940v1",
                "http://arxiv.org/pdf/2312.01940v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01937v1",
            "title": "Switchable band topology and geometric current in sliding bilayer\n  elemental ferroelectric",
            "updated": "2023-12-04T14:51:13Z",
            "published": "2023-12-04T14:51:13Z",
            "summary": "We demonstrate that sliding motion between two layers of the newly discovered\nferroelectric and topologically trivial bismuth (Bi) monolayer [Nature 617, 67\n(2023)] can induce a sequence of topological phase transitions, alternating\nbetween trivial and nontrivial states. Interestingly, a lateral shift, even\nwhen preserving spatial symmetry, can still switch the quantum spin Hall state\non and off. The substantial band-gap modulation and band inversion due to\ninterlayer sliding arise primarily from the intralayer in-plane charge transfer\nprocesses involving Bi atoms at the outermost atomic layers, rather than the\ninterlayer charge redistribution. We map out the topological phase diagram and\nthe geometric Berry curvature-dipole induced nonlinear anomalous Hall response\nresulting from sliding, highlighting the potential for robust mechanical\ncontrol over the edge current and the Hall current. Bilayer configurations that\nare $\\mathbb{Z}_2$ nontrivial can produce drastically different transverse\ncurrents orthogonal to the external electric field. This occurs because both\nthe direction and magnitude of the Berry curvature dipole at the Fermi level\ndepend sensitively on the sliding displacement. Our results suggest that\nbilayer bismuth could serve as a platform to realize power-efficient ``Berry\nslidetronics\" for topology memory applications.",
            "author": [
                "Zhuang Qian",
                "Zhihao Gong",
                "Jian Li",
                "Hua Wang",
                "Shi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01937v1",
                "http://arxiv.org/pdf/2312.01937v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02246v1",
            "title": "Conditional Variational Diffusion Models",
            "updated": "2023-12-04T14:45:56Z",
            "published": "2023-12-04T14:45:56Z",
            "summary": "Inverse problems aim to determine parameters from observations, a crucial\ntask in engineering and science. Lately, generative models, especially\ndiffusion models, have gained popularity in this area for their ability to\nproduce realistic solutions and their good mathematical properties. Despite\ntheir success, an important drawback of diffusion models is their sensitivity\nto the choice of variance schedule, which controls the dynamics of the\ndiffusion process. Fine-tuning this schedule for specific applications is\ncrucial but time-costly and does not guarantee an optimal result. We propose a\nnovel approach for learning the schedule as part of the training process. Our\nmethod supports probabilistic conditioning on data, provides high-quality\nsolutions, and is flexible, proving able to adapt to different applications\nwith minimum overhead. This approach is tested in two unrelated inverse\nproblems: super-resolution microscopy and quantitative phase imaging, yielding\ncomparable or superior results to previous methods and fine-tuned diffusion\nmodels. We conclude that fine-tuning the schedule by experimentation should be\navoided because it can be learned during training in a stable way that yields\nbetter results.",
            "author": [
                "Gabriel della Maggiora",
                "Luis Alberto Croquevielle",
                "Nikita Desphande",
                "Harry Horsley",
                "Thomas Heinis",
                "Artur Yakimovich"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02246v1",
                "http://arxiv.org/pdf/2312.02246v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "stat.ML",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01930v1",
            "title": "Solving the left-hand cut problem in lattice QCD: $T_{cc}(3875)^+$ from\n  finite volume energy levels",
            "updated": "2023-12-04T14:38:46Z",
            "published": "2023-12-04T14:38:46Z",
            "summary": "A novel effective-field-theory-based approach is implemented for extracting\ntwo-body scattering information from finite volume energies, serving as an\nalternative to L\\\"uscher's method. By explicitly incorporating one-pion\nexchange, the approach quantitatively accounts for effects related to left-hand\ncuts and range corrections from the longest-range interactions. The method\nutilizes the plane wave basis instead of the conventional partial wave\nexpansion, thereby also naturally including partial wave mixing effects\nresulting from rotational symmetry breaking in a cubic box. Applied to the\nlattice data for $DD^*$ scattering at a pion mass of 280 MeV, it reveals the\nsignificant impact of the one-pion exchange on P-wave and S-wave phase shifts.\nThe pole position of the $T_{cc}(3875)^+$ state, extracted from the\nfinite-volume energy levels while taking into account left-hand cut effects,\nrange corrections, and partial-wave mixing, appears to be consistent with a\nnear-threshold resonance.",
            "author": [
                "Lu Meng",
                "Vadim Baru",
                "Evgeny Epelbaum",
                "Arseniy A. Filin",
                "Ashot M. Gasparyan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01930v1",
                "http://arxiv.org/pdf/2312.01930v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01928v1",
            "title": "Consensus-Based Distributed Nonlinear Filtering with Kernel Mean\n  Embedding",
            "updated": "2023-12-04T14:37:40Z",
            "published": "2023-12-04T14:37:40Z",
            "summary": "This paper proposes a consensus-based distributed nonlinear filter with\nkernel mean embedding (KME). This fills with gap of posterior density\napproximation with KME for distributed nonlinear dynamic systems. To\napproximate the posterior density, the system state is embedded into a\nhigher-dimensional reproducing kernel Hilbert space (RKHS), and then the\nnonlinear measurement function is linearly converted. As a result, an update\nrule of KME of posterior distribution is established in the RKHS. To show the\nproposed distributed filter being capable of achieving the centralized\nestimation accuracy, a centralized filter, serving as an extension of the\nstandard Kalman filter in the state space to the RKHS, is developed first.\nBenefited from the KME, the proposed distributed filter converges to the\ncentralized one while maintaining the distributed pattern. Two examples are\nintroduced to demonstrate the effectiveness of the developed filters in target\ntracking scenarios including nearly constantly moving target and turning\ntarget, respectively, with bearing-only, range and bearing measurements.",
            "author": [
                "Liping Guo",
                "Jimin Wang",
                "Yanlong Zhao",
                "Ji-Feng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01928v1",
                "http://arxiv.org/pdf/2312.01928v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01923v1",
            "title": "Clonal dynamics of surface-driven growing tissues",
            "updated": "2023-12-04T14:30:44Z",
            "published": "2023-12-04T14:30:44Z",
            "summary": "The self-organization of cells into complex tissues relies on a tight\ncoordination of cell behavior. Identifying the cellular processes driving\ntissue growth is key for understanding the emergence of tissue forms and for\ndevising targeted therapies for aberrant growth, such as in cancer. Inferring\nthe mode of tissue growth, whether it is driven by cells on the surface or\ncells in the bulk, is possible in cell culture experiments, but difficult in\nmost tissues in living organisms (in vivo). Genetic tracing experiments, where\na subset of cells is labelled with inheritable markers have become important\nexperimental tools to study cell fate in vivo. Here, we show that the mode of\ntissue growth is reflected in the size distribution of the progeny of marked\ncells. To this end, we derive the clone-size distributions using analytical\ncalculations and an agent-based stochastic sampling technique in the limit of\nnegligible cell migration and cell death. We show that for surface-driven\ngrowth the clone-size distribution takes a characteristic power-law form with\nan exponent determined by fluctuations of the tissue surface. Our results allow\nfor the inference of the mode of tissue growth from genetic tracing\nexperiments.",
            "author": [
                "Ruslan Mukhamadiarov",
                "Matteo Ciarchi",
                "Fabrizio Olmeda",
                "Steffen Rulands"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01923v1",
                "http://arxiv.org/pdf/2312.01923v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "physics.bio-ph",
                "q-bio.CB",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01921v1",
            "title": "A Machine Learning Approach Towards SKILL Code Autocompletion",
            "updated": "2023-12-04T14:29:28Z",
            "published": "2023-12-04T14:29:28Z",
            "summary": "As Moore's Law continues to increase the complexity of electronic systems,\nElectronic Design Automation (EDA) must advance to meet global demand. An\nimportant example of an EDA technology is SKILL, a scripting language used to\ncustomize and extend EDA software. Recently, code generation models using the\ntransformer architecture have achieved impressive results in academic settings\nand have even been used in commercial developer tools to improve developer\nproductivity. To the best of our knowledge, this study is the first to apply\ntransformers to SKILL code autocompletion towards improving the productivity of\nhardware design engineers. In this study, a novel, data-efficient methodology\nfor generating SKILL code is proposed and experimentally validated. More\nspecifically, we propose a novel methodology for (i) creating a high-quality\nSKILL dataset with both unlabeled and labeled data, (ii) a training strategy\nwhere T5 models pre-trained on general programming language code are fine-tuned\non our custom SKILL dataset using unsupervised and supervised learning, and\n(iii) evaluating synthesized SKILL code. We show that models trained using the\nproposed methodology outperform baselines in terms of human-judgment score and\nBLEU score. A major challenge faced was the extremely small amount of available\nSKILL code data that can be used to train a transformer model to generate SKILL\ncode. Despite our validated improvements, the extremely small dataset available\nto us was still not enough to train a model that can reliably autocomplete\nSKILL code. We discuss this and other limitations as well as future work that\ncould address these limitations.",
            "author": [
                "Enrique Dehaerne",
                "Bappaditya Dey",
                "Wannes Meert"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01921v1",
                "http://arxiv.org/pdf/2312.01921v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL",
                "cs.PL",
                "I.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01915v1",
            "title": "A Reliable Representation with Bidirectional Transition Model for Visual\n  Reinforcement Learning Generalization",
            "updated": "2023-12-04T14:19:36Z",
            "published": "2023-12-04T14:19:36Z",
            "summary": "Visual reinforcement learning has proven effective in solving control tasks\nwith high-dimensional observations. However, extracting reliable and\ngeneralizable representations from vision-based observations remains a central\nchallenge. Inspired by the human thought process, when the representation\nextracted from the observation can predict the future and trace history, the\nrepresentation is reliable and accurate in comprehending the environment. Based\non this concept, we introduce a Bidirectional Transition (BiT) model, which\nleverages the ability to bidirectionally predict environmental transitions both\nforward and backward to extract reliable representations. Our model\ndemonstrates competitive generalization performance and sample efficiency on\ntwo settings of the DeepMind Control suite. Additionally, we utilize robotic\nmanipulation and CARLA simulators to demonstrate the wide applicability of our\nmethod.",
            "author": [
                "Xiaobo Hu",
                "Youfang Lin",
                "Yue Liu",
                "Jinwen Wang",
                "Shuo Wang",
                "Hehe Fan",
                "Kai Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01915v1",
                "http://arxiv.org/pdf/2312.01915v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01912v2",
            "title": "Resource Leak Checker (RLC#) for C# Code using CodeQL",
            "updated": "2023-12-05T07:19:53Z",
            "published": "2023-12-04T14:17:40Z",
            "summary": "Resource leaks occur when a program fails to release a finite resource after\nit is no longer needed. These leaks are a significant cause of real-world\ncrashes and performance issues. Given their critical impact on software\nperformance and security, detecting and preventing resource leaks is a crucial\nproblem.\n  Recent research has proposed a specify-and-check approach to prevent resource\nleaks. In this approach, programmers write resource management specifications\nthat guide how resources are stored, passed around, and released within an\napplication. We have developed a tool called RLC#, for detecting resource leaks\nin C# code. Inspired by the Resource Leak Checker (RLC) from the Checker\nFramework, RLC# employs CodeQL for intraprocedural data flow analysis. The tool\noperates in a modular fashion and relies on resource management specifications\nintegrated at method boundaries for interprocedural analysis.\n  In practice, RLC# has successfully identified 24 resource leaks in\nopen-source projects and internal proprietary Azure microservices. Its\nimplementation is declarative, and it scales well. While it incurs a reasonable\nfalse positive rate, the burden on developers is minimal, involving the\naddition of specifications to the source code.",
            "author": [
                "Pritam Gharat",
                "Narges Shadab",
                "Shrey Tiwari",
                "Shuvendu Lahiri",
                "Akash Lal"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01912v2",
                "http://arxiv.org/pdf/2312.01912v2"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01907v1",
            "title": "Model Predictive Control Approach to Autonomous Formation Flight",
            "updated": "2023-12-04T14:10:17Z",
            "published": "2023-12-04T14:10:17Z",
            "summary": "Formation flight is when multiple objects fly together in a coordination.\nVarious automatic control methods have been used for the autonomous execution\nof formation flight of aerial vehicles. In this paper, the capacity of the\nmodel predictive control (MPC) approach in the autonomous execution of\nformation flight is examined. The MPC is a controller that capable of\nperforming formation flight, maintaining tracking desired trajectory while\navoiding collisions between aerial vehicles, and obstacles faced. Through this\napproach, aerial vehicle models with six degrees of freedom in a\nthree-dimensional environment are performed formation flight autonomously,\nmostly in a triangle order. Not only the trajectory for the formation flight\ncan be tracked through the MPC architecture, also the collision avoidance\nstrategies of the aerial vehicles can be performed by this architecture.\nSimulation studies show that MPC has sufficient capability in both cases.\nTherefore, it is concluded that this method can deal with constraints, avoid\nobstacles as well as collisions between aerial vehicles. However,\nimplementation of MPC to aerial vehicles in real time holds challenges.",
            "author": [
                "Harun Celik",
                "Dilara Kilinc"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01907v1",
                "http://arxiv.org/pdf/2312.01907v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01904v1",
            "title": "Unsupervised Anomaly Detection using Aggregated Normative Diffusion",
            "updated": "2023-12-04T14:02:56Z",
            "published": "2023-12-04T14:02:56Z",
            "summary": "Early detection of anomalies in medical images such as brain MRI is highly\nrelevant for diagnosis and treatment of many conditions. Supervised machine\nlearning methods are limited to a small number of pathologies where there is\ngood availability of labeled data. In contrast, unsupervised anomaly detection\n(UAD) has the potential to identify a broader spectrum of anomalies by spotting\ndeviations from normal patterns. Our research demonstrates that existing\nstate-of-the-art UAD approaches do not generalise well to diverse types of\nanomalies in realistic multi-modal MR data. To overcome this, we introduce a\nnew UAD method named Aggregated Normative Diffusion (ANDi). ANDi operates by\naggregating differences between predicted denoising steps and ground truth\nbackwards transitions in Denoising Diffusion Probabilistic Models (DDPMs) that\nhave been trained on pyramidal Gaussian noise. We validate ANDi against three\nrecent UAD baselines, and across three diverse brain MRI datasets. We show that\nANDi, in some cases, substantially surpasses these baselines and shows\nincreased robustness to varying types of anomalies. Particularly in detecting\nmultiple sclerosis (MS) lesions, ANDi achieves improvements of up to 178% in\nterms of AUPRC.",
            "author": [
                "Alexander Frotscher",
                "Jaivardhan Kapoor",
                "Thomas Wolfers",
                "Christian F. Baumgartner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01904v1",
                "http://arxiv.org/pdf/2312.01904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01902v1",
            "title": "Trisections of PL 4-manifolds associated to colored triangulations",
            "updated": "2023-12-04T14:00:02Z",
            "published": "2023-12-04T14:00:02Z",
            "summary": "The purpose of the present paper is twofold: firstly to extend to\nnon-orientable compact 4-manifolds, both in the closed and the boundary case,\nthe notion of {\\it gem-induced trisection}, which arises from colored\ntriangulations; secondly to prove that, if the boundary is homeomorphic to a\nconnected sum of sphere bundles over $\\mathbb S^1$, gem-induced trisections\nnaturally give rise to trisections of the corresponding closed 4-manifold. As a\nconsequence, an estimation of the trisection genus of any closed orientable\n4-manifold in terms of surgery description is obtained via trisections\nassociated to colored triangulations. Moreover, trisections arising from gems\nturn out to realize the trisection genus for a wide class of (orientable and\nnon-orientable) 4-manifolds.",
            "author": [
                "Maria Rita Casali",
                "Paola Cristofori"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01902v1",
                "http://arxiv.org/pdf/2312.01902v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "57Q15 - 57K40 - 57M15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01898v1",
            "title": "Unlocking optimal batch size schedules using continuous-time control and\n  perturbation theory",
            "updated": "2023-12-04T13:54:05Z",
            "published": "2023-12-04T13:54:05Z",
            "summary": "Stochastic Gradient Descent (SGD) and its variants are almost universally\nused to train neural networks and to fit a variety of other parametric models.\nAn important hyperparameter in this context is the batch size, which determines\nhow many samples are processed before an update of the parameters occurs.\nPrevious studies have demonstrated the benefits of using variable batch sizes.\nIn this work, we will theoretically derive optimal batch size schedules for SGD\nand similar algorithms, up to an error that is quadratic in the learning rate.\nTo achieve this, we approximate the discrete process of parameter updates using\na family of stochastic differential equations indexed by the learning rate. To\nbetter handle the state-dependent diffusion coefficient, we further expand the\nsolution of this family into a series with respect to the learning rate. Using\nthis setup, we derive a continuous-time optimal batch size schedule for a large\nfamily of diffusion coefficients and then apply the results in the setting of\nlinear regression.",
            "author": [
                "Stefan Perko"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01898v1",
                "http://arxiv.org/pdf/2312.01898v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01896v1",
            "title": "A Linear-time Simulation of Deterministic $d$-Limited Automata",
            "updated": "2023-12-04T13:49:47Z",
            "published": "2023-12-04T13:49:47Z",
            "summary": "A $d$-limited automaton is a Turing machine that uses only the cells with the\ninput word (and end-markers) and rewrites symbols only in the first $d$ visits.\nThis model was introduced by T. Hibbard in 1967 and he showed that $d$-limited\nautomata recognize context-free languages for each $d \\geq 2$. He also proved\nthat languages recognizable by deterministic $d$-limited automata form a\nhierarchy and it was shown later by Pighizzini and Pisoni that it begins with\ndeterministic context-free languages (DCFLs) (for $d=2$).\n  As well-known, DCFLs are widely used in practice, especially in compilers\nsince they are linear-time recognizable and have the corresponding CF-grammars\nsubclass (LR$(1)$-grammars). In this paper we present a linear time recognition\nalgorithm for deterministic $d$-limited automata (in the RAM model) which opens\nan opportunity for their possible practical applications. We also generalize\nthis algorithm to deterministic $d(n)$-limited automata: the extension of\ndeterministic $d$-limited automata, where $d$ is not a constant, but a function\ndepending on the input length $n$.",
            "author": [
                "Alexander Rubtsov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01896v1",
                "http://arxiv.org/pdf/2312.01896v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01888v1",
            "title": "Highly Accelerated Weighted MMSE Algorithms for Designing Precoders in\n  FDD Systems with Incomplete CSI",
            "updated": "2023-12-04T13:42:10Z",
            "published": "2023-12-04T13:42:10Z",
            "summary": "In this work, we derive a lower bound on the training-based achievable\ndownlink (DL) sum rate (SR) of a multi-user multiple-input-single-output (MISO)\nsystem operating in frequency-division-duplex (FDD) mode. Assuming linear\nminimum mean square error (LMMSE) channel estimation is used, we establish a\nconnection of the derived lower bound on the signal-to-interference-noise-ratio\n(SINR) to an average MSE that allows to reformulate the SR maximization problem\nas the minimization of the augmented weighted average MSE (AWAMSE). We propose\nan iterative precoder design with three alternating steps, all given in closed\nform, drastically reducing the computation time. We show numerically the\neffectiveness of the proposed approach in challenging scenarios with limited\nchannel knowledge, i.e., we consider scenarios with a very limited number of\npilots. We additionally propose a more efficient version of the well-known\nstochastic iterative WMMSE (SIWMMSE) approach, where the precoder update is\ngiven in closed form.",
            "author": [
                "Donia Ben Amor",
                "Michael Joham",
                "Wolfgang Utschick"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01888v1",
                "http://arxiv.org/pdf/2312.01888v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01887v1",
            "title": "Non-Intrusive Load Monitoring for Feeder-Level EV Charging Detection:\n  Sliding Window-based Approaches to Offline and Online Detection",
            "updated": "2023-12-04T13:40:22Z",
            "published": "2023-12-04T13:40:22Z",
            "summary": "Understanding electric vehicle (EV) charging on the distribution network is\nkey to effective EV charging management and aiding decarbonization across the\nenergy and transport sectors. Advanced metering infrastructure has allowed\ndistribution system operators and utility companies to collect high-resolution\nload data from their networks. These advancements enable the non-intrusive load\nmonitoring (NILM) technique to detect EV charging using load measurement data.\nWhile existing studies primarily focused on NILM for EV charging detection in\nindividual households, there is a research gap on EV charging detection at the\nfeeder level, presenting unique challenges due to the combined load measurement\nfrom multiple households. In this paper, we develop a novel and effective\napproach for EV detection at the feeder level, involving sliding-window feature\nextraction and classical machine learning techniques, specifically models like\nXGBoost and Random Forest. Our developed method offers a lightweight and\nefficient solution, capable of quick training. Moreover, our developed method\nis versatile, supporting both offline and online EV charging detection. Our\nexperimental results demonstrate high-accuracy EV charging detection at the\nfeeder level, achieving an F-Score of 98.88% in offline detection and 93.01% in\nonline detection.",
            "author": [
                "Cameron Martin",
                "Fucai Ke",
                "Hao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01887v1",
                "http://arxiv.org/pdf/2312.01887v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01886v1",
            "title": "InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language\n  Models",
            "updated": "2023-12-04T13:40:05Z",
            "published": "2023-12-04T13:40:05Z",
            "summary": "Large vision-language models (LVLMs) have demonstrated their incredible\ncapability in image understanding and response generation. However, this rich\nvisual interaction also makes LVLMs vulnerable to adversarial examples. In this\npaper, we formulate a novel and practical gray-box attack scenario that the\nadversary can only access the visual encoder of the victim LVLM, without the\nknowledge of its prompts (which are often proprietary for service providers and\nnot publicly available) and its underlying large language model (LLM). This\npractical setting poses challenges to the cross-prompt and cross-model\ntransferability of targeted adversarial attack, which aims to confuse the LVLM\nto output a response that is semantically similar to the attacker's chosen\ntarget text. To this end, we propose an instruction-tuned targeted attack\n(dubbed InstructTA) to deliver the targeted adversarial attack on LVLMs with\nhigh transferability. Initially, we utilize a public text-to-image generative\nmodel to \"reverse\" the target response into a target image, and employ GPT-4 to\ninfer a reasonable instruction $\\boldsymbol{p}^\\prime$ from the target\nresponse. We then form a local surrogate model (sharing the same visual encoder\nwith the victim LVLM) to extract instruction-aware features of an adversarial\nimage example and the target image, and minimize the distance between these two\nfeatures to optimize the adversarial example. To further improve the\ntransferability, we augment the instruction $\\boldsymbol{p}^\\prime$ with\ninstructions paraphrased from an LLM. Extensive experiments demonstrate the\nsuperiority of our proposed method in targeted attack performance and\ntransferability.",
            "author": [
                "Xunguang Wang",
                "Zhenlan Ji",
                "Pingchuan Ma",
                "Zongjie Li",
                "Shuai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01886v1",
                "http://arxiv.org/pdf/2312.01886v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01884v1",
            "title": "Correlation and Unintended Biases on Univariate and Multivariate\n  Decision Trees",
            "updated": "2023-12-04T13:33:51Z",
            "published": "2023-12-04T13:33:51Z",
            "summary": "Decision Trees are accessible, interpretable, and well-performing\nclassification models. A plethora of variants with increasing expressiveness\nhas been proposed in the last forty years. We contrast the two families of\nunivariate DTs, whose split functions partition data through axis-parallel\nhyperplanes, and multivariate DTs, whose splits instead partition data through\noblique hyperplanes. The latter include the former, hence multivariate DTs are\nin principle more powerful. Surprisingly enough, however, univariate DTs\nconsistently show comparable performances in the literature. We analyze the\nreasons behind this, both with synthetic and real-world benchmark datasets. Our\nresearch questions test whether the pre-processing phase of removing\ncorrelation among features in datasets has an impact on the relative\nperformances of univariate vs multivariate DTs. We find that existing benchmark\ndatasets are likely biased towards favoring univariate DTs.",
            "author": [
                "Mattia Setzu",
                "Salvatore Ruggieri"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01884v1",
                "http://arxiv.org/pdf/2312.01884v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01882v1",
            "title": "Unleashing the Potential of Large Language Model: Zero-shot VQA for\n  Flood Disaster Scenario",
            "updated": "2023-12-04T13:25:16Z",
            "published": "2023-12-04T13:25:16Z",
            "summary": "Visual question answering (VQA) is a fundamental and essential AI task, and\nVQA-based disaster scenario understanding is a hot research topic. For\ninstance, we can ask questions about a disaster image by the VQA model and the\nanswer can help identify whether anyone or anything is affected by the\ndisaster. However, previous VQA models for disaster damage assessment have some\nshortcomings, such as limited candidate answer space, monotonous question\ntypes, and limited answering capability of existing models. In this paper, we\npropose a zero-shot VQA model named Zero-shot VQA for Flood Disaster Damage\nAssessment (ZFDDA). It is a VQA model for damage assessment without\npre-training. Also, with flood disaster as the main research object, we build a\nFreestyle Flood Disaster Image Question Answering dataset (FFD-IQA) to evaluate\nour VQA model. This new dataset expands the question types to include\nfree-form, multiple-choice, and yes-no questions. At the same time, we expand\nthe size of the previous dataset to contain a total of 2,058 images and 22,422\nquestion-meta ground truth pairs. Most importantly, our model uses\nwell-designed chain of thought (CoT) demonstrations to unlock the potential of\nthe large language model, allowing zero-shot VQA to show better performance in\ndisaster scenarios. The experimental results show that the accuracy in\nanswering complex questions is greatly improved with CoT prompts. Our study\nprovides a research basis for subsequent research of VQA for other disaster\nscenarios.",
            "author": [
                "Yimin Sun",
                "Chao Wang",
                "Yan Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01882v1",
                "http://arxiv.org/pdf/2312.01882v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01872v1",
            "title": "The CURE To Vulnerabilities in RPKI Validation",
            "updated": "2023-12-04T13:09:37Z",
            "published": "2023-12-04T13:09:37Z",
            "summary": "Over recent years, the Resource Public Key Infrastructure (RPKI) has seen\nincreasing adoption, with now 37.8% of the major networks filtering bogus BGP\nroutes. Systems interact with the RPKI over Relying Party (RP) implementations\nthat fetch RPKI objects and feed BGP routers with the validated\nprefix-ownership data. Consequently, any vulnerabilities or flaws within the RP\nsoftware can substantially threaten the stability and security of Internet\nrouting. We uncover severe flaws in all popular RP implementations, making them\nsusceptible to path traversal attacks, remotely triggered crashes, and inherent\ninconsistencies, violating RPKI standards. We report a total of 18\nvulnerabilities that canbe exploited to downgrade RPKI validation in border\nrouters or, worse, enable poisoning of the validation process, resulting in\nmalicious prefixes being wrongfully validated and legitimate RPKI-covered\nprefixes failing validation. Furthermore, our research discloses\ninconsistencies in the validation process, with two popular implementations\nleaving 8149 prefixes unprotected from hijacks, 6405 of which belong to Amazon.\nWhile these findings are significant in their own right, our principal\ncontribution lies in developing CURE, the first-of-its-kind system to\nsystematically detect bugs, vulnerabilities, and RFC compliance issues in RP\nimplementations via automated test generation. CURE is a powerful RPKI\npublication point emulator that enables easy and efficient fuzzing of complex\nRP validation pipelines. It is designed with a set of novel techniques,\nutilizing differential and stateful fuzzing. We generated over 600 million test\ncases and tested all popular RPs on them. Following our disclosure, the vendors\nalready assigned CVEs to the vulnerabilities we found.",
            "author": [
                "Donika Mirdita",
                "Haya Schulmann",
                "Niklas Vogel",
                "Michael Waidner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01872v1",
                "http://arxiv.org/pdf/2312.01872v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01871v1",
            "title": "FeaInfNet: Diagnosis in Medical Image with Feature-Driven Inference and\n  Visual Explanations",
            "updated": "2023-12-04T13:09:00Z",
            "published": "2023-12-04T13:09:00Z",
            "summary": "Interpretable deep learning models have received widespread attention in the\nfield of image recognition. Due to the unique multi-instance learning of\nmedical images and the difficulty in identifying decision-making regions, many\ninterpretability models that have been proposed still have problems of\ninsufficient accuracy and interpretability in medical image disease diagnosis.\nTo solve these problems, we propose feature-driven inference network\n(FeaInfNet). Our first key innovation involves proposing a feature-based\nnetwork reasoning structure, which is applied to FeaInfNet. The network of this\nstructure compares the similarity of each sub-region image patch with the\ndisease templates and normal templates that may appear in the region, and\nfinally combines the comparison of each sub-region to make the final diagnosis.\nIt simulates the diagnosis process of doctors to make the model interpretable\nin the reasoning process, while avoiding the misleading caused by the\nparticipation of normal areas in reasoning. Secondly, we propose local feature\nmasks (LFM) to extract feature vectors in order to provide global information\nfor these vectors, thus enhancing the expressive ability of the FeaInfNet.\nFinally, we propose adaptive dynamic masks (Adaptive-DM) to interpret feature\nvectors and prototypes into human-understandable image patches to provide\naccurate visual interpretation. We conducted qualitative and quantitative\nexperiments on multiple publicly available medical datasets, including RSNA,\niChallenge-PM, Covid-19, ChinaCXRSet, and MontgomerySet. The results of our\nexperiments validate that our method achieves state-of-the-art performance in\nterms of classification accuracy and interpretability compared to baseline\nmethods in medical image diagnosis. Additional ablation studies verify the\neffectiveness of each of our proposed components.",
            "author": [
                "Yitao Peng",
                "Lianghua He",
                "Die Hu",
                "Yihang Liu",
                "Longzhen Yang",
                "Shaohua Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01871v1",
                "http://arxiv.org/pdf/2312.01871v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01870v1",
            "title": "Extreme-value modelling of migratory bird arrival dates: Insights from\n  citizen science data",
            "updated": "2023-12-04T13:06:24Z",
            "published": "2023-12-04T13:06:24Z",
            "summary": "Citizen science mobilises many observers and gathers huge datasets but often\nwithout strict sampling protocols, which results in observation biases due to\nheterogeneity in sampling effort that can lead to biased statistical\ninferences. We develop a spatiotemporal Bayesian hierarchical model for\nbias-corrected estimation of arrival dates of the first migratory bird\nindividuals at a breeding site. Higher sampling effort could be correlated with\nearlier observed dates. We implement data fusion of two citizen-science\ndatasets with sensibly different protocols (BBS, eBird) and map posterior\ndistributions of the latent process, which contains four spatial components\nwith Gaussian process priors: species niche; sampling effort; position and\nscale parameters of annual first date of arrival. The data layer includes four\nresponse variables: counts of observed eBird locations (Poisson);\npresence-absence at observed eBird locations (Binomial); BBS occurrence counts\n(Poisson); first arrival dates (Generalized Extreme-Value). We devise a Markov\nChain Monte Carlo scheme and check by simulation that the latent process\ncomponents are identifiable. We apply our model to several migratory bird\nspecies in the northeastern US for 2001--2021. The sampling effort is shown to\nsignificantly modulate the observed first arrival date. We exploit this\nrelationship to effectively debias predictions of the true first arrival dates.",
            "author": [
                "Jonathan Koh",
                "Thomas Opitz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01870v1",
                "http://arxiv.org/pdf/2312.01870v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01865v1",
            "title": "A comprehensive survey of Schwarzschild's original papers:\n  Schwarzschild's trick and Einstein's s(h)tick",
            "updated": "2023-12-04T12:57:04Z",
            "published": "2023-12-04T12:57:04Z",
            "summary": "This paper examines Schwarzschild's key contributions to general relativity\nthrough his two papers. It focuses on his method for developing exterior and\ninterior solutions. The study emphasizes Schwarzschild's ingenious methods and\nthe implications of his solutions. The paper delves into the exchange of\nletters between Schwarzschild and Einstein, highlighting the collaborative\nnature of their scientific interaction. Interestingly, despite presenting\nSchwarzschild's exact solutions to the Prussian Academy, Einstein exhibited a\npreference for his approximate methods in his 1916 review paper \"The Foundation\nof the General Theory of Relativity.\" Contrary to common belief, the paper\nreveals that in 1916, Einstein's preference for approximate solutions over\nSchwarzschild's exact exterior solution was not due to a singularity concern.\nThis finding dissociates Einstein's 1916 methodology from his later\npreoccupation with singularities, which became prominent only during his\nsubsequent focus on unified field theory. Thus, the research posits that\nfactors other than singularities influenced Einstein's decision to stick with\napproximate methods in 1916.",
            "author": [
                "Galina Weinstein"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01865v1",
                "http://arxiv.org/pdf/2312.01865v1"
            ],
            "primary_category": "physics.hist-ph",
            "category": [
                "physics.hist-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01860v2",
            "title": "Unveiling Objects with SOLA: An Annotation-Free Image Search on the\n  Object Level for Automotive Data Sets",
            "updated": "2023-12-07T09:24:35Z",
            "published": "2023-12-04T12:48:44Z",
            "summary": "Huge image data sets are the fundament for the development of the perception\nof automated driving systems. A large number of images is necessary to train\nrobust neural networks that can cope with diverse situations. A sufficiently\nlarge data set contains challenging situations and objects. For testing the\nresulting functions, it is necessary that these situations and objects can be\nfound and extracted from the data set. While it is relatively easy to record a\nlarge amount of unlabeled data, it is far more difficult to find demanding\nsituations and objects. However, during the development of perception systems,\nit must be possible to access challenging data without having to perform\nlengthy and time-consuming annotations. A developer must therefore be able to\nsearch dynamically for specific situations and objects in a data set. Thus, we\ndesigned a method which is based on state-of-the-art neural networks to search\nfor objects with certain properties within an image. For the ease of use, the\nquery of this search is described using natural language. To determine the time\nsavings and performance gains, we evaluated our method qualitatively and\nquantitatively on automotive data sets.",
            "author": [
                "Philipp Rigoll",
                "Jacob Langner",
                "Eric Sax"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01860v2",
                "http://arxiv.org/pdf/2312.01860v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01859v1",
            "title": "Optimization of Antenna Performance for Global 21-cm Observations and\n  Verification Using Scaled Copies",
            "updated": "2023-12-04T12:47:57Z",
            "published": "2023-12-04T12:47:57Z",
            "summary": "The sky-averaged cosmological 21 cm signal can improve our understanding of\nthe evolution of the early Universe from the Dark Age to the end of the Epoch\nof Reionization. Although the EDGES experiment reported an absorption profile\nof this signal, there have been concerns about the plausibility of these\nresults, motivating independent validation experiments. One of these\ninitiatives is the Mapper of the IGM Spin Temperature (MIST), which is planned\nto be deployed at different remote locations around the world. One of its key\nfeatures is that it seeks to comprehensively compensate for systematic\nuncertainties through detailed modeling and characterization of its different\ninstrumental subsystems, particularly its antenna. Here we propose a novel\noptimizing scheme which can be used to design an antenna applied to MIST,\nimproving bandwidth, return loss, and beam chromaticity. This new procedure\ncombines the Particle Swarm Optimization (PSO) algorithm with a commercial\nelectromagnetic simulation software (HFSS). We improved the performance of two\nantenna models: a rectangular blade antenna, similar to the one used in the\nEDGES experiment, and a trapezoidal bow-tie antenna. Although the performance\nof both antennas improved after applying our optimization method, we found that\nour bow-tie model outperforms the blade antenna by achieving lower reflection\nlosses and beam chromaticity in the entire band of interest. To further\nvalidate the optimization process, we also built and characterized 1:20 scale\nmodels of both antenna types showing an excellent agreement with our\nsimulations.",
            "author": [
                "O. A. Restrepo",
                "F. I. Lucero",
                "G. Chaparro",
                "R. Rodr\u00edguez",
                "F. Pizarro",
                "R. Bustos",
                "M. D\u00edaz",
                "F. P. Mena"
            ],
            "link": [
                "http://dx.doi.org/10.1142/S2251171723500058",
                "http://arxiv.org/abs/2312.01859v1",
                "http://arxiv.org/pdf/2312.01859v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01858v1",
            "title": "Evaluating Dependencies in Fact Editing for Language Models: Specificity\n  and Implication Awareness",
            "updated": "2023-12-04T12:45:30Z",
            "published": "2023-12-04T12:45:30Z",
            "summary": "The potential of using a large language model (LLM) as a knowledge base (KB)\nhas sparked significant interest. To manage the knowledge acquired by LLMs, we\nneed to ensure that the editing of learned facts respects internal logical\nconstraints, which are known as dependency of knowledge. Existing work on\nediting LLMs has partially addressed the issue of dependency, when the editing\nof a fact should apply to its lexical variations without disrupting irrelevant\nones. However, they neglect the dependency between a fact and its logical\nimplications. We propose an evaluation protocol with an accompanying\nquestion-answering dataset, DepEdit, that provides a comprehensive assessment\nof the editing process considering the above notions of dependency. Our\nprotocol involves setting up a controlled environment in which we edit facts\nand monitor their impact on LLMs, along with their implications based on\nIf-Then rules. Extensive experiments on DepEdit show that existing knowledge\nediting methods are sensitive to the surface form of knowledge, and that they\nhave limited performance in inferring the implications of edited facts.",
            "author": [
                "Zichao Li",
                "Ines Arous",
                "Siva Reddy",
                "Jackie C. K. Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01858v1",
                "http://arxiv.org/pdf/2312.01858v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01856v1",
            "title": "Surviving the Heat: multi-wavelength analysis of V883 Ori reveals that\n  dust aggregates survive the sublimation of their ice mantles",
            "updated": "2023-12-04T12:39:25Z",
            "published": "2023-12-04T12:39:25Z",
            "summary": "Investigating the response of icy dust aggregates to water ice sublimation is\nessential for understanding the formation and properties of planetesimals in\nprotoplanetary discs. However, their fate remains unclear, as previous studies\nsuggest aggregates could either survive or completely fall apart to\n(sub){\\mu}m-sized grains. Protoplanetary discs around stars undergoing\naccretion outbursts represent a unique laboratory to study the ice sublimation\nprocess, as the water snowline is pushed outward to regions accessible to\ncurrent observatories. In this work, we aim to understand the aggregates'\nresponse to ice sublimation by focusing on V883 Ori, a system currently\nundergoing a powerful accretion outburst. We present new analysis of archival\nhigh resolution ALMA observations of the protoplanetary disc of V883 Ori at\n0.88, 1.3, 2.0, and 3.1 mm, and derive new radial spectral index profiles,\nwhich we compare with predictions from one-dimensional dust evolution\nsimulations. In the region of V883 Ori where water ice has sublimated, we find\nlower spectral indices than previously obtained, indicating the presence of\ncm-sized particles. Coupled with our dust evolution models, we find that the\nonly way to explain their presence is to assume they formed before the\noutburst, and survived the sublimation process. The resilience of dust\naggregates to such intense events leads us to speculate that it may extend to\nother environments with more gentle heating, such as pebbles drifting through\nthe water snowline in quiescent protoplanetary discs. In that case, it may\nalter the formation pathway of dry planetesimals interior to the snowline.",
            "author": [
                "Adrien Houge",
                "Enrique Mac\u00edas",
                "Sebastiaan Krijt"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01856v1",
                "http://arxiv.org/pdf/2312.01856v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01854v1",
            "title": "Galaxy to cloud scales",
            "updated": "2023-12-04T12:36:52Z",
            "published": "2023-12-04T12:36:52Z",
            "summary": "Simulations from the scales of isolated galaxies to clouds have been\ninstrumental in informing us about molecular cloud formation and evolution.\nSimulations are able to investigate the roles of gravity, feedback, turbulence,\nheating and cooling, and magnetic fields on the physics of the interstellar\nmedium, and star formation. Compared to simulations of individual clouds,\ngalactic and sub-galactic scale simulations can include larger galactic scale\nprocesses such as spiral arms, bars, and larger supernovae bubbles, which may\ninfluence star formation. Simulations show cloud properties and lifetimes in\nbroad agreement with observations. Gravity and spiral arms are required to\nproduce more massive GMCs, whilst stellar feedback, likely photoionisation,\nleads to relatively short cloud lifetimes. On larger scales, supernovae may be\nmore dominant in driving the structure and dynamics, but photoionisation may\nstill have a role. In terms of the dynamics, feedback is probably the main\ndriver of velocity dispersions, but large scale processes such as gravity and\nspiral arms may also be significant. Magnetic fields are generally found to\ndecrease star formation on galaxy or cloud scales, and simulations are ongoing\nto study whether clouds are sub or supercritical on different scales in galaxy\nscale simulations. Simulations on subgalactic scales, or zoom in simulations,\nallow better resolution of feedback processes, filamentary structure within\nclouds, and the study of stellar clusters.",
            "author": [
                "Clare Dobbs"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01854v1",
                "http://arxiv.org/pdf/2312.01854v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01853v1",
            "title": "Robot Synesthesia: In-Hand Manipulation with Visuotactile Sensing",
            "updated": "2023-12-04T12:35:43Z",
            "published": "2023-12-04T12:35:43Z",
            "summary": "Executing contact-rich manipulation tasks necessitates the fusion of tactile\nand visual feedback. However, the distinct nature of these modalities poses\nsignificant challenges. In this paper, we introduce a system that leverages\nvisual and tactile sensory inputs to enable dexterous in-hand manipulation.\nSpecifically, we propose Robot Synesthesia, a novel point cloud-based tactile\nrepresentation inspired by human tactile-visual synesthesia. This approach\nallows for the simultaneous and seamless integration of both sensory inputs,\noffering richer spatial information and facilitating better reasoning about\nrobot actions. The method, trained in a simulated environment and then deployed\nto a real robot, is applicable to various in-hand object rotation tasks.\nComprehensive ablations are performed on how the integration of vision and\ntouch can improve reinforcement learning and Sim2Real performance. Our project\npage is available at https://yingyuan0414.github.io/visuotactile/ .",
            "author": [
                "Ying Yuan",
                "Haichuan Che",
                "Yuzhe Qin",
                "Binghao Huang",
                "Zhao-Heng Yin",
                "Kang-Won Lee",
                "Yi Wu",
                "Soo-Chul Lim",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01853v1",
                "http://arxiv.org/pdf/2312.01853v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02244v1",
            "title": "Geometrically-driven Aggregation for Zero-shot 3D Point Cloud\n  Understanding",
            "updated": "2023-12-04T12:30:07Z",
            "published": "2023-12-04T12:30:07Z",
            "summary": "Zero-shot 3D point cloud understanding can be achieved via 2D Vision-Language\nModels (VLMs). Existing strategies directly map Vision-Language Models from 2D\npixels of rendered or captured views to 3D points, overlooking the inherent and\nexpressible point cloud geometric structure. Geometrically similar or close\nregions can be exploited for bolstering point cloud understanding as they are\nlikely to share semantic information. To this end, we introduce the first\ntraining-free aggregation technique that leverages the point cloud's 3D\ngeometric structure to improve the quality of the transferred Vision-Language\nModels. Our approach operates iteratively, performing local-to-global\naggregation based on geometric and semantic point-level reasoning. We benchmark\nour approach on three downstream tasks, including classification, part\nsegmentation, and semantic segmentation, with a variety of datasets\nrepresenting both synthetic/real-world, and indoor/outdoor scenarios. Our\napproach achieves new state-of-the-art results in all benchmarks. We will\nrelease the source code publicly.",
            "author": [
                "Guofeng Mei",
                "Luigi Riz",
                "Yiming Wang",
                "Fabio Poiesi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02244v1",
                "http://arxiv.org/pdf/2312.02244v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01842v1",
            "title": "Exploring the Viability of Synthetic Audio Data for Audio-Based Dialogue\n  State Tracking",
            "updated": "2023-12-04T12:25:46Z",
            "published": "2023-12-04T12:25:46Z",
            "summary": "Dialogue state tracking plays a crucial role in extracting information in\ntask-oriented dialogue systems. However, preceding research are limited to\ntextual modalities, primarily due to the shortage of authentic human audio\ndatasets. We address this by investigating synthetic audio data for audio-based\nDST. To this end, we develop cascading and end-to-end models, train them with\nour synthetic audio dataset, and test them on actual human speech data. To\nfacilitate evaluation tailored to audio modalities, we introduce a novel\nPhonemeF1 to capture pronunciation similarity. Experimental results showed that\nmodels trained solely on synthetic datasets can generalize their performance to\nhuman voice data. By eliminating the dependency on human speech data\ncollection, these insights pave the way for significant practical advancements\nin audio-based DST. Data and code are available at\nhttps://github.com/JihyunLee1/E2E-DST.",
            "author": [
                "Jihyun Lee",
                "Yejin Jeon",
                "Wonjun Lee",
                "Yunsu Kim",
                "Gary Geunbae Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01842v1",
                "http://arxiv.org/pdf/2312.01842v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01841v2",
            "title": "VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D\n  Hybrid Prior",
            "updated": "2023-12-07T03:14:22Z",
            "published": "2023-12-04T12:25:37Z",
            "summary": "Audio-driven talking head generation has drawn much attention in recent\nyears, and many efforts have been made in lip-sync, expressive facial\nexpressions, natural head pose generation, and high video quality. However, no\nmodel has yet led or tied on all these metrics due to the one-to-many mapping\nbetween audio and motion. In this paper, we propose VividTalk, a two-stage\ngeneric framework that supports generating high-visual quality talking head\nvideos with all the above properties. Specifically, in the first stage, we map\nthe audio to mesh by learning two motions, including non-rigid expression\nmotion and rigid head motion. For expression motion, both blendshape and vertex\nare adopted as the intermediate representation to maximize the representation\nability of the model. For natural head motion, a novel learnable head pose\ncodebook with a two-phase training mechanism is proposed. In the second stage,\nwe proposed a dual branch motion-vae and a generator to transform the meshes\ninto dense motion and synthesize high-quality video frame-by-frame. Extensive\nexperiments show that the proposed VividTalk can generate high-visual quality\ntalking head videos with lip-sync and realistic enhanced by a large margin, and\noutperforms previous state-of-the-art works in objective and subjective\ncomparisons.",
            "author": [
                "Xusen Sun",
                "Longhao Zhang",
                "Hao Zhu",
                "Peng Zhang",
                "Bang Zhang",
                "Xinya Ji",
                "Kangneng Zhou",
                "Daiheng Gao",
                "Liefeng Bo",
                "Xun Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01841v2",
                "http://arxiv.org/pdf/2312.01841v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01837v1",
            "title": "Prompting Disentangled Embeddings for Knowledge Graph Completion with\n  Pre-trained Language Model",
            "updated": "2023-12-04T12:20:25Z",
            "published": "2023-12-04T12:20:25Z",
            "summary": "Both graph structures and textual information play a critical role in\nKnowledge Graph Completion (KGC). With the success of Pre-trained Language\nModels (PLMs) such as BERT, they have been applied for text encoding for KGC.\nHowever, the current methods mostly prefer to fine-tune PLMs, leading to huge\ntraining costs and limited scalability to larger PLMs. In contrast, we propose\nto utilize prompts and perform KGC on a frozen PLM with only the prompts\ntrained. Accordingly, we propose a new KGC method named PDKGC with two prompts\n-- a hard task prompt which is to adapt the KGC task to the PLM pre-training\ntask of token prediction, and a disentangled structure prompt which learns\ndisentangled graph representation so as to enable the PLM to combine more\nrelevant structure knowledge with the text information. With the two prompts,\nPDKGC builds a textual predictor and a structural predictor, respectively, and\ntheir combination leads to more comprehensive entity prediction. Solid\nevaluation on two widely used KGC datasets has shown that PDKGC often\noutperforms the baselines including the state-of-the-art, and its components\nare all effective. Our codes and data are available at\nhttps://github.com/genggengcss/PDKGC.",
            "author": [
                "Yuxia Geng",
                "Jiaoyan Chen",
                "Yuhang Zeng",
                "Zhuo Chen",
                "Wen Zhang",
                "Jeff Z. Pan",
                "Yuxiang Wang",
                "Xiaoliang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01837v1",
                "http://arxiv.org/pdf/2312.01837v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01836v1",
            "title": "Integrated Drill Boom Hole-Seeking Control via Reinforcement Learning",
            "updated": "2023-12-04T12:16:02Z",
            "published": "2023-12-04T12:16:02Z",
            "summary": "Intelligent drill boom hole-seeking is a promising technology for enhancing\ndrilling efficiency, mitigating potential safety hazards, and relieving human\noperators. Most existing intelligent drill boom control methods rely on a\nhierarchical control framework based on inverse kinematics. However, these\nmethods are generally time-consuming due to the computational complexity of\ninverse kinematics and the inefficiency of the sequential execution of multiple\njoints. To tackle these challenges, this study proposes an integrated drill\nboom control method based on Reinforcement Learning (RL). We develop an\nintegrated drill boom control framework that utilizes a parameterized policy to\ndirectly generate control inputs for all joints at each time step, taking\nadvantage of joint posture and target hole information. By formulating the\nhole-seeking task as a Markov decision process, contemporary mainstream RL\nalgorithms can be directly employed to learn a hole-seeking policy, thus\neliminating the need for inverse kinematics solutions and promoting cooperative\nmulti-joint control. To enhance the drilling accuracy throughout the entire\ndrilling process, we devise a state representation that combines\nDenavit-Hartenberg joint information and preview hole-seeking discrepancy data.\nSimulation results show that the proposed method significantly outperforms\ntraditional methods in terms of hole-seeking accuracy and time efficiency.",
            "author": [
                "Haoqi Yan",
                "Haoyuan Xu",
                "Hongbo Gao",
                "Fei Ma",
                "Shengbo Eben Li",
                "Jingliang Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01836v1",
                "http://arxiv.org/pdf/2312.01836v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01832v1",
            "title": "SPECRUN: The Danger of Speculative Runahead Execution in Processors",
            "updated": "2023-12-04T12:11:59Z",
            "published": "2023-12-04T12:11:59Z",
            "summary": "Runahead execution is a continuously evolving microarchitectural technique\nfor processor performance. This paper introduces the first transient execution\nattack on the runahead execution, called SPECRUN, which exploits the unresolved\nbranch prediction during runahead execution. We show that SPECRUN eliminates\nthe limitation on the number of transient instructions posed by the reorder\nbuffer size, enhancing the exploitability and harmfulness of the attack. We\nconcretely demonstrate a proof-of-concept attack that causes leaking secrets\nfrom a victim process, validate the merit of SPECRUN, and design a secure\nrunahead execution scheme. This paper highlights the need to consider the\nsecurity of potential optimization techniques before implementing them in a\nprocessor.",
            "author": [
                "Chaoqun Shen",
                "Gang Qu",
                "Jiliang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01832v1",
                "http://arxiv.org/pdf/2312.01832v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01831v1",
            "title": "Equivariant plug-and-play image reconstruction",
            "updated": "2023-12-04T12:07:39Z",
            "published": "2023-12-04T12:07:39Z",
            "summary": "Plug-and-play algorithms constitute a popular framework for solving inverse\nimaging problems that rely on the implicit definition of an image prior via a\ndenoiser. These algorithms can leverage powerful pre-trained denoisers to solve\na wide range of imaging tasks, circumventing the necessity to train models on a\nper-task basis. Unfortunately, plug-and-play methods often show unstable\nbehaviors, hampering their promise of versatility and leading to suboptimal\nquality of reconstructed images. In this work, we show that enforcing\nequivariance to certain groups of transformations (rotations, reflections,\nand/or translations) on the denoiser strongly improves the stability of the\nalgorithm as well as its reconstruction quality. We provide a theoretical\nanalysis that illustrates the role of equivariance on better performance and\nstability. We present a simple algorithm that enforces equivariance on any\nexisting denoiser by simply applying a random transformation to the input of\nthe denoiser and the inverse transformation to the output at each iteration of\nthe algorithm. Experiments on multiple imaging modalities and denoising\nnetworks show that the equivariant plug-and-play algorithm improves both the\nreconstruction performance and the stability compared to their non-equivariant\ncounterparts.",
            "author": [
                "Matthieu Terris",
                "Thomas Moreau",
                "Nelly Pustelnik",
                "Julian Tachella"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01831v1",
                "http://arxiv.org/pdf/2312.01831v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01828v1",
            "title": "Hajnal--M\u00e1t\u00e9 graphs, Cohen reals, and disjoint type guessing",
            "updated": "2023-12-04T12:03:31Z",
            "published": "2023-12-04T12:03:31Z",
            "summary": "A Hajnal--M\\'{a}t\\'{e} graph is an uncountably chromatic graph on $\\omega_1$\nsatisfying a certain natural sparseness condition. We investigate\nHajnal-M\\'{a}t\\'{e} graphs and generalizations thereof, focusing on the\nexistence of Hajnal-M\\'{a}t\\'{e} graphs in models resulting from adding a\nsingle Cohen real. In particular, answering a question of D\\'{a}niel Soukup, we\nshow that such models necessarily contain triangle-free Hajnal-M\\'{a}t\\'{e}\ngraphs. In the process, we isolate a weakening of club guessing called\n\\emph{disjoint type guessing} that we feel is of interest in its own right. We\nshow that disjoint type guessing is independent of $\\mathsf{ZFC}$ and, if\ndisjoint type guessing holds in the ground model, then the forcing extension by\na single Cohen real contains Hajnal-M\\'{a}t\\'{e} graphs $G$ such that the\nchromatic numbers of finite subgraphs of $G$ grow arbitrarily slowly.",
            "author": [
                "Chris Lambie-Hanson",
                "D\u00e1vid Uhrik"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01828v1",
                "http://arxiv.org/pdf/2312.01828v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "math.CO",
                "03E05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01824v1",
            "title": "NANOGrav hints for first-order confinement-deconfinement phase\n  transition in different QCD-matter scenarios",
            "updated": "2023-12-04T11:55:43Z",
            "published": "2023-12-04T11:55:43Z",
            "summary": "Recent observations from several pulsar timing array (PTA) collaborations\nhave unveiled compelling evidence for a stochastic signal in the nanohertz\nband. This signal aligns remarkably with a gravitational wave (GW) background,\npotentially originating from the first-order color charge confinement phase\ntransition. Distinct quantum chromodynamics (QCD) matters, such as quarks or\ngluons, and diverse phase transition processes thereof can yield disparate GW\nenergy density spectra. In this letter, employing the Bayesian analysis on the\nNANOGrav 15-year data set, we explore the compatibility with the observed PTA\nsignal of the GW from phase transitions of various QCD matter scenarios in the\nframework of the holographic QCD. We find that the PTA signal can be\neffectively explained by the GW from the confinement-deconfinement phase\ntransition of pure quark systems in a hard wall model of the holographic QCD\nwhere the bubble dynamics, one important source of the GWs, is of the Jouguet\ndetonations. Notably, our analysis decisively rules out the plausibility of the\npure gluon QCD-matter scenario and the non-runaway bubble dynamics model for\nthe phase transition in explaining the observed PTA signal.",
            "author": [
                "Zu-Cheng Chen",
                "Shou-Long Li",
                "Puxun Wu",
                "Hongwei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01824v1",
                "http://arxiv.org/pdf/2312.01824v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01823v1",
            "title": "Exchange-of-Thought: Enhancing Large Language Model Capabilities through\n  Cross-Model Communication",
            "updated": "2023-12-04T11:53:56Z",
            "published": "2023-12-04T11:53:56Z",
            "summary": "Large Language Models (LLMs) have recently made significant strides in\ncomplex reasoning tasks through the Chain-of-Thought technique. Despite this\nprogress, their reasoning is often constrained by their intrinsic\nunderstanding, lacking external insights. To address this, we propose\nExchange-of-Thought (EoT), a novel framework that enables cross-model\ncommunication during problem-solving. Drawing inspiration from network\ntopology, EoT integrates four unique communication paradigms: Memory, Report,\nRelay, and Debate. This paper delves into the communication dynamics and volume\nassociated with each paradigm. To counterbalance the risks of incorrect\nreasoning chains, we implement a robust confidence evaluation mechanism within\nthese communications. Our experiments across diverse complex reasoning tasks\ndemonstrate that EoT significantly surpasses established baselines,\nunderscoring the value of external insights in enhancing LLM performance.\nFurthermore, we show that EoT achieves these superior results in a\ncost-effective manner, marking a promising advancement for efficient and\ncollaborative AI problem-solving.",
            "author": [
                "Zhangyue Yin",
                "Qiushi Sun",
                "Cheng Chang",
                "Qipeng Guo",
                "Junqi Dai",
                "Xuanjing Huang",
                "Xipeng Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01823v1",
                "http://arxiv.org/pdf/2312.01823v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01818v1",
            "title": "Learning Machine Morality through Experience and Interaction",
            "updated": "2023-12-04T11:46:34Z",
            "published": "2023-12-04T11:46:34Z",
            "summary": "Increasing interest in ensuring safety of next-generation Artificial\nIntelligence (AI) systems calls for novel approaches to embedding morality into\nautonomous agents. Traditionally, this has been done by imposing explicit\ntop-down rules or hard constraints on systems, for example by filtering system\noutputs through pre-defined ethical rules. Recently, instead, entirely\nbottom-up methods for learning implicit preferences from human behavior have\nbecome increasingly popular, such as those for training and fine-tuning Large\nLanguage Models. In this paper, we provide a systematization of existing\napproaches to the problem of introducing morality in machines - modeled as a\ncontinuum, and argue that the majority of popular techniques lie at the\nextremes - either being fully hard-coded, or entirely learned, where no\nexplicit statement of any moral principle is required. Given the relative\nstrengths and weaknesses of each type of methodology, we argue that more hybrid\nsolutions are needed to create adaptable and robust, yet more controllable and\ninterpretable agents.\n  In particular, we present three case studies of recent works which use\nlearning from experience (i.e., Reinforcement Learning) to explicitly provide\nmoral principles to learning agents - either as intrinsic rewards, moral\nlogical constraints or textual principles for language models. For example,\nusing intrinsic rewards in Social Dilemma games, we demonstrate how it is\npossible to represent classical moral frameworks for agents. We also present an\noverview of the existing work in this area in order to provide empirical\nevidence for the potential of this hybrid approach. We then discuss strategies\nfor evaluating the effectiveness of moral learning agents. Finally, we present\nopen research questions and implications for the future of AI safety and ethics\nwhich are emerging from this framework.",
            "author": [
                "Elizaveta Tennant",
                "Stephen Hailes",
                "Mirco Musolesi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01818v1",
                "http://arxiv.org/pdf/2312.01818v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01817v1",
            "title": "A simulation method for the wetting dynamics of liquid droplets on\n  deformable membranes",
            "updated": "2023-12-04T11:45:55Z",
            "published": "2023-12-04T11:45:55Z",
            "summary": "Biological cells utilize membranes and liquid-like droplets, known as\nbiomolecular condensates, to structure their interior. The interaction of\ndroplets and membranes, despite being involved in several key biological\nprocesses, is so far little-understood. Here, we present a first numerical\nmethod to simulate the continuum dynamics of droplets interacting with\ndeformable membranes via wetting. The method combines the advantages of the\nphase field method for multi-phase flow simulation and the arbitrary\nLagrangian-Eulerian (ALE) method for an explicit description of the elastic\nsurface. The model is thermodynamically consistent, coupling bulk hydrodynamics\nwith capillary forces, as well as bending, tension, and stretching of a thin\nmembrane. The method is validated by comparing simulations for single droplets\nto theoretical results of shape equations, and its capabilities are illustrated\nin 2D and 3D axisymmetric scenarios.",
            "author": [
                "Marcel Mokbel",
                "Dominic Mokbel",
                "Susanne Liese",
                "Christoph A. Weber",
                "Sebastian Aland"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01817v1",
                "http://arxiv.org/pdf/2312.01817v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cs.CE",
                "physics.bio-ph",
                "physics.comp-ph",
                "q-bio.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02242v1",
            "title": "Quantum State-Channel Duality for the calculation of Standard Model\n  scattering amplitudes",
            "updated": "2023-12-04T11:40:36Z",
            "published": "2023-12-04T11:40:36Z",
            "summary": "Recent instances of successful application of quantum information techniques\nto particle physics problems invite for an analysis of the mathematical details\nbehind such connection. In this paper, we identify the Choi-Jamiolkowski\nisomorphism, or state-channel duality, as a theoretical principle enabling the\napplication of the theory of quantum information to the scattering amplitudes\nassociated with Standard Model processes.",
            "author": [
                "Clelia Altomonte",
                "Alan J. Barr"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.physletb.2023.138303",
                "http://arxiv.org/abs/2312.02242v1",
                "http://arxiv.org/pdf/2312.02242v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01812v1",
            "title": "Emergence of innovations in networked populations with reputation-driven\n  interactions",
            "updated": "2023-12-04T11:33:25Z",
            "published": "2023-12-04T11:33:25Z",
            "summary": "In this work we analyze how reputation-based interactions influence the\nemergence of innovations. To do so, we make use of a dynamic model that mimics\nthe discovery process by which, at each time step, a pair of individuals meet\nand merge their knowledge to eventually result in a novel technology of higher\nvalue. The way in which these pairs are brought together is found to be crucial\nfor achieving the highest technological level. Our results show that when the\ninfluence of reputation is weak or moderate, it induces an acceleration of the\ndiscovery process with respect to the neutral case (purely random coupling).\nHowever, an excess of reputation is clearly detrimental, because it leads to an\nexcessive concentration of knowledge in a small set of people, which prevents a\ndiversification of the technologies discovered and, in addition, leads to\nsocieties in which a majority of individuals lack technical capabilities.",
            "author": [
                "Pablo Gallarta-S\u00e1enz",
                "Hugo P\u00e9rez-Mart\u00ednez",
                "Jes\u00fas G\u00f3mez-Garde\u00f1es"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01812v1",
                "http://arxiv.org/pdf/2312.01812v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01808v1",
            "title": "Head Orientation Estimation with Distributed Microphones Using Speech\n  Radiation Patterns",
            "updated": "2023-12-04T11:14:55Z",
            "published": "2023-12-04T11:14:55Z",
            "summary": "Determining the head orientation of a talker is not only beneficial for\nvarious speech signal processing applications, such as source localization or\nspeech enhancement, but also facilitates intuitive voice control and\ninteraction with smart environments or modern car assistants. Most approaches\nfor head orientation estimation are based on visual cues. However, this\nrequires camera systems which often are not available. We present an approach\nwhich purely uses audio signals captured with only a few distributed\nmicrophones around the talker. Specifically, we propose a novel method that\ndirectly incorporates measured or modeled speech radiation patterns to infer\nthe talker's orientation during active speech periods based on a cosine\nsimilarity measure. Moreover, an automatic gain adjustment technique is\nproposed for uncalibrated, irregular microphone setups, such as ad-hoc sensor\nnetworks. In experiments with signals recorded in both anechoic and reverberant\nenvironments, the proposed method outperforms state-of-the-art approaches,\nusing either measured or modeled speech radiation patterns.",
            "author": [
                "Kaspar M\u00fcller",
                "Bilgesu \u00c7akmak",
                "Paul Didier",
                "Simon Doclo",
                "Jan \u00d8stergaard",
                "Tobias Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01808v1",
                "http://arxiv.org/pdf/2312.01808v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01807v1",
            "title": "Moduli Space of Dihedral Spherical Surfaces and Measured Foliations",
            "updated": "2023-12-04T11:14:28Z",
            "published": "2023-12-04T11:14:28Z",
            "summary": "Cone spherical surfaces are Riemannian surfaces with constant curvature one\nand a finite number of conical singularities. Dihedral surfaces, a subset of\nthese spherical surfaces, possess monodromy groups that preserve a pair of\nantipodal points on the unit two-sphere within three-dimensional Euclidean\nspace. On each dihedral surface, we naturally define a pair of transverse\nmeasured foliations, which, conversely, fully characterize the original\ndihedral surface. Additionally, we introduce several geometric decompositions\nand deformations for dihedral surfaces. As a practical application, we\ndetermine the dimension of the moduli space for dihedral surfaces with\nprescribed cone angles and topological types. This dimension serves as a\nmeasure of the independent geometric parameters determining the isometric\nclasses of such surfaces.",
            "author": [
                "Sicheng Lu",
                "Bin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01807v1",
                "http://arxiv.org/pdf/2312.01807v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.CV",
                "math.DG",
                "32G15, 30F30, 53A10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01801v1",
            "title": "SPROUT: Authoring Programming Tutorials with Interactive Visualization\n  of Large Language Model Generation Process",
            "updated": "2023-12-04T10:46:52Z",
            "published": "2023-12-04T10:46:52Z",
            "summary": "The rapid development of large language models (LLMs), such as ChatGPT, has\nrevolutionized the efficiency of creating programming tutorials. LLMs can be\ninstructed with text prompts to generate comprehensive text descriptions of\ncode snippets. However, the lack of transparency in the end-to-end generation\nprocess has hindered the understanding of model behavior and limited user\ncontrol over the generated results. To tackle this challenge, we introduce a\nnovel approach that breaks down the programming tutorial creation task into\nactionable steps. By employing the tree-of-thought method, LLMs engage in an\nexploratory process to generate diverse and faithful programming tutorials. We\nthen present SPROUT, an authoring tool equipped with a series of interactive\nvisualizations that empower users to have greater control and understanding of\nthe programming tutorial creation process. A formal user study demonstrated the\neffectiveness of SPROUT, showing that our tool assists users to actively\nparticipate in the programming tutorial creation process, leading to more\nreliable and customizable results. By providing users with greater control and\nunderstanding, SPROUT enhances the user experience and improves the overall\nquality of programming tutorial. A free copy of this paper and all supplemental\nmaterials are available at\nhttps://osf.io/uez2t/?view_only=5102e958802341daa414707646428f86.",
            "author": [
                "Yihan Liu",
                "Zhen Wen",
                "Luoxuan Weng",
                "Ollie Woodman",
                "Yi Yang",
                "Wei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01801v1",
                "http://arxiv.org/pdf/2312.01801v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01800v1",
            "title": "Collaborative Neural Painting",
            "updated": "2023-12-04T10:45:12Z",
            "published": "2023-12-04T10:45:12Z",
            "summary": "The process of painting fosters creativity and rational planning. However,\nexisting generative AI mostly focuses on producing visually pleasant artworks,\nwithout emphasizing the painting process. We introduce a novel task,\nCollaborative Neural Painting (CNP), to facilitate collaborative art painting\ngeneration between humans and machines. Given any number of user-input\nbrushstrokes as the context or just the desired object class, CNP should\nproduce a sequence of strokes supporting the completion of a coherent painting.\nImportantly, the process can be gradual and iterative, so allowing users'\nmodifications at any phase until the completion. Moreover, we propose to solve\nthis task using a painting representation based on a sequence of parametrized\nstrokes, which makes it easy both editing and composition operations. These\nparametrized strokes are processed by a Transformer-based architecture with a\nnovel attention mechanism to model the relationship between the input strokes\nand the strokes to complete. We also propose a new masking scheme to reflect\nthe interactive nature of CNP and adopt diffusion models as the basic learning\nprocess for its effectiveness and diversity in the generative field. Finally,\nto develop and validate methods on the novel task, we introduce a new dataset\nof painted objects and an evaluation protocol to benchmark CNP both\nquantitatively and qualitatively. We demonstrate the effectiveness of our\napproach and the potential of the CNP task as a promising avenue for future\nresearch.",
            "author": [
                "Nicola Dall'Asen",
                "Willi Menapace",
                "Elia Peruzzo",
                "Enver Sangineto",
                "Yiming Wang",
                "Elisa Ricci"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01800v1",
                "http://arxiv.org/pdf/2312.01800v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01798v1",
            "title": "First Principal Investigations to Explore the Half-metallicity,\n  Structural, Mechanical, and Optoelectronic Properties of Sodium-Based\n  Fluoroperovskites NaYF3 (Y = Sc and Ti) for Applications in Spintronics and\n  Optoelectronics",
            "updated": "2023-12-04T10:42:42Z",
            "published": "2023-12-04T10:42:42Z",
            "summary": "A theoretical investigation was conducted on Na-based fluoro-perovskites\nNaYF3 (Y = Sc, Ti) to examine their structural, optical, electronic, and\nmechanical characteristics for the first time. These cubic compounds exhibit\nstructural stability, maintaining perovskite structures with lattice spacing\nranging from 4.15 to 4.26 {\\AA}. Computation of elastic parameters confirms\ntheir stability, ionic bonding, ductility, and anisotropy. Computed band\nprofiles reveal the half-metallic nature with indirect (M-{\\Gamma}) bandgaps\nfor the spin-down configurations. Furthermore, density-of-states analysis\nhighlights the role of Y (Sc, Ti) atoms in the metallic character and\nconduction band contribution. The lack of absorbance in the visible region\nhighlights the materials' suitability for optoelectronic devices. This\ninvestigation aims to provide comprehensive insights and encourage further\nexperimental research.",
            "author": [
                "Saeed Ullah",
                "Uzma Gul",
                "Saad Tariq",
                "Riaz Ullah",
                "Nasir Rahman",
                "Essam A. Ali",
                "Mudasser Husain",
                "Munawar Abbas",
                "Hafeez Ullah"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01798v1",
                "http://arxiv.org/pdf/2312.01798v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02241v1",
            "title": "A Mapping of Triangular Block Interleavers to DRAM for Optical Satellite\n  Communication",
            "updated": "2023-12-04T10:41:41Z",
            "published": "2023-12-04T10:41:41Z",
            "summary": "Communication in optical downlinks of low earth orbit (LEO) satellites\nrequires interleaving to enable reliable data transmission. These interleavers\nare orders of magnitude larger than conventional interleavers utilized for\nexample in wireless communication. Hence, the capacity of on-chip memories\n(SRAMs) is insufficient to store all symbols and external memories (DRAMs) must\nbe used. Due to the overall requirement for very high data rates beyond 100\nGbit/s, DRAM bandwidth then quickly becomes a critical bottleneck of the\ncommunication system. In this paper, we investigate triangular block\ninterleavers for the aforementioned application and show that the standard\nmapping of symbols used for SRAMs results in low bandwidth utilization for\nDRAMs, in some cases below 50 %. As a solution, we present a novel mapping\napproach that combines different optimizations and achieves over 90 % bandwidth\nutilization in all tested configurations. Further, the mapping can be applied\nto any JEDEC-compliant DRAM device.",
            "author": [
                "Lukas Steiner",
                "Timo Lehnigk-Emden",
                "Markus Fehrenz",
                "Norbert Wehn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02241v1",
                "http://arxiv.org/pdf/2312.02241v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01797v1",
            "title": "LLM A*: Human in the Loop Large Language Models Enabled A* Search for\n  Robotics",
            "updated": "2023-12-04T10:37:58Z",
            "published": "2023-12-04T10:37:58Z",
            "summary": "This research focuses on how Large Language Models (LLMs) can help with path\nplanning for mobile embodied agents such as robots, in a human-in-the-loop and\ninteractive manner. A novel framework named LLM A*, aims to leverage the\ncommonsense of LLMs, and the utility-optimal A* is proposed to facilitate\nfew-shot near-optimal path planning. Prompts are used to 1) provide LLMs with\nessential information like environment, cost, heuristics, etc.; 2) communicate\nhuman feedback to LLMs on intermediate planning results. This makes the whole\npath planning process a `white box' and human feedback guides LLM A* to\nconverge quickly compared to other data-driven methods such as reinforcement\nlearning-based (RL) path planning. In addition, it makes code-free path\nplanning practical, henceforth promoting the inclusiveness of artificial\nintelligence techniques. Comparative analysis against A* and RL shows that LLM\nA* is more efficient in terms of search space and achieves an on-a-par path\nwith A* and a better path than RL. The interactive nature of LLM A* also makes\nit a promising tool for deployment in collaborative human-robot tasks.",
            "author": [
                "Hengjia Xiao",
                "Peng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01797v1",
                "http://arxiv.org/pdf/2312.01797v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01796v1",
            "title": "Using Bayesian Optimization to Design Time Step Size Controllers with\n  Application to Modified Patankar--Runge--Kutta Methods",
            "updated": "2023-12-04T10:36:26Z",
            "published": "2023-12-04T10:36:26Z",
            "summary": "Modified Patankar--Runge--Kutta (MPRK) methods are linearly implicit time\nintegration schemes developed to preserve positivity and a linear invariant\nsuch as the total mass in chemical reactions. MPRK methods are naturally\nequipped with embedded schemes yielding a local error estimate similar to\nRunge--Kutta pairs. To design good time step size controllers using these error\nestimates, we propose to use Bayesian optimization. In particular, we design a\nnovel objective function that captures important properties such as tolerance\nconvergence and computational stability. We apply our new approach to several\nMPRK schemes and controllers based on digital signal processing, extending\nclassical PI and PID controllers. We demonstrate that the optimization process\nyields controllers that are at least as good as the best controllers chosen\nfrom a wide range of suggestions available for classical explicit and implicit\ntime integration methods.",
            "author": [
                "Thomas Izgin",
                "Hendrik Ranocha"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01796v1",
                "http://arxiv.org/pdf/2312.01796v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65L05, 65L50, 65L20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01795v1",
            "title": "Distributed Continual Learning with CoCoA in High-dimensional Linear\n  Regression",
            "updated": "2023-12-04T10:35:46Z",
            "published": "2023-12-04T10:35:46Z",
            "summary": "We consider estimation under scenarios where the signals of interest exhibit\nchange of characteristics over time. In particular, we consider the continual\nlearning problem where different tasks, e.g., data with different\ndistributions, arrive sequentially and the aim is to perform well on the newly\narrived task without performance degradation on the previously seen tasks. In\ncontrast to the continual learning literature focusing on the centralized\nsetting, we investigate the problem from a distributed estimation perspective.\nWe consider the well-established distributed learning algorithm COCOA, which\ndistributes the model parameters and the corresponding features over the\nnetwork. We provide exact analytical characterization for the generalization\nerror of COCOA under continual learning for linear regression in a range of\nscenarios, where overparameterization is of particular interest. These\nanalytical results characterize how the generalization error depends on the\nnetwork structure, the task similarity and the number of tasks, and show how\nthese dependencies are intertwined. In particular, our results show that the\ngeneralization error can be significantly reduced by adjusting the network\nsize, where the most favorable network size depends on task similarity and the\nnumber of tasks. We present numerical results verifying the theoretical\nanalysis and illustrate the continual learning performance of COCOA with a\ndigit classification task.",
            "author": [
                "Martin Hellkvist",
                "Ay\u00e7a \u00d6z\u00e7elikkale",
                "Anders Ahl\u00e9n"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01795v1",
                "http://arxiv.org/pdf/2312.01795v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01792v1",
            "title": "Wild-Tab: A Benchmark For Out-Of-Distribution Generalization In Tabular\n  Regression",
            "updated": "2023-12-04T10:27:38Z",
            "published": "2023-12-04T10:27:38Z",
            "summary": "Out-of-Distribution (OOD) generalization, a cornerstone for building robust\nmachine learning models capable of handling data diverging from the training\nset's distribution, is an ongoing challenge in deep learning. While significant\nprogress has been observed in computer vision and natural language processing,\nits exploration in tabular data, ubiquitous in many industrial applications,\nremains nascent. To bridge this gap, we present Wild-Tab, a large-scale\nbenchmark tailored for OOD generalization in tabular regression tasks. The\nbenchmark incorporates 3 industrial datasets sourced from fields like weather\nprediction and power consumption estimation, providing a challenging testbed\nfor evaluating OOD performance under real-world conditions. Our extensive\nexperiments, evaluating 10 distinct OOD generalization methods on Wild-Tab,\nreveal nuanced insights. We observe that many of these methods often struggle\nto maintain high-performance levels on unseen data, with OOD performance\nshowing a marked drop compared to in-distribution performance. At the same\ntime, Empirical Risk Minimization (ERM), despite its simplicity, delivers\nrobust performance across all evaluations, rivaling the results of\nstate-of-the-art methods. Looking forward, we hope that the release of Wild-Tab\nwill facilitate further research on OOD generalization and aid in the\ndeployment of machine learning models in various real-world contexts where\nhandling distribution shifts is a crucial requirement.",
            "author": [
                "Sergey Kolesnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01792v1",
                "http://arxiv.org/pdf/2312.01792v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02240v1",
            "title": "Contrastive Learning-Based Spectral Knowledge Distillation for\n  Multi-Modality and Missing Modality Scenarios in Semantic Segmentation",
            "updated": "2023-12-04T10:27:09Z",
            "published": "2023-12-04T10:27:09Z",
            "summary": "Improving the performance of semantic segmentation models using multispectral\ninformation is crucial, especially for environments with low-light and adverse\nconditions. Multi-modal fusion techniques pursue either the learning of\ncross-modality features to generate a fused image or engage in knowledge\ndistillation but address multimodal and missing modality scenarios as distinct\nissues, which is not an optimal approach for multi-sensor models. To address\nthis, a novel multi-modal fusion approach called CSK-Net is proposed, which\nuses a contrastive learning-based spectral knowledge distillation technique\nalong with an automatic mixed feature exchange mechanism for semantic\nsegmentation in optical (EO) and infrared (IR) images. The distillation scheme\nextracts detailed textures from the optical images and distills them into the\noptical branch of CSK-Net. The model encoder consists of shared convolution\nweights with separate batch norm (BN) layers for both modalities, to capture\nthe multi-spectral information from different modalities of the same objects. A\nNovel Gated Spectral Unit (GSU) and mixed feature exchange strategy are\nproposed to increase the correlation of modality-shared information and\ndecrease the modality-specific information during the distillation process.\nComprehensive experiments show that CSK-Net surpasses state-of-the-art models\nin multi-modal tasks and for missing modalities when exclusively utilizing IR\ndata for inference across three public benchmarking datasets. For missing\nmodality scenarios, the performance increase is achieved without additional\ncomputational costs compared to the baseline segmentation models.",
            "author": [
                "Aniruddh Sikdar",
                "Jayant Teotia",
                "Suresh Sundaram"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02240v1",
                "http://arxiv.org/pdf/2312.02240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01790v1",
            "title": "Exploring Multi-Modal Fusion for Image Manipulation Detection and\n  Localization",
            "updated": "2023-12-04T10:25:42Z",
            "published": "2023-12-04T10:25:42Z",
            "summary": "Recent image manipulation localization and detection techniques usually\nleverage forensic artifacts and traces that are produced by a noise-sensitive\nfilter, such as SRM and Bayar convolution. In this paper, we showcase that\ndifferent filters commonly used in such approaches excel at unveiling different\ntypes of manipulations and provide complementary forensic traces. Thus, we\nexplore ways of merging the outputs of such filters and aim to leverage the\ncomplementary nature of the artifacts produced to perform image manipulation\nlocalization and detection (IMLD). We propose two distinct methods: one that\nproduces independent features from each forensic filter and then fuses them\n(this is referred to as late fusion) and one that performs early mixing of\ndifferent modal outputs and produces early combined features (this is referred\nto as early fusion). We demonstrate that both approaches achieve competitive\nperformance for both image manipulation localization and detection,\noutperforming state-of-the-art models across several datasets.",
            "author": [
                "Konstantinos Triaridis",
                "Vasileios Mezaris"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01790v1",
                "http://arxiv.org/pdf/2312.01790v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01789v1",
            "title": "Two-stage optimized unified adversarial patch for attacking\n  visible-infrared cross-modal detectors in the physical world",
            "updated": "2023-12-04T10:25:34Z",
            "published": "2023-12-04T10:25:34Z",
            "summary": "Currently, many studies have addressed security concerns related to visible\nand infrared detectors independently. In practical scenarios, utilizing\ncross-modal detectors for tasks proves more reliable than relying on\nsingle-modal detectors. Despite this, there is a lack of comprehensive security\nevaluations for cross-modal detectors. While existing research has explored the\nfeasibility of attacks against cross-modal detectors, the implementation of a\nrobust attack remains unaddressed. This work introduces the Two-stage Optimized\nUnified Adversarial Patch (TOUAP) designed for performing attacks against\nvisible-infrared cross-modal detectors in real-world, black-box settings. The\nTOUAP employs a two-stage optimization process: firstly, PSO optimizes an\nirregular polygonal infrared patch to attack the infrared detector; secondly,\nthe color QR code is optimized, and the shape information of the infrared patch\nfrom the first stage is used as a mask. The resulting irregular polygon visible\nmodal patch executes an attack on the visible detector. Through extensive\nexperiments conducted in both digital and physical environments, we validate\nthe effectiveness and robustness of the proposed method. As the TOUAP surpasses\nbaseline performance, we advocate for its widespread attention.",
            "author": [
                "Chengyin Hu",
                "Weiwen Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01789v1",
                "http://arxiv.org/pdf/2312.01789v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01788v1",
            "title": "Functional Magnetic Resonance Imaging Changes and Increased Muscle\n  Pressure in Fibromyalgia: Insights from Prominent Theories of Pain and Muscle\n  Imaging",
            "updated": "2023-12-04T10:21:30Z",
            "published": "2023-12-04T10:21:30Z",
            "summary": "Fibromyalgia is a complicated and multifaceted disorder marked by widespread\nchronic pain, fatigue, and muscle tenderness. Current explanations for the\npathophysiology of this condition include the Central Sensitization Theory,\nCytokine Inflammation Theory, Muscle Hypoxia, Muscle Tender Point Theory, and\nSmall Fiber Neuropathy Theory. The objective of this review article is to\nexamine and explain each of these current theories and to provide a background\non our current understanding of fibromyalgia. The medical literature on this\ndisorder, as well as on the roles of functional magnetic resonance imaging\n(fMRI) and elastography as diagnostic tools, was reviewed from the 1970s to\nearly 2023, primarily using the PubMed database. Five prominent theories of\nfibromyalgia etiology were examined: 1) Central Sensitization Theory; 2)\nCytokine Inflammation Theory; 3) Muscle Hypoxia; 4) Muscle Tender Point Theory;\nand 5) Small Fiber Neuropathy Theory. Previous fMRI studies of FMS have\nrevealed two key findings. First, patients with FMS show altered activation\npatterns in brain regions involved in pain processing. Second, the connectivity\nbetween brain structures in individuals diagnosed with FMS and healthy controls\nis different. Both of these findings will be expanded upon in this paper.\n  The article also explores the potential for future research in fibromyalgia\ndue to the advancements in fMRI and elastography techniques, such as shear wave\nultrasound. Increased understanding of the underlying mechanisms contributing\nto fibromyalgia symptoms is necessary for improved diagnosis and treatment, and\nadvanced imaging techniques can aid in this process.",
            "author": [
                "Seth Adler",
                "Farzan Vahedifard",
                "Rachel Akers",
                "Christopher Sica",
                "Mehmet Kocak",
                "Edwin Moore",
                "Marc Minkus",
                "Gianna Elias",
                "Nikhil Aggarwal",
                "Sharon Byrd",
                "Mehmoodur Rasheed",
                "Robert S. Katz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01788v1",
                "http://arxiv.org/pdf/2312.01788v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "q-bio.CB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01787v1",
            "title": "Developing Linguistic Patterns to Mitigate Inherent Human Bias in\n  Offensive Language Detection",
            "updated": "2023-12-04T10:20:36Z",
            "published": "2023-12-04T10:20:36Z",
            "summary": "With the proliferation of social media, there has been a sharp increase in\noffensive content, particularly targeting vulnerable groups, exacerbating\nsocial problems such as hatred, racism, and sexism. Detecting offensive\nlanguage use is crucial to prevent offensive language from being widely shared\non social media. However, the accurate detection of irony, implication, and\nvarious forms of hate speech on social media remains a challenge. Natural\nlanguage-based deep learning models require extensive training with large,\ncomprehensive, and labeled datasets. Unfortunately, manually creating such\ndatasets is both costly and error-prone. Additionally, the presence of\nhuman-bias in offensive language datasets is a major concern for deep learning\nmodels. In this paper, we propose a linguistic data augmentation approach to\nreduce bias in labeling processes, which aims to mitigate the influence of\nhuman bias by leveraging the power of machines to improve the accuracy and\nfairness of labeling processes. This approach has the potential to improve\noffensive language classification tasks across multiple languages and reduce\nthe prevalence of offensive content on social media.",
            "author": [
                "Toygar Tanyel",
                "Besher Alkurdi",
                "Serkan Ayvaz"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01787v1",
                "http://arxiv.org/pdf/2312.01787v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01778v1",
            "title": "Differential deposition applied to x-ray mirror substrate",
            "updated": "2023-12-04T10:03:22Z",
            "published": "2023-12-04T10:03:22Z",
            "summary": "The process of differential deposition is currently applied at the ESRF in\norder to correct figure errors of x-ray optics substrates, prior to multilayer\ndeposition. The substrate is moved at a controlled speed in front of a\nsputtering source to precisely control the deposition profile. This work will\ndescribe the concept of differential deposition at the ESRF as well as recent\nresults of its implementation to correct a real mirror substrate surface.\nFinally, initial studies using a synchrotron beamline characterization\ntechnique based on x-ray total reflection are presented.",
            "author": [
                "Patrice Bras",
                "Sylvain Labour\u00e9",
                "Amparo Vivo",
                "Fran\u00e7ois Perrin",
                "Christian Morawe"
            ],
            "link": [
                "http://dx.doi.org/10.1117/12.2665823",
                "http://arxiv.org/abs/2312.01778v1",
                "http://arxiv.org/pdf/2312.01778v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01777v1",
            "title": "Doubly 1-Bit Quantized Massive MIMO",
            "updated": "2023-12-04T10:03:09Z",
            "published": "2023-12-04T10:03:09Z",
            "summary": "Enabling communications in the (sub-)THz band will call for massive\nmultiple-input multiple-output (MIMO) arrays at either the transmit- or\nreceive-side, or at both. To scale down the complexity and power consumption\nwhen operating across massive frequency and antenna dimensions, a sacrifice in\nthe resolution of the digital-to-analog/analog-to-digital converters\n(DACs/ADCs) will be inevitable. In this paper, we analyze the extreme scenario\nwhere both the transmit- and receive-side are equipped with fully digital\nmassive MIMO arrays and 1-bit DACs/ADCs, which leads to a system with minimum\nradio-frequency complexity, cost, and power consumption. Building upon the\nBussgang decomposition, we derive a tractable approximation of the mean squared\nerror (MSE) between the transmitted data symbols and their soft estimates.\nNumerical results show that, despite its simplicity, a doubly 1-bit quantized\nmassive MIMO system with very large antenna arrays can deliver an impressive\nperformance in terms of MSE and symbol error rate.",
            "author": [
                "Italo Atzeni",
                "Antti T\u00f6lli",
                "Duy H. N. Nguyen",
                "A. Lee Swindlehurst"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01777v1",
                "http://arxiv.org/pdf/2312.01777v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01775v1",
            "title": "Geometry on Optimal Problem",
            "updated": "2023-12-04T10:00:40Z",
            "published": "2023-12-04T10:00:40Z",
            "summary": "We introduce an algorithm which can be directly used to feasible and optimum\nsearch in linear programming. Starting from an initial point the algorithm\niteratively moves a point in a direction to resolve the violated constraints.\nAt the same time, it ensures that previously fulfilled constraints are not\nbreached during this process. The method is based on geometrical properties of\nn-dimensional space and can be used on any type of linear constraints (>, =,\n$\\geq$), moreover it can be used when the feasible region is\nnon-full-dimensional.",
            "author": [
                "Denys Shcherbak",
                "Natalya Pya Arnqvist"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01775v1",
                "http://arxiv.org/pdf/2312.01775v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01771v1",
            "title": "IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks",
            "updated": "2023-12-04T09:48:29Z",
            "published": "2023-12-04T09:48:29Z",
            "summary": "In-context learning allows adapting a model to new tasks given a task\ndescription at test time. In this paper, we present IMProv - a generative model\nthat is able to in-context learn visual tasks from multimodal prompts. Given a\ntextual description of a visual task (e.g. \"Left: input image, Right:\nforeground segmentation\"), a few input-output visual examples, or both, the\nmodel in-context learns to solve it for a new test input. We train a masked\ngenerative transformer on a new dataset of figures from computer vision papers\nand their associated captions, together with a captioned large-scale image-text\ndataset. During inference time, we prompt the model with text and/or image task\nexample(s) and have the model inpaint the corresponding output. We show that\ntraining our model with text conditioning and scaling the dataset size improves\nin-context learning for computer vision tasks by over +10\\% AP for Foreground\nSegmentation, over +5\\% gains in AP for Single Object Detection, and almost\n20\\% lower LPIPS in Colorization. Our empirical results suggest that vision and\nlanguage prompts are complementary and it is advantageous to use both to\nachieve better in-context learning performance. Project page is available at\nhttps://jerryxu.net/IMProv .",
            "author": [
                "Jiarui Xu",
                "Yossi Gandelsman",
                "Amir Bar",
                "Jianwei Yang",
                "Jianfeng Gao",
                "Trevor Darrell",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01771v1",
                "http://arxiv.org/pdf/2312.01771v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01756v1",
            "title": "A Comprehensive Literature Review on Sweet Orange Leaf Diseases",
            "updated": "2023-12-04T09:35:21Z",
            "published": "2023-12-04T09:35:21Z",
            "summary": "Sweet orange leaf diseases are significant to agricultural productivity. Leaf\ndiseases impact fruit quality in the citrus industry. The apparition of machine\nlearning makes the development of disease finder. Early detection and diagnosis\nare necessary for leaf management. Sweet orange leaf disease-predicting\nautomated systems have already been developed using different image-processing\ntechniques. This comprehensive literature review is systematically based on\nleaf disease and machine learning methodologies applied to the detection of\ndamaged leaves via image classification. The benefits and limitations of\ndifferent machine learning models, including Vision Transformer (ViT), Neural\nNetwork (CNN), CNN with SoftMax and RBF SVM, Hybrid CNN-SVM, HLB-ConvMLP,\nEfficientNet-b0, YOLOv5, YOLOv7, Convolutional, Deep CNN. These machine\nlearning models tested on various datasets and detected the disease. This\ncomprehensive review study related to leaf disease compares the performance of\nthe models; those models' accuracy, precision, recall, etc., were used in the\nsubsisting studies",
            "author": [
                "Yousuf Rayhan Emon",
                "Md Golam Rabbani",
                "Dr. Md. Taimur Ahad",
                "Faruk Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01756v1",
                "http://arxiv.org/pdf/2312.01756v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02239v1",
            "title": "Model-based Deep Learning for Beam Prediction based on a Channel Chart",
            "updated": "2023-12-04T09:31:17Z",
            "published": "2023-12-04T09:31:17Z",
            "summary": "Channel charting builds a map of the radio environment in an unsupervised\nway. The obtained chart locations can be seen as low-dimensional compressed\nversions of channel state information that can be used for a wide variety of\napplications, including beam prediction. In non-standalone or cell-free\nsystems, chart locations computed at a given base station can be transmitted to\nseveral other base stations (possibly operating at different frequency bands)\nfor them to predict which beams to use. This potentially yields a dramatic\nreduction of the overhead due to channel estimation or beam management, since\nonly the base station performing charting requires channel state information,\nthe others directly predicting the beam from the chart location. In this paper,\nadvanced model-based neural network architectures are proposed for both channel\ncharting and beam prediction. The proposed methods are assessed on realistic\nsynthetic channels, yielding promising results.",
            "author": [
                "Taha Yassine",
                "Baptiste Chatelier",
                "Vincent Corlay",
                "Matthieu Crussi\u00e8re",
                "Stephane Paquelet",
                "Olav Tirkkonen",
                "Luc Le Magoarou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02239v1",
                "http://arxiv.org/pdf/2312.02239v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01751v1",
            "title": "Joint Task Partitioning and Parallel Scheduling in Device-Assisted\n  Mobile Edge Networks",
            "updated": "2023-12-04T09:22:42Z",
            "published": "2023-12-04T09:22:42Z",
            "summary": "With the development of the Internet of Things (IoT), certain IoT devices\nhave the capability to not only accomplish their own tasks but also\nsimultaneously assist other resource-constrained devices. Therefore, this paper\nconsiders a device-assisted mobile edge computing system that leverages\nauxiliary IoT devices to alleviate the computational burden on the edge\ncomputing server and enhance the overall system performance. In this study,\ncomputationally intensive tasks are decomposed into multiple partitions, and\neach task partition can be processed in parallel on an IoT device or the edge\nserver. The objective of this research is to develop an efficient online\nalgorithm that addresses the joint optimization of task partitioning and\nparallel scheduling under time-varying system states, posing challenges to\nconventional numerical optimization methods. To address these challenges, a\nframework called online task partitioning action and parallel scheduling policy\ngeneration (OTPPS) is proposed, which is based on deep reinforcement learning\n(DRL). Specifically, the framework leverages a deep neural network (DNN) to\nlearn the optimal partitioning action for each task by mapping input states.\nFurthermore, it is demonstrated that the remaining parallel scheduling problem\nexhibits NP-hard complexity when considering a specific task partitioning\naction. To address this subproblem, a fair and delay-minimized task scheduling\n(FDMTS) algorithm is designed. Extensive evaluation results demonstrate that\nOTPPS achieves near-optimal average delay performance and consistently high\nfairness levels in various environmental states compared to other baseline\nschemes.",
            "author": [
                "Yang Li",
                "Xinlei Ge",
                "Bo Lei",
                "Xing Zhang",
                "Wenbo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01751v1",
                "http://arxiv.org/pdf/2312.01751v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01748v1",
            "title": "Deep CNN for Coherent Seismic Noise Removal: A Perspective",
            "updated": "2023-12-04T09:11:06Z",
            "published": "2023-12-04T09:11:06Z",
            "summary": "Seismic denoising is an important processing step before subsequent imaging\nand interpretation, which consumes a significant amount of time, whether it is\nfor Quality control or for the associated computations. We present results of\nour work in training convolutional neural networks for denoising seismic data,\nspecifically attenuation of surface related multiples and removal of overlap of\nshot energies during simultaneous-shooting survey. The proposed methodology is\nbeing explored not only for its ability to minimize human involvement but also\nbecause of the trained filter's ability to accelerate the process, hence,\nreduce processing time.",
            "author": [
                "Rohit Shrivastava",
                "Ashish Asgekar",
                "Evert Kramer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01748v1",
                "http://arxiv.org/pdf/2312.01748v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01744v1",
            "title": "SEFGAN: Harvesting the Power of Normalizing Flows and GANs for Efficient\n  High-Quality Speech Enhancement",
            "updated": "2023-12-04T09:10:08Z",
            "published": "2023-12-04T09:10:08Z",
            "summary": "This paper proposes SEFGAN, a Deep Neural Network (DNN) combining maximum\nlikelihood training and Generative Adversarial Networks (GANs) for efficient\nspeech enhancement (SE). For this, a DNN is trained to synthesize the enhanced\nspeech conditioned on noisy speech using a Normalizing Flow (NF) as generator\nin a GAN framework. While the combination of likelihood models and GANs is not\ntrivial, SEFGAN demonstrates that a hybrid adversarial and maximum likelihood\ntraining approach enables the model to maintain high quality audio generation\nand log-likelihood estimation. Our experiments indicate that this approach\nstrongly outperforms the baseline NF-based model without introducing additional\ncomplexity to the enhancement network. A comparison using computational metrics\nand a listening experiment reveals that SEFGAN is competitive with other\nstate-of-the-art models.",
            "author": [
                "Martin Strauss",
                "Nicola Pia",
                "Nagashree K. S. Rao",
                "Bernd Edler"
            ],
            "link": [
                "http://dx.doi.org/10.1109/WASPAA58266.2023.10248144",
                "http://arxiv.org/abs/2312.01744v1",
                "http://arxiv.org/pdf/2312.01744v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01742v1",
            "title": "Fully Spiking Denoising Diffusion Implicit Models",
            "updated": "2023-12-04T09:07:09Z",
            "published": "2023-12-04T09:07:09Z",
            "summary": "Spiking neural networks (SNNs) have garnered considerable attention owing to\ntheir ability to run on neuromorphic devices with super-high speeds and\nremarkable energy efficiencies. SNNs can be used in conventional neural\nnetwork-based time- and energy-consuming applications. However, research on\ngenerative models within SNNs remains limited, despite their advantages. In\nparticular, diffusion models are a powerful class of generative models, whose\nimage generation quality surpass that of the other generative models, such as\nGANs. However, diffusion models are characterized by high computational costs\nand long inference times owing to their iterative denoising feature. Therefore,\nwe propose a novel approach fully spiking denoising diffusion implicit model\n(FSDDIM) to construct a diffusion model within SNNs and leverage the high speed\nand low energy consumption features of SNNs via synaptic current learning\n(SCL). SCL fills the gap in that diffusion models use a neural network to\nestimate real-valued parameters of a predefined probabilistic distribution,\nwhereas SNNs output binary spike trains. The SCL enables us to complete the\nentire generative process of diffusion models exclusively using SNNs. We\ndemonstrate that the proposed method outperforms the state-of-the-art fully\nspiking generative model.",
            "author": [
                "Ryo Watanabe",
                "Yusuke Mukuta",
                "Tatsuya Harada"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01742v1",
                "http://arxiv.org/pdf/2312.01742v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01740v1",
            "title": "MobileUtr: Revisiting the relationship between light-weight CNN and\n  Transformer for efficient medical image segmentation",
            "updated": "2023-12-04T09:04:05Z",
            "published": "2023-12-04T09:04:05Z",
            "summary": "Due to the scarcity and specific imaging characteristics in medical images,\nlight-weighting Vision Transformers (ViTs) for efficient medical image\nsegmentation is a significant challenge, and current studies have not yet paid\nattention to this issue. This work revisits the relationship between CNNs and\nTransformers in lightweight universal networks for medical image segmentation,\naiming to integrate the advantages of both worlds at the infrastructure design\nlevel. In order to leverage the inductive bias inherent in CNNs, we abstract a\nTransformer-like lightweight CNNs block (ConvUtr) as the patch embeddings of\nViTs, feeding Transformer with denoised, non-redundant and highly condensed\nsemantic information. Moreover, an adaptive Local-Global-Local (LGL) block is\nintroduced to facilitate efficient local-to-global information flow exchange,\nmaximizing Transformer's global context information extraction capabilities.\nFinally, we build an efficient medical image segmentation model (MobileUtr)\nbased on CNN and Transformer. Extensive experiments on five public medical\nimage datasets with three different modalities demonstrate the superiority of\nMobileUtr over the state-of-the-art methods, while boasting lighter weights and\nlower computational cost. Code is available at\nhttps://github.com/FengheTan9/MobileUtr.",
            "author": [
                "Fenghe Tang",
                "Bingkun Nian",
                "Jianrui Ding",
                "Quan Quan",
                "Jie Yang",
                "Wei Liu",
                "S. Kevin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01740v1",
                "http://arxiv.org/pdf/2312.01740v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "I.4.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01739v1",
            "title": "Divide-and-Conquer Strategy for Large-Scale Dynamic Bayesian Network\n  Structure Learning",
            "updated": "2023-12-04T09:03:06Z",
            "published": "2023-12-04T09:03:06Z",
            "summary": "Dynamic Bayesian Networks (DBNs), renowned for their interpretability, have\nbecome increasingly vital in representing complex stochastic processes in\nvarious domains such as gene expression analysis, healthcare, and traffic\nprediction. Structure learning of DBNs from data is challenging, particularly\nfor datasets with thousands of variables. Most current algorithms for DBN\nstructure learning are adaptations from those used in static Bayesian Networks\n(BNs), and are typically focused on small-scale problems. In order to solve\nlarge-scale problems while taking full advantage of existing algorithms, this\npaper introduces a novel divide-and-conquer strategy, originally developed for\nstatic BNs, and adapts it for large-scale DBN structure learning. In this work,\nwe specifically concentrate on 2 Time-sliced Bayesian Networks (2-TBNs), a\nspecial class of DBNs. Furthermore, we leverage the prior knowledge of 2-TBNs\nto enhance the performance of the strategy we introduce. Our approach\nsignificantly improves the scalability and accuracy of 2-TBN structure\nlearning. Experimental results demonstrate the effectiveness of our method,\nshowing substantial improvements over existing algorithms in both computational\nefficiency and structure learning accuracy. On problem instances with more than\n1,000 variables, our approach improves two accuracy metrics by 74.45% and\n110.94% on average , respectively, while reducing runtime by 93.65% on average.",
            "author": [
                "Hui Ouyang",
                "Cheng Chen",
                "Ke Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01739v1",
                "http://arxiv.org/pdf/2312.01739v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01735v1",
            "title": "Weighted Q-learning for optimal dynamic treatment regimes with MNAR\n  coavriates",
            "updated": "2023-12-04T08:56:11Z",
            "published": "2023-12-04T08:56:11Z",
            "summary": "Dynamic treatment regimes (DTRs) formalize medical decision-making as a\nsequence of rules for different stages, mapping patient-level information to\nrecommended treatments. In practice, estimating an optimal DTR using\nobservational data from electronic medical record (EMR) databases can be\ncomplicated by covariates that are missing not at random (MNAR) due to\ninformative monitoring of patients. Since complete case analysis can result in\nconsistent estimation of outcome model parameters under the assumption of\noutcome-independent missingness \\citep{Yang_Wang_Ding_2019}, Q-learning is a\nnatural approach to accommodating MNAR covariates. However, the backward\ninduction algorithm used in Q-learning can introduce complications, as MNAR\ncovariates at later stages can result in MNAR pseudo-outcomes at earlier\nstages, leading to suboptimal DTRs, even if outcome variables are fully\nobserved. To address this unique missing data problem in DTR settings, we\npropose two weighted Q-learning approaches where inverse probability weights\nfor missingness of the pseudo-outcomes are obtained through estimating\nequations with valid nonresponse instrumental variables or sensitivity\nanalysis. Asymptotic properties of the weighted Q-learning estimators are\nderived and the finite-sample performance of the proposed methods is evaluated\nand compared with alternative methods through extensive simulation studies.\nUsing EMR data from the Medical Information Mart for Intensive Care database,\nwe apply the proposed methods to investigate the optimal fluid strategy for\nsepsis patients in intensive care units.",
            "author": [
                "Jian Sun",
                "Li Su",
                "Bo Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01735v1",
                "http://arxiv.org/pdf/2312.01735v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01734v1",
            "title": "Effective Adapter for Face Recognition in the Wild",
            "updated": "2023-12-04T08:55:46Z",
            "published": "2023-12-04T08:55:46Z",
            "summary": "In this paper, we tackle the challenge of face recognition in the wild, where\nimages often suffer from low quality and real-world distortions. Traditional\nheuristic approaches-either training models directly on these degraded images\nor their enhanced counterparts using face restoration techniques-have proven\nineffective, primarily due to the degradation of facial features and the\ndiscrepancy in image domains. To overcome these issues, we propose an effective\nadapter for augmenting existing face recognition models trained on high-quality\nfacial datasets. The key of our adapter is to process both the unrefined and\nthe enhanced images by two similar structures where one is fixed and the other\ntrainable. Such design can confer two benefits. First, the dual-input system\nminimizes the domain gap while providing varied perspectives for the face\nrecognition model, where the enhanced image can be regarded as a complex\nnon-linear transformation of the original one by the restoration model. Second,\nboth two similar structures can be initialized by the pre-trained models\nwithout dropping the past knowledge. The extensive experiments in zero-shot\nsettings show the effectiveness of our method by surpassing baselines of about\n3%, 4%, and 7% in three datasets. Our code will be publicly available at\nhttps://github.com/liuyunhaozz/FaceAdapter/.",
            "author": [
                "Yunhao Liu",
                "Lu Qi",
                "Yu-Ju Tsai",
                "Xiangtai Li",
                "Kelvin C. K. Chan",
                "Ming-Hsuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01734v1",
                "http://arxiv.org/pdf/2312.01734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01730v1",
            "title": "Set-valued stochastic integrals for convoluted L\u00e9vy processes",
            "updated": "2023-12-04T08:43:28Z",
            "published": "2023-12-04T08:43:28Z",
            "summary": "In this paper we study set-valued Volterra-type stochastic integrals driven\nby L\\'{e}vy processes. Upon extending the classical definitions of set-valued\nstochastic integral functionals to convoluted integrals with square-integrable\nkernels, set-valued convoluted stochastic integrals are defined by taking the\nclosed decomposable hull of the integral functionals for generic time. We show\nthat, aside from well-established results for set-valued It\\^{o} integrals,\nwhile set-valued stochastic integrals with respect to a finite-variation\nPoisson random measure are guaranteed to be integrably bounded for bounded\nintegrands, this is not true when the random measure is of infinite variation.\nFor indefinite integrals, we prove that it is a mutual effect of kernel\nsingularity and jumps that the set-valued convoluted integrals are possibly\nexplosive and take extended vector values. These results have some important\nimplications on how set-valued fractional dynamical systems are to be\nconstructed in general. Two classes of set-monotone processes are studied for\npractical interests in economic and financial modeling.",
            "author": [
                "Weixuan Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01730v1",
                "http://arxiv.org/pdf/2312.01730v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "q-fin.MF",
                "28B20, 60G22, 60G57"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01727v2",
            "title": "Deep learning acceleration of iterative model-based light fluence\n  correction for photoacoustic tomography",
            "updated": "2023-12-05T10:15:45Z",
            "published": "2023-12-04T08:34:19Z",
            "summary": "Photoacoustic tomography (PAT) is a promising imaging technique that can\nvisualize the distribution of chromophores within biological tissue. However,\nthe accuracy of PAT imaging is compromised by light fluence (LF), which hinders\nthe quantification of light absorbers. Currently, model-based iterative methods\nare used for LF correction, but they require significant computational\nresources due to repeated LF estimation based on differential light transport\nmodels. To improve LF correction efficiency, we propose to use Fourier neural\noperator (FNO), a neural network specially designed for solving differential\nequations, to learn the forward projection of light transport in PAT. Trained\nusing paired finite-element-based LF simulation data, our FNO model replaces\nthe traditional computational heavy LF estimator during iterative correction,\nsuch that the correction procedure is significantly accelerated. Simulation and\nexperimental results demonstrate that our method achieves comparable LF\ncorrection quality to traditional iterative methods while reducing the\ncorrection time by over 30 times.",
            "author": [
                "Zhaoyong Liang",
                "Shuangyang Zhang",
                "Zhichao Liang",
                "Zhongxin Mo",
                "Xiaoming Zhang",
                "Yutian Zhong",
                "Wufan Chen",
                "Li Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01727v2",
                "http://arxiv.org/pdf/2312.01727v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01726v1",
            "title": "Simultaneous Alignment and Surface Regression Using Hybrid 2D-3D\n  Networks for 3D Coherent Layer Segmentation of Retinal OCT Images with Full\n  and Sparse Annotations",
            "updated": "2023-12-04T08:32:31Z",
            "published": "2023-12-04T08:32:31Z",
            "summary": "Layer segmentation is important to quantitative analysis of retinal optical\ncoherence tomography (OCT). Recently, deep learning based methods have been\ndeveloped to automate this task and yield remarkable performance. However, due\nto the large spatial gap and potential mismatch between the B-scans of an OCT\nvolume, all of them were based on 2D segmentation of individual B-scans, which\nmay lose the continuity and diagnostic information of the retinal layers in 3D\nspace. Besides, most of these methods required dense annotation of the OCT\nvolumes, which is labor-intensive and expertise-demanding. This work presents a\nnovel framework based on hybrid 2D-3D convolutional neural networks (CNNs) to\nobtain continuous 3D retinal layer surfaces from OCT volumes, which works well\nwith both full and sparse annotations. The 2D features of individual B-scans\nare extracted by an encoder consisting of 2D convolutions. These 2D features\nare then used to produce the alignment displacement vectors and layer\nsegmentation by two 3D decoders coupled via a spatial transformer module. Two\nlosses are proposed to utilize the retinal layers' natural property of being\nsmooth for B-scan alignment and layer segmentation, respectively, and are the\nkey to the semi-supervised learning with sparse annotation. The entire\nframework is trained end-to-end. To the best of our knowledge, this is the\nfirst work that attempts 3D retinal layer segmentation in volumetric OCT images\nbased on CNNs. Experiments on a synthetic dataset and three public clinical\ndatasets show that our framework can effectively align the B-scans for\npotential motion correction, and achieves superior performance to\nstate-of-the-art 2D deep learning methods in terms of both layer segmentation\naccuracy and cross-B-scan 3D continuity in both fully and semi-supervised\nsettings, thus offering more clinical values than previous works.",
            "author": [
                "Hong Liu",
                "Dong Wei",
                "Donghuan Lu",
                "Xiaoying Tang",
                "Liansheng Wang",
                "Yefeng Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01726v1",
                "http://arxiv.org/pdf/2312.01726v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01725v1",
            "title": "StableVITON: Learning Semantic Correspondence with Latent Diffusion\n  Model for Virtual Try-On",
            "updated": "2023-12-04T08:27:59Z",
            "published": "2023-12-04T08:27:59Z",
            "summary": "Given a clothing image and a person image, an image-based virtual try-on aims\nto generate a customized image that appears natural and accurately reflects the\ncharacteristics of the clothing image. In this work, we aim to expand the\napplicability of the pre-trained diffusion model so that it can be utilized\nindependently for the virtual try-on task.The main challenge is to preserve the\nclothing details while effectively utilizing the robust generative capability\nof the pre-trained model. In order to tackle these issues, we propose\nStableVITON, learning the semantic correspondence between the clothing and the\nhuman body within the latent space of the pre-trained diffusion model in an\nend-to-end manner. Our proposed zero cross-attention blocks not only preserve\nthe clothing details by learning the semantic correspondence but also generate\nhigh-fidelity images by utilizing the inherent knowledge of the pre-trained\nmodel in the warping process. Through our proposed novel attention total\nvariation loss and applying augmentation, we achieve the sharp attention map,\nresulting in a more precise representation of clothing details. StableVITON\noutperforms the baselines in qualitative and quantitative evaluation, showing\npromising quality in arbitrary person images. Our code is available at\nhttps://github.com/rlawjdghek/StableVITON.",
            "author": [
                "Jeongho Kim",
                "Gyojung Gu",
                "Minho Park",
                "Sunghyun Park",
                "Jaegul Choo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01725v1",
                "http://arxiv.org/pdf/2312.01725v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01720v1",
            "title": "Secure-ISAC: Secure V2X Communication: An Integrated Sensing and\n  Communication Perspective",
            "updated": "2023-12-04T08:21:04Z",
            "published": "2023-12-04T08:21:04Z",
            "summary": "In Vehicle-to-Everything (V2X) systems, reliable and secure information\nexchange plays a pivotal role in road safety and traffic management. Due to the\nopen nature of the wireless medium and the constant or intermittent mobility of\nvehicles, the security of transmissions in V2X is more challenging compared to\ntraditional wireless networks. Physical layer security (PLS) leverages the\ninherent randomness of wireless communication channels to ensure the\nconfidentiality and security of information transmission. Current PLS schemes\nin integrated communications and sensing (ISAC) enabled V2X systems is to\nutilize communication interference to significantly impact the eavesdropping\nchannel more than the legitimate channel. However, in an ISAC-enabled V2X\nsystem, it is crucial to prioritize and address the issue of interference\ncoupling as it significantly impacts the confidentiality and security of\ninformation exchange. This goes beyond simply relying on the communication\ninterference. Until now, no discussions or studies on integrating security with\nISAC (Seucue-ISAC) in ISAC-enabled V2X systems, specifically regarding the\nexploitation of sensing interference or coupling interference. In this article,\nwe provide a comprehensive review on PLS metrics and security threats\nencountered in V2X communication. And then, we discuss and analyze four popular\nPLS techniques and the main challenges associated with their implementation in\nISAC-enabled V2X systems. Finally, we share our vision for PLS studies in\nISAC-based V2X systems to promote Secure-ISAC.",
            "author": [
                "Kan Yu",
                "Zhiyong Feng",
                "Dong Li",
                "Jiguo Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01720v1",
                "http://arxiv.org/pdf/2312.01720v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01714v1",
            "title": "Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large\n  Language Models",
            "updated": "2023-12-04T08:07:21Z",
            "published": "2023-12-04T08:07:21Z",
            "summary": "The advancement of Large Language Models(LLMs) has brought substantial\nattention to the Chain of Thought(CoT) approach, primarily due to its ability\nto enhance the capability of LLMs on tasks requiring complex reasoning.\nMoreover, the significance of CoT approaches extends to the application of LLMs\nfor multi-modal tasks, such as multi-modal question answering. However, the\nselection of optimal CoT demonstration examples in multi-modal reasoning for\nLLMs remains less explored for LLMs due to the inherent complexity of\nmulti-modal examples. In this paper, we introduce a novel approach that\naddresses this challenge by using retrieval mechanisms to dynamically and\nautomatically select demonstration examples based on cross-modal similarities.\nThis method aims to refine the CoT reasoning process in multi-modal scenarios\nvia informing LLMs with more relevant and informative examples. Furthermore, we\nemploy a stratified sampling method categorising demonstration examples into\ngroups based on their types and retrieving examples from different groups\nrespectively to promote the diversity of demonstration examples. Through a\nseries of experiments, we demonstrate that our approach significantly improves\nthe performance of LLMs, achieving state-of-the-art results in multi-modal\nreasoning tasks. Specifically, our methods demonstrate significant advancements\non the ScienceQA dataset. While our method based on ChatGPT outperforms the\nChameleon(ChatGPT) by 2.74% with an accuracy of 82.67%, the GPT4-based approach\nsurpasses the Chameleon(GPT-4) by 0.89%, achieving 87.43% on accuracy under the\nsame setting. Moreover, our best performing show a 6.05% increase over\nChameleon for ChatGPT-based models and a 4.57% increase for GPT-4-based models.",
            "author": [
                "Bingshuai Liu",
                "Chenyang Lyu",
                "Zijun Min",
                "Zhanyu Wang",
                "Jinsong Su",
                "Longyue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01714v1",
                "http://arxiv.org/pdf/2312.01714v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02236v1",
            "title": "Rethinking Adversarial Training with Neural Tangent Kernel",
            "updated": "2023-12-04T08:06:59Z",
            "published": "2023-12-04T08:06:59Z",
            "summary": "Adversarial training (AT) is an important and attractive topic in deep\nlearning security, exhibiting mysteries and odd properties. Recent studies of\nneural network training dynamics based on Neural Tangent Kernel (NTK) make it\npossible to reacquaint AT and deeply analyze its properties. In this paper, we\nperform an in-depth investigation of AT process and properties with NTK, such\nas NTK evolution. We uncover three new findings that are missed in previous\nworks. First, we disclose the impact of data normalization on AT and the\nimportance of unbiased estimators in batch normalization layers. Second, we\nexperimentally explore the kernel dynamics and propose more time-saving AT\nmethods. Third, we study the spectrum feature inside the kernel to address the\ncatastrophic overfitting problem. To the best of our knowledge, it is the first\nwork leveraging the observations of kernel dynamics to improve existing AT\nmethods.",
            "author": [
                "Guanlin Li",
                "Han Qiu",
                "Shangwei Guo",
                "Jiwei Li",
                "Tianwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02236v1",
                "http://arxiv.org/pdf/2312.02236v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02235v1",
            "title": "GenEM: Physics-Informed Generative Cryo-Electron Microscopy",
            "updated": "2023-12-04T07:52:56Z",
            "published": "2023-12-04T07:52:56Z",
            "summary": "In the past decade, deep conditional generative models have revolutionized\nthe generation of realistic images, extending their application from\nentertainment to scientific domains. Single-particle cryo-electron microscopy\n(cryo-EM) is crucial in resolving near-atomic resolution 3D structures of\nproteins, such as the SARS-COV-2 spike protein. To achieve high-resolution\nreconstruction, AI models for particle picking and pose estimation have been\nadopted. However, their performance is still limited as they lack high-quality\nannotated datasets. To address this, we introduce physics-informed generative\ncryo-electron microscopy (GenEM), which for the first time integrates\nphysical-based cryo-EM simulation with a generative unpaired noise translation\nto generate physically correct synthetic cryo-EM datasets with realistic\nnoises. Initially, GenEM simulates the cryo-EM imaging process based on a\nvirtual specimen. To generate realistic noises, we leverage an unpaired noise\ntranslation via contrastive learning with a novel mask-guided sampling scheme.\nExtensive experiments show that GenEM is capable of generating realistic\ncryo-EM images. The generated dataset can further enhance particle picking and\npose estimation models, eventually improving the reconstruction resolution. We\nwill release our code and annotated synthetic datasets.",
            "author": [
                "Jiakai Zhang",
                "Qihe Chen",
                "Yan Zeng",
                "Wenyuan Gao",
                "Xuming He",
                "Zhijie Liu",
                "Jingyi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02235v1",
                "http://arxiv.org/pdf/2312.02235v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01708v1",
            "title": "A global existence result for weakly coupled two-phase poromechanics",
            "updated": "2023-12-04T07:52:12Z",
            "published": "2023-12-04T07:52:12Z",
            "summary": "Multiphase poromechanics describes the evolution of multiphase flow in\ndeformable porous media. Mathematical models for such multiphysics system are\ninheritely nonlinear, potentially degenerate and fully coupled systems of\npartial differential equations. In this work, we present a thermodynamically\nconsistent multiphase poromechanics model falling into the category of Biot\nequations and obeying to a generalized gradient flow structure. It involves\ncapillarity effects, degenerate relative permeabilities, and gravity effects.\nIn addition to established models it introduces a Lagrange multiplier\nassociated to a bound constraint on the effective porosity in particular\nensuring its positivity. We establish existence of global weak solutions under\nthe assumption of a weak coupling strength, implicitly utilizing the gradient\nflow structure, as well as regularization, a Faedo-Galerkin approach and\ncompactness arguments. This comprises the first global existence result for\nmultiphase poromechanics accounting for degeneracies that are consistent with\nthe multiphase nature of the flow.",
            "author": [
                "Jakub Wiktor Both",
                "Cl\u00e9ment Canc\u00e8s"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01708v1",
                "http://arxiv.org/pdf/2312.01708v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01701v1",
            "title": "Mitigating Fine-Grained Hallucination by Fine-Tuning Large\n  Vision-Language Models with Caption Rewrites",
            "updated": "2023-12-04T07:43:02Z",
            "published": "2023-12-04T07:43:02Z",
            "summary": "Large language models (LLMs) have shown remarkable performance in natural\nlanguage processing (NLP) tasks. To comprehend and execute diverse human\ninstructions over image data, instruction-tuned large vision-language models\n(LVLMs) have been introduced. However, LVLMs may suffer from different types of\nobject hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained\nobject hallucinations only (i.e., generated objects non-existent in the input\nimage). The fine-grained object attributes and behaviors non-existent in the\nimage may still be generated but not measured by the current evaluation\nmethods. In this paper, we thus focus on reducing fine-grained hallucinations\nof LVLMs. We propose \\textit{ReCaption}, a framework that consists of two\ncomponents: rewriting captions using ChatGPT and fine-tuning the\ninstruction-tuned LVLMs on the rewritten captions. We also propose a\nfine-grained probing-based evaluation method named \\textit{Fine-Grained Object\nHallucination Evaluation} (\\textit{FGHE}). Our experiment results demonstrate\nthat ReCaption effectively reduces fine-grained object hallucination for\ndifferent LVLM options and improves their text generation quality. The code can\nbe found at https://github.com/Anonymousanoy/FOHE.",
            "author": [
                "Lei Wang",
                "Jiabang He",
                "Shenshen Li",
                "Ning Liu",
                "Ee-Peng Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01701v1",
                "http://arxiv.org/pdf/2312.01701v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01700v1",
            "title": "Data Management For Large Language Models: A Survey",
            "updated": "2023-12-04T07:42:16Z",
            "published": "2023-12-04T07:42:16Z",
            "summary": "Data plays a fundamental role in the training of Large Language Models\n(LLMs). Effective data management, particularly in the formulation of a\nwell-suited training dataset, holds significance for enhancing model\nperformance and improving training efficiency during pretraining and supervised\nfine-tuning phases. Despite the considerable importance of data management, the\ncurrent research community still falls short in providing a systematic analysis\nof the rationale behind management strategy selection, its consequential\neffects, methodologies for evaluating curated datasets, and the ongoing pursuit\nof improved strategies. Consequently, the exploration of data management has\nattracted more and more attention among the research community. This survey\nprovides a comprehensive overview of current research in data management within\nboth the pretraining and supervised fine-tuning stages of LLMs, covering\nvarious noteworthy aspects of data management strategy design: data quantity,\ndata quality, domain/task composition, etc. Looking toward the future, we\nextrapolate existing challenges and outline promising directions for\ndevelopment in this field. Therefore, this survey serves as a guiding resource\nfor practitioners aspiring to construct powerful LLMs through effective data\nmanagement practices. The collection of the latest papers is available at\nhttps://github.com/ZigeW/data_management_LLM.",
            "author": [
                "Zige Wang",
                "Wanjun Zhong",
                "Yufei Wang",
                "Qi Zhu",
                "Fei Mi",
                "Baojun Wang",
                "Lifeng Shang",
                "Xin Jiang",
                "Qun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01700v1",
                "http://arxiv.org/pdf/2312.01700v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01697v2",
            "title": "Hulk: A Universal Knowledge Translator for Human-Centric Tasks",
            "updated": "2023-12-05T05:37:25Z",
            "published": "2023-12-04T07:36:04Z",
            "summary": "Human-centric perception tasks, e.g., human mesh recovery, pedestrian\ndetection, skeleton-based action recognition, and pose estimation, have wide\nindustrial applications, such as metaverse and sports analysis. There is a\nrecent surge to develop human-centric foundation models that can benefit a\nbroad range of human-centric perception tasks. While many human-centric\nfoundation models have achieved success, most of them only excel in 2D vision\ntasks or require extensive fine-tuning for practical deployment in real-world\nscenarios. These limitations severely restrict their usability across various\ndownstream tasks and situations. To tackle these problems, we present Hulk, the\nfirst multimodal human-centric generalist model, capable of addressing most of\nthe mainstream tasks simultaneously without task-specific finetuning, covering\n2D vision, 3D vision, skeleton-based, and vision-language tasks. The key to\nachieving this is condensing various task-specific heads into two general\nheads, one for discrete representations, e.g., languages, and the other for\ncontinuous representations, e.g., location coordinates. The outputs of two\nheads can be further stacked into four distinct input and output modalities.\nThis uniform representation enables Hulk to treat human-centric tasks as\nmodality translation, integrating knowledge across a wide range of tasks. To\nvalidate the effectiveness of our proposed method, we conduct comprehensive\nexperiments on 11 benchmarks across 8 human-centric tasks. Experimental results\nsurpass previous methods substantially, demonstrating the superiority of our\nproposed method. The code will be available on\nhttps://github.com/OpenGVLab/HumanBench.",
            "author": [
                "Yizhou Wang",
                "Yixuan Wu",
                "Shixiang Tang",
                "Weizhen He",
                "Xun Guo",
                "Feng Zhu",
                "Lei Bai",
                "Rui Zhao",
                "Jian Wu",
                "Tong He",
                "Wanli Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01697v2",
                "http://arxiv.org/pdf/2312.01697v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01689v1",
            "title": "Fast and accurate sparse-view CBCT reconstruction using meta-learned\n  neural attenuation field and hash-encoding regularization",
            "updated": "2023-12-04T07:23:44Z",
            "published": "2023-12-04T07:23:44Z",
            "summary": "Cone beam computed tomography (CBCT) is an emerging medical imaging technique\nto visualize the internal anatomical structures of patients. During a CBCT\nscan, several projection images of different angles or views are collectively\nutilized to reconstruct a tomographic image. However, reducing the number of\nprojections in a CBCT scan while preserving the quality of a reconstructed\nimage is challenging due to the nature of an ill-posed inverse problem.\nRecently, a neural attenuation field (NAF) method was proposed by adopting a\nneural radiance field algorithm as a new way for CBCT reconstruction,\ndemonstrating fast and promising results using only 50 views. However,\ndecreasing the number of projections is still preferable to reduce potential\nradiation exposure, and a faster reconstruction time is required considering a\ntypical scan time. In this work, we propose a fast and accurate sparse-view\nCBCT reconstruction (FACT) method to provide better reconstruction quality and\nfaster optimization speed in the minimal number of view acquisitions ($<$ 50\nviews). In the FACT method, we meta-trained a neural network and a hash-encoder\nusing a few scans (= 15), and a new regularization technique is utilized to\nreconstruct the details of an anatomical structure. In conclusion, we have\nshown that the FACT method produced better, and faster reconstruction results\nover the other conventional algorithms based on CBCT scans of different body\nparts (chest, head, and abdomen) and CT vendors (Siemens, Phillips, and GE).",
            "author": [
                "Heejun Shin",
                "Taehee Kim",
                "Jongho Lee",
                "Seyoung Chun",
                "Seungryung Cho",
                "Dongmyung Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01689v1",
                "http://arxiv.org/pdf/2312.01689v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01682v1",
            "title": "ResEnsemble-DDPM: Residual Denoising Diffusion Probabilistic Models for\n  Ensemble Learning",
            "updated": "2023-12-04T07:14:20Z",
            "published": "2023-12-04T07:14:20Z",
            "summary": "Nowadays, denoising diffusion probabilistic models have been adapted for many\nimage segmentation tasks. However, existing end-to-end models have already\ndemonstrated remarkable capabilities. Rather than using denoising diffusion\nprobabilistic models alone, integrating the abilities of both denoising\ndiffusion probabilistic models and existing end-to-end models can better\nimprove the performance of image segmentation. Based on this, we implicitly\nintroduce residual term into the diffusion process and propose\nResEnsemble-DDPM, which seamlessly integrates the diffusion model and the\nend-to-end model through ensemble learning. The output distributions of these\ntwo models are strictly symmetric with respect to the ground truth\ndistribution, allowing us to integrate the two models by reducing the residual\nterm. Experimental results demonstrate that our ResEnsemble-DDPM can further\nimprove the capabilities of existing models. Furthermore, its ensemble learning\nstrategy can be generalized to other downstream tasks in image generation and\nget strong competitiveness.",
            "author": [
                "Shi Zhenning",
                "Dong Changsheng",
                "Xie Xueshuo",
                "Pan Bin",
                "He Along",
                "Li Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01682v1",
                "http://arxiv.org/pdf/2312.01682v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01679v1",
            "title": "Adversarial Medical Image with Hierarchical Feature Hiding",
            "updated": "2023-12-04T07:04:20Z",
            "published": "2023-12-04T07:04:20Z",
            "summary": "Deep learning based methods for medical images can be easily compromised by\nadversarial examples (AEs), posing a great security flaw in clinical\ndecision-making. It has been discovered that conventional adversarial attacks\nlike PGD which optimize the classification logits, are easy to distinguish in\nthe feature space, resulting in accurate reactive defenses. To better\nunderstand this phenomenon and reassess the reliability of the reactive\ndefenses for medical AEs, we thoroughly investigate the characteristic of\nconventional medical AEs. Specifically, we first theoretically prove that\nconventional adversarial attacks change the outputs by continuously optimizing\nvulnerable features in a fixed direction, thereby leading to outlier\nrepresentations in the feature space. Then, a stress test is conducted to\nreveal the vulnerability of medical images, by comparing with natural images.\nInterestingly, this vulnerability is a double-edged sword, which can be\nexploited to hide AEs. We then propose a simple-yet-effective hierarchical\nfeature constraint (HFC), a novel add-on to conventional white-box attacks,\nwhich assists to hide the adversarial feature in the target feature\ndistribution. The proposed method is evaluated on three medical datasets, both\n2D and 3D, with different modalities. The experimental results demonstrate the\nsuperiority of HFC, \\emph{i.e.,} it bypasses an array of state-of-the-art\nadversarial medical AE detectors more efficiently than competing adaptive\nattacks, which reveals the deficiencies of medical reactive defense and allows\nto develop more robust defenses in future.",
            "author": [
                "Qingsong Yao",
                "Zecheng He",
                "Yuexiang Li",
                "Yi Lin",
                "Kai Ma",
                "Yefeng Zheng",
                "S. Kevin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01679v1",
                "http://arxiv.org/pdf/2312.01679v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01678v2",
            "title": "Jellyfish: A Large Language Model for Data Preprocessing",
            "updated": "2023-12-05T18:02:46Z",
            "published": "2023-12-04T07:01:54Z",
            "summary": "In this paper, we present Jellyfish, an open-source LLM as a universal task\nsolver for DP. Built on the Llama 2 13B model, Jellyfish is instruction-tuned\nwith the datasets of several typical DP tasks including error detection, data\nimputation, schema matching, and entity matching, and delivers generalizability\nto other tasks. Remarkably, Jellyfish can operate on a local, single, and\nlow-priced GPU with its 13 billion parameters, ensuring data security and\nenabling further tuning. Its proficiency in understanding natural language\nallows users to manually craft instructions for DP tasks. Unlike many existing\nmethods that heavily rely on prior knowledge, Jellyfish acquires domain\nknowledge during its tuning process and integrates optional knowledge injection\nduring inference. A distinctive feature of Jellyfish is its interpreter, which\nelucidates its output decisions. To construct Jellyfish, we develop a series of\npre-tuning and DP-tuning techniques. Jellyfish is equipped with an instance\nserializer, which automatically translates raw data into model prompts, and a\nknowledge injector, which optionally introduces task- and dataset-specific\nknowledge to enhance DP performance. Our evaluation of Jellyfish, using a range\nof real datasets, shows its competitiveness compared to state-of-the-art\nmethods and its strong generalizability to unseen tasks. Jellyfish's\nperformance rivals that of GPT series models, and its interpreter offers\nenhanced reasoning capabilities compared to GPT-3.5. Furthermore, our\nevaluation highlights the effectiveness of the techniques employed in\nconstructing Jellyfish. Our model is available at Hugging Face:\nhttps://huggingface.co/NECOUDBFM/Jellyfish .",
            "author": [
                "Haochen Zhang",
                "Yuyang Dong",
                "Chuan Xiao",
                "Masafumi Oyamada"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01678v2",
                "http://arxiv.org/pdf/2312.01678v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01677v2",
            "title": "Multi-task Image Restoration Guided By Robust DINO Features",
            "updated": "2023-12-05T17:46:12Z",
            "published": "2023-12-04T06:59:55Z",
            "summary": "Multi-task image restoration has gained significant interest due to its\ninherent versatility and efficiency compared to its single-task counterpart.\nDespite its potential, performance degradation is observed with an increase in\nthe number of tasks, primarily attributed to the distinct nature of each\nrestoration task. Addressing this challenge, we introduce\n\\mbox{\\textbf{DINO-IR}}, a novel multi-task image restoration approach\nleveraging robust features extracted from DINOv2. Our empirical analysis shows\nthat while shallow features of DINOv2 capture rich low-level image\ncharacteristics, the deep features ensure a robust semantic representation\ninsensitive to degradations while preserving high-frequency contour details.\nBuilding on these features, we devise specialized components, including\nmulti-layer semantic fusion module, DINO-Restore adaption and fusion module,\nand DINO perception contrastive loss, to integrate DINOv2 features into the\nrestoration paradigm. Equipped with the aforementioned components, our DINO-IR\nperforms favorably against existing multi-task image restoration approaches in\nvarious tasks by a large margin, indicating the superiority and necessity of\nreinforcing the robust features for multi-task image restoration.",
            "author": [
                "Xin Lin",
                "Chao Ren",
                "Kelvin C. K. Chan",
                "Lu Qi",
                "Jinshan Pan",
                "Ming-Hsuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01677v2",
                "http://arxiv.org/pdf/2312.01677v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01672v1",
            "title": "STADEE: STAtistics-based DEEp Detection of Machine Generated Text",
            "updated": "2023-12-04T06:45:47Z",
            "published": "2023-12-04T06:45:47Z",
            "summary": "We present STADEE, a \\textbf{STA}tistics-based \\textbf{DEE}p detection method\nto identify machine-generated text, addressing the limitations of current\nmethods that rely heavily on fine-tuning pre-trained language models (PLMs).\nSTADEE integrates key statistical text features with a deep classifier,\nfocusing on aspects like token probability and cumulative probability, crucial\nfor handling nucleus sampling. Tested across diverse datasets and scenarios\n(in-domain, out-of-domain, and in-the-wild), STADEE demonstrates superior\nperformance, achieving an 87.05% F1 score in-domain and outperforming both\ntraditional statistical methods and fine-tuned PLMs, especially in\nout-of-domain and in-the-wild settings, highlighting its effectiveness and\ngeneralizability.",
            "author": [
                "Zheng Chen",
                "Huming Liu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-4752-2_60",
                "http://arxiv.org/abs/2312.01672v1",
                "http://arxiv.org/pdf/2312.01672v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02233v1",
            "title": "MedXChat: Bridging CXR Modalities with a Unified Multimodal Large Model",
            "updated": "2023-12-04T06:40:12Z",
            "published": "2023-12-04T06:40:12Z",
            "summary": "Despite the success of Large Language Models (LLMs) in general image tasks, a\ngap persists in the medical field for a multimodal large model adept at\nhandling the nuanced diversity of medical images. Addressing this, we propose\nMedXChat, a unified multimodal large model designed for seamless interactions\nbetween medical assistants and users. MedXChat encompasses three key\nfunctionalities: CXR(Chest X-ray)-to-Report generation, CXR-based visual\nquestion-answering (VQA), and Text-to-CXR synthesis. Our contributions are as\nfollows. Firstly, our model showcases exceptional cross-task adaptability,\ndisplaying adeptness across all three defined tasks and outperforming the\nbenchmark models on the MIMIC dataset in medical multimodal applications.\nSecondly, we introduce an innovative Text-to-CXR synthesis approach that\nutilizes instruction-following capabilities within the Stable Diffusion (SD)\narchitecture. This technique integrates smoothly with the existing model\nframework, requiring no extra parameters, thereby maintaining the SD's\ngenerative strength while also bestowing upon it the capacity to render\nfine-grained medical images with high fidelity. Comprehensive experiments\nvalidate MedXChat's synergistic enhancement across all tasks. Our instruction\ndata and model will be open-sourced.",
            "author": [
                "Ling Yang",
                "Zhanyu Wang",
                "Luping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02233v1",
                "http://arxiv.org/pdf/2312.02233v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02232v1",
            "title": "HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with\n  Diverse Poses",
            "updated": "2023-12-04T06:37:11Z",
            "published": "2023-12-04T06:37:11Z",
            "summary": "We present HumanNeRF-SE, which can synthesize diverse novel pose images with\nsimple input. Previous HumanNeRF studies require large neural networks to fit\nthe human appearance and prior knowledge. Subsequent methods build upon this\napproach with some improvements. Instead, we reconstruct this approach,\ncombining explicit and implicit human representations with both general and\nspecific mapping processes. Our key insight is that explicit shape can filter\nthe information used to fit implicit representation, and frozen general mapping\ncombined with point-specific mapping can effectively avoid overfitting and\nimprove pose generalization performance. Our explicit and implicit human\nrepresent combination architecture is extremely effective. This is reflected in\nour model's ability to synthesize images under arbitrary poses with few-shot\ninput and increase the speed of synthesizing images by 15 times through a\nreduction in computational complexity without using any existing acceleration\nmodules. Compared to the state-of-the-art HumanNeRF studies, HumanNeRF-SE\nachieves better performance with fewer learnable parameters and less training\ntime (see Figure 1).",
            "author": [
                "Caoyuan Ma",
                "Yu-Lun Liu",
                "Zhixiang Wang",
                "Wu Liu",
                "Xinchen Liu",
                "Zheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02232v1",
                "http://arxiv.org/pdf/2312.02232v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01668v1",
            "title": "Optimal dividend payout with path-dependent drawdown constraint",
            "updated": "2023-12-04T06:36:27Z",
            "published": "2023-12-04T06:36:27Z",
            "summary": "This paper studies an optimal dividend payout problem with drawdown\nconstraint in a Brownian motion model, where the dividend payout rate must be\nno less than a fixed proportion of its historical running maximum. It is a\nstochastic control problem, where the admissible control depends on its past\nvalues, thus is path-dependent. The related Hamilton-Jacobi-Bellman equation\nturns out to be a new type of two-dimensional variational inequality with\ngradient constraint, which has only been studied by viscosity solution\ntechnique in the literature. In this paper, we use delicate PDE methods to\nobtain a strong solution. Different from the viscosity solution, based on our\nsolution, we succeed in deriving an optimal feedback payout strategy, which is\nexpressed in terms of two free boundaries and the running maximum surplus\nprocess. Furthermore, we have obtained many properties of the value function\nand the free boundaries such as the boundedness, continuity etc. Numerical\nexamples are presented as well to verify our theoretical results and give some\nnew but not proved financial insights.",
            "author": [
                "Chonghu Guan",
                "Jiacheng Fan",
                "Zuo Quan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01668v1",
                "http://arxiv.org/pdf/2312.01668v1"
            ],
            "primary_category": "q-fin.MF",
            "category": [
                "q-fin.MF",
                "math.OC",
                "q-fin.PM",
                "35R35, 35Q93, 91G10, 91G30, 93E20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01665v1",
            "title": "Evaluation of flamelet-based models for liquid ammonia combustion in a\n  temporally evolving mixing layer",
            "updated": "2023-12-04T06:28:24Z",
            "published": "2023-12-04T06:28:24Z",
            "summary": "Liquid ammonia combustion can be enhanced by co-firing with small molecular\nfuels such as methane, and liquid ammonia will undergo flash evaporation due to\nits relatively low saturation pressure. These characteristics, involving the\npresence of multiple fuel streams, a rapid phase change process, and strong\nheat loss, pose challenges for flamelet modeling of liquid ammonia combustion.\nTo address these issues, this study aims to evaluate the effectiveness of\nflamelet-based models for liquid ammonia combustion in a turbulent mixing\nlayer. Specifically, the extended flamelet/progress variable (E-FPV), extended\nflamelet-generated manifolds (E-FGM), and extended hybrid (E-Hybrid) models are\ndeveloped and assessed. Firstly, a three-dimensional Point-Particle Direct\nNumerical Simulation (PP-DNS) with detailed chemistry is performed, where the\nturbulent flow is fully resolved, and the ammonia droplets are described by the\nLagrangian method, to investigate the combustion characteristics of a liquid\nammonia/methane co-fired flame and to provide state-of-the-art validation data\nfor flamelet modeling. The PP-DNS results reveal distinct stages in the liquid\nammonia/methane co-fired flame. The phase change process introduces significant\nheat loss due to the high latent heat of liquid ammonia. Subsequently,\nflamelet-based models are developed to account for the complex fuel streams,\nrapid phase change process, and strong local heat loss. The performance of\nthese models is evaluated through a priori analysis by comparing the\npredictions with the PP-DNS results. The a priori results show that the E-FGM\nmodel outperforms the E-FPV and E-Hybrid models. This superior performance can\nbe attributed to the rapid flash evaporation and sufficient mixing of the\nsuperheated ammonia, resulting in the dominance of the premixed combustion mode\nin liquid ammonia combustion.",
            "author": [
                "Zhenhua An",
                "Jiangkuan Xing",
                "Abhishek Lakshman Pillai",
                "Ryoichi Kurose"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01665v1",
                "http://arxiv.org/pdf/2312.01665v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01664v1",
            "title": "Quantum Algorithm for Radiative Transfer Equation",
            "updated": "2023-12-04T06:25:44Z",
            "published": "2023-12-04T06:25:44Z",
            "summary": "The radiation transfer equation is widely used for simulating such as heat\ntransfer in engineering, diffuse optical tomography in healthcare, and\nradiation hydrodynamics in astrophysics. By combining the lattice Boltzmann\nmethod, we propose a quantum algorithm for radiative transfer. This algorithm\nencompasses all the essential physical processes of radiative transfer:\nabsorption, scattering, and emission. Our quantum algorithm exponentially\naccelerates radiative transfer calculations compared to classical algorithms.\nIn order to verify the quantum algorithm, we perform quantum circuit simulation\nusing IBM Qiskit Aer and find good agreement between our numerical result and\nthe exact solution. The algorithm opens new application of fault-tolerant\nquantum computers for plasma engineering, telecommunications, nuclear fusion\ntechnology, healthcare and astrophysics.",
            "author": [
                "Asuka Igarashi",
                "Tadashi Kadowaki",
                "Shiro Kawabata"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01664v1",
                "http://arxiv.org/pdf/2312.01664v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "astro-ph.GA",
                "physics.app-ph",
                "physics.comp-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01662v1",
            "title": "Universal Deoxidation of Semiconductor Substrates Assisted by\n  Machine-Learning and Real-Time-Feedback-Control",
            "updated": "2023-12-04T06:24:49Z",
            "published": "2023-12-04T06:24:49Z",
            "summary": "Thin film deposition is an essential step in the semiconductor process.\nDuring preparation or loading, the substrate is exposed to the air unavoidably,\nwhich has motivated studies of the process control to remove the surface oxide\nbefore thin film deposition. Optimizing the deoxidation process in molecular\nbeam epitaxy (MBE) for a random substrate is a multidimensional challenge and\nsometimes controversial. Due to variations in semiconductor materials and\ngrowth processes, the determination of substrate deoxidation temperature is\nhighly dependent on the grower's expertise; the same substrate may yield\ninconsistent results when evaluated by different growers. Here, we employ a\nmachine learning (ML) hybrid convolution and vision transformer (CNN-ViT)\nmodel. This model utilizes reflection high-energy electron diffraction (RHEED)\nvideo as input to determine the deoxidation status of the substrate as output,\nenabling automated substrate deoxidation under a controlled architecture. This\nalso extends to the successful application of deoxidation processes on other\nsubstrates. Furthermore, we showcase the potential of models trained on data\nfrom a single MBE equipment to achieve high-accuracy deployment on other\nequipment. In contrast to traditional methods, our approach holds exceptional\npractical value. It standardizes deoxidation temperatures across various\nequipment and substrate materials, advancing the standardization research\nprocess in semiconductor preparation, a significant milestone in thin film\ngrowth technology. The concepts and methods demonstrated in this work are\nanticipated to revolutionize semiconductor manufacturing in optoelectronics and\nmicroelectronics industries by applying them to diverse material growth\nprocesses.",
            "author": [
                "Chao Shen",
                "Wenkang Zhan",
                "Jian Tang",
                "Zhaofeng Wu",
                "Bo Xu",
                "Chao Zhao",
                "Zhanguo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01662v1",
                "http://arxiv.org/pdf/2312.01662v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cs.LG",
                "cs.SY",
                "eess.IV",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01661v1",
            "title": "ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating\n  Pre-university Math Questions",
            "updated": "2023-12-04T06:23:37Z",
            "published": "2023-12-04T06:23:37Z",
            "summary": "Mathematical questioning is crucial for assessing students problem-solving\nskills. Since manually creating such questions requires substantial effort,\nautomatic methods have been explored. Existing state-of-the-art models rely on\nfine-tuning strategies and struggle to generate questions that heavily involve\nmultiple steps of logical and arithmetic reasoning. Meanwhile, large language\nmodels(LLMs) such as ChatGPT have excelled in many NLP tasks involving logical\nand arithmetic reasoning. Nonetheless, their applications in generating\neducational questions are underutilized, especially in the field of\nmathematics. To bridge this gap, we take the first step to conduct an in-depth\nanalysis of ChatGPT in generating pre-university math questions. Our analysis\nis categorized into two main settings: context-aware and context-unaware. In\nthe context-aware setting, we evaluate ChatGPT on existing math\nquestion-answering benchmarks covering elementary, secondary, and ternary\nclasses. In the context-unaware setting, we evaluate ChatGPT in generating math\nquestions for each lesson from pre-university math curriculums that we crawl.\nOur crawling results in TopicMath, a comprehensive and novel collection of\npre-university math curriculums collected from 121 math topics and 428 lessons\nfrom elementary, secondary, and tertiary classes. Through this analysis, we aim\nto provide insight into the potential of ChatGPT as a math questioner.",
            "author": [
                "Phuoc Pham Van Long",
                "Duc Anh Vu",
                "Nhat M. Hoang",
                "Xuan Long Do",
                "Anh Tuan Luu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01661v1",
                "http://arxiv.org/pdf/2312.01661v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01659v1",
            "title": "RiskBench: A Scenario-based Benchmark for Risk Identification",
            "updated": "2023-12-04T06:21:22Z",
            "published": "2023-12-04T06:21:22Z",
            "summary": "Intelligent driving systems aim to achieve a zero-collision mobility\nexperience, requiring interdisciplinary efforts to enhance safety performance.\nThis work focuses on risk identification, the process of identifying and\nanalyzing risks stemming from dynamic traffic participants and unexpected\nevents. While significant advances have been made in the community, the current\nevaluation of different risk identification algorithms uses independent\ndatasets, leading to difficulty in direct comparison and hindering collective\nprogress toward safety performance enhancement. To address this limitation, we\nintroduce \\textbf{RiskBench}, a large-scale scenario-based benchmark for risk\nidentification. We design a scenario taxonomy and augmentation pipeline to\nenable a systematic collection of ground truth risks under diverse scenarios.\nWe assess the ability of ten algorithms to (1) detect and locate risks, (2)\nanticipate risks, and (3) facilitate decision-making. We conduct extensive\nexperiments and summarize future research on risk identification. Our aim is to\nencourage collaborative endeavors in achieving a society with zero collisions.\nWe have made our dataset and benchmark toolkit publicly on the project page:\nhttps://hcis-lab.github.io/RiskBench/",
            "author": [
                "Chi-Hsi Kung",
                "Chieh-Chi Yang",
                "Pang-Yuan Pao",
                "Shu-Wei Lu",
                "Pin-Lun Chen",
                "Hsin-Cheng Lu",
                "Yi-Ting Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01659v1",
                "http://arxiv.org/pdf/2312.01659v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01658v1",
            "title": "AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for\n  Preconditioning Matrix",
            "updated": "2023-12-04T06:20:14Z",
            "published": "2023-12-04T06:20:14Z",
            "summary": "Adaptive optimizers, such as Adam, have achieved remarkable success in deep\nlearning. A key component of these optimizers is the so-called preconditioning\nmatrix, providing enhanced gradient information and regulating the step size of\neach gradient direction. In this paper, we propose a novel approach to\ndesigning the preconditioning matrix by utilizing the gradient difference\nbetween two successive steps as the diagonal elements. These diagonal elements\nare closely related to the Hessian and can be perceived as an approximation of\nthe inner product between the Hessian row vectors and difference of the\nadjacent parameter vectors. Additionally, we introduce an auto-switching\nfunction that enables the preconditioning matrix to switch dynamically between\nStochastic Gradient Descent (SGD) and the adaptive optimizer. Based on these\ntwo techniques, we develop a new optimizer named AGD that enhances the\ngeneralization performance. We evaluate AGD on public datasets of Natural\nLanguage Processing (NLP), Computer Vision (CV), and Recommendation Systems\n(RecSys). Our experimental results demonstrate that AGD outperforms the\nstate-of-the-art (SOTA) optimizers, achieving highly competitive or\nsignificantly better predictive performance. Furthermore, we analyze how AGD is\nable to switch automatically between SGD and the adaptive optimizer and its\nactual effects on various scenarios. The code is available at\nhttps://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers.",
            "author": [
                "Yun Yue",
                "Zhiling Ye",
                "Jiadi Jiang",
                "Yongchao Liu",
                "Ke Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01658v1",
                "http://arxiv.org/pdf/2312.01658v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01656v2",
            "title": "The Contemporary Art of Image Search: Iterative User Intent Expansion\n  via Vision-Language Model",
            "updated": "2023-12-05T02:24:38Z",
            "published": "2023-12-04T06:14:25Z",
            "summary": "Image search is an essential and user-friendly method to explore vast\ngalleries of digital images. However, existing image search methods heavily\nrely on proximity measurements like tag matching or image similarity, requiring\nprecise user inputs for satisfactory results. To meet the growing demand for a\ncontemporary image search engine that enables accurate comprehension of users'\nsearch intentions, we introduce an innovative user intent expansion framework.\nOur framework leverages visual-language models to parse and compose multi-modal\nuser inputs to provide more accurate and satisfying results. It comprises\ntwo-stage processes: 1) a parsing stage that incorporates a language parsing\nmodule with large language models to enhance the comprehension of textual\ninputs, along with a visual parsing module that integrates an interactive\nsegmentation module to swiftly identify detailed visual elements within images;\nand 2) a logic composition stage that combines multiple user search intents\ninto a unified logic expression for more sophisticated operations in complex\nsearching scenarios. Moreover, the intent expansion framework enables users to\nperform flexible contextualized interactions with the search results to further\nspecify or adjust their detailed search intents iteratively. We implemented the\nframework into an image search system for NFT (non-fungible token) search and\nconducted a user study to evaluate its usability and novel properties. The\nresults indicate that the proposed framework significantly improves users'\nimage search experience. Particularly the parsing and contextualized\ninteractions prove useful in allowing users to express their search intents\nmore accurately and engage in a more enjoyable iterative search experience.",
            "author": [
                "Yilin Ye",
                "Qian Zhu",
                "Shishi Xiao",
                "Kang Zhang",
                "Wei Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01656v2",
                "http://arxiv.org/pdf/2312.01656v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01655v1",
            "title": "Quantum Polar Metric Learning: Efficient Classically Learned Quantum\n  Embeddings",
            "updated": "2023-12-04T06:13:53Z",
            "published": "2023-12-04T06:13:53Z",
            "summary": "Deep metric learning has recently shown extremely promising results in the\nclassical data domain, creating well-separated feature spaces. This idea was\nalso adapted to quantum computers via Quantum Metric Learning(QMeL). QMeL\nconsists of a 2 step process with a classical model to compress the data to fit\ninto the limited number of qubits, then train a Parameterized Quantum\nCircuit(PQC) to create better separation in Hilbert Space. However, on Noisy\nIntermediate Scale Quantum (NISQ) devices. QMeL solutions result in high\ncircuit width and depth, both of which limit scalability. We propose Quantum\nPolar Metric Learning (QPMeL) that uses a classical model to learn the\nparameters of the polar form of a qubit. We then utilize a shallow PQC with\n$R_y$ and $R_z$ gates to create the state and a trainable layer of\n$ZZ(\\theta)$-gates to learn entanglement. The circuit also computes fidelity\nvia a SWAP Test for our proposed Fidelity Triplet Loss function, used to train\nboth classical and quantum components. When compared to QMeL approaches, QPMeL\nachieves 3X better multi-class separation, while using only 1/2 the number of\ngates and depth. We also demonstrate that QPMeL outperforms classical networks\nwith similar configurations, presenting a promising avenue for future research\non fully classical models with quantum loss functions.",
            "author": [
                "Vinayak Sharma",
                "Aviral Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01655v1",
                "http://arxiv.org/pdf/2312.01655v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "I.2.6; E.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03003v1",
            "title": "Explore, Select, Derive, and Recall: Augmenting LLM with Human-like\n  Memory for Mobile Task Automation",
            "updated": "2023-12-04T06:13:35Z",
            "published": "2023-12-04T06:13:35Z",
            "summary": "The advent of large language models (LLMs) has opened up new opportunities in\nthe field of mobile task automation. Their superior language understanding and\nreasoning capabilities allow users to automate complex and repetitive tasks.\nHowever, due to the inherent unreliability and high operational cost of LLMs,\ntheir practical applicability is quite limited. To address these issues, this\npaper introduces MemoDroid, an innovative LLM-based mobile task automator\nenhanced with a unique app memory. MemoDroid emulates the cognitive process of\nhumans interacting with a mobile app -- explore, select, derive, and recall.\nThis approach allows for a more precise and efficient learning of a task's\nprocedure by breaking it down into smaller, modular components that can be\nre-used, re-arranged, and adapted for various objectives. We implement\nMemoDroid using online LLMs services (GPT-3.5 and GPT-4) and evaluate its\nperformance on 50 unique mobile tasks across 5 widely used mobile apps. The\nresults indicate that MemoDroid can adapt learned tasks to varying contexts\nwith 100% accuracy and reduces their latency and cost by 69.22% and 77.36%\ncompared to a GPT-4 powered baseline.",
            "author": [
                "Sunjae Lee",
                "Junyoung Choi",
                "Jungjae Lee",
                "Hojun Choi",
                "Steven Y. Ko",
                "Sangeun Oh",
                "Insik Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03003v1",
                "http://arxiv.org/pdf/2312.03003v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01651v1",
            "title": "Experimental Optimal Quantum State Estimation with Genuine Three-copy\n  Collective Measurements",
            "updated": "2023-12-04T06:03:02Z",
            "published": "2023-12-04T06:03:02Z",
            "summary": "Nonclassical phenomena tied to entangled states are focuses of foundational\nstudies and powerful resources in many applications. By contrast, the\ncounterparts on quantum measurements are still poorly understood. Notably,\ngenuine multipartite nonclassicality is barely discussed, not to say\nexperimental realization. Here we experimentally demonstrate the power of\ngenuine tripartite nonclassicality in quantum measurements based on a simple\nestimation problem. To this end we realize an optimal genuine three-copy\ncollective measurement via a nine-step two-dimensional photonic quantum walk\nwith 30 elaborately designed coin operators. Then we realize an optimal\nestimation protocol and achieve an unprecedented high estimation fidelity,\nwhich can beat all strategies based on restricted collective measurements by\nmore than 11 standard deviations. These results clearly demonstrate that\ngenuine collective measurements can extract more information than local\nmeasurements and restricted collective measurements. Our work opens the door\nfor exploring genuine multipartite nonclassical measurements and their power in\nquantum information processing.",
            "author": [
                "Kai Zhou",
                "Changhao Yi",
                "Wen-Zhe Yan",
                "Zhibo Hou",
                "Huangjun Zhu",
                "Guo-Yong Xiang",
                "Chuan-Feng Li",
                "Guang-Can Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01651v1",
                "http://arxiv.org/pdf/2312.01651v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01649v1",
            "title": "A simple stacked ensemble machine learning model to predict naturalized\n  catchment hydrology and allocation status",
            "updated": "2023-12-04T06:01:43Z",
            "published": "2023-12-04T06:01:43Z",
            "summary": "New Zealand legislation requires that Regional Councils set limits for water\nresource usage to manage the effects of abstractions in over-allocated\ncatchments. We propose a simple stacked ensemble machine learning model to\npredict the probable naturalized hydrology and allocation status across 317\nanthropogenically stressed gauged catchments and across 18,612 ungauged river\nreaches in Otago. The training and testing of ensemble machine learning models\nprovides unbiased results characterized as very good (R2 > 0.8) to extremely\ngood (R2 > 0.9) when predicting naturalized mean annual low flow and Mean flow.\nStatistical 5-fold stacking identifies varying levels of risk for managing\nwater-resource sustainability in over-allocated catchments; for example, at the\nrespective 5th, 25th, 50th, 75th, and 95th percentiles the number of\noverallocated catchments are 73, 57, 44, 23, and 22. The proposed model can be\napplied to inform sustainable stream management in other regional catchments\nacross New Zealand and worldwide.",
            "author": [
                "Michael J. Friedel",
                "Dave Stewart",
                "Xiao Feng Lu",
                "Pete Stevenson",
                "Helen Manly",
                "Tom Dyer"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01649v1",
                "http://arxiv.org/pdf/2312.01649v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01648v1",
            "title": "Characterizing Large Language Model Geometry Solves Toxicity Detection\n  and Generation",
            "updated": "2023-12-04T06:01:32Z",
            "published": "2023-12-04T06:01:32Z",
            "summary": "Large Language Models~(LLMs) drive current AI breakthroughs despite very\nlittle being known about their internal representations, e.g., how to extract a\nfew informative features to solve various downstream tasks. To provide a\npractical and principled answer, we propose to characterize LLMs from a\ngeometric perspective. We obtain in closed form (i) the intrinsic dimension in\nwhich the Multi-Head Attention embeddings are constrained to exist and (ii) the\npartition and per-region affine mappings of the per-layer feedforward networks.\nOur results are informative, do not rely on approximations, and are actionable.\nFirst, we show that, motivated by our geometric interpretation, we can bypass\nLlama$2$'s RLHF by controlling its embedding's intrinsic dimension through\ninformed prompt manipulation. Second, we derive $7$ interpretable spline\nfeatures that can be extracted from any (pre-trained) LLM layer, providing a\nrich abstract representation of their inputs. Those features alone ($224$ for\nMistral-7B and Llama$2$-7B) are sufficient to help solve toxicity detection,\ninfer the domain of the prompt, and even tackle the Jigsaw challenge, which\naims at characterizing the type of toxicity of various prompts. Our results\ndemonstrate how, even in large-scale regimes, exact theoretical results can\nanswer practical questions in language models. Code:\n\\url{https://github.com/RandallBalestriero/SplineLLM}.",
            "author": [
                "Randall Balestriero",
                "Romain Cosentino",
                "Sarath Shekkizhar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01648v1",
                "http://arxiv.org/pdf/2312.01648v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01646v1",
            "title": "Enhancing data-limited assessments: Optimal utilization of\n  fishery-dependent data through random effects -- A case study on Korea chub\n  mackerel ($\\textit{Scomber japonicus}$)",
            "updated": "2023-12-04T05:56:21Z",
            "published": "2023-12-04T05:56:21Z",
            "summary": "In a state-space framework, temporal variations in fishery-dependent\nprocesses, such as selectivity and catchability, can be modeled as random\neffects. This makes state-space models (SSMs) powerful tools for data-limited\nassessments, especially when conventional CPUE standardization is inapplicable.\nHowever, the flexibility of this modeling approach can lead to challenges such\nas overfitting and parameter non-identifiability. To demonstrate and address\nthese challenges, we developed a state-space length-based age-structured model,\nwhich we applied to the Korea chub mackerel ($\\textit{Scomber japonicus}$)\nstock as a case study. The model underwent rigorous scrutiny using various\nmodel checking methods to detect potential model mis-specification and\nnon-identifiability under diverse scenarios. Our results demonstrated that\nincorporating temporal variations in fishery-dependent processes through random\neffects resolved model mis-specification, but excessive inclusion of random\neffects rendered the model sensitive to a small number of observations, even\nwhen the model was identifiable. For the non-identifiability issue, we employed\na non-degenerate estimator, using a gamma distribution as a penalty for the\nstandard deviation (SD) parameters of observation errors. This approach made\nthe SD parameters identifiable and facilitated the simultaneous estimation of\nboth process and observation error variances with minimal bias, known to be a\nchallenging task in SSMs. These findings underscore the importance of model\nchecking in SSMs and emphasize the need for careful consideration of\noverfitting and non-identifiability when developing such models for\ndata-limited assessments. Additionally, novel assessment results for the\nmackerel stock were presented, and implications for future stock assessment and\nmanagement were discussed.",
            "author": [
                "Kyuhan Kim",
                "Nokuthaba Sibanda",
                "Richard Arnold",
                "Teresa A'mar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01646v1",
                "http://arxiv.org/pdf/2312.01646v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01645v1",
            "title": "A text-dependent speaker verification application framework based on\n  Chinese numerical string corpus",
            "updated": "2023-12-04T05:52:59Z",
            "published": "2023-12-04T05:52:59Z",
            "summary": "Researches indicate that text-dependent speaker verification (TD-SV) often\noutperforms text-independent verification (TI-SV) in short speech scenarios.\nHowever, collecting large-scale fixed text speech data is challenging, and as\nspeech length increases, factors like sentence rhythm and pauses affect TDSV's\nsensitivity to text sequence. Based on these factors, We propose the hypothesis\nthat strategies such as more fine-grained pooling methods on time scales and\ndecoupled representations of speech speaker embedding and text embedding are\nmore suitable for TD-SV. We have introduced an end-to-end TD-SV system based on\na dataset comprising longer Chinese numerical string texts. It contains a text\nembedding network, a speaker embedding network, and back-end fusion. First, we\nrecorded a dataset consisting of long Chinese numerical text named SHAL, which\nis publicly available on the Open-SLR website. We addressed the issue of\ndataset scarcity by augmenting it using Tacotron2 and HiFi-GAN. Next, we\nintroduced a dual representation of speech with text embedding and speaker\nembedding. In the text embedding network, we employed an enhanced Transformer\nand introduced a triple loss that includes text classification loss, CTC loss,\nand decoder loss. For the speaker embedding network, we enhanced a sliding\nwindow attentive statistics pooling (SWASP), combined with attentive statistics\npooling (ASP) to create a multi-scale pooling method. Finally, we fused text\nembedding and speaker embedding. Our pooling methods achieved an equal error\nrate (EER) performance improvement of 49.2% on Hi-Mia and 75.0% on SHAL,\nrespectively.",
            "author": [
                "Litong Zheng",
                "Feng Hong",
                "Weijie Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01645v1",
                "http://arxiv.org/pdf/2312.01645v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01644v1",
            "title": "TMSR: Tiny Multi-path CNNs for Super Resolution",
            "updated": "2023-12-04T05:52:49Z",
            "published": "2023-12-04T05:52:49Z",
            "summary": "In this paper, we proposed a tiny multi-path CNN-based Super-Resolution (SR)\nmethod, called TMSR. We mainly refer to some tiny CNN-based SR methods, under\n5k parameters. The main contribution of the proposed method is the improved\nmulti-path learning and self-defined activated function. The experimental\nresults show that TMSR obtains competitive image quality (i.e. PSNR and SSIM)\ncompared to the related works under 5k parameters.",
            "author": [
                "Chia-Hung Liu",
                "Tzu-Hsin Hsieh",
                "Kuan-Yu Huang",
                "Pei-Yin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01644v1",
                "http://arxiv.org/pdf/2312.01644v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01642v1",
            "title": "Voice-Based Smart Assistant System for Vehicles using RASA",
            "updated": "2023-12-04T05:48:18Z",
            "published": "2023-12-04T05:48:18Z",
            "summary": "Conversational AIs, or chatbots, mimic human speech when conversing. Smart\nassistants facilitate the automation of several tasks that needed human\nintervention earlier. Because of their accuracy, absence of dependence on human\nresources, and accessibility around the clock, chatbots can be employed in\nvehicles too. Due to people's propensity to divert their attention away from\nthe task of driving while engaging in other activities like calling, playing\nmusic, navigation, and getting updates on the weather forecast and latest news,\nroad safety has declined and accidents have increased as a result. It would be\nadvantageous to automate these tasks using voice commands rather than carrying\nthem out manually. This paper focuses on the development of a voice-based smart\nassistance application for vehicles based on the RASA framework. The smart\nassistant provides functionalities like navigation, communication via calls,\ngetting weather forecasts and the latest news updates, and music that are\ncompletely voice-based in nature.",
            "author": [
                "Aditya Paranjape",
                "Yash Patwardhan",
                "Vedant Deshpande",
                "Aniket Darp",
                "Jayashree Jagdale"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01642v1",
                "http://arxiv.org/pdf/2312.01642v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01639v1",
            "title": "On the Effectiveness of Large Language Models in Domain-Specific Code\n  Generation",
            "updated": "2023-12-04T05:41:02Z",
            "published": "2023-12-04T05:41:02Z",
            "summary": "Large language models (LLMs) such as ChatGPT have shown remarkable\ncapabilities in code generation. Despite their great success, their\neffectiveness within particular domains (e.g., web development) necessitates\nfurther evaluation. In this study, we conduct an empirical study of\ndomain-specific code generation with LLMs. We demonstrate that LLMs exhibit\nsub-optimal performance in generating domain-specific code, due to their\nlimited proficiency in utilizing domain-specific libraries. We further observe\nthat incorporating API knowledge as prompts can empower LLMs to generate more\nprofessional code. Based on these findings, we further investigate how to\nefficiently incorporate API knowledge into the code generation process. We\nexperiment with three strategies for incorporating domain knowledge, namely,\nexternal knowledge inquirer, chain-of-thought prompting, and chain-of-thought\nfine-tuning. We refer to these strategies as a new code generation approach\ncalled DomCoder. Experimental results show that all strategies of DomCoder lead\nto improvement in the effectiveness of domain-specific code generation under\ncertain settings. The results also show that there is still ample room for\nfurther improvement, based on which we suggest possible future works.",
            "author": [
                "Meng Chen",
                "Hongyu Zhang",
                "Chengcheng Wan",
                "Zhao Wei",
                "Yong Xu",
                "Juhong Wang",
                "Xiaodong Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01639v1",
                "http://arxiv.org/pdf/2312.01639v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01638v1",
            "title": "J-Net: Improved U-Net for Terahertz Image Super-Resolution",
            "updated": "2023-12-04T05:39:51Z",
            "published": "2023-12-04T05:39:51Z",
            "summary": "Terahertz (THz) waves are electromagnetic waves in the 0.1 to 10 THz\nfrequency range, and THz imaging is utilized in a range of applications,\nincluding security inspections, biomedical fields, and the non-destructive\nexamination of materials. However, THz images have low resolution due to the\nlong wavelength of THz waves. Therefore, improving the resolution of THz images\nis one of the current hot research topics. We propose a novel network\narchitecture called J-Net which is improved version of U-Net to solve the THz\nimage super-resolution. It employs the simple baseline blocks which can extract\nlow resolution (LR) image features and learn the mapping of LR images to\nhighresolution (HR) images efficiently. All training was conducted using the\nDIV2K+Flickr2K dataset, and we employed the peak signal-to-noise ratio (PSNR)\nfor quantitative comparison. In our comparisons with other THz image\nsuper-resolution methods, JNet achieved a PSNR of 32.52 dB, surpassing other\ntechniques by more than 1 dB. J-Net also demonstrates superior performance on\nreal THz images compared to other methods. Experiments show that the proposed\nJ-Net achieves better PSNR and visual improvement compared with other THz image\nsuper-resolution methods.",
            "author": [
                "Woon-Ha Yeo",
                "Seung-Hwan Jung",
                "Seung Jae Oh",
                "Inhee Maeng",
                "Eui Su Lee",
                "Han-Cheol Ryu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01638v1",
                "http://arxiv.org/pdf/2312.01638v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01637v1",
            "title": "Near-real-time monitoring of global ocean carbon sink",
            "updated": "2023-12-04T05:37:29Z",
            "published": "2023-12-04T05:37:29Z",
            "summary": "Mitigation of climate change will highly rely on a carbon emission trajectory\nthat achieves carbon neutrality by the 2050s. The ocean plays a critical role\nin modulating climate change by sequestering CO2 from the atmosphere. Relying\non the multidisciplinary cutting-edge methodologies and technologies, the\nnear-real-time monitoring of global ocean carbon sinks from January 2022 to\nJuly 2023 aims to provide the world's latest assessment of monthly and gridded\nglobal ocean carbon sinks based on machine learning and other data science\ntechnologies. The project will help us find a robust route to deal with climate\nchange, which will significantly promote the ocean carbon sinks research and\nwill be of great interest for policy makers, researchers, and the public. This\nresearch aims to build up an integrated machine learning framework and\nmethodology for assessing global ocean carbon neutral process; development of\nnear-real-time dataset; development of visualization platform; research papers\npublished in international prestigious journals; an executive report openly\naccessible to policy makers and the public.",
            "author": [
                "Piyu Ke",
                "Xiaofan Gui",
                "Wei Cao",
                "Dezhi Wang",
                "Ce Hou",
                "Lixing Wang",
                "Xuanren Song",
                "Yun Li",
                "Biqing Zhu",
                "Jiang Bian",
                "Stephen Sitch",
                "Philippe Ciais",
                "Pierre Friedlingstein",
                "Zhu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01637v1",
                "http://arxiv.org/pdf/2312.01637v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01629v1",
            "title": "CLAMP: Contrastive LAnguage Model Prompt-tuning",
            "updated": "2023-12-04T05:13:59Z",
            "published": "2023-12-04T05:13:59Z",
            "summary": "Large language models (LLMs) have emerged as powerful general-purpose\ninterfaces for many machine learning problems. Recent work has adapted LLMs to\ngenerative visual tasks like image captioning, visual question answering, and\nvisual chat, using a relatively small amount of instruction-tuning data. In\nthis paper, we explore whether modern LLMs can also be adapted to classifying\nan image into a set of categories. First, we evaluate multimodal LLMs that are\ntuned for generative tasks on zero-shot image classification and find that\ntheir performance is far below that of specialized models like CLIP. We then\npropose an approach for light fine-tuning of LLMs using the same contrastive\nimage-caption matching objective as CLIP. Our results show that LLMs can,\nindeed, achieve good image classification performance when adapted this way.\nOur approach beats state-of-the-art mLLMs by 13% and slightly outperforms\ncontrastive learning with a custom text model, while also retaining the LLM's\ngenerative abilities. LLM initialization appears to particularly help\nclassification in domains under-represented in the visual pre-training data.",
            "author": [
                "Piotr Teterwak",
                "Ximeng Sun",
                "Bryan A. Plummer",
                "Kate Saenko",
                "Ser-Nam Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01629v1",
                "http://arxiv.org/pdf/2312.01629v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01627v1",
            "title": "Teachers' trust and perceptions of AI in education: The role of culture\n  and AI self-efficacy in six countries",
            "updated": "2023-12-04T05:07:23Z",
            "published": "2023-12-04T05:07:23Z",
            "summary": "AI-based educational technology (AI-EdTech) is increasingly adopted in K-12\neducation. Teachers play a critical role in this process as they are expected\nto use AI-EdTech in ways that support their teaching practice and students'\nlearning outcomes. Teachers' willingness to meaningfully integrate these\ntechnologies into their everyday educational activities depends on their\nattitudes toward AI-EdTech. We surveyed 508 K-12 teachers in six countries\nacross four continents (Brazil, Israel, Japan, Norway, Sweden, USA) about the\nperceived benefits of, concerns about, and trust in AI-EdTech. We examine\ndemographic, geo-cultural, professional, and psychological factors that might\ninfluence teachers' attitudes. Our results showed that teachers with higher AI\nunderstanding and self-efficacy perceive more benefits, fewer concerns, and\nstronger trust. We also found geographic and cultural differences in teachers'\nattitudes, including their trust in AI-EdTech, but no demographic differences\nemerged based on their age, gender, or level of education. The findings provide\na comprehensive, international account of factors influencing teachers'\nattitudes toward AI-EdTech. Efforts to raise teachers' understanding of, and\ntrust in AI-EdTech, while considering their cultural values are encouraged to\nsupport its adoption in K-12 education.",
            "author": [
                "Olga Viberg",
                "Mutlu Cukurova",
                "Yael Feldman-Maggor",
                "Giora Alexandron",
                "Shizuka Shirai",
                "Susumu Kanemune",
                "Barbara Wasson",
                "Cathrine T\u00f8mte",
                "Daniel Spikol",
                "Marcelo Milrad",
                "Raquel Coelho",
                "Ren\u00e9 F. Kizilcec"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01627v1",
                "http://arxiv.org/pdf/2312.01627v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01625v1",
            "title": "Interference-Constrained Scheduling of a Cognitive Multi-hop Underwater\n  Acoustic Network",
            "updated": "2023-12-04T05:01:30Z",
            "published": "2023-12-04T05:01:30Z",
            "summary": "This paper investigates optimal scheduling for a cognitive multi-hop\nunderwater acoustic network with a primary user interference constraint. The\nnetwork consists of primary and secondary users, with multi-hop transmission\nadopted for both user types to provide reliable communications. Critical\ncharacteristics of underwater acoustic channels, including significant\npropagation delay, distance-and-frequency dependent attenuation, half-duplex\nmodem, and inter-hop interference, are taken into account in the design and\nanalysis. In particular, time-slot allocation is found to be more effective\nthan frequency-slot allocation due to the underwater channel model. The goal of\nthe network scheduling problem is to maximize the end-to-end throughput of the\noverall system while limiting the throughput loss of primary users. Both\ncentralized and decentralized approaches are considered. Partially Observable\nMarkov Decision Processes (POMDP) framework is applied to formulate the\noptimization problem, and an optimal dynamic programming algorithm is derived.\nHowever, the optimal dynamic programming solution is computationally\nintractable. Key properties are shown for the objective function, enabling the\ndesign of approximate schemes with significant complexity reduction. Numerical\nresults show that the proposed schemes significantly increase system throughput\nwhile maintaining the primary throughput loss constraint. Under certain traffic\nconditions, the throughput gain over frequency-slot allocation schemes can be\nas high as 50%.",
            "author": [
                "Chen Peng",
                "Urbashi Mitra"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JOE.2023.3336462",
                "http://arxiv.org/abs/2312.01625v1",
                "http://arxiv.org/pdf/2312.01625v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01623v3",
            "title": "Universal Segmentation at Arbitrary Granularity with Language\n  Instruction",
            "updated": "2023-12-07T10:55:03Z",
            "published": "2023-12-04T04:47:48Z",
            "summary": "This paper aims to achieve universal segmentation of arbitrary semantic\nlevel. Despite significant progress in recent years, specialist segmentation\napproaches are limited to specific tasks and data distribution. Retraining a\nnew model for adaptation to new scenarios or settings takes expensive\ncomputation and time cost, which raises the demand for versatile and universal\nsegmentation model that can cater to various granularity. Although some\nattempts have been made for unifying different segmentation tasks or\ngeneralization to various scenarios, limitations in the definition of paradigms\nand input-output spaces make it difficult for them to achieve accurate\nunderstanding of content at arbitrary granularity. To this end, we present\nUniLSeg, a universal segmentation model that can perform segmentation at any\nsemantic level with the guidance of language instructions. For training\nUniLSeg, we reorganize a group of tasks from original diverse distributions\ninto a unified data format, where images with texts describing segmentation\ntargets as input and corresponding masks are output. Combined with a automatic\nannotation engine for utilizing numerous unlabeled data, UniLSeg achieves\nexcellent performance on various tasks and settings, surpassing both specialist\nand unified segmentation models.",
            "author": [
                "Yong Liu",
                "Cairong Zhang",
                "Yitong Wang",
                "Jiahao Wang",
                "Yujiu Yang",
                "Yansong Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01623v3",
                "http://arxiv.org/pdf/2312.01623v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01619v2",
            "title": "How Many Validation Labels Do You Need? Exploring the Design Space of\n  Label-Efficient Model Ranking",
            "updated": "2023-12-06T22:42:27Z",
            "published": "2023-12-04T04:20:38Z",
            "summary": "The paper introduces LEMR, a framework that reduces annotation costs for\nmodel selection tasks. Our approach leverages ensemble methods to generate\npseudo-labels, employs uncertainty sampling for target acquisition, and\nutilizes a Z-score mechanism for iterative committee reelection to refine model\nranks. We present a systematic study across various selection metrics,\ndemonstrating that LEMR achieves comparable results to fully labeled datasets\nwith a fraction of the labeling budget. Our findings indicate that LEMR not\nonly economizes the labeling effort in weak supervision and semi-supervised\nlearning settings but also effectively guides prompt selection for large\nlanguage models. With extensive experiments across 23 tasks, we reveal that our\nframework can dramatically decrease the labeling cost without compromising the\naccuracy of model selection, thereby offering a cost-effective alternative to\ntraditional practices.",
            "author": [
                "Zhengyu Hu",
                "Jieyu Zhang",
                "Yue Yu",
                "Yuchen Zhuang",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01619v2",
                "http://arxiv.org/pdf/2312.01619v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01618v1",
            "title": "Equations driven by fast-oscillating functions of a Wiener process",
            "updated": "2023-12-04T04:19:10Z",
            "published": "2023-12-04T04:19:10Z",
            "summary": "We study systems of differential equations driven by fast-oscillating\nfunctions of a Wiener process. In the limit when the frequency of oscillations\ngoes to infinity, we identify the limiting SDE systems which are driven by\nseveral independent Wiener processes. The solutions of the original equations\nconverge to those of the limiting system in law. The limiting equations include\nadditional drift terms which have the form of Stratonovich corrections. Our\nresult can thus be interpreted as a reqularization of SDE systems. The systems\nwe study are motivated by experimental work on the motion of light-sensitive\nrobots and on motility-induced phase separation in bacterial colonies.",
            "author": [
                "Tanner M. Reese",
                "Jan Wehr"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01618v1",
                "http://arxiv.org/pdf/2312.01618v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01610v1",
            "title": "Accelerated Parallel Magnetic Resonance Imaging with Compressed Sensing\n  using Structured Sparsity",
            "updated": "2023-12-04T04:01:13Z",
            "published": "2023-12-04T04:01:13Z",
            "summary": "Compressed sensing is an imaging paradigm that allows one to invert an\nunderdetermined linear system by imposing the a priori knowledge that the\nsought after solution is sparse (i.e., mostly zeros). Previous works have shown\nthat if one also knows something about the sparsity pattern (the locations\nwhere non-zero entries exist), one can take advantage of this structure to\nimprove the quality of the result. A significant application of compressed\nsensing is magnetic resonance imaging (MRI), where samples are acquired in the\nFourier domain. Compressed sensing allows one to reconstruct a high-quality\nimage with fewer samples which can be collected with a faster scan. This\nincreases the robustness of MRI to patient motion since less motion is possible\nduring the shorter scan. Parallel imaging, where multiple coils are used to\ngather data, is another an more ubiquitously used method for accelerating MRI.\nExisting combinations of these acceleration methods, such as Sparse SENSE,\nyield high quality images with an even shorter scan time than either technique\nalone. In this work, we show how to modify Sparse SENSE with structured\nsparsity to reconstruct a high quality image with even fewer samples.",
            "author": [
                "Nicholas Dwork",
                "Erin K. Englund"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01610v1",
                "http://arxiv.org/pdf/2312.01610v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01608v1",
            "title": "A Variation Problem for Mappings between Statistical Manifolds",
            "updated": "2023-12-04T03:48:21Z",
            "published": "2023-12-04T03:48:21Z",
            "summary": "We present statistical biharmonic maps, a new class of mappings between\nstatistical manifolds naturally derived from a variation problem. We give the\nEuler-Lagrange equation of this problem and prove that improper affine\nhyperspheres induce examples of such maps.",
            "author": [
                "Hitoshi Furuhata",
                "Ryu Ueno"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01608v1",
                "http://arxiv.org/pdf/2312.01608v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "53B12 (Primary) 53A15, 58E20, 53C43 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02230v1",
            "title": "A Simple and Scalable Representation for Graph Generation",
            "updated": "2023-12-04T03:43:26Z",
            "published": "2023-12-04T03:43:26Z",
            "summary": "Recently, there has been a surge of interest in employing neural networks for\ngraph generation, a fundamental statistical learning problem with critical\napplications like molecule design and community analysis. However, most\napproaches encounter significant limitations when generating large-scale\ngraphs. This is due to their requirement to output the full adjacency matrices\nwhose size grows quadratically with the number of nodes. In response to this\nchallenge, we introduce a new, simple, and scalable graph representation named\ngap encoded edge list (GEEL) that has a small representation size that aligns\nwith the number of edges. In addition, GEEL significantly reduces the\nvocabulary size by incorporating the gap encoding and bandwidth restriction\nschemes. GEEL can be autoregressively generated with the incorporation of node\npositional encoding, and we further extend GEEL to deal with attributed graphs\nby designing a new grammar. Our findings reveal that the adoption of this\ncompact representation not only enhances scalability but also bolsters\nperformance by simplifying the graph generation process. We conduct a\ncomprehensive evaluation across ten non-attributed and two molecular graph\ngeneration tasks, demonstrating the effectiveness of GEEL.",
            "author": [
                "Yunhui Jang",
                "Seul Lee",
                "Sungsoo Ahn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02230v1",
                "http://arxiv.org/pdf/2312.02230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01606v2",
            "title": "Deep Learning-Driven Enhancement of Welding Quality Control: Predicting\n  Welding Depth and Pore Volume in Hairpin Welding",
            "updated": "2023-12-05T05:43:31Z",
            "published": "2023-12-04T03:38:17Z",
            "summary": "To advance quality assurance in the welding process, this study presents a\nrobust deep learning model that enables the prediction of two critical welds\nKey Performance Characteristics (KPCs): welding depth and average pore volume.\nIn the proposed approach, a comprehensive range of laser welding Key Input\nCharacteristics (KICs) is utilized, including welding beam geometries, welding\nfeed rates, path repetitions for weld beam geometries, and bright light weld\nratios for all paths, all of which were obtained from hairpin welding\nexperiments. Two deep learning networks are employed with multiple hidden dense\nlayers and linear activation functions to showcase the capabilities of deep\nneural networks in capturing the intricate nonlinear connections inherent\nwithin welding KPCs and KICs. Applying deep learning networks to the small\nnumerical experimental hairpin welding dataset has shown promising results,\nachieving Mean Absolute Error (MAE) values as low as 0.1079 for predicting\nwelding depth and 0.0641 for average pore volume. Additionally, the validity\nverification demonstrates the reliability of the proposed method. This, in\nturn, promises significant advantages in controlling welding outcomes, moving\nbeyond the current trend of relying merely on monitoring for defect\nclassification.",
            "author": [
                "Amena Darwish",
                "Stefan Ericson",
                "Rohollah Ghasemi",
                "Tobias Andersson",
                "Dan L\u00f6nn",
                "Andreas Andersson Lassila",
                "Kent Salomonsson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01606v2",
                "http://arxiv.org/pdf/2312.01606v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01602v1",
            "title": "Quantum Time Series Similarity Measures and Quantum Temporal Kernels",
            "updated": "2023-12-04T03:33:51Z",
            "published": "2023-12-04T03:33:51Z",
            "summary": "This article presents a quantum computing approach to the design of\nsimilarity measures and kernels for classification of stochastic symbol time\nseries. The similarity is estimated through a quantum generative model of the\ntime series. We consider classification tasks where the class of each sequence\ndepends on its future evolution. In this case a stochastic generative model\nprovides natural notions of equivalence and distance between the sequences. The\nkernel functions are derived from the generative model, exploiting its\ninformation about the sequences evolution.We assume that the stochastic process\ngenerating the sequences is Markovian and model it by a Quantum Hidden Markov\nModel (QHMM). The model defines the generation of each sequence through a path\nof mixed quantum states in its Hilbert space. The observed symbols are emitted\nby application of measurement operators at each state. The generative model\ndefines the feature space for the kernel. The kernel maps each sequence to the\nfinal state of its generation path. The Markovian assumption about the process\nand the fact that the quantum operations are contractive, guarantee that the\nsimilarity of the states implies (probabilistic) similarity of the\ndistributions defined by the states and the processes originating from these\nstates. This is the heuristic we use in order to propose this class of kernels\nfor classification of sequences, based on their future behavior. The proposed\napproach is applied for classification of high frequency symbolic time series\nin the financial industry.",
            "author": [
                "Vanio Markov",
                "Vladimir Rastunkov",
                "Daniel Fry"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01602v1",
                "http://arxiv.org/pdf/2312.01602v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01600v1",
            "title": "A phenomenological model for interstitial hydrogen absorption in niobium",
            "updated": "2023-12-04T03:22:53Z",
            "published": "2023-12-04T03:22:53Z",
            "summary": "A phenomenological model has been developed for hydrogen absorption in\nniobium. The model has 9 free parameters that have a physical basis. The model\nprovides an excellent fit to the highly accurate isotherm data by Veleckis et\nal. and has been cross validated by limiting the fitting procedure to a\ntraining set. The model makes it possible to extract more information from the\ndata than could be extracted with the computational methods available when the\nmeasurements were made. The partial molal enthalpy and partial molal entropy of\nhydrogen dissolution were calculated using the parameter values corresponding\nto the best fit to the isotherms. These quantities are consistent with those\nreported by Veleckis et al. Interpreting the model parameter values reveals\ninsights into the nature of the interaction between hydrogen atoms in niobium.\nThese insights supports our previous analysis of hydrogen interactions in\nniobium using density functional theory calculations.",
            "author": [
                "Arvind Ramachandran",
                "Houlong Zhuang",
                "Klaus Lackner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01600v1",
                "http://arxiv.org/pdf/2312.01600v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01598v1",
            "title": "Good Questions Help Zero-Shot Image Reasoning",
            "updated": "2023-12-04T03:18:51Z",
            "published": "2023-12-04T03:18:51Z",
            "summary": "Aligning the recent large language models (LLMs) with computer vision models\nleads to large vision-language models (LVLMs), which have paved the way for\nzero-shot image reasoning tasks. However, LVLMs are usually trained on short\nhigh-level captions only referring to sparse focus regions in images. Such a\n``tunnel vision'' limits LVLMs to exploring other relevant contexts in complex\nscenes. To address this challenge, we introduce Question-Driven Visual\nExploration (QVix), a novel prompting strategy that enhances the exploratory\ncapabilities of LVLMs in zero-shot reasoning tasks. QVix leverages LLMs' strong\nlanguage prior to generate input-exploratory questions with more details than\nthe original query, guiding LVLMs to explore visual content more\ncomprehensively and uncover subtle or peripheral details. QVix enables a wider\nexploration of visual scenes, improving the LVLMs' reasoning accuracy and depth\nin tasks such as visual question answering and visual entailment. Our\nevaluations on various challenging zero-shot vision-language benchmarks,\nincluding ScienceQA and fine-grained visual classification, demonstrate that\nQVix significantly outperforms existing methods, highlighting its effectiveness\nin bridging the gap between complex visual data and LVLMs' exploratory\nabilities.",
            "author": [
                "Kaiwen Yang",
                "Tao Shen",
                "Xinmei Tian",
                "Xiubo Geng",
                "Chongyang Tao",
                "Dacheng Tao",
                "Tianyi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01598v1",
                "http://arxiv.org/pdf/2312.01598v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01597v1",
            "title": "SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference",
            "updated": "2023-12-04T03:18:46Z",
            "published": "2023-12-04T03:18:46Z",
            "summary": "Recent advances in contrastive language-image pretraining (CLIP) have\ndemonstrated strong capabilities in zero-shot classification by aligning visual\nrepresentations with target text embeddings in an image level. However, in\ndense prediction tasks, CLIP often struggles to localize visual features within\nan image and fails to give accurate pixel-level predictions, which prevents it\nfrom functioning as a generalized visual foundation model. In this work, we aim\nto enhance CLIP's potential for semantic segmentation with minimal\nmodifications to its pretrained models. By rethinking self-attention, we\nsurprisingly find that CLIP can adapt to dense prediction tasks by simply\nintroducing a novel Correlative Self-Attention (CSA) mechanism. Specifically,\nwe replace the traditional self-attention block of CLIP vision encoder's last\nlayer by our CSA module and reuse its pretrained projection matrices of query,\nkey, and value, leading to a training-free adaptation approach for CLIP's\nzero-shot semantic segmentation. Extensive experiments show the advantage of\nCSA: we obtain a 38.2% average zero-shot mIoU across eight semantic\nsegmentation benchmarks highlighted in this paper, significantly outperforming\nthe existing SoTA's 33.9% and the vanilla CLIP's 14.1%.",
            "author": [
                "Feng Wang",
                "Jieru Mei",
                "Alan Yuille"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01597v1",
                "http://arxiv.org/pdf/2312.01597v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01596v1",
            "title": "Statistic electromotive force of solid-state conductor P / polar liquid\n  L / solid-state conductor N capacitor",
            "updated": "2023-12-04T03:18:24Z",
            "published": "2023-12-04T03:18:24Z",
            "summary": "Based on the energy conversion of the dynamic electric effect from the\nsolid/liquid contact double electric layer is the dynamic electromotive\npotential, this paper studies the static appearance and the release of the\nelectric field energy of the solid/liquid contact double electric layer, so a\nspecial capacitor (P/L/N capacitor) of solid conductor P / polar liquid L /\nsolid conductor N is constructed. The observations based on experiments are as\nfollows: (i) the contact double electric layer derived from the internal\npotential difference polarization of the solid conductor / polar liquid is\nequivalent to the external electric field polarization of the ordinary\ncapacitor. The formation process of the contact double electric layer is the\nspontaneous charging process of the P/L/N capacitor, and the P/L/N capacitor\nstill shows the electric field energy of the contact double electric layer.\n(ii) Because the polarized external potential difference of the solid conductor\n/ polar liquid contacting the double electric layer is always less than the\ninternal potential difference, the short-circuit P/L/N capacitor also has a\ncontinuous electromotive force after the discharge, statically releasing the\nelectric field energy contacting the double electric layer. (iii) The contact\ndouble electric layer of solid conductor / polar liquid is produced\nspontaneously caused by mutual contact, and it is also a self-organizing\nprocess of absorbing the environmental heat energy into the electric field\nenergy of the contact double electric layer. P/L/N capacitors realize\nthermoelectric conversion by releasing the electric field energy of the contact\ndouble electric layer. The above-mentioned phenomenon provides the possibility\nfor the development of self-generated capacitors and self-supplied power\nsupply.",
            "author": [
                "Zhengliang Wang",
                "Shanfei Chen",
                "Gelin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01596v1",
                "http://arxiv.org/pdf/2312.01596v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01594v2",
            "title": "Impact of the LZ Experiment on DM Phenomenology and Naturalness in the\n  MSSM",
            "updated": "2023-12-05T07:26:53Z",
            "published": "2023-12-04T03:17:29Z",
            "summary": "Taking the bino-dominated dark matter (DM) as an example, through approximate\nanalytical formulas and numerical results, this paper analyzes impact of the\nLUX-ZEPLIN (LZ) Experiment on DM phenomenology and naturalness in Minimal\nSuper-symmetric Standard Model(MSSM). It concluded that under the limitation of\nthe latest LZ experiment, MSSM suffers unattractive fine-tunings. The reason is\nthat the latest LZ experiment results improve $\\mu$ bounds, e.g., for the cases\nof the Z- or h-mediated resonant annihilations to achieve the measured dark\nmatter density, the LZ experiment require $\\mu$ should be larger than about\n$500~{\\rm GeV}$ or TeV magnitude, which imply a tuning to predict the $Z$-boson\nmass and simultaneously worsen the naturalness of the $Z$- and $h$-mediated\nresonant annihilations to achieve the measured dark matter density.",
            "author": [
                "Li Dongwei",
                "Meng Lei",
                "Zhou Haijing"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01594v2",
                "http://arxiv.org/pdf/2312.01594v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01592v1",
            "title": "Expand BERT Representation with Visual Information via Grounded Language\n  Learning with Multimodal Partial Alignment",
            "updated": "2023-12-04T03:16:48Z",
            "published": "2023-12-04T03:16:48Z",
            "summary": "Language models have been supervised with both language-only objective and\nvisual grounding in existing studies of visual-grounded language learning.\nHowever, due to differences in the distribution and scale of visual-grounded\ndatasets and language corpora, the language model tends to mix up the context\nof the tokens that occurred in the grounded data with those that do not. As a\nresult, during representation learning, there is a mismatch between the visual\ninformation and the contextual meaning of the sentence. To overcome this\nlimitation, we propose GroundedBERT - a grounded language learning method that\nenhances the BERT representation with visually grounded information.\nGroundedBERT comprises two components: (i) the original BERT which captures the\ncontextual representation of words learned from the language corpora, and (ii)\na visual grounding module which captures visual information learned from\nvisual-grounded datasets. Moreover, we employ Optimal Transport (OT),\nspecifically its partial variant, to solve the fractional alignment problem\nbetween the two modalities. Our proposed method significantly outperforms the\nbaseline language models on various language tasks of the GLUE and SQuAD\ndatasets.",
            "author": [
                "Cong-Duy Nguyen",
                "The-Anh Vu-Le",
                "Thong Nguyen",
                "Tho Quan",
                "Luu Anh Tuan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01592v1",
                "http://arxiv.org/pdf/2312.01592v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01591v1",
            "title": "Integrability and singularities of Harish-Chandra characters",
            "updated": "2023-12-04T03:15:12Z",
            "published": "2023-12-04T03:15:12Z",
            "summary": "Let $G$ be a reductive group over a local field $F$ of characteristic $0$. By\nHarish-Chandra's regularity theorem, every global character $\\Theta_{\\pi}$ of\nan irreducible, admissible representation $\\pi$ of $G$ is given by a locally\nintegrable function $\\theta_{\\pi}$ on $G$. It is a natural question whether\n$\\theta_{\\pi}$ has better integrability properties, namely, whether it is\nlocally $L^{1+\\epsilon}$-integrable for some $\\epsilon>0$. It follows from\nHarish-Chandra's work that the answer is positive, and this gives rise to a new\nsingularity invariant of representations $\\epsilon_{\\star}(\\pi):=\\sup\\left\\{\n\\epsilon:\\theta_{\\pi}\\in L_{\\mathrm{Loc}}^{1+\\epsilon}(G)\\right\\} $, which we\nexplore in this paper.\n  We provide a lower bound on $\\epsilon_{\\star}(\\pi)$ for any $G$, and\ndetermine $\\epsilon_{\\star}(\\pi)$ in the case of a $p$-adic $\\mathrm{GL}_{n}$.\nThis is done by studying integrability properties of the Fourier transforms\n$\\widehat{\\xi_{\\mathcal{O}}}$ of stable Richardson nilpotent orbital integrals\n$\\xi_{\\mathcal{O}}$. We express $\\epsilon_{\\star}(\\widehat{\\xi_{\\mathcal{O}}})$\nas the log-canonical threshold of a suitable relative Weyl discriminant, and\nuse a resolution of singularities algorithm coming from the theory of\nhyperplane arrangements, to compute it in terms of the partition associated\nwith the orbit.\n  As an application, we obtain bounds on the multiplicities of $K$-types in\nirreducible representations of $G$ in the $p$-adic case, where $K$ is an open\ncompact subgroup.",
            "author": [
                "Itay Glazer",
                "Julia Gordon",
                "Yotam I. Hendel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01591v1",
                "http://arxiv.org/pdf/2312.01591v1"
            ],
            "primary_category": "math.RT",
            "category": [
                "math.RT",
                "math.AG",
                "20G05, 14B05, 20G05 (Primary) 14N20, 17B08, 22E30, 22E35, 22E46,\n  32S22, 43A30 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02229v1",
            "title": "Synthetic Data Generation Techniques for Developing AI-based Speech\n  Assessments for Parkinson's Disease (A Comparative Study)",
            "updated": "2023-12-04T03:12:09Z",
            "published": "2023-12-04T03:12:09Z",
            "summary": "Changes in speech and language are among the first signs of Parkinson's\ndisease (PD). Thus, clinicians have tried to identify individuals with PD from\ntheir voices for years. Doctors can leverage AI-based speech assessments to\nspot PD thanks to advancements in artificial intelligence (AI). Such AI systems\ncan be developed using machine learning classifiers that have been trained\nusing individuals' voices. Although several studies have shown reasonable\nresults in developing such AI systems, these systems would need more data\nsamples to achieve promising performance. This paper explores using deep\nlearning-based data generation techniques on the accuracy of machine learning\nclassifiers that are the core of such systems.",
            "author": [
                "Mahboobeh Parsapoor"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02229v1",
                "http://arxiv.org/pdf/2312.02229v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01588v1",
            "title": "ActiveClean: Generating Line-Level Vulnerability Data via Active\n  Learning",
            "updated": "2023-12-04T03:09:31Z",
            "published": "2023-12-04T03:09:31Z",
            "summary": "Deep learning vulnerability detection tools are increasing in popularity and\nhave been shown to be effective. These tools rely on large volume of high\nquality training data, which are very hard to get. Most of the currently\navailable datasets provide function-level labels, reporting whether a function\nis vulnerable or not vulnerable. However, for a vulnerability detection to be\nuseful, we need to also know the lines that are relevant to the vulnerability.\nThis paper makes efforts towards developing systematic tools and proposes.\nActiveClean to generate the large volume of line-level vulnerability data from\ncommits. That is, in addition to function-level labels, it also reports which\nlines in the function are likely responsible for vulnerability detection. In\nthe past, static analysis has been applied to clean commits to generate\nline-level data. Our approach based on active learning, which is easy to use\nand scalable, provide a complementary approach to static analysis. We designed\nsemantic and syntactic properties from commit lines and use them to train the\nmodel. We evaluated our approach on both Java and C datasets processing more\nthan 4.3K commits and 119K commit lines. AcitveClean achieved an F1 score\nbetween 70-74. Further, we also show that active learning is effective by using\njust 400 training data to reach F1 score of 70.23. Using ActiveClean, we\ngenerate the line-level labels for the entire FFMpeg project in the Devign\ndataset, including 5K functions, and also detected incorrect function-level\nlabels. We demonstrated that using our cleaned data, LineVul, a SOTA line-level\nvulnerability detection tool, detected 70 more vulnerable lines and 18 more\nvulnerable functions, and improved Top 10 accuracy from 66% to 73%.",
            "author": [
                "Ashwin Kallingal Joshy",
                "Mirza Sanjida Alam",
                "Shaila Sharmin",
                "Qi Li",
                "Wei Le"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01588v1",
                "http://arxiv.org/pdf/2312.01588v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02227v1",
            "title": "Improving Multimodal Sentiment Analysis: Supervised Angular Margin-based\n  Contrastive Learning for Enhanced Fusion Representation",
            "updated": "2023-12-04T02:58:19Z",
            "published": "2023-12-04T02:58:19Z",
            "summary": "The effectiveness of a model is heavily reliant on the quality of the fusion\nrepresentation of multiple modalities in multimodal sentiment analysis.\nMoreover, each modality is extracted from raw input and integrated with the\nrest to construct a multimodal representation. Although previous methods have\nproposed multimodal representations and achieved promising results, most of\nthem focus on forming positive and negative pairs, neglecting the variation in\nsentiment scores within the same class. Additionally, they fail to capture the\nsignificance of unimodal representations in the fusion vector. To address these\nlimitations, we introduce a framework called Supervised Angular-based\nContrastive Learning for Multimodal Sentiment Analysis. This framework aims to\nenhance discrimination and generalizability of the multimodal representation\nand overcome biases in the fusion vector's modality. Our experimental results,\nalong with visualizations on two widely used datasets, demonstrate the\neffectiveness of our approach.",
            "author": [
                "Cong-Duy Nguyen",
                "Thong Nguyen",
                "Duc Anh Vu",
                "Luu Anh Tuan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02227v1",
                "http://arxiv.org/pdf/2312.02227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01586v1",
            "title": "On the Maximization of Long-Run Reward CVaR for Markov Decision\n  Processes",
            "updated": "2023-12-04T02:48:53Z",
            "published": "2023-12-04T02:48:53Z",
            "summary": "This paper studies the optimization of Markov decision processes (MDPs) from\na risk-seeking perspective, where the risk is measured by conditional\nvalue-at-risk (CVaR). The objective is to find a policy that maximizes the\nlong-run CVaR of instantaneous rewards over an infinite horizon across all\nhistory-dependent randomized policies. By establishing two optimality\ninequalities of opposing directions, we prove that the maximum of long-run CVaR\nof MDPs over the set of history-dependent randomized policies can be found\nwithin the class of stationary randomized policies. In contrast to classical\nMDPs, we find that there may not exist an optimal stationary deterministic\npolicy for maximizing CVaR. Instead, we prove the existence of an optimal\nstationary randomized policy that requires randomizing over at most two\nactions. Via a convex optimization representation of CVaR, we convert the\nlong-run CVaR maximization MDP into a minimax problem, where we prove the\ninterchangeability of minimum and maximum and the related existence of saddle\npoint solutions. Furthermore, we propose an algorithm that finds the saddle\npoint solution by solving two linear programs. These results are then extended\nto objectives that involve maximizing some combination of mean and CVaR of\nrewards simultaneously. Finally, we conduct numerical experiments to\ndemonstrate the main results.",
            "author": [
                "Li Xia",
                "Zhihui Yu",
                "Peter W. Glynn"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01586v1",
                "http://arxiv.org/pdf/2312.01586v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01582v1",
            "title": "Explaining with Contrastive Phrasal Highlighting: A Case Study in\n  Assisting Humans to Detect Translation Differences",
            "updated": "2023-12-04T02:40:28Z",
            "published": "2023-12-04T02:40:28Z",
            "summary": "Explainable NLP techniques primarily explain by answering \"Which tokens in\nthe input are responsible for this prediction?''. We argue that for NLP models\nthat make predictions by comparing two input texts, it is more useful to\nexplain by answering \"What differences between the two inputs explain this\nprediction?''. We introduce a technique to generate contrastive highlights that\nexplain the predictions of a semantic divergence model via\nphrase-alignment-guided erasure. We show that the resulting highlights match\nhuman rationales of cross-lingual semantic differences better than popular\npost-hoc saliency techniques and that they successfully help people detect\nfine-grained meaning differences in human translations and critical machine\ntranslation errors.",
            "author": [
                "Eleftheria Briakou",
                "Navita Goyal",
                "Marine Carpuat"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01582v1",
                "http://arxiv.org/pdf/2312.01582v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02226v1",
            "title": "Generating Action-conditioned Prompts for Open-vocabulary Video Action\n  Recognition",
            "updated": "2023-12-04T02:31:38Z",
            "published": "2023-12-04T02:31:38Z",
            "summary": "Exploring open-vocabulary video action recognition is a promising venture,\nwhich aims to recognize previously unseen actions within any arbitrary set of\ncategories. Existing methods typically adapt pretrained image-text models to\nthe video domain, capitalizing on their inherent strengths in generalization. A\ncommon thread among such methods is the augmentation of visual embeddings with\ntemporal information to improve the recognition of seen actions. Yet, they\ncompromise with standard less-informative action descriptions, thus faltering\nwhen confronted with novel actions. Drawing inspiration from human cognitive\nprocesses, we argue that augmenting text embeddings with human prior knowledge\nis pivotal for open-vocabulary video action recognition. To realize this, we\ninnovatively blend video models with Large Language Models (LLMs) to devise\nAction-conditioned Prompts. Specifically, we harness the knowledge in LLMs to\nproduce a set of descriptive sentences that contain distinctive features for\nidentifying given actions. Building upon this foundation, we further introduce\na multi-modal action knowledge alignment mechanism to align concepts in video\nand textual knowledge encapsulated within the prompts. Extensive experiments on\nvarious video benchmarks, including zero-shot, few-shot, and base-to-novel\ngeneralization settings, demonstrate that our method not only sets new SOTA\nperformance but also possesses excellent interpretability.",
            "author": [
                "Chengyou Jia",
                "Minnan Luo",
                "Xiaojun Chang",
                "Zhuohang Dang",
                "Mingfei Han",
                "Mengmeng Wang",
                "Guang Dai",
                "Sizhe Dang",
                "Jingdong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02226v1",
                "http://arxiv.org/pdf/2312.02226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01576v1",
            "title": "Learning Efficient Unsupervised Satellite Image-based Building Damage\n  Detection",
            "updated": "2023-12-04T02:20:35Z",
            "published": "2023-12-04T02:20:35Z",
            "summary": "Existing Building Damage Detection (BDD) methods always require\nlabour-intensive pixel-level annotations of buildings and their conditions,\nhence largely limiting their applications. In this paper, we investigate a\nchallenging yet practical scenario of BDD, Unsupervised Building Damage\nDetection (U-BDD), where only unlabelled pre- and post-disaster satellite image\npairs are provided. As a pilot study, we have first proposed an advanced U-BDD\nbaseline that leverages pre-trained vision-language foundation models (i.e.,\nGrounding DINO, SAM and CLIP) to address the U-BDD task. However, the apparent\ndomain gap between satellite and generic images causes low confidence in the\nfoundation models used to identify buildings and their damages. In response, we\nfurther present a novel self-supervised framework, U-BDD++, which improves upon\nthe U-BDD baseline by addressing domain-specific issues associated with\nsatellite imagery. Furthermore, the new Building Proposal Generation (BPG)\nmodule and the CLIP-enabled noisy Building Proposal Selection (CLIP-BPS) module\nin U-BDD++ ensure high-quality self-training. Extensive experiments on the\nwidely used building damage assessment benchmark demonstrate the effectiveness\nof the proposed method for unsupervised building damage detection. The\npresented annotation-free and foundation model-based paradigm ensures an\nefficient learning phase. This study opens a new direction for real-world BDD\nand sets a strong baseline for future research.",
            "author": [
                "Yiyun Zhang",
                "Zijian Wang",
                "Yadan Luo",
                "Xin Yu",
                "Zi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01576v1",
                "http://arxiv.org/pdf/2312.01576v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01575v1",
            "title": "A Challenging Multimodal Video Summary: Simultaneously Extracting and\n  Generating Keyframe-Caption Pairs from Video",
            "updated": "2023-12-04T02:17:14Z",
            "published": "2023-12-04T02:17:14Z",
            "summary": "This paper proposes a practical multimodal video summarization task setting\nand a dataset to train and evaluate the task. The target task involves\nsummarizing a given video into a predefined number of keyframe-caption pairs\nand displaying them in a listable format to grasp the video content quickly.\nThis task aims to extract crucial scenes from the video in the form of images\n(keyframes) and generate corresponding captions explaining each keyframe's\nsituation. This task is useful as a practical application and presents a highly\nchallenging problem worthy of study. Specifically, achieving simultaneous\noptimization of the keyframe selection performance and caption quality\nnecessitates careful consideration of the mutual dependence on both preceding\nand subsequent keyframes and captions. To facilitate subsequent research in\nthis field, we also construct a dataset by expanding upon existing datasets and\npropose an evaluation framework. Furthermore, we develop two baseline systems\nand report their respective performance.",
            "author": [
                "Keito Kudo",
                "Haruki Nagasawa",
                "Jun Suzuki",
                "Nobuyuki Shimizu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01575v1",
                "http://arxiv.org/pdf/2312.01575v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01574v1",
            "title": "Fast Sampling for Linear Inverse Problems of Vectors and Tensors using\n  Multilinear Extensions",
            "updated": "2023-12-04T02:12:41Z",
            "published": "2023-12-04T02:12:41Z",
            "summary": "Sampling vector and tensor signals is the process of choosing sites in\nvectors and tensors to place sensors in order to effectively recover the whole\nsignals from a limited number of observations by solving linear inverse\nproblems (LIPs). Here, we present closed-form multilinear extensions for the\nframe potential of pruned matrices, and based on these, we develop an algorithm\nnamed fast Frank-Wolfe algorithm for sampling vectors and tensors with low\ncomplexity. Then we provide the approximation factor of our proposed algorithm\nfor a special class of sampling matrices. Then, we conduct experiments to\nverify the higher performance and lower complexity of our proposed algorithm.\nFinally, we demonstrate that FFW sampling and least squares reconstruction\nyield superior results for image data compared to convCNP completion with\nrandom sampling.",
            "author": [
                "Hao Li",
                "Dong Liang",
                "Zixi Zhou",
                "Zheng Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01574v1",
                "http://arxiv.org/pdf/2312.01574v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01573v1",
            "title": "Survey on deep learning in multimodal medical imaging for cancer\n  detection",
            "updated": "2023-12-04T02:07:47Z",
            "published": "2023-12-04T02:07:47Z",
            "summary": "The task of multimodal cancer detection is to determine the locations and\ncategories of lesions by using different imaging techniques, which is one of\nthe key research methods for cancer diagnosis. Recently, deep learning-based\nobject detection has made significant developments due to its strength in\nsemantic feature extraction and nonlinear function fitting. However, multimodal\ncancer detection remains challenging due to morphological differences in\nlesions, interpatient variability, difficulty in annotation, and imaging\nartifacts. In this survey, we mainly investigate over 150 papers in recent\nyears with respect to multimodal cancer detection using deep learning, with a\nfocus on datasets and solutions to various challenges such as data annotation,\nvariance between classes, small-scale lesions, and occlusion. We also provide\nan overview of the advantages and drawbacks of each approach. Finally, we\ndiscuss the current scope of work and provide directions for the future\ndevelopment of multimodal cancer detection.",
            "author": [
                "Yan Tian",
                "Zhaocheng Xu",
                "Yujun Ma",
                "Weiping Ding",
                "Ruili Wang",
                "Zhihong Gao",
                "Guohua Cheng",
                "Linyang He",
                "Xuran Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01573v1",
                "http://arxiv.org/pdf/2312.01573v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01571v1",
            "title": "How to Configure Good In-Context Sequence for Visual Question Answering",
            "updated": "2023-12-04T02:03:23Z",
            "published": "2023-12-04T02:03:23Z",
            "summary": "Inspired by the success of Large Language Models in dealing with new tasks\nvia In-Context Learning (ICL) in NLP, researchers have also developed Large\nVision-Language Models (LVLMs) with ICL capabilities. However, when\nimplementing ICL using these LVLMs, researchers usually resort to the simplest\nway like random sampling to configure the in-context sequence, thus leading to\nsub-optimal results. To enhance the ICL performance, in this study, we use\nVisual Question Answering (VQA) as case study to explore diverse in-context\nconfigurations to find the powerful ones. Additionally, through observing the\nchanges of the LVLM outputs by altering the in-context sequence, we gain\ninsights into the inner properties of LVLMs, improving our understanding of\nthem. Specifically, to explore in-context configurations, we design diverse\nretrieval methods and employ different strategies to manipulate the retrieved\ndemonstrations. Through exhaustive experiments on three VQA datasets: VQAv2,\nVizWiz, and OK-VQA, we uncover three important inner properties of the applied\nLVLM and demonstrate which strategies can consistently improve the ICL VQA\nperformance. Our code is provided in:\nhttps://github.com/GaryJiajia/OFv2_ICL_VQA.",
            "author": [
                "Li Li",
                "Jiawei Peng",
                "Huiyi Chen",
                "Chongyang Gao",
                "Xu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01571v1",
                "http://arxiv.org/pdf/2312.01571v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01568v1",
            "title": "Multimodal Speech Emotion Recognition Using Modality-specific\n  Self-Supervised Frameworks",
            "updated": "2023-12-04T01:49:24Z",
            "published": "2023-12-04T01:49:24Z",
            "summary": "Emotion recognition is a topic of significant interest in assistive robotics\ndue to the need to equip robots with the ability to comprehend human behavior,\nfacilitating their effective interaction in our society. Consequently,\nefficient and dependable emotion recognition systems supporting optimal\nhuman-machine communication are required. Multi-modality (including speech,\naudio, text, images, and videos) is typically exploited in emotion recognition\ntasks. Much relevant research is based on merging multiple data modalities and\ntraining deep learning models utilizing low-level data representations.\nHowever, most existing emotion databases are not large (or complex) enough to\nallow machine learning approaches to learn detailed representations. This paper\nexplores modalityspecific pre-trained transformer frameworks for\nself-supervised learning of speech and text representations for data-efficient\nemotion recognition while achieving state-of-the-art performance in recognizing\nemotions. This model applies feature-level fusion using nonverbal cue data\npoints from motion capture to provide multimodal speech emotion recognition.\nThe model was trained using the publicly available IEMOCAP dataset, achieving\nan overall accuracy of 77.58% for four emotions, outperforming state-of-the-art\napproaches",
            "author": [
                "Rutherford Agbeshi Patamia",
                "Paulo E. Santos",
                "Kingsley Nketia Acheampong",
                "Favour Ekong",
                "Kwabena Sarpong",
                "She Kun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01568v1",
                "http://arxiv.org/pdf/2312.01568v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01566v1",
            "title": "Coronary Atherosclerotic Plaque Characterization with Photon-counting\n  CT: a Simulation-based Feasibility Study",
            "updated": "2023-12-04T01:47:00Z",
            "published": "2023-12-04T01:47:00Z",
            "summary": "Recent development of photon-counting CT (PCCT) brings great opportunities\nfor plaque characterization with much-improved spatial resolution and spectral\nimaging capability. While existing coronary plaque PCCT imaging results are\nbased on detectors made of CZT or CdTe materials, deep-silicon photon-counting\ndetectors have unique performance characteristics and promise distinct imaging\ncapabilities. In this work, we report a systematic simulation study of a\ndeep-silicon PCCT scanner with a new clinically-relevant digital plaque phantom\nwith realistic geometrical parameters and chemical compositions. This work\ninvestigates the effects of spatial resolution, noise, motion artifacts,\nradiation dose, and spectral characterization. Our simulation results suggest\nthat the deep-silicon PCCT design provides adequate spatial resolution for\nvisualizing a necrotic core and quantitation of key plaque features. Advanced\ndenoising techniques and aggressive bowtie filter designs can keep image noise\nto acceptable levels at this resolution while keeping radiation dose comparable\nto that of a conventional CT scan. The ultrahigh resolution of PCCT also means\nan elevated sensitivity to motion artifacts. It is found that a tolerance of\nless than 0.4 mm residual movement range requires the application of accurate\nmotion correction methods for best plaque imaging quality with PCCT.",
            "author": [
                "Mengzhou Li",
                "Mingye Wu",
                "Jed Pack",
                "Pengwei Wu",
                "Bruno De Man",
                "Adam Wang",
                "Koen Nieman",
                "Ge Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01566v1",
                "http://arxiv.org/pdf/2312.01566v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01564v1",
            "title": "APoLLo: Unified Adapter and Prompt Learning for Vision Language Models",
            "updated": "2023-12-04T01:42:09Z",
            "published": "2023-12-04T01:42:09Z",
            "summary": "The choice of input text prompt plays a critical role in the performance of\nVision-Language Pretrained (VLP) models such as CLIP. We present APoLLo, a\nunified multi-modal approach that combines Adapter and Prompt learning for\nVision-Language models. Our method is designed to substantially improve the\ngeneralization capabilities of VLP models when they are fine-tuned in a\nfew-shot setting. We introduce trainable cross-attention-based adapter layers\nin conjunction with vision and language encoders to strengthen the alignment\nbetween the two modalities. We enforce consistency between the respective\nencoder branches (receiving augmented inputs) to prevent overfitting in\ndownstream tasks. Our method is evaluated on three representative tasks:\ngeneralization to novel classes, cross-dataset evaluation, and unseen domain\nshifts. In practice, APoLLo achieves a relative gain up to 6.03% over MaPLe\n(SOTA) on novel classes for 10 diverse image recognition datasets.",
            "author": [
                "Sanjoy Chowdhury",
                "Sayan Nag",
                "Dinesh Manocha"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01564v1",
                "http://arxiv.org/pdf/2312.01564v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01558v1",
            "title": "Hyperspectral Image Compression Using Sampling and Implicit Neural\n  Representations",
            "updated": "2023-12-04T01:10:04Z",
            "published": "2023-12-04T01:10:04Z",
            "summary": "Hyperspectral images, which record the electromagnetic spectrum for a pixel\nin the image of a scene, often store hundreds of channels per pixel and contain\nan order of magnitude more information than a similarly-sized RBG color image.\nConsequently, concomitant with the decreasing cost of capturing these images,\nthere is a need to develop efficient techniques for storing, transmitting, and\nanalyzing hyperspectral images. This paper develops a method for hyperspectral\nimage compression using implicit neural representations where a multilayer\nperceptron network F with sinusoidal activation functions \"learns\" to map pixel\nlocations to pixel intensities for a given hyperspectral image I. F thus acts\nas a compressed encoding of this image, and the original image is reconstructed\nby evaluating F at each pixel location. We use a sampling method with two\nfactors: window size and sampling rate to reduce the compression time. We have\nevaluated our method on four benchmarks -- Indian Pines, Jasper Ridge, Pavia\nUniversity, and Cuprite using PSNR and SSIM -- and we show that the proposed\nmethod achieves better compression than JPEG, JPEG2000, and PCA-DCT at low\nbitrates. Besides, we compare our results with the learning-based methods like\nPCA+JPEG2000, FPCA+JPEG2000, 3D DCT, 3D DWT+SVR, and WSRC and show the\ncorresponding results in the \"Compression Results\" section. We also show that\nour methods with sampling achieve better speed and performance than our method\nwithout sampling.",
            "author": [
                "Shima Rezasoltani",
                "Faisal Z. Qureshi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01558v1",
                "http://arxiv.org/pdf/2312.01558v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01554v2",
            "title": "Building Ears for Robots: Machine Hearing in the Age of Autonomy",
            "updated": "2023-12-05T06:06:52Z",
            "published": "2023-12-04T00:52:18Z",
            "summary": "This study explores the significance of robot hearing systems, emphasizing\ntheir importance for robots operating in diverse and uncertain environments. It\nintroduces the hardware design principles using robotaxis as an example, where\nexterior microphone arrays are employed to detect sound events such as sirens.\nThe challenges, goals, and test methods are discussed, focusing on achieving a\nsuitable signal-to-noise ratio (SNR). Additionally, it presents a preliminary\nsoftware framework rooted in probabilistic robotics theory, advocating for the\nintegration of robot hearing into the broader context of perception and\ndecision-making. It discusses various models, including Bayes filters,\npartially observable Markov decision processes (POMDP), and multiagent systems,\nhighlighting the multifaceted roles that robot hearing can play. In conclusion,\nas service robots continue to evolve, robot hearing research will expand,\noffering new perspectives and challenges for future development beyond simple\nsound event classification.",
            "author": [
                "Xuan Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01554v2",
                "http://arxiv.org/pdf/2312.01554v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.RO",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01552v1",
            "title": "The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context\n  Learning",
            "updated": "2023-12-04T00:46:11Z",
            "published": "2023-12-04T00:46:11Z",
            "summary": "The alignment tuning process of large language models (LLMs) typically\ninvolves instruction learning through supervised fine-tuning (SFT) and\npreference tuning via reinforcement learning from human feedback (RLHF). A\nrecent study, LIMA (Zhou et al. 2023), shows that using merely 1K examples for\nSFT can achieve significant alignment performance as well, suggesting that the\neffect of alignment tuning might be \"superficial.\" This raises questions about\nhow exactly the alignment tuning transforms a base LLM.\n  We analyze the effect of alignment tuning by examining the token distribution\nshift between base LLMs and their aligned counterpart. Our findings reveal that\nbase LLMs and their alignment-tuned versions perform nearly identically in\ndecoding on the majority of token positions. Most distribution shifts occur\nwith stylistic tokens. These direct evidence strongly supports the Superficial\nAlignment Hypothesis suggested by LIMA.\n  Based on these findings, we rethink the alignment of LLMs by posing the\nresearch question: how effectively can we align base LLMs without SFT or RLHF?\nTo address this, we introduce a simple, tuning-free alignment method, URIAL.\nURIAL achieves effective alignment purely through in-context learning (ICL)\nwith base LLMs, requiring as few as three constant stylistic examples and a\nsystem prompt. We conduct a fine-grained and interpretable evaluation on a\ndiverse set of examples, named JUST-EVAL-INSTRUCT. Results demonstrate that\nbase LLMs with URIAL can match or even surpass the performance of LLMs aligned\nwith SFT or SFT+RLHF. We show that the gap between tuning-free and tuning-based\nalignment methods can be significantly reduced through strategic prompting and\nICL. Our findings on the superficial nature of alignment tuning and results\nwith URIAL suggest that deeper analysis and theoretical understanding of\nalignment is crucial to future LLM research.",
            "author": [
                "Bill Yuchen Lin",
                "Abhilasha Ravichander",
                "Ximing Lu",
                "Nouha Dziri",
                "Melanie Sclar",
                "Khyathi Chandu",
                "Chandra Bhagavatula",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01552v1",
                "http://arxiv.org/pdf/2312.01552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01550v2",
            "title": "Using human and robot synthetic data for training smart hand tools",
            "updated": "2023-12-05T16:44:06Z",
            "published": "2023-12-04T00:42:25Z",
            "summary": "The future of work does not require a choice between human and robot. Aside\nfrom explicit human-robot collaboration, robotics can play an increasingly\nimportant role in helping train workers as well as the tools they may use,\nespecially in complex tasks that may be difficult to automate or effectively\nroboticize. This paper introduces a form of smart tool for use by human workers\nand shows how training the tool for task recognition, one of the key\nrequirements, can be accomplished. Machine learning (ML) with purely\nhuman-based data can be extremely laborious and time-consuming. First, we show\nhow data synthetically-generated by a robot can be leveraged in the ML training\nprocess. Later, we demonstrate how fine-tuning ML models for individual\nphysical tasks and workers can significantly scale up the benefits of using ML\nto provide this feedback. Experimental results show the effectiveness and\nscalability of our approach, as we test data size versus accuracy. Smart hand\ntools of the type introduced here can provide insights and real-time analytics\non efficient and safe tool usage and operation, thereby enhancing human\nparticipation and skill in a wide range of work environments. Using robotic\nplatforms to help train smart tools will be essential, particularly given the\ndiverse types of applications for which smart hand tools are envisioned for\nhuman use.",
            "author": [
                "Jose Bendana",
                "Sundar Sripada V. S.",
                "Carlos D. Salazar",
                "Sandeep Chinchali",
                "Raul G. Longoria"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01550v2",
                "http://arxiv.org/pdf/2312.01550v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01548v1",
            "title": "Tomographic projection optimization for volumetric additive\n  manufacturing with general band constraint Lp-norm minimization",
            "updated": "2023-12-04T00:36:11Z",
            "published": "2023-12-04T00:36:11Z",
            "summary": "Tomographic volumetric additive manufacturing is a rapidly growing\nfabrication technology that enables rapid production of 3D objects through a\nsingle build step. In this process, the design of projections directly impacts\ngeometric resolution, material properties, and manufacturing yield of the final\nprinted part. Herein, we identify the hidden equivalent operations of three\nmajor existing projection optimization schemes and reformulate them into a\ngeneral loss function where the optimization behavior can be systematically\nstudied, and unique capabilities of the individual schemes can coalesce. The\nloss function formulation proposed in this study unified the optimization for\nbinary and greyscale targets and relaxed the problem through local tolerancing\nand local weighting. In addition to features reported in literature, this\nformulation offers global control on error sparsity and consistent\nincorporation of non-linear dose response mapping throughout initialization,\noptimization, and evaluation. A parameter-sweep analysis in this study guides\nusers in tuning optimization parameters for application-specific goals.",
            "author": [
                "Chi Chung Li",
                "Joseph Toombs",
                "Hayden K. Taylor",
                "Thomas J. Wallin"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01548v1",
                "http://arxiv.org/pdf/2312.01548v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "90C26",
                "J.2; J.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01546v1",
            "title": "Learning Channel Capacity with Neural Mutual Information Estimator Based\n  on Message Importance Measure",
            "updated": "2023-12-04T00:26:00Z",
            "published": "2023-12-04T00:26:00Z",
            "summary": "Channel capacity estimation plays a crucial role in beyond 5G intelligent\ncommunications. Despite its significance, this task is challenging for a\nmajority of channels, especially for the complex channels not modeled as the\nwell-known typical ones. Recently, neural networks have been used in mutual\ninformation estimation and optimization. They are particularly considered as\nefficient tools for learning channel capacity. In this paper, we propose a\ncooperative framework to simultaneously estimate channel capacity and design\nthe optimal codebook. First, we will leverage MIM-based GAN, a novel form of\ngenerative adversarial network (GAN) using message importance measure (MIM) as\nthe information distance, into mutual information estimation, and develop a\nnovel method, named MIM-based mutual information estimator (MMIE). Then, we\ndesign a generalized cooperative framework for channel capacity learning, in\nwhich a generator is regarded as an encoder producing the channel input, while\na discriminator is the mutual information estimator that assesses the\nperformance of the generator. Through the adversarial training, the generator\nautomatically learns the optimal codebook and the discriminator estimates the\nchannel capacity. Numerical experiments will demonstrate that compared with\nseveral conventional estimators, the MMIE achieves state-of-the-art performance\nin terms of accuracy and stability.",
            "author": [
                "Zhefan Li",
                "Rui She",
                "Pingyi Fan",
                "Chenghui Peng",
                "Khaled B. Letaief"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01546v1",
                "http://arxiv.org/pdf/2312.01546v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02225v1",
            "title": "Digital Histopathology with Graph Neural Networks: Concepts and\n  Explanations for Clinicians",
            "updated": "2023-12-04T00:20:50Z",
            "published": "2023-12-04T00:20:50Z",
            "summary": "To address the challenge of the ``black-box\" nature of deep learning in\nmedical settings, we combine GCExplainer - an automated concept discovery\nsolution - along with Logic Explained Networks to provide global explanations\nfor Graph Neural Networks. We demonstrate this using a generally applicable\ngraph construction and classification pipeline, involving panoptic segmentation\nwith HoVer-Net and cancer prediction with Graph Convolution Networks. By\ntraining on H&E slides of breast cancer, we show promising results in offering\nexplainable and trustworthy AI tools for clinicians.",
            "author": [
                "Alessandro Farace di Villaforesta",
                "Lucie Charlotte Magister",
                "Pietro Barbiero",
                "Pietro Li\u00f2"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02225v1",
                "http://arxiv.org/pdf/2312.02225v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01545v1",
            "title": "Diverse Entanglement Mechanisms in Multimode Nonlinear Continuous\n  Variables",
            "updated": "2023-12-04T00:20:43Z",
            "published": "2023-12-04T00:20:43Z",
            "summary": "Non-Gaussian entangled states play a crucial role in harnessing quantum\nadvantage in continuous-variable quantum information. However, how to fully\ncharacterize N-partite (N > 3) non-Gaussian entanglement without quantum state\ntomography remains elusive, leading to a very limited understanding of the\nunderlying entanglement mechanism. Here, we propose several necessary and\nsufficient conditions for the positive-partial-transposition separability of\nmultimode nonlinear quantum states resulting from high-order Hamiltonians and\nsuccessive beam splitting operations. When applied to the initial state, the\nbeam-splitter operations induce the emergence of different types of\nentanglement mechanisms, including pairwise high-order entanglement, collective\nhigh-order entanglement and the crossover between the two. We show numerically\nthat for the four-mode scenario, the threshold for the existence of\nentanglement for any bipartition does not exceed the entanglement of the\noriginal state at fixed high-order moments. These results provide a new\nperspective for understanding multipartite nonlinear entanglement and will\npromote their application in quantum information processing.",
            "author": [
                "Da Zhang",
                "David Barral",
                "Yanpeng Zhang",
                "Kamel Bencheikh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01545v1",
                "http://arxiv.org/pdf/2312.01545v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01543v1",
            "title": "Torso-Based Control Interface for Standing Mobility-Assistive Devices",
            "updated": "2023-12-04T00:11:14Z",
            "published": "2023-12-04T00:11:14Z",
            "summary": "Wheelchairs and mobility devices have transformed our bodies into cybernic\nsystems, extending our well-being by enabling individuals with reduced mobility\nto regain freedom. Notwithstanding, current interfaces of control require to\nuse the hands, therefore constraining the user from performing functional\nactivities of daily living. In this work, we present a unique design of\ntorso-based control interface with compliant coupling support for standing\nmobility assistive devices. We take the coupling between the human and robot\ninto consideration in the interface design. The design includes a compliant\nsupport mechanism and a mapping between the body movement space and the\nvelocity space. We present experiments including multiple conditions, with a\njoystick for comparison with the proposed torso control interface. The results\nof a path-following experiment showed that users were able to control the\ndevice naturally using the hands-free interface, and the performance was\ncomparable with the joystick, with 10% more consumed time, an average cross\nerror of 0.116 m and 4.9% less average acceleration. The result of an\nobject-transferring experiment showed the advantage of using the proposed\ninterface in case users needed to manipulate objects while locomotion. The\ntorso control scored 15% less in the System Usability Scale than the joystick\nin the path following task but 3.3% more in the object transferring task.",
            "author": [
                "Yang Chen",
                "Diego Paez-Granados",
                "Modar Hassan",
                "Kenji Suzuki"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01543v1",
                "http://arxiv.org/pdf/2312.01543v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01538v1",
            "title": "Recurrent Distance-Encoding Neural Networks for Graph Representation\n  Learning",
            "updated": "2023-12-03T23:36:16Z",
            "published": "2023-12-03T23:36:16Z",
            "summary": "Graph neural networks based on iterative one-hop message passing have been\nshown to struggle in harnessing information from distant nodes effectively.\nConversely, graph transformers allow each node to attend to all other nodes\ndirectly, but suffer from high computational complexity and have to rely on\nad-hoc positional encoding to bake in the graph inductive bias. In this paper,\nwe propose a new architecture to reconcile these challenges. Our approach stems\nfrom the recent breakthroughs in long-range modeling provided by deep\nstate-space models on sequential data: for a given target node, our model\naggregates other nodes by their shortest distances to the target and uses a\nparallelizable linear recurrent network over the chain of distances to provide\na natural encoding of its neighborhood structure. With no need for positional\nencoding, we empirically show that the performance of our model is highly\ncompetitive compared with that of state-of-the-art graph transformers on\nvarious benchmarks, at a drastically reduced computational complexity. In\naddition, we show that our model is theoretically more expressive than one-hop\nmessage passing neural networks.",
            "author": [
                "Yuhui Ding",
                "Antonio Orvieto",
                "Bobby He",
                "Thomas Hofmann"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01538v1",
                "http://arxiv.org/pdf/2312.01538v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01537v1",
            "title": "Unlocking the Potential of Federated Learning: The Symphony of Dataset\n  Distillation via Deep Generative Latents",
            "updated": "2023-12-03T23:30:48Z",
            "published": "2023-12-03T23:30:48Z",
            "summary": "Data heterogeneity presents significant challenges for federated learning\n(FL). Recently, dataset distillation techniques have been introduced, and\nperformed at the client level, to attempt to mitigate some of these challenges.\nIn this paper, we propose a highly efficient FL dataset distillation framework\non the server side, significantly reducing both the computational and\ncommunication demands on local devices while enhancing the clients' privacy.\nUnlike previous strategies that perform dataset distillation on local devices\nand upload synthetic data to the server, our technique enables the server to\nleverage prior knowledge from pre-trained deep generative models to synthesize\nessential data representations from a heterogeneous model architecture. This\nprocess allows local devices to train smaller surrogate models while enabling\nthe training of a larger global model on the server, effectively minimizing\nresource utilization. We substantiate our claim with a theoretical analysis,\ndemonstrating the asymptotic resemblance of the process to the hypothetical\nideal of completely centralized training on a heterogeneous dataset. Empirical\nevidence from our comprehensive experiments indicates our method's superiority,\ndelivering an accuracy enhancement of up to 40% over non-dataset-distillation\ntechniques in highly heterogeneous FL contexts, and surpassing existing\ndataset-distillation methods by 18%. In addition to the high accuracy, our\nframework converges faster than the baselines because rather than the server\ntrains on several sets of heterogeneous data distributions, it trains on a\nmulti-modal distribution. Our code is available at\nhttps://github.com/FedDG23/FedDG-main.git",
            "author": [
                "Yuqi Jia",
                "Saeed Vahidian",
                "Jingwei Sun",
                "Jianyi Zhang",
                "Vyacheslav Kungurtsev",
                "Neil Zhenqiang Gong",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01537v1",
                "http://arxiv.org/pdf/2312.01537v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01534v1",
            "title": "Skeletal Cut Loci on Convex Polyhedra",
            "updated": "2023-12-03T23:25:58Z",
            "published": "2023-12-03T23:25:58Z",
            "summary": "The cut locus C(x) on a convex polyhedron P with respect to a point x is a\ntree of geodesic segments (shortest paths) on P that includes every vertex. In\ngeneral, edges of C(x) are not edges of P, i.e., not part of the 1-skeleton\nSk(P) of P. We say that P has a *skeletal cut locus* if there is some x in P\nsuch that C(x) is a subset of Sk(P). In this paper we study skeletal cut loci,\nobtaining three main results.\n  First, given any combinatorial tree T , there exists a convex polyhedron P\nand a point x with a skeletal cut locus that matches the combinatorics of T.\nSecond, any (non-degenerate) polyhedron P has at most a finite number of points\nx for which C(x) is a subset of Sk(P). Third, we show that almost all polyhedra\nhave no skeletal cut locus.\n  Because the source unfolding of P with respect to x is always a\nnon-overlapping net for P, and because the boundary of the source unfolding is\nthe (unfolded) cut locus, source unfoldings of polyhedra with skeletal cut loci\nare edge-unfoldings, and moreover \"blooming,\" avoiding self-intersection during\nan unfolding process.",
            "author": [
                "Joseph O'Rourke",
                "Costin Vilcu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01534v1",
                "http://arxiv.org/pdf/2312.01534v1"
            ],
            "primary_category": "cs.CG",
            "category": [
                "cs.CG",
                "math.MG",
                "52B10, 52C99",
                "F.2.2; G.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01532v1",
            "title": "Using Large Language Models to Accelerate Communication for Users with\n  Severe Motor Impairments",
            "updated": "2023-12-03T23:12:49Z",
            "published": "2023-12-03T23:12:49Z",
            "summary": "Finding ways to accelerate text input for individuals with profound motor\nimpairments has been a long-standing area of research. Closing the speed gap\nfor augmentative and alternative communication (AAC) devices such as\neye-tracking keyboards is important for improving the quality of life for such\nindividuals. Recent advances in neural networks of natural language pose new\nopportunities for re-thinking strategies and user interfaces for enhanced\ntext-entry for AAC users. In this paper, we present SpeakFaster, consisting of\nlarge language models (LLMs) and a co-designed user interface for text entry in\na highly-abbreviated form, allowing saving 57% more motor actions than\ntraditional predictive keyboards in offline simulation. A pilot study with 19\nnon-AAC participants typing on a mobile device by hand demonstrated gains in\nmotor savings in line with the offline simulation, while introducing relatively\nsmall effects on overall typing speed. Lab and field testing on two eye-gaze\ntyping users with amyotrophic lateral sclerosis (ALS) demonstrated text-entry\nrates 29-60% faster than traditional baselines, due to significant saving of\nexpensive keystrokes achieved through phrase and word predictions from\ncontext-aware LLMs. These findings provide a strong foundation for further\nexploration of substantially-accelerated text communication for motor-impaired\nusers and demonstrate a direction for applying LLMs to text-based user\ninterfaces.",
            "author": [
                "Shanqing Cai",
                "Subhashini Venugopalan",
                "Katie Seaver",
                "Xiang Xiao",
                "Katrin Tomanek",
                "Sri Jalasutram",
                "Meredith Ringel Morris",
                "Shaun Kane",
                "Ajit Narayanan",
                "Robert L. MacDonald",
                "Emily Kornman",
                "Daniel Vance",
                "Blair Casey",
                "Steve M. Gleason",
                "Philip Q. Nelson",
                "Michael P. Brenner"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01532v1",
                "http://arxiv.org/pdf/2312.01532v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01529v2",
            "title": "T3D: Towards 3D Medical Image Understanding through Vision-Language\n  Pre-training",
            "updated": "2023-12-05T09:01:07Z",
            "published": "2023-12-03T23:03:22Z",
            "summary": "Expert annotation of 3D medical image for downstream analysis is\nresource-intensive, posing challenges in clinical applications. Visual\nself-supervised learning (vSSL), though effective for learning visual\ninvariance, neglects the incorporation of domain knowledge from medicine. To\nincorporate medical knowledge into visual representation learning,\nvision-language pre-training (VLP) has shown promising results in 2D image.\nHowever, existing VLP approaches become generally impractical when applied to\nhigh-resolution 3D medical images due to GPU hardware constraints and the\npotential loss of critical details caused by downsampling, which is the\nintuitive solution to hardware constraints. To address the above limitations,\nwe introduce T3D, the first VLP framework designed for high-resolution 3D\nmedical images. T3D incorporates two text-informed pretext tasks:\n(\\lowerromannumeral{1}) text-informed contrastive learning;\n(\\lowerromannumeral{2}) text-informed image restoration. These tasks focus on\nlearning 3D visual representations from high-resolution 3D medical images and\nintegrating clinical knowledge from radiology reports, without distorting\ninformation through forced alignment of downsampled volumes with detailed\nanatomical text. Trained on a newly curated large-scale dataset of 3D medical\nimages and radiology reports, T3D significantly outperforms current vSSL\nmethods in tasks like organ and tumor segmentation, as well as disease\nclassification. This underlines T3D's potential in representation learning for\n3D medical image analysis. All data and code will be available upon acceptance.",
            "author": [
                "Che Liu",
                "Cheng Ouyang",
                "Yinda Chen",
                "Cesar C\u00e9sar Quilodr\u00e1n-Casas",
                "Lei Ma",
                "Jie Fu",
                "Yike Guo",
                "Anand Shah",
                "Wenjia Bai",
                "Rossella Arcucci"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01529v2",
                "http://arxiv.org/pdf/2312.01529v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01525v1",
            "title": "$Z_3$ symmetry of the CKM and PMNS matrices",
            "updated": "2023-12-03T22:48:49Z",
            "published": "2023-12-03T22:48:49Z",
            "summary": "We develop for the CKM and PMNS matrices a new representation with special\nproperties. It is obtained by splitting each of these matrices into two\nrotations by the angle ${\\sim}2\\pi/3$ and a universal diagonal matrix with\nelements, which are cubic roots of~1. Such a representation of the CKM and PMNS\nmatrices may indicate the $Z_{3}$ symmetry to be present in the Yukawa sector\nof the~SM. Identical mathematical structure of the CKM and PMNS matrices is\nalso an extension of the quark-lepton universality. In this approach the CP\nviolation is a natural consequence of the structure of the Yukawa couplings.\nThe CP violating phase is not a fitted parameter and its value is governed by\nthe parameters of two rotations. The parameters of the diagonalizing matrices\nof the bi-unitary transformation do not exhibit a hierarchy, which means that\nthe origins of the hierarchy of quark masses and of the CKM matrix elements are\nnot the same.",
            "author": [
                "Piotr Kielanowski",
                "S. Rebeca Ju\u00e1rez Wysozka",
                "Liliana V\u00e1zquez Mercado"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01525v1",
                "http://arxiv.org/pdf/2312.01525v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01524v1",
            "title": "Code Swarm: A Code Generation Tool Based on the Automatic Derivation of\n  Transformation Rule Set",
            "updated": "2023-12-03T22:47:42Z",
            "published": "2023-12-03T22:47:42Z",
            "summary": "Automatic generation of software code from system design models remains an\nactively explored research area for the past several years. A number of tools\nare currently available to facilitate and automate the task of generating code\nfrom software models. To the best of our knowledge, existing software tools\nrely on an explicitly defined transformation rule set to perform the\nmodel-to-code transformation process. In this paper, we introduce a novel tool\nnamed Code Swarm, abbreviated as CodS, that automatically generates\nimplementation code from system design models by utilizing a swarm-based\napproach. Specifically, CodS is capable of generating Java code from the class\nand state models of the software system by making use of the previously solved\nmodel-to-code transformation examples. Our tool enables the designers to\nspecify behavioural actions in the input models using the Action Specification\nLanguage (ASL). We use an industrial case study of the Elevator Control System\n(ECS) to perform the experimental validation of our tool. Our results indicate\nthat the code generated by CodS is correct and consistent with the input design\nmodels. CodS performs the process of automatic code generation without taking\nthe explicit transformation rule set or languages metamodels information as\ninput, which distinguishes it from all the existing automatic code generation\ntools.",
            "author": [
                "Hina Mahmood",
                "Atif Aftab Jilani",
                "Abdul Rauf"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01524v1",
                "http://arxiv.org/pdf/2312.01524v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01523v1",
            "title": "SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise",
            "updated": "2023-12-03T22:44:58Z",
            "published": "2023-12-03T22:44:58Z",
            "summary": "In this paper, we introduce a novel fine-tuning technique for language\nmodels, which involves incorporating symmetric noise into the embedding\nprocess. This method aims to enhance the model's function by more stringently\nregulating its local curvature, demonstrating superior performance over the\ncurrent method, NEFTune. When fine-tuning the LLaMA-2-7B model using Alpaca,\nstandard techniques yield a 29.79% score on AlpacaEval. However, our approach,\nSymNoise, increases this score significantly to 69.04%, using symmetric noisy\nembeddings. This is a 6.7% improvement over the state-of-the-art method,\nNEFTune~(64.69%). Furthermore, when tested on various models and stronger\nbaseline instruction datasets, such as Evol-Instruct, ShareGPT, OpenPlatypus,\nSymNoise consistently outperforms NEFTune. The current literature, including\nNEFTune, has underscored the importance of more in-depth research into the\napplication of noise-based strategies in the fine-tuning of language models.\nOur approach, SymNoise, is another significant step towards this direction,\nshowing notable improvement over the existing state-of-the-art method.",
            "author": [
                "Arjun Singh",
                "Abhay Kumar Yadav"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01523v1",
                "http://arxiv.org/pdf/2312.01523v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01522v1",
            "title": "G2D: From Global to Dense Radiography Representation Learning via\n  Vision-Language Pre-training",
            "updated": "2023-12-03T22:44:04Z",
            "published": "2023-12-03T22:44:04Z",
            "summary": "Recently, medical vision-language pre-training (VLP) has reached substantial\nprogress to learn global visual representation from medical images and their\npaired radiology reports. However, medical imaging tasks in real world usually\nrequire finer granularity in visual features. These tasks include visual\nlocalization tasks (e.g., semantic segmentation, object detection) and visual\ngrounding task. Yet, current medical VLP methods face challenges in learning\nthese fine-grained features, as they primarily focus on brute-force alignment\nbetween image patches and individual text tokens for local visual feature\nlearning, which is suboptimal for downstream dense prediction tasks. In this\nwork, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense\nlevel representation learning (G2D) that achieves significantly improved\ngranularity and more accurate grounding for the learned features, compared to\nexisting medical VLP approaches. In particular, G2D learns dense and\nsemantically-grounded image representations via a pseudo segmentation task\nparallel with the global vision-language alignment. Notably, generating pseudo\nsegmentation targets does not incur extra trainable parameters: they are\nobtained on the fly during VLP with a parameter-free processor. G2D achieves\nsuperior performance across 6 medical imaging tasks and 25 diseases,\nparticularly in semantic segmentation, which necessitates fine-grained,\nsemantically-grounded image features. In this task, G2D surpasses peer models\neven when fine-tuned with just 1\\% of the training data, compared to the 100\\%\nused by these models. The code will be released upon acceptance.",
            "author": [
                "Che Liu",
                "Cheng Ouyang",
                "Sibo Cheng",
                "Anand Shah",
                "Wenjia Bai",
                "Rossella Arcucci"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01522v1",
                "http://arxiv.org/pdf/2312.01522v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01518v1",
            "title": "Analyzing State-Level Longevity Trends with the U.S. Mortality Database",
            "updated": "2023-12-03T22:23:09Z",
            "published": "2023-12-03T22:23:09Z",
            "summary": "We investigate state-level age-specific mortality trends based on the United\nStates Mortality Database (USMDB) published by the Human Mortality Database. In\ntandem with looking at the longevity experience across the 51 states, we also\nconsider a collection of socio-demographic, economic and educational covariates\nthat correlate with mortality trends. To obtain smoothed mortality surfaces for\neach state, we implement the machine learning framework of Multi-Output\nGaussian Process regression (Huynh \\& Ludkovski 2021) on targeted groupings of\n3--6 states. Our detailed exploratory analysis shows that the mortality\nexperience is highly inhomogeneous across states in terms of respective Age\nstructures. We moreover document multiple divergent trends between best and\nworst states, between Females and Males, and between younger and older Ages.\nThe comparisons across the 50+ fitted models offer opportunities for rich\ninsights about drivers of mortality in the U.S. and are visualized through\nnumerous figures and an online interactive dashboard.",
            "author": [
                "Mike Ludkovski",
                "Doris Padilla"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01518v1",
                "http://arxiv.org/pdf/2312.01518v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01515v1",
            "title": "Bigger is not Always Better: The Effect of Context Size on Speech\n  Pre-Training",
            "updated": "2023-12-03T22:08:54Z",
            "published": "2023-12-03T22:08:54Z",
            "summary": "It has been generally assumed in the automatic speech recognition (ASR)\nliterature that it is better for models to have access to wider context\nwindows. Yet, many of the potential reasons this might be true in the\nsupervised setting do not necessarily transfer over to the case of unsupervised\nlearning. We investigate how much context is necessary to achieve high-quality\npre-trained acoustic models using self-supervised learning. We principally\ninvestigate contrastive predictive coding (CPC), which we adapt to be able to\nprecisely control the amount of context visible to the model during training\nand inference. We find that phone discriminability in the resulting model\nrepresentations peaks at around 40~ms of preceding context, and that having too\nmuch context (beyond around 320 ms) substantially degrades the quality of the\nrepresentations. Surprisingly, we find that this pattern also transfers to\nsupervised ASR when the pre-trained representations are used as frozen input\nfeatures. Our results point to potential changes in the design of current\nupstream architectures to better facilitate a variety of downstream tasks.",
            "author": [
                "Sean Robertson",
                "Ewan Dunbar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01515v1",
                "http://arxiv.org/pdf/2312.01515v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01510v1",
            "title": "WindCline: Sloping Wind Tunnel for Characterizing Flame Behavior Under\n  Variable Inclines and Wind Conditions",
            "updated": "2023-12-03T21:26:36Z",
            "published": "2023-12-03T21:26:36Z",
            "summary": "Developing accurate computational models of wildfire dynamics is increasingly\nimportant due to the substantial and expanding negative impacts of wildfire\nevents on human health, infrastructure, and the environment. Wildfire spread\nand emissions depend on a number of factors, including fuel type, environmental\nconditions (moisture, wind speed, etc.) and terrain/location. However, there\ncurrently exist only a few experimental facilities that enable testing of the\ninterplay of these factors at length scales <1 m with carefully controlled and\ncharacterized boundary conditions and advanced diagnostics. Experiments\nperformed at such facilities are required for informing and validating\ncomputational models. Here we present the design and characterization of a\nnovel tilting wind tunnel (the 'WindCline') for studying wildfire dynamics. The\nWindCline is unique in that the entire tunnel platform is constructed to pivot\naround a central axis, which enables sloping of the entire system without\ncompromising the quality of the flow properties. In addition, this facility has\na configurable design for the test section and diffuser to accommodate a suite\nof advanced diagnostics to aid in the characterization of 1) the parameters\nneeded to establish boundary conditions and 2) flame properties and dynamics.\nThe WindCline thus allows for measurement and control of several critical\nwildfire variables and boundary conditions, especially at the small length\nscales important to the development of high fidelity computational simulations\n(10 - 100 cm). Computational modeling frameworks developed and validated under\nthese controlled conditions can expand understanding of fundamental combustion\nprocesses, promoting greater confidence when leveraging these processes in\ncomplex combustion environments.",
            "author": [
                "Amanda S. Makowiecki",
                "Sean C. Coburn",
                "Samantha Sheppard",
                "Brendan Bitterlin",
                "Timothy Breda",
                "Abdul Dawlatzai",
                "Robert Giannella",
                "Alexandra Jaros",
                "Christopher Kling",
                "Eric Kolb",
                "Caelan Lapointe",
                "Sam Simons-Wellin",
                "Hope A. Michelsen",
                "John W. Daily",
                "Michael Hannigan",
                "Peter E. Hamlington",
                "John Farnsworth",
                "Gregory B. Rieker"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01510v1",
                "http://arxiv.org/pdf/2312.01510v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01509v1",
            "title": "Tackling Bias in Pre-trained Language Models: Current Trends and\n  Under-represented Societies",
            "updated": "2023-12-03T21:25:10Z",
            "published": "2023-12-03T21:25:10Z",
            "summary": "The benefits and capabilities of pre-trained language models (LLMs) in\ncurrent and future innovations are vital to any society. However, introducing\nand using LLMs comes with biases and discrimination, resulting in concerns\nabout equality, diversity and fairness, and must be addressed. While\nunderstanding and acknowledging bias in LLMs and developing mitigation\nstrategies are crucial, the generalised assumptions towards societal needs can\nresult in disadvantages towards under-represented societies and indigenous\npopulations. Furthermore, the ongoing changes to actual and proposed amendments\nto regulations and laws worldwide also impact research capabilities in tackling\nthe bias problem. This research presents a comprehensive survey synthesising\nthe current trends and limitations in techniques used for identifying and\nmitigating bias in LLMs, where the overview of methods for tackling bias are\ngrouped into metrics, benchmark datasets, and mitigation strategies. The\nimportance and novelty of this survey are that it explores the perspective of\nunder-represented societies. We argue that current practices tackling the bias\nproblem cannot simply be 'plugged in' to address the needs of under-represented\nsocieties. We use examples from New Zealand to present requirements for\nadopting existing techniques to under-represented societies.",
            "author": [
                "Vithya Yogarajan",
                "Gillian Dobbie",
                "Te Taka Keegan",
                "Rostam J. Neuwirth"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01509v1",
                "http://arxiv.org/pdf/2312.01509v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01507v1",
            "title": "Learn2Extend: Extending sequences by retaining their statistical\n  properties with mixture models",
            "updated": "2023-12-03T21:05:50Z",
            "published": "2023-12-03T21:05:50Z",
            "summary": "This paper addresses the challenge of extending general finite sequences of\nreal numbers within a subinterval of the real line, maintaining their inherent\nstatistical properties by employing machine learning. Our focus lies on\npreserving the gap distribution and pair correlation function of these point\nsets. Leveraging advancements in deep learning applied to point processes, this\npaper explores the use of an auto-regressive \\textit{Sequence Extension Mixture\nModel} (SEMM) for extending finite sequences, by estimating directly the\nconditional density, instead of the intensity function. We perform comparative\nexperiments on multiple types of point processes, including Poisson, locally\nattractive, and locally repelling sequences, and we perform a case study on the\nprediction of Riemann $\\zeta$ function zeroes. The results indicate that the\nproposed mixture model outperforms traditional neural network architectures in\nsequence extension with the retention of statistical properties. Given this\nmotivation, we showcase the capabilities of a mixture model to extend\nsequences, maintaining specific statistical properties, i.e. the gap\ndistribution, and pair correlation indicators.",
            "author": [
                "Dimitris Vartziotis",
                "George Dasoulas",
                "Florian Pausinger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01507v1",
                "http://arxiv.org/pdf/2312.01507v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03002v1",
            "title": "The mechanistic basis of data dependence and abrupt learning in an\n  in-context classification task",
            "updated": "2023-12-03T20:53:41Z",
            "published": "2023-12-03T20:53:41Z",
            "summary": "Transformer models exhibit in-context learning: the ability to accurately\npredict the response to a novel query based on illustrative examples in the\ninput sequence. In-context learning contrasts with traditional in-weights\nlearning of query-output relationships. What aspects of the training data\ndistribution and architecture favor in-context vs in-weights learning? Recent\nwork has shown that specific distributional properties inherent in language,\nsuch as burstiness, large dictionaries and skewed rank-frequency distributions,\ncontrol the trade-off or simultaneous appearance of these two forms of\nlearning. We first show that these results are recapitulated in a minimal\nattention-only network trained on a simplified dataset. In-context learning\n(ICL) is driven by the abrupt emergence of an induction head, which\nsubsequently competes with in-weights learning. By identifying progress\nmeasures that precede in-context learning and targeted experiments, we\nconstruct a two-parameter model of an induction head which emulates the full\ndata distributional dependencies displayed by the attention-based network. A\nphenomenological model of induction head formation traces its abrupt emergence\nto the sequential learning of three nested logits enabled by an intrinsic\ncurriculum. We propose that the sharp transitions in attention-based networks\narise due to a specific chain of multi-layer operations necessary to achieve\nICL, which is implemented by nested nonlinearities sequentially learned during\ntraining.",
            "author": [
                "Gautam Reddy"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03002v1",
                "http://arxiv.org/pdf/2312.03002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01504v1",
            "title": "Effectively Fine-tune to Improve Large Multimodal Models for Radiology\n  Report Generation",
            "updated": "2023-12-03T20:42:38Z",
            "published": "2023-12-03T20:42:38Z",
            "summary": "Writing radiology reports from medical images requires a high level of domain\nexpertise. It is time-consuming even for trained radiologists and can be\nerror-prone for inexperienced radiologists. It would be appealing to automate\nthis task by leveraging generative AI, which has shown drastic progress in\nvision and language understanding. In particular, Large Language Models (LLM)\nhave demonstrated impressive capabilities recently and continued to set new\nstate-of-the-art performance on almost all natural language tasks. While many\nhave proposed architectures to combine vision models with LLMs for multimodal\ntasks, few have explored practical fine-tuning strategies. In this work, we\nproposed a simple yet effective two-stage fine-tuning protocol to align visual\nfeatures to LLM's text embedding space as soft visual prompts. Our framework\nwith OpenLLaMA-7B achieved state-of-the-art level performance without\ndomain-specific pretraining. Moreover, we provide detailed analyses of soft\nvisual prompts and attention mechanisms, shedding light on future research\ndirections.",
            "author": [
                "Yuzhe Lu",
                "Sungmin Hong",
                "Yash Shah",
                "Panpan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01504v1",
                "http://arxiv.org/pdf/2312.01504v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01500v1",
            "title": "Unsupervised Approach to Evaluate Sentence-Level Fluency: Do We Really\n  Need Reference?",
            "updated": "2023-12-03T20:09:23Z",
            "published": "2023-12-03T20:09:23Z",
            "summary": "Fluency is a crucial goal of all Natural Language Generation (NLG) systems.\nWidely used automatic evaluation metrics fall short in capturing the fluency of\nmachine-generated text. Assessing the fluency of NLG systems poses a challenge\nsince these models are not limited to simply reusing words from the input but\nmay also generate abstractions. Existing reference-based fluency evaluations,\nsuch as word overlap measures, often exhibit weak correlations with human\njudgments. This paper adapts an existing unsupervised technique for measuring\ntext fluency without the need for any reference. Our approach leverages various\nword embeddings and trains language models using Recurrent Neural Network (RNN)\narchitectures. We also experiment with other available multilingual Language\nModels (LMs). To assess the performance of the models, we conduct a comparative\nanalysis across 10 Indic languages, correlating the obtained fluency scores\nwith human judgments. Our code and human-annotated benchmark test-set for\nfluency is available at\nhttps://github.com/AnanyaCoder/TextFluencyForIndicLanaguges.",
            "author": [
                "Gopichand Kanumolu",
                "Lokesh Madasu",
                "Pavan Baswani",
                "Ananya Mukherjee",
                "Manish Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01500v1",
                "http://arxiv.org/pdf/2312.01500v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01499v1",
            "title": "Towards Decentralized Task Offloading and Resource Allocation in\n  User-Centric Mobile Edge Computing",
            "updated": "2023-12-03T20:07:22Z",
            "published": "2023-12-03T20:07:22Z",
            "summary": "In the traditional cellular-based mobile edge computing (MEC), users at the\nedge of the cell are prone to suffer severe inter-cell interference and signal\nattenuation, leading to low throughput even transmission interruptions. Such\nedge effect severely obstructs offloading of tasks to MEC servers. To address\nthis issue, we propose user-centric mobile edge computing (UCMEC), a novel MEC\narchitecture integrating user-centric transmission, which can ensure high\nthroughput and reliable communication for task offloading. Then, we formulate\nan optimization problem with joint consideration of task offloading, power\ncontrol, and computing resource allocation in UCMEC, aiming at obtaining the\noptimal performance in terms of long-term average total delay. To solve the\nintractable problem, we propose two decentralized joint optimization schemes\nbased on multi-agent deep reinforcement learning (MADRL) and convex\noptimization, which consider both cooperation and non-cooperation among network\nnodes. Simulation results demonstrate that the proposed schemes in UCMEC can\nsignificantly improve the uplink transmission rate by at most 343.56% and\nreduce the long-term average total delay by at most 45.57% compared to\ntraditional cellular-based MEC.",
            "author": [
                "Langtian Qin",
                "Hancheng Lu",
                "Yuang Chen",
                "Baolin Chong",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01499v1",
                "http://arxiv.org/pdf/2312.01499v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.DC",
                "cs.SY",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01498v1",
            "title": "Learning Neural Traffic Rules",
            "updated": "2023-12-03T20:06:43Z",
            "published": "2023-12-03T20:06:43Z",
            "summary": "Extensive research has been devoted to the field of multi-agent navigation.\nRecently, there has been remarkable progress attributed to the emergence of\nlearning-based techniques with substantially elevated intelligence and realism.\nNonetheless, prevailing learned models face limitations in terms of scalability\nand effectiveness, primarily due to their agent-centric nature, i.e., the\nlearned neural policy is individually deployed on each agent. Inspired by the\nefficiency observed in real-world traffic networks, we present an\nenvironment-centric navigation policy. Our method learns a set of traffic rules\nto coordinate a vast group of unintelligent agents that possess only basic\ncollision-avoidance capabilities. Our method segments the environment into\ndistinct blocks and parameterizes the traffic rule using a Graph Recurrent\nNeural Network (GRNN) over the block network. Each GRNN node is trained to\nmodulate the velocities of agents as they traverse through. Using either\nImitation Learning (IL) or Reinforcement Learning (RL) schemes, we demonstrate\nthe efficacy of our neural traffic rules in resolving agent congestion, closely\nresembling real-world traffic regulations. Our method handles up to $240$\nagents at real-time and generalizes across diverse agent and environment\nconfigurations.",
            "author": [
                "Xuan Zhang",
                "Xifeng Gao",
                "Kui Wu",
                "Zherong Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01498v1",
                "http://arxiv.org/pdf/2312.01498v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01497v1",
            "title": "Feedback from protoclusters does not significantly change the kinematic\n  properties of the embedded dense gas structures",
            "updated": "2023-12-03T20:00:15Z",
            "published": "2023-12-03T20:00:15Z",
            "summary": "A total of 64 ATOMS sources at different evolutionary stages were selected to\ninvestigate the kinematics and dynamics of gas structures under feedback. We\nidentified dense gas structures based on the integrated intensity map of\nH$^{13}$CO$^+$ J=1-0 emission, and then extracted the average spectra of all\nstructures to investigate their velocity components and gas kinematics. For the\nscaling relations between velocity dispersion $\\sigma$, effective radius $R$\nand column density $N$ of all structures, $\\sigma-N*R$ always has a stronger\ncorrelation compared to $\\sigma-N$ and $\\sigma-R$. There are significant\ncorrelations between velocity dispersion and column density, which may imply\nthat the velocity dispersion originates from gravitational collapse, also\nrevealed by the velocity gradients. The measured velocity gradients for dense\ngas structures in early-stage sources and late-stage sources are comparable,\nindicating gravitational collapse through all evolutionary stages. We\nquantitatively estimated the velocity dispersion generated by the outflows,\ninflows, ionized gas pressure and radiation pressure, and found that the\nionized gas feedback is stronger than other feedback mechanisms. However,\nalthough feedback from HII regions is the strongest, it does not significantly\naffect the physical properties of the embedded dense gas structures. Combining\nwith the conclusions in Zhou+2023 on cloud-clump scales, we suggest that\nalthough feedback from cloud to core scales will break up the original cloud\ncomplex, the substructures of the original complex can be reorganized into new\ngravitationally governed configurations around new gravitational centers. This\nprocess is accompanied by structural destruction and generation, and changes in\ngravitational centers, but gravitational collapse is always ongoing.",
            "author": [
                "J. W. Zhou",
                "S. Dib",
                "F. Wyrowski",
                "T. Liu",
                "S. H. Li",
                "P. Sanhueza",
                "M. Juvela",
                "F. W. Xu",
                "H. L. Liu",
                "T. Baug",
                "Y. P. Peng",
                "K. M. Menten",
                "L. Bronfman",
                "C. W. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01497v1",
                "http://arxiv.org/pdf/2312.01497v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01493v1",
            "title": "Random zero currents of sections of Hermitian line bundles over compact\n  Riemannian manifolds",
            "updated": "2023-12-03T19:41:53Z",
            "published": "2023-12-03T19:41:53Z",
            "summary": "This paper is concerned with zero currents of random section of a Hermitian\nline bundle $E$ over a compact oriented Riemannian manifold. Given a metric\nconnection, heat flow yields a natural 1-parameter family of probability\nmeasures on the space of smooth sections $\\Gamma E$. It is shown that the\ncorresponding family of random zero currents connects the curvature of the\nbundle to the ground state zero current.",
            "author": [
                "Felix Kn\u00f6ppel"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01493v1",
                "http://arxiv.org/pdf/2312.01493v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01492v1",
            "title": "The Multilinear Rank and Core of Trifocal Grassmann Tensors",
            "updated": "2023-12-03T19:41:44Z",
            "published": "2023-12-03T19:41:44Z",
            "summary": "Closed formulas for the multilinear rank of trifocal Grassmann tensors are\nobtained. An alternative process to the standard HOSVD is introduced for the\ncomputation of the core of trifocal Grassmann tensors. Both of these results\nare obtained, under natural genericity conditions, leveraging the canonical\nform for these tensors, obtained by the same authors in a previous work. A\ngallery of explicit examples is also included.",
            "author": [
                "Marina Bertolini",
                "Gian Mario Besana",
                "Gilberto Bini",
                "Cristina Turrini"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01492v1",
                "http://arxiv.org/pdf/2312.01492v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "15A69, 14N05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01490v1",
            "title": "GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment\n  Draping",
            "updated": "2023-12-03T19:21:53Z",
            "published": "2023-12-03T19:21:53Z",
            "summary": "Recent neural, physics-based modeling of garment deformations allows faster\nand visually aesthetic results as opposed to the existing methods.\nMaterial-specific parameters are used by the formulation to control the garment\ninextensibility. This delivers unrealistic results with physically implausible\nstretching. Oftentimes, the draped garment is pushed inside the body which is\neither corrected by an expensive post-processing, thus adding to further\ninconsistent stretching; or by deploying a separate training regime for each\nbody type, restricting its scalability. Additionally, the flawed skinning\nprocess deployed by existing methods produces incorrect results on loose\ngarments.\n  In this paper, we introduce a geometrical constraint to the existing\nformulation that is collision-aware and imposes garment inextensibility\nwherever possible. Thus, we obtain realistic results where draped clothes\nstretch only while covering bigger body regions. Furthermore, we propose a\ngeometry-aware garment skinning method by defining a body-garment closeness\nmeasure which works for all garment types, especially the loose ones.",
            "author": [
                "Ruochen Chen",
                "Liming Chen",
                "Shaifali Parashar"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01490v1",
                "http://arxiv.org/pdf/2312.01490v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01488v1",
            "title": "ADT: Agent-based Dynamic Thresholding for Anomaly Detection",
            "updated": "2023-12-03T19:07:30Z",
            "published": "2023-12-03T19:07:30Z",
            "summary": "The complexity and scale of IT systems are increasing dramatically, posing\nmany challenges to real-world anomaly detection. Deep learning anomaly\ndetection has emerged, aiming at feature learning and anomaly scoring, which\nhas gained tremendous success. However, little work has been done on the\nthresholding problem despite it being a critical factor for the effectiveness\nof anomaly detection. In this paper, we model thresholding in anomaly detection\nas a Markov Decision Process and propose an agent-based dynamic thresholding\n(ADT) framework based on a deep Q-network. The proposed method can be\nintegrated into many systems that require dynamic thresholding. An auto-encoder\nis utilized in this study to obtain feature representations and produce anomaly\nscores for complex input data. ADT can adjust thresholds adaptively by\nutilizing the anomaly scores from the auto-encoder and significantly improve\nanomaly detection performance. The properties of ADT are studied through\nexperiments on three real-world datasets and compared with benchmarks, hence\ndemonstrating its thresholding capability, data-efficient learning, stability,\nand robustness. Our study validates the effectiveness of reinforcement learning\nin optimal thresholding control in anomaly detection.",
            "author": [
                "Xue Yang",
                "Enda Howley",
                "Micheal Schukat"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01488v1",
                "http://arxiv.org/pdf/2312.01488v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01487v1",
            "title": "BetterMinton Service: Analyzing the Badminton Service using Open Kinetic\n  Chain",
            "updated": "2023-12-03T19:02:52Z",
            "published": "2023-12-03T19:02:52Z",
            "summary": "We present a badminton training system that focuses on the backhand short\nservice. Unlike the prior motor skill training systems which focus on the\ntrainee's posture, our system analyzes the process of moving joints with the\nopen kinetic chain (OKC), which helps align movement and minimize muscle use\nfor better joint control. We process the users' mocap data to visually show\ntheir last service process comparing to 4 ideal OKC characteristics that we\ncollected from a 6-sub-elite formative study as well as recommended contact\nposture. We validate our system through a 12-user study that measures serving\naccuracy, qualitative feedback, and skeletal data with users at various skill\nlevels and open source our skeletal analysis model for future use. While the\nparticipants' overall service accuracy was not significantly improved, our\nresults show that our system helps participants in the short term to fine-tune\ntheir service motion closer to our ideal 4 OKC characteristics.",
            "author": [
                "Eden Cong-He Xu",
                "Lung-Pan Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01487v1",
                "http://arxiv.org/pdf/2312.01487v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03001v1",
            "title": "Computer Vision for Increased Operative Efficiency via Identification of\n  Instruments in the Neurosurgical Operating Room: A Proof-of-Concept Study",
            "updated": "2023-12-03T19:01:50Z",
            "published": "2023-12-03T19:01:50Z",
            "summary": "Objectives Computer vision (CV) is a field of artificial intelligence that\nenables machines to interpret and understand images and videos. CV has the\npotential to be of assistance in the operating room (OR) to track surgical\ninstruments. We built a CV algorithm for identifying surgical instruments in\nthe neurosurgical operating room as a potential solution for surgical\ninstrument tracking and management to decrease surgical waste and opening of\nunnecessary tools. Methods We collected 1660 images of 27 commonly used\nneurosurgical instruments. Images were labeled using the VGG Image Annotator\nand split into 80% training and 20% testing sets in order to train a U-Net\nConvolutional Neural Network using 5-fold cross validation. Results Our U-Net\nachieved a tool identification accuracy of 80-100% when distinguishing 25\nclasses of instruments, with 19/25 classes having accuracy over 90%. The model\nperformance was not adequate for sub classifying Adson, Gerald, and Debakey\nforceps, which had accuracies of 60-80%. Conclusions We demonstrated the\nviability of using machine learning to accurately identify surgical\ninstruments. Instrument identification could help optimize surgical tray\npacking, decrease tool usage and waste, decrease incidence of instrument\nmisplacement events, and assist in timing of routine instrument maintenance.\nMore training data will be needed to increase accuracy across all surgical\ninstruments that would appear in a neurosurgical operating room. Such\ntechnology has the potential to be used as a method to be used for proving what\ntools are truly needed in each type of operation allowing surgeons across the\nworld to do more with less.",
            "author": [
                "Tanner J. Zachem",
                "Sully F. Chen",
                "Vishal Venkatraman",
                "David AW Sykes",
                "Ravi Prakash",
                "Samantha Spellicy",
                "Alexander D Suarez",
                "Weston Ross",
                "Patrick J. Codd"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03001v1",
                "http://arxiv.org/pdf/2312.03001v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03000v1",
            "title": "VidereX: A Navigational Application inspired by ants",
            "updated": "2023-12-03T18:59:01Z",
            "published": "2023-12-03T18:59:01Z",
            "summary": "Navigation is a crucial element in any person's life, whether for work,\neducation, social living or any other miscellaneous reason; naturally, the\nimportance of it is universally recognised and valued. One of the critical\ncomponents of navigation is vision, which facilitates movement from one place\nto another. Navigating unfamiliar settings, especially for the blind or\nvisually impaired, can pose significant challenges, impacting their\nindependence and quality of life. Current assistive travel solutions have\nshortcomings, including GPS limitations and a demand for an efficient,\nuser-friendly, and portable model. Addressing these concerns, this paper\npresents VidereX: a smartphone-based solution using an ant-inspired navigation\nalgorithm. Emulating ants' ability to learn a route between nest and feeding\ngrounds after a single traversal, VidereX enables users to rapidly acquire\nnavigational data using a one/few-shot learning strategy. A key component of\nVidereX is its emphasis on active user engagement. Like ants with a scanning\nbehaviour to actively investigate their environment, users wield the camera,\nactively exploring the visual landscape. Far from the passive reception of\ndata, this process constitutes a dynamic exploration, echoing nature's\nnavigational mechanisms.",
            "author": [
                "Nam Ho Koh",
                "Doran Amos",
                "Paul Graham",
                "Andrew Philippides"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03000v1",
                "http://arxiv.org/pdf/2312.03000v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02999v1",
            "title": "Efficient Incremental Potential Contact for Actuated Face Simulation",
            "updated": "2023-12-03T18:58:54Z",
            "published": "2023-12-03T18:58:54Z",
            "summary": "We present a quasi-static finite element simulator for human face animation.\nWe model the face as an actuated soft body, which can be efficiently simulated\nusing Projective Dynamics (PD). We adopt Incremental Potential Contact (IPC) to\nhandle self-intersection. However, directly integrating IPC into the simulation\nwould impede the high efficiency of the PD solver, since the stiffness matrix\nin the global step is no longer constant and cannot be pre-factorized. We\nnotice that the actual number of vertices affected by the collision is only a\nsmall fraction of the whole model, and by utilizing this fact we effectively\ndecrease the scale of the linear system to be solved. With the proposed\noptimization method for collision, we achieve high visual fidelity at a\nrelatively low performance overhead.",
            "author": [
                "Bo Li",
                "Lingchen Yang",
                "Barbara Solenthaler"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610543.3626161",
                "http://arxiv.org/abs/2312.02999v1",
                "http://arxiv.org/pdf/2312.02999v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01480v1",
            "title": "The impact of varying inhomogeneous reionization histories on metrics of\n  Ly$\u03b1$ opacity",
            "updated": "2023-12-03T18:44:29Z",
            "published": "2023-12-03T18:44:29Z",
            "summary": "The epoch of hydrogen reionization is complete by $z=5$, but its progression\nat higher redshifts is uncertain. Measurements of Ly$\\alpha$ forest opacity\nshow large scatter at $z<6$, suggestive of spatial fluctuations in neutral\nfraction ($x_\\mathrm{HI}$), temperature, or ionizing background, either\nindividually or in combination. However, these effects are degenerate,\nnecessitating modeling these physics in tandem in order to properly interpret\nthe observations. We begin this process by developing a framework for modeling\nthe reionization history and associated temperature fluctuations, with the\nintention of incorporating ionizing background fluctuations at a later time. To\ndo this, we generate several reionization histories using semi-numerical code\nAMBER, selecting histories with volume-weighted neutral fractions that adhere\nto the observed CMB optical depth and dark pixel fractions. Implementing these\nhistories in the \\texttt{Nyx} cosmological hydrodynamics code, we examine the\nevolution of gas within the simulation, and the associated metrics of the\nLy$\\alpha$ forest opacity. We find that the pressure smoothing scale within the\nIGM is strongly correlated with the adiabatic index of the temperature-density\nrelation. We find that while models with 20,000 K photoheating at reionization\nare better able to reproduce the shape of the observed $z=5$ 1D flux power\nspectrum than those with 10,000 K, they fail to match the highest wavenumbers.\nThe simulated autocorrelation function and optical depth distributions are\nsystematically low and narrow, respectively, compared to the observed values,\nbut are in better agreement when the reionization history is longer in\nduration, more symmetric in its distribution of reionization redshifts, or if\nthere are remaining neutral regions at $z<6$. The systematically low variance\nlikely requires the addition of a fluctuating UVB.",
            "author": [
                "Caitlin C. Doughty",
                "Joseph F. Hennawi",
                "Jose O\u00f1orbe",
                "Frederick B. Davies",
                "Zarija Luki\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01480v1",
                "http://arxiv.org/pdf/2312.01480v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01479v1",
            "title": "OpenVoice: Versatile Instant Voice Cloning",
            "updated": "2023-12-03T18:41:54Z",
            "published": "2023-12-03T18:41:54Z",
            "summary": "We introduce OpenVoice, a versatile voice cloning approach that requires only\na short audio clip from the reference speaker to replicate their voice and\ngenerate speech in multiple languages. OpenVoice represents a significant\nadvancement in addressing the following open challenges in the field: 1)\nFlexible Voice Style Control. OpenVoice enables granular control over voice\nstyles, including emotion, accent, rhythm, pauses, and intonation, in addition\nto replicating the tone color of the reference speaker. The voice styles are\nnot directly copied from and constrained by the style of the reference speaker.\nPrevious approaches lacked the ability to flexibly manipulate voice styles\nafter cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves\nzero-shot cross-lingual voice cloning for languages not included in the\nmassive-speaker training set. Unlike previous approaches, which typically\nrequire extensive massive-speaker multi-lingual (MSML) dataset for all\nlanguages, OpenVoice can clone voices into a new language without any\nmassive-speaker training data for that language. OpenVoice is also\ncomputationally efficient, costing tens of times less than commercially\navailable APIs that offer even inferior performance. To foster further research\nin the field, we have made the source code and trained model publicly\naccessible. We also provide qualitative results in our demo website. Prior to\nits public release, our internal version of OpenVoice was used tens of millions\nof times by users worldwide between May and October 2023, serving as the\nbackend of MyShell.ai.",
            "author": [
                "Zengyi Qin",
                "Wenliang Zhao",
                "Xumin Yu",
                "Xin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01479v1",
                "http://arxiv.org/pdf/2312.01479v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02221v1",
            "title": "Slice3D: Multi-Slice, Occlusion-Revealing, Single View 3D Reconstruction",
            "updated": "2023-12-03T18:36:40Z",
            "published": "2023-12-03T18:36:40Z",
            "summary": "We introduce multi-slice reasoning, a new notion for single-view 3D\nreconstruction which challenges the current and prevailing belief that\nmulti-view synthesis is the most natural conduit between single-view and 3D.\nOur key observation is that object slicing is more advantageous than altering\nviews to reveal occluded structures. Specifically, slicing is more\nocclusion-revealing since it can peel through any occluders without\nobstruction. In the limit, i.e., with infinitely many slices, it is guaranteed\nto unveil all hidden object parts. We realize our idea by developing Slice3D, a\nnovel method for single-view 3D reconstruction which first predicts multi-slice\nimages from a single RGB image and then integrates the slices into a 3D model\nusing a coordinate-based transformer network for signed distance prediction.\nThe slice images can be regressed or generated, both through a U-Net based\nnetwork. For the former, we inject a learnable slice indicator code to\ndesignate each decoded image into a spatial slice location, while the slice\ngenerator is a denoising diffusion model operating on the entirety of slice\nimages stacked on the input channels. We conduct extensive evaluation against\nstate-of-the-art alternatives to demonstrate superiority of our method,\nespecially in recovering complex and severely occluded shape structures, amid\nambiguities. All Slice3D results were produced by networks trained on a single\nNvidia A40 GPU, with an inference time less than 20 seconds.",
            "author": [
                "Yizhi Wang",
                "Wallace Lira",
                "Wenqi Wang",
                "Ali Mahdavi-Amiri",
                "Hao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02221v1",
                "http://arxiv.org/pdf/2312.02221v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01476v1",
            "title": "Context-Enhanced Relational Operators with Vector Embeddings",
            "updated": "2023-12-03T18:23:48Z",
            "published": "2023-12-03T18:23:48Z",
            "summary": "Collecting data, extracting value, and combining insights from relational and\ncontext-rich multi-modal sources in data processing pipelines presents a\nchallenge for traditional relational DBMS. While relational operators allow\ndeclarative and optimizable query specification, they are limited to data\ntransformations unsuitable for capturing or analyzing context. On the other\nhand, representation learning models can map context-rich data into embeddings,\nallowing machine-automated context processing but requiring imperative data\ntransformation integration with the analytical query.\n  To bridge this dichotomy, we present a context-enhanced relational join and\nintroduce an embedding operator composable with relational operators. This\nenables hybrid relational and context-rich vector data processing, with\nalgebraic equivalences compatible with relational algebra and corresponding\nlogical and physical optimizations. We investigate model-operator interaction\nwith vector data processing and study the characteristics of the E-join\noperator. Using an example of string embeddings, we demonstrate enabling hybrid\ncontext-enhanced processing on relational join operators with vector\nembeddings. The importance of holistic optimization, from logical to physical,\nis demonstrated in an order of magnitude execution time improvement.",
            "author": [
                "Viktor Sanca",
                "Manos Chatzakis",
                "Anastasia Ailamaki"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01476v1",
                "http://arxiv.org/pdf/2312.01476v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02998v1",
            "title": "Personality of AI",
            "updated": "2023-12-03T18:23:45Z",
            "published": "2023-12-03T18:23:45Z",
            "summary": "This research paper delves into the evolving landscape of fine-tuning large\nlanguage models (LLMs) to align with human users, extending beyond basic\nalignment to propose \"personality alignment\" for language models in\norganizational settings. Acknowledging the impact of training methods on the\nformation of undefined personality traits in AI models, the study draws\nparallels with human fitting processes using personality tests. Through an\noriginal case study, we demonstrate the necessity of personality fine-tuning\nfor AIs and raise intriguing questions about applying human-designed tests to\nAIs, engineering specialized AI personality tests, and shaping AI personalities\nto suit organizational roles. The paper serves as a starting point for\ndiscussions and developments in the burgeoning field of AI personality\nalignment, offering a foundational anchor for future exploration in\nhuman-machine teaming and co-existence.",
            "author": [
                "Byunggu Yu",
                "Junwhan Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02998v1",
                "http://arxiv.org/pdf/2312.02998v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01470v1",
            "title": "ee$\\in$MC: Low Energy Mesons and the Residual QCD Potential",
            "updated": "2023-12-03T17:49:39Z",
            "published": "2023-12-03T17:49:39Z",
            "summary": "The Flux-Tube Breaking Model in ee$\\in$MC is expanded to include the residual\nQCD potential between the Final-State mesons, within the non-relativistic\nlimit. These residual QCD potentials have been predicted in the context of the\nFlux-Tube Breaking Models to generate meson-meson molecular states for the\n$f_{0}(500)$, $f_{0}(980)$, $a_{0}(980)$, through the colour hyper-fine\nspin-spin interaction. These residual potentials are also found to have an\nimportant impact on the $S_{1}$ decay of the $a_{1}$ and $K_{1}$ axial-vector\nmesons due to the colour hyper-fine spin-spin interaction. It is found that in\nthe low mass regions, the $\\rho(770)$ and $K^{*}(892)$ are sensitive to the\nlinear-confining potential and colour-Coulomb potential suggesting that with\nthe high statistics at the B-Factories, it may be possible to probe the\nlinear-confining potential and colour-Coulomb potential through a model\ndependent description of the resonance shape or by exploiting multiple\nproduction process.",
            "author": [
                "Ian M. Nugent"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01470v1",
                "http://arxiv.org/pdf/2312.01470v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01465v1",
            "title": "Developing an Error Budget for the Nonlinear Curvature Wavefront Sensor",
            "updated": "2023-12-03T17:23:57Z",
            "published": "2023-12-03T17:23:57Z",
            "summary": "Consistent operation of adaptive optics (AO) systems requires the use of a\nwavefront sensor (WFS) with high sensitivity and low noise. The nonlinear\ncurvature WFS (nlCWFS) has been shown both in simulations and lab experiments\nto be more sensitive than the industry-standard Shack-Hartmann WFS (SHWFS), but\nits noise characteristics have yet to be thoroughly explored. In this paper, we\ndevelop a spatial domain wavefront error budget for the nlCWFS that includes\ncommon sources of noise that introduce uncertainty into the reconstruction\nprocess (photon noise, finite bit depth, read noise, vibrations,\nnon-common-path errors, servo lag, etc.). We find that the nlCWFS can\nout-perform the SHWFS in a variety of environmental conditions, and that the\nprimary challenge involves overcoming speed limitations related to the\nwavefront reconstructor. The results of this work may be used to inform the\ndesign of nlCWFS systems for a broad range of AO applications.",
            "author": [
                "Sam Potier",
                "Justin Crepp",
                "Stanimir Letchev"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01465v1",
                "http://arxiv.org/pdf/2312.01465v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01464v1",
            "title": "Diffusion Posterior Sampling for Nonlinear CT Reconstruction",
            "updated": "2023-12-03T17:20:11Z",
            "published": "2023-12-03T17:20:11Z",
            "summary": "Diffusion models have been demonstrated as powerful deep learning tools for\nimage generation in CT reconstruction and restoration. Recently, diffusion\nposterior sampling, where a score-based diffusion prior is combined with a\nlikelihood model, has been used to produce high quality CT images given\nlow-quality measurements. This technique is attractive since it permits a\none-time, unsupervised training of a CT prior; which can then be incorporated\nwith an arbitrary data model. However, current methods only rely on a linear\nmodel of x-ray CT physics to reconstruct or restore images. While it is common\nto linearize the transmission tomography reconstruction problem, this is an\napproximation to the true and inherently nonlinear forward model. We propose a\nnew method that solves the inverse problem of nonlinear CT image reconstruction\nvia diffusion posterior sampling. We implement a traditional unconditional\ndiffusion model by training a prior score function estimator, and apply Bayes\nrule to combine this prior with a measurement likelihood score function derived\nfrom the nonlinear physical model to arrive at a posterior score function that\ncan be used to sample the reverse-time diffusion process. This plug-and-play\nmethod allows incorporation of a diffusion-based prior with generalized\nnonlinear CT image reconstruction into multiple CT system designs with\ndifferent forward models, without the need for any additional training. We\ndevelop the algorithm that performs this reconstruction, including an\nordered-subsets variant for accelerated processing and demonstrate the\ntechnique in both fully sampled low dose data and sparse-view geometries using\na single unsupervised training of the prior.",
            "author": [
                "Shudong Li",
                "Matthew Tivnan",
                "Yuan Shen",
                "J. Webster Stayman"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01464v1",
                "http://arxiv.org/pdf/2312.01464v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.CV",
                "eess.IV",
                "physics.comp-ph",
                "J.3; I.4.4; I.4.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01463v1",
            "title": "Development of a Monte Carlo tool for simulating electron transport in\n  noble liquids",
            "updated": "2023-12-03T17:18:41Z",
            "published": "2023-12-03T17:18:41Z",
            "summary": "This study presents a Monte Carlo simulation tool for modeling the\ntransportation processes of thermal electrons in noble liquids, specifically\nfocusing on liquid argon and liquid xenon. The study aims to elucidate the\nmicroscopical mechanisms governing the drift and diffusion of electrons within\nthe context of time projection chambers (TPCs), with detailed considerations of\ncoherent electron-atom scattering and electric field force. The simulation tool\nis implemented in the Geant4 framework, allowing for the exploration of\nelectron transport parameters, including drift velocity, longitudinal diffusion\ncoefficient, and transverse diffusion coefficient. The simulation is validated\nby comparing its results for drift velocity and diffusion coefficients with\nexperimental measurements, revealing good agreement in the low to moderate\nelectric field ranges. Discrepancies in high electric field regions are\ndiscussed, highlighting the impact of impurities and the need for improved\ncross-section calculations. Despite some limitations, the simulation tool\nprovides valuable insights into electron transport in noble liquids, offering a\nfoundation for future enhancements and applications in diverse research areas.",
            "author": [
                "Yijun Xie",
                "Yi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01463v1",
                "http://arxiv.org/pdf/2312.01463v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01461v1",
            "title": "Spin-fluctuation heat capacity at magnetic phase transition in the Co,Fe\n  doped MnSi",
            "updated": "2023-12-03T17:13:06Z",
            "published": "2023-12-03T17:13:06Z",
            "summary": "An universal line revealing an independence of spin fuctuation contributions\nto the heat capacity on impurity content and its nature is discovered in the\nhelical phase of Mn(Co,Fe)Si. This situation declares an invariance of the heat\ncapacity of spin subsystem under doping, which probably arises as a result of\nrelative stiffness of the helical spin structure in respect to the impurity\nspins. On the other hand the situation drastically changes at the helical\nfuctuation region when no long range spin order exists.",
            "author": [
                "S. M. Stishov",
                "A. E. Petrova",
                "A. M. Belemuk"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01461v1",
                "http://arxiv.org/pdf/2312.01461v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.01460v1",
            "title": "Towards an accurate and generalizable multiple sclerosis lesion\n  segmentation model using self-ensembled lesion fusion",
            "updated": "2023-12-03T17:08:10Z",
            "published": "2023-12-03T17:08:10Z",
            "summary": "Automatic multiple sclerosis (MS) lesion segmentation using multi-contrast\nmagnetic resonance (MR) images provides improved efficiency and reproducibility\ncompared to manual delineation. Current state-of-the-art automatic MS lesion\nsegmentation methods utilize modified U-Net-like architectures. However, in the\nliterature, dedicated architecture modifications were always required to\nmaximize their performance. In addition, the best-performing methods have not\nproven to be generalizable to diverse test datasets with contrast variations\nand image artifacts. In this work, we developed an accurate and generalizable\nMS lesion segmentation model using the well-known U-Net architecture without\nfurther modification. A novel test-time self-ensembled lesion fusion strategy\nis proposed that not only achieved the best performance using the ISBI 2015 MS\nsegmentation challenge data but also demonstrated robustness across various\nself-ensemble parameter choices. Moreover, equipped with instance normalization\nrather than batch normalization widely used in literature, the model trained on\nthe ISBI challenge data generalized well on clinical test datasets from\ndifferent scanners.",
            "author": [
                "Jinwei Zhang",
                "Lianrui Zuo",
                "Blake E. Dewey",
                "Samuel W. Remedios",
                "Dzung L. Pham",
                "Aaron Carass",
                "Jerry L. Prince"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01460v1",
                "http://arxiv.org/pdf/2312.01460v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    }
]