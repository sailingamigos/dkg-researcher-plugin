[
    {
        "public": [
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02418v1/1.0",
                "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
                "year": 2024,
                "abstract": "Foundational vision-language models such as CLIP are becoming a new paradigm\nin vision, due to their excellent generalization abilities. However, adapting\nthese models for downstream tasks while maintaining their generalization\nremains a challenge. In literature, one branch of methods adapts CLIP by\nlearning prompts using visual information. While effective, most of these works\nrequire labeled data which is not practical, and often struggle to generalize\ntowards new datasets due to over-fitting on the source data. An alternative\napproach resorts to training-free methods by generating class descriptions from\nlarge language models (LLMs) and perform prompt ensembling. However, these\nmethods often generate class specific prompts that cannot be transferred to\nother classes, which incur higher costs by generating LLM descriptions for each\nclass separately. In this work, we propose to combine the strengths of these\nboth streams of methods by learning prompts using only text data derived from\nLLMs. As supervised training of prompts is not trivial due to absence of\nimages, we develop a training approach that allows prompts to extract rich\ncontextual knowledge from LLM data. Moreover, with LLM contextual data mapped\nwithin the learned prompts, it enables zero-shot transfer of prompts to new\nclasses and datasets potentially cutting the LLM prompt engineering cost. To\nthe best of our knowledge, this is the first work that learns generalized\nprompts using text only data. We perform extensive evaluations on 4 benchmarks\nwhere our method improves over prior ensembling works while being competitive\nto those utilizing labeled images. Our code and pre-trained models are\navailable at https://github.com/muzairkhattak/ProText.",
                "authors": [
                    "Muhammad Uzair Khattak",
                    "Muhammad Ferjad Naeem",
                    "Muzammal Naseer",
                    "Luc Van Gool",
                    "Federico Tombari"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02418v1",
                    "http://arxiv.org/pdf/2401.02418v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02417v1/1.0",
                "title": "Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic\n  Speech Recognition",
                "year": 2024,
                "abstract": "While word error rates of automatic speech recognition (ASR) systems have\nconsistently fallen, natural language understanding (NLU) applications built on\ntop of ASR systems still attribute significant numbers of failures to\nlow-quality speech recognition results. Existing assistant systems collect\nlarge numbers of these unsuccessful interactions, but these systems usually\nfail to learn from these interactions, even in an offline fashion. In this\nwork, we introduce CLC: Contrastive Learning for Conversations, a family of\nmethods for contrastive fine-tuning of models in a self-supervised fashion,\nmaking use of easily detectable artifacts in unsuccessful conversations with\nassistants. We demonstrate that our CLC family of approaches can improve the\nperformance of ASR models on OD3, a new public large-scale semi-synthetic\nmeta-dataset of audio task-oriented dialogues, by up to 19.2%. These gains\ntransfer to real-world systems as well, where we show that CLC can help to\nimprove performance by up to 6.7% over baselines. We make OD3 publicly\navailable at https://github.com/amazon-science/amazon-od3 .",
                "authors": [
                    "David M. Chan",
                    "Shalini Ghosh",
                    "Hitesh Tulsiani",
                    "Ariya Rastrow",
                    "Bj\u00f6rn Hoffmeister"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02417v1",
                    "http://arxiv.org/pdf/2401.02417v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.CL",
                    "cs.LG",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02416v1/1.0",
                "title": "ODIN: A Single Model for 2D and 3D Perception",
                "year": 2024,
                "abstract": "State-of-the-art models on contemporary 3D perception benchmarks like ScanNet\nconsume and label dataset-provided 3D point clouds, obtained through post\nprocessing of sensed multiview RGB-D images. They are typically trained\nin-domain, forego large-scale 2D pre-training and outperform alternatives that\nfeaturize the posed RGB-D multiview images instead. The gap in performance\nbetween methods that consume posed images versus post-processed 3D point clouds\nhas fueled the belief that 2D and 3D perception require distinct model\narchitectures. In this paper, we challenge this view and propose ODIN\n(Omni-Dimensional INstance segmentation), a model that can segment and label\nboth 2D RGB images and 3D point clouds, using a transformer architecture that\nalternates between 2D within-view and 3D cross-view information fusion. Our\nmodel differentiates 2D and 3D feature operations through the positional\nencodings of the tokens involved, which capture pixel coordinates for 2D patch\ntokens and 3D coordinates for 3D feature tokens. ODIN achieves state-of-the-art\nperformance on ScanNet200, Matterport3D and AI2THOR 3D instance segmentation\nbenchmarks, and competitive performance on ScanNet, S3DIS and COCO. It\noutperforms all previous works by a wide margin when the sensed 3D point cloud\nis used in place of the point cloud sampled from 3D mesh. When used as the 3D\nperception engine in an instructable embodied agent architecture, it sets a new\nstate-of-the-art on the TEACh action-from-dialogue benchmark. Our code and\ncheckpoints can be found at the project website: https://odin-seg.github.io.",
                "authors": [
                    "Ayush Jain",
                    "Pushkal Katara",
                    "Nikolaos Gkanatsios",
                    "Adam W. Harley",
                    "Gabriel Sarch",
                    "Kriti Aggarwal",
                    "Vishrav Chaudhary",
                    "Katerina Fragkiadaki"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02416v1",
                    "http://arxiv.org/pdf/2401.02416v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02415v1/1.0",
                "title": "LLaMA Pro: Progressive LLaMA with Block Expansion",
                "year": 2024,
                "abstract": "Humans generally acquire new skills without compromising the old; however,\nthe opposite holds for Large Language Models (LLMs), e.g., from LLaMA to\nCodeLLaMA. To this end, we propose a new post-pretraining method for LLMs with\nan expansion of Transformer blocks. We tune the expanded blocks using only new\ncorpus, efficiently and effectively improving the model's knowledge without\ncatastrophic forgetting. In this paper, we experiment on the corpus of code and\nmath, yielding LLaMA Pro-8.3B, a versatile foundation model initialized from\nLLaMA2-7B, excelling in general tasks, programming, and mathematics. LLaMA Pro\nand its instruction-following counterpart (LLaMA Pro-Instruct) achieve advanced\nperformance among various benchmarks, demonstrating superiority over existing\nopen models in the LLaMA family and the immense potential of reasoning and\naddressing diverse tasks as an intelligent agent. Our findings provide valuable\ninsights into integrating natural and programming languages, laying a solid\nfoundation for developing advanced language agents that operate effectively in\nvarious environments.",
                "authors": [
                    "Chengyue Wu",
                    "Yukang Gan",
                    "Yixiao Ge",
                    "Zeyu Lu",
                    "Jiahao Wang",
                    "Ye Feng",
                    "Ping Luo",
                    "Ying Shan"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02415v1",
                    "http://arxiv.org/pdf/2401.02415v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02413v1/1.0",
                "title": "Simulation-Based Inference with Quantile Regression",
                "year": 2024,
                "abstract": "We present Neural Quantile Estimation (NQE), a novel Simulation-Based\nInference (SBI) method based on conditional quantile regression. NQE\nautoregressively learns individual one dimensional quantiles for each posterior\ndimension, conditioned on the data and previous posterior dimensions. Posterior\nsamples are obtained by interpolating the predicted quantiles using monotonic\ncubic Hermite spline, with specific treatment for the tail behavior and\nmulti-modal distributions. We introduce an alternative definition for the\nBayesian credible region using the local Cumulative Density Function (CDF),\noffering substantially faster evaluation than the traditional Highest Posterior\nDensity Region (HPDR). In case of limited simulation budget and/or known model\nmisspecification, a post-processing broadening step can be integrated into NQE\nto ensure the unbiasedness of the posterior estimation with negligible\nadditional computational cost. We demonstrate that the proposed NQE method\nachieves state-of-the-art performance on a variety of benchmark problems.",
                "authors": [
                    "He Jia"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02413v1",
                    "http://arxiv.org/pdf/2401.02413v1"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02412v1/1.0",
                "title": "LLM Augmented LLMs: Expanding Capabilities through Composition",
                "year": 2024,
                "abstract": "Foundational models with billions of parameters which have been trained on\nlarge corpora of data have demonstrated non-trivial skills in a variety of\ndomains. However, due to their monolithic structure, it is challenging and\nexpensive to augment them or impart new skills. On the other hand, due to their\nadaptation abilities, several new instances of these models are being trained\ntowards new domains and tasks. In this work, we study the problem of efficient\nand practical composition of existing foundation models with more specific\nmodels to enable newer capabilities. To this end, we propose CALM --\nComposition to Augment Language Models -- which introduces cross-attention\nbetween models to compose their representations and enable new capabilities.\nSalient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'\nexisting LLMs along with a few additional parameters and data, (ii) Existing\nmodel weights are kept intact, and hence preserves existing capabilities, and\n(iii) Applies to diverse domains and settings. We illustrate that augmenting\nPaLM2-S with a smaller model trained on low-resource languages results in an\nabsolute improvement of up to 13\\% on tasks like translation into English and\narithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is\naugmented with a code-specific model, we see a relative improvement of 40\\%\nover the base model for code generation and explanation tasks -- on-par with\nfully fine-tuned counterparts.",
                "authors": [
                    "Rachit Bansal",
                    "Bidisha Samanta",
                    "Siddharth Dalmia",
                    "Nitish Gupta",
                    "Shikhar Vashishth",
                    "Sriram Ganapathy",
                    "Abhishek Bapna",
                    "Prateek Jain",
                    "Partha Talukdar"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02412v1",
                    "http://arxiv.org/pdf/2401.02412v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02411v1/1.0",
                "title": "What You See is What You GAN: Rendering Every Pixel for High-Fidelity\n  Geometry in 3D GANs",
                "year": 2024,
                "abstract": "3D-aware Generative Adversarial Networks (GANs) have shown remarkable\nprogress in learning to generate multi-view-consistent images and 3D geometries\nof scenes from collections of 2D images via neural volume rendering. Yet, the\nsignificant memory and computational costs of dense sampling in volume\nrendering have forced 3D GANs to adopt patch-based training or employ\nlow-resolution rendering with post-processing 2D super resolution, which\nsacrifices multiview consistency and the quality of resolved geometry.\nConsequently, 3D GANs have not yet been able to fully resolve the rich 3D\ngeometry present in 2D images. In this work, we propose techniques to scale\nneural volume rendering to the much higher resolution of native 2D images,\nthereby resolving fine-grained 3D geometry with unprecedented detail. Our\napproach employs learning-based samplers for accelerating neural rendering for\n3D GAN training using up to 5 times fewer depth samples. This enables us to\nexplicitly \"render every pixel\" of the full-resolution image during training\nand inference without post-processing superresolution in 2D. Together with our\nstrategy to learn high-quality surface geometry, our method synthesizes\nhigh-resolution 3D geometry and strictly view-consistent images while\nmaintaining image quality on par with baselines relying on post-processing\nsuper resolution. We demonstrate state-of-the-art 3D gemetric quality on FFHQ\nand AFHQ, setting a new standard for unsupervised learning of 3D shapes in 3D\nGANs.",
                "authors": [
                    "Alex Trevithick",
                    "Matthew Chan",
                    "Towaki Takikawa",
                    "Umar Iqbal",
                    "Shalini De Mello",
                    "Manmohan Chandraker",
                    "Ravi Ramamoorthi",
                    "Koki Nagano"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02411v1",
                    "http://arxiv.org/pdf/2401.02411v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.GR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02409v1/1.0",
                "title": "Gravitational waves from dark domain walls",
                "year": 2024,
                "abstract": "For most of cosmic history, the evolution of our Universe has been governed\nby the physics of a 'dark sector', consisting of dark matter and dark energy,\nwhose properties are only understood in a schematic way. The influence of these\nconstituents is mediated exclusively by the force of gravity, meaning that\ninsight into their nature must be gleaned from gravitational phenomena. The\nadvent of gravitational-wave astronomy has revolutionised the field of black\nhole astrophysics, and opens a new window of discovery for cosmological\nsources. Relevant examples include topological defects, such as domain walls or\ncosmic strings, which are remnants of a phase transition. Here we present the\nfirst simulations of cosmic structure formation in which the dynamics of the\ndark sector introduces domain walls as a source of stochastic gravitational\nwaves in the late Universe. We study in detail how the spectrum of\ngravitational waves is affected by the properties of the model, and extrapolate\nthe results to scales relevant to the recent evidence for a stochastic\ngravitational wave background. Our relativistic implementation of the field\ndynamics paves the way for optimal use of the next generation of gravitational\nexperiments to unravel the dark sector.",
                "authors": [
                    "\u00d8yvind Christiansen",
                    "Julian Adamek",
                    "Farbod Hassani",
                    "David F. Mota"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02409v1",
                    "http://arxiv.org/pdf/2401.02409v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "gr-qc",
                    "hep-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02407v1/1.0",
                "title": "A network-level transport model of tau progression in the Alzheimer's\n  brain",
                "year": 2024,
                "abstract": "One of the hallmarks of Alzheimer's disease (AD) is the accumulation and\nspread of toxic aggregates of tau protein. The progression of AD tau pathology\nis thought to be highly stereotyped, which is in part due to the fact that tau\ncan spread between regions via the white matter tracts that connect them.\nMathematically, this phenomenon has been described using models of \"network\ndiffusion\", where the rate of spread of tau between brain regions is\nproportional to its concentration gradient and the amount of white matter\nbetween them. Although these models can robustly predict the progression of\npathology in a wide variety of neurodegenerative diseases, including AD, an\nunder explored aspect of tau spreading is that it is governed not simply by\ndiffusion but also active transport along axonal microtubules. Spread can\ntherefore take on a directional bias, resulting in distinct patterns of\ndeposition, but current models struggle to capture this phenomenon. Recently,\nwe have developed a mathematical model of the axonal transport of toxic tau\nproteins that takes into account the effects tau exerts on the molecular\nmotors. Here we describe and implement a macroscopic version of this model,\nwhich we call the Network Transport Model (NTM). A key feature of this model is\nthat, while it predicts tau dynamics at a regional level, it is parameterized\nin terms of only microscopic processes such as aggregation and transport rates;\nthat is, differences in brain-wide tau progression can be explained by its\nmicroscopic properties. We provide numerical evidence that, as with the\ntwo-neuron model that the NTM extends, there are distinct and rich dynamics\nwith respect to the overall rate of spread and the staging of pathology when we\nsimulated the NTM on the hippocampal subnetwork. The theoretical insights\nprovided by the NTM have broad implications for understanding AD\npathophysiology more generally.",
                "authors": [
                    "Veronica Tora",
                    "Justin Torok",
                    "Michiel Bertsch",
                    "Ashish Raj"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02407v1",
                    "http://arxiv.org/pdf/2401.02407v1"
                ],
                "primary_category": "math.AP",
                "categories": [
                    "math.AP",
                    "q-bio.NC",
                    "05C90, 35A01, 35Q92, 92C50"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02406v1/1.0",
                "title": "Multi-segmented non-isothermal compositional liquid gas well model for\n  geothermal processes",
                "year": 2024,
                "abstract": "We consider a non-isothermal compositional gas liquid model for the\nsimulation of well operations in geothermal processes. The model accounts for\nphase transitions assumed to be at thermodynamical equilibrium and is based on\nan hydrodynamical Drift Flux Model (DFM) combined with a No Pressure Wave\napproximation of the momentum equation. The focus of this work is on the design\nof a robust discretization accounting for slanted and multibranch wells with\nthe ability to simulate both transient behavior such as well opening as well as\ncoupled simulations at the time scale of the reservoir. It is based on a\nstaggered finite volume scheme in space combined with a fully implicit Euler\ntime integration. The construction of consistent and stable numerical fluxes is\na key feature for a robust numerical method. It is achieved by combining a\nmonotone flux approximation for the phase superficial velocities with an upwind\napproximation of the phase molar fractions, density and enthalpy. In order to\nfacilitate the coupling of the well and reservoir models, the Newton\nlinearization accounts for the elimination of the hydrodynamical unknowns\nleading to Jacobian systems using the same primary unknowns than those of the\nreservoir model. The efficiency of our approach is investigated on both stand\nalone well test cases without and with cross flow, and on a fully coupled\nwell-reservoir simulation.",
                "authors": [
                    "Daniel Castanon Quiroz",
                    "Laurent Jeannin",
                    "Simon Lopez",
                    "Roland Masson"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02406v1",
                    "http://arxiv.org/pdf/2401.02406v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02404v1/1.0",
                "title": "Correctness Comparison of ChatGPT-4, Bard, Claude-2, and Copilot for\n  Spatial Tasks",
                "year": 2024,
                "abstract": "Generative AI including large language models (LLMs) have recently gained\nsignificant interest in the geo-science community through its versatile\ntask-solving capabilities including coding, spatial computations, generation of\nsample data, time-series forecasting, toponym recognition, or image\nclassification. So far, the assessment of LLMs for spatial tasks has primarily\nfocused on ChatGPT, arguably the most prominent AI chatbot, whereas other\nchatbots received less attention. To narrow this research gap, this study\nevaluates the correctness of responses for a set of 54 spatial tasks assigned\nto four prominent chatbots, i.e., ChatGPT-4, Bard, Claude-2, and Copilot.\nOverall, the chatbots performed well on spatial literacy, GIS theory, and\ninterpretation of programming code and given functions, but revealed weaknesses\nin mapping, code generation, and code translation. ChatGPT-4 outperformed other\nchatbots across most task categories.",
                "authors": [
                    "Hartwig H. Hochmair",
                    "Levente Juhasz",
                    "Takoda Kemp"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02404v1",
                    "http://arxiv.org/pdf/2401.02404v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02403v1/1.0",
                "title": "Real-Time 2D Temperature Field Prediction in Metal Additive\n  Manufacturing Using Physics-Informed Neural Networks",
                "year": 2024,
                "abstract": "Accurately predicting the temperature field in metal additive manufacturing\n(AM) processes is critical to preventing overheating, adjusting process\nparameters, and ensuring process stability. While physics-based computational\nmodels offer precision, they are often time-consuming and unsuitable for\nreal-time predictions and online control in iterative design scenarios.\nConversely, machine learning models rely heavily on high-quality datasets,\nwhich can be costly and challenging to obtain within the metal AM domain. Our\nwork addresses this by introducing a physics-informed neural network framework\nspecifically designed for temperature field prediction in metal AM. This\nframework incorporates a physics-informed input, physics-informed loss\nfunction, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture.\nUtilizing real-time temperature data from the process, our model predicts 2D\ntemperature fields for future timestamps across diverse geometries, deposition\npatterns, and process parameters. We validate the proposed framework in two\nscenarios: full-field temperature prediction for a thin wall and 2D temperature\nfield prediction for cylinder and cubic parts, demonstrating errors below 3%\nand 1%, respectively. Our proposed framework exhibits the flexibility to be\napplied across diverse scenarios with varying process parameters, geometries,\nand deposition patterns.",
                "authors": [
                    "Pouyan Sajadi",
                    "Mostafa Rahmani Dehaghani",
                    "Yifan Tang",
                    "G. Gary Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02403v1",
                    "http://arxiv.org/pdf/2401.02403v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02402v1/1.0",
                "title": "3D Open-Vocabulary Panoptic Segmentation with 2D-3D Vision-Language\n  Distillation",
                "year": 2024,
                "abstract": "3D panoptic segmentation is a challenging perception task, which aims to\npredict both semantic and instance annotations for 3D points in a scene.\nAlthough prior 3D panoptic segmentation approaches have achieved great\nperformance on closed-set benchmarks, generalizing to novel categories remains\nan open problem. For unseen object categories, 2D open-vocabulary segmentation\nhas achieved promising results that solely rely on frozen CLIP backbones and\nensembling multiple classification outputs. However, we find that simply\nextending these 2D models to 3D does not achieve good performance due to poor\nper-mask classification quality on novel categories. In this paper, we propose\nthe first method to tackle 3D open-vocabulary panoptic segmentation. Our model\ntakes advantage of the fusion between learnable LiDAR features and dense frozen\nvision CLIP features, using a single classification head to make predictions\nfor both base and novel classes. To further improve the classification\nperformance on novel classes and leverage the CLIP model, we propose two novel\nloss functions: object-level distillation loss and voxel-level distillation\nloss. Our experiments on the nuScenes and SemanticKITTI datasets show that our\nmethod outperforms strong baselines by a large margin.",
                "authors": [
                    "Zihao Xiao",
                    "Longlong Jing",
                    "Shangxuan Wu",
                    "Alex Zihao Zhu",
                    "Jingwei Ji",
                    "Chiyu Max Jiang",
                    "Wei-Chih Hung",
                    "Thomas Funkhouser",
                    "Weicheng Kuo",
                    "Anelia Angelova",
                    "Yin Zhou",
                    "Shiwei Sheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02402v1",
                    "http://arxiv.org/pdf/2401.02402v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02394v1/1.0",
                "title": "Image denoising and model-independent parameterization for improving\n  IVIM MRI",
                "year": 2024,
                "abstract": "Variability of IVIM parameters throughout the literature is a long-standing\nissue, and perfusion-related parameters are difficult to interpret. We\ndemonstrate for improving the analysis of intravoxel incoherent motion imaging\n(IVIM) magnetic resonance (MR) images, using image denoising and a quantitative\napproach that does not require imposing specific exponential models. IVIM\nimages were acquired for 13 head-and-neck patients prior to radiotherapy. Of\nthese, 5 patients also had post-radiotherapy scans acquired. Image quality was\nimproved prior to parameter fitting via denoising. For this, we employed neural\nblind deconvolution, a method of undertaking the ill-posed mathematical problem\nof blind deconvolution using neural networks. The signal decay curve was then\nquantified in terms of area under the curve ($AUC$) parameters. Denoised images\nwere assessed in terms of blind image quality metrics, and correlations between\ntheir derived parameters in parotid glands with radiotherapy dose levels. We\nassessed the method's ability to recover artificial pseudokernels which had\nbeen applied to denoised images. $AUC$ parameters were compared with the\napparent diffusion coefficient ($ADC$), biexponential, and triexponential model\nparameters, in terms of their correlations with dose, and their relative\ncontributions to the total variance of the dataset, obtained through singular\nvalue decomposition. Image denoising resulted in improved blind image quality\nmetrics, and higher correlations between IVIM parameters and dose. $AUC$\nparameters were more correlated with dose than traditional IVIM parameters, and\ncaptured the highest proportion of the dataset's variance. V This method of\ndescribing the signal decay curve with model-independent parameters like the\n$AUC$, and preprocessing images with denoising techniques, shows potential for\nimproving reproducibility and utility of IVIM imaging.",
                "authors": [
                    "Caleb Sample",
                    "Jonn Wu",
                    "Haley Clark"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02394v1",
                    "http://arxiv.org/pdf/2401.02394v1"
                ],
                "primary_category": "physics.med-ph",
                "categories": [
                    "physics.med-ph",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02393v1/1.0",
                "title": "A PDE approach for solving the characteristic function of the\n  generalised signature process",
                "year": 2024,
                "abstract": "The signature of a path, as a fundamental object in Rough path theory, serves\nas a generating function for non-communicative monomials on path space. It\ntransforms the path into a grouplike element in the tensor algebra space,\nsummarising the path faithfully up to a generalised form of re-parameterisation\n(a negligible equivalence class in this context). Our paper concerns stochastic\nprocesses and studies the characteristic function of the path signature of the\nstochastic process. In contrast to the expected signature, it determines the\nlaw on the random signatures without any regularity condition. The computation\nof the characteristic function of the random signature offers potential\napplications in stochastic analysis and machine learning, where the expected\nsignature plays an important role. In this paper, we focus on a\ntime-homogeneous It\\^o diffusion process, and adopt a PDE approach to derive\nthe characteristic function of its signature defined at any fixed time horizon.\nA key ingredient of our approach is the introduction of the\ngeneralised-signature process. This lifting enables us to establish the\nFeynman-Kac-type theorem for the characteristic function of the\ngeneralised-signature process by following the martingale approach. Moreover,\nas an application of our results, we present a novel derivation of the joint\ncharacteristic function of Brownian motion coupled with the L\\'evy area,\nleveraging the structure theorem of anti-symmetric matrices.",
                "authors": [
                    "Terry Lyons",
                    "Hao Ni",
                    "Jiajie Tao"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02393v1",
                    "http://arxiv.org/pdf/2401.02393v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "math.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02391v1/1.0",
                "title": "Updated numerical study of transverse single-spin asymmetries in\n  single-inclusive pion production from lepton-nucleon collisions",
                "year": 2024,
                "abstract": "We revisit the analysis of transverse single-spin asymmetries $A_N$ in\nlepton-nucleon scattering where only a single pion is detected in the final\nstate, $\\ell\\,N^\\uparrow\\to h\\, X$. This observable is the Electron-Ion\nCollider (EIC) analogue to $A_N$ in proton-proton collisions, $p^\\uparrow p\\to\nh\\,X$, that has been studied intensely for decades, especially at the\nRelativistic Heavy Ion Collider (RHIC). We incorporate new theoretical\ndevelopments in the collinear twist-3 framework and utilize recent extractions\nof (Sivers-like and Collins-like) quark-gluon-quark correlators in the\nnumerical computations. We compare our calculations to HERMES measurements as\nwell as make predictions for Jefferson Lab, COMPASS, and EIC kinematics. We\nfurther explore the role of next-to-leading order (NLO) corrections to the\n(twist-2) unpolarized cross section (denominator of $A_N$) and consider what\ncan be deduced empirically about the potential numerical significance of the\nfull NLO calculation of $A_N$ in this process. We consider sources of\ntheoretical uncertainty in our predictions, which present potential\nopportunities then for future measurements to improve our understanding of\n$A_N$ and multi-parton correlations in hadrons.",
                "authors": [
                    "Sophia Fitzgibbons",
                    "Michel Malda",
                    "Jacob Marsh",
                    "Daniel Pitonyak",
                    "Penn Smith"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02391v1",
                    "http://arxiv.org/pdf/2401.02391v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "hep-ex",
                    "nucl-ex",
                    "nucl-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02386v1/1.0",
                "title": "Direction of Arrival Estimation Using Microphone Array Processing for\n  Moving Humanoid Robots",
                "year": 2024,
                "abstract": "The auditory system of humanoid robots has gained increased attention in\nrecent years. This system typically acquires the surrounding sound field by\nmeans of a microphone array. Signals acquired by the array are then processed\nusing various methods. One of the widely applied methods is direction of\narrival estimation. The conventional direction of arrival estimation methods\nassume that the array is fixed at a given position during the estimation.\nHowever, this is not necessarily true for an array installed on a moving\nhumanoid robot. The array motion, if not accounted for appropriately, can\nintroduce a significant error in the estimated direction of arrival. The\ncurrent paper presents a signal model that takes the motion into account. Based\non this model, two processing methods are proposed. The first one compensates\nfor the motion of the robot. The second method is applicable to periodic\nsignals and utilizes the motion in order to enhance the performance to a level\nbeyond that of a stationary array. Numerical simulations and an experimental\nstudy are provided, demonstrating that the motion compensation method almost\neliminates the motion-related error. It is also demonstrated that by using the\nmotion-based enhancement method it is possible to improve the direction of\narrival estimation performance, as compared to that obtained when using a\nstationary array.",
                "authors": [
                    "Vladimir Tourbabin",
                    "Boaz Rafaely"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/TASLP.2015.2464671",
                    "http://arxiv.org/abs/2401.02386v1",
                    "http://arxiv.org/pdf/2401.02386v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.RO",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02385v1/1.0",
                "title": "TinyLlama: An Open-Source Small Language Model",
                "year": 2024,
                "abstract": "We present TinyLlama, a compact 1.1B language model pretrained on around 1\ntrillion tokens for approximately 3 epochs. Building on the architecture and\ntokenizer of Llama 2, TinyLlama leverages various advances contributed by the\nopen-source community (e.g., FlashAttention), achieving better computational\nefficiency. Despite its relatively small size, TinyLlama demonstrates\nremarkable performance in a series of downstream tasks. It significantly\noutperforms existing open-source language models with comparable sizes. Our\nmodel checkpoints and code are publicly available on GitHub at\nhttps://github.com/jzhang38/TinyLlama.",
                "authors": [
                    "Peiyuan Zhang",
                    "Guangtao Zeng",
                    "Tianduo Wang",
                    "Wei Lu"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02385v1",
                    "http://arxiv.org/pdf/2401.02385v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02384v1/1.0",
                "title": "ChartAssisstant: A Universal Chart Multimodal Language Model via\n  Chart-to-Table Pre-training and Multitask Instruction Tuning",
                "year": 2024,
                "abstract": "Charts play a vital role in data visualization, understanding data patterns,\nand informed decision-making. However, their unique combination of graphical\nelements (e.g., bars, lines) and textual components (e.g., labels, legends)\nposes challenges for general-purpose multimodal models. While vision-language\nmodels trained on chart data excel in comprehension, they struggle with\ngeneralization and require task-specific fine-tuning. To address these\nchallenges, we propose ChartAssistant, a chart-based vision-language model for\nuniversal chart comprehension and reasoning. ChartAssistant leverages ChartSFT,\na comprehensive dataset covering diverse chart-related tasks with basic and\nspecialized chart types. It undergoes a two-stage training process, starting\nwith pre-training on chart-to-table parsing to align chart and text, followed\nby multitask instruction-following fine-tuning. This approach enables\nChartAssistant to achieve competitive performance across various chart tasks\nwithout task-specific fine-tuning. Experimental results demonstrate significant\nperformance gains over the state-of-the-art UniChart method, outperforming\nOpenAI's GPT-4V(ision) on real-world chart data. The code and data are\navailable at https://github.com/OpenGVLab/ChartAst.",
                "authors": [
                    "Fanqing Meng",
                    "Wenqi Shao",
                    "Quanfeng Lu",
                    "Peng Gao",
                    "Kaipeng Zhang",
                    "Yu Qiao",
                    "Ping Luo"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02384v1",
                    "http://arxiv.org/pdf/2401.02384v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.02378v1/1.0",
                "title": "Opinion formation in the world trade network",
                "year": 2024,
                "abstract": "We extend the opinion formation approach to probe the world influence of\neconomical organizations. Our opinion formation model mimics a battle between\ncurrencies within the international trade network. Based on the United Nations\nComtrade database, we construct the world trade network for the years of the\nlast decade from 2010 to 2020. We consider different core groups constituted by\ncountries preferring to trade in a specific currency. We will consider\nprincipally two core groups, namely, 5 Anglo-Saxon countries which prefer to\ntrade in US dollar and the 11 BRICS+ which prefer to trade in a hypothetical\ncurrency, hereafter called BRI, pegged to their economies. We determine the\ntrade currency preference of the other countries via a Monte Carlo process\ndepending on the direct transactions between the countries. The results\nobtained in the frame of this mathematical model show that starting from year\n2014 the majority of the world countries would have preferred to trade in BRI\nthan USD. The Monte Carlo process reaches a steady state with 3 distinct\ngroups: two groups of countries preferring, whatever is the initial\ndistribution of the trade currency preferences, to trade, one in BRI and the\nother in USD, and a third group of countries swinging as a whole between USD\nand BRI depending on the initial distribution of the trade currency\npreferences. We also analyze the battle between USD, EUR and BRI, and present\nthe reduced Google matrix description of the trade relations between the\nAnglo-Saxon countries and the BRICS+.",
                "authors": [
                    "C\u00e9lestin Coquid\u00e9",
                    "Jos\u00e9 Lages",
                    "Dima L. Shepelyansky"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.02378v1",
                    "http://arxiv.org/pdf/2401.02378v1"
                ],
                "primary_category": "q-fin.TR",
                "categories": [
                    "q-fin.TR",
                    "cond-mat.stat-mech",
                    "cs.SI",
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15227v1/1.0",
                "title": "Epidemic modeling and flattening the infection curve in social networks",
                "year": 2023,
                "abstract": "The main goal of this paper is to model the epidemic and flattening the\ninfection curve of the social networks. Flattening the infection curve implies\nslowing down the spread of the disease and reducing the infection rate via\nsocial-distancing, isolation (quarantine) and vaccination. The\nnan-pharmaceutical methods are a much simpler and efficient way to control the\nspread of epidemic and infection rate. By specifying a target group with high\ncentrality for isolation and quarantine one can reach a much flatter infection\ncurve (related to Corona for example) without adding extra costs to health\nservices. The aim of this research is, first, modeling the epidemic and, then,\ngiving strategies and structural algorithms for targeted vaccination or\ntargeted non-pharmaceutical methods for reducing the peak of the viral disease\nand flattening the infection curve. These methods are more efficient for\nnan-pharmaceutical interventions as finding the target quarantine group\nflattens the infection curve much easier. For this purpose, a few number of\nparticular nodes with high centrality are isolated and the infection curve is\nanalyzed. Our research shows meaningful results for flattening the infection\ncurve only by isolating a few number of targeted nodes in the social network.\nThe proposed methods are independent of the type of the disease and are\neffective for any viral disease, e.g., Covid-19.",
                "authors": [
                    "Mohammadreza Doostmohammadian",
                    "Soraya Doustmohamadian",
                    "Najmeh Doostmohammadian",
                    "Azam Doustmohammadian",
                    "Houman Zarrabi",
                    "Hamid R. Rabiee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15227v1",
                    "http://arxiv.org/pdf/2311.15227v1"
                ],
                "primary_category": "cs.SI",
                "categories": [
                    "cs.SI",
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14742v1/1.0",
                "title": "Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce\n  Relevance",
                "year": 2023,
                "abstract": "Relevance module plays a fundamental role in e-commerce search as they are\nresponsible for selecting relevant products from thousands of items based on\nuser queries, thereby enhancing users experience and efficiency. The\ntraditional approach models the relevance based product titles and queries, but\nthe information in titles alone maybe insufficient to describe the products\ncompletely. A more general optimization approach is to further leverage product\nimage information. In recent years, vision-language pre-training models have\nachieved impressive results in many scenarios, which leverage contrastive\nlearning to map both textual and visual features into a joint embedding space.\nIn e-commerce, a common practice is to fine-tune on the pre-trained model based\non e-commerce data. However, the performance is sub-optimal because the\nvision-language pre-training models lack of alignment specifically designed for\nqueries. In this paper, we propose a method called Query-LIFE (Query-aware\nLanguage Image Fusion Embedding) to address these challenges. Query-LIFE\nutilizes a query-based multimodal fusion to effectively incorporate the image\nand title based on the product types. Additionally, it employs query-aware\nmodal alignment to enhance the accuracy of the comprehensive representation of\nproducts. Furthermore, we design GenFilt, which utilizes the generation\ncapability of large models to filter out false negative samples and further\nimprove the overall performance of the contrastive learning task in the model.\nExperiments have demonstrated that Query-LIFE outperforms existing baselines.\nWe have conducted ablation studies and human evaluations to validate the\neffectiveness of each module within Query-LIFE. Moreover, Query-LIFE has been\ndeployed on Miravia Search, resulting in improved both relevance and conversion\nefficiency.",
                "authors": [
                    "Hai Zhu",
                    "Yuankai Guo",
                    "Ronggang Dou",
                    "Kai Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14742v1",
                    "http://arxiv.org/pdf/2311.14742v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15222v2/1.0",
                "title": "Decision Tree Psychological Risk Assessment in Currency Trading",
                "year": 2023,
                "abstract": "This research paper focuses on the integration of Artificial Intelligence\n(AI) into the currency trading landscape, positing the development of\npersonalized AI models, essentially functioning as intelligent personal\nassistants tailored to the idiosyncrasies of individual traders. The paper\nposits that AI models are capable of identifying nuanced patterns within the\ntrader's historical data, facilitating a more accurate and insightful\nassessment of psychological risk dynamics in currency trading. The PRI is a\ndynamic metric that experiences fluctuations in response to market conditions\nthat foster psychological fragility among traders. By employing sophisticated\ntechniques, a classifying decision tree is crafted, enabling clearer\ndecision-making boundaries within the tree structure. By incorporating the\nuser's chronological trade entries, the model becomes adept at identifying\ncritical junctures when psychological risks are heightened. The real-time\nnature of the calculations enhances the model's utility as a proactive tool,\noffering timely alerts to traders about impending moments of psychological\nrisks. The implications of this research extend beyond the confines of currency\ntrading, reaching into the realms of other industries where the judicious\napplication of personalized modeling emerges as an efficient and strategic\napproach. This paper positions itself at the intersection of cutting-edge\ntechnology and the intricate nuances of human psychology, offering a\ntransformative paradigm for decision making support in dynamic and\nhigh-pressure environments.",
                "authors": [
                    "Jai Pal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15222v2",
                    "http://arxiv.org/pdf/2311.15222v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CE",
                    "q-fin.GN"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15221v1/1.0",
                "title": "The Local Landscape of Phase Retrieval Under Limited Samples",
                "year": 2023,
                "abstract": "In this paper, we provide a fine-grained analysis of the local landscape of\nphase retrieval under the regime with limited samples. Our aim is to ascertain\nthe minimal sample size necessary to guarantee a benign local landscape\nsurrounding global minima in high dimensions. Let $n$ and $d$ denote the sample\nsize and input dimension, respectively. We first explore the local convexity\nand establish that when $n=o(d\\log d)$, for almost every fixed point in the\nlocal ball, the Hessian matrix must have negative eigenvalues as long as $d$ is\nsufficiently large. Consequently, the local landscape is highly non-convex. We\nnext consider the one-point strong convexity and show that as long as\n$n=\\omega(d)$, with high probability, the landscape is one-point strongly\nconvex in the local annulus: $\\{w\\in\\mathbb{R}^d: o_d(1)\\leqslant\n\\|w-w^*\\|\\leqslant c\\}$, where $w^*$ is the ground truth and $c$ is an absolute\nconstant. This implies that gradient descent initialized from any point in this\ndomain can converge to an $o_d(1)$-loss solution exponentially fast.\nFurthermore, we show that when $n=o(d\\log d)$, there is a radius of\n$\\widetilde\\Theta\\left(\\sqrt{1/d}\\right)$ such that one-point convexity breaks\nin the corresponding smaller local ball. This indicates an impossibility to\nestablish a convergence to exact $w^*$ for gradient descent under limited\nsamples by relying solely on one-point convexity.",
                "authors": [
                    "Kaizhao Liu",
                    "Zihao Wang",
                    "Lei Wu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15221v1",
                    "http://arxiv.org/pdf/2311.15221v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "cs.LG",
                    "eess.SP",
                    "math.IT",
                    "math.OC",
                    "math.ST",
                    "stat.ML",
                    "stat.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15218v4/1.0",
                "title": "Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and\n  Qualitative Analysis",
                "year": 2023,
                "abstract": "The application of Machine learning to finance has become a familiar\napproach, even more so in stock market forecasting. The stock market is highly\nvolatile, and huge amounts of data are generated every minute globally. The\nextraction of effective intelligence from this data is of critical importance.\nHowever, a collaboration of numerical stock data with qualitative text data can\nbe a challenging task. In this work, we accomplish this by providing an\nunprecedented, publicly available dataset with technical and fundamental data\nand sentiment that we gathered from news archives, TV news captions, radio\ntranscripts, tweets, daily financial newspapers, etc. The text data entries\nused for sentiment extraction total more than 1.4 Million. The dataset consists\nof daily entries from January 2018 to December 2022 for eight companies\nrepresenting diverse industrial sectors and the Dow Jones Industrial Average\n(DJIA) as a whole. Holistic Fundamental and Technical data is provided training\nready for Model learning and deployment. Most importantly, the data generated\ncould be used for incremental online learning with real-time data points\nretrieved daily since no stagnant data was utilized. All the data was retired\nfrom APIs or self-designed robust information retrieval technologies with\nextremely low latency and zero monetary cost. These adaptable technologies\nfacilitate data extraction for any stock. Moreover, the utilization of\nSpearman's rank correlation over real-time data, linking stock returns with\nsentiment analysis has produced noteworthy results for the DJIA and the eight\nother stocks, achieving accuracy levels surpassing 60%. The dataset is made\navailable at https://github.com/batking24/Huge-Stock-Dataset.",
                "authors": [
                    "Sai Akash Bathini",
                    "Dagli Cihan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15218v4",
                    "http://arxiv.org/pdf/2311.15218v4"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.CE",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15215v1/1.0",
                "title": "From OTFS to DD-ISAC: Integrating Sensing and Communications in the\n  Delay Doppler Domain",
                "year": 2023,
                "abstract": "Next-generation vehicular networks are expected to provide the capability of\nrobust environmental sensing in addition to reliable communications to meet\nintelligence requirements. A promising solution is the integrated sensing and\ncommunication (ISAC) technology, which performs both functionalities using the\nsame spectrum and hardware resources. Most existing works on ISAC consider the\nOrthogonal Frequency Division Multiplexing (OFDM) waveform. Nevertheless,\nvehicle motion introduces Doppler shift, which breaks the subcarrier\northogonality and leads to performance degradation. The recently proposed\nOrthogonal Time Frequency Space (OTFS) modulation, which exploits various\nadvantages of Delay Doppler (DD) channels, has been shown to support reliable\ncommunication in high-mobility scenarios. Moreover, the DD waveform can\ndirectly interact with radar sensing parameters, which are actually delay and\nDoppler shifts. This paper investigates the advantages of applying the DD\ncommunication waveform to ISAC. Specifically, we first provide a comprehensive\noverview of implementing DD communications, based on which several advantages\nof DD-ISAC over OFDM-based ISAC are revealed, including transceiver designs and\nthe ambiguity function. Furthermore, a detailed performance comparison are\npresented, where the target detection probability and the mean squared error\n(MSE) performance are also studied. Finally, some challenges and opportunities\nof DD-ISAC are also provided.",
                "authors": [
                    "Weijie Yuan",
                    "Lin Zhou",
                    "Saeid K. Dehkordi",
                    "Shuangyang Li",
                    "Pingzhi Fan",
                    "Giuseppe Caire",
                    "H. Vincent Poor"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15215v1",
                    "http://arxiv.org/pdf/2311.15215v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15213v1/1.0",
                "title": "Leveraging Anatomical Constraints with Uncertainty for Pneumothorax\n  Segmentation",
                "year": 2023,
                "abstract": "Pneumothorax is a medical emergency caused by abnormal accumulation of air in\nthe pleural space - the potential space between the lungs and chest wall. On 2D\nchest radiographs, pneumothorax occurs within the thoracic cavity and outside\nof the mediastinum and we refer to this area as \"lung+ space\". While deep\nlearning (DL) has increasingly been utilized to segment pneumothorax lesions in\nchest radiographs, many existing DL models employ an end-to-end approach. These\nmodels directly map chest radiographs to clinician-annotated lesion areas,\noften neglecting the vital domain knowledge that pneumothorax is inherently\nlocation-sensitive.\n  We propose a novel approach that incorporates the lung+ space as a constraint\nduring DL model training for pneumothorax segmentation on 2D chest radiographs.\nTo circumvent the need for additional annotations and to prevent potential\nlabel leakage on the target task, our method utilizes external datasets and an\nauxiliary task of lung segmentation. This approach generates a specific\nconstraint of lung+ space for each chest radiograph. Furthermore, we have\nincorporated a discriminator to eliminate unreliable constraints caused by the\ndomain shift between the auxiliary and target datasets.\n  Our results demonstrated significant improvements, with average performance\ngains of 4.6%, 3.6%, and 3.3% regarding Intersection over Union (IoU), Dice\nSimilarity Coefficient (DSC), and Hausdorff Distance (HD). Our research\nunderscores the significance of incorporating medical domain knowledge about\nthe location-specific nature of pneumothorax to enhance DL-based lesion\nsegmentation.",
                "authors": [
                    "Han Yuan",
                    "Chuan Hong",
                    "Nguyen Tuan Anh Tran",
                    "Xinxing Xu",
                    "Nan Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15213v1",
                    "http://arxiv.org/pdf/2311.15213v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15212v1/1.0",
                "title": "OpenPerf: A Benchmarking Framework for the Sustainable Development of\n  the Open-Source Ecosystem",
                "year": 2023,
                "abstract": "Benchmarking involves designing scientific test methods, tools, and\nframeworks to quantitatively and comparably assess specific performance\nindicators of certain test subjects. With the development of artificial\nintelligence, AI benchmarking datasets such as ImageNet and DataPerf have\ngradually become consensus standards in both academic and industrial fields.\nHowever, constructing a benchmarking framework remains a significant challenge\nin the open-source domain due to the diverse range of data types, the wide\narray of research issues, and the intricate nature of collaboration networks.\nThis paper introduces OpenPerf, a benchmarking framework designed for the\nsustainable development of the open-source ecosystem. This framework defines 9\ntask benchmarking tasks in the open-source research, encompassing 3 data types:\ntime series, text, and graphics, and addresses 6 research problems including\nregression, classification, recommendation, ranking, network building, and\nanomaly detection. Based on the above tasks, we implemented 3 data science task\nbenchmarks, 2 index-based benchmarks, and 1 standard benchmark. Notably, the\nindex-based benchmarks have been adopted by the China Electronics\nStandardization Institute as evaluation criteria for open-source community\ngovernance. Additionally, we have developed a comprehensive toolkit for\nOpenPerf, which not only offers robust data management, tool integration, and\nuser interface capabilities but also adopts a Benchmarking-as-a-Service (BaaS)\nmodel to serve academic institutions, industries, and foundations. Through its\napplication in renowned companies and institutions such as Alibaba, Ant Group,\nand East China Normal University, we have validated OpenPerf's pivotal role in\nthe healthy evolution of the open-source ecosystem.",
                "authors": [
                    "Fenglin Bi",
                    "Fanyu Han",
                    "Shengyu Zhao",
                    "Jinlu Li",
                    "Yanbin Zhang",
                    "Wei Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15212v1",
                    "http://arxiv.org/pdf/2311.15212v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15211v1/1.0",
                "title": "Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation",
                "year": 2023,
                "abstract": "Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.",
                "authors": [
                    "Haoyi Wu",
                    "Kewei Tu"
                ],
                "url": [
                    "http://dx.doi.org/10.18653/v1/2023.findings-acl.482",
                    "http://arxiv.org/abs/2311.15211v1",
                    "http://arxiv.org/pdf/2311.15211v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15210v1/1.0",
                "title": "Topology combined machine learning for consonant recognition",
                "year": 2023,
                "abstract": "In artificial-intelligence-aided signal processing, existing deep learning\nmodels often exhibit a black-box structure, and their validity and\ncomprehensibility remain elusive. The integration of topological methods,\ndespite its relatively nascent application, serves a dual purpose of making\nmodels more interpretable as well as extracting structural information from\ntime-dependent data for smarter learning. Here, we provide a transparent and\nbroadly applicable methodology, TopCap, to capture the most salient topological\nfeatures inherent in time series for machine learning. Rooted in\nhigh-dimensional ambient spaces, TopCap is capable of capturing features rarely\ndetected in datasets with low intrinsic dimensionality. Applying time-delay\nembedding and persistent homology, we obtain descriptors which encapsulate\ninformation such as the vibration of a time series, in terms of its variability\nof frequency, amplitude, and average line, demonstrated with simulated data.\nThis information is then vectorised and fed into multiple machine learning\nalgorithms such as k-nearest neighbours and support vector machine. Notably, in\nclassifying voiced and voiceless consonants, TopCap achieves an accuracy\nexceeding 96% and is geared towards designing topological convolutional layers\nfor deep learning of speech and audio signals.",
                "authors": [
                    "Pingyao Feng",
                    "Siheng Yi",
                    "Qingrui Qu",
                    "Zhiwang Yu",
                    "Yifei Zhu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15210v1",
                    "http://arxiv.org/pdf/2311.15210v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.ST",
                    "stat.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16501v1/1.0",
                "title": "PISA: Point-cloud-based Instructed Scene Augmentation",
                "year": 2023,
                "abstract": "Indoor scene augmentation has become an emerging topic in the field of\ncomputer vision with applications in augmented and virtual reality. However,\nexisting scene augmentation methods mostly require a pre-built object database\nwith a given position as the desired location. In this paper, we propose the\nfirst end-to-end multi-modal deep neural network that can generate point cloud\nobjects consistent with their surroundings, conditioned on text instructions.\nOur model generates a seemly object in the appropriate position based on the\ninputs of a query and point clouds, thereby enabling the creation of new\nscenarios involving previously unseen layouts of objects. Database of\npre-stored CAD models is no longer needed. We use Point-E as our generative\nmodel and introduce methods including quantified position prediction and Top-K\nestimation to mitigate the false negative problems caused by ambiguous language\ndescription. Moreover, we evaluate the ability of our model by demonstrating\nthe diversity of generated objects, the effectiveness of instruction, and\nquantitative metric results, which collectively indicate that our model is\ncapable of generating realistic in-door objects. For a more thorough\nevaluation, we also incorporate visual grounding as a metric to assess the\nquality of the scenes generated by our model.",
                "authors": [
                    "Yiyang Luo",
                    "Ke Lin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16501v1",
                    "http://arxiv.org/pdf/2311.16501v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15209v2/1.0",
                "title": "See and Think: Embodied Agent in Virtual Environment",
                "year": 2023,
                "abstract": "Large language models (LLMs) have achieved impressive progress on several\nopen-world tasks. Recently, using LLMs to build embodied agents has been a\nhotspot. In this paper, we propose STEVE, a comprehensive and visionary\nembodied agent in the Minecraft virtual environment. STEVE consists of three\nkey components: vision perception, language instruction, and code action.\nVision perception involves the interpretation of visual information in the\nenvironment, which is then integrated into the LLMs component with agent state\nand task instruction. Language instruction is responsible for iterative\nreasoning and decomposing complex tasks into manageable guidelines. Code action\ngenerates executable skill actions based on retrieval in skill database,\nenabling the agent to interact effectively within the Minecraft environment. We\nalso collect STEVE-21K dataset, which includes 600$+$ vision-environment pairs,\n20K knowledge question-answering pairs, and 200$+$ skill-code pairs. We conduct\ncontinuous block search, knowledge question and answering, and tech tree\nmastery to evaluate the performance. Extensive experiments show that STEVE\nachieves at most $1.5 \\times$ faster unlocking key tech trees and $2.5 \\times$\nquicker in block search tasks compared to previous state-of-the-art methods.",
                "authors": [
                    "Zhonghan Zhao",
                    "Wenhao Chai",
                    "Xuan Wang",
                    "Li Boyi",
                    "Shengyu Hao",
                    "Shidong Cao",
                    "Tian Ye",
                    "Jenq-Neng Hwang",
                    "Gaoang Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15209v2",
                    "http://arxiv.org/pdf/2311.15209v2"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15208v1/1.0",
                "title": "LongStory: Coherent, Complete and Length Controlled Long story\n  Generation",
                "year": 2023,
                "abstract": "A human author can write any length of story without losing coherence. Also,\nthey always bring the story to a proper ending, an ability that current\nlanguage models lack. In this work, we present the LongStory for coherent,\ncomplete, and length-controlled long story generation. LongStory introduces two\nnovel methodologies: (1) the long and short-term contexts weight calibrator\n(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights\nfor long-term context Memory and short-term context Cheating, acknowledging\ntheir distinct roles. The LSP employs discourse tokens to convey the structural\npositions of a long story. Trained on three datasets with varied average story\nlengths, LongStory outperforms other baselines, including the strong story\ngenerator Plotmachine, in coherence, completeness, relevance, and\nrepetitiveness. We also perform zero-shot tests on each dataset to assess the\nmodel's ability to predict outcomes beyond its training data and validate our\nmethodology by comparing its performance with variants of our model.",
                "authors": [
                    "Kyeongman Park",
                    "Nakyeong Yang",
                    "Kyomin Jung"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15208v1",
                    "http://arxiv.org/pdf/2311.15208v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15207v1/1.0",
                "title": "Efficient interpolation of molecular properties across chemical compound\n  space with low-dimensional descriptors",
                "year": 2023,
                "abstract": "We demonstrate accurate data-starved models of molecular properties for\ninterpolation in chemical compound spaces with low-dimensional descriptors.\n  Our starting point is based on three-dimensional, universal, physical\ndescriptors derived from the properties of the distributions of the eigenvalues\nof Coulomb matrices. To account for the shape and composition of molecules, we\ncombine these descriptors with six-dimensional features informed by the\nGershgorin circle theorem. We use the nine-dimensional descriptors thus\nobtained for Gaussian process regression based on kernels with variable\nfunctional form, leading to extremely efficient, low-dimensional interpolation\nmodels. The resulting models trained with 100 molecules are able to predict the\nproduct of entropy and temperature ($S \\times T$) and zero point vibrational\nenergy (ZPVE) with the absolute error under 1 kcal mol$^{-1}$ for $> 78$ \\% and\nunder 1.3 kcal mol$^{-1}$ for $> 92$ \\% of molecules in the test data. The test\ndata comprises 20,000 molecules with complexity varying from three atoms to 29\natoms and the ranges of $S \\times T$ and ZPVE covering 36 kcal mol$^{-1}$ and\n161 kcal mol$^{-1}$, respectively. We also illustrate that the descriptors\nbased on the Gershgorin circle theorem yield more accurate models of molecular\nentropy than those based on graph neural networks that explicitly account for\nthe atomic connectivity of molecules.",
                "authors": [
                    "Yun-Wen Mao",
                    "Roman V. Krems"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15207v1",
                    "http://arxiv.org/pdf/2311.15207v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15205v1/1.0",
                "title": "Discrete stopping times in the lattice of continuous functions",
                "year": 2023,
                "abstract": "A functional calculus for an order complete vector lattice $\\mathcal{E}$ was\ndeveloped by Grobler in 2014 using the Daniell integral. We show that if one\nrepresents the universal completion of $\\mathcal{E}$ as $C^\\infty(K)$, then the\nDaniell functional calculus for continuous functions is exactly the pointwise\ncomposition of functions in $C^\\infty(K)$. This representation allows an easy\ndeduction of the various properties of the functional calculus. Afterwards, we\nstudy discrete stopping times and stopped processes in $C^\\infty(K)$. We obtain\na representation that is analogous to what is expected in probability theory.",
                "authors": [
                    "Achintya Raya Polavarapu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15205v1",
                    "http://arxiv.org/pdf/2311.15205v1"
                ],
                "primary_category": "math.FA",
                "categories": [
                    "math.FA",
                    "46A40, 46E05, 60G20, 60G40"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15204v1/1.0",
                "title": "OpenDigger: Data Mining and Information Service System for Open\n  Collaboration Digital Ecosystem",
                "year": 2023,
                "abstract": "The widespread development and adoption of open-source software have built an\necosystem for open development and collaboration. In this ecosystem,\nindividuals and organizations collaborate to create high-quality software that\ncan be used by everyone. Social collaboration platforms like GitHub have\nfurther facilitated large-scale, distributed, and fine-grained code\ncollaboration and technical interactions. Countless developers contribute code,\nreview code, report bugs, and propose new features on these platforms every\nday, generating a massive amount of valuable behavioral data from the open\ncollaboration process. This paper presents the design and implementation of\nOpenDigger, a comprehensive data mining and information service system for open\ncollaboration in the digital ecosystem. The goal is to build a data\ninfrastructure for the open-source domain and promote the continuous\ndevelopment of the open-source ecosystem. The metrics and analysis models in\nthe OpenDigger system can mine various knowledge from the macro to micro levels\nin the open-source digital ecosystem. Through a unified information service\ninterface, OpenDigger provides various open-source information services to\ndifferent user groups, including governments, enterprises, foundations, and\nindividuals. As a novel information service system in the open-source\necosystem, this paper demonstrates the effectiveness of the metrics and models\nin OpenDigger through several real-world scenarios, including products, tools,\napplications, and courses. It showcases the significant and diverse practical\napplications of the metrics and models in both algorithmic and business\naspects.",
                "authors": [
                    "Xiaoya Xia",
                    "Shengyu Zhao",
                    "Fanyu Han",
                    "Fenglin Bi",
                    "Wei Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15204v1",
                    "http://arxiv.org/pdf/2311.15204v1"
                ],
                "primary_category": "cs.DL",
                "categories": [
                    "cs.DL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15198v1/1.0",
                "title": "ChatGPT and Beyond: The Generative AI Revolution in Education",
                "year": 2023,
                "abstract": "The wide adoption and usage of generative artificial intelligence (AI)\nmodels, particularly ChatGPT, has sparked a surge in research exploring their\npotential applications in the educational landscape. This survey examines\nacademic literature published between November, 2022, and July, 2023,\nspecifically targeting high-impact research from Scopus-indexed Q1 and Q2\njournals. This survey delves into the practical applications and implications\nof generative AI models across a diverse range of educational contexts. Through\na comprehensive and rigorous evaluation of recent academic literature, this\nsurvey seeks to illuminate the evolving role of generative AI models,\nparticularly ChatGPT, in education. By shedding light on the potential\nbenefits, challenges, and emerging trends in this dynamic field, the survey\nendeavors to contribute to the understanding of the nexus between artificial\nintelligence and education. The findings of this review will empower educators,\nresearchers, and policymakers to make informed decisions about the integration\nof AI technologies into learning environments.",
                "authors": [
                    "Mohammad AL-Smadi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15198v1",
                    "http://arxiv.org/pdf/2311.15198v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.03719v3/1.0",
                "title": "Assessing AI Chatbots Performance in Comprehensive Standardized Test\n  Preparation; A Case Study with GRE",
                "year": 2023,
                "abstract": "This research paper presents an analysis of how well three artificial\nintelligence chatbots, Bing, ChatGPT, and GPT-4, perform when answering\nquestions from standardized tests. The Graduate Record Examination (GRE) is\nused in this paper as a case study. A total of 137 questions with different\nforms of quantitative reasoning and 157 questions with verbal categories were\nused to assess their capabilities. This paper presents the performance of each\nchatbot across various skills and styles tested in the exam. This paper also\nexplores the proficiency of these chatbots in addressing image-based questions\nand illustrates the uncertainty level of each chatbot. The results show varying\ndegrees of success across the chatbots, where GPT-4 served as the most\nproficient, especially in complex language understanding tasks and image-based\nquestions. Results highlight the ability of these chatbots to pass the GRE with\na high score, which encourages the use of these chatbots in test preparation.\nThe results also show how important it is to ensure that, if the test is\nadministered online, as it was during COVID, the test taker is segregated from\nthese resources for a fair competition on higher education opportunities.",
                "authors": [
                    "Mohammad Abu-Haifa",
                    "Bara'a Etawi",
                    "Huthaifa Alkhatatbeh",
                    "Ayman Ababneh"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.03719v3",
                    "http://arxiv.org/pdf/2312.03719v3"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15194v1/1.0",
                "title": "Neural Network Models of Becoming a Cardinal Principle Knower",
                "year": 2023,
                "abstract": "As children enter elementary school, their understanding of the ordinal\nstructure of numbers transitions from a memorized count list of the first\n50-100 numbers to knowing the successor function and understanding the\ncountably infinite. We investigate this developmental change in two neural\nnetwork models that learn the successor function on the pairs (N, N+1) for N in\n(0, 98). The first uses a one-hot encoding of the input and output values and\ncorresponds to children memorizing a count list, while the second model uses a\nplace-value encoding and corresponds to children learning the language rules\nfor naming numbers. The place-value model showed a predicted drop in\nrepresentational similarity across tens boundaries. Counting across a tens\nboundary can be understood as a vector operation in 2D space, where the numbers\nwith the same tens place are organized in a linearly separable manner, whereas\nthose with the same ones place are grouped together. A curriculum learning\nsimulation shows that, in the expanding numerical environment of the developing\nchild, representations of smaller numbers continue to be sharpened even as\nlarger numbers begin to be learned. These models set the stage for future work\nusing recurrent architectures to move beyond learning the successor function to\nsimulating the counting process more generally, and point towards a deeper\nunderstanding of what it means to understand the countably infinite.",
                "authors": [
                    "Vima Gupta",
                    "Sashank Varma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15194v1",
                    "http://arxiv.org/pdf/2311.15194v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15185v1/1.0",
                "title": "Contractibility of the solution sets for set optimization problems",
                "year": 2023,
                "abstract": "This paper aims at investigating the contractibility of the solution sets for\nset optimization problems by utilizing strictly quasi cone-convexlikeness,\nwhich is an assumption weaker than strictly cone-convexity, strictly\ncone-quasiconvexity and strictly naturally quasi cone-convexity. We establish\nthe contractibility of l-minimal, l-weak minimal, u-minimal and u-weak minimal\nsolution sets for set optimization problems by using the star-shape sets and\nthe nonlinear scalarizing functions for sets. Moreover, we also discuss the\narcwise connectedness and the contractibility of p-minimal and p-weak minimal\nsolution sets for set optimization problems by using the scalarization\ntechnique. Finally, our main results are applied to the contractibility of the\nsolution sets for vector optimization problems.",
                "authors": [
                    "Bin Chen",
                    "Yu Han"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15185v1",
                    "http://arxiv.org/pdf/2311.15185v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15180v1/1.0",
                "title": "Benchmarking Large Language Model Volatility",
                "year": 2023,
                "abstract": "The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.",
                "authors": [
                    "Boyang Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15180v1",
                    "http://arxiv.org/pdf/2311.15180v1"
                ],
                "primary_category": "q-fin.TR",
                "categories": [
                    "q-fin.TR",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15167v2/1.0",
                "title": "Self-supervised OCT Image Denoising with Slice-to-Slice Registration and\n  Reconstruction",
                "year": 2023,
                "abstract": "Strong speckle noise is inherent to optical coherence tomography (OCT)\nimaging and represents a significant obstacle for accurate quantitative\nanalysis of retinal structures which is key for advances in clinical diagnosis\nand monitoring of disease. Learning-based self-supervised methods for\nstructure-preserving noise reduction have demonstrated superior performance\nover traditional methods but face unique challenges in OCT imaging. The high\ncorrelation of voxels generated by coherent A-scan beams undermines the\nefficacy of self-supervised learning methods as it violates the assumption of\nindependent pixel noise. We conduct experiments demonstrating limitations of\nexisting models due to this independence assumption. We then introduce a new\nend-to-end self-supervised learning framework specifically tailored for OCT\nimage denoising, integrating slice-by-slice training and registration modules\ninto one network. An extensive ablation study is conducted for the proposed\napproach. Comparison to previously published self-supervised denoising models\ndemonstrates improved performance of the proposed framework, potentially\nserving as a preprocessing step towards superior segmentation performance and\nquantitative analysis.",
                "authors": [
                    "Shijie Li",
                    "Palaiologos Alexopoulos",
                    "Anse Vellappally",
                    "Ronald Zambrano",
                    "Wollstein Gadi",
                    "Guido Gerig"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15167v2",
                    "http://arxiv.org/pdf/2311.15167v2"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15166v1/1.0",
                "title": "CP violation in lepton-number-conserving processes through heavy\n  Majorana neutrinos at future lepton colliders",
                "year": 2023,
                "abstract": "Small neutrino masses confirmed in the neutrino oscillation experiments\nindicate the need for new physics beyond the standard model. Seesaw mechanism\nis an interesting way to extend the standard model for explaining the neutrino\nmasses. In a low-scale type-I seesaw mechanism, the tiny masses of neutrinos\ncan be explained by heavy Majorana neutrino masses. Heavy Majorana neutrinos\ncan lead to lepton-number-violating processes and the induced CP violation can\ncontribute to the baryon asymmetry in the Universe. Heavy Majorana neutrinos\ncan also lead to lepton-number-conserving processes and in this paper, we study\nthe CP violation in lepton-number-conserving processes through heavy Majorana\nneutrinos at future lepton colliders. New possible observations of CP violation\ncan also be connected to evidences of new physics beyond the standard model.",
                "authors": [
                    "Zhe Wang",
                    "Xing-Hua Yang",
                    "Xin-Yi Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15166v1",
                    "http://arxiv.org/pdf/2311.15166v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15164v1/1.0",
                "title": "Neural-Optic Co-Designed Polarization-Multiplexed Metalens for Compact\n  Computational Spectral Imaging",
                "year": 2023,
                "abstract": "As the realm of spectral imaging applications extends its reach into the\ndomains of mobile technology and augmented reality, the demands for compact yet\nhigh-fidelity systems become increasingly pronounced. Conventional\nmethodologies, exemplified by coded aperture snapshot spectral imaging systems,\nare significantly limited by their cumbersome physical dimensions and form\nfactors. To address this inherent challenge, diffractive optical elements\n(DOEs) have been repeatedly employed as a means to mitigate issues related to\nthe bulky nature of these systems. Nonetheless, it's essential to note that the\ncapabilities of DOEs primarily revolve around the modulation of the phase of\nlight. Here, we introduce an end-to-end computational spectral imaging\nframework based on a polarization-multiplexed metalens. A distinguishing\nfeature of this approach lies in its capacity to simultaneously modulate\northogonal polarization channels. When harnessed in conjunction with a neural\nnetwork, it facilitates the attainment of high-fidelity spectral\nreconstruction. Importantly, the framework is intrinsically fully\ndifferentiable, a feature that permits the joint optimization of both the\nmetalens structure and the parameters governing the neural network. The\nexperimental results presented herein validate the exceptional spatial-spectral\nreconstruction performance, underscoring the efficacy of this system in\npractical, real-world scenarios. This innovative approach transcends the\ntraditional boundaries separating hardware and software in the realm of\ncomputational imaging and holds the promise of substantially propelling the\nminiaturization of spectral imaging systems.",
                "authors": [
                    "Qiangbo Zhang",
                    "Peicheng Lin",
                    "Chang Wang",
                    "Yang Zhang",
                    "Zeqing Yu",
                    "Xinyu Liu",
                    "Ting Xu",
                    "Zhenrong Zheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15164v1",
                    "http://arxiv.org/pdf/2311.15164v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15163v1/1.0",
                "title": "Deep Learning-Based Approaches for Contactless Fingerprints Segmentation\n  and Extraction",
                "year": 2023,
                "abstract": "Fingerprints are widely recognized as one of the most unique and reliable\ncharacteristics of human identity. Most modern fingerprint authentication\nsystems rely on contact-based fingerprints, which require the use of\nfingerprint scanners or fingerprint sensors for capturing fingerprints during\nthe authentication process. Various types of fingerprint sensors, such as\noptical, capacitive, and ultrasonic sensors, employ distinct techniques to\ngather and analyze fingerprint data. This dependency on specific hardware or\nsensors creates a barrier or challenge for the broader adoption of fingerprint\nbased biometric systems. This limitation hinders the widespread adoption of\nfingerprint authentication in various applications and scenarios. Border\ncontrol, healthcare systems, educational institutions, financial transactions,\nand airport security face challenges when fingerprint sensors are not\nuniversally available. To mitigate the dependence on additional hardware, the\nuse of contactless fingerprints has emerged as an alternative. Developing\nprecise fingerprint segmentation methods, accurate fingerprint extraction\ntools, and reliable fingerprint matchers are crucial for the successful\nimplementation of a robust contactless fingerprint authentication system. This\npaper focuses on the development of a deep learning-based segmentation tool for\ncontactless fingerprint localization and segmentation. Our system leverages\ndeep learning techniques to achieve high segmentation accuracy and reliable\nextraction of fingerprints from contactless fingerprint images. In our\nevaluation, our segmentation method demonstrated an average mean absolute error\n(MAE) of 30 pixels, an error in angle prediction (EAP) of 5.92 degrees, and a\nlabeling accuracy of 97.46%. These results demonstrate the effectiveness of our\nnovel contactless fingerprint segmentation and extraction tools.",
                "authors": [
                    "M. G. Sarwar Murshed",
                    "Syed Konain Abbas",
                    "Sandip Purnapatra",
                    "Daqing Hou",
                    "Faraz Hussain"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15163v1",
                    "http://arxiv.org/pdf/2311.15163v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15162v1/1.0",
                "title": "Domain Knowledge Injection in Bayesian Search for New Materials",
                "year": 2023,
                "abstract": "In this paper we propose DKIBO, a Bayesian optimization (BO) algorithm that\naccommodates domain knowledge to tune exploration in the search space. Bayesian\noptimization has recently emerged as a sample-efficient optimizer for many\nintractable scientific problems. While various existing BO frameworks allow the\ninput of prior beliefs to accelerate the search by narrowing down the space,\nincorporating such knowledge is not always straightforward and can often\nintroduce bias and lead to poor performance. Here we propose a simple approach\nto incorporate structural knowledge in the acquisition function by utilizing an\nadditional deterministic surrogate model to enrich the approximation power of\nthe Gaussian process. This is suitably chosen according to structural\ninformation of the problem at hand and acts a corrective term towards a\nbetter-informed sampling. We empirically demonstrate the practical utility of\nthe proposed method by successfully injecting domain knowledge in a materials\ndesign task. We further validate our method's performance on different\nexperimental settings and ablation analyses.",
                "authors": [
                    "Zikai Xie",
                    "Xenophon Evangelopoulos",
                    "Joseph Thacker",
                    "Andrew Cooper"
                ],
                "url": [
                    "http://dx.doi.org/10.3233/FAIA230587",
                    "http://arxiv.org/abs/2311.15162v1",
                    "http://arxiv.org/pdf/2311.15162v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "68W99",
                    "I.2.8"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15158v1/1.0",
                "title": "Angular-Distance Based Channel Estimation for Holographic MIMO",
                "year": 2023,
                "abstract": "This paper investigates the channel estimation for holographic MIMO systems\nby unmasking their distinctions from the conventional one. Specifically, we\nelucidate that the channel estimation, subject to holographic MIMO's\nelectromagnetically large antenna arrays, has to discriminate not only the\nangles of a user/scatterer but also its distance information, namely the\nthree-dimensional (3D) azimuth and elevation angles plus the distance (AED)\nparameters. As the angular-domain representation fails to characterize the\nsparsity inherent in holographic MIMO channels, the tightly coupled 3D AED\nparameters are firstly decomposed for independently constructing their own\ncovariance matrices. Then, the recovery of each individual parameter can be\nstructured as a compressive sensing (CS) problem by harnessing the covariance\nmatrix constructed. This pair of techniques contribute to a parametric\ndecomposition and compressed deconstruction (DeRe) framework, along with a\nformulation of the maximum likelihood estimation for each parameter. Then, an\nefficient algorithm, namely DeRe-based variational Bayesian inference and\nmessage passing (DeRe-VM), is proposed for the sharp detection of the 3D AED\nparameters and the robust recovery of sparse channels. Finally, the proposed\nchannel estimation regime is confirmed to be of great robustness in\naccommodating different channel conditions, regardless of the near-field and\nfar-field contexts of a holographic MIMO system, as well as an improved\nperformance in comparison to the state-of-the-art benchmarks.",
                "authors": [
                    "Yuanbin Chen",
                    "Ying Wang",
                    "Zhaocheng Wang",
                    "Zhu Han"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15158v1",
                    "http://arxiv.org/pdf/2311.15158v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15153v1/1.0",
                "title": "Self-Supervised Learning for SAR ATR with a Knowledge-Guided Predictive\n  Architecture",
                "year": 2023,
                "abstract": "Recently, the emergence of a large number of Synthetic Aperture Radar (SAR)\nsensors and target datasets has made it possible to unify downstream tasks with\nself-supervised learning techniques, which can pave the way for building the\nfoundation model in the SAR target recognition field. The major challenge of\nself-supervised learning for SAR target recognition lies in the generalizable\nrepresentation learning in low data quality and noise.To address the\naforementioned problem, we propose a knowledge-guided predictive architecture\nthat uses local masked patches to predict the multiscale SAR feature\nrepresentations of unseen context. The core of the proposed architecture lies\nin combining traditional SAR domain feature extraction with state-of-the-art\nscalable self-supervised learning for accurate generalized feature\nrepresentations. The proposed framework is validated on various downstream\ndatasets (MSTAR, FUSAR-Ship, SAR-ACD and SSDD), and can bring consistent\nperformance improvement for SAR target recognition. The experimental results\nstrongly demonstrate the unified performance improvement of the self-supervised\nlearning technique for SAR target recognition across diverse targets, scenes\nand sensors.",
                "authors": [
                    "Weijie Li",
                    "Yang Wei",
                    "Tianpeng Liu",
                    "Yuenan Hou",
                    "Yongxiang Liu",
                    "Li Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15153v1",
                    "http://arxiv.org/pdf/2311.15153v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.03718v1/1.0",
                "title": "Large Language Models in Law: A Survey",
                "year": 2023,
                "abstract": "The advent of artificial intelligence (AI) has significantly impacted the\ntraditional judicial industry. Moreover, recently, with the development of\nAI-generated content (AIGC), AI and law have found applications in various\ndomains, including image recognition, automatic text generation, and\ninteractive chat. With the rapid emergence and growing popularity of large\nmodels, it is evident that AI will drive transformation in the traditional\njudicial industry. However, the application of legal large language models\n(LLMs) is still in its nascent stage. Several challenges need to be addressed.\nIn this paper, we aim to provide a comprehensive survey of legal LLMs. We not\nonly conduct an extensive survey of LLMs, but also expose their applications in\nthe judicial system. We first provide an overview of AI technologies in the\nlegal field and showcase the recent research in LLMs. Then, we discuss the\npractical implementation presented by legal LLMs, such as providing legal\nadvice to users and assisting judges during trials. In addition, we explore the\nlimitations of legal LLMs, including data, algorithms, and judicial practice.\nFinally, we summarize practical recommendations and propose future development\ndirections to address these challenges.",
                "authors": [
                    "Jinqi Lai",
                    "Wensheng Gan",
                    "Jiayang Wu",
                    "Zhenlian Qi",
                    "Philip S. Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.03718v1",
                    "http://arxiv.org/pdf/2312.03718v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15150v1/1.0",
                "title": "Observation of the spectral bifurcation in the Fractional Nonlinear\n  Schr\u00f6dinger Equation",
                "year": 2023,
                "abstract": "We report a comprehensive investigation and experimental realization of\nspectral bifurcations of ultrafast soliton pulses. These bifurcations are\ninduced by the interplay between fractional group-velocity dispersion and Kerr\nnonlinearity (self-phase modulation) within the framework of the fractional\nnonlinear Schr\\\"{o}dinger equation. To capture the dynamics of the pulses under\nthe action of the fractional dispersion and nonlinearity, we propose an\neffective `force' model based on the frequency chirp, which characterizes their\ninteractions as either `repulsion', `attraction', or `equilibration'. By\nleveraging the `force' model, we design segmented fractional dispersion\nprofiles that directly generate spectral bifurcations \\{1\\}$\\rightarrow$ \\{N\\}\nat relevant nonlinearity levels. These results extend beyond the traditional\nsequence of bifurcations \\{1\\}$\\rightarrow$ \\{2\\}$\\rightarrow$ \\{3\\} ...\n$\\rightarrow$ \\{N\\} associated with the growth of the nonlinearity. The\nexperimental validation involves a precisely tailored hologram within a pulse\nshaper setup, coupled to an alterable nonlinear medium. Notably, we achieve up\nto N=5 in \\{1\\}$\\rightarrow$ \\{N\\} bifurcations at a significantly lower\nstrength of nonlinearity than otherwise would be required in a sequential\ncascade. The proposal for engineering spectral bifurcation patterns holds\nsignificant potential for ultrafast signal processing applications. As a\npractical illustration, we employ these bifurcation modes to optical data\nsqueezing and transmitting it across a 100-km-long single-mode fiber.",
                "authors": [
                    "Shilong Liu",
                    "Yingwen Zhang",
                    "St\u00e9phane Virally",
                    "Ebrahim Karimi",
                    "Boris A. Malomed",
                    "Denis V. Seletskiy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15150v1",
                    "http://arxiv.org/pdf/2311.15150v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "math-ph",
                    "math.MP",
                    "nlin.PS",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15145v2/1.0",
                "title": "Choosing Wisely and Learning Deeply: Selective Cross-Modality\n  Distillation via CLIP for Domain Generalization",
                "year": 2023,
                "abstract": "Domain Generalization (DG), a crucial research area, seeks to train models\nacross multiple domains and test them on unseen ones. In this paper, we\nintroduce a novel approach, namely, Selective Cross-Modality Distillation for\nDomain Generalization (SCMD). SCMD leverages the capabilities of large\nvision-language models, specifically the CLIP model, to train a more efficient\nmodel, ensuring it acquires robust generalization capabilities across unseen\ndomains. Our primary contribution is a unique selection framework strategically\ndesigned to identify hard-to-learn samples for distillation. In parallel, we\nintroduce a novel cross-modality module. This module seamlessly combines the\nprojected features of the student model with the text embeddings from CLIP,\nensuring the alignment of similarity distributions. We assess SCMD's\nperformance on various benchmarks, where it empowers a ResNet50 to deliver\nstate-of-the-art performance, surpassing existing domain generalization\nmethods. Furthermore, we provide a theoretical analysis of our selection\nstrategy, offering deeper insight into its effectiveness and potential in the\nfield of DG.",
                "authors": [
                    "Jixuan Leng",
                    "Yijiang Li",
                    "Haohan Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15145v2",
                    "http://arxiv.org/pdf/2311.15145v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15143v1/1.0",
                "title": "Reduced Augmentation Implicit Low-rank (RAIL) integrators for\n  advection-diffusion and Fokker-Planck models",
                "year": 2023,
                "abstract": "This paper introduces a novel computational approach termed the Reduced\nAugmentation Implicit Low-rank (RAIL) method by investigating two predominant\nresearch directions in low-rank solutions to time-dependent partial\ndifferential equations (PDEs): dynamical low-rank (DLR), and step and\ntruncation (SAT) tensor methods. The RAIL method, along with the development of\nthe SAT approach, is designed to enhance the efficiency of traditional\nfull-rank implicit solvers from method-of-lines discretizations of\ntime-dependent PDEs, while maintaining accuracy and stability. We consider\nspectral methods for spatial discretization, and diagonally implicit\nRunge-Kutta (DIRK) and implicit-explicit (IMEX) RK methods for time\ndiscretization. The efficiency gain is achieved by investigating low-rank\nstructures within solutions at each RK stage using a singular value\ndecomposition (SVD). In particular, we develop a reduced augmentation procedure\nto predict the basis functions to construct projection subspaces. This\nprocedure balances algorithm accuracy and efficiency by incorporating as many\nbases as possible from previous RK stages and predictions, and by optimizing\nthe basis representation through SVD truncation. As such, one can form implicit\nschemes for updating basis functions in a dimension-by-dimension manner,\nsimilar in spirit to the K-L step in the DLR framework. We also apply a\nglobally mass conservative post-processing step at the end of each RK stage. We\nvalidate the RAIL method through numerical simulations of advection-diffusion\nproblems and a Fokker-Planck model, showcasing its ability to efficiently\nhandle time-dependent PDEs while maintaining global mass conservation. Our\napproach generalizes and bridges the DLR and SAT approaches, offering a\ncomprehensive framework for efficiently and accurately solving time-dependent\nPDEs with implicit treatment.",
                "authors": [
                    "Joseph Nakao",
                    "Jing-Mei Qiu",
                    "Lukas Einkemmer"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15143v1",
                    "http://arxiv.org/pdf/2311.15143v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.NA",
                    "65"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15141v1/1.0",
                "title": "OFDMA-F$^2$L: Federated Learning With Flexible Aggregation Over an OFDMA\n  Air Interface",
                "year": 2023,
                "abstract": "Federated learning (FL) can suffer from a communication bottleneck when\ndeployed in mobile networks, limiting participating clients and deterring FL\nconvergence. The impact of practical air interfaces with discrete modulations\non FL has not previously been studied in depth. This paper proposes a new\nparadigm of flexible aggregation-based FL (F$^2$L) over orthogonal frequency\ndivision multiple-access (OFDMA) air interface, termed as ``OFDMA-F$^2$L'',\nallowing selected clients to train local models for various numbers of\niterations before uploading the models in each aggregation round. We optimize\nthe selections of clients, subchannels and modulations, adapting to channel\nconditions and computing powers. Specifically, we derive an upper bound on the\noptimality gap of OFDMA-F$^2$L capturing the impact of the selections, and show\nthat the upper bound is minimized by maximizing the weighted sum rate of the\nclients per aggregation round. A Lagrange-dual based method is developed to\nsolve this challenging mixed integer program of weighted sum rate maximization,\nrevealing that a ``winner-takes-all'' policy provides the almost surely optimal\nclient, subchannel, and modulation selections. Experiments on multilayer\nperceptrons and convolutional neural networks show that OFDMA-F$^2$L with\noptimal selections can significantly improve the training convergence and\naccuracy, e.g., by about 18\\% and 5\\%, compared to potential alternatives.",
                "authors": [
                    "Shuyan Hu",
                    "Xin Yuan",
                    "Wei Ni",
                    "Xin Wang",
                    "Ekram Hossain",
                    "H. Vincent Poor"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15141v1",
                    "http://arxiv.org/pdf/2311.15141v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15138v2/1.0",
                "title": "Can SAM recognize crops? Quantifying the zero-shot performance of a\n  semantic segmentation foundation model on generating crop-type maps using\n  satellite imagery for precision agriculture",
                "year": 2023,
                "abstract": "Climate change is increasingly disrupting worldwide agriculture, making\nglobal food production less reliable. To tackle the growing challenges in\nfeeding the planet, cutting-edge management strategies, such as precision\nagriculture, empower farmers and decision-makers with rich and actionable\ninformation to increase the efficiency and sustainability of their farming\npractices. Crop-type maps are key information for decision-support tools but\nare challenging and costly to generate. We investigate the capabilities of Meta\nAI's Segment Anything Model (SAM) for crop-map prediction task, acknowledging\nits recent successes at zero-shot image segmentation. However, SAM being\nlimited to up-to 3 channel inputs and its zero-shot usage being class-agnostic\nin nature pose unique challenges in using it directly for crop-type mapping. We\npropose using clustering consensus metrics to assess SAM's zero-shot\nperformance in segmenting satellite imagery and producing crop-type maps.\nAlthough direct crop-type mapping is challenging using SAM in zero-shot\nsetting, experiments reveal SAM's potential for swiftly and accurately\noutlining fields in satellite images, serving as a foundation for subsequent\ncrop classification. This paper attempts to highlight a use-case of\nstate-of-the-art image segmentation models like SAM for crop-type mapping and\nrelated specific needs of the agriculture industry, offering a potential avenue\nfor automatic, efficient, and cost-effective data products for precision\nagriculture practices.",
                "authors": [
                    "Rutuja Gurav",
                    "Het Patel",
                    "Zhuocheng Shang",
                    "Ahmed Eldawy",
                    "Jia Chen",
                    "Elia Scudiero",
                    "Evangelos Papalexakis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15138v2",
                    "http://arxiv.org/pdf/2311.15138v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15137v1/1.0",
                "title": "Multi-fidelity Constrained Optimization for Stochastic Black Box\n  Simulators",
                "year": 2023,
                "abstract": "Constrained optimization of the parameters of a simulator plays a crucial\nrole in a design process. These problems become challenging when the simulator\nis stochastic, computationally expensive, and the parameter space is\nhigh-dimensional. One can efficiently perform optimization only by utilizing\nthe gradient with respect to the parameters, but these gradients are\nunavailable in many legacy, black-box codes. We introduce the algorithm\nScout-Nd (Stochastic Constrained Optimization for N dimensions) to tackle the\nissues mentioned earlier by efficiently estimating the gradient, reducing the\nnoise of the gradient estimator, and applying multi-fidelity schemes to further\nreduce computational effort. We validate our approach on standard benchmarks,\ndemonstrating its effectiveness in optimizing parameters highlighting better\nperformance compared to existing methods.",
                "authors": [
                    "Atul Agrawal",
                    "Kislaya Ravi",
                    "Phaedon-Stelios Koutsourelakis",
                    "Hans-Joachim Bungartz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15137v1",
                    "http://arxiv.org/pdf/2311.15137v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC",
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15132v1/1.0",
                "title": "Enhancement of Superconducting Properties of Polycrystalline CaKFe4As4\n  by High-Pressure Growth",
                "year": 2023,
                "abstract": "High-pressure growth is a unique method to improve the sample quality and\nsize. Here, we have used the high gas pressure and high-temperature synthesis\n(HP-HTS) method to grow CaKFe4As4 (1144) bulks and investigated their\nsuperconducting properties using structural, microstructural, transport, and\nmagnetic studies. The microstructural analysis demonstrates that 1144 samples\nprepared by HP-HTS have improved the sample density and grain connectivity. The\ntransition temperature (Tconset) of 1144 bulks prepared by HP-HTS is increased\nup to 35.2 K with a transition width ({\\Delta}T) of 1 K, which is remarkably\ncomparable to the reported 1144 single crystal. Additionally, the critical\ncurrent density (Jc) is enhanced by almost one order of magnitude compared with\nthe parent compound prepared by the conventional synthesis process at ambient\npressure (CSP), which could be attributed to the improved sample density and\neffective pinning centers. Our study demonstrates that the sample quality and\nsuperconducting properties of various iron-based superconductors can be\nenhanced by applying the HP-HTS approach, and further research is demanded in\nthis direction.",
                "authors": [
                    "Manasa Manasa",
                    "Mohammad Azam",
                    "Tatiana Zajarniuk",
                    "Ryszard Diduszko",
                    "Tomasz Cetner",
                    "Andrzej Morawski",
                    "Andrzej Wisniewski",
                    "Shiv J. Singh"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/TASC.2023.3345821",
                    "http://arxiv.org/abs/2311.15132v1",
                    "http://arxiv.org/pdf/2311.15132v1"
                ],
                "primary_category": "cond-mat.supr-con",
                "categories": [
                    "cond-mat.supr-con",
                    "cond-mat.mtrl-sci",
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15131v1/1.0",
                "title": "Localizing Lying in Llama: Understanding Instructed Dishonesty on\n  True-False Questions Through Prompting, Probing, and Patching",
                "year": 2023,
                "abstract": "Large language models (LLMs) demonstrate significant knowledge through their\noutputs, though it is often unclear whether false outputs are due to a lack of\nknowledge or dishonesty. In this paper, we investigate instructed dishonesty,\nwherein we explicitly prompt LLaMA-2-70b-chat to lie. We perform prompt\nengineering to find which prompts best induce lying behavior, and then use\nmechanistic interpretability approaches to localize where in the network this\nbehavior occurs. Using linear probing and activation patching, we localize five\nlayers that appear especially important for lying. We then find just 46\nattention heads within these layers that enable us to causally intervene such\nthat the lying model instead answers honestly. We show that these interventions\nwork robustly across many prompts and dataset splits. Overall, our work\ncontributes a greater understanding of dishonesty in LLMs so that we may hope\nto prevent it.",
                "authors": [
                    "James Campbell",
                    "Richard Ren",
                    "Phillip Guo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15131v1",
                    "http://arxiv.org/pdf/2311.15131v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15128v1/1.0",
                "title": "Quickest Change Detection with Post-Change Density Estimation",
                "year": 2023,
                "abstract": "The problem of quickest change detection in a sequence of independent\nobservations is considered. The pre-change distribution is assumed to be known,\nwhile the post-change distribution is unknown. Two tests based on post-change\ndensity estimation are developed for this problem, the window-limited\nnon-parametric generalized likelihood ratio (NGLR) CuSum test and the\nnon-parametric window-limited adaptive (NWLA) CuSum test. Both tests do not\nassume any knowledge of the post-change distribution, except that the\npost-change density satisfies certain smoothness conditions that allows for\nefficient non-parametric estimation. Also, they do not require any\npre-collected post-change training samples. Under certain convergence\nconditions on the density estimator, it is shown that both tests are\nfirst-order asymptotically optimal, as the false alarm rate goes to zero. The\nanalysis is validated through numerical results, where both tests are compared\nwith baseline tests that have distributional knowledge.",
                "authors": [
                    "Yuchen Liang",
                    "Venugopal V. Veeravalli"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15128v1",
                    "http://arxiv.org/pdf/2311.15128v1"
                ],
                "primary_category": "math.ST",
                "categories": [
                    "math.ST",
                    "eess.SP",
                    "stat.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15127v1/1.0",
                "title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large\n  Datasets",
                "year": 2023,
                "abstract": "We present Stable Video Diffusion - a latent video diffusion model for\nhigh-resolution, state-of-the-art text-to-video and image-to-video generation.\nRecently, latent diffusion models trained for 2D image synthesis have been\nturned into generative video models by inserting temporal layers and finetuning\nthem on small, high-quality video datasets. However, training methods in the\nliterature vary widely, and the field has yet to agree on a unified strategy\nfor curating video data. In this paper, we identify and evaluate three\ndifferent stages for successful training of video LDMs: text-to-image\npretraining, video pretraining, and high-quality video finetuning. Furthermore,\nwe demonstrate the necessity of a well-curated pretraining dataset for\ngenerating high-quality videos and present a systematic curation process to\ntrain a strong base model, including captioning and filtering strategies. We\nthen explore the impact of finetuning our base model on high-quality data and\ntrain a text-to-video model that is competitive with closed-source video\ngeneration. We also show that our base model provides a powerful motion\nrepresentation for downstream tasks such as image-to-video generation and\nadaptability to camera motion-specific LoRA modules. Finally, we demonstrate\nthat our model provides a strong multi-view 3D-prior and can serve as a base to\nfinetune a multi-view diffusion model that jointly generates multiple views of\nobjects in a feedforward fashion, outperforming image-based methods at a\nfraction of their compute budget. We release code and model weights at\nhttps://github.com/Stability-AI/generative-models .",
                "authors": [
                    "Andreas Blattmann",
                    "Tim Dockhorn",
                    "Sumith Kulal",
                    "Daniel Mendelevitch",
                    "Maciej Kilian",
                    "Dominik Lorenz",
                    "Yam Levi",
                    "Zion English",
                    "Vikram Voleti",
                    "Adam Letts",
                    "Varun Jampani",
                    "Robin Rombach"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15127v1",
                    "http://arxiv.org/pdf/2311.15127v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15120v1/1.0",
                "title": "The nature of very-faint X-ray binaries: Near-infrared spectroscopy of\n  1RXH J173523.7$-$354013 reveals a giant companion",
                "year": 2023,
                "abstract": "Very-faint X-ray binaries (VFXBs) are a sub-class of black holes and neutron\nstars in binaries that appear to be accreting at a very low rate. In addition\nto providing interesting constraints on poorly understood forms of accretion,\nelucidating the nature of VFXBs is particularly interesting for binary\nevolution and population modeling. Through near-infrared (nIR) spectroscopy, we\nhere investigate the nature of the bursting neutron star and VFXB 1RXH\nJ173523.7$-$354013 (J1735), which persistently accretes at an X-ray luminosity\nof $L_X \\sim 10^{34} - 10^{35}~L_{\\odot}$. Our analysis shows that the nIR\nemission is dominated by that of the companion star, which we find to be a late\nG or early K-type giant, making this the second neutron star identified as a\nVFXB found to have a giant companion. We discuss how several of the system\nproperties are difficult to reconcile with a wind-fed symbiotic X-ray binary.\nWe therefore also propose an alternative scenario wherein J1735 is a wide\nbinary system (supported by the discovery of a 7.5 d modulation in the nIR\nlight curves) with a quiescent luminosity of $L_X \\sim 10^{34} -\n10^{35}~L_{\\odot}$, in which the donor star is overflowing its Roche lobe. This\nraises the possibility that J1735 may, every century or more, exhibit very long\nand very bright outbursts during which it reaches accretion rates around the\nEddington limit like the neutron star Z sources.",
                "authors": [
                    "A. W. Shaw",
                    "N. Degenaar",
                    "T. J. Maccarone",
                    "C. O. Heinke",
                    "R. Wijnands",
                    "J. van den Eijnden"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15120v1",
                    "http://arxiv.org/pdf/2311.15120v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15117v1/1.0",
                "title": "Resilience-driven Planning of Electric Power Systems Against Extreme\n  Weather Events",
                "year": 2023,
                "abstract": "With the increasing frequency of natural disasters, operators must prioritize\nimprovements in the existing electric power grid infrastructure to enhance the\nresilience of the grid. Resilience to extreme weather events necessitates\nlowering the impacts of high-impact, low-probability (HILP) events, which is\nonly possible when such events are considered during the planning stage. This\npaper proposes a two-stage stochastic planning model where the generation\ndispatch, line hardening, line capacity expansion, and distributed generation\nsizing and siting decisions are proactively decided to minimize the overall\nload shed and its risk for extreme weather scenarios, where the risk is modeled\nusing conditional value-at-risk. To alleviate computational complexity without\nsacrificing solution quality, a representative scenario sampling method is\nused. Finally, the overall framework is tested on a standard IEEE reliability\ntest system to evaluate the effectiveness of the proposed approach. Several\nplanning portfolios are presented that can help system planners identify\ntrade-offs between system resilience, planning budget, and risk aversion.",
                "authors": [
                    "Abodh Poudyal",
                    "Shishir Lamichhane",
                    "Anamika Dubey",
                    "Josue Campos do Prado"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15117v1",
                    "http://arxiv.org/pdf/2311.15117v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2401.01347v1/1.0",
                "title": "Convex Regions of Opinion Dynamics, Approaches to the Complexity of\n  Binary Consensus with Reference to Addiction and Obliviousness: Integrated\n  Dimer Model Perspective",
                "year": 2023,
                "abstract": "The field of opinion dynamics has its roots in early research that applied\nmethods from magnetic physics to gain insights into the formation of social\nopinions. A central challenge in this field lies in modeling how diverse\nopinions coexist and exert influence on each other. In the realm of social\nissues, it's In this study, we leverage the dimer construct and the dimer model\nto establish a theoretical framework. Through numerical simulations, we\ndemonstrate how this proposed model can be applied to real-world scenarios of\nsocial opinion formation. The model involves the computation of the Castellain\nmatrix \\(K\\), the distribution function \\(Z\\), and the probability of dimer\nconfiguration \\(P(D)\\) for convex regions with varying positions and distances.\nIt explores how alterations in convex regions impact the probability of dimer\nconfiguration.\n  Furthermore, our model takes into account two critical factors: \"dependence\"\nand \"forgetting\" in the process of opinion formation. It also delves into the\nconcepts of \"distance\" and \"location\" of opinions. The results of numerical\nsimulations shed light on how our model effectively captures the processes\ninvolved in real-world social opinion formation.\n  This study lays the groundwork for a deeper comprehension of the social\nopinion formation process and the development of strategies to address\nreal-world social issues. In essence, our research introduces a novel\nmethodology for comprehending and dissecting the intricate dynamics of opinion\nformation within the realm of opinion dynamics.\n  This theoretical framework, coupled with a numerical simulation-based\napproach, offers fresh insights that extend beyond the confines of opinion\ndynamics. It opens up new perspectives in the domains of social science,\nphysics, and computational modeling, ultimately contributing to a more profound\nunderstanding of social opinion formation.",
                "authors": [
                    "Yasuko Kawahata"
                ],
                "url": [
                    "http://arxiv.org/abs/2401.01347v1",
                    "http://arxiv.org/pdf/2401.01347v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15114v1/1.0",
                "title": "Studies of the Inhomogeneous Cosmology in Higher Dimensional space-time\n  with a Cosmological Constant",
                "year": 2023,
                "abstract": "We have studied the inhomogeneous cosmology in Kaluza-Klein spacetime with\npositive cosmological constant. Depending on the integration constant we have\nderived two types of solutions. The dimensional reduction is possible of extra\ndimensional scale factor depending on the curvature of the metric for positive\ncosmological constant for all solutions. The high value of entropy in present\nobservable universe and the possible matter leakage in $4D$ world due to\nreduction of extra dimension are also discussed. Our solutions show that early\ndeceleration and late accelerating nature of the universe. Findings are\nverified by the wellknown Raychaudhuri equation.",
                "authors": [
                    "D. Panigrahi",
                    "S. Chatterjee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15114v1",
                    "http://arxiv.org/pdf/2311.15114v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc",
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15110v1/1.0",
                "title": "Relevance feedback strategies for recall-oriented neural information\n  retrieval",
                "year": 2023,
                "abstract": "In a number of information retrieval applications (e.g., patent search,\nliterature review, due diligence, etc.), preventing false negatives is more\nimportant than preventing false positives. However, approaches designed to\nreduce review effort (like \"technology assisted review\") can create false\nnegatives, since they are often based on active learning systems that exclude\ndocuments automatically based on user feedback. Therefore, this research\nproposes a more recall-oriented approach to reducing review effort. More\nspecifically, through iteratively re-ranking the relevance rankings based on\nuser feedback, which is also referred to as relevance feedback. In our proposed\nmethod, the relevance rankings are produced by a BERT-based dense-vector search\nand the relevance feedback is based on cumulatively summing the queried and\nselected embeddings. Our results show that this method can reduce review effort\nbetween 17.85% and 59.04%, compared to a baseline approach (of no feedback),\ngiven a fixed recall target",
                "authors": [
                    "Timo Kats",
                    "Peter van der Putten",
                    "Jan Scholtes"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15110v1",
                    "http://arxiv.org/pdf/2311.15110v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15108v1/1.0",
                "title": "Leveraging Diffusion Perturbations for Measuring Fairness in Computer\n  Vision",
                "year": 2023,
                "abstract": "Computer vision models have been known to encode harmful biases, leading to\nthe potentially unfair treatment of historically marginalized groups, such as\npeople of color. However, there remains a lack of datasets balanced along\ndemographic traits that can be used to evaluate the downstream fairness of\nthese models. In this work, we demonstrate that diffusion models can be\nleveraged to create such a dataset. We first use a diffusion model to generate\na large set of images depicting various occupations. Subsequently, each image\nis edited using inpainting to generate multiple variants, where each variant\nrefers to a different perceived race. Using this dataset, we benchmark several\nvision-language models on a multi-class occupation classification task. We find\nthat images generated with non-Caucasian labels have a significantly higher\noccupation misclassification rate than images generated with Caucasian labels,\nand that several misclassifications are suggestive of racial biases. We measure\na model's downstream fairness by computing the standard deviation in the\nprobability of predicting the true occupation label across the different\nperceived identity groups. Using this fairness metric, we find significant\ndisparities between the evaluated vision-and-language models. We hope that our\nwork demonstrates the potential value of diffusion methods for fairness\nevaluations.",
                "authors": [
                    "Nicholas Lui",
                    "Bryan Chia",
                    "William Berrios",
                    "Candace Ross",
                    "Douwe Kiela"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15108v1",
                    "http://arxiv.org/pdf/2311.15108v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15106v1/1.0",
                "title": "Solving the Right Problem is Key for Translational NLP: A Case Study in\n  UMLS Vocabulary Insertion",
                "year": 2023,
                "abstract": "As the immense opportunities enabled by large language models become more\napparent, NLP systems will be increasingly expected to excel in real-world\nsettings. However, in many instances, powerful models alone will not yield\ntranslational NLP solutions, especially if the formulated problem is not well\naligned with the real-world task. In this work, we study the case of UMLS\nvocabulary insertion, an important real-world task in which hundreds of\nthousands of new terms, referred to as atoms, are added to the UMLS, one of the\nmost comprehensive open-source biomedical knowledge bases. Previous work aimed\nto develop an automated NLP system to make this time-consuming, costly, and\nerror-prone task more efficient. Nevertheless, practical progress in this\ndirection has been difficult to achieve due to a problem formulation and\nevaluation gap between research output and the real-world task. In order to\naddress this gap, we introduce a new formulation for UMLS vocabulary insertion\nwhich mirrors the real-world task, datasets which faithfully represent it and\nseveral strong baselines we developed through re-purposing existing solutions.\nAdditionally, we propose an effective rule-enhanced biomedical language model\nwhich enables important new model behavior, outperforms all strong baselines\nand provides measurable qualitative improvements to editors who carry out the\nUVI task. We hope this case study provides insight into the considerable\nimportance of problem formulation for the success of translational NLP\nsolutions.",
                "authors": [
                    "Bernal Jimenez Gutierrez",
                    "Yuqing Mao",
                    "Vinh Nguyen",
                    "Kin Wah Fung",
                    "Yu Su",
                    "Olivier Bodenreider"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15106v1",
                    "http://arxiv.org/pdf/2311.15106v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15105v1/1.0",
                "title": "Relative mixed multiplicities and mixed Buchsbaum-Rim multiplicities",
                "year": 2023,
                "abstract": "We define and study the natural multigraded extension of the relative\nmultiplicities introduced by Simis, Ulrich and Vasconcelos. We call these new\ninvariants relative mixed multiplicities. We show that they have a stable value\nequal to the mixed Buchsbaum-Rim multiplicity of Kleiman and Thorup.\nFurthermore, we prove that integral dependence and birationality can be\ndetected via the vanishing of relative mixed multiplicities.",
                "authors": [
                    "Yairon Cid-Ruiz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15105v1",
                    "http://arxiv.org/pdf/2311.15105v1"
                ],
                "primary_category": "math.AC",
                "categories": [
                    "math.AC",
                    "math.AG",
                    "13H15, 14C17, 13D40, 13A30, 13B22"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15097v1/1.0",
                "title": "AugmentTRAJ: A framework for point-based trajectory data augmentation",
                "year": 2023,
                "abstract": "Data augmentation has emerged as a powerful technique in machine learning,\nstrengthening model robustness while mitigating overfitting and under-fitting\nissues by generating diverse synthetic data. Nevertheless, despite its success\nin other domains, data augmentation's potential remains largely untapped in\nmobility data analysis, primarily due to the intricate nature and unique format\nof trajectory data. Additionally, there is a lack of frameworks capable of\npoint-wise data augmentation, which can reliably generate synthetic\ntrajectories while preserving the inherent characteristics of the original\ndata. To address these challenges, this research introduces AugmenTRAJ, an\nopen-source Python3 framework designed explicitly for trajectory data\naugmentation. AugmenTRAJ offers a reliable and well-controlled approach for\ngenerating synthetic trajectories, thereby enabling the harnessing of data\naugmentation benefits in mobility analysis. This thesis presents a\ncomprehensive overview of the methodologies employed in developing AugmenTRAJ\nand showcases the various data augmentation techniques available within the\nframework. AugmenTRAJ opens new possibilities for enhancing mobility data\nanalysis models' performance and generalization capabilities by providing\nresearchers with a practical and versatile tool for augmenting trajectory data,\nIts user-friendly implementation in Python3 facilitates easy integration into\nexisting workflows, offering the community an accessible resource to leverage\nthe full potential of data augmentation in trajectory-based applications.",
                "authors": [
                    "Yaksh J Haranwala"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15097v1",
                    "http://arxiv.org/pdf/2311.15097v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16185v1/1.0",
                "title": "Enhancing Sentiment Analysis Results through Outlier Detection\n  Optimization",
                "year": 2023,
                "abstract": "When dealing with text data containing subjective labels like speaker\nemotions, inaccuracies or discrepancies among labelers are not uncommon. Such\ndiscrepancies can significantly affect the performance of machine learning\nalgorithms. This study investigates the potential of identifying and addressing\noutliers in text data with subjective labels, aiming to enhance classification\noutcomes. We utilized the Deep SVDD algorithm, a one-class classification\nmethod, to detect outliers in nine text-based emotion and sentiment analysis\ndatasets. By employing both a small-sized language model (DistilBERT base model\nwith 66 million parameters) and non-deep learning machine learning algorithms\n(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our\nfindings suggest that the removal of outliers can lead to enhanced results in\nmost cases. Additionally, as outliers in such datasets are not necessarily\nunlearnable, we experienced utilizing a large language model -- DeBERTa v3\nlarge with 131 million parameters, which can capture very complex patterns in\ndata. We continued to observe performance enhancements across multiple\ndatasets.",
                "authors": [
                    "Yuetian Chen",
                    "Mei Si"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16185v1",
                    "http://arxiv.org/pdf/2311.16185v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15090v1/1.0",
                "title": "Fine-Grained Unsupervised Cross-Modality Domain Adaptation for\n  Vestibular Schwannoma Segmentation",
                "year": 2023,
                "abstract": "The domain adaptation approach has gained significant acceptance in\ntransferring styles across various vendors and centers, along with filling the\ngaps in modalities. However, multi-center application faces the challenge of\nthe difficulty of domain adaptation due to their intra-domain differences. We\nfocus on introducing a fine-grained unsupervised framework for domain\nadaptation to facilitate cross-modality segmentation of vestibular schwannoma\n(VS) and cochlea. We propose to use a vector to control the generator to\nsynthesize a fake image with given features. And then, we can apply various\naugmentations to the dataset by searching the feature dictionary. The diversity\naugmentation can increase the performance and robustness of the segmentation\nmodel. On the CrossMoDA validation phase Leaderboard, our method received a\nmean Dice score of 0.765 and 0.836 on VS and cochlea, respectively.",
                "authors": [
                    "Luyi Han",
                    "Tao Tan",
                    "Ritse Mann"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15090v1",
                    "http://arxiv.org/pdf/2311.15090v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15085v3/1.0",
                "title": "Corrections to Landau Fermi-liquid fixed-point approximation in\n  nonlinear bosonized theory: Application to $g_A^L$ in nuclei",
                "year": 2023,
                "abstract": "We calculated in nonlinear bosonized theory $1/\\bar{N}$ corrections to the\nLandau Fermi-liquid fixed-point (FLFP) axial-vector coupling constant in\nnuclear matter $g_A^L\\approx 1$ to which the Landau parameter $F_1^\\omega$\npredominantly contributes. We obtain the correction to $F_1^\\omega$ to\ncalculate the correction $\\delta g_A^L$ to the axial-vector coupling constant\n$g_A^L$ at the nuclear saturation density. It comes out to be extremely small,\n$\\delta g_A^L\\sim O(10^{-4})$. We discuss how the \"dilaton-limit fixed-point\n(DLFP)\" result $g_A=1$ can be preserved from finite nuclei to high densities\nrelevant to massive neutron stars and its possible impact on $0\\nu\\beta\\beta$\ndecay processes involved in going beyond the Standard Model.",
                "authors": [
                    "Long-Qi Shao",
                    "Mannque Rho"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15085v3",
                    "http://arxiv.org/pdf/2311.15085v3"
                ],
                "primary_category": "nucl-th",
                "categories": [
                    "nucl-th",
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15084v1/1.0",
                "title": "Minimal Specialization: Coevolution of Network Structure and Dynamics",
                "year": 2023,
                "abstract": "The changing topology of a network is driven by the need to maintain or\noptimize network function. As this function is often related to moving\nquantities such as traffic, information, etc. efficiently through the network\nthe structure of the network and the dynamics on the network directly depend on\nthe other. To model this interplay of network structure and dynamics we use the\ndynamics on the network, or the dynamical processes the network models, to\ninfluence the dynamics of the network structure, i.e., to determine where and\nwhen to modify the network structure. We model the dynamics on the network\nusing Jackson network dynamics and the dynamics of the network structure using\nminimal specialization, a variant of the more general network growth model\nknown as specialization. The resulting model, which we refer to as the\nintegrated specialization model, coevolves both the structure and the dynamics\nof the network. We show this model produces networks with real-world\nproperties, such as right-skewed degree distributions, sparsity, the\nsmall-world property, and non-trivial equitable partitions. Additionally, when\ncompared to other growth models, the integrated specialization model creates\nnetworks with small diameter, minimizing distances across the network. Along\nwith producing these structural features, this model also sequentially removes\nthe network's largest bottlenecks. The result are networks that have both\ndynamic and structural features that allow quantities to more efficiently move\nthrough the network.",
                "authors": [
                    "Annika King",
                    "Dallas Smith",
                    "Benjamin Webb"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15084v1",
                    "http://arxiv.org/pdf/2311.15084v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph",
                    "math.DS",
                    "90B10"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15082v3/1.0",
                "title": "Learning graph-Fourier spectra of textured surface images for defect\n  localization",
                "year": 2023,
                "abstract": "In the realm of industrial manufacturing, product inspection remains a\nsignificant bottleneck, with only a small fraction of manufactured items\nundergoing inspection for surface defects. Advances in imaging systems and AI\ncan allow automated full inspection of manufactured surfaces. However, even the\nmost contemporary imaging and machine learning methods perform poorly for\ndetecting defects in images with highly textured backgrounds, that stem from\ndiverse manufacturing processes. This paper introduces an approach based on\ngraph Fourier analysis to automatically identify defective images, as well as\ncrucial graph Fourier coefficients that inform the defects in images amidst\nhighly textured backgrounds. The approach capitalizes on the ability of graph\nrepresentations to capture the complex dynamics inherent in high-dimensional\ndata, preserving crucial locality properties in a lower dimensional space. A\nconvolutional neural network model (1D-CNN) was trained with the coefficients\nof the graph Fourier transform of the images as the input to identify, with\nclassification accuracy of 99.4%, if the image contains a defect. An\nexplainable AI method using SHAP (SHapley Additive exPlanations) was used to\nfurther analyze the trained 1D-CNN model to discern important spectral\ncoefficients for each image. This approach sheds light on the crucial\ncontribution of low-frequency graph eigen waveforms to precisely localize\nsurface defects in images, thereby advancing the realization of zero-defect\nmanufacturing.",
                "authors": [
                    "Tapan Ganatma Nakkina",
                    "Adithyaa Karthikeyan",
                    "Yuhao Zhong",
                    "Ceyhun Eksin",
                    "Satish T. S. Bukkapatnam"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15082v3",
                    "http://arxiv.org/pdf/2311.15082v3"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15080v1/1.0",
                "title": "Weakly-Supervised Audio-Visual Segmentation",
                "year": 2023,
                "abstract": "Audio-visual segmentation is a challenging task that aims to predict\npixel-level masks for sound sources in a video. Previous work applied a\ncomprehensive manually designed architecture with countless pixel-wise accurate\nmasks as supervision. However, these pixel-level masks are expensive and not\navailable in all cases. In this work, we aim to simplify the supervision as the\ninstance-level annotation, i.e., weakly-supervised audio-visual segmentation.\nWe present a novel Weakly-Supervised Audio-Visual Segmentation framework,\nnamely WS-AVS, that can learn multi-scale audio-visual alignment with\nmulti-scale multiple-instance contrastive learning for audio-visual\nsegmentation. Extensive experiments on AVSBench demonstrate the effectiveness\nof our WS-AVS in the weakly-supervised audio-visual segmentation of\nsingle-source and multi-source scenarios.",
                "authors": [
                    "Shentong Mo",
                    "Bhiksha Raj"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15080v1",
                    "http://arxiv.org/pdf/2311.15080v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG",
                    "cs.MM",
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15077v1/1.0",
                "title": "Multilingual self-supervised speech representations improve the speech\n  recognition of low-resource African languages with codeswitching",
                "year": 2023,
                "abstract": "While many speakers of low-resource languages regularly code-switch between\ntheir languages and other regional languages or English, datasets of\ncodeswitched speech are too small to train bespoke acoustic models from scratch\nor do language model rescoring. Here we propose finetuning self-supervised\nspeech representations such as wav2vec 2.0 XLSR to recognize code-switched\ndata. We find that finetuning self-supervised multilingual representations and\naugmenting them with n-gram language models trained from transcripts reduces\nabsolute word error rates by up to 20% compared to baselines of hybrid models\ntrained from scratch on code-switched data. Our findings suggest that in\ncircumstances with limited training data finetuning self-supervised\nrepresentations is a better performing and viable solution.",
                "authors": [
                    "Tol\u00falop\u00e9 \u00d2g\u00fanr\u00e8m\u00ed",
                    "Christopher D. Manning",
                    "Dan Jurafsky"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15077v1",
                    "http://arxiv.org/pdf/2311.15077v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15075v1/1.0",
                "title": "Mug-STAN: Adapting Image-Language Pretrained Models for General Video\n  Understanding",
                "year": 2023,
                "abstract": "Large-scale image-language pretrained models, e.g., CLIP, have demonstrated\nremarkable proficiency in acquiring general multi-modal knowledge through\nweb-scale image-text data. Despite the impressive performance of image-language\nmodels on various image tasks, how to effectively expand them on general video\nunderstanding remains an area of ongoing exploration. In this paper, we\ninvestigate the image-to-video transferring from the perspective of the model\nand the data, unveiling two key obstacles impeding the adaptation of\nimage-language models: non-generalizable temporal modeling and partially\nmisaligned video-text data. To address these challenges, we propose\nSpatial-Temporal Auxiliary Network with Mutual-guided alignment module\n(Mug-STAN), a simple yet effective framework extending image-text model to\ndiverse video tasks and video-text data.Specifically, STAN adopts a branch\nstructure with decomposed spatial-temporal modules to enable generalizable\ntemporal modeling, while Mug suppresses misalignment by introducing token-wise\nfeature aggregation of either modality from the other. Extensive experimental\nresults verify Mug-STAN significantly improves adaptation of language-image\npretrained models such as CLIP and CoCa at both video-text post-pretraining and\nfinetuning stages. With our solution, state-of-the-art zero-shot and finetuning\nresults on various downstream datasets, including MSR-VTT, DiDeMo, LSMDC,\nKinetics-400, Something-Something-2, HMDB-51, UCF- 101, and AVA, are achieved.\nMoreover, by integrating pretrained Mug-STAN with the emerging multimodal\ndialogue model, we can realize zero-shot video chatting. Codes are available at\nhttps://github.com/farewellthree/STAN",
                "authors": [
                    "Ruyang Liu",
                    "Jingjia Huang",
                    "Wei Gao",
                    "Thomas H. Li",
                    "Ge Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15075v1",
                    "http://arxiv.org/pdf/2311.15075v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15074v1/1.0",
                "title": "Upconversion of infrared light by graphitic micro-particles due to\n  photo-induced structural modification",
                "year": 2023,
                "abstract": "Recent reports of upconversion and white light emission from graphitic\nparticles warrant an explanation of the physics behind the process. We offer a\nmodel, wherein the upconversion is facilitated by photo-induced electronic\nstructure modification allowing for multi-photon processes. As per the\nprediction of the model, we experimentally show that graphite upconverts\ninfrared light centered around 1.31~$\\mu$m to broadband white light centered\naround 0.85 $\\mu$m. Our results suggest that upconversion from shortwave\ninfrared ($\\sim$3~$\\mu$m) to visible region may be possible. Our experiments\nshow that the population dynamics of the electronic states involved in this\nupconversion process occur in the timescale of milliseconds.",
                "authors": [
                    "Rohin Sharma",
                    "Nishma Bhattarai",
                    "Rijan Maharjan",
                    "Lilia M. Woods",
                    "Nirajan Ojha",
                    "Ashim Dhakal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15074v1",
                    "http://arxiv.org/pdf/2311.15074v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15069v1/1.0",
                "title": "Multiuser Beamforming for Partially-Connected Millimeter Wave Massive\n  MIMO",
                "year": 2023,
                "abstract": "Multiuser beamforming is considered for partially-connected millimeter wave\nmassive MIMO systems. Based on perfect channel state information (CSI), a\nlow-complexity hybrid beamforming scheme that decouples the analog beamformer\nand the digital beamformer is proposed to maximize the sum-rate. The analog\nbeamformer design is modeled as a phase alignment problem to harvest the array\ngain. Given the analog beamformer, the digital beamformer is designed by\nsolving a weighted minimum mean squared error problem. Then based on imperfect\nCSI, an analog-only beamformer design scheme is proposed, where the design\nproblem aims at maximizing the desired signal power on the current user and\nminimizing the power on the other users to mitigate the multiuser interference.\nThe original problem is then transformed into a series of independent beam\nnulling subproblems, where an efficient iterative algorithm using the\nmajorization-minimization framework is proposed to solve the subproblems.\nSimulation results show that, under perfect CSI, the proposed scheme achieves\nalmost the same sum-rate performance as the existing schemes but with lower\ncomputational complexity; and under imperfect CSI, the proposed analog-only\nbeamforming design scheme can effectively mitigate the multiuser interference.",
                "authors": [
                    "Chenhao Qi",
                    "Jinlin Hu",
                    "Yang Du",
                    "Arumugam Nallanathan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15069v1",
                    "http://arxiv.org/pdf/2311.15069v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15066v1/1.0",
                "title": "Beam Training and Tracking for Extremely Large-Scale MIMO Communications",
                "year": 2023,
                "abstract": "In this paper, beam training and beam tracking are investigated for extremely\nlarge-scale multiple-input-multiple-output communication systems with\npartially-connected hybrid combining structures. Firstly, we propose a\ntwo-stage hybrid-field beam training scheme for both the near field and the far\nfield. In the first stage, each subarray independently uses multiple far-field\nchannel steering vectors to approximate near-field ones for analog combining.\nTo find the codeword best fitting for the channel, digital combiners in the\nsecond stage are designed to combine the outputs of the analog combiners from\nthe first stage. Then, based on the principle of stationary phase and the\ntime-frequency duality, the expressions of subarray signals after analog\ncombining are analytically derived and a beam refinement based on phase shifts\nof subarrays~(BRPSS) scheme with closed-form solutions is proposed for\nhigh-resolution channel parameter estimation. Moreover, a low-complexity\nnear-field beam tracking scheme is developed, where the kinematic model is\nadopted to characterize the channel variations and the extended Kalman filter\nis exploited for beam tracking. Simulation results verify the effectiveness of\nthe proposed schemes.",
                "authors": [
                    "Kangjian Chen",
                    "Chenhao Qi",
                    "Cheng-Xiang Wang",
                    "Geoffrey Ye Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15066v1",
                    "http://arxiv.org/pdf/2311.15066v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15062v1/1.0",
                "title": "Simultaneous Beam Training and Target Sensing in ISAC Systems with RIS",
                "year": 2023,
                "abstract": "This paper investigates an integrated sensing and communication (ISAC) system\nwith reconfigurable intelligent surface (RIS). Our simultaneous beam training\nand target sensing (SBTTS) scheme enables the base station to perform beam\ntraining with the user terminals (UTs) and the RIS, and simultaneously to sense\nthe targets. Based on our findings, the energy of the echoes from the RIS is\naccumulated in the angle-delay domain while that from the targets is\naccumulated in the Doppler-delay domain. The SBTTS scheme can distinguish the\nRIS from the targets with the mixed echoes from the RIS and the targets. Then\nwe propose a positioning and array orientation estimation (PAOE) scheme for\nboth the line-of-sight channels and the non-line-of-sight channels based on the\nbeam training results of SBTTS by developing a low-complexity two-dimensional\nfast search algorithm. Based on the SBTTS and PAOE schemes, we further compute\nthe angle-of-arrival and angle-of-departure for the channels between the RIS\nand the UTs by exploiting the geometry relationship to accomplish the beam\nalignment of the ISAC system. Simulation results verify the effectiveness of\nthe proposed schemes.",
                "authors": [
                    "Kangjian Chen",
                    "Chenhao Qi",
                    "Octavia A. Dobre",
                    "Geoffrey Ye Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15062v1",
                    "http://arxiv.org/pdf/2311.15062v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.IT",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15061v1/1.0",
                "title": "SenseAI: Real-Time Inpainting for Electron Microscopy",
                "year": 2023,
                "abstract": "Despite their proven success and broad applicability to Electron Microscopy\n(EM) data, joint dictionary-learning and sparse-coding based inpainting\nalgorithms have so far remained impractical for real-time usage with an\nElectron Microscope. For many EM applications, the reconstruction time for a\nsingle frame is orders of magnitude longer than the data acquisition time,\nmaking it impossible to perform exclusively subsampled acquisition. This\nlimitation has led to the development of SenseAI, a C++/CUDA library capable of\nextremely efficient dictionary-based inpainting. SenseAI provides N-dimensional\ndictionary learning, live reconstructions, dictionary transfer and\nvisualization, as well as real-time plotting of statistics, parameters, and\nimage quality metrics.",
                "authors": [
                    "Jack Wells",
                    "Amirafshar Moshtaghpour",
                    "Daniel Nicholls",
                    "Alex W. Robinson",
                    "Yalin Zheng",
                    "Jony Castagna",
                    "Nigel D. Browning"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15061v1",
                    "http://arxiv.org/pdf/2311.15061v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15060v1/1.0",
                "title": "Key Issues in Wireless Transmission for NTN-Assisted Internet of Things",
                "year": 2023,
                "abstract": "Non-terrestrial networks (NTNs) have become appealing resolutions for\nseamless coverage in the next-generation wireless transmission, where a large\nnumber of Internet of Things (IoT) devices diversely distributed can be\nefficiently served. The explosively growing number of IoT devices brings a new\nchallenge for massive connection. The long-distance wireless signal propagation\nin NTNs leads to severe path loss and large latency, where the accurate\nacquisition of channel state information (CSI) is another challenge, especially\nfor fast-moving non-terrestrial base stations (NTBSs). Moreover, the scarcity\nof on-board resources of NTBSs is also a challenge for resource allocation. To\nthis end, we investigate three key issues, where the existing schemes and\nemerging resolutions for these three key issues have been comprehensively\npresented. The first issue is to enable the massive connection by designing\nrandom access to establish the wireless link and multiple access to transmit\ndata streams. The second issue is to accurately acquire CSI in various channel\nconditions by channel estimation and beam training, where orthogonal time\nfrequency space modulation and dynamic codebooks are on focus. The third issue\nis to efficiently allocate the wireless resources, including power allocation,\nspectrum sharing, beam hopping, and beamforming. At the end of this article,\nsome future research topics are identified.",
                "authors": [
                    "Chenhao Qi",
                    "Jing Wang",
                    "Leyi Lyu",
                    "Lei Tan",
                    "Jinming Zhang",
                    "Geoffrey Ye Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15060v1",
                    "http://arxiv.org/pdf/2311.15060v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.IT",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15059v1/1.0",
                "title": "Beyond the aggregated paradigm: phenology and structure in mutualistic\n  networks",
                "year": 2023,
                "abstract": "Mutualistic interactions, where species interact to obtain mutual benefits,\nconstitute an essential component of natural ecosystems. The use of ecological\nnetworks to represent the species and their ecological interactions allows the\nstudy of structural and dynamic patterns common to different ecosystems.\nHowever, by neglecting the temporal dimension of mutualistic communities,\nrelevant insights into the organization and functioning of natural ecosystems\ncan be lost. Therefore, it is crucial to incorporate empirical phenology -- the\ncycles of species' activity within a season -- to fully understand the effects\nof temporal variability on network architecture. In this paper, by using two\nempirical datasets together with a set of synthetic models, we propose a\nframework to characterize phenology on ecological networks and assess the\neffect of temporal variability. Analyses reveal that non-trivial information is\nmissed when portraying the network of interactions as static, which leads to\noverestimating the value of fundamental structural features. We discuss the\nimplications of our findings for mutualistic relationships and intra-guild\ncompetition for common resources. We show that recorded interactions and\nspecies' activity duration are pivotal factors in accurately replicating\nobserved patterns within mutualistic communities. Furthermore, our exploration\nof synthetic models underscores the system-specific character of the mechanisms\ndriving phenology, increasing our understanding of the complexities of natural\necosystems.",
                "authors": [
                    "Cl\u00e0udia Payrat\u00f3-Borr\u00e0s",
                    "Carlos Gracia-L\u00e1zaro",
                    "Laura Hern\u00e1ndez",
                    "Yamir Moreno"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15059v1",
                    "http://arxiv.org/pdf/2311.15059v1"
                ],
                "primary_category": "q-bio.PE",
                "categories": [
                    "q-bio.PE",
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15055v1/1.0",
                "title": "Automatically Finding and Categorizing Replication Studies",
                "year": 2023,
                "abstract": "In many fields of experimental science, papers that failed to replicate\ncontinue to be cited as a result of the poor discoverability of replication\nstudies. As a first step to creating a system that automatically finds\nreplication studies for a given paper, 334 replication studies and 344\nreplicated studies were collected. Replication studies could be identified in\nthe dataset based on text content at a higher rate than chance (AUROC = 0.886).\n  Additionally, successful replication studies could be distinguished from\nfailed replication studies at a higher rate than chance (AUROC = 0.664).",
                "authors": [
                    "Bob de Ruiter"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15055v1",
                    "http://arxiv.org/pdf/2311.15055v1"
                ],
                "primary_category": "cs.DL",
                "categories": [
                    "cs.DL",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15054v1/1.0",
                "title": "Detection of developmental language disorder in Cypriot Greek children\n  using a machine learning neural network algorithm",
                "year": 2023,
                "abstract": "Children with developmental language disorder (DLD) encounter difficulties in\nacquiring various language structures. Early identification and intervention\nare crucial to prevent negative long-term outcomes impacting the academic,\nsocial, and emotional development of children. The study aims to develop an\nautomated method for the identification of DLD using artificial intelligence,\nspecifically a neural network machine learning algorithm. This protocol is\napplied for the first time in Cypriot Greek children, which is generally\nconsidered underresearched in the context of DLD. The neural network model was\ntrained using perceptual and production data elicited from children with DLD\nand healthy controls. The k-fold technique was used to crossvalidate the\nalgorithm. The performance of the model was evaluated using metrics such as\naccuracy, precision, recall, F1 score, and ROC/AUC curve to assess its ability\nto make accurate predictions on a set of unseen data. The results demonstrated\nhigh classification values for all metrics (between 0.92 and 0.98), indicating\nthe high accuracy of the neural model in classifying children with DLD.\nAdditionally, the variable importance analysis revealed that the language\nproduction skills of children had a more significant impact on the performance\nof the model compared to perception skills. Neural networks represent powerful\ntools for detecting DLD, providing early and quick assessments of the disorder,\nand having the potential to improve clinical outcomes.",
                "authors": [
                    "Georgios P. Georgiou",
                    "Elena Theodorou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15054v1",
                    "http://arxiv.org/pdf/2311.15054v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15050v1/1.0",
                "title": "Super Winds and Radio Emission in X-ray Binary Systems",
                "year": 2023,
                "abstract": "We have recently proposed that supercritical colliding wind binaries (SCWBs)\nare suitable scenarios for particle acceleration and nonthermal radiation. In\nthese X-ray binary systems (XRBs), the wind from the companion star collides\nwith the wind ejected from the super-Eddington accretion disk of the stellar\nblack hole. Strong shocks are generated in this collision, leading to the\nacceleration of particles and subsequent broadband emission through different\nnonthermal radiative processes. In particular, we estimate luminosities of the\norder of $L\\approx 10^{34}\\,{\\rm erg\\,s^{-1}}$ in the radio band. One of the\nmajor components in these processes is the power provided by the super wind\nexpelled from the disk. Furthermore, some properties of the wind photosphere,\nsuch as its geometry or its temperature distribution, also contribute to the\nabsorption and reprocessing of the nonthermal radiation. In this work, we\nperform a more detailed description of the powerful wind launched from the\naccretion disk, in order to obtain a better understanding of the\nabove-mentioned processes.",
                "authors": [
                    "L. Abaroa",
                    "G. E. Romero"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15050v1",
                    "http://arxiv.org/pdf/2311.15050v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15047v1/1.0",
                "title": "Training a Hopfield Variational Autoencoder with Equilibrium Propagation",
                "year": 2023,
                "abstract": "On dedicated analog hardware, equilibrium propagation is an energy-efficient\nalternative to backpropagation. In spite of its theoretical guarantees, its\napplication in the AI domain remains limited to the discriminative setting.\nMeanwhile, despite its high computational demands, generative AI is on the\nrise. In this paper, we demonstrate the application of Equilibrium Propagation\nin training a variational autoencoder (VAE) for generative modeling. Leveraging\nthe symmetric nature of Hopfield networks, we propose using a single model to\nserve as both the encoder and decoder which could effectively halve the\nrequired chip size for VAE implementations, paving the way for more efficient\nanalog hardware configurations.",
                "authors": [
                    "Tom Van Der Meersch",
                    "Johannes Deleu",
                    "Thomas Demeester"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15047v1",
                    "http://arxiv.org/pdf/2311.15047v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15041v1/1.0",
                "title": "MPCNN: A Novel Matrix Profile Approach for CNN-based Sleep Apnea\n  Classification",
                "year": 2023,
                "abstract": "Sleep apnea (SA) is a significant respiratory condition that poses a major\nglobal health challenge. Previous studies have investigated several machine and\ndeep learning models for electrocardiogram (ECG)-based SA diagnoses. Despite\nthese advancements, conventional feature extractions derived from ECG signals,\nsuch as R-peaks and RR intervals, may fail to capture crucial information\nencompassed within the complete PQRST segments. In this study, we propose an\ninnovative approach to address this diagnostic gap by delving deeper into the\ncomprehensive segments of the ECG signal. The proposed methodology draws\ninspiration from Matrix Profile algorithms, which generate an Euclidean\ndistance profile from fixed-length signal subsequences. From this, we derived\nthe Min Distance Profile (MinDP), Max Distance Profile (MaxDP), and Mean\nDistance Profile (MeanDP) based on the minimum, maximum, and mean of the\nprofile distances, respectively. To validate the effectiveness of our approach,\nwe use the modified LeNet-5 architecture as the primary CNN model, along with\ntwo existing lightweight models, BAFNet and SE-MSCNN, for ECG classification\ntasks. Our extensive experimental results on the PhysioNet Apnea-ECG dataset\nrevealed that with the new feature extraction method, we achieved a per-segment\naccuracy up to 92.11 \\% and a per-recording accuracy of 100\\%. Moreover, it\nyielded the highest correlation compared to state-of-the-art methods, with a\ncorrelation coefficient of 0.989. By introducing a new feature extraction\nmethod based on distance relationships, we enhanced the performance of certain\nlightweight models, showing potential for home sleep apnea test (HSAT) and SA\ndetection in IoT devices. The source code for this work is made publicly\navailable in GitHub: https://github.com/vinuni-vishc/MPCNN-Sleep-Apnea.",
                "authors": [
                    "Hieu X. Nguyen",
                    "Duong V. Nguyen",
                    "Hieu H. Pham",
                    "Cuong D. Do"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15041v1",
                    "http://arxiv.org/pdf/2311.15041v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15038v1/1.0",
                "title": "Low-latency Visual Previews of Large Synchrotron Micro-CT Datasets",
                "year": 2023,
                "abstract": "The unprecedented rate at which synchrotron radiation facilities are\nproducing micro-computed (micro-CT) datasets has resulted in an overwhelming\namount of data that scientists struggle to browse and interact with in\nreal-time. Thousands of arthropods are scanned into micro-CT within the NOVA\nproject, producing a large collection of gigabyte-sized datasets. In this work,\nwe present methods to reduce the size of this data, scaling it from gigabytes\nto megabytes, enabling the micro-CT dataset to be delivered in real-time. In\naddition, arthropods can be identified by scientists even after implementing\ndata reduction methodologies. Our initial step is to devise three distinct\nvisual previews that comply with the best practices of data exploration.\nSubsequently, each visual preview warrants its own design consideration,\nthereby necessitating an individual data processing pipeline for each. We aim\nto present data reduction algorithms applied across the data processing\npipelines. Particularly, we reduce size by using the multi-resolution\nslicemaps, the server-side rendering, and the histogram filtering approaches.\nIn the evaluation, we examine the disparities of each method to identify the\nmost favorable arrangement for our operation, which can then be adjusted for\nother experiments that have comparable necessities. Our demonstration proved\nthat reducing the dataset size to the megabyte range is achievable without\ncompromising the arthropod's geometry information.",
                "authors": [
                    "Nicholas Tan Jerome",
                    "Suren Chilingaryan",
                    "Thomas van de Kamp",
                    "Andreas Kopmann"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15038v1",
                    "http://arxiv.org/pdf/2311.15038v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16515v1/1.0",
                "title": "Word for Person: Zero-shot Composed Person Retrieval",
                "year": 2023,
                "abstract": "Searching for specific person has great security value and social benefits,\nand it often involves a combination of visual and textual information.\nConventional person retrieval methods, whether image-based or text-based,\nusually fall short in effectively harnessing both types of information, leading\nto the loss of accuracy. In this paper, a whole new task called Composed Person\nRetrieval (CPR) is proposed to jointly utilize both image and text information\nfor target person retrieval. However, the supervised CPR must depend on very\ncostly manual annotation dataset, while there are currently no available\nresources. To mitigate this issue, we firstly introduce the Zero-shot Composed\nPerson Retrieval (ZS-CPR), which leverages existing domain-related data to\nresolve the CPR problem without reliance on expensive annotations. Secondly, to\nlearn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where\na lightweight Textual Inversion Network (TINet) and a text-based person\nretrieval model based on fine-tuned Contrastive Language-Image Pre-training\n(CLIP) network are learned without utilizing any CPR data. Thirdly, a finely\nannotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the\nbenchmark to assess the performance of the proposed Word4Per framework.\nExtensive experiments under both Rank-1 and mAP demonstrate the effectiveness\nof Word4Per for the ZS-CPR task, surpassing the comparative methods by over\n10%. The code and ITCPR dataset will be publicly available at\nhttps://github.com/Delong-liu-bupt/Word4Per.",
                "authors": [
                    "Delong Liu",
                    "Haiwen Li",
                    "Zhicheng Zhao",
                    "Fei Su",
                    "Hongying Meng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16515v1",
                    "http://arxiv.org/pdf/2311.16515v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15032v1/1.0",
                "title": "nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla\n  Sentiment Analysis",
                "year": 2023,
                "abstract": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nSentiment Analysis of Bangla Social Media Posts organized at the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The main objective\nof this task is to identify the polarity of social media content using a Bangla\ndataset annotated with positive, neutral, and negative labels provided by the\nshared task organizers. Our best system for this task is a transfer learning\napproach with data augmentation which achieved a micro F1 score of 0.71. Our\nbest system ranked 12th among 30 teams that participated in the competition.",
                "authors": [
                    "Dhiman Goswami",
                    "Md Nishat Raihan",
                    "Sadiya Sayara Chowdhury Puspo",
                    "Marcos Zampieri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15032v1",
                    "http://arxiv.org/pdf/2311.15032v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15030v1/1.0",
                "title": "Learning Task-adaptive Quasi-stiffness Control for A Powered\n  Transfemoral Prosthesis",
                "year": 2023,
                "abstract": "While significant advancements have been made in the mechanical and\ntask-specific controller designs of powered transfemoral prostheses, developing\na task-adaptive control framework that generalizes across various locomotion\nmodes and terrain conditions remains an open problem. This study proposes a\ntask-adaptive learning quasi-stiffness control framework for powered prostheses\nthat generalizes across tasks, including the torque-angle relationship\nreconstruction part and the quasi-stiffness controller design part.\nQuasi-stiffness is defined as the slope of the human joint's torque-angle\nrelationship. To accurately obtain the torque-angle relationship in a new task,\na Gaussian Process Regression (GPR) model is introduced to predict the target\nfeatures of the human joint's angle and torque in the task. Then a Kernelized\nMovement Primitives (KMP) is employed to reconstruct the torque-angle\nrelationship of a new task from multiple human demonstrations and estimated\ntarget features. Based on the torque-angle relationship of the new task, a\nquasi-stiffness control approach is designed for a powered prosthesis. Finally,\nthe proposed framework is validated through practical examples, including\nvarying speed and incline walking tasks. The proposed framework has the\npotential to expand to variable walking tasks in daily life for the\ntransfemoral amputees.",
                "authors": [
                    "Teng Ma",
                    "Shucong Yin",
                    "Zhimin Hou",
                    "Binxin Huang",
                    "Chuheng Chen",
                    "Haoyong Yu",
                    "Chenglong Fu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15030v1",
                    "http://arxiv.org/pdf/2311.15030v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15029v1/1.0",
                "title": "nlpBDpatriots at BLP-2023 Task 1: A Two-Step Classification for Violence\n  Inciting Text Detection in Bangla",
                "year": 2023,
                "abstract": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nViolence Inciting Text Detection (VITD) organized as part of the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The aim of this task\nis to identify and classify the violent threats, that provoke further unlawful\nviolent acts. Our best-performing approach for the task is two-step\nclassification using back translation and multilinguality which ranked 6th out\nof 27 teams with a macro F1 score of 0.74.",
                "authors": [
                    "Md Nishat Raihan",
                    "Dhiman Goswami",
                    "Sadiya Sayara Chowdhury Puspo",
                    "Marcos Zampieri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15029v1",
                    "http://arxiv.org/pdf/2311.15029v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15027v1/1.0",
                "title": "Double-Flow-based Steganography without Embedding for Image-to-Image\n  Hiding",
                "year": 2023,
                "abstract": "As an emerging concept, steganography without embedding (SWE) hides a secret\nmessage without directly embedding it into a cover. Thus, SWE has the unique\nadvantage of being immune to typical steganalysis methods and can better\nprotect the secret message from being exposed. However, existing SWE methods\nare generally criticized for their poor payload capacity and low fidelity of\nrecovered secret messages. In this paper, we propose a novel\nsteganography-without-embedding technique, named DF-SWE, which addresses the\naforementioned drawbacks and produces diverse and natural stego images.\nSpecifically, DF-SWE employs a reversible circulation of double flow to build a\nreversible bijective transformation between the secret image and the generated\nstego image. Hence, it provides a way to directly generate stego images from\nsecret images without a cover image. Besides leveraging the invertible\nproperty, DF-SWE can invert a secret image from a generated stego image in a\nnearly lossless manner and increases the fidelity of extracted secret images.\nTo the best of our knowledge, DF-SWE is the first SWE method that can hide\nlarge images and multiple images into one image with the same size,\nsignificantly enhancing the payload capacity. According to the experimental\nresults, the payload capacity of DF-SWE achieves 24-72 BPP is 8000-16000 times\ncompared to its competitors while producing diverse images to minimize the\nexposure risk. Importantly, DF-SWE can be applied in the steganography of\nsecret images in various domains without requiring training data from the\ncorresponding domains. This domain-agnostic property suggests that DF-SWE can\n1) be applied to hiding private data and 2) be deployed in resource-limited\nsystems.",
                "authors": [
                    "Bingbing Song",
                    "Derui Wang",
                    "Tianwei Zhang",
                    "Renyang Liu",
                    "Yu Lin",
                    "Wei Zhou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15027v1",
                    "http://arxiv.org/pdf/2311.15027v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16184v1/1.0",
                "title": "Impact of overlapping signals on parameterized post-Newtonian\n  coefficients in tests of gravity",
                "year": 2023,
                "abstract": "Gravitational waves have been instrumental in providing deep insights into\nthe nature of gravity. Next-generation detectors, such as the Einstein\nTelescope, are predicted to have a higher detection rate given the increased\nsensitivity and lower cut-off frequency. However, this increased sensitivity\nraises challenges concerning parameter estimation due to the foreseeable\noverlap of signals from multiple sources. Overlapping signals (OSs), if not\nproperly identified, may introduce biases in estimating post-Newtonian (PN)\ncoefficients in parameterized tests of general relativity (GR). We investigate\nhow OSs affect $-1$PN to 2PN terms in parameterized GR tests, examining their\npotential to falsely suggest GR deviations. We estimate the prevalence of such\nmisleading signals in next-generation detectors, and their collective influence\non GR tests. We compare the effects of OSs on coefficients at different PN\norders, concluding that overall the 1PN coefficient suffers the most. Our\nfindings also reveal that while a non-negligible portion of OSs exhibit biases\nin PN coefficients that might individually prefer to conclude deviations from\nGR, collectively, the direction to deviate is random and a statistical\ncombination will still be in favor of GR.",
                "authors": [
                    "Yixuan Dang",
                    "Ziming Wang",
                    "Dicong Liang",
                    "Lijing Shao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16184v1",
                    "http://arxiv.org/pdf/2311.16184v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15026v1/1.0",
                "title": "Impact craters formed by spinning granular projectiles",
                "year": 2023,
                "abstract": "Craters formed by the impact of agglomerated materials are commonly observed\nin nature, such as asteroids colliding with planets and moons. In this paper,\nwe investigate how the projectile spin and cohesion lead to different crater\nshapes. For that, we carried out DEM (discrete element method) computations of\nspinning granular projectiles impacting onto cohesionless grains, for different\nbonding stresses, initial spins and initial heights. We found that, as the\nbonding stresses decrease and the initial spin increases, the projectile's\ngrains spread farther from the collision point, and, in consequence, the crater\nshape becomes flatter, with peaks around the rim and in the center of craters.\nOur results shed light on the dispersion of the projectile's material and the\ndifferent shapes of craters found on Earth and other planetary environments.",
                "authors": [
                    "Douglas Daniel de Carvalho",
                    "Nicolao Cerqueira Lima",
                    "Erick de Moraes Franklin"
                ],
                "url": [
                    "http://dx.doi.org/10.1103/PhysRevE.108.054904",
                    "http://arxiv.org/abs/2311.15026v1",
                    "http://arxiv.org/pdf/2311.15026v1"
                ],
                "primary_category": "astro-ph.EP",
                "categories": [
                    "astro-ph.EP",
                    "physics.geo-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15023v1/1.0",
                "title": "Offensive Language Identification in Transliterated and Code-Mixed\n  Bangla",
                "year": 2023,
                "abstract": "Identifying offensive content in social media is vital for creating safe\nonline communities. Several recent studies have addressed this problem by\ncreating datasets for various languages. In this paper, we explore offensive\nlanguage identification in texts with transliterations and code-mixing,\nlinguistic phenomena common in multilingual societies, and a known challenge\nfor NLP systems. We introduce TB-OLID, a transliterated Bangla offensive\nlanguage dataset containing 5,000 manually annotated comments. We train and\nfine-tune machine learning models on TB-OLID, and we evaluate their results on\nthis dataset. Our results show that English pre-trained transformer-based\nmodels, such as fBERT and HateBERT achieve the best performance on this\ndataset.",
                "authors": [
                    "Md Nishat Raihan",
                    "Umma Hani Tanmoy",
                    "Anika Binte Islam",
                    "Kai North",
                    "Tharindu Ranasinghe",
                    "Antonios Anastasopoulos",
                    "Marcos Zampieri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15023v1",
                    "http://arxiv.org/pdf/2311.15023v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15021v1/1.0",
                "title": "The Imprimitivity Fell Bundle",
                "year": 2023,
                "abstract": "Given a full right-Hilbert C*-module $\\mathbf{X}$ over a C*-algebra $A$, the\nset $\\mathbb{K}_{A}(\\mathbf{X})$ of $A$-compact operators on $\\mathbf{X}$ is\nthe (up to isomorphism) unique C*-algebra that is strongly Morita equivalent to\nthe coefficient algebra $A$ via $\\mathbf{X}$. As bimodule,\n$\\mathbb{K}_{A}(\\mathbf{X})$ can also be thought of as the balanced tensor\nproduct $\\mathbf{X}\\otimes_{A} \\mathbf{X}^{\\mathrm{op}}$, and so the latter\nnaturally becomes a C*-algebra. We generalize both of these facts to the world\nof Fell bundles over groupoids: Suppose $\\mathscr{B}$ is a Fell bundle over a\ngroupoid $\\mathcal{H}$ and $\\mathscr{M}$ an upper semi-continuous Banach bundle\nover a principal right $\\mathcal{H}$-space $X$. If $\\mathscr{M}$ carries a\nright-action of $\\mathscr{B}$ and a sufficiently nice $\\mathscr{B}$-valued\ninner product, then its imprimitivity Fell bundle\n$\\mathbb{K}_{\\mathscr{B}}(\\mathscr{M})=\\mathscr{M}\\otimes_{\\mathscr{B}}\n\\mathscr{M}^{\\mathrm{op}}$ is a Fell bundle over the imprimitivity groupoid of\n$X$, and it is the unique Fell bundle that is equivalent to $\\mathscr{B}$ via\n$\\mathscr{M}$. We show that $\\mathbb{K}_{\\mathscr{B}}(\\mathscr{M})$ generalizes\nthe 'higher order' compact operators of Abadie and Ferraro in the case of\nsaturated bundles over groups, and that the theorem recovers results such as\nKumjian's Stabilization trick.",
                "authors": [
                    "Anna Duwenig"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15021v1",
                    "http://arxiv.org/pdf/2311.15021v1"
                ],
                "primary_category": "math.OA",
                "categories": [
                    "math.OA",
                    "46L55, 46L05, 22A22"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15020v1/1.0",
                "title": "Careful Synchronization of One-Cluster Automata",
                "year": 2023,
                "abstract": "In this paper we investigate careful synchronization of one-cluster partial\nautomata. First we prove that in general case the shortest carefully\nsynchronizing word for such automata is of length $2^\\frac{n}{2} + 1$, where\n$n$ is the number of states of an automaton. Additionally we prove that\nchecking whether a given one-cluster partial automaton is carefully\nsynchronizing is NP-hard even in the case of binary alphabet.",
                "authors": [
                    "Jakub Ruszil"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15020v1",
                    "http://arxiv.org/pdf/2311.15020v1"
                ],
                "primary_category": "cs.FL",
                "categories": [
                    "cs.FL",
                    "cs.CC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15016v1/1.0",
                "title": "E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation",
                "year": 2023,
                "abstract": "Achieving empathy is a crucial step toward humanized dialogue systems.\nCurrent approaches for empathetic dialogue generation mainly perceive an\nemotional label to generate an empathetic response conditioned on it, which\nsimply treat emotions independently, but ignore the intrinsic emotion\ncorrelation in dialogues, resulting in inaccurate emotion perception and\nunsuitable response generation. In this paper, we propose a novel emotion\ncorrelation enhanced empathetic dialogue generation framework, which\ncomprehensively realizes emotion correlation learning, utilization, and\nsupervising. Specifically, a multi-resolution emotion graph is devised to\ncapture context-based emotion interactions from different resolutions, further\nmodeling emotion correlation. Then we propose an emotion correlation enhanced\ndecoder, with a novel correlation-aware aggregation and soft/hard strategy,\nrespectively improving the emotion perception and response generation.\nExperimental results on the benchmark dataset demonstrate the superiority of\nour model in both empathetic perception and expression.",
                "authors": [
                    "Fengyi Fu",
                    "Lei Zhang",
                    "Quan Wang",
                    "Zhendong Mao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15016v1",
                    "http://arxiv.org/pdf/2311.15016v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "I.2.7"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15010v2/1.0",
                "title": "Adapter is All You Need for Tuning Visual Tasks",
                "year": 2023,
                "abstract": "Pre-training & fine-tuning can enhance the transferring efficiency and\nperformance in visual tasks. Recent delta-tuning methods provide more options\nfor visual classification tasks. Despite their success, existing visual\ndelta-tuning art fails to exceed the upper limit of full fine-tuning on\nchallenging tasks like instance segmentation and semantic segmentation. To find\na competitive alternative to full fine-tuning, we propose the Multi-cognitive\nVisual Adapter (Mona) tuning, a novel adapter-based tuning method. First, we\nintroduce multiple vision-friendly filters into the adapter to enhance its\nability to process visual signals, while previous methods mainly rely on\nlanguage-friendly linear filters. Second, we add the scaled normalization layer\nin the adapter to regulate the distribution of input features for visual\nfilters. To fully demonstrate the practicality and generality of Mona, we\nconduct experiments on multiple representative visual tasks, including instance\nsegmentation on COCO, semantic segmentation on ADE20K, object detection on\nPascal VOC, and image classification on several common datasets. Exciting\nresults illustrate that Mona surpasses full fine-tuning on all these tasks and\nis the only delta-tuning method outperforming full fine-tuning on instance\nsegmentation and semantic segmentation tasks. For example, Mona achieves a 1%\nperformance gain on the COCO dataset compared to full fine-tuning.\nComprehensive results suggest that Mona-tuning is more suitable for retaining\nand utilizing the capabilities of pre-trained models than full fine-tuning. The\ncode will be released at https://github.com/Leiyi-Hu/mona.",
                "authors": [
                    "Dongshuo Yin",
                    "Leiyi Hu",
                    "Bin Li",
                    "Youqun Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15010v2",
                    "http://arxiv.org/pdf/2311.15010v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15007v1/1.0",
                "title": "Guiding principles for the design of a chemical vapor deposition process\n  for highly crystalline transition metal dichalcogenides",
                "year": 2023,
                "abstract": "Two-dimensional transition metal dichalcogenides (TMDs) for advanced logic\ntransistor technologies are deposited by various modifications of the chemical\nvapor deposition (CVD) method using a wide variety of precursors. Being a major\nelectrical performance limiter, the TMD crystal grain size strongly differs\nbetween the various CVD precursor chemistries from nano- to millimeter-sized\ncrystals. However, it remains unclear how the CVD precursor chemistry affects\nthe nucleation density and resulting TMD crystal grain size. This work\npostulates guiding principles to design a CVD process for highly crystalline\nTMD deposition using a quantitative analytical model benchmarked against\nliterature. The TMD nucleation density reduces favorably under low\nsupersaturation conditions, where the metal precursor sorption on the starting\nsurface is reversible and the corresponding metal precursor desorption rate\nexceeds the overall deposition rate. Such reversible precursor adsorption\nguarantees efficient long-range gas-phase lateral diffusion of precursor\nspecies in addition to short-range surface diffusion, which vitally increases\ncrystal grain size. As such, the proposed model explains the large spread in\nexperimentally observed TMD nucleation densities and crystal grain sizes for\nstate-of-the-art CVD chemistries. Ultimately, it empowers the reader to\ninterpret and modulate precursor adsorption and diffusion reactions through\ndesigning CVD precursor chemistries compatible with temperature sensitive\napplication schemes.",
                "authors": [
                    "Vladislav Voronenkov",
                    "Benjamin Groven",
                    "Henry Medina Silva",
                    "Pierre Morin",
                    "Stefan De Gendt"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15007v1",
                    "http://arxiv.org/pdf/2311.15007v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15006v1/1.0",
                "title": "A Survey Examining Neuromorphic Architecture in Space and Challenges\n  from Radiation",
                "year": 2023,
                "abstract": "Inspired by the human brain's structure and function, neuromorphic computing\nhas emerged as a promising approach for developing energy-efficient and\npowerful computing systems. Neuromorphic computing offers significant\nprocessing speed and power consumption advantages in aerospace applications.\nThese two factors are crucial for real-time data analysis and decision-making.\nHowever, the harsh space environment, particularly with the presence of\nradiation, poses significant challenges to the reliability and performance of\nthese computing systems. This paper comprehensively surveys the integration of\nradiation-resistant neuromorphic computing systems in aerospace applications.\nWe explore the challenges posed by space radiation, review existing solutions\nand developments, present case studies of neuromorphic computing systems used\nin space applications, discuss future directions, and discuss the potential\nbenefits of this technology in future space missions.",
                "authors": [
                    "Jonathan Naoukin",
                    "Murat Isik",
                    "Karn Tiwari"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15006v1",
                    "http://arxiv.org/pdf/2311.15006v1"
                ],
                "primary_category": "cs.ET",
                "categories": [
                    "cs.ET"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15005v1/1.0",
                "title": "Spectrum Sharing between UAV-based Wireless Mesh Networks and Ground\n  Networks",
                "year": 2023,
                "abstract": "The unmanned aerial vehicle (UAV)-based wireless mesh networks can\neconomically provide wireless services for the areas with disasters. However,\nthe capacity of air-to-air communications is limited due to the multi-hop\ntransmissions. In this paper, the spectrum sharing between UAV-based wireless\nmesh networks and ground networks is studied to improve the capacity of the UAV\nnetworks. Considering the distribution of UAVs as a three-dimensional (3D)\nhomogeneous Poisson point process (PPP) within a vertical range, the stochastic\ngeometry is applied to analyze the impact of the height of UAVs, the transmit\npower of UAVs, the density of UAVs and the vertical range, etc., on the\ncoverage probability of ground network user and UAV network user, respectively.\nThe optimal height of UAVs is numerically achieved in maximizing the capacity\nof UAV networks with the constraint of the coverage probability of ground\nnetwork user. This paper provides a basic guideline for the deployment of\nUAV-based wireless mesh networks.",
                "authors": [
                    "Zhiqing Wei",
                    "Zijun Guo",
                    "Zhiyong Feng",
                    "Jialin Zhu",
                    "Caijun Zhong",
                    "Qihui Wu",
                    "Huici Wu"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/WCSP.2018.8555855",
                    "http://arxiv.org/abs/2311.15005v1",
                    "http://arxiv.org/pdf/2311.15005v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.NA",
                    "math.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15003v1/1.0",
                "title": "Enumerating Error Bounded Polytime Algorithms Through Arithmetical\n  Theories",
                "year": 2023,
                "abstract": "We consider a minimal extension of the language of arithmetic, such that the\nbounded formulas provably total in a suitably-defined theory \\`a la Buss\n(expressed in this new language) precisely capture polytime random functions.\nThen, we provide two new characterizations of the semantic class BPP obtained\nby internalizing the error-bound check within a logical system: the first\nrelies on measure-sensitive quantifiers, while the second is based on standard\nfirst-order quantification. This leads us to introduce a family of effectively\nenumerable subclasses of BPP, called BPP_T and consisting of languages captured\nby those probabilistic Turing machines whose underlying error can be proved\nbounded in the theory T. As a paradigmatic example of this approach, we\nestablish that polynomial identity testing is in BPP_T where\nT=$\\mathrm{I}\\Delta_0+\\mathrm{Exp}$ is a well-studied theory based on bounded\ninduction.",
                "authors": [
                    "Melissa Antonelli",
                    "Ugo Dal Lago",
                    "Davide Davoli",
                    "Isabel Oitavem",
                    "Paolo Pistone"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15003v1",
                    "http://arxiv.org/pdf/2311.15003v1"
                ],
                "primary_category": "cs.LO",
                "categories": [
                    "cs.LO",
                    "math.LO",
                    "F.4.1; F.1.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14998v1/1.0",
                "title": "On the integration of Ito equations with a random or a W-symmetry",
                "year": 2023,
                "abstract": "Symmetries can be used to integrate scalar Ito equation -- or reduce systems\nof such equations -- by the Kozlov substitution, i.e. passing to symmetry\nadapted coordinates. While the theory is well established for so called\ndeterministic standard symmetries (the class originally studied by Kozlov),\nsome points need clarification for so called random standard symmetries and\nW-symmetries. This paper is devoted to such clarification; in particular we\nnote that the theory naturally calls, for these classes of symmetries, to also\nconsider generalized Ito equations; and that while Kozlov theory is extended\nsubstantially unharmed for random standard symmetries, W-symmetries should be\nhandled with great care, and cannot be used towards integration of stochastic\nequations, albeit they have different uses.",
                "authors": [
                    "Giuseppe Gaeta"
                ],
                "url": [
                    "http://dx.doi.org/10.1063/5.0141333",
                    "http://arxiv.org/abs/2311.14998v1",
                    "http://arxiv.org/pdf/2311.14998v1"
                ],
                "primary_category": "math-ph",
                "categories": [
                    "math-ph",
                    "math.MP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16491v1/1.0",
                "title": "$Z^*$: Zero-shot Style Transfer via Attention Rearrangement",
                "year": 2023,
                "abstract": "Despite the remarkable progress in image style transfer, formulating style in\nthe context of art is inherently subjective and challenging. In contrast to\nexisting learning/tuning methods, this study shows that vanilla diffusion\nmodels can directly extract style information and seamlessly integrate the\ngenerative prior into the content image without retraining. Specifically, we\nadopt dual denoising paths to represent content/style references in latent\nspace and then guide the content image denoising process with style latent\ncodes. We further reveal that the cross-attention mechanism in latent diffusion\nmodels tends to blend the content and style images, resulting in stylized\noutputs that deviate from the original content image. To overcome this\nlimitation, we introduce a cross-attention rearrangement strategy. Through\ntheoretical analysis and experiments, we demonstrate the effectiveness and\nsuperiority of the diffusion-based $\\underline{Z}$ero-shot $\\underline{S}$tyle\n$\\underline{T}$ransfer via $\\underline{A}$ttention $\\underline{R}$earrangement,\nZ-STAR.",
                "authors": [
                    "Yingying Deng",
                    "Xiangyu He",
                    "Fan Tang",
                    "Weiming Dong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16491v1",
                    "http://arxiv.org/pdf/2311.16491v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14995v1/1.0",
                "title": "Gohberg-Semencul Estimation of Toeplitz Structured Covariance Matrices\n  and Their Inverses",
                "year": 2023,
                "abstract": "When only few data samples are accessible, utilizing structural prior\nknowledge is essential for estimating covariance matrices and their inverses.\nOne prominent example is knowing the covariance matrix to be Toeplitz\nstructured, which occurs when dealing with wide sense stationary (WSS)\nprocesses. This work introduces a novel class of positive definiteness ensuring\nlikelihood-based estimators for Toeplitz structured covariance matrices (CMs)\nand their inverses. In order to accomplish this, we derive positive\ndefiniteness enforcing constraint sets for the Gohberg-Semencul (GS)\nparameterization of inverse symmetric Toeplitz matrices. Motivated by the\nrelationship between the GS parameterization and autoregressive (AR) processes,\nwe propose hyperparameter tuning techniques, which enable our estimators to\ncombine advantages from state-of-the-art likelihood and non-parametric\nestimators. Moreover, we present a computationally cheap closed-form estimator,\nwhich is derived by maximizing an approximate likelihood. Due to the ensured\npositive definiteness, our estimators perform well for both the estimation of\nthe CM and the inverse covariance matrix (ICM). Extensive simulation results\nvalidate the proposed estimators' efficacy for several standard Toeplitz\nstructured CMs commonly employed in a wide range of applications.",
                "authors": [
                    "Benedikt B\u00f6ck",
                    "Dominik Semmler",
                    "Benedikt Fesl",
                    "Michael Baur",
                    "Wolfgang Utschick"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14995v1",
                    "http://arxiv.org/pdf/2311.14995v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14994v1/1.0",
                "title": "Exploring Causal Learning through Graph Neural Networks: An In-depth\n  Review",
                "year": 2023,
                "abstract": "In machine learning, exploring data correlations to predict outcomes is a\nfundamental task. Recognizing causal relationships embedded within data is\npivotal for a comprehensive understanding of system dynamics, the significance\nof which is paramount in data-driven decision-making processes. Beyond\ntraditional methods, there has been a surge in the use of graph neural networks\n(GNNs) for causal learning, given their capabilities as universal data\napproximators. Thus, a thorough review of the advancements in causal learning\nusing GNNs is both relevant and timely. To structure this review, we introduce\na novel taxonomy that encompasses various state-of-the-art GNN methods employed\nin studying causality. GNNs are further categorized based on their applications\nin the causality domain. We further provide an exhaustive compilation of\ndatasets integral to causal learning with GNNs to serve as a resource for\npractical study. This review also touches upon the application of causal\nlearning across diverse sectors. We conclude the review with insights into\npotential challenges and promising avenues for future exploration in this\nrapidly evolving field of machine learning.",
                "authors": [
                    "Simi Job",
                    "Xiaohui Tao",
                    "Taotao Cai",
                    "Haoran Xie",
                    "Lin Li",
                    "Jianming Yong",
                    "Qing Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14994v1",
                    "http://arxiv.org/pdf/2311.14994v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14990v1/1.0",
                "title": "View it like a radiologist: Shifted windows for deep learning\n  augmentation of CT images",
                "year": 2023,
                "abstract": "Deep learning has the potential to revolutionize medical practice by\nautomating and performing important tasks like detecting and delineating the\nsize and locations of cancers in medical images. However, most deep learning\nmodels rely on augmentation techniques that treat medical images as natural\nimages. For contrast-enhanced Computed Tomography (CT) images in particular,\nthe signals producing the voxel intensities have physical meaning, which is\nlost during preprocessing and augmentation when treating such images as natural\nimages. To address this, we propose a novel preprocessing and intensity\naugmentation scheme inspired by how radiologists leverage multiple viewing\nwindows when evaluating CT images. Our proposed method, window shifting,\nrandomly places the viewing windows around the region of interest during\ntraining. This approach improves liver lesion segmentation performance and\nrobustness on images with poorly timed contrast agent. Our method outperforms\nclassical intensity augmentations as well as the intensity augmentation\npipeline of the popular nn-UNet on multiple datasets.",
                "authors": [
                    "Eirik A. \u00d8stmo",
                    "Kristoffer K. Wickstr\u00f8m",
                    "Keyur Radiya",
                    "Michael C. Kampffmeyer",
                    "Robert Jenssen"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/MLSP55844.2023.10285978",
                    "http://arxiv.org/abs/2311.14990v1",
                    "http://arxiv.org/pdf/2311.14990v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14988v1/1.0",
                "title": "The Performance Analysis of Spectrum Sharing between UAV enabled\n  Wireless Mesh Networks and Ground Networks",
                "year": 2023,
                "abstract": "Unmanned aerial vehicle (UAV) has the advantages of large coverage and\nflexibility, which could be applied in disaster management to provide wireless\nservices to the rescuers and victims. When UAVs forms an aerial mesh network,\nline-of-sight (LoS) air-to-air (A2A) communications have long transmission\ndistance, which extends the coverage of multiple UAVs. However, the capacity of\nUAV is constrained due to the multiple hop transmissions in aerial mesh\nnetworks. In this paper, spectrum sharing between UAV enabled wireless mesh\nnetworks and ground networks is studied to improve the capacity of UAV\nnetworks. Considering two-dimensional (2D) and three-dimensional (3D)\nhomogeneous Poisson point process (PPP) modeling for the distribution of UAVs\nwithin a vertical range {\\Delta}h, stochastic geometry is applied to analyze\nthe impact of the height of UAVs, the transmit power of UAVs, the density of\nUAVs and the vertical range, etc., on the coverage probability of ground\nnetwork user and UAV network user. Besides, performance improvement of spectrum\nsharing with directional antenna is verified. With the object function of\nmaximizing the transmission capacity, the optimal altitude of UAVs is obtained.\nThis paper provides a theoretical guideline for the spectrum sharing of UAV\nenabled wireless mesh networks, which may contribute significant value to the\nstudy of spectrum sharing mechanisms for UAV enabled wireless mesh networks.",
                "authors": [
                    "Zhiqing Wei",
                    "Jialin Zhu",
                    "Zijun Guo",
                    "Fan Ning"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/JSEN.2020.3038774",
                    "http://arxiv.org/abs/2311.14988v1",
                    "http://arxiv.org/pdf/2311.14988v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.PF"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14987v1/1.0",
                "title": "Reconstruction of a Long-term spatially Contiguous Solar-Induced\n  Fluorescence (LCSIF) over 1982-2022",
                "year": 2023,
                "abstract": "Satellite-observed solar-induced chlorophyll fluorescence (SIF) is a powerful\nproxy for diagnosing the photosynthetic characteristics of terrestrial\necosystems. Despite the increasing spatial and temporal resolutions of these\nsatellite retrievals, records of SIF are primarily limited to the recent\ndecade, impeding their application in detecting long-term dynamics of ecosystem\nfunction and structure. In this study, we leverage the two surface reflectance\nbands (red and near-infrared) available both from Advanced Very High-Resolution\nRadiometer (AVHRR, 1982-2022) and MODerate-resolution Imaging Spectroradiometer\n(MODIS, 2001-2022). Importantly, we calibrate and orbit-correct the AVHRR bands\nagainst their MODIS counterparts during their overlapping period. Using the\nlong-term bias-corrected reflectance data, a neural network is then built to\nreproduce the Orbiting Carbon Observatory-2 SIF using AVHRR and MODIS, and used\nto map SIF globally over the entire 1982-2022 period. Compared with the\nprevious MODIS-based CSIF product relying on four reflectance bands, our\ntwo-band-based product has similar skill but can be advantageously extended to\nthe bias-corrected AVHRR period. Further comparison with three widely used\nvegetation indices (NDVI, kNDVI, NIRv; all based empirically on red and\nnear-infrared bands) shows a higher or comparable correlation of LCSIF with\nsatellite SIF and site-level GPP estimates across vegetation types, ensuring a\ngreater capacity of LCSIF for representing terrestrial photosynthesis.\nGlobally, LCSIF-AVHRR shows an accelerating upward trend since 1982, with an\naverage rate of 0.0025 mW m-2 nm-1 sr-1 per decade during 1982-2000 and 0.0038\nmW m-2 nm-1 sr-1 per decade during 2001-2022. Our LCSIF data provide\nopportunities to better understand the long-term dynamics of ecosystem\nphotosynthesis and their underlying driving processes.",
                "authors": [
                    "Jianing Fang",
                    "Xu Lian",
                    "Youngryel Ryu",
                    "Sungchan Jeong",
                    "Chongya Jiang",
                    "Pierre Gentine"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14987v1",
                    "http://arxiv.org/pdf/2311.14987v1"
                ],
                "primary_category": "physics.geo-ph",
                "categories": [
                    "physics.geo-ph",
                    "astro-ph.IM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14983v1/1.0",
                "title": "Neural Network Based Approach to Recognition of Meteor Tracks in the\n  Mini-EUSO Telescope Data",
                "year": 2023,
                "abstract": "Mini-EUSO is a wide-angle fluorescence telescope that registers ultraviolet\n(UV) radiation in the nocturnal atmosphere of Earth from the International\nSpace Station. Meteors are among multiple phenomena that manifest themselves\nnot only in the visible range but also in the UV. We present two simple\nartificial neural networks that allow for recognizing meteor signals in the\nMini-EUSO data with high accuracy in terms of a binary classification problem.\nWe expect that similar architectures can be effectively used for signal\nrecognition in other fluorescence telescopes, regardless of the nature of the\nsignal. Due to their simplicity, the networks can be implemented in onboard\nelectronics of future orbital or balloon experiments.",
                "authors": [
                    "Mikhail Zotov",
                    "Dmitry Anzhiganov",
                    "Aleksandr Kryazhenkov",
                    "Dario Barghini",
                    "Matteo Battisti",
                    "Alexander Belov",
                    "Mario Bertaina",
                    "Marta Bianciotto",
                    "Francesca Bisconti",
                    "Carl Blaksley",
                    "Sylvie Blin",
                    "Giorgio Cambi\u00e8",
                    "Francesca Capel",
                    "Marco Casolino",
                    "Toshikazu Ebisuzaki",
                    "Johannes Eser",
                    "Francesco Fenu",
                    "Massimo Alberto Franceschi",
                    "Alessio Golzio",
                    "Philippe Gorodetzky",
                    "Fumiyoshi Kajino",
                    "Hiroshi Kasuga",
                    "Pavel Klimov",
                    "Massimiliano Manfrin",
                    "Laura Marcelli",
                    "Hiroko Miyamoto",
                    "Alexey Murashov",
                    "Tommaso Napolitano",
                    "Hiroshi Ohmori",
                    "Angela Olinto",
                    "Etienne Parizot",
                    "Piergiorgio Picozza",
                    "Lech Wiktor Piotrowski",
                    "Zbigniew Plebaniak",
                    "Guillaume Pr\u00e9v\u00f4t",
                    "Enzo Reali",
                    "Marco Ricci",
                    "Giulia Romoli",
                    "Naoto Sakaki",
                    "Kenji Shinozaki",
                    "Christophe De La Taille",
                    "Yoshiyuki Takizawa",
                    "Michal Vr\u00e1bel",
                    "Lawrence Wiencke"
                ],
                "url": [
                    "http://dx.doi.org/10.3390/a16090448",
                    "http://arxiv.org/abs/2311.14983v1",
                    "http://arxiv.org/pdf/2311.14983v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14982v1/1.0",
                "title": "Active Queue Management with Data-Driven Delay Violation Probability\n  Predictors",
                "year": 2023,
                "abstract": "The increasing demand for latency-sensitive applications has necessitated the\ndevelopment of sophisticated algorithms that efficiently manage packets with\nend-to-end delay targets traversing the networked infrastructure. Network\ncomponents must consider minimizing the packets' end-to-end delay violation\nprobabilities (DVP) as a guiding principle throughout the transmission path to\nensure timely deliveries. Active queue management (AQM) schemes are commonly\nused to mitigate congestion by dropping packets and controlling queuing delay.\nToday's established AQM schemes are threshold-driven, identifying congestion\nand trigger packet dropping using a predefined criteria which is unaware of\npackets' DVPs. In this work, we propose a novel framework, Delta, that combines\nend-to-end delay characterization with AQM for minimizing DVP. In a queuing\ntheoretic environment, we show that such a policy is feasible by utilizing a\ndata-driven approach to predict the queued packets' DVPs. That enables Delta\nAQM to effectively handle links with arbitrary stationary service time\nprocesses. The implementation is described in detail, and its performance is\nevaluated and compared with state of the art AQM algorithms. Our results show\nthe Delta outperforms current AQM schemes substantially, in particular in\nscenarios where high reliability, i.e. high quantiles of the tail latency\ndistribution, are of interest.",
                "authors": [
                    "Samie Mostafavi",
                    "Neelabhro Roy",
                    "Gy\u00f6rgy D\u00e1n",
                    "James Gross"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14982v1",
                    "http://arxiv.org/pdf/2311.14982v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14981v2/1.0",
                "title": "Multi-task Planar Reconstruction with Feature Warping Guidance",
                "year": 2023,
                "abstract": "Piece-wise planar 3D reconstruction simultaneously segments plane instances\nand recovers their 3D plane parameters from an image, which is particularly\nuseful for indoor or man-made environments. Efficient reconstruction of 3D\nplanes coupled with semantic predictions offers advantages for a wide range of\napplications requiring scene understanding and concurrent spatial mapping.\nHowever, most existing planar reconstruction models either neglect semantic\npredictions or do not run efficiently enough for real-time applications. We\nintroduce SOLOPlanes, a real-time planar reconstruction model based on a\nmodified instance segmentation architecture which simultaneously predicts\nsemantics for each plane instance, along with plane parameters and piece-wise\nplane instance masks. We achieve an improvement in instance mask segmentation\nby including multi-view guidance for plane predictions in the training process.\nThis cross-task improvement, training for plane prediction but improving the\nmask segmentation, is due to the nature of feature sharing in multi-task\nlearning. Our model simultaneously predicts semantics using single images at\ninference time, while achieving real-time predictions at 43 FPS.",
                "authors": [
                    "Luan Wei",
                    "Anna Hilsmann",
                    "Peter Eisert"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14981v2",
                    "http://arxiv.org/pdf/2311.14981v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14980v1/1.0",
                "title": "Long-time behavior of the time-dependent damped nonlinear Schrodinger\n  equation",
                "year": 2023,
                "abstract": "We investigate the large time behavior of the solutions to the nonlinear\nfocusing Schr\\\"odinger equation with a time-dependent damping in the energy\nsub-critical regime. The scattering results obtained in this work constitute a\nnatural extension of the ones in [15] where a constant damping is considered.",
                "authors": [
                    "Makram Hamouda",
                    "Mohamed Majdoub"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14980v1",
                    "http://arxiv.org/pdf/2311.14980v1"
                ],
                "primary_category": "math.AP",
                "categories": [
                    "math.AP",
                    "math-ph",
                    "math.MP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14972v1/1.0",
                "title": "Leveraging Neural Networks with Attention Mechanism for High-Order\n  Accuracy in Charge Density in Particle-in-Cell Simulation",
                "year": 2023,
                "abstract": "In this research, we introduce an innovative three-network architecture that\ncomprises an encoder-decoder framework with an attention mechanism. The\narchitecture comprises a 1st-order-pre-trainer, a 2nd-order-improver, and a\ndiscriminator network, designed to boost the order accuracy of charge density\nin Particle-In-Cell (PIC) simulations. We acquire our training data from our\nself-developed 3-D PIC code, JefiPIC. The training procedure starts with the\n1st-order-pre-trainer, which is trained on a large dataset to predict charge\ndensities based on the provided article positions. Subsequently, we fine-tune\nthe 1st-order-pre-trainer, whose predictions then serve as inputs to the\n2nd-order-improver. Meanwhile, we train the 2nd-order-improver and\ndiscriminator network using a smaller volume of 2nd-order data, thereby\nachieving to generate charge density with 2nd-order accuracy. In the concluding\nphase, we replace JefiPIC's conventional particle interpolation process with\nour trained neural network. Our results demonstrate that the neural\nnetwork-enhanced PIC simulation can effectively simulate plasmas with 2\nnd-order accuracy. This highlights the advantage of our proposed neural\nnetwork: it can achieve higher-accuracy data with fewer real labels.",
                "authors": [
                    "Jian-Nan Chen",
                    "Jun-Jie Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14972v1",
                    "http://arxiv.org/pdf/2311.14972v1"
                ],
                "primary_category": "physics.comp-ph",
                "categories": [
                    "physics.comp-ph",
                    "physics.plasm-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14970v1/1.0",
                "title": "UWB Radar SLAM: an Anchorless Approach in Vision Denied Indoor\n  Environments",
                "year": 2023,
                "abstract": "LiDAR and cameras are frequently used as sensors for simultaneous\nlocalization and mapping (SLAM). However, these sensors are prone to failure\nunder low visibility (e.g. smoke) or places with reflective surfaces (e.g.\nmirrors). On the other hand, electromagnetic waves exhibit better penetration\nproperties when the wavelength increases, thus are not affected by low\nvisibility. Hence, this paper presents ultra-wideband (UWB) radar as an\nalternative to the existing sensors. UWB is generally known to be used in\nanchor-tag SLAM systems. One or more anchors are installed in the environment\nand the tags are attached to the robots. Although this method performs well\nunder low visibility, modifying the existing infrastructure is not always\nfeasible. UWB has also been used in peer-to-peer ranging collaborative SLAM\nsystems. However, this requires more than a single robot and does not include\nmapping in the mentioned environment like smoke. Therefore, the presented\napproach in this paper solely depends on the UWB transceivers mounted on-board.\nIn addition, an extended Kalman filter (EKF) SLAM is used to solve the SLAM\nproblem at the back-end. Experiments were conducted and demonstrated that the\nproposed UWB-based radar SLAM is able to map natural point landmarks inside an\nindoor environment while improving robot localization.",
                "authors": [
                    "H. A. G. C. Premachandra",
                    "Ran Liu",
                    "Chau Yuen",
                    "U-Xuan Tan"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/LRA.2023.3293354",
                    "http://arxiv.org/abs/2311.14970v1",
                    "http://arxiv.org/pdf/2311.14970v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14966v1/1.0",
                "title": "Walking a Tightrope -- Evaluating Large Language Models in High-Risk\n  Domains",
                "year": 2023,
                "abstract": "High-risk domains pose unique challenges that require language models to\nprovide accurate and safe responses. Despite the great success of large\nlanguage models (LLMs), such as ChatGPT and its variants, their performance in\nhigh-risk domains remains unclear. Our study delves into an in-depth analysis\nof the performance of instruction-tuned LLMs, focusing on factual accuracy and\nsafety adherence. To comprehensively assess the capabilities of LLMs, we\nconduct experiments on six NLP datasets including question answering and\nsummarization tasks within two high-risk domains: legal and medical. Further\nqualitative analysis highlights the existing limitations inherent in current\nLLMs when evaluating in high-risk domains. This underscores the essential\nnature of not only improving LLM capabilities but also prioritizing the\nrefinement of domain-specific metrics, and embracing a more human-centric\napproach to enhance safety and factual reliability. Our findings advance the\nfield toward the concerns of properly evaluating LLMs in high-risk domains,\naiming to steer the adaptability of LLMs in fulfilling societal obligations and\naligning with forthcoming regulations, such as the EU AI Act.",
                "authors": [
                    "Chia-Chien Hung",
                    "Wiem Ben Rim",
                    "Lindsay Frost",
                    "Lars Bruckner",
                    "Carolin Lawrence"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14966v1",
                    "http://arxiv.org/pdf/2311.14966v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14964v1/1.0",
                "title": "Selective Inference for Changepoint detection by Recurrent Neural\n  Network",
                "year": 2023,
                "abstract": "In this study, we investigate the quantification of the statistical\nreliability of detected change points (CPs) in time series using a Recurrent\nNeural Network (RNN). Thanks to its flexibility, RNN holds the potential to\neffectively identify CPs in time series characterized by complex dynamics.\nHowever, there is an increased risk of erroneously detecting random noise\nfluctuations as CPs. The primary goal of this study is to rigorously control\nthe risk of false detections by providing theoretically valid p-values to the\nCPs detected by RNN. To achieve this, we introduce a novel method based on the\nframework of Selective Inference (SI). SI enables valid inferences by\nconditioning on the event of hypothesis selection, thus mitigating selection\nbias. In this study, we apply SI framework to RNN-based CP detection, where\ncharacterizing the complex process of RNN selecting CPs is our main technical\nchallenge. We demonstrate the validity and effectiveness of the proposed method\nthrough artificial and real data experiments.",
                "authors": [
                    "Tomohiro Shiraishi",
                    "Daiki Miwa",
                    "Vo Nguyen Le Duy",
                    "Ichiro Takeuchi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14964v1",
                    "http://arxiv.org/pdf/2311.14964v1"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14961v2/1.0",
                "title": "Repetition factorization of automatic sequences",
                "year": 2023,
                "abstract": "Following Inoue et al., we define a word to be a repetition if it is a\n(fractional) power of exponent at least 2. A word has a repetition\nfactorization if it is the product of repetitions. We study repetition\nfactorizations in several (generalized) automatic sequences, including the\ninfinite Fibonacci word, the Thue-Morse word, paperfolding words, and the\nRudin-Shapiro sequence.",
                "authors": [
                    "Jeffrey Shallit",
                    "Xinhao Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14961v2",
                    "http://arxiv.org/pdf/2311.14961v2"
                ],
                "primary_category": "cs.FL",
                "categories": [
                    "cs.FL",
                    "cs.DM",
                    "math.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14957v1/1.0",
                "title": "Multi-Scale Sub-Band Constant-Q Transform Discriminator for\n  High-Fidelity Vocoder",
                "year": 2023,
                "abstract": "Generative Adversarial Network (GAN) based vocoders are superior in inference\nspeed and synthesis quality when reconstructing an audible waveform from an\nacoustic representation. This study focuses on improving the discriminator to\npromote GAN-based vocoders. Most existing time-frequency-representation-based\ndiscriminators are rooted in Short-Time Fourier Transform (STFT), whose\ntime-frequency resolution in a spectrogram is fixed, making it incompatible\nwith signals like singing voices that require flexible attention for different\nfrequency bands. Motivated by that, our study utilizes the Constant-Q Transform\n(CQT), which owns dynamic resolution among frequencies, contributing to a\nbetter modeling ability in pitch accuracy and harmonic tracking. Specifically,\nwe propose a Multi-Scale Sub-Band CQT (MS-SB-CQT) Discriminator, which operates\non the CQT spectrogram at multiple scales and performs sub-band processing\naccording to different octaves. Experiments conducted on both speech and\nsinging voices confirm the effectiveness of our proposed method. Moreover, we\nalso verified that the CQT-based and the STFT-based discriminators could be\ncomplementary under joint training. Specifically, enhanced by the proposed\nMS-SB-CQT and the existing MS-STFT Discriminators, the MOS of HiFi-GAN can be\nboosted from 3.27 to 3.87 for seen singers and from 3.40 to 3.78 for unseen\nsingers.",
                "authors": [
                    "Yicheng Gu",
                    "Xueyao Zhang",
                    "Liumeng Xue",
                    "Zhizheng Wu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14957v1",
                    "http://arxiv.org/pdf/2311.14957v1"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14951v2/1.0",
                "title": "Programmable high-dimensional Hamiltonian in a photonic waveguide array",
                "year": 2023,
                "abstract": "Waveguide lattices offer a compact and stable platform for a range of\napplications, including quantum walks, topological effects, condensed matter\nsystem simulation, and classical and quantum information processing. In such\nlattices, the Hamiltonian's hopping and on-site terms determine the optical\nevolution, which can be engineered using waveguide spacing and refractive index\nprofile. While waveguide lattices have been realized in various photonic\nplatforms, these devices have always been static and designed for specific\napplications. We present a programmable waveguide array in which the\nHamiltonian terms can be electro-optically tuned to implement various\nHamiltonian continuous-time evolutions on a single device. We used a single\narray with 11 waveguides in lithium niobate, controlled via 22 electrodes, to\nperform a range of experiments that realized the Su-Schriffer-Heeger model, the\nAubrey-Andre model, and Anderson localization, which is equivalent to over 2500\nstatic devices. Our architecture's micron-scale local electric fields\nindependently control waveguide coupling coefficients and effective indices,\nwhich overcomes cross-talk limitations of thermo-optic phase shifters in other\nplatforms such as silicon, silicon-nitride, and silica. Electro-optic control\nallows for ultra-fast and more precise reconfigurability with lower power\nconsumption, and with quantum input states, our platform can enable the study\nof multiple condensed matter quantum dynamics with a single device.",
                "authors": [
                    "Yang Yang",
                    "Robert J. Chapman",
                    "Ben Haylock",
                    "Francesco Lenzini",
                    "Yogesh N. Joglekar",
                    "Mirko Lobino",
                    "Alberto Peruzzo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14951v2",
                    "http://arxiv.org/pdf/2311.14951v2"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14950v1/1.0",
                "title": "An exact solution for the magnetic diffusion problem with a\n  step-function resistivity model",
                "year": 2023,
                "abstract": "In the magnetic diffusion problem, a magnetic diffusion equation is coupled\nby an Ohmic heating energy equation. The Ohmic heating can make the magnetic\ndiffusion coefficient (i. e., the resistivity) vary violently, and make the\ndiffusion a highly nonlinear process. For this reason, the problem is normally\nvery hard to be solved analytically. In this article, under the condition of a\nstep-function resistivity and a constant boundary magnetic field, we\nsuccessfully derived an exact solution for this nonlinear problem, which should\nbe an interesting thing in the area of partial differential equations. What's\nmore, the solution could serve as a valuable benchmark example for testing\nsimulation methods of the magnetic diffusion problem.",
                "authors": [
                    "Bo Xiao",
                    "Ganghua Wang",
                    "Li Zhao",
                    "Chunsheng Feng",
                    "Shi Shu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14950v1",
                    "http://arxiv.org/pdf/2311.14950v1"
                ],
                "primary_category": "math-ph",
                "categories": [
                    "math-ph",
                    "math.MP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14949v1/1.0",
                "title": "Vector-Quantized Prompt Learning for Paraphrase Generation",
                "year": 2023,
                "abstract": "Deep generative modeling of natural languages has achieved many successes,\nsuch as producing fluent sentences and translating from one language into\nanother. However, the development of generative modeling techniques for\nparaphrase generation still lags behind largely due to the challenges in\naddressing the complex conflicts between expression diversity and semantic\npreservation. This paper proposes to generate diverse and high-quality\nparaphrases by exploiting the pre-trained models with instance-dependent\nprompts. To learn generalizable prompts, we assume that the number of abstract\ntransforming patterns of paraphrase generation (governed by prompts) is finite\nand usually not large. Therefore, we present vector-quantized prompts as the\ncues to control the generation of pre-trained models. Extensive experiments\ndemonstrate that the proposed method achieves new state-of-art results on three\nbenchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release\nall the code upon acceptance.",
                "authors": [
                    "Haotian Luo",
                    "Yixin Liu",
                    "Peidong Liu",
                    "Xianggen Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14949v1",
                    "http://arxiv.org/pdf/2311.14949v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14946v1/1.0",
                "title": "RFSoC-based front-end electronics for pulse detection",
                "year": 2023,
                "abstract": "Radiation measurement relies on pulse detection, which can be performed using\nvarious configurations of high-speed analog-to-digital converters (ADCs) and\nfield-programmable gate arrays (FPGAs). For optimal power consumption, design\nsimplicity, system flexibility, and the availability of DSP slices, we consider\nthe Radio Frequency System-on-Chip (RFSoC) to be a more suitable option than\ntraditional setups. To this end, we have developed custom RFSoC-based\nelectronics and verified its feasibility. The ADCs on RFSoC exhibit a flat\nfrequency response of 1-125 MHz. The root-mean-square (RMS) noise level is 2.1\nADC without any digital signal processing. The digital signal processing\nimproves the RMS noise level to 0.8 ADC (input equivalent 40 Vrms). Baseline\ncorrection via digital signal processing can effectively prevent\nphotomultiplier overshoot after a large pulse. Crosstalk between all channels\nis less than -55 dB. The measured data transfer speed can support up to 32 kHz\ntrigger rates (corresponding to 750 Mbps). Overall, our RFSoC-based electronics\nare highly suitable for pulse detection, and after some modifications, they\nwill be employed in the Kamioka Liquid Scintillator Anti-Neutrino Detector\n(KamLAND).",
                "authors": [
                    "S. N. Axani",
                    "S. Futagi",
                    "M. Garcia",
                    "C. Grant",
                    "K. Hosokawa",
                    "S. Ieki",
                    "K. Inoue",
                    "K. Ishidoshiro",
                    "N. Kawada",
                    "Y. Matsumoto",
                    "T. Nakahata",
                    "K. Nakamura",
                    "R. Shouji",
                    "H. Song",
                    "L. A. Winslow"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14946v1",
                    "http://arxiv.org/pdf/2311.14946v1"
                ],
                "primary_category": "physics.ins-det",
                "categories": [
                    "physics.ins-det"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14943v1/1.0",
                "title": "Generation of polarized electron beams through self-injection in the\n  interaction of a laser with a pre-polarized plasma",
                "year": 2023,
                "abstract": "Polarized electron beam production via laser wakefield acceleration in\npre-polarized plasma is investigated by particle-in-cell simulations. The\nevolution of the electron beam polarization is studied based on the\nThomas-Bargmann-Michel-Telegdi equation for the transverse and longitudinal\nself-injection, and the depolarization process is found to be influenced by the\ninjection schemes. In the case of transverse self-injection as found typically\nin the bubble regime, the spin precession of the accelerated electrons is\nmainly influenced by the wakefield. However, in the case of longitudinal\ninjection in the quasi-one-dimensional regime (for example, F. Y. Li \\emph{et\nal}., Phys. Rev. Lett. 110, 135002 (2013)), the direction of electron spin\noscillates in the laser filed. Since the electrons move around the laser axis,\nthe net influence of the laser field is nearly zero and the contribution of the\nwakefield can be ignored. Finally, an ultra-short electron beam with\npolarization of $99\\%$ can be obtained using longitudinal self-injection.",
                "authors": [
                    "L. R. Yin",
                    "X. F. Li",
                    "Y. J. Gu",
                    "N. Cao",
                    "Q. Kong",
                    "M. Buescher",
                    "S. M. Weng",
                    "M. Chen",
                    "Z. M. Sheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14943v1",
                    "http://arxiv.org/pdf/2311.14943v1"
                ],
                "primary_category": "physics.plasm-ph",
                "categories": [
                    "physics.plasm-ph",
                    "physics.acc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14942v1/1.0",
                "title": "Hybrid Precoding and Combining for mmWave Full-Duplex Joint Radar and\n  Communication Systems under Self-Interference",
                "year": 2023,
                "abstract": "In the context of integrated sensing and communication (ISAC), a full-duplex\n(FD) transceiver can operate as a monostatic radar while maintaining\ncommunication capabilities. This paper investigates the design of precoders and\ncombiners for a joint radar and communication (JRC) system at mmWave\nfrequencies. The primary goals of the design are to minimize self-interference\n(SI) caused by FD operation, while guaranteeing certain performance in terms of\nsome sensing and communication metrics, as well as taking into account the\nhardware limitations coming from a hybrid MIMO architecture. Specifically, we\nintroduce a generalized eigenvalue-based precoder that takes into account\ndownlink user rate, radar gain, and SI suppression. Since the hybrid\nanalog/digital architecture degrades the SI suppression capability of the\nprecoder, we further enhance SI suppression with the analog combiner. Our\nnumerical results demonstrate that the proposed architecture achieves the\nrequired radar gain and SI mitigation while incurring a small loss in downlink\nspectral efficiency. Additionally, the numerical experiments also show that the\nuse of orthogonal frequency division multiplexing (OFDM) for radar processing\nwith the proposed beamforming architecture results in highly accurate range and\nvelocity estimates for detected targets.",
                "authors": [
                    "Murat Bayraktar",
                    "Nuria Gonz\u00e1lez-Prelcic",
                    "Hao Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14942v1",
                    "http://arxiv.org/pdf/2311.14942v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.IT",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14941v1/1.0",
                "title": "Development of a Chemistry Dynamic Load Balancing Solver with Sparse\n  Analytical Jacobian Approach for Rapid and Accurate Reactive Flow Simulations",
                "year": 2023,
                "abstract": "In addressing the demands of industrial high-fidelity computation, the\npresent study introduces a rapid and accurate customized solver developed on\nthe OpenFOAM platform. To enhance computational efficiency, a novel integrated\nacceleration strategy is introduced. Initially, a sparse analytical Jacobian\napproach utilizing the SpeedCHEM chemistry library was implemented to increase\nthe efficiency of the ODE solver. Subsequently, the Dynamic Load Balancing\n(DLB) code was employed to uniformly distribute the computational workload for\nchemistry among multiple processes. Further optimization was achieved through\nthe introduction of the Open Multi-Processing (OpenMP) method to enhance\nparallel computing efficiency. Lastly, the Local Time Stepping (LTS) scheme was\nintegrated to maximize the individual time step for each computational cell,\nresulting in a noteworthy minimum speed-up of over 31 times. The effectiveness\nand robustness of this customized solver were systematically validated against\nthree distinct partially turbulent premixed flames, Sandia Flames D, E, and F.\nAdditionally, a comparative analysis was conducted, encompassing different\nturbulence models, turbulent Prandtl numbers, and model constants, resulting in\nthe recommendation of optimal numerical parameters for various conditions. The\npresent study offers one viable solution for rapid and accurate calculations in\nthe OpenFOAM platform, while also providing insights into the selection of\nturbulence models and parameters for industrial numerical simulation.",
                "authors": [
                    "Yinan Yang",
                    "Tsukasa Hori",
                    "Shinya Sawada",
                    "Fumiteru Akamatsu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14941v1",
                    "http://arxiv.org/pdf/2311.14941v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "cs.NA",
                    "math.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14935v1/1.0",
                "title": "A Novel Deep Clustering Framework for Fine-Scale Parcellation of\n  Amygdala Using dMRI Tractography",
                "year": 2023,
                "abstract": "The amygdala plays a vital role in emotional processing and exhibits\nstructural diversity that necessitates fine-scale parcellation for a\ncomprehensive understanding of its anatomico-functional correlations. Diffusion\nMRI tractography is an advanced imaging technique that can estimate the brain's\nwhite matter structural connectivity to potentially reveal the topography of\nthe amygdala for studying its subdivisions. In this work, we present a deep\nclustering pipeline to perform automated, fine-scale parcellation of the\namygdala using diffusion MRI tractography. First, we incorporate a newly\nproposed deep learning approach to enable accurate segmentation of the amygdala\ndirectly on the dMRI data. Next, we design a novel streamline clustering-based\nstructural connectivity feature for a robust representation of voxels within\nthe amygdala. Finally, we improve the popular joint dimensionality reduction\nand k-means clustering approach to enable amygdala parcellation at a finer\nscale. With the proposed method, we obtain nine unique amygdala parcels.\nExperiments show that these parcels can be consistently identified across\nsubjects and have good correspondence to the widely used coarse-scale amygdala\nparcellation.",
                "authors": [
                    "Haolin He",
                    "Ce Zhu",
                    "Le Zhang",
                    "Yipeng Liu",
                    "Xiao Xu",
                    "Yuqian Chen",
                    "Leo Zekelman",
                    "Jarrett Rushmore",
                    "Yogesh Rathi",
                    "Nikos Makris",
                    "Lauren J. O'Donnell",
                    "Fan Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14935v1",
                    "http://arxiv.org/pdf/2311.14935v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14933v1/1.0",
                "title": "ArcaDB: A Container-based Disaggregated Query Engine for Heterogenous\n  Computational Environments",
                "year": 2023,
                "abstract": "Modern enterprises rely on data management systems to collect, store, and\nanalyze vast amounts of data related with their operations. Nowadays, clusters\nand hardware accelerators (e.g., GPUs, TPUs) have become a necessity to scale\nwith the data processing demands in many applications related to social media,\nbioinformatics, surveillance systems, remote sensing, and medical informatics.\nGiven this new scenario, the architecture of data analytics engines must evolve\nto take advantage of these new technological trends. In this paper, we present\nArcaDB: a disaggregated query engine that leverages container technology to\nplace operators at compute nodes that fit their performance profile. In ArcaDB,\na query plan is dispatched to worker nodes that have different computing\ncharacteristics. Each operator is annotated with the preferred type of compute\nnode for execution, and ArcaDB ensures that the operator gets picked up by the\nappropriate workers. We have implemented a prototype version of ArcaDB using\nJava, Python, and Docker containers. We have also completed a preliminary\nperformance study of this prototype, using images and scientific data. This\nstudy shows that ArcaDB can speed up query performance by a factor of 3.5x in\ncomparison with a shared-nothing, symmetric arrangement.",
                "authors": [
                    "Kristalys Ruiz-Rohena",
                    "Manuel Rodriguez-Martinez"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14933v1",
                    "http://arxiv.org/pdf/2311.14933v1"
                ],
                "primary_category": "cs.DB",
                "categories": [
                    "cs.DB"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14926v1/1.0",
                "title": "FreePIH: Training-Free Painterly Image Harmonization with Diffusion\n  Model",
                "year": 2023,
                "abstract": "This paper provides an efficient training-free painterly image harmonization\n(PIH) method, dubbed FreePIH, that leverages only a pre-trained diffusion model\nto achieve state-of-the-art harmonization results. Unlike existing methods that\nrequire either training auxiliary networks or fine-tuning a large pre-trained\nbackbone, or both, to harmonize a foreground object with a painterly-style\nbackground image, our FreePIH tames the denoising process as a plug-in module\nfor foreground image style transfer. Specifically, we find that the very last\nfew steps of the denoising (i.e., generation) process strongly correspond to\nthe stylistic information of images, and based on this, we propose to augment\nthe latent features of both the foreground and background images with Gaussians\nfor a direct denoising-based harmonization. To guarantee the fidelity of the\nharmonized image, we make use of multi-scale features to enforce the\nconsistency of the content and stability of the foreground objects in the\nlatent space, and meanwhile, aligning both fore-/back-grounds with the same\nstyle. Moreover, to accommodate the generation with more structural and\ntextural details, we further integrate text prompts to attend to the latent\nfeatures, hence improving the generation quality. Quantitative and qualitative\nevaluations on COCO and LAION 5B datasets demonstrate that our method can\nsurpass representative baselines by large margins.",
                "authors": [
                    "Ruibin Li",
                    "Jingcai Guo",
                    "Song Guo",
                    "Qihua Zhou",
                    "Jie Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14926v1",
                    "http://arxiv.org/pdf/2311.14926v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14925v1/1.0",
                "title": "Coordinate-based Neural Network for Fourier Phase Retrieval",
                "year": 2023,
                "abstract": "Fourier phase retrieval is essential for high-definition imaging of nanoscale\nstructures across diverse fields, notably coherent diffraction imaging. This\nstudy presents the Single impliCit neurAl Network (SCAN), a tool built upon\ncoordinate neural networks meticulously designed for enhanced phase retrieval\nperformance. Bypassing the pitfalls of conventional iterative methods, which\nfrequently face high computational loads and are prone to noise interference,\nSCAN adeptly connects object coordinates to their amplitude and phase within a\nunified network in an unsupervised manner. While many existing methods\nprimarily use Fourier magnitude in their loss function, our approach\nincorporates both the predicted magnitude and phase, enhancing retrieval\naccuracy. Comprehensive tests validate SCAN's superiority over traditional and\nother deep learning models regarding accuracy and noise robustness. We also\ndemonstrate that SCAN excels in the ptychography setting.",
                "authors": [
                    "Tingyou Li",
                    "Zixin Xu",
                    "Yong S. Chu",
                    "Xiaojing Huang",
                    "Jizhou Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14925v1",
                    "http://arxiv.org/pdf/2311.14925v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16476v1/1.0",
                "title": "LANS: A Layout-Aware Neural Solver for Plane Geometry Problem",
                "year": 2023,
                "abstract": "Geometry problem solving (GPS) is a challenging mathematical reasoning task\nrequiring multi-modal understanding, fusion and reasoning. Existing neural\nsolvers take GPS as a vision-language task but be short in the representation\nof geometry diagrams which carry rich and complex layout information. In this\npaper, we propose a layout-aware neural solver named LANS, integrated with two\nnew modules: multimodal layout-aware pre-trained language model (MLA-PLM) and\nlayout-aware fusion attention (LA-FA). MLA-PLM adopts structural and semantic\npre-training (SSP) to implement global relationship modeling, and point\nmatching pre-training (PMP) to achieve alignment between visual points and\ntextual points. LA-FA employs a layout-aware attention mask to realize\npoint-guided cross-modal fusion for further boosting layout awareness of LANS.\nExtensive experiments on datasets Geometry3K and PGPS9K validate the\neffectiveness of the layout-aware modules and superior problem solving\nperformance of our LANS solver, over existing symbolic solvers and neural\nsolvers. The code will make public available soon.",
                "authors": [
                    "Ming-Liang Zhang",
                    "Zhong-Zhi Li",
                    "Fei Yin",
                    "Cheng-Lin Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16476v1",
                    "http://arxiv.org/pdf/2311.16476v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16511v1/1.0",
                "title": "GPT4Video: A Unified Multimodal Large Language Model for\n  lnstruction-Followed Understanding and Safety-Aware Generation",
                "year": 2023,
                "abstract": "While the recent advances in Multimodal Large Language Models (MLLMs)\nconstitute a significant leap forward in the field, these models are\npredominantly confined to the realm of input-side multimodal comprehension,\nlacking the capacity for multimodal content generation. To fill this gap, we\npresent GPT4Video, a unified multi-model framework that empowers Large Language\nModels (LLMs) with the capability of both video understanding and generation.\nSpecifically, we develop an instruction-following-based approach integrated\nwith the stable diffusion generative model, which has demonstrated to\neffectively and securely handle video generation scenarios. GPT4Video offers\nthe following benefits: 1) It exhibits impressive capabilities in both video\nunderstanding and generation scenarios. For example, GPT4Video outperforms\nValley by 11.8\\% on the Video Question Answering task, and surpasses NExt-GPT\nby 2.3\\% on the Text to Video generation task. 2) it endows the LLM/MLLM with\nvideo generation capabilities without requiring additional training parameters\nand can flexibly interface with a wide range of models to perform video\ngeneration. 3) it maintains a safe and healthy conversation not only in\noutput-side but also the input side in an end-to-end manner. Qualitative and\nqualitative experiments demonstrate that GPT4Video holds the potential to\nfunction as a effective, safe and Humanoid-like video assistant that can handle\nboth video understanding and generation scenarios.",
                "authors": [
                    "Zhanyu Wang",
                    "Longyue Wang",
                    "Zhen Zhao",
                    "Minghao Wu",
                    "Chenyang Lyu",
                    "Huayang Li",
                    "Deng Cai",
                    "Luping Zhou",
                    "Shuming Shi",
                    "Zhaopeng Tu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16511v1",
                    "http://arxiv.org/pdf/2311.16511v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14922v1/1.0",
                "title": "GBD-TS: Goal-based Pedestrian Trajectory Prediction with Diffusion using\n  Tree Sampling Algorithm",
                "year": 2023,
                "abstract": "Predicting pedestrian trajectories is crucial for improving the safety and\neffectiveness of autonomous driving and mobile robots. However, this task is\nnontrivial due to the inherent stochasticity of human motion, which naturally\nrequires the predictor to generate multi-model prediction. Previous works have\nused various generative methods, such as GAN and VAE, for pedestrian trajectory\nprediction. Nevertheless, these methods may suffer from problems, including\nmode collapse and relatively low-quality results. The denoising diffusion\nprobabilistic model (DDPM) has recently been applied to trajectory prediction\ndue to its simple training process and powerful reconstruction ability.\nHowever, current diffusion-based methods are straightforward without fully\nleveraging input information and usually require many denoising iterations\nleading to a long inference time or an additional network for initialization.\nTo address these challenges and promote the application of diffusion models in\ntrajectory prediction, we propose a novel scene-aware multi-modal pedestrian\ntrajectory prediction framework called GBD. GBD combines goal prediction with\nthe diffusion network. First, the goal predictor produces multiple goals, and\nthen the diffusion network generates multi-modal trajectories conditioned on\nthese goals. Furthermore, we introduce a new diffusion sampling algorithm named\ntree sampling (TS), which leverages common feature to reduce the inference time\nand improve accuracy for multi-modal prediction. Experimental results\ndemonstrate that our GBD-TS method achieves state-of-the-art performance with\nreal-time inference speed.",
                "authors": [
                    "Ge Sun",
                    "Sheng Wang",
                    "Yang Xiao",
                    "Lei Zhu",
                    "Ming Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14922v1",
                    "http://arxiv.org/pdf/2311.14922v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14920v1/1.0",
                "title": "DECap: Towards Generalized Explicit Caption Editing via Diffusion\n  Mechanism",
                "year": 2023,
                "abstract": "Explicit Caption Editing (ECE) -- refining reference image captions through a\nsequence of explicit edit operations (e.g., KEEP, DETELE) -- has raised\nsignificant attention due to its explainable and human-like nature. After\ntraining with carefully designed reference and ground-truth caption pairs,\nstate-of-the-art ECE models exhibit limited generalization ability beyond the\noriginal training data distribution, i.e., they are tailored to refine content\ndetails only in in-domain samples but fail to correct errors in out-of-domain\nsamples. To this end, we propose a new Diffusion-based Explicit Caption editing\nmethod: DECap. Specifically, we reformulate the ECE task as a denoising process\nunder the diffusion mechanism, and introduce innovative edit-based noising and\ndenoising processes. Thanks to this design, the noising process can help to\neliminate the need for meticulous paired data selection by directly introducing\nword-level noises for training, learning diverse distribution over input\nreference caption. The denoising process involves the explicit predictions of\nedit operations and corresponding content words, refining reference captions\nthrough iterative step-wise editing. To further efficiently implement our\ndiffusion process and improve the inference speed, DECap discards the prevalent\nmulti-stage design and directly generates edit operations and content words\nsimultaneously. Extensive ablations have demonstrated the strong generalization\nability of DECap in various scenarios. More interestingly, it even shows great\npotential in improving the quality and controllability of caption generation.",
                "authors": [
                    "Zhen Wang",
                    "Jun Xiao",
                    "Tao Chen",
                    "Long Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14920v1",
                    "http://arxiv.org/pdf/2311.14920v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14919v1/1.0",
                "title": "Faster Minimum Bayes Risk Decoding with Confidence-based Pruning",
                "year": 2023,
                "abstract": "Minimum Bayes risk (MBR) decoding outputs the hypothesis with the highest\nexpected utility over the model distribution for some utility function. It has\nbeen shown to improve accuracy over beam search in conditional language\ngeneration problems and especially neural machine translation, in both human\nand automatic evaluations. However, the standard sampling-based algorithm for\nMBR is substantially more computationally expensive than beam search, requiring\na large number of samples as well as a quadratic number of calls to the utility\nfunction, limiting its applicability. We describe an algorithm for MBR which\ngradually grows the number of samples used to estimate the utility while\npruning hypotheses that are unlikely to have the highest utility according to\nconfidence estimates obtained with bootstrap sampling. Our method requires\nfewer samples and drastically reduces the number of calls to the utility\nfunction compared to standard MBR while being statistically indistinguishable\nin terms of accuracy. We demonstrate the effectiveness of our approach in\nexperiments on three language pairs, using chrF++ and COMET as\nutility/evaluation metrics.",
                "authors": [
                    "Julius Cheng",
                    "Andreas Vlachos"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14919v1",
                    "http://arxiv.org/pdf/2311.14919v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14918v1/1.0",
                "title": "Resolution- and Stimulus-agnostic Super-Resolution of Ultra-High-Field\n  Functional MRI: Application to Visual Studies",
                "year": 2023,
                "abstract": "High-resolution fMRI provides a window into the brain's mesoscale\norganization. Yet, higher spatial resolution increases scan times, to\ncompensate for the low signal and contrast-to-noise ratio. This work introduces\na deep learning-based 3D super-resolution (SR) method for fMRI. By\nincorporating a resolution-agnostic image augmentation framework, our method\nadapts to varying voxel sizes without retraining. We apply this innovative\ntechnique to localize fine-scale motion-selective sites in the early visual\nareas. Detection of these sites typically requires a resolution higher than 1\nmm isotropic, whereas here, we visualize them based on lower resolution (2-3mm\nisotropic) fMRI data. Remarkably, the super-resolved fMRI is able to recover\nhigh-frequency detail of the interdigitated organization of these sites\n(relative to the color-selective sites), even with training data sourced from\ndifferent subjects and experimental paradigms -- including non-visual\nresting-state fMRI, underscoring its robustness and versatility. Quantitative\nand qualitative results indicate that our method has the potential to enhance\nthe spatial resolution of fMRI, leading to a drastic reduction in acquisition\ntime.",
                "authors": [
                    "Hongwei Bran Li",
                    "Matthew S. Rosen",
                    "Shahin Nasr",
                    "Juan Eugenio Iglesias"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14918v1",
                    "http://arxiv.org/pdf/2311.14918v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14917v1/1.0",
                "title": "Consolidate Viability and Information Theories for Task-Oriented\n  Communications: A Homeostasis Solution",
                "year": 2023,
                "abstract": "The next generation of cellular networks, 6G, is expected to offer a range of\nexciting applications and services, including holographic communication,\nmachine-to-machine communication, and data sensing from millions of devices.\nThere is an incremental exhaustion of the spectral resources. It is crucial to\nefficiently manage these resources through value-driven approaches that\neliminate waste and continually enhance the communication process. These\nmanagement principles align with the Task-Oriented Communications (TOC)\nphilosophy. The aim is to allocate the minimum necessary communication resource\naccording to the receiver's objective and continuously improve the\ncommunication process. However, it is currently unclear how to build knowledge\nof the receiver's goal and operate accordingly for efficient-resource\nutilization. Our management approach combines viability theory and transfer\nentropy to ensure that the actor remains within a viable space as per their\ngoal and to gradually reduce the information exchange through knowledge\naccumulation. We discuss these theories in the context of TOC and examine their\napplication in the plant process control case. Finally, we provide insights\ninto future research directions from computational, performance, and protocol\nperspectives.",
                "authors": [
                    "Ozgur Ercetin",
                    "Mohaned Chraiti",
                    "Rustu Erciyes Karakaya"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14917v1",
                    "http://arxiv.org/pdf/2311.14917v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "cs.SY",
                    "eess.SY",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14916v2/1.0",
                "title": "An Efficient Game-Theoretic Planner for Automated Lane Merging with\n  Multi-Modal Behavior Understanding",
                "year": 2023,
                "abstract": "In this paper, we propose a novel behavior planner that combines game theory\nwith search-based planning for automated lane merging. Specifically, inspired\nby human drivers, we model the interaction between vehicles as a gap selection\nprocess. To overcome the challenge of multi-modal behavior exhibited by the\nsurrounding vehicles, we formulate the trajectory selection as a matrix game\nand compute an equilibrium. Next, we validate our proposed planner in the\nhigh-fidelity simulator CARLA and demonstrate its effectiveness in handling\ninteractions in dense traffic scenarios.",
                "authors": [
                    "Luyao Zhang",
                    "Shaohang Han",
                    "Sergio Grammatico"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14916v2",
                    "http://arxiv.org/pdf/2311.14916v2"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.RO",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14914v1/1.0",
                "title": "A Replica-BCS theory for dirty superconductors",
                "year": 2023,
                "abstract": "Motivated by the discovery of the anomalous metal state in superconductor\nthin films, we revisit in this paper the problem of dirty superconductors using\na replica-symmetric BCS (RS-BCS) theory for dirty metals with net attractive\ninteractions. Within the RS-BCS mean field theory, we show that the (dirty)\nsuperconductor transits to a Cooper-pair-glass state beyond a critical strength\nof disorder. The single particle tunneling density of states and the superfluid\ndensity are computed within the RS-BCS theory for different strengths of\ndisorder. We find that the single-particle spectral gap is strongly enhanced by\ndisorder and the superfluid density reduces rapidly from the corresponding\nclean superconducting limit with increasing strength of disorder but remains\nfinite in the Cooper-pair-glass state. The nature of the Cooper-pair-glass\nstate and relevance of our result to the anomalous metal state are briefly\ndiscussed.",
                "authors": [
                    "Yat Fan Lau",
                    "Tai Kai Ng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14914v1",
                    "http://arxiv.org/pdf/2311.14914v1"
                ],
                "primary_category": "cond-mat.supr-con",
                "categories": [
                    "cond-mat.supr-con",
                    "cond-mat.dis-nn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14913v1/1.0",
                "title": "Tensor Unfolding Characterization",
                "year": 2023,
                "abstract": "Tensors play a pivotal role in the realms of science and engineering,\nparticularly in the realms of data analysis, machine learning, and\ncomputational mathematics. The process of unfolding a tensor into matrices,\ncommonly known as tensor unfolding or matricization, serves as a valuable\ntechnique for simplifying the representation of tensors with higher orders. In\nthis study, we initially derive unfolded matrices from a specified tensor over\na B{'e}zout ring using a matrix equivalence relation. We proceed to elucidate\nthe relationships between eigenvalues and eigenvectors within these unfolded\nmatrices. Additionally, we employ the localization approach outlined by\nGerstein to ascertain the count of distinct matrix equivalence classes present\namong the unfolded matrices.",
                "authors": [
                    "Shih-Yu Chang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14913v1",
                    "http://arxiv.org/pdf/2311.14913v1"
                ],
                "primary_category": "math.RA",
                "categories": [
                    "math.RA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14912v1/1.0",
                "title": "Electroweak corrections to Higgs boson production via Z Z fusion at the\n  future LHeC",
                "year": 2023,
                "abstract": "An important mechanism for production of the Higgs boson at the prospective\nLarge Hadron-electron Collider (LHeC) is via neutral current (NC) weak boson\nfusion (WBF) processes. Aside from its role in measurements of Higgs couplings\nwithin the standard model, this production mode is particularly useful in\nsearchings of Higgs decays into invisble particles in various models for the\nHigg portal dark matter. In this work we compute the electroweak corrections\nfor the NC WBF at the LHeC up to the 1-loop level. For a center-of-mass energy\nof 1.98 TeV, the magnitudes of the relative corrections for the total cross\nsection at next-to-leading (NLO) order are respectively 8% and 17%, in the two\nrenormalization schemes we use. The NLO terms also distort various\ndistributions (notably, those for Higgs and electron observables) computed at\nthe leading order. Along with our previous treatment of the charge current\nprocesses, this paper completes the calulation of the NLO EW effects for the\ndominant Higgs production modes at the LHeC.",
                "authors": [
                    "Hanying Xiong",
                    "Hongsheng Hou",
                    "Zhuoni Qian",
                    "Qingjun Xu",
                    "Bowen Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14912v1",
                    "http://arxiv.org/pdf/2311.14912v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16181v1/1.0",
                "title": "mvlearnR and Shiny App for multiview learning",
                "year": 2023,
                "abstract": "The package mvlearnR and accompanying Shiny App is intended for integrating\ndata from multiple sources or views or modalities (e.g. genomics, proteomics,\nclinical and demographic data). Most existing software packages for multiview\nlearning are decentralized and offer limited capabilities, making it difficult\nfor users to perform comprehensive integrative analysis. The new package wraps\nstatistical and machine learning methods and graphical tools, providing a\nconvenient and easy data integration workflow. For users with limited\nprogramming language, we provide a Shiny Application to facilitate data\nintegration anywhere and on any device. The methods have potential to offer\ndeeper insights into complex disease mechanisms.\n  Availability and Implementation: mvlearnR is available from the following\nGitHub repository: https://github.com/lasandrall/mvlearnR. The web application\nis hosted on shinyapps.io and available at:\nhttps://multi-viewlearn.shinyapps.io/MultiView_Modeling/",
                "authors": [
                    "Elise F. Palzer",
                    "Sandra E. Safo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16181v1",
                    "http://arxiv.org/pdf/2311.16181v1"
                ],
                "primary_category": "q-bio.GN",
                "categories": [
                    "q-bio.GN",
                    "cs.LG",
                    "stat.AP",
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14909v1/1.0",
                "title": "Continual Referring Expression Comprehension via Dual Modular\n  Memorization",
                "year": 2023,
                "abstract": "Referring Expression Comprehension (REC) aims to localize an image region of\na given object described by a natural-language expression. While promising\nperformance has been demonstrated, existing REC algorithms make a strong\nassumption that training data feeding into a model are given upfront, which\ndegrades its practicality for real-world scenarios. In this paper, we propose\nContinual Referring Expression Comprehension (CREC), a new setting for REC,\nwhere a model is learning on a stream of incoming tasks. In order to\ncontinuously improve the model on sequential tasks without forgetting prior\nlearned knowledge and without repeatedly re-training from a scratch, we propose\nan effective baseline method named Dual Modular Memorization (DMM), which\nalleviates the problem of catastrophic forgetting by two memorization modules:\nImplicit-Memory and Explicit-Memory. Specifically, the former module aims to\nconstrain drastic changes to important parameters learned on old tasks when\nlearning a new task; while the latter module maintains a buffer pool to\ndynamically select and store representative samples of each seen task for\nfuture rehearsal. We create three benchmarks for the new CREC setting, by\nrespectively re-splitting three widely-used REC datasets RefCOCO, RefCOCO+ and\nRefCOCOg into sequential tasks. Extensive experiments on the constructed\nbenchmarks demonstrate that our DMM method significantly outperforms other\nalternatives, based on two popular REC backbones. We make the source code and\nbenchmarks publicly available to foster future progress in this field:\nhttps://github.com/zackschen/DMM.",
                "authors": [
                    "Heng Tao Shen",
                    "Cheng Chen",
                    "Peng Wang",
                    "Lianli Gao",
                    "Meng Wang",
                    "Jingkuan Song"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/TIP.2022.3212317",
                    "http://arxiv.org/abs/2311.14909v1",
                    "http://arxiv.org/pdf/2311.14909v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14908v1/1.0",
                "title": "Support Vector Machine Implementation on MPI-CUDA and Tensorflow\n  Framework",
                "year": 2023,
                "abstract": "Support Vector Machine (SVM) algorithm requires a high computational cost\n(both in memory and time) to solve a complex quadratic programming (QP)\noptimization problem during the training process. Consequently, SVM\nnecessitates high computing hardware capabilities. The central processing unit\n(CPU) clock frequency cannot be increased due to physical limitations in the\nminiaturization process. However, the potential of parallel multi-architecture,\navailable in both multi-core CPUs and highly scalable GPUs, emerges as a\npromising solution to enhance algorithm performance. Therefore, there is an\nopportunity to reduce the high computational time required by SVM for solving\nthe QP optimization problem. This paper presents a comparative study that\nimplements the SVM algorithm on different parallel architecture frameworks. The\nexperimental results show that SVM MPI-CUDA implementation achieves a speedup\nover SVM TensorFlow implementation on different datasets. Moreover, SVM\nTensorFlow implementation provides a cross-platform solution that can be\nmigrated to alternative hardware components, which will reduces the development\ntime.",
                "authors": [
                    "Islam Elgarhy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14908v1",
                    "http://arxiv.org/pdf/2311.14908v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14907v1/1.0",
                "title": "Transitioning to Tomorrow: The Global Journey Towards a Sustainable\n  Energy Economy",
                "year": 2023,
                "abstract": "The spotlight is on the intertwined nature of sustainability and energy\ntransition. As the world grapples with environmental challenges, the push for a\ngreen approach to energy is more crucial than ever. This transition promises\nnot just a cleaner planet but also better public health and job opportunities.\nThere is a call for united front from policymakers, businesses, and communities\nto fast-track this eco-friendly shift.",
                "authors": [
                    "Rajini K R Karduri"
                ],
                "url": [
                    "http://dx.doi.org/10.13140/RG.2.2.14081.63841",
                    "http://arxiv.org/abs/2311.14907v1",
                    "http://arxiv.org/pdf/2311.14907v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14906v1/1.0",
                "title": "AutoEval-Video: An Automatic Benchmark for Assessing Large Vision\n  Language Models in Open-Ended Video Question Answering",
                "year": 2023,
                "abstract": "We propose a novel and challenging benchmark, AutoEval-Video, to\ncomprehensively evaluate large vision-language models in open-ended video\nquestion answering. The comprehensiveness of AutoEval-Video is demonstrated in\ntwo aspects: 1) AutoEval-Video constructs open-ended video-questions across 9\nskill dimensions, addressing capabilities of perception, comprehension, and\ngeneration. 2) AutoEval-Video contains newly collected videos that cover over\n40 distinct themes. To efficiently evaluate responses to the open-ended\nquestions, we employ an LLM-based evaluation approach, but instead of merely\nproviding a reference answer, we annotate unique evaluation rules for every\nsingle instance (video-question pair). To maximize the robustness of these\nrules, we develop a novel adversarial annotation mechanism. By using\ninstance-specific rules as prompt, GPT-4, as an automatic evaluator, can\nachieve a stable evaluation accuracy of around 97.0\\%, comparable to the 94.9\\%\n- 97.5\\% accuracy of a human evaluator. Furthermore, we assess the performance\nof eight large vision-language models on AutoEval-Video. Among them,\nGPT-4V(ision) significantly outperforms other models, achieving an accuracy of\n32.2\\%. However, there is still substantial room for improvement compared to\nhuman accuracy of 72.8\\%. By conducting an extensive case study, we uncover\nseveral drawbacks of GPT-4V, such as limited temporal and dynamic\ncomprehension, and overly general responses. Code is available at\n\\href{https://github.com/Xiuyuan-Chen/AutoEval-Video}{\\color{magenta}https://github.com/Xiuyuan-Chen/AutoEval-Video}.",
                "authors": [
                    "Xiuyuan Chen",
                    "Yuan Lin",
                    "Yuchen Zhang",
                    "Weiran Huang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14906v1",
                    "http://arxiv.org/pdf/2311.14906v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14904v1/1.0",
                "title": "LLM-Assisted Code Cleaning For Training Accurate Code Generators",
                "year": 2023,
                "abstract": "Natural language to code generation is an important application area of LLMs\nand has received wide attention from the community. The majority of relevant\nstudies have exclusively concentrated on increasing the quantity and functional\ncorrectness of training sets while disregarding other stylistic elements of\nprograms. More recently, data quality has garnered a lot of interest and\nmultiple works have showcased its importance for improving performance. In this\nwork, we investigate data quality for code and find that making the code more\nstructured and readable leads to improved code generation performance of the\nsystem. We build a novel data-cleaning pipeline that uses these principles to\ntransform existing programs by 1.) renaming variables, 2.) modularizing and\ndecomposing complex code into smaller helper sub-functions, and 3.) inserting\nnatural-language based plans via LLM based transformations. We evaluate our\napproach on two challenging algorithmic code generation benchmarks and find\nthat fine-tuning CodeLLaMa-7B on our transformed modularized programs improves\nthe performance by up to 30% compared to fine-tuning on the original dataset.\nAdditionally, we demonstrate improved performance from using a smaller amount\nof higher-quality data, finding that a model fine-tuned on the entire original\ndataset is outperformed by a model trained on 15% of our cleaned dataset. Even\nin comparison to closed-source models, our models outperform the much larger\nAlphaCoder models.",
                "authors": [
                    "Naman Jain",
                    "Tianjun Zhang",
                    "Wei-Lin Chiang",
                    "Joseph E. Gonzalez",
                    "Koushik Sen",
                    "Ion Stoica"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14904v1",
                    "http://arxiv.org/pdf/2311.14904v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14903v1/1.0",
                "title": "Code Generation Based Grading: Evaluating an Auto-grading Mechanism for\n  \"Explain-in-Plain-English\" Questions",
                "year": 2023,
                "abstract": "Comprehending and elucidating the purpose of code is often cited as being a\nkey learning objective within introductory programming courses. To address this\nobjective ``Explain-in-Plain-English'' questions, in which students are shown a\nsegment of code and asked to provide an abstract description of the code's\npurpose, have been adopted. However, given EiPE questions require a natural\nlanguage response, they often require manual grading which is time-consuming\nfor course staff and delays feedback for students. With the advent of large\nlanguage models (LLMs) capable of generating code, responses to EiPE questions\ncan be used to generate code segments, the correctness of which can then be\neasily verified using test cases. We refer to this approach as \"Code Generation\nBased Grading\" (CGBG) and in this paper we explore its agreement with human\ngraders using EiPE responses from past exams in an introductory programming\ncourse taught in Python. Overall, we find that CGBG achieves moderate agreement\nwith human graders with the primary area of disagreement being its leniency\nwith respect to low-level and line-by-line descriptions of code.",
                "authors": [
                    "David H. Smith IV",
                    "Craig Zilles"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14903v1",
                    "http://arxiv.org/pdf/2311.14903v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14901v1/1.0",
                "title": "Code Search Debiasing:Improve Search Results beyond Overall Ranking\n  Performance",
                "year": 2023,
                "abstract": "Code search engine is an essential tool in software development. Many code\nsearch methods have sprung up, focusing on the overall ranking performance of\ncode search. In this paper, we study code search from another perspective by\nanalyzing the bias of code search models. Biased code search engines provide\npoor user experience, even though they show promising overall performance. Due\nto different development conventions (e.g., prefer long queries or\nabbreviations), some programmers will find the engine useful, while others may\nfind it hard to get desirable search results. To mitigate biases, we develop a\ngeneral debiasing framework that employs reranking to calibrate search results.\nIt can be easily plugged into existing engines and handle new code search\nbiases discovered in the future. Experiments show that our framework can\neffectively reduce biases. Meanwhile, the overall ranking performance of code\nsearch gets improved after debiasing.",
                "authors": [
                    "Sheng Zhang",
                    "Hui Li",
                    "Yanlin Wang",
                    "Zhao Wei",
                    "Yong Xiu",
                    "Juhong Wang",
                    "Rongong Ji"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14901v1",
                    "http://arxiv.org/pdf/2311.14901v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14900v1/1.0",
                "title": "Resfusion: Prior Residual Noise embedded Denoising Diffusion\n  Probabilistic Models",
                "year": 2023,
                "abstract": "Recently, Denoising Diffusion Probabilistic Models have been widely used in\nimage segmentation, by generating segmentation masks conditioned on the input\nimage. However, previous works can not seamlessly integrate existing end-to-end\nmodels with denoising diffusion models. Existing research can only select\nacceleration steps based on experience rather than calculating them\nspecifically. Moreover, most methods are limited to small models and\nsmall-scale datasets, unable to generalize to general datasets and a wider\nrange of tasks. Therefore, we propose Resfusion with a novel resnoise-diffusion\nprocess, which gradually generates segmentation masks or any type of target\nimage, seamlessly integrating state-of-the-art end-to-end models and denoising\ndiffusion models. Resfusion bridges the discrepancy between the likelihood\noutput and the ground truth output through a Markov process. Through the novel\nsmooth equivalence transformation in resnoise-diffusion process, we determine\nthe optimal acceleration step. Experimental results demonstrate that Resfusion\ncombines the capabilities of existing end-to-end models and denoising diffusion\nmodels, further enhancing performance and achieving outstanding results.\nMoreover, Resfusion is not limited to segmentation tasks, it can easily\ngeneralize to any general tasks of image generation and exhibit strong\ncompetitiveness.",
                "authors": [
                    "Shi Zhenning",
                    "Dong Changsheng",
                    "Pan Bin",
                    "Xie Xueshuo",
                    "He Along",
                    "Qu Qiaoying",
                    "Li Tao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14900v1",
                    "http://arxiv.org/pdf/2311.14900v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16180v1/1.0",
                "title": "Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing\n  Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence",
                "year": 2023,
                "abstract": "Approximately 30% of all traffic fatalities in the United States are\nattributed to alcohol-impaired driving. This means that, despite stringent laws\nagainst this offense in every state, the frequency of drunk driving accidents\nis alarming, resulting in approximately one person being killed every 45\nminutes. The process of charging individuals with Driving Under the Influence\n(DUI) is intricate and can sometimes be subjective, involving multiple stages\nsuch as observing the vehicle in motion, interacting with the driver, and\nconducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed\nthrough racial profiling, leading to some groups and geographical areas facing\nfewer DUI tests, resulting in many actual DUI incidents going undetected,\nultimately leading to a higher number of fatalities. To tackle this issue, our\nresearch introduces an Artificial Intelligence-based predictor that is both\nfairness-aware and incorporates domain knowledge to analyze DUI-related\nfatalities in different geographic locations. Through this model, we gain\nintriguing insights into the interplay between various demographic groups,\nincluding age, race, and income. By utilizing the provided information to\nallocate policing resources in a more equitable and efficient manner, there is\npotential to reduce DUI-related fatalities and have a significant impact on\nroad safety.",
                "authors": [
                    "Tejas Venkateswaran",
                    "Sheikh Rabiul Islam",
                    "Md Golam Moula Mehedi Hasan",
                    "Mohiuddin Ahmed"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16180v1",
                    "http://arxiv.org/pdf/2311.16180v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14898v1/1.0",
                "title": "HongTu: Scalable Full-Graph GNN Training on Multiple GPUs (via\n  communication-optimized CPU data offloading)",
                "year": 2023,
                "abstract": "Full-graph training on graph neural networks (GNN) has emerged as a promising\ntraining method for its effectiveness. Full-graph training requires extensive\nmemory and computation resources. To accelerate this training process,\nresearchers have proposed employing multi-GPU processing. However the\nscalability of existing frameworks is limited as they necessitate maintaining\nthe training data for every layer in GPU memory. To efficiently train on large\ngraphs, we present HongTu, a scalable full-graph GNN training system running on\nGPU-accelerated platforms. HongTu stores vertex data in CPU memory and offloads\ntraining to GPUs. HongTu employs a memory-efficient full-graph training\nframework that reduces runtime memory consumption by using partition-based\ntraining and recomputation-caching-hybrid intermediate data management. To\naddress the issue of increased host-GPU communication caused by duplicated\nneighbor access among partitions, HongTu employs a deduplicated communication\nframework that converts the redundant host-GPU communication to efficient\ninter/intra-GPU data access. Further, HongTu uses a cost model-guided graph\nreorganization method to minimize communication overhead. Experimental results\non a 4XA100 GPU server show that HongTu effectively supports billion-scale\nfull-graph GNN training while reducing host-GPU data communication by 25%-71%.\nCompared to the full-graph GNN system DistGNN running on 16 CPU nodes, HongTu\nachieves speedups ranging from 7.8X to 20.2X. For small graphs where the\ntraining data fits into the GPUs, HongTu achieves performance comparable to\nexisting GPU-based GNN systems.",
                "authors": [
                    "Qiange Wang",
                    "Yao Chen",
                    "Weng-Fai Wong",
                    "Bingsheng He"
                ],
                "url": [
                    "http://dx.doi.org/10.1145/3626733",
                    "http://arxiv.org/abs/2311.14898v1",
                    "http://arxiv.org/pdf/2311.14898v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14896v1/1.0",
                "title": "Suppressing Coherent Synchrotron Radiation Effects in Chicane Bunch\n  Compressors",
                "year": 2023,
                "abstract": "The most significant advances in the accelerator-based light sources (i.e.,\nx-ray free electron lasers) are driven by the development of bunch compression\nand high-brightness sources in the last several decades. For bunch compression,\nthe symmetric four-dipole $C$-chicane is typically exploited since it is\nsimple, effective, and naturally dispersion-free at all orders. However, the\nemission of the coherent synchrotron radiation (CSR), becomes a main\ncontributing factor to transverse emittance degradation during bunch\ncompression. Suppressing CSR effect is necessary otherwise the anticipative\ncompression schemes are susceptible to beam quality degradation. To alleviate\nthis difficulty, this paper reports a CSR-cancelled theoretical design for\nasymmetric $C$- and $S$-chicanes. The CSR cancelation conditions of the two\nchicanes are derived with the aid of the point-kick model. A rigorous analysis\nis provided to verify the proposed CSR cancelation conditions for asymmetric\n$C$- and $S$-chicanes, performed by the integration method and ELEGANT\nsimulations. Compared to the symmetric $C$- and $S$-chicanes with identical\nbunch compression targets, the CSR-induced emittance growth of the asymmetric\nones can be reduced by two orders of magnitude and at the order of 0.1\\%. The\ndemonstration of this novel discovery opens the door for the chicane bunch\ncompressors to meet the ever-increasing demands of future accelerator\napplications, particularly important in the field of x-ray free electron\nlasers.",
                "authors": [
                    "Fancong Zeng",
                    "Yi Jiao",
                    "Weihang Liu",
                    "Cheng-Ying Tsai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14896v1",
                    "http://arxiv.org/pdf/2311.14896v1"
                ],
                "primary_category": "physics.acc-ph",
                "categories": [
                    "physics.acc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14895v1/1.0",
                "title": "Data-Driven Nonlinear State Observation using Video Measurements",
                "year": 2023,
                "abstract": "State observation is necessary for feedback control but often challenging for\nnonlinear systems. While Kazantzis-Kravaris/Luenberger (KKL) observer gives a\ngeneric design, its model-based numerical solution is difficult. In this paper,\nwe propose a simple method to determine a data-driven KKL observer, namely to\n(i) transform the measured output signals by a linear time-invariant dynamics,\nand (ii) reduce the dimensionality to principal components. This approach is\nespecially suitable for systems with rich measurements and low-dimensional\nstate space, for example, when videos can be obtained in real time. We present\nan application to a video of the well-known Belousov-Zhabotinsky (B-Z) reaction\nsystem with severe nonlinearity, where the data-driven KKL observer recovers an\noscillatory state orbit with slow damping.",
                "authors": [
                    "Cormak Weeks",
                    "Wentao Tang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14895v1",
                    "http://arxiv.org/pdf/2311.14895v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14890v1/1.0",
                "title": "Segment-Based Wall Treatment Model for Heat Transfer Rate in Smoothed\n  Particle Hydrodynamics",
                "year": 2023,
                "abstract": "In this study, a smoothed particle hydrodynamics (SPH) model that applies a\nsegment-based boundary treatment is used to simulate natural convection. In a\nnatural convection simulated using an SPH model, the wall boundary treatment is\na major issue because accurate heat transfer from boundaries should be\ncalculated. The boundary particle method, which models the boundary by placing\nmultiple layers of particles on and behind the wall boundary, is the most\nwidely used boundary treatment method. Although this method can impose accurate\nboundary conditions, boundary modeling for complex shapes is challenging and\nrequires excessive computational costs depending on the boundary shape. In this\nstudy, we utilize a segment-based boundary treatment method to model the wall\nboundary and apply this method to the energy conservation equation for the wall\nheat transfer model. The proposed method solves the problems arising from the\nuse of boundary particles and simultaneously provides accurate heat transfer\ncalculation results for the wall. In various numerical examples, the proposed\nmethod is verified through a comparison with available experimental results,\nSPH results using the boundary particle method, and finite volume method (FVM)\nresults.",
                "authors": [
                    "Hyung-Jun Park",
                    "Jaekwang Kim",
                    "Hyojin Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14890v1",
                    "http://arxiv.org/pdf/2311.14890v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "cs.NA",
                    "math.NA",
                    "physics.comp-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14877v1/1.0",
                "title": "Triadic percolation induces dynamical topological patterns in\n  higher-order networks",
                "year": 2023,
                "abstract": "Triadic interactions are higher-order interactions that occur when a set of\nnodes affects the interaction between two other nodes. Examples of triadic\ninteractions are present in the brain when glia modulate the synaptic signals\namong neuron pairs or when interneuron axon-axonic synapses enable presynaptic\ninhibition and facilitation, and in ecosystems when one or more species can\naffect the interaction among two other species. On random graphs, triadic\npercolation has been recently shown to turn percolation into a fully-fledged\ndynamical process in which the size of the giant component undergoes a route to\nchaos. However, in many real cases, triadic interactions are local and occur on\nspatially embedded networks. Here we show that triadic interactions in spatial\nnetworks induce a very complex spatio-temporal modulation of the giant\ncomponent which gives rise to triadic percolation patterns with significantly\ndifferent topology. We classify the observed patterns (stripes, octopus, and\nsmall clusters) with topological data analysis and we assess their information\ncontent (entropy and complexity). Moreover, we illustrate the multistability of\nthe dynamics of the triadic percolation patterns and we provide a comprehensive\nphase diagram of the model. These results open new perspectives in percolation\nas they demonstrate that in presence of spatial triadic interactions, the giant\ncomponent can acquire a time-varying topology. Hence, this work provides a\ntheoretical framework that can be applied to model realistic scenarios in which\nthe giant component is time-dependent as in neuroscience.",
                "authors": [
                    "Ana P. Mill\u00e1n",
                    "Hanlin Sun",
                    "Joaqu\u00ecn J. Torres",
                    "Ginestra Bianconi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14877v1",
                    "http://arxiv.org/pdf/2311.14877v1"
                ],
                "primary_category": "nlin.AO",
                "categories": [
                    "nlin.AO",
                    "cond-mat.dis-nn",
                    "cond-mat.stat-mech",
                    "nlin.CD",
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14876v1/1.0",
                "title": "Exploiting Large Language Models (LLMs) through Deception Techniques and\n  Persuasion Principles",
                "year": 2023,
                "abstract": "With the recent advent of Large Language Models (LLMs), such as ChatGPT from\nOpenAI, BARD from Google, Llama2 from Meta, and Claude from Anthropic AI, gain\nwidespread use, ensuring their security and robustness is critical. The\nwidespread use of these language models heavily relies on their reliability and\nproper usage of this fascinating technology. It is crucial to thoroughly test\nthese models to not only ensure its quality but also possible misuses of such\nmodels by potential adversaries for illegal activities such as hacking. This\npaper presents a novel study focusing on exploitation of such large language\nmodels against deceptive interactions. More specifically, the paper leverages\nwidespread and borrows well-known techniques in deception theory to investigate\nwhether these models are susceptible to deceitful interactions.\n  This research aims not only to highlight these risks but also to pave the way\nfor robust countermeasures that enhance the security and integrity of language\nmodels in the face of sophisticated social engineering tactics. Through\nsystematic experiments and analysis, we assess their performance in these\ncritical security domains. Our results demonstrate a significant finding in\nthat these large language models are susceptible to deception and social\nengineering attacks.",
                "authors": [
                    "Sonali Singh",
                    "Faranak Abri",
                    "Akbar Siami Namin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14876v1",
                    "http://arxiv.org/pdf/2311.14876v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC",
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14875v2/1.0",
                "title": "Uncertainty Aware AI for 2D MRI Segmentation",
                "year": 2023,
                "abstract": "Robust uncertainty estimations are necessary in safety-critical applications\nof Deep Learning. One such example is the semantic segmentation of medical\nimages, whilst deep-learning approaches have high performance in such tasks\nthey lack interpretability as they give no indication of their confidence when\nmaking classification decisions. Robust and interpretable segmentation is a\ncritical first stage in automatically screening for pathologies hence the\noptimal solution is one which can provide high accuracy but also capture the\nunderlying uncertainty. In this work, we present an uncertainty-aware\nsegmentation model, BA U-Net, for use on MRI data that incorporates Bayesian\nNeural Networks and Attention Mechanisms to provide accurate and interpretable\nsegmentations. We evaluated our model on the publicly available BraTS 2020\ndataset using F1 Score and Intersection Over Union (IoU) as evaluation metrics.",
                "authors": [
                    "Lohith Konathala"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14875v2",
                    "http://arxiv.org/pdf/2311.14875v2"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14872v1/1.0",
                "title": "The Power Board of the KM3NeT Digital Optical Module: design, upgrade,\n  and production",
                "year": 2023,
                "abstract": "The KM3NeT Collaboration is building an underwater neutrino observatory at\nthe bottom of the Mediterranean Sea consisting of two neutrino telescopes, both\ncomposed of a three-dimensional array of light detectors, known as digital\noptical modules. Each digital optical module contains a set of 31 three inch\nphotomultiplier tubes distributed over the surface of a 0.44 m diameter\npressure-resistant glass sphere. The module includes also calibration\ninstruments and electronics for power, readout and data acquisition. The power\nboard was developed to supply power to all the elements of the digital optical\nmodule. The design of the power board began in 2013, and several prototypes\nwere produced and tested. After an exhaustive validation process in various\nlaboratories within the KM3NeT Collaboration, a mass production batch began,\nresulting in the construction of over 1200 power boards so far. These boards\nwere integrated in the digital optical modules that have already been produced\nand deployed, 828 until October 2023. In 2017, an upgrade of the power board,\nto increase reliability and efficiency, was initiated. After the validation of\na pre-production series, a production batch of 800 upgraded boards is currently\nunderway. This paper describes the design, architecture, upgrade, validation,\nand production of the power board, including the reliability studies and tests\nconducted to ensure the safe operation at the bottom of the Mediterranean Sea\nthroughout the observatory's lifespan",
                "authors": [
                    "S. Aiello",
                    "A. Albert",
                    "S. Alves Garre",
                    "Z. Aly",
                    "A. Ambrosone",
                    "F. Ameli",
                    "M. Andre",
                    "E. Androutsou",
                    "M. Anguita",
                    "L. Aphecetche",
                    "M. Ardid",
                    "S. Ardid",
                    "H. Atmani",
                    "J. Aublin",
                    "F. Badaracco",
                    "L. Bailly-Salins",
                    "Z. Bardacova",
                    "B. Baret",
                    "A. Bariego Quintana",
                    "S. Basegmez du Pree",
                    "Y. Becherini",
                    "M. Bendahman",
                    "F. Benfenati",
                    "M. Benhassi",
                    "D. M. Benoit",
                    "E. Berbee",
                    "V. Bertin",
                    "V. van Beveren",
                    "S. Biagi",
                    "M. Boettcher",
                    "D. Bonanno",
                    "J. Boumaaza",
                    "M. Bouta",
                    "M. Bouwhuis",
                    "C. Bozza",
                    "R. M. Bozza",
                    "H. Branzas",
                    "F. Bretaudeau",
                    "R. Bruijn",
                    "J. Brunner",
                    "R. Bruno",
                    "E. Buis",
                    "R. Buompane",
                    "J. Busto",
                    "B. Caiffi",
                    "D. Calvo",
                    "S. Campion",
                    "A. Capone",
                    "F. Careniniu",
                    "V. Carretero",
                    "T. Cartraud",
                    "P. Castaldi",
                    "V. Cecchini",
                    "S. Celli",
                    "L. Cerisy",
                    "M. Chabab",
                    "M. Chadolias",
                    "C. Champion",
                    "A. Chena",
                    "S. Cherubini",
                    "T. Chiarusi",
                    "M. Circella",
                    "R. Cocimano",
                    "J. A. B. Coelho",
                    "A. Coleiro",
                    "S. Colonges",
                    "R. Coniglione",
                    "P. Coyle",
                    "A. Creusot",
                    "G. Cuttone",
                    "R. Dallier",
                    "Y. Darras",
                    "A. De Benedittis",
                    "B. De Martino",
                    "V. Decoene",
                    "R. Del Burgo",
                    "I. Del Rosso",
                    "U. M. Di Cerbo",
                    "L. S. Di Mauro",
                    "I. Di Palma",
                    "A. F. D\u00edaz",
                    "C. Diaz",
                    "D. Diego-Tortosa",
                    "C. Distefano",
                    "A. Domia",
                    "C. Donzaud",
                    "D. Dornic",
                    "M. Dorra",
                    "E. Drakopoulou",
                    "D. Drouhin",
                    "R. Dvornicky",
                    "T. Eberla",
                    "E. Eckerova",
                    "A. Eddymaoui",
                    "T. van Eeden",
                    "M. Eff",
                    "D. van Eijk",
                    "I. El Bojaddaini",
                    "S. El Hedri",
                    "A. Enzenhofer",
                    "G. Ferrara",
                    "M. D. Filipovica",
                    "F. Filippini",
                    "D. Franciotti",
                    "L. A. Fusco",
                    "O. Gabellaa",
                    "J. Gabriela",
                    "S. Gagliardini",
                    "T. Gal",
                    "J. Garc\u0131a Mendez",
                    "A. Garcia Soto",
                    "C. Gatius Oliver",
                    "N. Gei\u00dfelbrecht",
                    "H. Ghaddari",
                    "L. Gialanella",
                    "B. K. Gibson",
                    "E. Giorgio",
                    "I. Goos",
                    "P. Goswami",
                    "D. Goupilliere",
                    "S. R. Gozzini",
                    "R. Gracia",
                    "K. Grafa",
                    "C. Guidi",
                    "B. Guillon",
                    "M. Gutierrez",
                    "H. van Haren",
                    "A. Heijboer",
                    "A. Hekalo",
                    "L. Henniga",
                    "J. J. Hernandez-Rey",
                    "W. Idrissi Ibnsalih",
                    "G. Illuminati",
                    "P. Jansweijer",
                    "M. de Jonga",
                    "P. de Jonga",
                    "B. J. Jung",
                    "P. Kalaczynski",
                    "O. Kalekin",
                    "U. F. Katz",
                    "A. Khatun",
                    "G. Kistauri",
                    "C. Kopper",
                    "A. Kouchner",
                    "V. Kueviakoe",
                    "V. Kulikovskiy",
                    "R. Kvatadze",
                    "M. Labalme",
                    "R. Lahmann",
                    "G. Larosa",
                    "C. Lastoria",
                    "A. Lazo",
                    "S. Le Stum",
                    "G. Lehaut",
                    "E. Leonora",
                    "N. Lessing",
                    "G. Levi",
                    "M. Lindsey Clark",
                    "P. Litrico",
                    "F. Longhitano",
                    "J. Majumdar",
                    "L. Malerba",
                    "F. Mamedov",
                    "J. Manczak",
                    "A. Manfredae",
                    "M. Marconi",
                    "A. Margiotta",
                    "A. Marinelli",
                    "C. Markou",
                    "L. Martin",
                    "J. A. Mart\u0131nez-Mora",
                    "F. Marzaioli",
                    "M. Mastrodicasa",
                    "S. Mastroianni",
                    "S. Miccich",
                    "G. Miele",
                    "P. Migliozzi",
                    "E. Migneco",
                    "S. Minutoli",
                    "M. L. Mitsou",
                    "C. M. Mollo",
                    "L. Morales-Gallegos",
                    "M. Morga",
                    "A. Moussa",
                    "I. Mozun Mateo",
                    "R. Muller",
                    "P. Musico",
                    "M. R. Musone",
                    "M. Musumeci",
                    "S. Navas",
                    "A. Nayerhoda",
                    "C. A. Nicolau",
                    "B. Nkosi",
                    "B. O. Fearraigh",
                    "V. Oliviero",
                    "A. Orlando",
                    "E. Oukacha",
                    "D. Paesani",
                    "J. Palacios Gonzalez",
                    "G. Papalashvili",
                    "V. Parisi",
                    "E. J. Pastor Gomez",
                    "A. M. Pauna",
                    "G. E. Pavalas",
                    "G. Pellegrini",
                    "S. Pe\u00f1aa Martinez",
                    "M. Perrin-Terrin",
                    "J. Perronnel",
                    "V. Pestel",
                    "R. Pestes",
                    "P. Piattelli",
                    "C. Poirre",
                    "V. Popa",
                    "T. Pradier",
                    "J. Prado",
                    "S. Pulvirenti",
                    "G. Quemener",
                    "C. A. Quiroz-Rangel",
                    "U. Rahaman",
                    "N. Randazzo",
                    "R. Randriatoamana",
                    "S. Razzaque",
                    "I. C. Rea",
                    "D. Real",
                    "G. Riccobene",
                    "J. Robinson",
                    "A. Romanov",
                    "A. Saina",
                    "F. Salesa Greus",
                    "D. F. E. Samtleben",
                    "A. Sanchez Losa",
                    "S. Sanfilippo",
                    "M. Sanguineti",
                    "C. Santonastaso",
                    "D. Santonocito",
                    "P. Sapienza",
                    "J. Schmelling",
                    "J. Schnabel",
                    "J. Schumann",
                    "H. M. Schutt",
                    "J. Seneca",
                    "N. Sennan",
                    "B. Setter",
                    "I. Sgura",
                    "R. Shanidze",
                    "A. Sharma",
                    "Y. Shitov",
                    "F. Simkovic",
                    "A. Simonelli",
                    "A. Sinopoulou",
                    "M. V. Smirnov",
                    "B. Spisso",
                    "M. Spurio",
                    "D. Stavropoulos",
                    "I. Stekl",
                    "M. Taiuti",
                    "Y. Tayalati",
                    "H. Thiersen",
                    "I. Tosta e Melo",
                    "E. Tragi",
                    "B. Trocme",
                    "V. Tsourapis",
                    "E. Tzamariudaki",
                    "A. Vacheret",
                    "A. Valer Melchor",
                    "V. Valsecchi",
                    "V. Van Elewyck",
                    "G. Vannoye",
                    "G. Vasileiadis",
                    "F. Vazquez de Sola",
                    "C. Verilhac",
                    "A. Veutro",
                    "S. Viola",
                    "D. Vivolo",
                    "J. Wilms",
                    "E. de Wolf",
                    "H. Yepes Ramirez",
                    "G. Zarpapis",
                    "S. Zavatarelli",
                    "A. Zegarelli",
                    "D. Zito",
                    "J. D. Zornoza",
                    "J. Zuniga",
                    "N. Zywuck"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14872v1",
                    "http://arxiv.org/pdf/2311.14872v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "physics.ins-det"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14871v1/1.0",
                "title": "Tracing Influence at Scale: A Contrastive Learning Approach to Linking\n  Public Comments and Regulator Responses",
                "year": 2023,
                "abstract": "U.S. Federal Regulators receive over one million comment letters each year\nfrom businesses, interest groups, and members of the public, all advocating for\nchanges to proposed regulations. These comments are believed to have\nwide-ranging impacts on public policy. However, measuring the impact of\nspecific comments is challenging because regulators are required to respond to\ncomments but they do not have to specify which comments they are addressing. In\nthis paper, we propose a simple yet effective solution to this problem by using\nan iterative contrastive method to train a neural model aiming for matching\ntext from public comments to responses written by regulators. We demonstrate\nthat our proposal substantially outperforms a set of selected text-matching\nbaselines on a human-annotated test set. Furthermore, it delivers performance\ncomparable to the most advanced gigantic language model (i.e., GPT-4), and is\nmore cost-effective when handling comments and regulator responses matching in\nlarger scale.",
                "authors": [
                    "Linzi Xing",
                    "Brad Hackinen",
                    "Giuseppe Carenini"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14871v1",
                    "http://arxiv.org/pdf/2311.14871v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14870v1/1.0",
                "title": "Multi-scale energy homogenization for 3D printed microstructures with a\n  Diritchlet boundary condition relaxation under plastic deformation",
                "year": 2023,
                "abstract": "The present work is a proof of concept of the capabilities of paralellization\nin the calculation of metamaterials in a non-linear regime. In this work we\nsubdivided the bulk material into subregions where the mechanical properties\nare homogenized energetically. We demonstrate that the calculation can be\nsubdivided to save RAM memory and fit the local non-linear behaviour of the\nmetamaterial. This methodology has the potentiality to be implemented in the\nparallelization of those calculations, where the right estimation of the energy\nof the local processes at every step is important.",
                "authors": [
                    "Antonio Tabanera",
                    "Luis Saucedo-Mora",
                    "Miguel Angel Sanz",
                    "Francisco J. Montans"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14870v1",
                    "http://arxiv.org/pdf/2311.14870v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14865v2/1.0",
                "title": "Improving Cross-Domain Hate Speech Generalizability with Emotion\n  Knowledge",
                "year": 2023,
                "abstract": "Reliable automatic hate speech (HS) detection systems must adapt to the\nin-flow of diverse new data to curtail hate speech. However, hate speech\ndetection systems commonly lack generalizability in identifying hate speech\ndissimilar to data used in training, impeding their robustness in real-world\ndeployments. In this work, we propose a hate speech generalization framework\nthat leverages emotion knowledge in a multitask architecture to improve the\ngeneralizability of hate speech detection in a cross-domain setting. We\ninvestigate emotion corpora with varying emotion categorical scopes to\ndetermine the best corpus scope for supplying emotion knowledge to foster\ngeneralized hate speech detection. We further assess the relationship between\nusing pretrained Transformers models adapted for hate speech and its effect on\nour emotion-enriched hate speech generalization model. We perform extensive\nexperiments on six publicly available datasets sourced from different online\ndomains and show that our emotion-enriched HS detection generalization method\ndemonstrates consistent generalization improvement in cross-domain evaluation,\nincreasing generalization performance up to 18.1% and average cross-domain\nperformance up to 8.5%, according to the F1 measure.",
                "authors": [
                    "Shi Yin Hong",
                    "Susan Gauch"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14865v2",
                    "http://arxiv.org/pdf/2311.14865v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14859v1/1.0",
                "title": "An Empirical Investigation into Benchmarking Model Multiplicity for\n  Trustworthy Machine Learning: A Case Study on Image Classification",
                "year": 2023,
                "abstract": "Deep learning models have proven to be highly successful. Yet, their\nover-parameterization gives rise to model multiplicity, a phenomenon in which\nmultiple models achieve similar performance but exhibit distinct underlying\nbehaviours. This multiplicity presents a significant challenge and necessitates\nadditional specifications in model selection to prevent unexpected failures\nduring deployment. While prior studies have examined these concerns, they focus\non individual metrics in isolation, making it difficult to obtain a\ncomprehensive view of multiplicity in trustworthy machine learning. Our work\nstands out by offering a one-stop empirical benchmark of multiplicity across\nvarious dimensions of model design and its impact on a diverse set of\ntrustworthy metrics. In this work, we establish a consistent language for\nstudying model multiplicity by translating several trustworthy metrics into\naccuracy under appropriate interventions. We also develop a framework, which we\ncall multiplicity sheets, to benchmark multiplicity in various scenarios. We\ndemonstrate the advantages of our setup through a case study in image\nclassification and provide actionable insights into the impact and trends of\ndifferent hyperparameters on model multiplicity. Finally, we show that\nmultiplicity persists in deep learning models even after enforcing additional\nspecifications during model selection, highlighting the severity of\nover-parameterization. The concerns of under-specification thus remain, and we\nseek to promote a more comprehensive discussion of multiplicity in trustworthy\nmachine learning.",
                "authors": [
                    "Prakhar Ganesh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14859v1",
                    "http://arxiv.org/pdf/2311.14859v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14858v1/1.0",
                "title": "Enhanced MIMO-DCT-OFDM System Using Cosine Domain Equalizer",
                "year": 2023,
                "abstract": "Discrete Cosine Transform (DCT) can be used instead of conventional Discrete\nFourier Transform (DFT) for the Orthogonal Frequency Division Multiplexing\n(OFDM) construction, which offers many advantages. In this paper, the\nMultiple-Input-Multiple-Output (MIMO) DCT-OFDM is enhanced using a proposed\nCosine Domain Equalizer (CDE) instead of a Frequency Domain Equalizer (FDE).\nThe results are evaluated through the Rayleigh fading channel with Co-Carrier\nFrequency Offset (Co-CFO) of different MIMO configurations. The average bit\nerror probability and the simulated time of the proposed scheme and the\nconventional one is compared, which indicates the importance of the proposed\nscheme. Also, a closed formula for the number of arithmetic operations of the\nproposed equalizer is developed. The proposed equalizer gives a simulation time\nreduction of about 81.21%, 83.74% compared to that of the conventional LZF-FDE,\nand LMMSE-FDE, respectively for the case of 4x4 configuration.",
                "authors": [
                    "Khaled Ramadan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14858v1",
                    "http://arxiv.org/pdf/2311.14858v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "cs.PF",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00805v1/1.0",
                "title": "Gender inference: can chatGPT outperform common commercial tools?",
                "year": 2023,
                "abstract": "An increasing number of studies use gender information to understand\nphenomena such as gender bias, inequity in access and participation, or the\nimpact of the Covid pandemic response. Unfortunately, most datasets do not\ninclude self-reported gender information, making it necessary for researchers\nto infer gender from other information, such as names or names and country\ninformation. An important limitation of these tools is that they fail to\nappropriately capture the fact that gender exists on a non-binary scale,\nhowever, it remains important to evaluate and compare how well these tools\nperform in a variety of contexts. In this paper, we compare the performance of\na generative Artificial Intelligence (AI) tool ChatGPT with three commercially\navailable list-based and machine learning-based gender inference tools (Namsor,\nGender-API, and genderize.io) on a unique dataset. Specifically, we use a large\nOlympic athlete dataset and report how variations in the input (e.g., first\nname and first and last name, with and without country information) impact the\naccuracy of their predictions. We report results for the full set, as well as\nfor the subsets: medal versus non-medal winners, athletes from the largest\nEnglish-speaking countries, and athletes from East Asia. On these sets, we find\nthat Namsor is the best traditional commercially available tool. However,\nChatGPT performs at least as well as Namsor and often outperforms it,\nespecially for the female sample when country and/or last name information is\navailable. All tools perform better on medalists versus non-medalists and on\nnames from English-speaking countries. Although not designed for this purpose,\nChatGPT may be a cost-effective tool for gender prediction. In the future, it\nmight even be possible for ChatGPT or other large scale language models to\nbetter identify self-reported gender rather than report gender on a binary\nscale.",
                "authors": [
                    "Michelle Alexopoulos",
                    "Kelly Lyons",
                    "Kaushar Mahetaji",
                    "Marcus Emmanuel Barnes",
                    "Rogan Gutwillinger"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00805v1",
                    "http://arxiv.org/pdf/2312.00805v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14852v1/1.0",
                "title": "Self-aligned photonic defect microcavities with site-controlled quantum\n  dots",
                "year": 2023,
                "abstract": "Despite the superiority in quantum properties, self-assembled semiconductor\nquantum dots face challenges in terms of scalable device integration because of\ntheir random growth positions, originating from the Stranski-Krastanov growth\nmode. Even with existing site-controlled growth techniques, for example,\nnanohole or buried stressor concepts, a further lithography and etching step\nwith high spatial alignment requirements isnecessary to accurately integrate\nQDs into the nanophotonic devices. Here, we report on the fabrication and\ncharacterization of strain-induced site-controlled microcavities where\nsite-controlled quantum dots are positioned at the antinode of the optical mode\nfield in a self-aligned manner without the need of any further nano-processing.\nWe show that the Q-factor, mode volume, height, and the ellipticity of\nsite-controlled microcavities can be tailored by the size of an integrated\nAlAs/Al2O3 buried stressor, with an opening ranging from 1 to 4 $\\mu$m. Lasing\nsignatures, including super-linear input-output response, linewidth narrowing\nnear threshold, and gain competition above threshold, are observed for a\n3.6-$\\mu$m self-aligned cavity with a Q-factor of 18000. Furthermore, by\nwaiving the rather complex lateral nano-structuring usually performed during\nthe fabrication process of micropillar lasers and vertical-cavity surface\nemitting lasers, quasi-planar site-controlled cavities exhibit no detrimental\neffects of excitation power induced heating and thermal rollover. Our\nstraightforward deterministic nanofabrication concept of high-quality quantum\ndot microcavities integrates seamlessly with the industrial-matured\nmanufacturing process and the buried-stressor techniques, paving the way for\nexceptional scalability and straightforward manufacturing of high-\\b{eta}\nmicrolasers and bright quantum light sources.",
                "authors": [
                    "C. -W. Shih",
                    "I. Limame",
                    "C. C. Palekar",
                    "A. Koulas-Simos",
                    "A. Kaganskiy",
                    "P. Klenovsk\u00fd",
                    "S. Reitzenstein"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14852v1",
                    "http://arxiv.org/pdf/2311.14852v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14851v1/1.0",
                "title": "Unified Medical Image Pre-training in Language-Guided Common Semantic\n  Space",
                "year": 2023,
                "abstract": "Vision-Language Pre-training (VLP) has shown the merits of analysing medical\nimages, by leveraging the semantic congruence between medical images and their\ncorresponding reports. It efficiently learns visual representations, which in\nturn facilitates enhanced analysis and interpretation of intricate imaging\ndata. However, such observation is predominantly justified on single-modality\ndata (mostly 2D images like X-rays), adapting VLP to learning unified\nrepresentations for medical images in real scenario remains an open challenge.\nThis arises from medical images often encompass a variety of modalities,\nespecially modalities with different various number of dimensions (e.g., 3D\nimages like Computed Tomography). To overcome the aforementioned challenges, we\npropose an Unified Medical Image Pre-training framework, namely UniMedI, which\nutilizes diagnostic reports as common semantic space to create unified\nrepresentations for diverse modalities of medical images (especially for 2D and\n3D images). Under the text's guidance, we effectively uncover visual modality\ninformation, identifying the affected areas in 2D X-rays and slices containing\nlesion in sophisticated 3D CT scans, ultimately enhancing the consistency\nacross various medical imaging modalities. To demonstrate the effectiveness and\nversatility of UniMedI, we evaluate its performance on both 2D and 3D images\nacross 10 different datasets, covering a wide range of medical image tasks such\nas classification, segmentation, and retrieval. UniMedI has demonstrated\nsuperior performance in downstream tasks, showcasing its effectiveness in\nestablishing a universal medical visual representation.",
                "authors": [
                    "Xiaoxuan He",
                    "Yifan Yang",
                    "Xinyang Jiang",
                    "Xufang Luo",
                    "Haoji Hu",
                    "Siyun Zhao",
                    "Dongsheng Li",
                    "Yuqing Yang",
                    "Lili Qiu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14851v1",
                    "http://arxiv.org/pdf/2311.14851v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14850v2/1.0",
                "title": "TrojanedCM: A Repository of Trojaned Large Language Models of Code",
                "year": 2023,
                "abstract": "With the rapid growth of research in trojaning deep neural models of source\ncode, we observe that there is a need of developing a benchmark trojaned models\nfor testing various trojan detection and unlearning techniques. In this work,\nwe aim to provide the scientific community with diverse trojaned code models,\nthat cover a variety of state-of-the-art architectures, on which they can\nexamine such techniques. We thus present TrojanedCM, a publicly available\nrepository of clean and poisoned models of source code. We provide poisoned\nmodels for two code classification tasks (defect detection and clone detection)\nand a code generation task (text-to-code generation). We finetuned popular\npretrained code models such as CodeBERT, PLBART, CodeT5, CodeT5+, on poisoned\ndatasets that we generated from benchmark datasets (Devign, BigCloneBench,\nCONCODE) for the above mentioned tasks. The repository also provides full\naccess to the architecture and parameters of the models, allowing practitioners\nto investigate different white-box analysis techniques. In addition to the\npoisoned models, we also provide a poisoning framework using which\npractitioners can deploy various poisoning strategies for the different tasks\nand models of source code. All the material are accessible via this link:\nhttps://github.com/UH-SERG/TrojanedCM.",
                "authors": [
                    "Aftab Hussain",
                    "Md Rafiqul Islam Rabin",
                    "Mohammad Amin Alipour"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14850v2",
                    "http://arxiv.org/pdf/2311.14850v2"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14847v1/1.0",
                "title": "Experimental and numerical study of a second-order transition in the\n  behavior of confined self-propelled particles",
                "year": 2023,
                "abstract": "In this study, we conduct experimental investigations on the behavior of\nconfined self-propelled particles within a circular arena, employing small\ncommercial robots capable of locomotion, communication, and information\nprocessing. These robots execute circular trajectories, which can be clockwise\nor counterclockwise, based on two internal states. Using a majority-based\nstochastic decision algorithm, each robot can reverse its direction based on\nthe states of two neighboring robots. By manipulating a control parameter\ngoverning the interaction, the system exhibits a transition-from a state where\nall robots rotate randomly to one where they rotate uniformly in the same\ndirection. Moreover, this transition significantly impacts the trajectories of\nthe robots. To extend our findings to larger systems, we introduce a\nmathematical model enabling characterization of the order transition type and\nthe resulting trajectories. Our results reveal a second-order transition from\nactive Brownian to chiral motion. Lastly, we analyze the particle density\nwithin the arena, examining how it varies concerning system size and the\ncontrol parameter.",
                "authors": [
                    "E. Barone",
                    "G. A. Patterson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14847v1",
                    "http://arxiv.org/pdf/2311.14847v1"
                ],
                "primary_category": "cond-mat.other",
                "categories": [
                    "cond-mat.other",
                    "cond-mat.soft"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14843v1/1.0",
                "title": "Unveiling the 3D structure of nova shells with MUSE -- The case of RR\n  Pic",
                "year": 2023,
                "abstract": "Nova eruptions occur in cataclysmic variables when enough material has been\naccreted onto the surface of the white dwarf primary. As a consequence, the\nmaterial that has been accumulated until then is expelled into the interstellar\nmedium, forming an expanding nova shell around the system. Understanding the\nphysical process that shapes the morphology of nova shells is essential to\nfully comprehend how the ejection mechanism operates during nova eruptions.\nBecause of its closeness and age, the nova shell around the classical nova RR\nPic (Nova Pic 1925) is an ideal target for studying the evolving morphology of\nnova shells. In this work, we present an IFS study of the RR Pic nova shell,\nwith a particular emphasis on the extraction of the 3D morphology of the shell.\nThe nova shell was observed by the Multi-Unit Spectroscopic Explorer (MUSE)\ninstrument placed at the ESO-VLT. The MUSE datacube confirms the presence of\nthe nova shell in H$\\rm\\alpha$, H$\\rm\\beta$ and [OIII], and very faintly in\n[NII]. A comparison with previous observations suggests that the shell\ncontinues in its free-expansion phase but with the different parts of the shell\napparently expanding at different rates. The data analysis corroborates the\nprevious vision that the shell is composed of an equatorial ring and polar\nfilaments. At the same time, the new data also reveal that [OIII] is confined\nin gaps located in the tropical regions of the shell where no Hydrogen is\nobserved. The flux measurements indicate that ~99% of the shell flux is\nconfined to the equatorial ring, while the polar filaments show a flux\nasymmetry between the NE and SW filaments. We have estimated the mass of the\nshell to be ~5x10$^{-5}$M$_\\odot$. From the analysis of the 3D-extracted data,\nwe determine that the ring structure extends ~8,000 au from the central binary,\nand has a position angle of ~155 deg and an inclination of ~74 deg.",
                "authors": [
                    "Lientur Celed\u00f3n",
                    "Linda Schmidtobreick",
                    "Claus Tappert",
                    "Fernando Selman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14843v1",
                    "http://arxiv.org/pdf/2311.14843v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14840v1/1.0",
                "title": "Control of Equalization of Invariants",
                "year": 2023,
                "abstract": "A new class of control problems is discussed - homeostasis control.\nHomeostasis control problems can be considered as control problems with a given\ntarget set, in particular, as a problem of stabilizing the values of some\ntarget function, which is an invariant of the control free system. The report\nexamines a more general class: equalizing the values of two or more objective\nfunctions, each of which is an invariant of the corresponding subsystem of a\ncomplex system. An approach to the design of control algorithms based on the\nspeed gradient method is proposed and the conditions for the pplicability of\nthe approach are established.",
                "authors": [
                    "Alexander Fradkov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14840v1",
                    "http://arxiv.org/pdf/2311.14840v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14838v1/1.0",
                "title": "OpusCleaner and OpusTrainer, open source toolkits for training Machine\n  Translation and Large language models",
                "year": 2023,
                "abstract": "Developing high quality machine translation systems is a labour intensive,\nchallenging and confusing process for newcomers to the field. We present a pair\nof tools OpusCleaner and OpusTrainer that aim to simplify the process, reduce\nthe amount of work and lower the entry barrier for newcomers.\n  OpusCleaner is a data downloading, cleaning, and proprocessing toolkit. It is\ndesigned to allow researchers to quickly download, visualise and preprocess\nbilingual (or monolingual) data that comes from many different sources, each of\nthem with different quality, issues, and unique filtering/preprocessing\nrequirements.\n  OpusTrainer is a data scheduling and data augmenting tool aimed at building\nlarge scale, robust machine translation systems and large language models. It\nfeatures deterministic data mixing from many different sources, on-the-fly data\naugmentation and more.\n  Using these tools, we showcase how we can use it to create high quality\nmachine translation model robust to noisy user input; multilingual models and\nterminology aware models.",
                "authors": [
                    "Nikolay Bogoychev",
                    "Jelmer van der Linde",
                    "Graeme Nail",
                    "Barry Haddow",
                    "Jaume Zaragoza-Bernabeu",
                    "Gema Ram\u00edrez-S\u00e1nchez",
                    "Lukas Weymann",
                    "Tudor Nicolae Mateiu",
                    "Jind\u0159ich Helcl",
                    "Mikko Aulamo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14838v1",
                    "http://arxiv.org/pdf/2311.14838v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14837v2/1.0",
                "title": "Benchmarking Robustness of Text-Image Composed Retrieval",
                "year": 2023,
                "abstract": "Text-image composed retrieval aims to retrieve the target image through the\ncomposed query, which is specified in the form of an image plus some text that\ndescribes desired modifications to the input image. It has recently attracted\nattention due to its ability to leverage both information-rich images and\nconcise language to precisely express the requirements for target images.\nHowever, the robustness of these approaches against real-world corruptions or\nfurther text understanding has never been studied. In this paper, we perform\nthe first robustness study and establish three new diversified benchmarks for\nsystematic analysis of text-image composed retrieval against natural\ncorruptions in both vision and text and further probe textural understanding.\nFor natural corruption analysis, we introduce two new large-scale benchmark\ndatasets, CIRR-C and FashionIQ-C for testing in open domain and fashion domain\nrespectively, both of which apply 15 visual corruptions and 7 textural\ncorruptions. For textural understanding analysis, we introduce a new diagnostic\ndataset CIRR-D by expanding the original raw data with synthetic data, which\ncontains modified text to better probe textual understanding ability including\nnumerical variation, attribute variation, object removal, background variation,\nand fine-grained evaluation. The code and benchmark datasets are available at\nhttps://github.com/SunTongtongtong/Benchmark-Robustness-Text-Image-Compose-Retrieval.",
                "authors": [
                    "Shitong Sun",
                    "Jindong Gu",
                    "Shaogang Gong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14837v2",
                    "http://arxiv.org/pdf/2311.14837v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14836v2/1.0",
                "title": "Custom Data Augmentation for low resource ASR using Bark and\n  Retrieval-Based Voice Conversion",
                "year": 2023,
                "abstract": "This paper proposes two innovative methodologies to construct customized\nCommon Voice datasets for low-resource languages like Hindi. The first\nmethodology leverages Bark, a transformer-based text-to-audio model developed\nby Suno, and incorporates Meta's enCodec and a pre-trained HuBert model to\nenhance Bark's performance. The second methodology employs Retrieval-Based\nVoice Conversion (RVC) and uses the Ozen toolkit for data preparation. Both\nmethodologies contribute to the advancement of ASR technology and offer\nvaluable insights into addressing the challenges of constructing customized\nCommon Voice datasets for under-resourced languages. Furthermore, they provide\na pathway to achieving high-quality, personalized voice generation for a range\nof applications.",
                "authors": [
                    "Anand Kamble",
                    "Aniket Tathe",
                    "Suyash Kumbharkar",
                    "Atharva Bhandare",
                    "Anirban C. Mitra"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14836v2",
                    "http://arxiv.org/pdf/2311.14836v2"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "cs.CL",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14835v2/1.0",
                "title": "Weak Alignment Supervision from Hybrid Model Improves End-to-end ASR",
                "year": 2023,
                "abstract": "In this paper, we aim to create weak alignment supervision from an existing\nhybrid system to aid the end-to-end modeling of automatic speech recognition.\nTowards this end, we use the existing hybrid ASR system to produce triphone\nalignments of the training audios. We then create a cross-entropy loss at a\ncertain layer of the encoder using the derived alignments. In contrast to the\ngeneral one-hot cross-entropy losses, here we use a cross-entropy loss with a\nlabel smoothing parameter to regularize the supervision. As a comparison, we\nalso conduct the experiments with one-hot cross-entropy losses and CTC losses\nwith loss weighting. The results show that placing the weak alignment\nsupervision with the label smoothing parameter of 0.5 at the third encoder\nlayer outperforms the other two approaches and leads to about 5\\% relative WER\nreduction on the TED-LIUM 2 dataset over the baseline. We see similar\nimprovements when applying the method out-of-the-box on a Tagalog end-to-end\nASR system.",
                "authors": [
                    "Jintao Jiang",
                    "Yingbo Gao",
                    "Zoltan Tuske"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14835v2",
                    "http://arxiv.org/pdf/2311.14835v2"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "cs.CL",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14834v2/1.0",
                "title": "The MIP Workshop 2023 Computational Competition on Reoptimization",
                "year": 2023,
                "abstract": "This paper describes the computational challenge developed for a\ncomputational competition held in 2023 for the $20^{\\textrm{th}}$ anniversary\nof the Mixed Integer Programming Workshop. The topic of this competition was\nreoptimization, also known as warm starting, of mixed integer linear\noptimization problems after slight changes to the input data for a common\nformulation. The challenge was to accelerate the proof of optimality of the\nmodified instances by leveraging the information from the solving processes of\npreviously solved instances, all while creating high-quality primal solutions.\nSpecifically, we discuss the competition's format, the creation of public and\nhidden datasets, and the evaluation criteria. Our goal is to establish a\nmethodology for the generation of benchmark instances and an evaluation\nframework, along with benchmark datasets, to foster future research on\nreoptimization of mixed integer linear optimization problems.",
                "authors": [
                    "Suresh Bolusani",
                    "Mathieu Besan\u00e7on",
                    "Ambros Gleixner",
                    "Timo Berthold",
                    "Claudia D'Ambrosio",
                    "Gonzalo Mu\u00f1oz",
                    "Joseph Paat",
                    "Dimitri Thomopulos"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14834v2",
                    "http://arxiv.org/pdf/2311.14834v2"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC",
                    "90-08, 90C11, 90C57"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14831v1/1.0",
                "title": "Study of MMSE-Based Resource Allocation for Clustered Cell-Free Massive\n  MIMO Networks",
                "year": 2023,
                "abstract": "In this paper, a downlink cell-free massive multiple-input multiple-output\n(CF massive MIMO) system and a network clustering is considered. Closed form\nsum-rate expressions are derived for CF and the clustered CF (CLCF) networks\nwhere linear precoders included zero forcing (ZF) and minimum mean square error\n(MMSE) are implemented. An MMSE-based resource allocation technique with\nmultiuser scheduling based on an enhanced greedy technique and power allocation\nbased on the gradient descent (GD) method is proposed in the CLCF network to\nimprove the system performance. Numerical results show that the proposed\ntechnique is superior to the existing approaches and the computational cost and\nthe signaling load are essentially reduced in the CLCF network.",
                "authors": [
                    "S. Mashdour",
                    "R. C. de Lamare"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14831v1",
                    "http://arxiv.org/pdf/2311.14831v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14830v1/1.0",
                "title": "Active galaxy nuclei: current state of the problem",
                "year": 2023,
                "abstract": "This review presents the main points of current advances in the field of\nactive galactic nuclei (AGN). A brief historical excursion about the search for\nthe nature of AGN is given. The problem of close binary systems consisting of\nsupermassive black holes located in the centers of galaxies is discussed in\ndetails. The main characteristics, as well as new methods for studying and\n``weighing'' these new objects, are described. This paper is based on a\npresentation made in the astrophysical seminar, which dedicated to the memory\nof the outstanding astrophysicist N.G. Bochkarev (took place on May 19, 2023 at\nthe Sternberg Astronomical Institute of Moscow State University).",
                "authors": [
                    "Elena Seifina"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14830v1",
                    "http://arxiv.org/pdf/2311.14830v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA",
                    "F.2.2"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14829v2/1.0",
                "title": "Proximal Algorithms for Accelerated Langevin Dynamics",
                "year": 2023,
                "abstract": "We develop a novel class of MCMC algorithms based on a stochastized Nesterov\nscheme. With an appropriate addition of noise, the result is a\ntime-inhomogeneous underdamped Langevin equation, which we prove emits a\nspecified target distribution as its invariant measure. Convergence rates to\nstationarity under Wasserstein-2 distance are established as well.\nMetropolis-adjusted and stochastic gradient versions of the proposed Langevin\ndynamics are also provided. Experimental illustrations show superior\nperformance of the proposed method over typical Langevin samplers for different\nmodels in statistics and image processing including better mixing of the\nresulting Markov chains.",
                "authors": [
                    "Duy H. Thai",
                    "Alexander L. Young",
                    "David B. Dunson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14829v2",
                    "http://arxiv.org/pdf/2311.14829v2"
                ],
                "primary_category": "cs.CE",
                "categories": [
                    "cs.CE",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14828v1/1.0",
                "title": "Deep Latent Force Models: ODE-based Process Convolutions for Bayesian\n  Deep Learning",
                "year": 2023,
                "abstract": "Effectively modeling phenomena present in highly nonlinear dynamical systems\nwhilst also accurately quantifying uncertainty is a challenging task, which\noften requires problem-specific techniques. We outline the deep latent force\nmodel (DLFM), a domain-agnostic approach to tackling this problem, which\nconsists of a deep Gaussian process architecture where the kernel at each layer\nis derived from an ordinary differential equation using the framework of\nprocess convolutions. Two distinct formulations of the DLFM are presented which\nutilise weight-space and variational inducing points-based Gaussian process\napproximations, both of which are amenable to doubly stochastic variational\ninference. We provide evidence that our model is capable of capturing highly\nnonlinear behaviour in real-world multivariate time series data. In addition,\nwe find that our approach achieves comparable performance to a number of other\nprobabilistic models on benchmark regression tasks. We also empirically assess\nthe negative impact of the inducing points framework on the extrapolation\ncapabilities of LFM-based models.",
                "authors": [
                    "Thomas Baldwin-McDonald",
                    "Mauricio A. \u00c1lvarez"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14828v1",
                    "http://arxiv.org/pdf/2311.14828v1"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14826v1/1.0",
                "title": "Quantum tunnelling without a barrier",
                "year": 2023,
                "abstract": "Tunnelling is a renowned concept in modern physics that highlights the\npeculiarity of non-classical dynamics. Despite its ubiquity questions remain.\nWe focus on tunnelling through the barrier created by a strong laser field that\nilluminates an atomic target, which is essential to the creation of attosecond\npulses and ultimately all attosecond processes. Here, we present an optical\ntunnelling event that, unexpectedly, happens at a time when the instantaneous\nelectric field is zero and there is no barrier. We discover this strong-field\nionisation event by introducing the colour-switchover technique $-$ the gradual\nreplacement of a laser field with its second harmonic $-$ within which the\nzero-field tunnelling appears when the two amplitudes are equal. This event is\na topologically stable feature and it appears at all Keldysh parameters. The\ntunnelling without a barrier highlights the disconnect between the standard\nintuition built on the picture of a quasi-static barrier, and the nonadiabatic\nnature of the process. Our findings provide a key ingredient to the\nunderstanding of strong-field processes, such as high-harmonic generation and\nlaser-induced electron diffraction, driven by the increasingly accessible class\nof strongly polychromatic light fields.",
                "authors": [
                    "Anne Weber",
                    "Margarita Khokhlova",
                    "Emilio Pisanty"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14826v1",
                    "http://arxiv.org/pdf/2311.14826v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "physics.atom-ph",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14824v1/1.0",
                "title": "A Reusable AI-Enabled Defect Detection System for Railway Using\n  Ensembled CNN",
                "year": 2023,
                "abstract": "Accurate Defect detection is crucial for ensuring the trustworthiness of\nintelligent railway systems. Current approaches rely on single deep-learning\nmodels, like CNNs, which employ a large amount of data to capture underlying\npatterns. Training a new defect classifier with limited samples often leads to\noverfitting and poor performance on unseen images. To address this, researchers\nhave advocated transfer learning and fine-tuning the pre-trained models.\nHowever, using a single backbone network in transfer learning still may cause\nbottleneck issues and inconsistent performance if it is not suitable for a\nspecific problem domain. To overcome these challenges, we propose a reusable\nAI-enabled defect detection approach. By combining ensemble learning with\ntransfer learning models (VGG-19, MobileNetV3, and ResNet-50), we improved the\nclassification accuracy and achieved consistent performance at a certain phase\nof training. Our empirical analysis demonstrates better and more consistent\nperformance compared to other state-of-the-art approaches. The consistency\nsubstantiates the reusability of the defect detection system for newly evolved\ndefected rail parts. Therefore we anticipate these findings to benefit further\nresearch and development of reusable AI-enabled solutions for railway systems.",
                "authors": [
                    "Rahatara Ferdousi",
                    "Fedwa Laamarti",
                    "Chunsheng Yang",
                    "Abdulmotaleb El Saddik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14824v1",
                    "http://arxiv.org/pdf/2311.14824v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG",
                    "68T45, 68T05",
                    "I.2.10; I.5.2"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14822v1/1.0",
                "title": "Text and Click inputs for unambiguous open vocabulary instance\n  segmentation",
                "year": 2023,
                "abstract": "Segmentation localizes objects in an image on a fine-grained per-pixel scale.\nSegmentation benefits by humans-in-the-loop to provide additional input of\nobjects to segment using a combination of foreground or background clicks.\nTasks include photoediting or novel dataset annotation, where human annotators\nleverage an existing segmentation model instead of drawing raw pixel level\nannotations. We propose a new segmentation process, Text + Click segmentation,\nwhere a model takes as input an image, a text phrase describing a class to\nsegment, and a single foreground click specifying the instance to segment.\nCompared to previous approaches, we leverage open-vocabulary image-text models\nto support a wide-range of text prompts. Conditioning segmentations on text\nprompts improves the accuracy of segmentations on novel or unseen classes. We\ndemonstrate that the combination of a single user-specified foreground click\nand a text prompt allows a model to better disambiguate overlapping or\nco-occurring semantic categories, such as \"tie\", \"suit\", and \"person\". We study\nthese results across common segmentation datasets such as refCOCO, COCO, VOC,\nand OpenImages. Source code available here.",
                "authors": [
                    "Nikolai Warner",
                    "Meera Hahn",
                    "Jonathan Huang",
                    "Irfan Essa",
                    "Vighnesh Birodkar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14822v1",
                    "http://arxiv.org/pdf/2311.14822v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14816v1/1.0",
                "title": "Learning Arousal-Valence Representation from Categorical Emotion Labels\n  of Speech",
                "year": 2023,
                "abstract": "Dimensional representations of speech emotions such as the arousal-valence\n(AV) representation provide a continuous and fine-grained description and\ncontrol than their categorical counterparts. They have wide applications in\ntasks such as dynamic emotion understanding and expressive text-to-speech\nsynthesis. Existing methods that predict the dimensional emotion representation\nfrom speech cast it as a supervised regression task. These methods face data\nscarcity issues, as dimensional annotations are much harder to acquire than\ncategorical labels. In this work, we propose to learn the AV representation\nfrom categorical emotion labels of speech. We start by learning a rich and\nemotion-relevant high-dimensional speech feature representation using\nself-supervised pre-training and emotion classification fine-tuning. This\nrepresentation is then mapped to the 2D AV space according to psychological\nfindings through anchored dimensionality reduction. Experiments show that our\nmethod achieves a Concordance Correlation Coefficient (CCC) performance\ncomparable to state-of-the-art supervised regression methods on IEMOCAP without\nleveraging ground-truth AV annotations during training. This validates our\nproposed approach on AV prediction. Furthermore, visualization of AV\npredictions on MEAD and EmoDB datasets shows the interpretability of the\nlearned AV representations.",
                "authors": [
                    "Enting Zhou",
                    "You Zhang",
                    "Zhiyao Duan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14816v1",
                    "http://arxiv.org/pdf/2311.14816v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14815v1/1.0",
                "title": "Geometric theory on large-scale and local determination of density\n  dependence of a recovering large carnivore population",
                "year": 2023,
                "abstract": "Density-dependent population growth is a feature of large carnivores like\nwolves ($\\textit{Canis lupus}$), with mechanisms typically attributed to\nresource (e.g. prey) limitation. Such mechanisms are local phenomena and rely\non individuals having access to information, such as prey availability at their\nlocation. Using over four decades of wolf population and range expansion data\nfrom Wisconsin (USA) wolves, we found that the population not only exhibited\ndensity dependence locally but also at landscape scale. Superficially, one may\nconsider space as yet another limiting resource to explain landscape-scale\ndensity dependence. However, this view poses an information puzzle: most\nindividuals do not have access to global information such as range-wide habitat\navailability as they would for local prey availability. How would the\npopulation \"know\" when to slow their range expansion? To understand observed\nlarge-scale spatial density dependence, we propose a reaction-diffusion model,\nfirst introduced by Fisher and Kolmogorov, with a \"travelling wave\" solution,\nwherein the population expands from a core range that quickly achieves local\ncarrying capacity. Early-stage acceleration and later-stage deceleration of\npopulation growth can be explained by early elongation of an expanding frontier\nand a later collision of the expanding frontier with a habitat boundary. Such a\nprocess does not require individuals to have global density information. We\nillustrate our proposal with simulations and spatial visualizations of wolf\nrecolonization in the western Great Lakes region over time relative to habitat\nsuitability. We further synthesize previous studies on wolf habitat selection\nin the western Great Lakes region and argue that the habitat boundary appeared\nto be driven by spatial variation in mortality, likely associated with human\nuse of the landscape.",
                "authors": [
                    "Yunyi Shen",
                    "Erik R. Olson",
                    "Timothy R. Van Deelen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14815v1",
                    "http://arxiv.org/pdf/2311.14815v1"
                ],
                "primary_category": "q-bio.PE",
                "categories": [
                    "q-bio.PE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14812v1/1.0",
                "title": "Robust Joint Estimation of Galaxy Redshift and Spectral Templates using\n  Online Dictionary Learning",
                "year": 2023,
                "abstract": "We present a novel approach to analyzing astronomical spectral survey data\nusing our non-linear extension of an online dictionary learning algorithm.\nCurrent and upcoming surveys such as SPHEREx will use spectral data to build a\n3D map of the universe by estimating the redshifts of millions of galaxies.\nExisting algorithms rely on hand-curated external templates and have limited\nperformance due to model mismatch error. Our algorithm addresses this\nlimitation by jointly estimating both the underlying spectral features in\ncommon across the entire dataset, as well as the redshift of each galaxy. Our\nonline approach scales well to large datasets since we only process a single\nspectrum in memory at a time. Our algorithm performs better than a\nstate-of-the-art existing algorithm when analyzing a mock SPHEREx dataset,\nachieving a NMAD standard deviation of 0.18% and a catastrophic error rate of\n0.40% when analyzing noiseless data. Our algorithm also performs well over a\nwide range of signal to noise ratios (SNR), delivering sub-percent NMAD and\ncatastrophic error above median SNR of 20. We released our algorithm publicly\nat github.com/HyperspectralDictionaryLearning/BryanEtAl2023 .",
                "authors": [
                    "Sean Bryan",
                    "Ayan Barekzai",
                    "Delondrae Carter",
                    "Philip Mauskopf",
                    "Julian Mena",
                    "Danielle Rivera",
                    "Abel S. Uriarte",
                    "Pao-Yu Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14812v1",
                    "http://arxiv.org/pdf/2311.14812v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "astro-ph.CO",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14809v1/1.0",
                "title": "JWST and ALMA discern the assembly of structural and obscured components\n  in a high-redshift starburst galaxy",
                "year": 2023,
                "abstract": "We present observations and analysis of the starburst, PACS-819, at z=1.45\n($M_*=10^{10.7}$ M$_{ \\odot}$), using high-resolution ($0^{\\prime \\prime}.1$;\n0.8 kpc) ALMA and multi-wavelength JWST images from the COSMOS-Web program.\nDissimilar to HST/ACS images in the rest-frame UV, the redder NIRCam and MIRI\nimages reveal a smooth central mass concentration and spiral-like features,\natypical for such an intense starburst. Through dynamical modeling of the CO\nJ=5--4 emission with ALMA, PACS-819 is rotation-dominated thus has a disk-like\nnature. However, kinematic anomalies in CO and asymmetric features in the bluer\nJWST bands (e.g., F150W) support a more disturbed nature likely due to\ninteractions. The JWST imaging further enables us to map the distribution of\nstellar mass and dust attenuation, thus clarifying the relationships between\ndifferent structural components, not discernable in the previous HST images.\nThe CO J = 5 -- 4 and FIR dust continuum emission are co-spatial with a\nheavily-obscured starbursting core (<1 kpc) which is partially surrounded by\nmuch less obscured star-forming structures including a prominent arc, possibly\na tidally-distorted dwarf galaxy, and a clump, either a sign of an ongoing\nviolent disk instability or a recently accreted low-mass satellite. With\nspatially-resolved maps, we find a high molecular gas fraction in the central\narea reaching $\\sim3$ ($M_{\\text{gas}}$/$M_*$) and short depletion times\n($M_{\\text{gas}}/SFR\\sim$ 120 Myrs) across the entire system. These\nobservations provide insights into the complex nature of starbursts in the\ndistant universe and underscore the wealth of complementary information from\nhigh-resolution observations with both ALMA and JWST.",
                "authors": [
                    "Zhaoxuan Liu",
                    "John D. Silverman",
                    "Emanuele Daddi",
                    "Annagrazia Puglisi",
                    "Alvio Renzini",
                    "Boris S. Kalita",
                    "Jeyhan S. Kartaltepe",
                    "Daichi Kashino",
                    "Giulia Rodighiero",
                    "Wiphu Rujopakarn",
                    "Tomoko L. Suzuki",
                    "Takumi S. Tanaka",
                    "Francesco Valentino",
                    "Irham Taufik Andika",
                    "Caitlin M. Casey",
                    "Andreas Faisst",
                    "Maximilien Franco",
                    "Ghassem Gozaliasl",
                    "Steven Gillman",
                    "Christopher C. Hayward",
                    "Anton M. Koekemoer",
                    "Vasily Kokorev",
                    "Erini Lambrides",
                    "Minju M. Lee",
                    "Georgios E. Magdis",
                    "Santosh Harish",
                    "Henry Joy McCracken",
                    "Jason Rhodes",
                    "Marko Shuntov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14809v1",
                    "http://arxiv.org/pdf/2311.14809v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14808v1/1.0",
                "title": "Data-to-Text Bilingual Generation",
                "year": 2023,
                "abstract": "This document illustrates the use of pyrealb for generating two parallel\ntexts (English and French) from a single source of data. The data selection and\ntext organisation processes are shared between the two languages. only language\ndependent word and phrasing choices are distinct processes. The realized texts\nthus convey identical information in both languages without the risk of being\nlost in translation. This is especially important in cases where strict and\nsimultaneous bilingualism is required. We first present the types of\napplications targeted by this approach and how the pyrealb English and French\nrealizer can be used for achieving this goal in a natural way. We describe an\nobject-oriented organization to ensure a convenient realization in both\nlanguages. To illustrate the process, different types of applications are then\nbriefly sketched with links to the source code. A brief comparison of the text\ngeneration is given with the output of an instance of a GPT.",
                "authors": [
                    "Guy Lapalme"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14808v1",
                    "http://arxiv.org/pdf/2311.14808v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "I.2.7"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14807v1/1.0",
                "title": "Multifractal detrended fluctuation analysis of rainfall time series in\n  the Guadeloupe archipelago",
                "year": 2023,
                "abstract": "Due to the vulnerability of the Caribbean islands to the climate change\nissue, it is important to investigate the behavior of rainfall. In addition,\nthe soil of the French West Indies Islands has been contaminated by an\ninsecticide (Chlordecone) whose decontamination is mainly done by drainage\nwater. Thus, it is crucial to investigate the fluctuations of rainfall in these\ncomplex environments. In this study, 19 daily rainfall series recorded in\ndifferent stations of Guadeloupe archipelago from 2005 to 2014 were analyzed\nwith the multifractal detrended fluctuation analysis (MF-DFA) method. The aim\nof this work is to characterize the long-range correlations and multifractal\nproperties of the time series and to find geographical patterns over the three\nmost important islands. This is the first study that addresses the analysis of\nmultifractal properties of rainfall series in the Caribbean islands. This\nregion is typically characterized by the almost constant influence of the trade\nwinds and a high exposure to changes in the general atmospheric circulation. 12\nstations exhibit two different power-law scaling regions in rainfall series,\nwith distinct long-range correlations and multifractal properties for large and\nsmall scales. On the contrary, the rest of stations only show a single region\nof scales for relatively small scales. Hurst exponents reveal persistent\nlong-range correlations. In the most eastern analyzed areas, larger scales\nexhibit higher persistence than smaller scales, which suggests a relationship\nbetween persistence and the highest exposure to the trade winds. Stronger\nconclusions can be drawn from multifractal spectra, which indicate that most\nrainfall series have a multifractal nature with higher complexity and degree of\nmultifractality at the smallest scales. Furthermore, a clear dependence of\nmultifractal nature on the latitude is revealed.",
                "authors": [
                    "J. Gomez-Gomez",
                    "T. Plocoste",
                    "E. Alexis",
                    "F. J. Jimenez-Hornero",
                    "E. Gutierrez de Rave",
                    "S. P. Nuiro"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/j.jhydrol.2023.130377",
                    "http://arxiv.org/abs/2311.14807v1",
                    "http://arxiv.org/pdf/2311.14807v1"
                ],
                "primary_category": "physics.ao-ph",
                "categories": [
                    "physics.ao-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14803v1/1.0",
                "title": "Black hole spectroscopy beyond Kerr: agnostic and theory-based tests\n  with next-generation interferometers",
                "year": 2023,
                "abstract": "Black hole spectroscopy is a clean and powerful tool to test gravity in the\nstrong-field regime and to probe the nature of compact objects. Next-generation\nground-based detectors, such as the Einstein Telescope and Cosmic Explorer,\nwill observe thousands of binary black hole mergers with large signal-to-noise\nratios, allowing for accurate measurements of the remnant black hole\nquasinormal mode frequencies and damping times. In previous work we developed\nan observable-based parametrization of the quasinormal mode spectrum of\nspinning black holes beyond general relativity (ParSpec). In this paper we use\nthis parametrization to ask: can next-generation detectors detect or constrain\ndeviations from the Kerr spectrum by stacking multiple observations of binary\nmergers from astrophysically motivated populations? We focus on two families of\ntests: (i) agnostic (null) tests, and (ii) theory-based tests, which make use\nof quasinormal frequency calculations in specific modified theories of gravity.\nWe consider in particular two quadratic gravity theories\n(Einstein-scalar-Gauss-Bonnet and dynamical Chern-Simons gravity) and various\neffective field theory-based extensions of general relativity. We find that\nrobust inference of hypothetical corrections to general relativity requires\npushing the slow-rotation expansion to high orders. Even when high-order\nexpansions are available, ringdown observations alone may not be sufficient to\nmeasure deviations from the Kerr spectrum for theories with dimensionful\ncoupling constants. This is because the constraints are dominated by \"light\"\nblack hole remnants, and only few of them have sufficiently high\nsignal-to-noise ratio in the ringdown. Black hole spectroscopy with\nnext-generation detectors may be able to set tight constraints on theories with\ndimensionless coupling, as long as we assume prior knowledge of the mass and\nspin of the remnant black hole.",
                "authors": [
                    "Andrea Maselli",
                    "Sophia Yi",
                    "Lorenzo Pierini",
                    "Vania Vellucci",
                    "Luca Reali",
                    "Leonardo Gualtieri",
                    "Emanuele Berti"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14803v1",
                    "http://arxiv.org/pdf/2311.14803v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc",
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14796v1/1.0",
                "title": "Scattering from an external field in quantum chromodynamics at high\n  energies: from foundations to interdisciplinary connections",
                "year": 2023,
                "abstract": "We review the factorization of the $S$-matrix elements in the context of\nparticle scattering off an external field, which can serve as a model for the\nfield of a large nucleus. The factorization takes the form of a convolution of\nlight cone wave functions describing the physical incoming and outgoing states\nin terms of bare partons, and products of Wilson lines. The latter represent\nthe interaction between the bare partons and the external field. Specializing\nto elastic scattering amplitudes of onia at very high energies, we introduce\nthe color dipole model, which formulates the calculation of the modulus-squared\nof the wave functions in quantum chromodynamics with the help of a branching\nrandom walk, and the scattering amplitudes as observables on this classical\nstochastic process. Methods developed for general branching processes produce\nanalytical formulas for the asymptotics of such observables, and thus enable\none to derive exact large-rapidity expressions for onium-nucleus cross\nsections, from which electron-nucleus cross sections may be inferred.",
                "authors": [
                    "Athanasia-Konstantina Angelopoulou",
                    "Anh Dung Le",
                    "St\u00e9phane Munier"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14796v1",
                    "http://arxiv.org/pdf/2311.14796v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14792v1/1.0",
                "title": "A soft and transient ultraluminous X-ray source with 6-h modulation in\n  the NGC 300 galaxy",
                "year": 2023,
                "abstract": "We investigate the nature of CXOU J005440.5-374320 (J0054), a peculiar bright\n($\\sim$$4\\times10^{39}$ erg/s) and soft X-ray transient in the spiral galaxy\nNGC 300 with a 6-hour periodic flux modulation that was detected in a 2014\nChandra observation. Subsequent observations with Chandra and XMM-Newton, as\nwell as a large observational campaign of NGC 300 and its sources performed\nwith the Swift Neil Gehrels Observatory, showed that this source exhibits\nrecurrent flaring activity: four other outbursts were detected across $\\sim$8\nyears of monitoring. Using data from the Swift/UVOT archive and from the\nXMM-Newton/OM and Gaia catalogues, we noted the source is likely associated\nwith a bright blue optical/ultraviolet counterpart. This prompted us to perform\nfollow-up observations with the Southern African Large Telescope in December\n2019. With the multi-wavelength information at hand, we discuss several\npossibilities for the nature of J0054. Although none is able to account for the\nfull range of the observed peculiar features, we found that the two most\npromising scenarios are a stellar-mass compact object in a binary system with a\nWolf$-$Rayet star companion, or the recurrent tidal stripping of a stellar\nobject trapped in a system with an intermediate-mass ($\\sim1000$ $M_\\odot$)\nblack hole.",
                "authors": [
                    "A. Sacchi",
                    "P. Esposito",
                    "D. de Martino",
                    "R. Soria",
                    "G. L. Israel",
                    "A. A. C. Sander",
                    "L. Sidoli",
                    "D. A. H. Buckley",
                    "I. M. Monageng",
                    "A. Tiengo",
                    "M. Arca Sedda",
                    "C. Pinto",
                    "R. Di Stefano",
                    "M. Imbrogno",
                    "A. Carleo",
                    "G. Rivolta"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14792v1",
                    "http://arxiv.org/pdf/2311.14792v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14794v1/1.0",
                "title": "The Role of Vectors in Reheating",
                "year": 2023,
                "abstract": "We explore various aspects concerning the role of vector bosons during the\nreheating process. Generally, reheating occurs during the period of\noscillations of the inflaton condensate and the evolution of the radiation bath\ndepends on the inflaton equation of state. For oscillations about a quadratic\nminimum, the equation of state parameter, $w = p/\\rho =0$, and the evolution of\nthe temperature, $T(a)$ with respect to the scale factor is independent of the\nspin of the inflaton decay products. However, for cases when $w>0$, there is a\ndependence on the spin, and here we consider the evolution when the inflaton\ndecays or scatters to vector bosons. We also investigate the gravitational\nproduction of vector bosons as potential dark matter candidates. Gravitational\nproduction predominantly occurs through the longitudinal mode. We compare these\nresults to the gravitational production of scalars.",
                "authors": [
                    "Marcos A. G. Garcia",
                    "Kunio Kaneta",
                    "Wenqi Ke",
                    "Yann Mambrini",
                    "Keith A. Olive",
                    "Sarunas Verner"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14794v1",
                    "http://arxiv.org/pdf/2311.14794v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14795v1/1.0",
                "title": "Pulsar Nulling and Vacuum Radio Emission from Axion Clouds",
                "year": 2023,
                "abstract": "Non-relativistic axions can be efficiently produced in in the polar caps of\npulsars, resulting in the formation of a dense cloud of gravitationally bound\naxions. Here, we investigate the interplay between such an axion cloud and the\nelectrodynamics in the pulsar magnetosphere, focusing specifically on the\ndynamics in the polar caps, where the impact of the axion cloud is expected to\nbe most pronounced. For sufficiently light axions $m_a \\lesssim 10^{-7}$ eV, we\nshow that the axion cloud can occasionally screen the local electric field\nresponsible for particle acceleration and pair production, inducing a periodic\nnulling of the pulsar's intrinsic radio emission. At larger axion masses, the\nsmall-scale fluctuations in the axion field tend to suppress the back-reaction\nof the axion on the electrodynamics; however, we point out that the incoherent\noscillations of the axion in short-lived regions of vacuum near the neutron\nstar surface can produce a narrow radio line, which provides a complementary\nsource of radio emission to the plasma-resonant emission processes identified\nin previous work. While this work focuses on the leading order correction to\npair production in the magnetosphere, we speculate that there can exist\ndramatic deviations in the electrodynamics of these systems when the axion\nback-reaction becomes non-linear.",
                "authors": [
                    "Andrea Caputo",
                    "Samuel J. Witte",
                    "Alexander A. Philippov",
                    "Ted Jacobson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14795v1",
                    "http://arxiv.org/pdf/2311.14795v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "astro-ph.CO",
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14671v1/1.0",
                "title": "SEGIC: Unleashing the Emergent Correspondence for In-Context\n  Segmentation",
                "year": 2023,
                "abstract": "In-context segmentation aims at segmenting novel images using a few labeled\nexample images, termed as \"in-context examples\", exploring content similarities\nbetween examples and the target. The resulting models can be generalized\nseamlessly to novel segmentation tasks, significantly reducing the labeling and\ntraining costs compared with conventional pipelines. However, in-context\nsegmentation is more challenging than classic ones due to its meta-learning\nnature, requiring the model to learn segmentation rules conditioned on a few\nsamples, not just the segmentation. Unlike previous work with ad-hoc or\nnon-end-to-end designs, we propose SEGIC, an end-to-end segment-in-context\nframework built upon a single vision foundation model (VFM). In particular,\nSEGIC leverages the emergent correspondence within VFM to capture dense\nrelationships between target images and in-context samples. As such,\ninformation from in-context samples is then extracted into three types of\ninstructions, i.e. geometric, visual, and meta instructions, serving as\nexplicit conditions for the final mask prediction. SEGIC is a straightforward\nyet effective approach that yields state-of-the-art performance on one-shot\nsegmentation benchmarks. Notably, SEGIC can be easily generalized to diverse\ntasks, including video object segmentation and open-vocabulary segmentation.\nCode will be available at \\url{https://github.com/MengLcool/SEGIC}.",
                "authors": [
                    "Lingchen Meng",
                    "Shiyi Lan",
                    "Hengduo Li",
                    "Jose M. Alvarez",
                    "Zuxuan Wu",
                    "Yu-Gang Jiang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14671v1",
                    "http://arxiv.org/pdf/2311.14671v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.15826v1/1.0",
                "title": "GeoChat: Grounded Large Vision-Language Model for Remote Sensing",
                "year": 2023,
                "abstract": "Recent advancements in Large Vision-Language Models (VLMs) have shown great\npromise in natural image domains, allowing users to hold a dialogue about given\nvisual content. However, such general-domain VLMs perform poorly for Remote\nSensing (RS) scenarios, leading to inaccurate or fabricated information when\npresented with RS domain-specific queries. Such a behavior emerges due to the\nunique challenges introduced by RS imagery. For example, to handle\nhigh-resolution RS imagery with diverse scale changes across categories and\nmany small objects, region-level reasoning is necessary alongside holistic\nscene interpretation. Furthermore, the lack of domain-specific multimodal\ninstruction following data as well as strong backbone models for RS make it\nhard for the models to align their behavior with user queries. To address these\nlimitations, we propose GeoChat - the first versatile remote sensing VLM that\noffers multitask conversational capabilities with high-resolution RS images.\nSpecifically, GeoChat can not only answer image-level queries but also accepts\nregion inputs to hold region-specific dialogue. Furthermore, it can visually\nground objects in its responses by referring to their spatial coordinates. To\naddress the lack of domain-specific datasets, we generate a novel RS multimodal\ninstruction-following dataset by extending image-text pairs from existing\ndiverse RS datasets. We establish a comprehensive benchmark for RS multitask\nconversations and compare with a number of baseline methods. GeoChat\ndemonstrates robust zero-shot performance on various RS tasks, e.g., image and\nregion captioning, visual question answering, scene classification, visually\ngrounded conversations and referring detection. Our code is available at\nhttps://github.com/mbzuai-oryx/geochat.",
                "authors": [
                    "Kartik Kuckreja",
                    "Muhammad Sohail Danish",
                    "Muzammal Naseer",
                    "Abhijit Das",
                    "Salman Khan",
                    "Fahad Shahbaz Khan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.15826v1",
                    "http://arxiv.org/pdf/2311.15826v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14670v1/1.0",
                "title": "Differentiable and accelerated spherical harmonic and Wigner transforms",
                "year": 2023,
                "abstract": "Many areas of science and engineering encounter data defined on spherical\nmanifolds. Modelling and analysis of spherical data often necessitates\nspherical harmonic transforms, at high degrees, and increasingly requires\nefficient computation of gradients for machine learning or other differentiable\nprogramming tasks. We develop novel algorithmic structures for accelerated and\ndifferentiable computation of generalised Fourier transforms on the sphere\n$\\mathbb{S}^2$ and rotation group $\\text{SO}(3)$, i.e. spherical harmonic and\nWigner transforms, respectively. We present a recursive algorithm for the\ncalculation of Wigner $d$-functions that is both stable to high harmonic\ndegrees and extremely parallelisable. By tightly coupling this with separable\nspherical transforms, we obtain algorithms that exhibit an extremely\nparallelisable structure that is well-suited for the high throughput computing\nof modern hardware accelerators (e.g. GPUs). We also develop a hybrid automatic\nand manual differentiation approach so that gradients can be computed\nefficiently. Our algorithms are implemented within the JAX differentiable\nprogramming framework in the S2FFT software code. Numerous samplings of the\nsphere are supported, including equiangular and HEALPix sampling. Computational\nerrors are at the order of machine precision for spherical samplings that admit\na sampling theorem. When benchmarked against alternative C codes we observe up\nto a 400-fold acceleration. Furthermore, when distributing over multiple GPUs\nwe achieve very close to optimal linear scaling with increasing number of GPUs\ndue to the highly parallelised and balanced nature of our algorithms. Provided\naccess to sufficiently many GPUs our transforms thus exhibit an unprecedented\neffective linear time complexity.",
                "authors": [
                    "Matthew A. Price",
                    "Jason D. McEwen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14670v1",
                    "http://arxiv.org/pdf/2311.14670v1"
                ],
                "primary_category": "physics.comp-ph",
                "categories": [
                    "physics.comp-ph",
                    "astro-ph.IM",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14669v1/1.0",
                "title": "Landau Singularities Revisited",
                "year": 2023,
                "abstract": "We reformulate the analysis of singularities of Feynman integrals in a way\nthat can be practically applied to perturbative computations in the Standard\nModel in dimensional regularization. After highlighting issues in the textbook\ntreatment of Landau singularities, we develop an algorithm for classifying and\ncomputing them using techniques from computational algebraic geometry. We\nintroduce an algebraic variety called the principal Landau determinant, which\ncaptures the singularities even in the presence of massless particles or UV/IR\ndivergences. We illustrate this for 114 example diagrams, including a\ncutting-edge 2-loop 5-point non-planar QCD process with multiple mass scales.\nThe algorithms introduced in this work are implemented in the open-source Julia\npackage PLD.jl available at https://mathrepo.mis.mpg.de/PLD/.",
                "authors": [
                    "Claudia Fevola",
                    "Sebastian Mizera",
                    "Simon Telen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14669v1",
                    "http://arxiv.org/pdf/2311.14669v1"
                ],
                "primary_category": "hep-th",
                "categories": [
                    "hep-th",
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14664v1/1.0",
                "title": "On the structure of genealogical trees associated with explosive\n  Crump-Mode-Jagers branching processes",
                "year": 2023,
                "abstract": "We study the structure of genealogical trees associated with explosive\nCrump-Mode-Jagers branching processes (stopped at the explosion time), proving\ncriteria for the associated tree to contain a node of infinite degree (a star)\nor an infinite path. Next, we provide uniqueness criteria under which with\nprobability $1$ there exists exactly one of a unique star or a unique infinite\npath. Under the latter uniqueness criteria, we also provide an example where,\nwith strictly positive probability less than $1$, there exists a unique node of\ninfinite degree in the model, thus this probability is not restricted to being\n$0$ or $1$. Moreover, we provide structure theorems when there is a star, when\ncertain trees appear as sub-trees of the star infinitely often. We apply our\nresults to general discrete evolving tree models of explosive recursive trees\nwith fitness, and as particular cases, we study a family of super-linear\npreferential attachment models with fitness. In the latter regime, we derive\nphase transitions in the model parameters in three different examples, leading\nto either exactly one star with probability $1$, or one infinite path with\nprobability $1$, with every node having finite degree. Furthermore, we\nhighlight examples where sub-trees $T$ of arbitrary size can appear infinitely\noften; behaviour that is markedly distinct from super-linear preferential\nattachment models studied in the literature so far.",
                "authors": [
                    "Tejas Iyer",
                    "Bas Lodewijks"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14664v1",
                    "http://arxiv.org/pdf/2311.14664v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14658v1/1.0",
                "title": "Convergence Analysis for Learning Orthonormal Deep Linear Neural\n  Networks",
                "year": 2023,
                "abstract": "Enforcing orthonormal or isometric property for the weight matrices has been\nshown to enhance the training of deep neural networks by mitigating gradient\nexploding/vanishing and increasing the robustness of the learned networks.\nHowever, despite its practical performance, the theoretical analysis of\northonormality in neural networks is still lacking; for example, how\northonormality affects the convergence of the training process. In this letter,\nwe aim to bridge this gap by providing convergence analysis for training\northonormal deep linear neural networks. Specifically, we show that Riemannian\ngradient descent with an appropriate initialization converges at a linear rate\nfor training orthonormal deep linear neural networks with a class of loss\nfunctions. Unlike existing works that enforce orthonormal weight matrices for\nall the layers, our approach excludes this requirement for one layer, which is\ncrucial to establish the convergence guarantee. Our results shed light on how\nincreasing the number of hidden layers can impact the convergence speed.\nExperimental results validate our theoretical analysis.",
                "authors": [
                    "Zhen Qin",
                    "Xuwei Tan",
                    "Zhihui Zhu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14658v1",
                    "http://arxiv.org/pdf/2311.14658v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14656v2/1.0",
                "title": "Charting New Territories: Exploring the Geographic and Geospatial\n  Capabilities of Multimodal LLMs",
                "year": 2023,
                "abstract": "Multimodal large language models (MLLMs) have shown remarkable capabilities\nacross a broad range of tasks but their knowledge and abilities in the\ngeographic and geospatial domains are yet to be explored, despite potential\nwide-ranging benefits to navigation, environmental research, urban development,\nand disaster response. We conduct a series of experiments exploring various\nvision capabilities of MLLMs within these domains, particularly focusing on the\nfrontier model GPT-4V, and benchmark its performance against open-source\ncounterparts. Our methodology involves challenging these models with a\nsmall-scale geographic benchmark consisting of a suite of visual tasks, testing\ntheir abilities across a spectrum of complexity. The analysis uncovers not only\nwhere such models excel, including instances where they outperform humans, but\nalso where they falter, providing a balanced view of their capabilities in the\ngeographic domain. To enable the comparison and evaluation of future models,\nour benchmark will be publicly released.",
                "authors": [
                    "Jonathan Roberts",
                    "Timo L\u00fcddecke",
                    "Rehan Sheikh",
                    "Kai Han",
                    "Samuel Albanie"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14656v2",
                    "http://arxiv.org/pdf/2311.14656v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14655v1/1.0",
                "title": "A Sparse Factor Model for Clustering High-Dimensional Longitudinal Data",
                "year": 2023,
                "abstract": "Recent advances in engineering technologies have enabled the collection of a\nlarge number of longitudinal features. This wealth of information presents\nunique opportunities for researchers to investigate the complex nature of\ndiseases and uncover underlying disease mechanisms. However, analyzing such\nkind of data can be difficult due to its high dimensionality, heterogeneity and\ncomputational challenges. In this paper, we propose a Bayesian nonparametric\nmixture model for clustering high-dimensional mixed-type (e.g., continuous,\ndiscrete and categorical) longitudinal features. We employ a sparse factor\nmodel on the joint distribution of random effects and the key idea is to induce\nclustering at the latent factor level instead of the original data to escape\nthe curse of dimensionality. The number of clusters is estimated through a\nDirichlet process prior. An efficient Gibbs sampler is developed to estimate\nthe posterior distribution of the model parameters. Analysis of real and\nsimulated data is presented and discussed. Our study demonstrates that the\nproposed model serves as a useful analytical tool for clustering\nhigh-dimensional longitudinal data.",
                "authors": [
                    "Zihang Lu",
                    "Noirrit Kiran Chandra"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14655v1",
                    "http://arxiv.org/pdf/2311.14655v1"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME",
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14788v1/1.0",
                "title": "Evaluating Large Language Models through Gender and Racial Stereotypes",
                "year": 2023,
                "abstract": "Language Models have ushered a new age of AI gaining traction within the NLP\ncommunity as well as amongst the general population. AI's ability to make\npredictions, generations and its applications in sensitive decision-making\nscenarios, makes it even more important to study these models for possible\nbiases that may exist and that can be exaggerated. We conduct a quality\ncomparative study and establish a framework to evaluate language models under\nthe premise of two kinds of biases: gender and race, in a professional setting.\nWe find out that while gender bias has reduced immensely in newer models, as\ncompared to older ones, racial bias still exists.",
                "authors": [
                    "Ananya Malik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14788v1",
                    "http://arxiv.org/pdf/2311.14788v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14653v1/1.0",
                "title": "Data-driven Prior Learning for Bayesian Optimisation",
                "year": 2023,
                "abstract": "Transfer learning for Bayesian optimisation has generally assumed a strong\nsimilarity between optimisation tasks, with at least a subset having similar\noptimal inputs. This assumption can reduce computational costs, but it is\nviolated in a wide range of optimisation problems where transfer learning may\nnonetheless be useful. We replace this assumption with a weaker one only\nrequiring the shape of the optimisation landscape to be similar, and analyse\nthe recent method Prior Learning for Bayesian Optimisation - PLeBO - in this\nsetting. By learning priors for the hyperparameters of the Gaussian process\nsurrogate model we can better approximate the underlying function, especially\nfor few function evaluations. We validate the learned priors and compare to a\nbreadth of transfer learning approaches, using synthetic data and a recent air\npollution optimisation problem as benchmarks. We show that PLeBO and prior\ntransfer find good inputs in fewer evaluations.",
                "authors": [
                    "Sigrid Passano Hellan",
                    "Christopher G. Lucas",
                    "Nigel H. Goddard"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14653v1",
                    "http://arxiv.org/pdf/2311.14653v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14652v1/1.0",
                "title": "One Pass Streaming Algorithm for Super Long Token Attention\n  Approximation in Sublinear Space",
                "year": 2023,
                "abstract": "Deploying Large Language Models (LLMs) in streaming applications that involve\nlong contexts, particularly for extended dialogues and text analysis, is of\nparamount importance but presents two significant challenges. Firstly, the\nmemory consumption is substantial during the decoding phase due to the caching\nof Key and Value states (KV) of previous tokens. Secondly, attention\ncomputation is time-consuming with a time complexity of $O(n^2)$ for the\ngeneration of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAI\nreleased a new model that is able to support a 128K-long document, in our\npaper, we focus on the memory-efficient issue when context length $n$ is much\ngreater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with\nQuery, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the\npolynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times\nd}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times\nt}$ to expedite attention ${\\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$\ntime executions. Despite this, storing the Key and Value matrices $K, V \\in\n\\mathbb{R}^{n \\times d}$ still necessitates $O( n d)$ space, leading to\nsignificant memory usage. In response to these challenges, we introduce a new\nalgorithm that only reads one pass of the data in streaming fashion. This\nmethod employs sublinear space $o(n)$ to store three sketch matrices,\nalleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits\nexceptional memory-efficient performance with super-long tokens. As the token\nlength $n$ increases, our error guarantee diminishes while the memory usage\nremains nearly constant. This unique attribute underscores the potential of our\ntechnique in efficiently handling LLMs in streaming applications.",
                "authors": [
                    "Raghav Addanki",
                    "Chenyang Li",
                    "Zhao Song",
                    "Chiwun Yang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14652v1",
                    "http://arxiv.org/pdf/2311.14652v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CL",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14651v1/1.0",
                "title": "History Filtering in Imperfect Information Games: Algorithms and\n  Complexity",
                "year": 2023,
                "abstract": "Historically applied exclusively to perfect information games, depth-limited\nsearch with value functions has been key to recent advances in AI for imperfect\ninformation games. Most prominent approaches with strong theoretical guarantees\nrequire subgame decomposition - a process in which a subgame is computed from\npublic information and player beliefs. However, subgame decomposition can\nitself require non-trivial computations, and its tractability depends on the\nexistence of efficient algorithms for either full enumeration or generation of\nthe histories that form the root of the subgame. Despite this, no formal\nanalysis of the tractability of such computations has been established in prior\nwork, and application domains have often consisted of games, such as poker, for\nwhich enumeration is trivial on modern hardware. Applying these ideas to more\ncomplex domains requires understanding their cost.\n  In this work, we introduce and analyze the computational aspects and\ntractability of filtering histories for subgame decomposition. We show that\nconstructing a single history from the root of the subgame is generally\nintractable, and then provide a necessary and sufficient condition for\nefficient enumeration. We also introduce a novel Markov Chain Monte Carlo-based\ngeneration algorithm for trick-taking card games - a domain where enumeration\nis often prohibitively expensive. Our experiments demonstrate its improved\nscalability in the trick-taking card game Oh Hell. These contributions clarify\nwhen and how depth-limited search via subgame decomposition can be an effective\ntool for sequential decision-making in imperfect information settings.",
                "authors": [
                    "Christopher Solinas",
                    "Douglas Rebstock",
                    "Nathan R. Sturtevant",
                    "Michael Buro"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14651v1",
                    "http://arxiv.org/pdf/2311.14651v1"
                ],
                "primary_category": "cs.GT",
                "categories": [
                    "cs.GT",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14650v2/1.0",
                "title": "GVEL: Fast Graph Loading in Edgelist and Compressed Sparse Row (CSR)\n  formats",
                "year": 2023,
                "abstract": "Efficient IO techniques are crucial in high-performance graph processing\nframeworks like Gunrock and Hornet, as fast graph loading is essential to\nminimize processing time and reduce system/cloud usage charges. This research\nstudy presents approaches for efficiently reading an Edgelist from a text file\nand converting it to a Compressed Sparse Row (CSR) representation. On a server\nwith dual 16-core Intel Xeon Gold 6226R processors and MegaRAID SAS-3 storage,\nour approach, which we term as GVEL, outperforms Hornet, Gunrock, and PIGO by\nsignificant margins in CSR reading, exhibiting an average speedup of 78x, 112x,\nand 1.8x, respectively. For Edgelist reading, GVEL is 2.6x faster than PIGO on\naverage, and achieves a Edgelist read rate of 1.9 billion edges/s. For every\ndoubling of threads, GVEL improves performance at an average rate of 1.9x and\n1.7x for reading Edgelist and reading CSR respectively.",
                "authors": [
                    "Subhajit Sahu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14650v2",
                    "http://arxiv.org/pdf/2311.14650v2"
                ],
                "primary_category": "cs.PF",
                "categories": [
                    "cs.PF",
                    "B.8.2"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14649v1/1.0",
                "title": "Learning in Deep Factor Graphs with Gaussian Belief Propagation",
                "year": 2023,
                "abstract": "We propose an approach to do learning in Gaussian factor graphs. We treat all\nrelevant quantities (inputs, outputs, parameters, latents) as random variables\nin a graphical model, and view both training and prediction as inference\nproblems with different observed nodes. Our experiments show that these\nproblems can be efficiently solved with belief propagation (BP), whose updates\nare inherently local, presenting exciting opportunities for distributed and\nasynchronous training. Our approach can be scaled to deep networks and provides\na natural means to do continual learning: use the BP-estimated parameter\nmarginals of the current task as parameter priors for the next. On a video\ndenoising task we demonstrate the benefit of learnable parameters over a\nclassical factor graph approach and we show encouraging performance of deep\nfactor graphs for continual image classification on MNIST.",
                "authors": [
                    "Seth Nabarro",
                    "Mark van der Wilk",
                    "Andrew J Davison"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14649v1",
                    "http://arxiv.org/pdf/2311.14649v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14648v2/1.0",
                "title": "Calibrated Language Models Must Hallucinate",
                "year": 2023,
                "abstract": "Recent language models generate false but plausible-sounding text with\nsurprising frequency. Such \"hallucinations\" are an obstacle to the usability of\nlanguage-based AI systems and can harm people who rely upon their outputs. This\nwork shows shows that there is an inherent statistical lower-bound on the rate\nthat pretrained language models hallucinate certain types of facts, having\nnothing to do with the transformer LM architecture or data quality. For\n\"arbitrary\" facts whose veracity cannot be determined from the training data,\nwe show that hallucinations must occur at a certain rate for language models\nthat satisfy a statistical calibration condition appropriate for generative\nlanguage models. Specifically, if the maximum probability of any fact is\nbounded, we show that the probability of generating a hallucination is close to\nthe fraction of facts that occur exactly once in the training data (a\n\"Good-Turing\" estimate), even assuming ideal training data without errors.\n  One conclusion is that models pretrained to be sufficiently good predictors\n(i.e., calibrated) may require post-training to mitigate hallucinations on the\ntype of arbitrary facts that tend to appear once in the training set. However,\nour analysis also suggests that there is no statistical reason that pretraining\nwill lead to hallucination on facts that tend to appear more than once in the\ntraining data (like references to publications such as articles and books,\nwhose hallucinations have been particularly notable and problematic) or on\nsystematic facts (like arithmetic calculations). Therefore, different\narchitectures and learning algorithms may mitigate these latter types of\nhallucinations.",
                "authors": [
                    "Adam Tauman Kalai",
                    "Santosh S. Vempala"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14648v2",
                    "http://arxiv.org/pdf/2311.14648v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.11473v1/1.0",
                "title": "Synthetic Shifts to Initial Seed Vector Exposes the Brittle Nature of\n  Latent-Based Diffusion Models",
                "year": 2023,
                "abstract": "Recent advances in Conditional Diffusion Models have led to substantial\ncapabilities in various domains. However, understanding the impact of\nvariations in the initial seed vector remains an underexplored area of concern.\nParticularly, latent-based diffusion models display inconsistencies in image\ngeneration under standard conditions when initialized with suboptimal initial\nseed vectors. To understand the impact of the initial seed vector on generated\nsamples, we propose a reliability evaluation framework that evaluates the\ngenerated samples of a diffusion model when the initial seed vector is\nsubjected to various synthetic shifts. Our results indicate that slight\nmanipulations to the initial seed vector of the state-of-the-art Stable\nDiffusion (Rombach et al., 2022) can lead to significant disturbances in the\ngenerated samples, consequently creating images without the effect of\nconditioning variables. In contrast, GLIDE (Nichol et al., 2022) stands out in\ngenerating reliable samples even when the initial seed vector is transformed.\nThus, our study sheds light on the importance of the selection and the impact\nof the initial seed vector in the latent-based diffusion model.",
                "authors": [
                    "Mao Po-Yuan",
                    "Shashank Kotyan",
                    "Tham Yik Foong",
                    "Danilo Vasconcellos Vargas"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.11473v1",
                    "http://arxiv.org/pdf/2312.11473v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14639v1/1.0",
                "title": "Unsupervised high-throughput segmentation of cells and cell nuclei in\n  quantitative phase images",
                "year": 2023,
                "abstract": "In the effort to aid cytologic diagnostics by establishing automatic single\ncell screening using high throughput digital holographic microscopy for\nclinical studies thousands of images and millions of cells are captured. The\nbottleneck lies in an automatic, fast, and unsupervised segmentation technique\nthat does not limit the types of cells which might occur. We propose an\nunsupervised multistage method that segments correctly without confusing noise\nor reflections with cells and without missing cells that also includes the\ndetection of relevant inner structures, especially the cell nucleus in the\nunstained cell. In an effort to make the information reasonable and\ninterpretable for cytopathologists, we also introduce new cytoplasmic and\nnuclear features of potential help for cytologic diagnoses which exploit the\nquantitative phase information inherent to the measurement scheme. We show that\nthe segmentation provides consistently good results over many experiments on\npatient samples in a reasonable per cell analysis time.",
                "authors": [
                    "Julia Sistermanns",
                    "Ellen Emken",
                    "Gregor Weirich",
                    "Oliver Hayden",
                    "Wolfgang Utschick"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14639v1",
                    "http://arxiv.org/pdf/2311.14639v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "q-bio.CB",
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14787v1/1.0",
                "title": "Rashba splitting in polar-nonpolar sandwich heterostructure : A DFT\n  Study",
                "year": 2023,
                "abstract": "In this study, we employ density functional theory (DFT) based\nfirst-principles calculations to investigate the spin-orbit effects in the\nelectronic structure of a polar-nonpolar sandwich heterostructure namely\nLAO$_{2.5}$/STO$_{5.5}$/LAO$_{2.5}$. Our focus on the Ti-3d bands reveals an\ninverted ordering of the STO-$\\rm t_{2g}$ orbital near the n-type interface,\nconsistent with earlier experimental work. In contrast, toward the p-type\ninterface, the orbital ordering aligns with the natural ordering of STO\norbitals, influenced by crystal field splitting. Interestingly, we have found a\nstrong inter-orbital coupling between $t_{2g}$ and $e_g$ orbital, which has not\nbeen reported earlier in $\\rm SrTiO_3$ based 2D system. Additionally, our\nobservations highlight that the cubic Rashba splitting in this system surpasses\nthe linear Rashba splitting, contrary to experimental findings. This\ncomprehensive analysis contributes to a refined understanding of the role of\norbital mixing in Rashba splitting in the sandwich oxide heterostructures.",
                "authors": [
                    "Sanchari Bhattacharya",
                    "Sanjoy Datta"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14787v1",
                    "http://arxiv.org/pdf/2311.14787v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14636v1/1.0",
                "title": "Baryon Asymmetry from the Decay and Scattering of a Majorana Fermion\n  Pair Coupled to Quarks",
                "year": 2023,
                "abstract": "We compute the baryon asymmetry in decay and scattering processes involving\nthe electromagnetically charge-neutral fermion $\\chi$ that carries nonzero\nbaryon number and interacts with quark-like fermions $U,D$ via a vector-vector\ndimension-six effective operator, in the theory we developed in our earlier\nwork. Majorana masses, that break baryon number, split the Dirac fermion $\\chi$\ninto a pair of Majorana fermions $\\chi_n$ with indefinite baryon number. We\nidentify loop amplitudes for $\\chi_n$ decay and scattering processes that are\nsensitive to the baryon number violation. The phases in the Majorana mass and\ncouplings, in conjunction with a phase of $\\pi/2$ from intermediate onshell\n$U,D$ in the loop, lead to $C$ and $CP$ violation in these processes. For some\nrepresentative parameter choices, we numerically compute the decay and\nscattering baryon asymmetries between the process and its conjugate process,\nand find that the asymmetry generated is phenomenologically very interesting.",
                "authors": [
                    "Shrihari Gopalakrishna",
                    "Rakesh Tibrewala"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14636v1",
                    "http://arxiv.org/pdf/2311.14636v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14635v1/1.0",
                "title": "Automated Detection and Counting of Windows using UAV Imagery based\n  Remote Sensing",
                "year": 2023,
                "abstract": "Despite the technological advancements in the construction and surveying\nsector, the inspection of salient features like windows in an\nunder-construction or existing building is predominantly a manual process.\nMoreover, the number of windows present in a building is directly related to\nthe magnitude of deformation it suffers under earthquakes. In this research, a\nmethod to accurately detect and count the number of windows of a building by\ndeploying an Unmanned Aerial Vehicle (UAV) based remote sensing system is\nproposed. The proposed two-stage method automates the identification and\ncounting of windows by developing computer vision pipelines that utilize data\nfrom UAV's onboard camera and other sensors. Quantitative and Qualitative\nresults show the effectiveness of our proposed approach in accurately detecting\nand counting the windows compared to the existing method.",
                "authors": [
                    "Dhruv Patel",
                    "Shivani Chepuri",
                    "Sarvesh Thakur",
                    "K. Harikumar",
                    "Ravi Kiran S.",
                    "K. Madhava Krishna"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14635v1",
                    "http://arxiv.org/pdf/2311.14635v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14786v1/1.0",
                "title": "GPT-4V Takes the Wheel: Evaluating Promise and Challenges for Pedestrian\n  Behavior Prediction",
                "year": 2023,
                "abstract": "Existing pedestrian behavior prediction methods rely primarily on deep neural\nnetworks that utilize features extracted from video frame sequences. Although\nthese vision-based models have shown promising results, they face limitations\nin effectively capturing and utilizing the dynamic spatio-temporal interactions\nbetween the target pedestrian and its surrounding traffic elements, crucial for\naccurate reasoning. Additionally, training these models requires manually\nannotating domain-specific datasets, a process that is expensive,\ntime-consuming, and difficult to generalize to new environments and scenarios.\nThe recent emergence of Large Multimodal Models (LMMs) offers potential\nsolutions to these limitations due to their superior visual understanding and\ncausal reasoning capabilities, which can be harnessed through semi-supervised\ntraining. GPT-4V(ision), the latest iteration of the state-of-the-art\nLarge-Language Model GPTs, now incorporates vision input capabilities. This\nreport provides a comprehensive evaluation of the potential of GPT-4V for\npedestrian behavior prediction in autonomous driving using publicly available\ndatasets: JAAD, PIE, and WiDEVIEW. Quantitative and qualitative evaluations\ndemonstrate GPT-4V(ision)'s promise in zero-shot pedestrian behavior prediction\nand driving scene understanding ability for autonomous driving. However, it\nstill falls short of the state-of-the-art traditional domain-specific models.\nChallenges include difficulties in handling small pedestrians and vehicles in\nmotion. These limitations highlight the need for further research and\ndevelopment in this area.",
                "authors": [
                    "Jia Huang",
                    "Peng Jiang",
                    "Alvika Gautam",
                    "Srikanth Saripalli"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14786v1",
                    "http://arxiv.org/pdf/2311.14786v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14633v1/1.0",
                "title": "One Strike, You're Out: Detecting Markush Structures in Low\n  Signal-to-Noise Ratio Images",
                "year": 2023,
                "abstract": "Modern research increasingly relies on automated methods to assist\nresearchers. An example of this is Optical Chemical Structure Recognition\n(OCSR), which aids chemists in retrieving information about chemicals from\nlarge amounts of documents. Markush structures are chemical structures that\ncannot be parsed correctly by OCSR and cause errors. The focus of this research\nwas to propose and test a novel method for classifying Markush structures.\nWithin this method, a comparison was made between fixed-feature extraction and\nend-to-end learning (CNN). The end-to-end method performed significantly better\nthan the fixed-feature method, achieving 0.928 (0.035 SD) Macro F1 compared to\nthe fixed-feature method's 0.701 (0.052 SD). Because of the nature of the\nexperiment, these figures are a lower bound and can be improved further. These\nresults suggest that Markush structures can be filtered out effectively and\naccurately using the proposed method. When implemented into OCSR pipelines,\nthis method can improve their performance and use to other researchers.",
                "authors": [
                    "Thomas Jurriaans",
                    "Kinga Szarkowska",
                    "Eric Nalisnick",
                    "Markus Schwoerer",
                    "Camilo Thorne",
                    "Saber Akhondi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14633v1",
                    "http://arxiv.org/pdf/2311.14633v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14631v2/1.0",
                "title": "CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image\n  Personalization",
                "year": 2023,
                "abstract": "We propose CatVersion, an inversion-based method that learns the personalized\nconcept through a handful of examples. Subsequently, users can utilize text\nprompts to generate images that embody the personalized concept, thereby\nachieving text-to-image personalization. In contrast to existing approaches\nthat emphasize word embedding learning or parameter fine-tuning for the\ndiffusion model, which potentially causes concept dilution or overfitting, our\nmethod concatenates embeddings on the feature-dense space of the text encoder\nin the diffusion model to learn the gap between the personalized concept and\nits base class, aiming to maximize the preservation of prior knowledge in\ndiffusion models while restoring the personalized concepts. To this end, we\nfirst dissect the text encoder's integration in the image generation process to\nidentify the feature-dense space of the encoder. Afterward, we concatenate\nembeddings on the Keys and Values in this space to learn the gap between the\npersonalized concept and its base class. In this way, the concatenated\nembeddings ultimately manifest as a residual on the original attention output.\nTo more accurately and unbiasedly quantify the results of personalized image\ngeneration, we improve the CLIP image alignment score based on masks.\nQualitatively and quantitatively, CatVersion helps to restore personalization\nconcepts more faithfully and enables more robust editing.",
                "authors": [
                    "Ruoyu Zhao",
                    "Mingrui Zhu",
                    "Shiyin Dong",
                    "Nannan Wang",
                    "Xinbo Gao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14631v2",
                    "http://arxiv.org/pdf/2311.14631v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14629v1/1.0",
                "title": "Light New Physics in $B\\to K^{(*)}\u03bd\\bar\u03bd$?",
                "year": 2023,
                "abstract": "The study of the rare decays $B\\to K^{(*)} \\nu \\bar\\nu$ offers a window into\nthe dynamics operating at the electroweak scale, allowing studies of the\nStandard Model and searches for heavy new physics. However, the analysis of\nthese decays is also potentially sensitive to the on-shell production of new\nlight bosons $X$ through the process $B\\to K^{(*)} X$. In particular, Belle~II\nhas recently measured $B^+\\to K^+\\nu\\bar\\nu$, finding a $2.8\\sigma$ excess\nunder the assumption of heavy new physics. Since this excess is rather\nlocalized in the kaon energy, a fit that includes the decay mode $B^+\\to K^+ X$\nto the kinematic distributions prefers $m_X\\approx2\\,$GeV with branching\nfraction Br$[B\\to KX]=(8.8\\pm2.5)\\times 10^{-6}$ and a significance of\n$\\approx3.6\\sigma$. However, no excess was found in the BaBar measurements of\n$B\\to K^{(*)} \\nu \\bar\\nu$, and a global analysis of the Belle II and BaBar\ndata leads to Br$[B\\to KX]=(5.1\\pm2.1)\\times 10^{-6}$ with a reduced\nsignificance of $\\approx2.4\\sigma$. We then study various simplified\ndark-flavoured models and present a possible UV completion based on a gauged\n$B_3-L_3$ symmetry, highlighting the discovery potential of dedicated searches\nfor $B\\to K^{(*)}X$ at Belle II.",
                "authors": [
                    "Wolfgang Altmannshofer",
                    "Andreas Crivellin",
                    "Huw Haigh",
                    "Gianluca Inguglia",
                    "Jorge Martin Camalich"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14629v1",
                    "http://arxiv.org/pdf/2311.14629v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14627v3/1.0",
                "title": "A new use of the Kurdyka-Lojasiewicz property to study asymptotic\n  behaviours of some stochastic optimization algorithms in a non-convex\n  differentiable framework",
                "year": 2023,
                "abstract": "The asymptotic analysis of a generic stochastic optimization algorithm mainly\nrelies on the establishment of a specific descent condition. While the\nconvexity assumption allows for technical shortcuts and generally leads to\nstrict convergence, dealing with the non-convex framework, on the contrary,\nrequires the use of specific results as those relying on the\nKurdyka-Lojasiewicz (KL) theory. While such tools have become popular in the\nfield of deterministic optimisation, they are much less widespread in the\nstochastic context and, in this case, the few works making use of them are\nessentially based on trajectory-by-trajectory approaches. In this paper, we\npropose a new methodology, also based on KL theory, for deeper asymptotic\ninvestigations on a stochastic scheme verifying a descent condition. The\nspecificity of our work is here to be of macroscopic nature insofar as our\nstrategy of proof is more in-expectation-based and therefore seems more natural\ntypically with respect to the noise properties, of conditional order,\nencountered in the stochastic literature nowadays.",
                "authors": [
                    "Jean-Baptiste Fest"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14627v3",
                    "http://arxiv.org/pdf/2311.14627v3"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14626v1/1.0",
                "title": "Time-reversal-like degeneracies distinguished by the anomalous Hall\n  effect in a metallic kagome ice compound",
                "year": 2023,
                "abstract": "In magnetic crystals, despite the explicit breaking of time-reversal\nsymmetry, two equilibrium states related by time reversal are always\nenergetically degenerate. In ferromagnets such time-reversal degeneracy can be\nmanifested by hysteresis loops in the magnetic field dependence of the\nmagnetization and, if metallic, in the anomalous Hall effect. Importantly, both\nquantities simply change signs but not their absolute sizes under time\nreversal, which follows from their fundamental definitions. Our integral\nexperimental and theoretical study shows that in the metallic kagome spin ice\nHoAgGe subject to finite magnetic fields parallel to the kagome plane, an\nemergent time-reversal-like degeneracy appears between magnetic states that\nhave the same energy and net magnetization, but different sizes of the\nanomalous Hall effect. These degeneracies are unraveled by finite hysteresis in\nthe field-dependent anomalous Hall effect contrasted with the vanishing\nhysteresis in the magnetization, which appears only at low-temperatures T$<$4K\nwhen the kagome spin ice is fully ordered into $\\sqrt{3}$$\\times$$\\sqrt{3}$\nstate. By explicitly determining the degenerate states and calculating the\ncorresponding physical properties using a tight-binding model, we nailed down\nthe time-reversal-like operation that transforms these degenerate states into\neach other. The operation is related to the nontrivial distortion of the kagome\nlattice in HoAgGe and is effective only because of the richness of degenerate\nstates unique to kagome spin ice. Our work points to the powerful role of the\nanomalous Hall effect to diagnose hidden symmetries in frustrated spin systems.",
                "authors": [
                    "Kan Zhao",
                    "Yoshi Tokiwa",
                    "Hua Chen",
                    "Philipp Gegenwart"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14626v1",
                    "http://arxiv.org/pdf/2311.14626v1"
                ],
                "primary_category": "cond-mat.str-el",
                "categories": [
                    "cond-mat.str-el",
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00043v1/1.0",
                "title": "Who is leading in AI? An analysis of industry AI research",
                "year": 2023,
                "abstract": "AI research is increasingly industry-driven, making it crucial to understand\ncompany contributions to this field. We compare leading AI companies by\nresearch publications, citations, size of training runs, and contributions to\nalgorithmic innovations. Our analysis reveals the substantial role played by\nGoogle, OpenAI and Meta. We find that these three companies have been\nresponsible for some of the largest training runs, developed a large fraction\nof the algorithmic innovations that underpin large language models, and led in\nvarious metrics of citation impact. In contrast, leading Chinese companies such\nas Tencent and Baidu had a lower impact on many of these metrics compared to US\ncounterparts. We observe many industry labs are pursuing large training runs,\nand that training runs from relative newcomers -- such as OpenAI and Anthropic\n-- have matched or surpassed those of long-standing incumbents such as Google.\nThe data reveals a diverse ecosystem of companies steering AI progress, though\nUS labs such as Google, OpenAI and Meta lead across critical metrics.",
                "authors": [
                    "Ben Cottier",
                    "Tamay Besiroglu",
                    "David Owen"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00043v1",
                    "http://arxiv.org/pdf/2312.00043v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14621v1/1.0",
                "title": "Received Signal and Channel Parameter Estimation in Molecular\n  Communications",
                "year": 2023,
                "abstract": "Molecular communication (MC) is a paradigm that employs molecules as\ninformation transmitters, hence, requiring unconventional transceivers and\ndetection techniques for the Internet of Bio-Nano Things (IoBNT). In this\nstudy, we provide a novel MC model that incorporates a spherical transmitter\nand receiver with partial absorption. This model offers a more realistic\nrepresentation than receiver architectures in literature, e.g. passive or\nentirely absorbing configurations. An optimization-based technique utilizing\nparticle swarm optimization (PSO) is employed to accurately estimate the\ncumulative number of molecules received. This technique yields nearly constant\ncorrection parameters and demonstrates a significant improvement of 5 times in\nterms of root mean square error (RMSE). The estimated channel model provides an\napproximate analytical impulse response; hence, it is used for estimating\nchannel parameters such as distance, diffusion coefficient, or a combination of\nboth. We apply iterative maximum likelihood estimation (MLE) for the parameter\nestimation, which gives consistent errors compared to the estimated Cramer-Rao\nLower Bound (CLRB).",
                "authors": [
                    "O. Tansel Baydas",
                    "Ozgur B. Akan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14621v1",
                    "http://arxiv.org/pdf/2311.14621v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14617v1/1.0",
                "title": "Neural Style Transfer for Computer Games",
                "year": 2023,
                "abstract": "Neural Style Transfer (NST) research has been applied to images, videos, 3D\nmeshes and radiance fields, but its application to 3D computer games remains\nrelatively unexplored. Whilst image and video NST systems can be used as a\npost-processing effect for a computer game, this results in undesired artefacts\nand diminished post-processing effects. Here, we present an approach for\ninjecting depth-aware NST as part of the 3D rendering pipeline. Qualitative and\nquantitative experiments are used to validate our in-game stylisation\nframework. We demonstrate temporally consistent results of artistically\nstylised game scenes, outperforming state-of-the-art image and video NST\nmethods.",
                "authors": [
                    "Eleftherios Ioannou",
                    "Steve Maddock"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14617v1",
                    "http://arxiv.org/pdf/2311.14617v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.02178v1/1.0",
                "title": "Hierarchical ML Codebook Design for Extreme MIMO Beam Management",
                "year": 2023,
                "abstract": "Beam management is a strategy to unify beamforming and channel state\ninformation (CSI) acquisition with large antenna arrays in 5G. Codebooks serve\nmultiple uses in beam management including beamforming reference signals, CSI\nreporting, and analog beam training. In this paper, we propose and evaluate a\nmachine learning-refined codebook design process for extremely large\nmultiple-input multiple-output (X-MIMO) systems. We propose a neural network\nand beam selection strategy to design the initial access and refinement\ncodebooks using end-to-end learning from beamspace representations. The\nalgorithm, called Extreme-Beam Management (X-BM), can significantly improve the\nperformance of extremely large arrays as envisioned for 6G and capture\nrealistic wireless and physical layer aspects. Our results show an 8dB\nimprovement in initial access and overall effective spectral efficiency\nimprovements compared to traditional codebook methods.",
                "authors": [
                    "Ryan M. Dreifuerst",
                    "Robert W. Heath Jr"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.02178v1",
                    "http://arxiv.org/pdf/2312.02178v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.IT",
                    "cs.LG",
                    "cs.SY",
                    "eess.SY",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14783v1/1.0",
                "title": "cryptoRAN: A review on cryptojacking and ransomware attacks w.r.t.\n  banking industry -- threats, challenges, & problems",
                "year": 2023,
                "abstract": "In the banking industry, ransomware is a well-known threat, but since the\nbeginning of 2022, cryptojacking, an emerging threat is posing a considerable\nchallenge to the banking industry. Ransomware has variants, and the attackers\nkeep changing the nature of these variants. This review paper studies the\ncomplex background of these two threats and scrutinizes the actual challenges,\nand problems that the banking industry and financial institutions face. These\nthreats, though distinct in nature, share commonalities, such as financial\nmotivations and sophisticated techniques. We focus on examining the newly\nemerged variants of ransomware while we provide a comprehensive idea of\ncryptojacking and its nature. This paper involves a detailed breakdown of the\nspecific threats posed by cryptojacking and ransomware. It explores the\ntechniques cybercriminals use, the variabilities they look for, and the\npotential consequences for financial institutions and their customers. This\npaper also finds out how cybercriminals change their techniques following the\nsecurity upgrades, and why financial firms including banks need to be proactive\nabout cyber threats. Additionally, this paper reviews the background study of\nsome existing papers, finds the research gaps that need to be addressed, and\nprovides suggestions including a conclusion and future scope on those disputes.\nLastly, we introduce a Digital Forensics and Incident Response (DFIR) approach\nfor up-to-date cyber threat hunting processes for minimizing both cryptojacking\nand ransomware attacks in the banking industry.",
                "authors": [
                    "Naresh Kshetri",
                    "Mir Mehedi Rahman",
                    "Sayed Abu Sayeed",
                    "Irin Sultana"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14783v1",
                    "http://arxiv.org/pdf/2311.14783v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14601v1/1.0",
                "title": "A Metalearned Neural Circuit for Nonparametric Bayesian Inference",
                "year": 2023,
                "abstract": "Most applications of machine learning to classification assume a closed set\nof balanced classes. This is at odds with the real world, where class\noccurrence statistics often follow a long-tailed power-law distribution and it\nis unlikely that all classes are seen in a single sample. Nonparametric\nBayesian models naturally capture this phenomenon, but have significant\npractical barriers to widespread adoption, namely implementation complexity and\ncomputational inefficiency. To address this, we present a method for extracting\nthe inductive bias from a nonparametric Bayesian model and transferring it to\nan artificial neural network. By simulating data with a nonparametric Bayesian\nprior, we can metalearn a sequence model that performs inference over an\nunlimited set of classes. After training, this \"neural circuit\" has distilled\nthe corresponding inductive bias and can successfully perform sequential\ninference over an open set of classes. Our experimental results show that the\nmetalearned neural circuit achieves comparable or better performance than\nparticle filter-based methods for inference in these models while being faster\nand simpler to use than methods that explicitly incorporate Bayesian\nnonparametric inference.",
                "authors": [
                    "Jake C. Snell",
                    "Gianluca Bencomo",
                    "Thomas L. Griffiths"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14601v1",
                    "http://arxiv.org/pdf/2311.14601v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NE",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.05258v1/1.0",
                "title": "Automated Small Kidney Cancer Detection in Non-Contrast Computed\n  Tomography",
                "year": 2023,
                "abstract": "This study introduces an automated pipeline for renal cancer (RC) detection\nin non-contrast computed tomography (NCCT). In the development of our pipeline,\nwe test three detections models: a shape model, a 2D-, and a 3D axial-sample\nmodel. Training (n=1348) and testing (n=64) data were gathered from open\nsources (KiTS23, Abdomen1k, CT-ORG) and Cambridge University Hospital (CUH).\nResults from cross-validation and testing revealed that the 2D axial sample\nmodel had the highest small ($\\leq$40mm diameter) RC detection area under the\ncurve (AUC) of 0.804. Our pipeline achieves 61.9\\% sensitivity and 92.7\\%\nspecificity for small kidney cancers on unseen test data. Our results are much\nmore accurate than previous attempts to automatically detect small renal\ncancers in NCCT, the most likely imaging modality for RC screening. This\npipeline offers a promising advance that may enable screening for kidney\ncancers.",
                "authors": [
                    "William McGough",
                    "Thomas Buddenkotte",
                    "Stephan Ursprung",
                    "Zeyu Gao",
                    "Grant Stewart",
                    "Mireia Crispin-Ortuzar"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.05258v1",
                    "http://arxiv.org/pdf/2312.05258v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG",
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14598v1/1.0",
                "title": "Target-driven splitting SPH optimization of thermal conductivity\n  distribution",
                "year": 2023,
                "abstract": "Efficiently enhancing heat conduction through optimized distribution of a\nlimited quantity of high thermal conductivity material is paramount in cooling\nelectronic devices and numerous other applications. This paper introduces a\ntarget-driven all-at-once approach for PDE-constrained optimization and derives\na splitting smoothed particle hydrodynamics (SPH) method for optimizing the\ndistribution of thermal conductivity in heat conduction problems. In this\nmethod, the optimization iteration of the system is split into several easily\naddressed steps. A targeting step is employed to progressively enforce the\ndirect target, which potentially leads to increased PDE residuals. Then, these\nresiduals are recovered through an evolution step of the design variable. After\nthis, a PDE solution step is carried out to further decrease the PDE residuals,\nand the system is ready for the next iteration. Unlike the simulation-based\napproaches, the present method does not rely on the adjoint state equation and\nconverged state variable field in each iteration, and the optimization process\nis significantly simplified and accelerated. With the utilization of an\nimplicit SPH splitting operator and a general numerical regularization\nformulation, the information propagation is further accelerated and the\nnumerical stability is greatly enhanced. Typical examples of heat conduction\noptimization demonstrate that the current method yields optimal results\ncomparable to previous methods and exhibits considerable computational\nefficiency. Moreover, the optimal results feature more moderate extreme values,\nwhich offers distinct advantages for the easier selection of appropriate\nmaterial with high thermal conductivity.",
                "authors": [
                    "Bo Zhang",
                    "Chi Zhang",
                    "Xiangyu Hu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14598v1",
                    "http://arxiv.org/pdf/2311.14598v1"
                ],
                "primary_category": "cs.CE",
                "categories": [
                    "cs.CE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14782v1/1.0",
                "title": "One Fits All: Universal Time Series Analysis by Pretrained LM and\n  Specially Designed Adaptors",
                "year": 2023,
                "abstract": "Despite the impressive achievements of pre-trained models in the fields of\nnatural language processing (NLP) and computer vision (CV), progress in the\ndomain of time series analysis has been limited. In contrast to NLP and CV,\nwhere a single model can handle various tasks, time series analysis still\nrelies heavily on task-specific methods for activities such as classification,\nanomaly detection, forecasting, and few-shot learning. The primary obstacle to\ndeveloping a pre-trained model for time series analysis is the scarcity of\nsufficient training data. In our research, we overcome this obstacle by\nutilizing pre-trained models from language or CV, which have been trained on\nbillions of data points, and apply them to time series analysis. We assess the\neffectiveness of the pre-trained transformer model in two ways. Initially, we\nmaintain the original structure of the self-attention and feedforward layers in\nthe residual blocks of the pre-trained language or image model, using the\nFrozen Pre-trained Transformer (FPT) for time series analysis with the addition\nof projection matrices for input and output. Additionally, we introduce four\nunique adapters, designed specifically for downstream tasks based on the\npre-trained model, including forecasting and anomaly detection. These adapters\nare further enhanced with efficient parameter tuning, resulting in superior\nperformance compared to all state-of-the-art methods.Our comprehensive\nexperimental studies reveal that (a) the simple FPT achieves top-tier\nperformance across various time series analysis tasks; and (b) fine-tuning the\nFPT with the custom-designed adapters can further elevate its performance,\noutshining specialized task-specific models.",
                "authors": [
                    "Tian Zhou",
                    "Peisong Niu",
                    "Xue Wang",
                    "Liang Sun",
                    "Rong Jin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14782v1",
                    "http://arxiv.org/pdf/2311.14782v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14594v1/1.0",
                "title": "MABFuzz: Multi-Armed Bandit Algorithms for Fuzzing Processors",
                "year": 2023,
                "abstract": "As the complexities of processors keep increasing, the task of effectively\nverifying their integrity and security becomes ever more daunting. The\nintricate web of instructions, microarchitectural features, and\ninterdependencies woven into modern processors pose a formidable challenge for\neven the most diligent verification and security engineers. To tackle this\ngrowing concern, recently, researchers have developed fuzzing techniques\nexplicitly tailored for hardware processors. However, a prevailing issue with\nthese hardware fuzzers is their heavy reliance on static strategies to make\ndecisions in their algorithms. To address this problem, we develop a novel\ndynamic and adaptive decision-making framework, MABFuzz, that uses multi-armed\nbandit (MAB) algorithms to fuzz processors. MABFuzz is agnostic to, and hence,\napplicable to, any existing hardware fuzzer. In the process of designing\nMABFuzz, we encounter challenges related to the compatibility of MAB algorithms\nwith fuzzers and maximizing their efficacy for fuzzing. We overcome these\nchallenges by modifying the fuzzing process and tailoring MAB algorithms to\naccommodate special requirements for hardware fuzzing.\n  We integrate three widely used MAB algorithms in a state-of-the-art hardware\nfuzzer and evaluate them on three popular RISC-V-based processors. Experimental\nresults demonstrate the ability of MABFuzz to cover a broader spectrum of\nprocessors' intricate landscapes and doing so with remarkable efficiency. In\nparticular, MABFuzz achieves up to 308x speedup in detecting vulnerabilities\nand up to 5x speedup in achieving coverage compared to a state-of-the-art\ntechnique.",
                "authors": [
                    "Vasudev Gohil",
                    "Rahul Kande",
                    "Chen Chen",
                    "Ahmad-Reza Sadeghi",
                    "Jeyavijayan Rajendran"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14594v1",
                    "http://arxiv.org/pdf/2311.14594v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14593v1/1.0",
                "title": "Visualizing Plasma Physics Simulations in Immersive Environments",
                "year": 2023,
                "abstract": "Plasma physics simulations create complex datasets for which researchers need\nstate-of-the-art visualization tools to gain insights. These datasets are 3D in\nnature but are commonly depicted and analyzed using 2D idioms displayed on 2D\nscreens. These offer limited understandability in a domain where spatial\nawareness is key. Virtual reality (VR) can be used as an alternative to\nconventional means for analyzing such datasets. VR has been known to improve\ndepth and spatial relationship perception, which are fundamental for obtaining\ninsights into 3D plasma morphology. Likewise, VR can potentially increase user\nengagement by offering more immersive and enjoyable experiences. Methods This\nstudy presents PlasmaVR, a proof-of-concept VR tool for visualizing datasets\nresulting from plasma physics simulations. It enables immersive\nmultidimensional data visualization of particles, scalar, and vector fields and\nuses a more natural interface. The study includes user evaluation with domain\nexperts where PlasmaVR was employed to assess the possible benefits of\nimmersive environments in plasma physics visualization. The experimental group\ncomprised five plasma physics researchers who were asked to perform tasks\ndesigned to represent their typical analysis workflow. To assess the\nsuitability of the prototype for the different types of tasks, a set of\nobjective metrics, such as completion time and number of errors, were measured.\nThe prototype's usability was also evaluated using a standard System Usability\nSurvey questionnaire.",
                "authors": [
                    "Nuno Verdelho Trindade",
                    "Oscar Amaro",
                    "David Bras",
                    "Daniel Goncalves",
                    "Jo\u00e3o Madeiras Pereira",
                    "Alfredo Ferreira"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14593v1",
                    "http://arxiv.org/pdf/2311.14593v1"
                ],
                "primary_category": "cs.GR",
                "categories": [
                    "cs.GR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14591v1/1.0",
                "title": "Cooperative Multi-Monostatic Sensing for Object Localization in 6G\n  Networks",
                "year": 2023,
                "abstract": "Enabling passive sensing of the environment using cellular base stations\n(BSs) will be one of the disruptive features of the sixth-generation (6G)\nnetworks. However, accurate localization and positioning of objects are\nchallenging to achieve as multipath significantly degrades the reflected echos.\nExisting localization techniques perform well under the assumption of large\nbandwidth available but perform poorly in bandwidth-limited scenarios. To\nalleviate this problem, in this work, we introduce a 5G New Radio (NR)-based\ncooperative multi-monostatic sensing framework for passive target localization\nthat operates in the Frequency Range 1 (FR1) band. We propose a novel\nfusion-based estimation process that can mitigate the effect of multipath by\nassigning appropriate weight to the range estimation of each BS. Extensive\nsimulation results using ray-tracing demonstrate the efficacy of the proposed\nmulti-sensing framework in bandwidth-limited scenarios.",
                "authors": [
                    "Maximiliano Rivera Figueroa",
                    "Pradyumna Kumar Bishoyi",
                    "Marina Petrova"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14591v1",
                    "http://arxiv.org/pdf/2311.14591v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14780v1/1.0",
                "title": "Wavelength-multiplexed Multi-mode EUV Reflection Ptychography based on\n  Automatic-Differentiation",
                "year": 2023,
                "abstract": "Ptychographic extreme ultraviolet (EUV) diffractive imaging has emerged as a\npromising candidate for the next-generation metrology solutions in the\nsemiconductor industry, as it can image wafer samples in reflection geometry at\nthe nanoscale. This technique has surged attention recently, owing to the\nsignificant progress in high-harmonic generation (HHG) EUV sources and\nadvancements in both hardware and software for computation.\n  In this study, a novel algorithm is introduced and tested, which enables\nwavelength-multiplexed reconstruction that enhances the measurement throughput\nand introduces data diversity, allowing the accurate characterisation of sample\nstructures. To tackle the inherent instabilities of the HHG source, a modal\napproach was adopted, which represents the cross-density function of the\nillumination by a series of mutually incoherent and independent spatial modes.\n  The proposed algorithm was implemented on a mainstream machine learning\nplatform, which leverages automatic differentiation to manage the drastic\ngrowth in model complexity and expedites the computation using GPU\nacceleration. By optimising over 200 million parameters, we demonstrate the\nalgorithm's capacity to accommodate experimental uncertainties and achieve a\nresolution approaching the diffraction limit in reflection geometry. The\nreconstruction of wafer samples with 20-nm heigh patterned gold structures on a\nsilicon substrate highlights our ability to handle complex physical\ninterrelations involving a multitude of parameters. These results establish\nptychography as an efficient and accurate metrology tool.",
                "authors": [
                    "Yifeng Shao",
                    "Sven Weerdenburg",
                    "Jacob Seifert",
                    "H. Paul Urbach",
                    "Allard P. Mosk",
                    "Wim Coene"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14780v1",
                    "http://arxiv.org/pdf/2311.14780v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14583v1/1.0",
                "title": "GPT Struct Me: Probing GPT Models on Narrative Entity Extraction",
                "year": 2023,
                "abstract": "The importance of systems that can extract structured information from\ntextual data becomes increasingly pronounced given the ever-increasing volume\nof text produced on a daily basis. Having a system that can effectively extract\nsuch information in an interoperable manner would be an asset for several\ndomains, be it finance, health, or legal. Recent developments in natural\nlanguage processing led to the production of powerful language models that can,\nto some degree, mimic human intelligence. Such effectiveness raises a pertinent\nquestion: Can these models be leveraged for the extraction of structured\ninformation? In this work, we address this question by evaluating the\ncapabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,\ncommonly known as ChatGPT -- in the extraction of narrative entities, namely\nevents, participants, and temporal expressions. This study is conducted on the\nText2Story Lusa dataset, a collection of 119 Portuguese news articles whose\nannotation framework includes a set of entity structures along with several\ntags and attribute values. We first select the best prompt template through an\nablation study over prompt components that provide varying degrees of\ninformation on a subset of documents of the dataset. Subsequently, we use the\nbest templates to evaluate the effectiveness of the models on the remaining\ndocuments. The results obtained indicate that GPT models are competitive with\nout-of-the-box baseline systems, presenting an all-in-one alternative for\npractitioners with limited resources. By studying the strengths and limitations\nof these models in the context of information extraction, we offer insights\nthat can guide future improvements and avenues to explore in this field.",
                "authors": [
                    "Hugo Sousa",
                    "Nuno Guimar\u00e3es",
                    "Al\u00edpio Jorge",
                    "Ricardo Campos"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/WI-IAT59888.2023.00063",
                    "http://arxiv.org/abs/2311.14583v1",
                    "http://arxiv.org/pdf/2311.14583v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14582v1/1.0",
                "title": "Theoretical investigation of slow gain recovery of quantum cascade\n  lasers observed in pump-probe experiment",
                "year": 2023,
                "abstract": "Time-resolved spectroscopy-based pump-probe experiments performed on quantum\ncascade lasers (QCLs) exhibit an initial fast gain recovery followed by a slow\ntail such that the equilibrium gain is not recovered in a cavity round-trip\ntime. This ultra-slow gain recovery or non-recovered gain cannot be explained\nby only the intersubband carrier dynamics of QCLs. This work shows that the\nFabry-Perot cavity dynamics and localized intersubband electron heating of QCLs\nare essential in ultra-slow and nonrecovered gain recovery. We developed a\ncomprehensive model, coupling cavity dynamics to the intersubband electrons'\nthermal evolution. We employ a four-level coupled Maxwell-Bloch model that\nconsiders temperature-dependent scattering and transport mechanisms in\ncalculating the gain recovery dynamics. If an intense pump pulse electrically\npumped close to the threshold propagates in the forward direction after being\ncoupled into the cavity, the reflected pump pulse will significantly deplete\nthe gain medium while propagating in the backward direction. Additionally, we\nshow that the intersubband electron sustains a localized high temperature even\nafter the pump pulse has left, which affects the overall carrier dynamics and\nleads to an ultra-slow gain recovery process. At near-perfect reflectivity, we\nobserve a gain depletion of 4% for 2 mm QCL. We further demonstrate that an\nadditional 10% gain depletion of probe pulse is seen at a steady state when the\nlaser is pumped at 1.6 times the threshold compared to the case where the hot\nelectron effect is not considered.",
                "authors": [
                    "Mrinmoy Kundu",
                    "Aroni Ghosh",
                    "Abdullah Jubair Bin Iqbal",
                    "Muhammad Anisuzzaman Talukder"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14582v1",
                    "http://arxiv.org/pdf/2311.14582v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14580v1/1.0",
                "title": "Large Language Models as Automated Aligners for benchmarking\n  Vision-Language Models",
                "year": 2023,
                "abstract": "With the advancements in Large Language Models (LLMs), Vision-Language Models\n(VLMs) have reached a new level of sophistication, showing notable competence\nin executing intricate cognition and reasoning tasks. However, existing\nevaluation benchmarks, primarily relying on rigid, hand-crafted datasets to\nmeasure task-specific performance, face significant limitations in assessing\nthe alignment of these increasingly anthropomorphic models with human\nintelligence. In this work, we address the limitations via Auto-Bench, which\ndelves into exploring LLMs as proficient aligners, measuring the alignment\nbetween VLMs and human intelligence and value through automatic data curation\nand assessment. Specifically, for data curation, Auto-Bench utilizes LLMs\n(e.g., GPT-4) to automatically generate a vast set of question-answer-reasoning\ntriplets via prompting on visual symbolic representations (e.g., captions,\nobject locations, instance relationships, and etc.). The curated data closely\nmatches human intent, owing to the extensive world knowledge embedded in LLMs.\nThrough this pipeline, a total of 28.5K human-verified and 3,504K unfiltered\nquestion-answer-reasoning triplets have been curated, covering 4 primary\nabilities and 16 sub-abilities. We subsequently engage LLMs like GPT-3.5 to\nserve as judges, implementing the quantitative and qualitative automated\nassessments to facilitate a comprehensive evaluation of VLMs. Our validation\nresults reveal that LLMs are proficient in both evaluation data curation and\nmodel assessment, achieving an average agreement rate of 85%. We envision\nAuto-Bench as a flexible, scalable, and comprehensive benchmark for evaluating\nthe evolving sophisticated VLMs.",
                "authors": [
                    "Yuanfeng Ji",
                    "Chongjian Ge",
                    "Weikai Kong",
                    "Enze Xie",
                    "Zhengying Liu",
                    "Zhengguo Li",
                    "Ping Luo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14580v1",
                    "http://arxiv.org/pdf/2311.14580v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14576v1/1.0",
                "title": "Physics-Informed Tensor Basis Neural Network for Turbulence Closure\n  Modeling",
                "year": 2023,
                "abstract": "Despite the increasing availability of high-performance computational\nresources, Reynolds-Averaged Navier-Stokes (RANS) simulations remain the\nworkhorse for the analysis of turbulent flows in real-world applications.\nLinear eddy viscosity models (LEVM), the most commonly employed model type,\ncannot accurately predict complex states of turbulence. This work combines a\ndeep-neural-network-based, nonlinear eddy viscosity model with turbulence\nrealizability constraints as an inductive bias in order to yield improved\npredictions of the anisotropy tensor. Using visualizations based on the\nbarycentric map, we show that the proposed machine learning method's anisotropy\ntensor predictions offer a significant improvement over all LEVMs in\ntraditionally challenging cases with surface curvature and flow separation.\nHowever, this improved anisotropy tensor does not, in general, yield improved\nmean-velocity and pressure field predictions in comparison with the\nbest-performing LEVM.",
                "authors": [
                    "Leon Riccius",
                    "Atul Agrawal",
                    "Phaedon-Stelios Koutsourelakis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14576v1",
                    "http://arxiv.org/pdf/2311.14576v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "physics.comp-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14575v1/1.0",
                "title": "Oriented singquandles and related algebraic structures",
                "year": 2023,
                "abstract": "In this paper we consider the algebraic structures related to invariants of\ntopological structures introduced respectively in [CEKL22] and [ADEM19]. Our\nmain results is to show how all these structures are closely related to each\nother using the language of binary operations.",
                "authors": [
                    "Marco Bonatto"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14575v1",
                    "http://arxiv.org/pdf/2311.14575v1"
                ],
                "primary_category": "math.GR",
                "categories": [
                    "math.GR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14561v1/1.0",
                "title": "Quantum Coding with Finite Thermodynamic Resources",
                "year": 2023,
                "abstract": "Quantum direct coding or Schumacher compression generalised the ideas of\nShannon theory, gave an operational meaning to the von Neumann entropy and\nestablished the term qubit. But remembering that information processing is\ncarried out by physical processes prompts one to wonder what thermodynamic\nresources are required to compress quantum information and how they constrain\none's ability to perform this task. That is, if Alice and Bob only have access\nto thermal quantum states and clocks with finite accuracy, how well can they\nmeasure, encode and decode pure quantum state messages? In this work we examine\nthese questions by modelling Alice's typical measurement as a unitary involving\na measurement probe, investigating imperfect timekeeping on encoding and\ndecoding and considering the role of temperature in Bob's appended qubits. In\ndoing so, we derive fidelity bounds for this protocol involving the\ncorrelations Alice can form with their measurement probe, the variance of the\nclock's ticks and the temperature of Bob's qubits. Finally, we give an insight\ninto the entropy produced by these two agents throughout the compression\nprotocol by relating the resources they use to a quantum thermodynamic cooling\nprotocol.",
                "authors": [
                    "Jake Xuereb",
                    "Tiago Debarba",
                    "Marcus Huber",
                    "Paul Erker"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14561v1",
                    "http://arxiv.org/pdf/2311.14561v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14778v1/1.0",
                "title": "Anomaly detection in cross-country money transfer temporal networks",
                "year": 2023,
                "abstract": "During the last decades, Anti-Financial Crime (AFC) entities and Financial\nInstitutions have put a constantly increasing effort to reduce financial crime\nand detect fraudulent activities, that are changing and developing in extremely\ncomplex ways. We propose an anomaly detection approach based on network\nanalysis to help AFC officers navigating through the high load of information\nthat is typical of AFC data-driven scenarios. By experimenting on a large\nfinancial dataset of more than 80M cross-country wire transfers, we leverage on\nthe properties of complex networks to develop a tool for explainable anomaly\ndetection, that can help in identifying outliers that could be engaged in\npotentially malicious activities according to financial regulations. We\nidentify a set of network centrality measures that provide useful insights on\nindividual nodes; by keeping track of the evolution over time of the\ncentrality-based node rankings, we are able to highlight sudden and unexpected\nchanges in the roles of individual nodes that deserve further attention by AFC\nofficers. Such changes can hardly be noticed by means of current AFC practices,\nthat sometimes can lack a higher-level, global vision of the system. This\napproach represents a preliminary step in the automation of AFC and AML\nprocesses, serving the purpose of facilitating the work of AFC officers by\nproviding them with a top-down view of the picture emerging from financial\ndata.",
                "authors": [
                    "Salvatore Vilella",
                    "Arthur Thomas Edward Capozzi Lupi",
                    "Marco Fornasiero",
                    "Dario Moncalvo",
                    "Valeria Ricci",
                    "Silvia Ronchiadin",
                    "Giancarlo Ruffo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14778v1",
                    "http://arxiv.org/pdf/2311.14778v1"
                ],
                "primary_category": "cs.SI",
                "categories": [
                    "cs.SI",
                    "cs.CE",
                    "cs.IR",
                    "I.2.1; H.3.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14556v1/1.0",
                "title": "Binary central stars of planetary nebulae in the Large Magellanic Cloud",
                "year": 2023,
                "abstract": "Close binary central stars of planetary nebulae (PNe) must have formed\nthrough a common envelope evolution during the giant phase experienced by one\nof the stars. Transfer of the angular momentum from the binary system to the\nenvelope leads to the shortening of the binary separations from the radius of\nred giant to the radius of the order of few tenths of AU. Thus, close binary\ncentral stars of planetary nebulae are laboratories to study the common\nenvelope phase of evolution. The close binary fraction in the Galaxy has been\nmeasured in various sky surveys, but the close binary fraction is not yet well\nconstrained for the Magellanic Clouds, and our results may help the study of\ncommon envelope evolution in low-metallicity environments. This paper presents\na continuation of our study of variability in the Magellanic Cloud planetary\nnebulae on the basis of data from the OGLE survey. Previously, we had analysed\nthe OGLE data in the Small Magellanic Cloud. Here, the study is extended to the\nLarge Magellanic Cloud (LMC). In this paper we search for close binary central\nstars with the aim to constrain the binary fraction and period distribution in\nthe LMC. We identified 290 counterparts of PNe in the LMC in the I-band images\nfrom the OGLE-III and OGLE-IV surveys. However, the light curves of ten objects\nwere not accessible in the OGLE database, and thus we analysed the time series\nphotometry of 280 PNe. In total, 32 variables were found, but 5 of them turned\nout to be foreground objects. Another 18 objects show irregular or regular\nvariability that is not attributable to the binarity of their central stars.\nTheir status and the nature of their variability will be verified in the\nfollow-up paper. Nine binary central stars of PNe with periods between 0.24 and\n23.6 days were discovered. The obtained fraction for the LMC PNe is\n3.3^(+2.6)_(-1.6)% without correcting for incompleteness.",
                "authors": [
                    "M. G\u0142adkowski",
                    "M. Hajduk",
                    "R. Smolec",
                    "R. Szczerba",
                    "I. Soszy\u0144ski"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14556v1",
                    "http://arxiv.org/pdf/2311.14556v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14777v1/1.0",
                "title": "From Text to Image: Exploring GPT-4Vision's Potential in Advanced\n  Radiological Analysis across Subspecialties",
                "year": 2023,
                "abstract": "The study evaluates and compares GPT-4 and GPT-4Vision for radiological\ntasks, suggesting GPT-4Vision may recognize radiological features from images,\nthereby enhancing its diagnostic potential over text-based descriptions.",
                "authors": [
                    "Felix Busch",
                    "Tianyu Han",
                    "Marcus Makowski",
                    "Daniel Truhn",
                    "Keno Bressem",
                    "Lisa Adams"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14777v1",
                    "http://arxiv.org/pdf/2311.14777v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16177v1/1.0",
                "title": "A hybrid local search algorithm for the Continuous Energy-Constrained\n  Scheduling Problem",
                "year": 2023,
                "abstract": "We consider the Continuous Energy-Constrained Scheduling Problem (CECSP). A\nset of jobs has to be processed on a continuous, shared resource. A schedule\nfor a job consists of a start time, completion time, and a resource consumption\nprofile. We want to find a schedule such that: each job does not start before\nits release time, is completed before its deadline, satisfies its full resource\nrequirement, and respects its lower and upper bounds on resource consumption\nduring processing. Our objective is to minimize the total weighted completion\ntime. We present a hybrid local search approach, using simulated annealing and\nlinear programming, and compare it to a mixed-integer linear programming (MILP)\nformulation. We show that the hybrid local search approach matches the MILP\nformulation in solution quality for small instances, and is able to find a\nfeasible solution for larger instances in reasonable time.",
                "authors": [
                    "Roel Brouwer",
                    "Marjan van den Akker",
                    "Han Hoogeveen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16177v1",
                    "http://arxiv.org/pdf/2311.16177v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14553v1/1.0",
                "title": "Analyzing Cross-Phase Effects of Reactive Power Intervention on\n  Distribution Voltage Control",
                "year": 2023,
                "abstract": "Increasing photovoltaic (PV) penetration in the distribution system can often\nlead to voltage violations. Mitigation of these violations requires reactive\npower intervention from PV inverters. However, the unbalanced nature of the\ndistribution system leads to mixed effects on the voltages of nearby nodes for\neach inverter injecting or absorbing reactive power. In particular, reactive\npower absorption to reduce over-voltage in one phase can exacerbate\nover-voltage in a different phase. In this paper, the factors impacting the\nincremental and decremental voltage effects of reactive power intervention are\nanalyzed in detail. The result of these effects on the distribution system\nperformance is presented to highlight their significance and the need to factor\nthem in for any coordinated voltage control algorithm.",
                "authors": [
                    "Dhaval Dalal",
                    "Anamitra Pal",
                    "Raja Ayyanar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14553v1",
                    "http://arxiv.org/pdf/2311.14553v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14552v2/1.0",
                "title": "Griffon: Spelling out All Object Locations at Any Granularity with Large\n  Language Models",
                "year": 2023,
                "abstract": "Replicating the innate human ability to detect all objects based on free-form\ntexts at any granularity remains a formidable challenge for Vision-Language\nmodels. Current Large Vision Language Models (LVLMs) are predominantly\nconstrained to grounding a single, pre-existing object, relying solely on data\nfrom Referring Expression Comprehension tasks. The limitation leads to a\ncompromise in model design, necessitating the introduction of visual expert\nmodels or the integration of customized head structures. Beyond these\nconstraints, our research delves into the untapped potential of LVLMs and\nuncover their inherent capability for basic object perception, allowing them to\naccurately identify and locate objects of interest. Building on this insight,\nwe introduce a novel language-prompted localization dataset designed to fully\nunleash the capabilities of LVLMs in integrating fine-grained object perception\nwith precise location awareness. More importantly, we present\n$\\textbf{Griffon}$, a purely LVLM-based baseline, which does not require the\nintroduction of any special tokens, expert models, or additional detection\nmodules. It simply maintains a consistent structure with popular LVLMs by\nunifying data formats across various localization-related scenarios and is\ntrained end-to-end through a well-designed pipeline. Comprehensive experiments\ndemonstrate that $\\textbf{Griffon}$ not only achieves state-of-the-art\nperformance on the fine-grained RefCOCO series but also approaches the\ncapabilities of the expert model Faster RCNN on the detection benchmark MSCOCO.",
                "authors": [
                    "Yufei Zhan",
                    "Yousong Zhu",
                    "Zhiyang Chen",
                    "Fan Yang",
                    "Ming Tang",
                    "Jinqiao Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14552v2",
                    "http://arxiv.org/pdf/2311.14552v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14551v1/1.0",
                "title": "Laser polarization control of ionization-injected electron beams and\n  x-ray radiation in laser wakefield accelerators",
                "year": 2023,
                "abstract": "In this paper we have studied the influence of the laser polarization on the\ndynamics of the ionization-injected electron beams and subsequently the\nproperties of the emitted betatron radiation in laser wakefield accelerators\n(LWFAs). While ionizing by a strong field laser radiation, generated\nphoto-electrons carry a residual transverse momentum in excess of the\nionization potential via the above threshold ionization process. This above\nthreshold ionization (ATI) momentum explicitly depends on the polarization\nstate of the ionizing laser and eventually governs the dynamics of the electron\nbeam trapped inside the wake potential. In order to systematically investigate\nthe effect of the laser polarization, here, we have employed complete three\ndimensional Particle-in-Cell simulations in the nonlinear bubble regime of the\nLWFAs. We focus, in particular, on the effects the laser polarization has on\nthe ionization injection mechanism, and how these features affect the final\nbeam properties, such as, beam charge, energy, energy spread and transverse\nemittance. We have also found that as the laser polarization gradually changes\nfrom linear to circular, the helicity of the electron trajectory, and hence the\nangular momentum carried by the beam increases significantly. Studies have been\nfurther extended to reveal the effect of the laser polarization on the\nradiation emitted by the accelerated electrons. The far field radiation spectra\nhave been calculated for the linear (LP) and circular polarization (CP) states\nof the laser. It has been shown that the spatial distributions and the\npolarization properties (Stokes parameters) of the emitted radiation for the\nabove two cases are substantially different. Therefore, our study provides a\nfacile and efficient alternative to regulate the properties of the accelerated\nelectron beams and x-ray radiation in LWFAs, utilizing ionization injection\nmechanism.",
                "authors": [
                    "Arghya Mukherjee",
                    "Daniel Seipt"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14551v1",
                    "http://arxiv.org/pdf/2311.14551v1"
                ],
                "primary_category": "physics.plasm-ph",
                "categories": [
                    "physics.plasm-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14550v1/1.0",
                "title": "Dynamics of metrics in measure spaces and scaling entropy",
                "year": 2023,
                "abstract": "This survey is dedicated to a new direction in the theory of dynamical\nsystems: the dynamics of metrics in measure spaces and new (catalytic)\ninvariants of transformations with invariant measure. A space equipped with a\nmeasure and a metric naturally consistent with each other (a metric triple, or\nan $mm$-space) automatically determines the notion of its entropy class, thus\nallowing one to construct a theory of scaling entropy for dynamical systems\nwith invariant measure, which is different and more general compared to the\nShannon-Kolmogorov theory. This possibility was hinted at by Shannon himself,\nbut the hint went unnoticed. The classification of metric triples in terms of\nmatrix distributions presented in this paper was proposed by M. Gromov and A.\nVershik. We describe some corollaries obtained by applying this theory.\n  A brief overview of the paper is presented in the first chapter.",
                "authors": [
                    "A. M. Vershik",
                    "G. A. Veprev",
                    "P. B. Zatitskii"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14550v1",
                    "http://arxiv.org/pdf/2311.14550v1"
                ],
                "primary_category": "math.DS",
                "categories": [
                    "math.DS",
                    "Primary 28C15, 28D05, 37A05, 37A35"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14545v1/1.0",
                "title": "A fuzzy algorithm for image rescaling and its comparison with other\n  methods of digital image processing",
                "year": 2023,
                "abstract": "The aim of this paper is to present a comparison among the fuzzy-type\nalgorithm for image rescaling introduced by Jurio et al., 2011, quoted in the\nlist of references, with some other existing algorithms such as the classical\nbicubic algorithm and the so-called sampling Kantorovich (SK) one. Note that,\nthe SK algorithm is a recent tool for image rescaling and enhancement that\nrevealed to be useful in several applications to real world problems, while\nbicubic algorithm is widely known in the literature. The comparison among the\nabove mentioned algorithms (all implemented by MatLab programming language) has\nbeen done in term of suitable similarity indexes such as the\nPeak-Signal-to-Noise-Ratio (PSNR) and the likelihood index $S$. Moreover, also\nthe CPU time of the considered algorithms has been analysed.",
                "authors": [
                    "Danilo Costarelli",
                    "Anna Rita Sambucini"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14545v1",
                    "http://arxiv.org/pdf/2311.14545v1"
                ],
                "primary_category": "math.FA",
                "categories": [
                    "math.FA",
                    "94A08, 68U10, 41A35, 41A30, 03E72"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14543v1/1.0",
                "title": "Data-Efficient Alignment of Large Language Models with Human Feedback\n  Through Natural Language",
                "year": 2023,
                "abstract": "Learning from human feedback is a prominent technique to align the output of\nlarge language models (LLMs) with human expectations. Reinforcement learning\nfrom human feedback (RLHF) leverages human preference signals that are in the\nform of ranking of response pairs to perform this alignment. However, human\npreference on LLM outputs can come in much richer forms including natural\nlanguage, which may provide detailed feedback on strengths and weaknesses of a\ngiven response. In this work we investigate data efficiency of modeling human\nfeedback that is in natural language. Specifically, we fine-tune an open-source\nLLM, e.g., Falcon-40B-Instruct, on a relatively small amount (1000 records or\neven less) of human feedback in natural language in the form of critiques and\nrevisions of responses. We show that this model is able to improve the quality\nof responses from even some of the strongest LLMs such as ChatGPT, BARD, and\nVicuna, through critique and revision of those responses. For instance, through\none iteration of revision of ChatGPT responses, the revised responses have\n56.6% win rate over the original ones, and this win rate can be further\nimproved to 65.9% after applying the revision for five iterations.",
                "authors": [
                    "Di Jin",
                    "Shikib Mehri",
                    "Devamanyu Hazarika",
                    "Aishwarya Padmakumar",
                    "Sungjin Lee",
                    "Yang Liu",
                    "Mahdi Namazifar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14543v1",
                    "http://arxiv.org/pdf/2311.14543v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14542v1/1.0",
                "title": "ToddlerDiffusion: Flash Interpretable Controllable Diffusion Model",
                "year": 2023,
                "abstract": "Diffusion-based generative models excel in perceptually impressive synthesis\nbut face challenges in interpretability. This paper introduces\nToddlerDiffusion, an interpretable 2D diffusion image-synthesis framework\ninspired by the human generation system. Unlike traditional diffusion models\nwith opaque denoising steps, our approach decomposes the generation process\ninto simpler, interpretable stages; generating contours, a palette, and a\ndetailed colored image. This not only enhances overall performance but also\nenables robust editing and interaction capabilities. Each stage is meticulously\nformulated for efficiency and accuracy, surpassing Stable-Diffusion (LDM).\nExtensive experiments on datasets like LSUN-Churches and COCO validate our\napproach, consistently outperforming existing methods. ToddlerDiffusion\nachieves notable efficiency, matching LDM performance on LSUN-Churches while\noperating three times faster with a 3.76 times smaller architecture. Our source\ncode is provided in the supplementary material and will be publicly accessible.",
                "authors": [
                    "Eslam Mohamed Bakr",
                    "Liangbing Zhao",
                    "Vincent Tao Hu",
                    "Matthieu Cord",
                    "Patrick Perez",
                    "Mohamed Elhoseiny"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14542v1",
                    "http://arxiv.org/pdf/2311.14542v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14540v2/1.0",
                "title": "RDF Stream Taxonomy: Systematizing RDF Stream Types in Research and\n  Practice",
                "year": 2023,
                "abstract": "Over the years, RDF streaming was explored in research and practice from many\nangles, resulting in a wide range of RDF stream definitions. This variety\npresents a major challenge in discussing and integrating streaming solutions,\ndue to the lack of a common language. This work attempts to address this\ncritical research gap, by systematizing RDF stream types present in the\nliterature in a novel taxonomy. The proposed RDF Stream Taxonomy (RDF-STaX) is\nembodied in an OWL 2 DL ontology that follows the FAIR principles, making it\nreadily applicable in practice. Extensive documentation and additional\nresources are provided, to foster the adoption of the ontology. Two realized\nuse cases are presented, demonstrating the usefulness of the resource in\ndiscussing research works and annotating streaming datasets. Another result of\nthis contribution is the novel nanopublications dataset, which serves as a\ncollaborative, living state-of-the-art review of RDF streaming. The aim of\nRDF-STaX is to address a real need of the community for a better way to\nsystematize and describe RDF streams. The resource is designed to help drive\ninnovation in RDF streaming, by fostering scientific discussion, cooperation,\nand tool interoperability.",
                "authors": [
                    "Piotr Sowinski",
                    "Pawel Szmeja",
                    "Maria Ganzha",
                    "Marcin Paprzycki"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14540v2",
                    "http://arxiv.org/pdf/2311.14540v2"
                ],
                "primary_category": "cs.DB",
                "categories": [
                    "cs.DB",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14539v1/1.0",
                "title": "CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue\n  Generation",
                "year": 2023,
                "abstract": "Medical dialogue generation relies on natural language generation techniques\nto enable online medical consultations. Recently, the widespread adoption of\nlarge-scale models in the field of natural language processing has facilitated\nrapid advancements in this technology. Existing medical dialogue models are\nmostly based on BERT and pre-trained on English corpora, but there is a lack of\nhigh-performing models on the task of Chinese medical dialogue generation. To\nsolve the above problem, this paper proposes CMed-GPT, which is the GPT\npre-training language model based on Chinese medical domain text. The model is\navailable in two versions, namely, base and large, with corresponding\nperplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and\nentity embeddings into the dialogue text in a uniform manner to meet the\nrequirements of downstream dialogue generation tasks. By applying both\nfine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.\nThis study not only confirms the exceptional performance of the CMed-GPT model\nin generating Chinese biomedical text but also highlights the advantages of\np-tuning over traditional fine-tuning with prefix prompts. Furthermore, we\nvalidate the significance of incorporating external information in medical\ndialogue generation, which enhances the quality of dialogue generation.",
                "authors": [
                    "Zhijie Qu",
                    "Juan Li",
                    "Zerui Ma",
                    "Jianqiang Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14539v1",
                    "http://arxiv.org/pdf/2311.14539v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14536v1/1.0",
                "title": "Exploring beyond-mean-field logarithmic divergences in Fermi-polaron\n  energy",
                "year": 2023,
                "abstract": "We perform a diagrammatic analysis of the energy of a mobile impurity\nimmersed in a strongly interacting two component Fermi gas to second order in\nthe impurity-bath interaction. These corrections demonstrate divergent behavior\nin the limit of large impurity momentum. We show the fundamental processes\nresponsible for these logarithmically divergent terms.\n  We study the problem in the general case without any assumptions regarding\nthe fermion-fermion interactions in the bath. We show that the divergent term\ncan be summed up to all orders in the Fermi-Fermi interaction and that the\nresulting expression is equivalent to the one obtained in the few body\ncalculation.\n  Finally, we provide a perturbative calculation to the second order in the\nFermi-Fermi interaction in the annex, and we show the diagrams responsible for\nthese terms.",
                "authors": [
                    "Ragheed Alhyder",
                    "Fr\u00e9d\u00e9ric Chevy",
                    "Xavier Leyronas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14536v1",
                    "http://arxiv.org/pdf/2311.14536v1"
                ],
                "primary_category": "cond-mat.quant-gas",
                "categories": [
                    "cond-mat.quant-gas"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14534v1/1.0",
                "title": "Finding Foundation Models for Time Series Classification with a PreText\n  Task",
                "year": 2023,
                "abstract": "Over the past decade, Time Series Classification (TSC) has gained an\nincreasing attention. While various methods were explored, deep learning -\nparticularly through Convolutional Neural Networks (CNNs)-stands out as an\neffective approach. However, due to the limited availability of training data,\ndefining a foundation model for TSC that overcomes the overfitting problem is\nstill a challenging task. The UCR archive, encompassing a wide spectrum of\ndatasets ranging from motion recognition to ECG-based heart disease detection,\nserves as a prime example for exploring this issue in diverse TSC scenarios. In\nthis paper, we address the overfitting challenge by introducing pre-trained\ndomain foundation models. A key aspect of our methodology is a novel pretext\ntask that spans multiple datasets. This task is designed to identify the\noriginating dataset of each time series sample, with the goal of creating\nflexible convolution filters that can be applied across different datasets. The\nresearch process consists of two phases: a pre-training phase where the model\nacquires general features through the pretext task, and a subsequent\nfine-tuning phase for specific dataset classifications. Our extensive\nexperiments on the UCR archive demonstrate that this pre-training strategy\nsignificantly outperforms the conventional training approach without\npre-training. This strategy effectively reduces overfitting in small datasets\nand provides an efficient route for adapting these models to new datasets, thus\nadvancing the capabilities of deep learning in TSC.",
                "authors": [
                    "Ali Ismail-Fawaz",
                    "Maxime Devanne",
                    "Stefano Berretti",
                    "Jonathan Weber",
                    "Germain Forestier"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14534v1",
                    "http://arxiv.org/pdf/2311.14534v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14532v1/1.0",
                "title": "Digital Twin-Native AI-Driven Service Architecture for Industrial\n  Networks",
                "year": 2023,
                "abstract": "The dramatic increase in the connectivity demand results in an excessive\namount of Internet of Things (IoT) sensors. To meet the management needs of\nthese large-scale networks, such as accurate monitoring and learning\ncapabilities, Digital Twin (DT) is the key enabler. However, current attempts\nregarding DT implementations remain insufficient due to the perpetual\nconnectivity requirements of IoT networks. Furthermore, the sensor data\nstreaming in IoT networks cause higher processing time than traditional\nmethods. In addition to these, the current intelligent mechanisms cannot\nperform well due to the spatiotemporal changes in the implemented IoT network\nscenario. To handle these challenges, we propose a DT-native AI-driven service\narchitecture in support of the concept of IoT networks. Within the proposed\nDT-native architecture, we implement a TCP-based data flow pipeline and a\nReinforcement Learning (RL)-based learner model. We apply the proposed\narchitecture to one of the broad concepts of IoT networks, the Internet of\nVehicles (IoV). We measure the efficiency of our proposed architecture and note\n~30% processing time-saving thanks to the TCP-based data flow pipeline.\nMoreover, we test the performance of the learner model by applying several\nlearning rate combinations for actor and critic networks and highlight the most\nsuccessive model.",
                "authors": [
                    "Kubra Duran",
                    "Matthew Broadbent",
                    "Gokhan Yurdakul",
                    "Berk Canberk"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14532v1",
                    "http://arxiv.org/pdf/2311.14532v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14530v1/1.0",
                "title": "Machine Translation for Ge'ez Language",
                "year": 2023,
                "abstract": "Machine translation (MT) for low-resource languages such as Ge'ez, an ancient\nlanguage that is no longer spoken in daily life, faces challenges such as\nout-of-vocabulary words, domain mismatches, and lack of sufficient labeled\ntraining data. In this work, we explore various methods to improve Ge'ez MT,\nincluding transfer-learning from related languages, optimizing shared\nvocabulary and token segmentation approaches, finetuning large pre-trained\nmodels, and using large language models (LLMs) for few-shot translation with\nfuzzy matches. We develop a multilingual neural machine translation (MNMT)\nmodel based on languages relatedness, which brings an average performance\nimprovement of about 4 BLEU compared to standard bilingual models. We also\nattempt to finetune the NLLB-200 model, one of the most advanced translation\nmodels available today, but find that it performs poorly with only 4k training\nsamples for Ge'ez. Furthermore, we experiment with using GPT-3.5, a\nstate-of-the-art LLM, for few-shot translation with fuzzy matches, which\nleverages embedding similarity-based retrieval to find context examples from a\nparallel corpus. We observe that GPT-3.5 achieves a remarkable BLEU score of\n9.2 with no initial knowledge of Ge'ez, but still lower than the MNMT baseline\nof 15.2. Our work provides insights into the potential and limitations of\ndifferent approaches for low-resource and ancient language MT.",
                "authors": [
                    "Aman Kassahun Wassie"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14530v1",
                    "http://arxiv.org/pdf/2311.14530v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14529v1/1.0",
                "title": "In situ Imaging of Precipitate Formation in Additively Manufactured\n  Al-Alloys by Scanning X-ray Fluorescence",
                "year": 2023,
                "abstract": "A new family of high-strength Al-alloys has recently been developed, tailored\nfor the powder bed fusion-laser beam process. In these alloys, Mn, Cr and Zr\nare incorporated in solid solution at amounts up to three times that of\nequilibrium in the as-printed state. Mn and Cr-enriched precipitates that form\nduring printing and heat treatment influence the material's mechanical\nproperties. In this study, direct imaging of these precipitates was\naccomplished through the utilisation of in situ synchrotron-based scanning\nX-ray fluorescence. During heat treatment, a selective accumulation of Cr and\nMn in two distinct types of precipitates at grain boundaries was observed.\nAdditionally, the microstructure at the melt-pool boundary, containing\nprecipitates found in the as-printed state, remains thermally stable during the\nheat treatment. The study demonstrates the significant value of employing\nhigh-sensitivity in-situ X-ray fluorescence microscopy in exploring the\nkinetics of sub-micrometre scale precipitation.",
                "authors": [
                    "Isac Lazar",
                    "Bharat Mehta",
                    "Vendulka Bertschov\u00e1",
                    "Sri Bala Aditya Malladi",
                    "Zhe Ren",
                    "Srashtasrita Das",
                    "Johannes Hagemann",
                    "Gerald Falkenberg",
                    "Karin Frisk",
                    "Anders Mikkelsen",
                    "Lars Nyborg"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14529v1",
                    "http://arxiv.org/pdf/2311.14529v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14521v4/1.0",
                "title": "GaussianEditor: Swift and Controllable 3D Editing with Gaussian\n  Splatting",
                "year": 2023,
                "abstract": "3D editing plays a crucial role in many areas such as gaming and virtual\nreality. Traditional 3D editing methods, which rely on representations like\nmeshes and point clouds, often fall short in realistically depicting complex\nscenes. On the other hand, methods based on implicit 3D representations, like\nNeural Radiance Field (NeRF), render complex scenes effectively but suffer from\nslow processing speeds and limited control over specific scene areas. In\nresponse to these challenges, our paper presents GaussianEditor, an innovative\nand efficient 3D editing algorithm based on Gaussian Splatting (GS), a novel 3D\nrepresentation. GaussianEditor enhances precision and control in editing\nthrough our proposed Gaussian semantic tracing, which traces the editing target\nthroughout the training process. Additionally, we propose Hierarchical Gaussian\nsplatting (HGS) to achieve stabilized and fine results under stochastic\ngenerative guidance from 2D diffusion models. We also develop editing\nstrategies for efficient object removal and integration, a challenging task for\nexisting methods. Our comprehensive experiments demonstrate GaussianEditor's\nsuperior control, efficacy, and rapid performance, marking a significant\nadvancement in 3D editing. Project Page:\nhttps://buaacyw.github.io/gaussian-editor/",
                "authors": [
                    "Yiwen Chen",
                    "Zilong Chen",
                    "Chi Zhang",
                    "Feng Wang",
                    "Xiaofeng Yang",
                    "Yikai Wang",
                    "Zhongang Cai",
                    "Lei Yang",
                    "Huaping Liu",
                    "Guosheng Lin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14521v4",
                    "http://arxiv.org/pdf/2311.14521v4"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14520v1/1.0",
                "title": "Shifted Composition I: Harnack and Reverse Transport Inequalities",
                "year": 2023,
                "abstract": "We formulate a new information-theoretic principle--the shifted composition\nrule--which bounds the divergence (e.g., Kullback-Leibler or R\\'enyi) between\nthe laws of two stochastic processes via the introduction of auxiliary shifts.\nIn this paper, we apply this principle to prove reverse transport inequalities\nfor diffusions which, by duality, imply F.-Y. Wang's celebrated dimension-free\nHarnack inequalities. Our approach bridges continuous-time coupling methods\nfrom geometric analysis with the discrete-time shifted divergence technique\nfrom differential privacy and sampling. It also naturally gives rise to (1) an\nalternative continuous-time coupling method based on optimal transport, which\nbypasses Girsanov transformations, (2) functional inequalities for\ndiscrete-time processes, and (3) a family of \"reverse\" Harnack inequalities.",
                "authors": [
                    "Jason M. Altschuler",
                    "Sinho Chewi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14520v1",
                    "http://arxiv.org/pdf/2311.14520v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "cs.IT",
                    "math.AP",
                    "math.FA",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14519v1/1.0",
                "title": "Benchmarking Large Language Models for Log Analysis, Security, and\n  Interpretation",
                "year": 2023,
                "abstract": "Large Language Models (LLM) continue to demonstrate their utility in a\nvariety of emergent capabilities in different fields. An area that could\nbenefit from effective language understanding in cybersecurity is the analysis\nof log files. This work explores LLMs with different architectures (BERT,\nRoBERTa, DistilRoBERTa, GPT-2, and GPT-Neo) that are benchmarked for their\ncapacity to better analyze application and system log files for security.\nSpecifically, 60 fine-tuned language models for log analysis are deployed and\nbenchmarked. The resulting models demonstrate that they can be used to perform\nlog analysis effectively with fine-tuning being particularly important for\nappropriate domain adaptation to specific log types. The best-performing\nfine-tuned sequence classification model (DistilRoBERTa) outperforms the\ncurrent state-of-the-art; with an average F1-Score of 0.998 across six datasets\nfrom both web application and system log sources. To achieve this, we propose\nand implement a new experimentation pipeline (LLM4Sec) which leverages LLMs for\nlog analysis experimentation, evaluation, and analysis.",
                "authors": [
                    "Egil Karlsen",
                    "Xiao Luo",
                    "Nur Zincir-Heywood",
                    "Malcolm Heywood"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14519v1",
                    "http://arxiv.org/pdf/2311.14519v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14517v1/1.0",
                "title": "tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models",
                "year": 2023,
                "abstract": "Contrastive Language-Audio Pretraining (CLAP) became of crucial importance in\nthe field of audio and speech processing. Its employment ranges from sound\nevent detection to text-to-audio generation. However, one of the main\nlimitations is the considerable amount of data required in the training process\nand the overall computational complexity during inference. This paper\ninvestigates how we can reduce the complexity of contrastive language-audio\npre-trained models, yielding an efficient model that we call tinyCLAP. We\nderive an unimodal distillation loss from first principles and explore how the\ndimensionality of the shared, multimodal latent space can be reduced via\npruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with a\nminimal reduction (less than 5%) in zero-shot classification performance across\nthe three sound event detection datasets on which it was tested",
                "authors": [
                    "Francesco Paissan",
                    "Elisabetta Farella"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14517v1",
                    "http://arxiv.org/pdf/2311.14517v1"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "cs.CL",
                    "cs.LG",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14515v1/1.0",
                "title": "On RIS-Aided SIMO Gaussian Channels: Towards A Single-RF MIMO\n  Transceiver Architecture",
                "year": 2023,
                "abstract": "In this paper, for a single-input multiple-output (SIMO) system aided by a\npassive reconfigurable intelligent surface (RIS), the joint transmission\naccomplished by the single transmit antenna and the RIS with multiple\ncontrollable reflective elements is considered. Relying on a general capacity\nupper bound derived by a maximum-trace argument, we respectively characterize\nthe capacity of such \\rev{a} channel in the low-SNR or the rank-one regimes, in\nwhich the optimal configuration of the RIS is proved to be beamforming with\ncarefully-chosen phase shifts. To exploit the potential of modulating extra\ninformation on the RIS, based on the QR decomposition, successive interference\ncancellation, and a strategy named \\textit{partially beamforming and partially\ninformation-carrying}, we propose a novel transceiver architecture with only a\nsingle RF front end at the transmitter, by which the considered channel can be\nregarded as a concatenation of a vector Gaussian channel and several\nphase-modulated channels. Especially, we investigate a class of vector Gaussian\nchannels with a hypersphere input support constraint, and not only generalize\nthe existing result to arbitrary-dimensional real spaces but also present its\nhigh-order capacity asymptotics, by which both capacities of\nhypersphere-constrained channels and achievable rates of the proposed\ntransceiver with two different signaling schemes can be well-approximated.\nInformation-theoretic analyses show that the transceiver architecture designed\nfor the SIMO channel has a boosted multiplexing gain, rather than one for the\nconventionally-used optimized beamforming scheme.Numerical results verify our\nderived asymptotics and show notable superiority of the proposed transceiver.",
                "authors": [
                    "Ru-Han Chen",
                    "Jing Zhou",
                    "Yonggang Zhu",
                    "Kai Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14515v1",
                    "http://arxiv.org/pdf/2311.14515v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14512v1/1.0",
                "title": "The centroid speed as a characteristic of the group speed of solar\n  coronal fast magnetoacoustic wave trains",
                "year": 2023,
                "abstract": "The highly-filamented nature of the coronal plasma significantly influences\ndynamic processes in the corona such as magnetohydrodynamic waves and\noscillations. Fast magnetoacoustic waves, guided by coronal plasma\nnon-uniformities, exhibit strong geometric dispersion, forming quasi-periodic\nfast-propagating (QFP) wave trains. QFP wave trains are observed in\nextreme-ultraviolet imaging data and indirectly in microwaves and low-frequency\nradio, aiding in understanding the magnetic connectivity, energy, and mass\ntransport in the corona. However, measuring the field-aligned group speed of\nQFP wave trains, as a key parameter for seismological analysis, is challenging\ndue to strong dispersion and associated rapid evolution of the wave train\nenvelope. We demonstrate that the group speed of QFP wave trains formed in\nplane low-$\\beta$ coronal plasma non-uniformities can be assessed through the\npropagation of the wave train's effective centre of mass, referred to as the\nwave train's centroid speed. This centroid speed, as a potential observable, is\nshown empirically to correspond to the group speed of the most energetic\nFourier harmonic in the wave train. The centroid speed is found to be almost\ninsensitive to the waveguide density contrast with the ambient corona, and to\nvary with the steepness of the transverse density profile. The discrepancy\nbetween the centroid speed as the group speed measure and the phase speed at\nthe corresponding wavelength is shown to reach 70\\%, which is crucial for the\nenergy flux estimation and interpretation of observations.",
                "authors": [
                    "Dmitrii Y. Kolotkov",
                    "Valery M. Nakariakov",
                    "Maximilien Cloesen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14512v1",
                    "http://arxiv.org/pdf/2311.14512v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "physics.space-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14508v1/1.0",
                "title": "Filasofia: A Framework for Streamlined Development of Real-Time Surgical\n  Simulations",
                "year": 2023,
                "abstract": "Virtual reality simulation has become a popular approach for training and\nassessing medical students. It offers diverse scenarios, realistic visuals, and\nquantitative performance metrics for objective evaluation. However, creating\nthese simulations can be time-consuming and complex, even for experienced\nusers. The SOFA framework is an open-source solution that efficiently simulates\nfinite element (FE) models in real-time. Yet, some users find it challenging to\nnavigate the software due to the numerous components required for a basic\nsimulation and their variability. Additionally, SOFA has limited visual\nrendering capabilities, leading developers to integrate other software for\nhigh-quality visuals. To address these issues, we developed Filasofia, a\ndedicated framework that simplifies development, provides modern visualization,\nand allows fine-tuning using SOFA objects. Our experiments demonstrate that\nFilasofia outperforms conventional SOFA simulations, even with real-time\nsubdivision. Our design approach aims to streamline development while offering\nflexibility for fine-tuning. Future work will focus on further simplification\nof the development process for users.",
                "authors": [
                    "Vladimir Poliakov",
                    "Dzmitry Tsetserukou",
                    "Emmanuel Vander Poorten"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14508v1",
                    "http://arxiv.org/pdf/2311.14508v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14506v1/1.0",
                "title": "Multi-Class Anomaly Detection based on Regularized Discriminative\n  Coupled hypersphere-based Feature Adaptation",
                "year": 2023,
                "abstract": "In anomaly detection, identification of anomalies across diverse product\ncategories is a complex task. This paper introduces a new model by including\nclass discriminative properties obtained by a modified Regularized\nDiscriminative Variational Auto-Encoder (RD-VAE) in the feature extraction\nprocess of Coupled-hypersphere-based Feature Adaptation (CFA). By doing so, the\nproposed Regularized Discriminative Coupled-hypersphere-based Feature\nAdaptation (RD-CFA), forms a solution for multi-class anomaly detection. By\nusing the discriminative power of RD-VAE to capture intricate class\ndistributions, combined with CFA's robust anomaly detection capability, the\nproposed method excels in discerning anomalies across various classes.\nExtensive evaluations on multi-class anomaly detection and localization using\nthe MVTec AD and BeanTech AD datasets showcase the effectiveness of RD-CFA\ncompared to eight leading contemporary methods.",
                "authors": [
                    "Mehdi Rafiei",
                    "Alexandros Iosifidis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14506v1",
                    "http://arxiv.org/pdf/2311.14506v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14505v1/1.0",
                "title": "Analysing the Impact of Removing Infrequent Words on Topic Quality in\n  LDA Models",
                "year": 2023,
                "abstract": "An initial procedure in text-as-data applications is text preprocessing. One\nof the typical steps, which can substantially facilitate computations, consists\nin removing infrequent words believed to provide limited information about the\ncorpus. Despite popularity of vocabulary pruning, not many guidelines on how to\nimplement it are available in the literature. The aim of the paper is to fill\nthis gap by examining the effects of removing infrequent words for the quality\nof topics estimated using Latent Dirichlet Allocation. The analysis is based on\nMonte Carlo experiments taking into account different criteria for infrequent\nterms removal and various evaluation metrics. The results indicate that pruning\nis beneficial and that the share of vocabulary which might be eliminated can be\nquite considerable.",
                "authors": [
                    "Victor Bystrov",
                    "Viktoriia Naboka-Krell",
                    "Anna Staszewska-Bystrova",
                    "Peter Winker"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14505v1",
                    "http://arxiv.org/pdf/2311.14505v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14504v1/1.0",
                "title": "Ultra-slow dynamics of free-running ring lasers: towards a minimal model",
                "year": 2023,
                "abstract": "The dynamics of a resonant, free-running ring laser, in the common case of a\nfast relaxation of the atomic polarization, is unexpectedly highly singular. As\nshown in [Phys. Rev. Research, {\\bf 5}, 023059 (2023)], this is due to the\ncloseness to a pure Hamiltonian dynamics ruled by a nonlinear wave equation,\nherein named Klein-Gordon-Toda model. In this paper, we derive a\nquasi-Hamiltonian model which allows describing realistic systems. In\nparticular, we identify two nearly conserved, energy-like quantities, which\n``naturally\" exhibit an ultra-slow dynamics confirmed and highlighted by\nnumerical simulations. A minimal version of the quasi-Hamiltonian model is\nfinally derived, which does not only reproduce the laser thresholds, but also\nhelps understanding the origin of the nearly integrable character of the laser\ndynamics.",
                "authors": [
                    "Giovanni Giacomelli",
                    "Antonio Politi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14504v1",
                    "http://arxiv.org/pdf/2311.14504v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "nlin.CD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14503v2/1.0",
                "title": "Back-action supercurrent diodes",
                "year": 2023,
                "abstract": "Back-action refers to a response that retro-acts on a system to tailor its\nproperties with respect to an external stimulus. This self-induced effect\ngenerally belongs to both the natural and technological realm, ranging from\nneural networks to optics and electronic circuitry. In electronics, back-action\nmechanisms are at the heart of many classes of devices such as amplifiers,\noscillators, and sensors. Here, we demonstrate that back-action can be\nsuccessfully exploited to achieve $\\textit{non-reciprocal}$ transport in\nsuperconducting circuits. Our device realizes a supercurrent diode, since the\ndissipationless current flows in one direction whereas dissipative transport\noccurs in the opposite direction. Supercurrent diodes presented so far rely on\nmagnetic elements or vortices to mediate charge transport or external magnetic\nfields to break time-reversal symmetry. In our implementation, back-action\nsolely turns a conventional reciprocal superconducting weak link with no\nasymmetry between the current bias directions into a diode, where the critical\ncurrent amplitude depends on the bias sign. The self-interaction of the\nsupercurrent with the device stems from the gate tunability of the critical\ncurrent, which uniquely promotes up to $\\sim$88% of magnetic field-free signal\nrectification and diode functionality with selectable polarity. The concept we\nintroduce is very general and can be applied directly to a large variety of\ndevices, thereby opening novel functionalities in superconducting electronics.",
                "authors": [
                    "Daniel Margineda",
                    "Alessandro Crippa",
                    "Elia Strambini",
                    "Yuri Fukaya",
                    "Maria Teresa Mercaldo",
                    "Carmine Ortix",
                    "Mario Cuoco",
                    "Francesco Giazotto"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14503v2",
                    "http://arxiv.org/pdf/2311.14503v2"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "cond-mat.supr-con"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14497v1/1.0",
                "title": "Advancing High-Throughput Combinatorial Aging Studies of Hybrid\n  Perovskite Thin-Films via Precise Automated Characterization Methods and\n  Machine Learning Assisted Analysis",
                "year": 2023,
                "abstract": "To optimize materials' stability, automated high-throughput workflows are of\nincreasing interest. However, many of those workflows use processes not\nsuitable for large-area depositions which limits the transferability of\nresults. While combinatorial approaches based on vapour-based depositions are\ninherently scalable, their potential for controlled stability assessments has\nyet to be exploited. Based on MAPbI3 thin-films as a prototypical system, we\ndemonstrate a combinatorial inert-gas workflow to study materials degradation\nbased on intrinsic factors only, closely resembling conditions in encapsulated\nde-vices. Through a comprehensive set of automated X-Ray fluorescence (XRF),\nX-Ray diffraction (XRD) and UV-Vis characterizations, we aim to obtain a\nholistic understanding of thin-film properties of pristine and aged thin-films.\nFrom phase changes derived from XRD characterizations before and after aging,\nwe observe simi-lar aging behaviours for MAPbI3 thin-films with varying PbI2\nresiduals. Using a custom-designed in-situ UV-Vis aging setup, the\ncombinatorial libraries are exposed to relevant aging conditions, such as heat\nor light-bias exposure. Simultaneously, UV-Vis photospectroscopy is performed\nto gain kinetic insights into the aging process which can be linked to\nintrinsic degradation processes such as autocatalytic decomposition. Despite\nscattering effects, which complicate the conventional interpretation of in-situ\nUV-Vis results, we demonstrate how a machine learning model trained on the\ncomprehensive characterization data before and after the aging process can link\noptical changes to phase changes during aging. Consequently, this approach does\nnot only enable semi-quantitative comparisons of materials' stability but also\nprovides detailed insights into the underlying degradation processes which are\notherwise mostly reported for investigations on single samples.",
                "authors": [
                    "Alexander Wieczorek",
                    "Austin G. Kuba",
                    "Jan Sommerh\u00e4user",
                    "Luis Nicklaus Caceres",
                    "Christian Wolff",
                    "Sebastian Siol"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14497v1",
                    "http://arxiv.org/pdf/2311.14497v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph",
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14495v1/1.0",
                "title": "StableSSM: Alleviating the Curse of Memory in State-space Models through\n  Stable Reparameterization",
                "year": 2023,
                "abstract": "In this paper, we investigate the long-term memory learning capabilities of\nstate-space models (SSMs) from the perspective of parameterization. We prove\nthat state-space models without any reparameterization exhibit a memory\nlimitation similar to that of traditional RNNs: the target relationships that\ncan be stably approximated by state-space models must have an exponential\ndecaying memory. Our analysis identifies this \"curse of memory\" as a result of\nthe recurrent weights converging to a stability boundary, suggesting that a\nreparameterization technique can be effective. To this end, we introduce a\nclass of reparameterization techniques for SSMs that effectively lift its\nmemory limitations. Besides improving approximation capabilities, we further\nillustrate that a principled choice of reparameterization scheme can also\nenhance optimization stability. We validate our findings using synthetic\ndatasets and language models.",
                "authors": [
                    "Shida Wang",
                    "Qianxiao Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14495v1",
                    "http://arxiv.org/pdf/2311.14495v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL",
                    "math.DS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14494v2/1.0",
                "title": "MVControl: Adding Conditional Control to Multi-view Diffusion for\n  Controllable Text-to-3D Generation",
                "year": 2023,
                "abstract": "We introduce MVControl, a novel neural network architecture that enhances\nexisting pre-trained multi-view 2D diffusion models by incorporating additional\ninput conditions, e.g. edge maps. Our approach enables the generation of\ncontrollable multi-view images and view-consistent 3D content. To achieve\ncontrollable multi-view image generation, we leverage MVDream as our base\nmodel, and train a new neural network module as additional plugin for\nend-to-end task-specific condition learning. To precisely control the shapes\nand views of generated images, we innovatively propose a new conditioning\nmechanism that predicts an embedding encapsulating the input spatial and view\nconditions, which is then injected to the network globally. Once MVControl is\ntrained, score-distillation (SDS) loss based optimization can be performed to\ngenerate 3D content, in which process we propose to use a hybrid diffusion\nprior. The hybrid prior relies on a pre-trained Stable-Diffusion network and\nour trained MVControl for additional guidance. Extensive experiments\ndemonstrate that our method achieves robust generalization and enables the\ncontrollable generation of high-quality 3D content. Code available at\nhttps://github.com/WU-CVGL/MVControl/.",
                "authors": [
                    "Zhiqi Li",
                    "Yiming Chen",
                    "Lingzhe Zhao",
                    "Peidong Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14494v2",
                    "http://arxiv.org/pdf/2311.14494v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14492v1/1.0",
                "title": "Numerical Generalized Randomized HMC processes for restricted domains",
                "year": 2023,
                "abstract": "We propose a generic approach for numerically efficient simulation from\nanalytically intractable distributions with constrained support. Our approach\nrelies upon Generalized Randomized Hamiltonian Monte Carlo (GRHMC) processes\nand combines these with a randomized transition kernel that appropriately\nadjusts the Hamiltonian flow at the boundary of the constrained domain,\nensuring that it remains within the domain. The numerical implementation of\nthis constrained GRHMC process exploits the sparsity of the randomized\ntransition kernel and the specific structure of the constraints so that the\nproposed approach is numerically accurate, computationally fast and operational\neven in high-dimensional applications. We illustrate this approach with\nposterior distributions of several Bayesian models with challenging parameter\ndomain constraints in applications to real-word data sets. Building on the\ncapability of GRHMC processes to efficiently explore otherwise challenging and\nhigh-dimensional posteriors, the proposed method expands the set of Bayesian\nmodels that can be analyzed by using the standard Markov-Chain Monte-Carlo\n(MCMC) methodology, As such, it can advance the development and use of Bayesian\nmodels with useful constrained priors, which are difficult to handle with\nexisting methods. The article is accompanied by an R-package\n(\\url{https://github.com/torekleppe/pdmphmc}), which allows for automatically\nimplementing GRHMC processes for arbitrary target distributions and domain\nconstraints.",
                "authors": [
                    "Tore Selland Kleppe",
                    "Roman Liesenfeld"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14492v1",
                    "http://arxiv.org/pdf/2311.14492v1"
                ],
                "primary_category": "stat.CO",
                "categories": [
                    "stat.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14490v1/1.0",
                "title": "Overview Of The 2023 Icassp Sp Clarity Challenge: Speech Enhancement For\n  Hearing Aids",
                "year": 2023,
                "abstract": "This paper reports on the design and outcomes of the ICASSP SP Clarity\nChallenge: Speech Enhancement for Hearing Aids. The scenario was a listener\nattending to a target speaker in a noisy, domestic environment. There were\nmultiple interferers and head rotation by the listener. The challenge extended\nthe second Clarity Enhancement Challenge (CEC2) by fixing the amplification\nstage of the hearing aid; evaluating with a combined metric for speech\nintelligibility and quality; and providing two evaluation sets, one based on\nsimulation and the other on real-room measurements. Five teams improved on the\nbaseline system for the simulated evaluation set, but the performance on the\nmeasured evaluation set was much poorer. Investigations are on-going to\ndetermine the exact cause of the mismatch between the simulated and measured\ndata sets. The presence of transducer noise in the measurements, lower order\nAmbisonics harming the ability for systems to exploit binaural cues and the\ndifferences between real and simulated room impulse responses are suggested\ncauses",
                "authors": [
                    "Trevor J. Cox",
                    "Jon Barker",
                    "Will Bailey",
                    "Simone Graetzer",
                    "Michael A. Akeroyd",
                    "John F. Culling",
                    "Graham Naylor"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14490v1",
                    "http://arxiv.org/pdf/2311.14490v1"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14488v1/1.0",
                "title": "Lightweight Framework for Automated Kidney Stone Detection using coronal\n  CT images",
                "year": 2023,
                "abstract": "Kidney stone disease results in millions of annual visits to emergency\ndepartments in the United States. Computed tomography (CT) scans serve as the\nstandard imaging modality for efficient detection of kidney stones. Various\napproaches utilizing convolutional neural networks (CNNs) have been proposed to\nimplement automatic diagnosis of kidney stones. However, there is a growing\ninterest in employing fast and efficient CNNs on edge devices in clinical\npractice. In this paper, we propose a lightweight fusion framework for kidney\ndetection and kidney stone diagnosis on coronal CT images. In our design, we\naim to minimize the computational costs of training and inference while\nimplementing an automated approach. The experimental results indicate that our\nframework can achieve competitive outcomes using only 8\\% of the original\ntraining data. These results include an F1 score of 96\\% and a False Negative\n(FN) error rate of 4\\%. Additionally, the average detection time per CT image\non a CPU is 0.62 seconds. Reproducibility: Framework implementation and models\navailable on GitHub.",
                "authors": [
                    "Fangyijie Wang",
                    "Guenole Silvestre",
                    "Kathleen M. Curran"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14488v1",
                    "http://arxiv.org/pdf/2311.14488v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14487v1/1.0",
                "title": "Reconciliation of expert priors for quantities and events and\n  application within the probabilistic Delphi method",
                "year": 2023,
                "abstract": "We consider the problem of aggregating the judgements of a group of experts\nto form a single prior distribution representing the judgements of the group.\nWe develop a Bayesian hierarchical model to reconcile the judgements of the\ngroup of experts based on elicited quantiles for continuous quantities and\nprobabilities for one-off events. Previous Bayesian reconciliation methods have\nnot been used widely, if at all, in contrast to pooling methods and\nconsensus-based approaches. To address this we embed Bayesian reconciliation\nwithin the probabilistic Delphi method. The result is to furnish the outcome of\nthe probabilistic Delphi method with a direct probabilistic interpretation,\nwith the resulting prior representing the judgements of the decision maker. We\ncan use the rationales from the Delphi process to group the experts for the\nhierarchical modelling. We illustrate the approach with applications to studies\nevaluating erosion in embankment dams and pump failures in a water pumping\nstation, and assess the properties of the approach using the TU Delft database\nof expert judgement studies. We see that, even using an off-the-shelf\nimplementation of the approach, it out-performs individual experts, equal\nweighting of experts and the classical method based on the log score.",
                "authors": [
                    "Kevin J. Wilson",
                    "Malcolm Farrow",
                    "Simon French",
                    "David Hartley"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14487v1",
                    "http://arxiv.org/pdf/2311.14487v1"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14486v1/1.0",
                "title": "Is there a (Pseudo)Scalar at 95 GeV?",
                "year": 2023,
                "abstract": "We discuss the possibility of interpreting the recent experimental hints, in\nfavour of a 95 GeV resonance, with extensions of the Standard Model featuring\nan extra Higgs doublet and SM scalar (2HDM+s) or pseudoscalar singlet (2HDM+a).\nThe possibility of reproducing the experimental anomalies will be compared with\nthe theoretical constraints on the extended Higgs sector as well as\ncomplementary bounds coming from flavour physics as well as other colliders\nsearchers. For both the 2HDM+s and 2HDM+a we will consider a generic natural\nflavour conserving (NFC) as well as the customary Type-I, -II, -X and -Y\nconfigurations of the Yukawa coupling to the BSM Higgs bosons.",
                "authors": [
                    "Giorgio Arcadi",
                    "Giorgio Busoni",
                    "David Cabo-Almeida",
                    "Navneet Krishnan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14486v1",
                    "http://arxiv.org/pdf/2311.14486v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14485v1/1.0",
                "title": "Towards Interpretable Classification of Leukocytes based on Deep\n  Learning",
                "year": 2023,
                "abstract": "Label-free approaches are attractive in cytological imaging due to their\nflexibility and cost efficiency. They are supported by machine learning\nmethods, which, despite the lack of labeling and the associated lower contrast,\ncan classify cells with high accuracy where the human observer has little\nchance to discriminate cells. In order to better integrate these workflows into\nthe clinical decision making process, this work investigates the calibration of\nconfidence estimation for the automated classification of leukocytes. In\naddition, different visual explanation approaches are compared, which should\nbring machine decision making closer to professional healthcare applications.\nFurthermore, we were able to identify general detection patterns in neural\nnetworks and demonstrate the utility of the presented approaches in different\nscenarios of blood cell analysis.",
                "authors": [
                    "Stefan R\u00f6hrl",
                    "Johannes Groll",
                    "Manuel Lengl",
                    "Simon Schumann",
                    "Christian Klenk",
                    "Dominik Heim",
                    "Martin Knopp",
                    "Oliver Hayden",
                    "Klaus Diepold"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14485v1",
                    "http://arxiv.org/pdf/2311.14485v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00804v1/1.0",
                "title": "Automatic detection of problem-gambling signs from online texts using\n  large language models",
                "year": 2023,
                "abstract": "Problem gambling is a major public health concern and is associated with\nprofound psychological distress and economic problems. There are numerous\ngambling communities on the internet where users exchange information about\ngames, gambling tactics, as well as gambling-related problems. Individuals\nexhibiting higher levels of problem gambling engage more in such communities.\nOnline gambling communities may provide insights into problem-gambling\nbehaviour. Using data scraped from a major German gambling discussion board, we\nfine-tuned a large language model, specifically a Bidirectional Encoder\nRepresentations from Transformers (BERT) model, to predict signs of\nproblem-gambling from forum posts. Training data were generated by manual\nannotation and by taking into account diagnostic criteria and gambling-related\ncognitive distortions. Using k-fold cross-validation, our models achieved a\nprecision of 0.95 and F1 score of 0.71, demonstrating that satisfactory\nclassification performance can be achieved by generating high-quality training\nmaterial through manual annotation based on diagnostic criteria. The current\nstudy confirms that a BERT-based model can be reliably used on small data sets\nand to detect signatures of problem gambling in online communication data. Such\ncomputational approaches may have potential for the detection of changes in\nproblem-gambling prevalence among online users.",
                "authors": [
                    "Elke Smith",
                    "Nils Reiter",
                    "Jan Peters"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00804v1",
                    "http://arxiv.org/pdf/2312.00804v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14483v2/1.0",
                "title": "SER_AMPEL: a multi-source dataset for speech emotion recognition of\n  Italian older adults",
                "year": 2023,
                "abstract": "In this paper, SER_AMPEL, a multi-source dataset for speech emotion\nrecognition (SER) is presented. The peculiarity of the dataset is that it is\ncollected with the aim of providing a reference for speech emotion recognition\nin case of Italian older adults. The dataset is collected following different\nprotocols, in particular considering acted conversations, extracted from movies\nand TV series, and recording natural conversations where the emotions are\nelicited by proper questions. The evidence of the need for such a dataset\nemerges from the analysis of the state of the art. Preliminary considerations\non the critical issues of SER are reported analyzing the classification results\non a subset of the proposed dataset.",
                "authors": [
                    "Alessandra Grossi",
                    "Francesca Gasparini"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14483v2",
                    "http://arxiv.org/pdf/2311.14483v2"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.CL",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14482v1/1.0",
                "title": "Sliding Window FastEdit: A Framework for Lesion Annotation in Whole-body\n  PET Images",
                "year": 2023,
                "abstract": "Deep learning has revolutionized the accurate segmentation of diseases in\nmedical imaging. However, achieving such results requires training with\nnumerous manual voxel annotations. This requirement presents a challenge for\nwhole-body Positron Emission Tomography (PET) imaging, where lesions are\nscattered throughout the body. To tackle this problem, we introduce SW-FastEdit\n- an interactive segmentation framework that accelerates the labeling by\nutilizing only a few user clicks instead of voxelwise annotations. While prior\ninteractive models crop or resize PET volumes due to memory constraints, we use\nthe complete volume with our sliding window-based interactive scheme. Our model\noutperforms existing non-sliding window interactive models on the AutoPET\ndataset and generalizes to the previously unseen HECKTOR dataset. A user study\nrevealed that annotators achieve high-quality predictions with only 10 click\niterations and a low perceived NASA-TLX workload. Our framework is implemented\nusing MONAI Label and is available:\nhttps://github.com/matt3o/AutoPET2-Submission/",
                "authors": [
                    "Matthias Hadlich",
                    "Zdravko Marinov",
                    "Moon Kim",
                    "Enrico Nasca",
                    "Jens Kleesiek",
                    "Rainer Stiefelhagen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14482v1",
                    "http://arxiv.org/pdf/2311.14482v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.AI",
                    "cs.CV",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14479v1/1.0",
                "title": "Controlled Text Generation via Language Model Arithmetic",
                "year": 2023,
                "abstract": "As Large Language Models (LLMs) are deployed more widely, customization with\nrespect to vocabulary, style and character becomes more important. In this work\nwe introduce model arithmetic, a novel inference framework for composing and\nbiasing LLMs without the need for model (re)training or highly specific\ndatasets. In addition, the framework allows for more precise control of\ngenerated text than direct prompting and prior controlled text generation (CTG)\ntechniques. Using model arithmetic, we can express prior CTG techniques as\nsimple formulas and naturally extend them to new and more effective\nformulations. Further, we show that speculative sampling, a technique for\nefficient LLM sampling, extends to our setting. This enables highly efficient\ntext generation with multiple composed models with only marginal overhead over\na single model. Our empirical evaluation demonstrates that model arithmetic\nallows fine-grained control of generated text while outperforming\nstate-of-the-art on the task of toxicity reduction.",
                "authors": [
                    "Jasper Dekoninck",
                    "Marc Fischer",
                    "Luca Beurer-Kellner",
                    "Martin Vechev"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14479v1",
                    "http://arxiv.org/pdf/2311.14479v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14478v1/1.0",
                "title": "Depletion-induced crystallization of anisotropic triblock colloids",
                "year": 2023,
                "abstract": "The intricate interplay between colloidal particle shape and precisely\nengineered interaction potentials has paved the way for the discovery of\nunprecedented crystal structures in both two and three dimensions. Here, we\nmake use of anisotropic triblock colloidal particles composed of two distinct\nmaterials. The resulting surface charge heterogeneity can be exploited to\ngenerate regioselective depletion interactions and directional bonding. Using\nextensive molecular dynamics simulations and a dimensionality reduction\nanalysis approach, we map out state diagrams for the self-assembly of such\ncolloids as a function of their aspect ratio and packing fraction for varying\ndepletant sizes in a quasi two-dimensional set-up. We observe the formation of\na wide variety of crystal structures such as a herringbone, brick-wall, tilted\nbrick-wall, and (tilted) ladder-like structures. More specifically, we\ndetermine the optimal parameters to enhance crystallization, and investigate\nthe nucleation process. Additionally, we explore the potential of using crystal\nmonolayers as templates for deposition, thereby creating complex\nthree-dimensional structures that hold promise for future applications.",
                "authors": [
                    "Fabrizio Camerin",
                    "Susana Mar\u00edn-Aguilar",
                    "Marjolein Dijkstra"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14478v1",
                    "http://arxiv.org/pdf/2311.14478v1"
                ],
                "primary_category": "cond-mat.soft",
                "categories": [
                    "cond-mat.soft"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14477v1/1.0",
                "title": "Simulation Limitations of Affine Cellular Automata",
                "year": 2023,
                "abstract": "Cellular automata are a famous model of computation, yet it is still a\nchallenging task to assess the computational capacity of a given automaton;\nespecially when it comes to showing negative results. In this paper, we focus\non studying this problem via the notion of CA relative simulation. We say that\nautomaton A is simulated by B if each space-time diagram of A can be, after\nsuitable transformations, reproduced by B.\n  We study affine automata - i.e., automata whose local rules are affine\nmappings of vector spaces. This broad class contains the well-studied cases of\nadditive automata. The main result of this paper shows that (almost) every\nautomaton affine over a finite field F_p can only simulate affine automata over\nF_p. We discuss how this general result implies, and widely surpasses,\nlimitations of additive automata previously proved in the literature.\n  We provide a formalization of the simulation notions into algebraic language\nand discuss how this opens a new path to showing negative results about the\ncomputational power of cellular automata using deeper algebraic theorems.",
                "authors": [
                    "Barbora Hudcov\u00e1",
                    "Jakub Kr\u00e1sensk\u00fd"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14477v1",
                    "http://arxiv.org/pdf/2311.14477v1"
                ],
                "primary_category": "cs.FL",
                "categories": [
                    "cs.FL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14474v1/1.0",
                "title": "Cosmic-Ray Physics at the South Pole",
                "year": 2023,
                "abstract": "The geographic South Pole provides unique opportunities to study cosmic\nparticles in the Southern Hemisphere. It represents an optimal location to\ndeploy large-scale neutrino telescopes in the deep Antarctic ice, such as\nAMANDA or IceCube. In both cases, the presence of an array, constructed to\nobserve extensive air showers, enables hybrid measurements of cosmic rays.\nWhile additional neutron monitors can provide information on solar cosmic rays,\nlarge detector arrays, like SPASE or IceTop, allow for precise measurements of\ncosmic rays with energies above several $100\\,\\rm{TeV}$. In coincidence with\nthe signals recorded in the deep ice, which are mostly due to the high-energy\nmuons produced in air showers, this hybrid detector setup provides important\ninformation about the nature of cosmic rays.\n  In this review, we will discuss the historical motivation and developments\ntowards measurements of cosmic rays at the geographic South Pole and highlight\nrecent results reported by the IceCube Collaboration. We will emphasize the\nimportant contributions by Thomas K. Gaisser and his colleagues that ultimately\nled to the rich Antarctic research program which today provides crucial\ninsights into cosmic-ray physics.",
                "authors": [
                    "D. Soldin",
                    "P. A. Evenson",
                    "H. Kolanoski",
                    "A. A. Watson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14474v1",
                    "http://arxiv.org/pdf/2311.14474v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE",
                    "physics.hist-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14473v1/1.0",
                "title": "Joint Diffusion: Mutual Consistency-Driven Diffusion Model for PET-MRI\n  Co-Reconstruction",
                "year": 2023,
                "abstract": "Positron Emission Tomography and Magnetic Resonance Imaging (PET-MRI) systems\ncan obtain functional and anatomical scans. PET suffers from a low\nsignal-to-noise ratio. Meanwhile, the k-space data acquisition process in MRI\nis time-consuming. The study aims to accelerate MRI and enhance PET image\nquality. Conventional approaches involve the separate reconstruction of each\nmodality within PET-MRI systems. However, there exists complementary\ninformation among multi-modal images. The complementary information can\ncontribute to image reconstruction. In this study, we propose a novel PET-MRI\njoint reconstruction model employing a mutual consistency-driven diffusion\nmode, namely MC-Diffusion. MC-Diffusion learns the joint probability\ndistribution of PET and MRI for utilizing complementary information. We\nconducted a series of contrast experiments about LPLS, Joint ISAT-net and\nMC-Diffusion by the ADNI dataset. The results underscore the qualitative and\nquantitative improvements achieved by MC-Diffusion, surpassing the\nstate-of-the-art method.",
                "authors": [
                    "Taofeng Xie",
                    "Zhuo-Xu Cui",
                    "Chen Luo",
                    "Huayu Wang",
                    "Congcong Liu",
                    "Yuanzhi Zhang",
                    "Xuemei Wang",
                    "Yanjie Zhu",
                    "Qiyu Jin",
                    "Guoqing Chen",
                    "Yihang Zhou",
                    "Dong Liang",
                    "Haifeng Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14473v1",
                    "http://arxiv.org/pdf/2311.14473v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14469v1/1.0",
                "title": "Fault Detection in Telecom Networks using Bi-level Federated Graph\n  Neural Networks",
                "year": 2023,
                "abstract": "5G and Beyond Networks become increasingly complex and heterogeneous, with\ndiversified and high requirements from a wide variety of emerging applications.\nThe complexity and diversity of Telecom networks place an increasing strain on\nmaintenance and operation efforts. Moreover, the strict security and privacy\nrequirements present a challenge for mobile operators to leverage network data.\nTo detect network faults, and mitigate future failures, prior work focused on\nleveraging traditional ML/DL methods to locate anomalies in networks. The\ncurrent approaches, although powerful, do not consider the intertwined nature\nof embedded and software-intensive Radio Access Network systems. In this paper,\nwe propose a Bi-level Federated Graph Neural Network anomaly detection and\ndiagnosis model that is able to detect anomalies in Telecom networks in a\nprivacy-preserving manner, while minimizing communication costs. Our method\nrevolves around conceptualizing Telecom data as a bi-level temporal Graph\nNeural Networks. The first graph captures the interactions between different\nRAN nodes that are exposed to different deployment scenarios in the network,\nwhile each individual Radio Access Network node is further elaborated into its\nsoftware (SW) execution graph. Additionally, we use Federated Learning to\naddress privacy and security limitations. Furthermore, we study the performance\nof anomaly detection model under three settings: (1) Centralized (2) Federated\nLearning and (3) Personalized Federated Learning using real-world data from an\noperational network. Our comprehensive experiments showed that Personalized\nFederated Temporal Graph Neural Networks method outperforms the most commonly\nused techniques for Anomaly Detection.",
                "authors": [
                    "R. Bourgerie",
                    "T. Zanouda"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14469v1",
                    "http://arxiv.org/pdf/2311.14469v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14465v1/1.0",
                "title": "DP-NMT: Scalable Differentially-Private Machine Translation",
                "year": 2023,
                "abstract": "Neural machine translation (NMT) is a widely popular text generation task,\nyet there is a considerable research gap in the development of\nprivacy-preserving NMT models, despite significant data privacy concerns for\nNMT systems. Differentially private stochastic gradient descent (DP-SGD) is a\npopular method for training machine learning models with concrete privacy\nguarantees; however, the implementation specifics of training a model with\nDP-SGD are not always clarified in existing models, with differing software\nlibraries used and code bases not always being public, leading to\nreproducibility issues. To tackle this, we introduce DP-NMT, an open-source\nframework for carrying out research on privacy-preserving NMT with DP-SGD,\nbringing together numerous models, datasets, and evaluation metrics in one\nsystematic software package. Our goal is to provide a platform for researchers\nto advance the development of privacy-preserving NMT systems, keeping the\nspecific details of the DP-SGD algorithm transparent and intuitive to\nimplement. We run a set of experiments on datasets from both general and\nprivacy-related domains to demonstrate our framework in use. We make our\nframework publicly available and welcome feedback from the community.",
                "authors": [
                    "Timour Igamberdiev",
                    "Doan Nam Long Vu",
                    "Felix K\u00fcnnecke",
                    "Zhuo Yu",
                    "Jannik Holmer",
                    "Ivan Habernal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14465v1",
                    "http://arxiv.org/pdf/2311.14465v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14463v1/1.0",
                "title": "Mechanism of charge transfer and electrostatic field fluctuations in\n  high entropy metallic alloys",
                "year": 2023,
                "abstract": "High entropy alloys present a new class of disordered metals which hold\npromising prospects for the next generation of materials and technology.\nHowever, much of the basic physics underlying these robust, multifunctional\nmaterials -- and those of other, more generic forms of disordered matter --\nstill remain the subject of ongoing inquiry. We thus present a minimal-working\nmodel that describes the disorder-driven fluctuations in the electronic charge\ndistributions and electrostatic \"Madelung\" fields in disordered metals. Our\ntheory follows a standard perturbative scheme and captures the leading\ncontributions from dominant electronic processes, including electrostatic\nscreening and impurity scattering events. We show here that a modest\nfirst-order treatment incorporating these effects is sufficient to reproduce\nthe linear charge transfer trends featured in both high-entropy and other\nconventional alloys, our model also shedding light on the microscopic origins\nof these statistical features. We further elaborate on the nature of these\nelectronic charge and Madelung field fluctuations by determining how these\nemerge from the statistics of the underlying disorder, and how these can be\ndescribed using the linear response formulation that we develop here. In doing\nso, our work answers various questions which have long-perplexed the disordered\nmaterials community. It also opens up possible avenues for providing systematic\ncorrections to modern first-principles approaches to disorder-modeling (e.g.\nthe conventional CPA method) which currently lack these statistical features.",
                "authors": [
                    "Wai-Ga D. Ho",
                    "Wasim Raja Mondal",
                    "Hanna Terletska",
                    "Ka-Ming Tam",
                    "Mariia Karabin",
                    "Markus Eisenbach",
                    "Yang Wang",
                    "Vladimir Dobrosavljevic"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14463v1",
                    "http://arxiv.org/pdf/2311.14463v1"
                ],
                "primary_category": "cond-mat.dis-nn",
                "categories": [
                    "cond-mat.dis-nn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14462v1/1.0",
                "title": "CT-xCOV: a CT-scan based Explainable Framework for COVid-19 diagnosis",
                "year": 2023,
                "abstract": "In this work, CT-xCOV, an explainable framework for COVID-19 diagnosis using\nDeep Learning (DL) on CT-scans is developed. CT-xCOV adopts an end-to-end\napproach from lung segmentation to COVID-19 detection and explanations of the\ndetection model's prediction. For lung segmentation, we used the well-known\nU-Net model. For COVID-19 detection, we compared three different CNN\narchitectures: a standard CNN, ResNet50, and DenseNet121. After the detection,\nvisual and textual explanations are provided. For visual explanations, we\napplied three different XAI techniques, namely, Grad-Cam, Integrated Gradient\n(IG), and LIME. Textual explanations are added by computing the percentage of\ninfection by lungs. To assess the performance of the used XAI techniques, we\npropose a ground-truth-based evaluation method, measuring the similarity\nbetween the visualization outputs and the ground-truth infections. The\nperformed experiments show that the applied DL models achieved good results.\nThe U-Net segmentation model achieved a high Dice coefficient (98%). The\nperformance of our proposed classification model (standard CNN) was validated\nusing 5-fold cross-validation (acc of 98.40% and f1-score 98.23%). Lastly, the\nresults of the comparison of XAI techniques show that Grad-Cam gives the best\nexplanations compared to LIME and IG, by achieving a Dice coefficient of 55%,\non COVID-19 positive scans, compared to 29% and 24% obtained by IG and LIME\nrespectively. The code and the dataset used in this paper are available in the\nGitHub repository [1].",
                "authors": [
                    "Ismail Elbouknify",
                    "Afaf Bouhoute",
                    "Khalid Fardousse",
                    "Ismail Berrada",
                    "Abdelmajid Badri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14462v1",
                    "http://arxiv.org/pdf/2311.14462v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14457v1/1.0",
                "title": "How to ensure a safe control strategy? Towards a SRL for urban transit\n  autonomous operation",
                "year": 2023,
                "abstract": "Deep reinforcement learning has gradually shown its latent decision-making\nability in urban rail transit autonomous operation. However, since\nreinforcement learning can not neither guarantee safety during learning nor\nexecution, this is still one of the major obstacles to the practical\napplication of reinforcement learning. Given this drawback, reinforcement\nlearning applied in the safety-critical autonomous operation domain remains\nchallenging without generating a safe control command sequence that avoids\noverspeed operations. Therefore, a SSA-DRL framework is proposed in this paper\nfor safe intelligent control of urban rail transit autonomous operation trains.\nThe proposed framework is combined with linear temporal logic, reinforcement\nlearning and Monte Carlo tree search and consists of four mainly module: a\npost-posed shielding, a searching tree module, a DRL framework and an\nadditional actor. Furthermore, the output of the framework can meet speed\nconstraint, schedule constraint and optimize the operation process. Finally,\nthe proposed SSA-DRL framework for decision-making in urban rail transit\nautonomous operation is evaluated in sixteen different sections, and its\neffectiveness is demonstrated through an ablation experiment and comparison\nwith the scheduled operation plan.",
                "authors": [
                    "Zicong Zhao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14457v1",
                    "http://arxiv.org/pdf/2311.14457v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14455v1/1.0",
                "title": "Universal Jailbreak Backdoors from Poisoned Human Feedback",
                "year": 2023,
                "abstract": "Reinforcement Learning from Human Feedback (RLHF) is used to align large\nlanguage models to produce helpful and harmless responses. Yet, prior work\nshowed these models can be jailbroken by finding adversarial prompts that\nrevert the model to its unaligned behavior. In this paper, we consider a new\nthreat where an attacker poisons the RLHF training data to embed a \"jailbreak\nbackdoor\" into the model. The backdoor embeds a trigger word into the model\nthat acts like a universal \"sudo command\": adding the trigger word to any\nprompt enables harmful responses without the need to search for an adversarial\nprompt. Universal jailbreak backdoors are much more powerful than previously\nstudied backdoors on language models, and we find they are significantly harder\nto plant using common backdoor attack techniques. We investigate the design\ndecisions in RLHF that contribute to its purported robustness, and release a\nbenchmark of poisoned models to stimulate future research on universal\njailbreak backdoors.",
                "authors": [
                    "Javier Rando",
                    "Florian Tram\u00e8r"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14455v1",
                    "http://arxiv.org/pdf/2311.14455v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CL",
                    "cs.CR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14452v1/1.0",
                "title": "Refinement Proofs in Rust Using Ghost Locks",
                "year": 2023,
                "abstract": "Refinement transforms an abstract system model into a concrete, executable\nprogram, such that properties established for the abstract model carry over to\nthe concrete implementation. Refinement has been used successfully in the\ndevelopment of substantial verified systems. Nevertheless, existing refinement\ntechniques have limitations that impede their practical usefulness. Some\ntechniques generate executable code automatically, which generally leads to\nimplementations with sub-optimal performance. Others employ bottom-up program\nverification to reason about efficient implementations, but impose strict\nrequirements on the structure of the code, the structure of the refinement\nproofs, as well as the employed verification logic and tools.\n  In this paper, we present a novel refinement technique that removes these\nlimitations. It supports a wide range of program structures, data\nrepresentations, and proof structures. Our approach supports reasoning about\nboth safety and liveness properties. We implement our approach in a\nstate-of-the-art verifier for the Rust language, which itself offers a strong\nfoundation for memory safety. We demonstrate the practicality of our approach\non a number of substantial case studies.",
                "authors": [
                    "Aurel B\u00edl\u00fd",
                    "Jo\u00e3o C. Pereira",
                    "Jan Sch\u00e4r",
                    "Peter M\u00fcller"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14452v1",
                    "http://arxiv.org/pdf/2311.14452v1"
                ],
                "primary_category": "cs.LO",
                "categories": [
                    "cs.LO",
                    "68Q60",
                    "F.3.1"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14451v2/1.0",
                "title": "Rigid partitions: from high connectivity to random graphs",
                "year": 2023,
                "abstract": "A graph is called $d$-rigid if there exists a generic embedding of its vertex\nset into $\\mathbb{R}^d$ such that every continuous motion of the vertices that\npreserves the lengths of all edges actually preserves the distances between all\npairs of vertices. The rigidity of a graph is the maximal $d$ such that the\ngraph is $d$-rigid. We present new sufficient conditions for the $d$-rigidity\nof a graph in terms of the existence of ``rigid partitions'' -- partitions of\nthe graph that satisfy certain connectivity properties. This extends previous\nresults by Crapo, Lindemann, and Lew, Nevo, Peled and Raz.\n  As an application, we present new results on the rigidity of highly-connected\ngraphs, random graphs, random bipartite graphs, pseudorandom graphs, and dense\ngraphs. In particular, we prove that random $C d\\log d$-regular graphs are\ntypically $d$-rigid, demonstrate the existence of a giant $d$-rigid component\nin sparse random binomial graphs, and show that the rigidity of relatively\nsparse random binomial bipartite graphs is roughly the same as that of the\ncomplete bipartite graph, which we consider an interesting phenomenon.\nFurthermore, we show that a graph admitting $\\binom{d+1}{2}$ disjoint connected\ndominating sets is $d$-rigid. This implies a weak version of the\nLov\\'asz--Yemini conjecture on the rigidity of highly-connected graphs. We also\npresent an alternative short proof for a recent result by Lew, Nevo, Peled, and\nRaz, which asserts that the hitting time for $d$-rigidity in the random graph\nprocess typically coincides with the hitting time for minimum degree $d$.",
                "authors": [
                    "Michael Krivelevich",
                    "Alan Lew",
                    "Peleg Michaeli"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14451v2",
                    "http://arxiv.org/pdf/2311.14451v2"
                ],
                "primary_category": "math.CO",
                "categories": [
                    "math.CO",
                    "05C10, 52C25, 05C40, 05C80, 05C50"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14450v1/1.0",
                "title": "Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on\n  Segmentation Models",
                "year": 2023,
                "abstract": "General purpose segmentation models are able to generate (semantic)\nsegmentation masks from a variety of prompts, including visual (points, boxed,\netc.) and textual (object names) ones. In particular, input images are\npre-processed by an image encoder to obtain embedding vectors which are later\nused for mask predictions. Existing adversarial attacks target the end-to-end\ntasks, i.e. aim at altering the segmentation mask predicted for a specific\nimage-prompt pair. However, this requires running an individual attack for each\nnew prompt for the same image. We propose instead to generate prompt-agnostic\nadversarial attacks by maximizing the $\\ell_2$-distance, in the latent space,\nbetween the embedding of the original and perturbed images. Since the encoding\nprocess only depends on the image, distorted image representations will cause\nperturbations in the segmentation masks for a variety of prompts. We show that\neven imperceptible $\\ell_\\infty$-bounded perturbations of radius\n$\\epsilon=1/255$ are often sufficient to drastically modify the masks predicted\nwith point, box and text prompts by recently proposed foundation models for\nsegmentation. Moreover, we explore the possibility of creating universal, i.e.\nnon image-specific, attacks which can be readily applied to any input without\nfurther computational cost.",
                "authors": [
                    "Francesco Croce",
                    "Matthias Hein"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14450v1",
                    "http://arxiv.org/pdf/2311.14450v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14448v1/1.0",
                "title": "Deep Learning for Automatic Strain Quantification in Arrhythmogenic\n  Right Ventricular Cardiomyopathy",
                "year": 2023,
                "abstract": "Quantification of cardiac motion with cine Cardiac Magnetic Resonance Imaging\n(CMRI) is an integral part of arrhythmogenic right ventricular cardiomyopathy\n(ARVC) diagnosis. Yet, the expert evaluation of motion abnormalities with CMRI\nis a challenging task. To automatically assess cardiac motion, we register\nCMRIs from different time points of the cardiac cycle using Implicit Neural\nRepresentations (INRs) and perform a biomechanically informed regularization\ninspired by the myocardial incompressibility assumption. To enhance the\nregistration performance, our method first rectifies the inter-slice\nmisalignment inherent to CMRI by performing a rigid registration guided by the\nlong-axis views, and then increases the through-plane resolution using an\nunsupervised deep learning super-resolution approach. Finally, we propose to\nsynergically combine information from short-axis and 4-chamber long-axis views,\nalong with an initialization to incorporate information from multiple cardiac\ntime points. Thereafter, to quantify cardiac motion, we calculate global and\nsegmental strain over a cardiac cycle and compute the peak strain. The\nevaluation of the method is performed on a dataset of cine CMRI scans from 47\nARVC patients and 67 controls. Our results show that inter-slice alignment and\ngeneration of super-resolved volumes combined with joint analysis of the two\ncardiac views, notably improves registration performance. Furthermore, the\nproposed initialization yields more physiologically plausible registrations.\nThe significant differences in the peak strain, discerned between the ARVC\npatients and healthy controls suggest that automated motion quantification\nmethods may assist in diagnosis and provide further understanding of\ndisease-specific alterations of cardiac motion.",
                "authors": [
                    "Laura Alvarez-Florez",
                    "J\u00f6rg Sander",
                    "Mimount Bourfiss",
                    "Fleur V. Y. Tjong",
                    "Birgitta K. Velthuis",
                    "Ivana I\u0161gum"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14448v1",
                    "http://arxiv.org/pdf/2311.14448v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14447v1/1.0",
                "title": "SNN Architecture for Differential Time Encoding Using Decoupled\n  Processing Time",
                "year": 2023,
                "abstract": "Spiking neural networks (SNNs) have gained attention in recent years due to\ntheir ability to handle sparse and event-based data better than regular\nartificial neural networks (ANNs). Since the structure of SNNs is less suited\nfor typically used accelerators such as GPUs than conventional ANNs, there is a\ndemand for custom hardware accelerators for processing SNNs. In the past, the\nmain focus was on platforms that resemble the structure of multiprocessor\nsystems. In this work, we propose a lightweight neuron layer architecture that\nallows network structures to be directly mapped onto digital hardware. Our\napproach is based on differential time coding of spike sequences and the\ndecoupling of processing time and spike timing that allows the SNN to be\nprocessed on different hardware platforms. We present synthesis and performance\nresults showing that this architecture can be implemented for networks of more\nthan 1000 neurons with high clock speeds on a State-of-the-Art FPGA. We\nfurthermore show results on the robustness of our approach to quantization.\nThese results demonstrate that high-accuracy inference can be performed with\nbit widths as low as 4.",
                "authors": [
                    "Daniel Windhager",
                    "Bernhard A. Moser",
                    "Michael Lunglmayr"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14447v1",
                    "http://arxiv.org/pdf/2311.14447v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14443v1/1.0",
                "title": "Petit programming language and compiler",
                "year": 2023,
                "abstract": "Petit is an educational programming language for learning compilers. Students\nembark on the journey of learning compilers through a series of six tutorials,\nprogressing from topics like lexical analysis and syntactic analysis to\nsemantic analysis and code generation. The initial tutorials in this series\ncover the practical applications of the lex and yacc tools, while the\nconcluding tutorial focuses on generating LLVM intermediate representation.",
                "authors": [
                    "Raul Barbosa"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14443v1",
                    "http://arxiv.org/pdf/2311.14443v1"
                ],
                "primary_category": "cs.PL",
                "categories": [
                    "cs.PL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14441v1/1.0",
                "title": "The Veronese subalgebras of a free alternative algebra of finite rank\n  are finitely generated",
                "year": 2023,
                "abstract": "It is proved that for any natural number $n$ the subalgebra of a free\nfinitely generated alternative algebra generated by all the words on generators\nwhose length is a multiple of $n$ (the Veronese $n$-subalgebra), is finitely\ngenerated.",
                "authors": [
                    "S. V. Pchelintsev",
                    "I. P. Shestakov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14441v1",
                    "http://arxiv.org/pdf/2311.14441v1"
                ],
                "primary_category": "math.RA",
                "categories": [
                    "math.RA",
                    "17D05, 17A50"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14435v1/1.0",
                "title": "GCPV: Guided Concept Projection Vectors for the Explainable Inspection\n  of CNN Feature Spaces",
                "year": 2023,
                "abstract": "For debugging and verification of computer vision convolutional deep neural\nnetworks (CNNs) human inspection of the learned latent representations is\nimperative. Therefore, state-of-the-art eXplainable Artificial Intelligence\n(XAI) methods globally associate given natural language semantic concepts with\nrepresenting vectors or regions in the CNN latent space supporting manual\ninspection. Yet, this approach comes with two major disadvantages: They are\nlocally inaccurate when reconstructing a concept label and discard information\nabout the distribution of concept instance representations. The latter, though,\nis of particular interest for debugging, like finding and understanding\noutliers, learned notions of sub-concepts, and concept confusion. Furthermore,\ncurrent single-layer approaches neglect that information about a concept may be\nspread over the CNN depth. To overcome these shortcomings, we introduce the\nlocal-to-global Guided Concept Projection Vectors (GCPV) approach: It (1)\ngenerates local concept vectors that each precisely reconstruct a concept\nsegmentation label, and then (2) generalizes these to global concept and even\nsub-concept vectors by means of hiearchical clustering. Our experiments on\nobject detectors demonstrate improved performance compared to the\nstate-of-the-art, the benefit of multi-layer concept vectors, and robustness\nagainst low-quality concept segmentation labels. Finally, we demonstrate that\nGCPVs can be applied to find root causes for confusion of concepts like bus and\ntruck, and reveal interesting concept-level outliers. Thus, GCPVs pose a\npromising step towards interpretable model debugging and informed data\nimprovement.",
                "authors": [
                    "Georgii Mikriukov",
                    "Gesina Schwalbe",
                    "Christian Hellert",
                    "Korinna Bade"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14435v1",
                    "http://arxiv.org/pdf/2311.14435v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14427v1/1.0",
                "title": "Disentangling the Spectral Properties of the Hodge Laplacian: Not All\n  Small Eigenvalues Are Equal",
                "year": 2023,
                "abstract": "The rich spectral information of the graph Laplacian has been instrumental in\ngraph theory, machine learning, and graph signal processing for applications\nsuch as graph classification, clustering, or eigenmode analysis. Recently, the\nHodge Laplacian has come into focus as a generalisation of the ordinary\nLaplacian for higher-order graph models such as simplicial and cellular\ncomplexes. Akin to the traditional analysis of graph Laplacians, many authors\nanalyse the smallest eigenvalues of the Hodge Laplacian, which are connected to\nimportant topological properties such as homology. However, small eigenvalues\nof the Hodge Laplacian can carry different information depending on whether\nthey are related to curl or gradient eigenmodes, and thus may not be\ncomparable. We therefore introduce the notion of persistent eigenvector\nsimilarity and provide a method to track individual harmonic, curl, and\ngradient eigenvectors/-values through the so-called persistence filtration,\nleveraging the full information contained in the Hodge-Laplacian spectrum\nacross all possible scales of a point cloud. Finally, we use our insights (a)\nto introduce a novel form of topological spectral clustering and (b) to\nclassify edges and higher-order simplices based on their relationship to the\nsmallest harmonic, curl, and gradient eigenvectors.",
                "authors": [
                    "Vincent P. Grande",
                    "Michael T. Schaub"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14427v1",
                    "http://arxiv.org/pdf/2311.14427v1"
                ],
                "primary_category": "math.AT",
                "categories": [
                    "math.AT",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00803v1/1.0",
                "title": "InceptionCaps: A Performant Glaucoma Classification Model for\n  Data-scarce Environment",
                "year": 2023,
                "abstract": "Glaucoma is an irreversible ocular disease and is the second leading cause of\nvisual disability worldwide. Slow vision loss and the asymptomatic nature of\nthe disease make its diagnosis challenging. Early detection is crucial for\npreventing irreversible blindness. Ophthalmologists primarily use retinal\nfundus images as a non-invasive screening method. Convolutional neural networks\n(CNN) have demonstrated high accuracy in the classification of medical images.\nNevertheless, CNN's translation-invariant nature and inability to handle the\npart-whole relationship between objects make its direct application unsuitable\nfor glaucomatous fundus image classification, as it requires a large number of\nlabelled images for training. This work reviews existing state of the art\nmodels and proposes InceptionCaps, a novel capsule network (CapsNet) based deep\nlearning model having pre-trained InceptionV3 as its convolution base, for\nautomatic glaucoma classification. InceptionCaps achieved an accuracy of 0.956,\nspecificity of 0.96, and AUC of 0.9556, which surpasses several\nstate-of-the-art deep learning model performances on the RIM-ONE v2 dataset.\nThe obtained result demonstrates the robustness of the proposed deep learning\nmodel.",
                "authors": [
                    "Gyanendar Manohar",
                    "Ruairi O'Reilly"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00803v1",
                    "http://arxiv.org/pdf/2312.00803v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14419v1/1.0",
                "title": "Narratives from GPT-derived Networks of News, and a link to Financial\n  Markets Dislocations",
                "year": 2023,
                "abstract": "Starting from a corpus of economic articles from The Wall Street Journal, we\npresent a novel systematic way to analyse news content that evolves over time.\nWe leverage on state-of-the-art natural language processing techniques (i.e.\nGPT3.5) to extract the most important entities of each article available, and\naggregate co-occurrence of entities in a related graph at the weekly level.\nNetwork analysis techniques and fuzzy community detection are tested on the\nproposed set of graphs, and a framework is introduced that allows systematic\nbut interpretable detection of topics and narratives. In parallel, we propose\nto consider the sentiment around main entities of an article as a more accurate\nproxy for the overall sentiment of such piece of text, and describe a\ncase-study to motivate this choice. Finally, we design features that\ncharacterise the type and structure of news within each week, and map them to\nmoments of financial markets dislocations. The latter are identified as dates\nwith unusually high volatility across asset classes, and we find quantitative\nevidence that they relate to instances of high entropy in the high-dimensional\nspace of interconnected news. This result further motivates the pursued efforts\nto provide a novel framework for the systematic analysis of narratives within\nnews.",
                "authors": [
                    "Deborah Miori",
                    "Constantin Petrov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14419v1",
                    "http://arxiv.org/pdf/2311.14419v1"
                ],
                "primary_category": "q-fin.CP",
                "categories": [
                    "q-fin.CP",
                    "econ.GN",
                    "q-fin.EC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14768v1/1.0",
                "title": "AdaDiff: Adaptive Step Selection for Fast Diffusion",
                "year": 2023,
                "abstract": "Diffusion models, as a type of generative models, have achieved impressive\nresults in generating images and videos conditioned on textual conditions.\nHowever, the generation process of diffusion models involves denoising for\ndozens of steps to produce photorealistic images/videos, which is\ncomputationally expensive. Unlike previous methods that design\n``one-size-fits-all'' approaches for speed up, we argue denoising steps should\nbe sample-specific conditioned on the richness of input texts. To this end, we\nintroduce AdaDiff, a lightweight framework designed to learn instance-specific\nstep usage policies, which are then used by the diffusion model for generation.\nAdaDiff is optimized using a policy gradient method to maximize a carefully\ndesigned reward function, balancing inference time and generation quality. We\nconduct experiments on three image generation and two video generation\nbenchmarks and demonstrate that our approach achieves similar results in terms\nof visual quality compared to the baseline using a fixed 50 denoising steps\nwhile reducing inference time by at least 33%, going as high as 40%.\nFurthermore, our qualitative analysis shows that our method allocates more\nsteps to more informative text conditions and fewer steps to simpler text\nconditions.",
                "authors": [
                    "Hui Zhang",
                    "Zuxuan Wu",
                    "Zhen Xing",
                    "Jie Shao",
                    "Yu-Gang Jiang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14768v1",
                    "http://arxiv.org/pdf/2311.14768v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14414v1/1.0",
                "title": "Deformable multi-modal image registration for the correlation between\n  optical measurements and histology images",
                "year": 2023,
                "abstract": "The correlation of optical measurements with a correct pathology label is\noften hampered by imprecise registration caused by deformations in histology\nimages. This study explores an automated multi-modal image registration\ntechnique utilizing deep learning principles to align snapshot breast specimen\nimages with corresponding histology images. The input images, acquired through\ndifferent modalities, present challenges due to variations in intensities and\nstructural visibility, making linear assumptions inappropriate. An unsupervised\nand supervised learning approach, based on the VoxelMorph model, was explored,\nmaking use of a dataset with manually registered images used as ground truth.\nEvaluation metrics, including Dice scores and mutual information, reveal that\nthe unsupervised model outperforms the supervised (and manual approach)\nsignificantly, achieving superior image alignment. This automated registration\napproach holds promise for improving the validation of optical technologies by\nminimizing human errors and inconsistencies associated with manual\nregistration.",
                "authors": [
                    "Lianne Feenstra",
                    "Maud Lambregts",
                    "Theo J. M Ruers",
                    "Behdad Dashtbozorg"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14414v1",
                    "http://arxiv.org/pdf/2311.14414v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14410v1/1.0",
                "title": "Unveiling The Factors of Aesthetic Preferences with Explainable AI",
                "year": 2023,
                "abstract": "The allure of aesthetic appeal in images captivates our senses, yet the\nunderlying intricacies of aesthetic preferences remain elusive. In this study,\nwe pioneer a novel perspective by utilizing machine learning models that focus\non aesthetic attributes known to influence preferences. Through a data mining\napproach, our models process these attributes as inputs to predict the\naesthetic scores of images. Moreover, to delve deeper and obtain interpretable\nexplanations regarding the factors driving aesthetic preferences, we utilize\nthe popular Explainable AI (XAI) technique known as SHapley Additive\nexPlanations (SHAP). Our methodology involves employing various machine\nlearning models, including Random Forest, XGBoost, Support Vector Regression,\nand Multilayer Perceptron, to compare their performances in accurately\npredicting aesthetic scores, and consistently observing results in conjunction\nwith SHAP. We conduct experiments on three image aesthetic benchmarks,\nproviding insights into the roles of attributes and their interactions.\nUltimately, our study aims to shed light on the complex nature of aesthetic\npreferences in images through machine learning and provides a deeper\nunderstanding of the attributes that influence aesthetic judgements.",
                "authors": [
                    "Derya Soydaner",
                    "Johan Wagemans"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14410v1",
                    "http://arxiv.org/pdf/2311.14410v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14409v2/1.0",
                "title": "A Shock Flash Breaking Out of a Dusty Red Supergiant",
                "year": 2023,
                "abstract": "Shock breakout emission is light that arises when a shockwave, generated by\ncore-collapse explosion of a massive star, passes through its outer envelope.\nHitherto, the earliest detection of such a signal was at several hours after\nthe explosion, though a few others had been reported. The temporal evolution of\nearly light curves should reveal insights into the shock propagation, including\nexplosion asymmetry and environment in the vicinity, but this has been hampered\nby the lack of multiwavelength observations. Here we report the instant\nmultiband observations of a type II supernova (SN 2023ixf) in the galaxy M101\n(at a distance of 6.85+/-0.15 Mpc), beginning at about 1.4 hours after the\nexplosion. The exploding star was a red supergiant with a radius of about 440\nsolar radii. The light curves evolved rapidly, on timescales of 1-2 hours, and\nappeared unusually fainter and redder than predicted by models within the first\nfew hours, which we attribute to an optically thick dust shell before it was\ndisrupted by the shockwave. We infer that the breakout and perhaps the\ndistribution of the surrounding dust were not spherically symmetric.",
                "authors": [
                    "Gaici Li",
                    "Maokai Hu",
                    "Wenxiong Li",
                    "Yi Yang",
                    "Xiaofeng Wang",
                    "Shengyu Yan",
                    "Lei Hu",
                    "Jujia Zhang",
                    "Yiming Mao",
                    "Henrik Riise",
                    "Xing Gao",
                    "Tianrui Sun",
                    "Jialian Liu",
                    "Dingrong Xiong",
                    "Lifan Wang",
                    "Jun Mo",
                    "Abdusamatjan Iskandar",
                    "Gaobo Xi",
                    "Danfeng Xiang",
                    "Lingzhi Wang",
                    "Guoyou Sun",
                    "Keming Zhang",
                    "Jian Chen",
                    "Weili Lin",
                    "Fangzhou Guo",
                    "Qichun Liu",
                    "Guangyao Cai",
                    "Wenjie Zhou",
                    "Jingyuan Zhao",
                    "Jin Chen",
                    "Xin Zheng",
                    "Keying Li",
                    "Mi Zhang",
                    "Shijun Xu",
                    "Xiaodong Lyu",
                    "A. J. Castro-Tirado",
                    "Vasilii Chufarin",
                    "Nikolay Potapov",
                    "Ivan Ionov",
                    "Stanislav Korotkiy",
                    "Sergey Nazarov",
                    "Kirill Sokolovsky",
                    "Norman Hamann",
                    "Eliot Herman"
                ],
                "url": [
                    "http://dx.doi.org/10.1038/s41586-023-06843-6",
                    "http://arxiv.org/abs/2311.14409v2",
                    "http://arxiv.org/pdf/2311.14409v2"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE",
                    "astro-ph.SR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14407v1/1.0",
                "title": "LLamol: A Dynamic Multi-Conditional Generative Transformer for De Novo\n  Molecular Design",
                "year": 2023,
                "abstract": "Generative models have demonstrated substantial promise in Natural Language\nProcessing (NLP) and have found application in designing molecules, as seen in\nGeneral Pretrained Transformer (GPT) models. In our efforts to develop such a\ntool for exploring the organic chemical space in search of potentially\nelectro-active compounds, we present \"LLamol\", a single novel generative\ntransformer model based on the LLama 2 architecture, which was trained on a 13M\nsuperset of organic compounds drawn from diverse public sources. To allow for a\nmaximum flexibility in usage and robustness in view of potentially incomplete\ndata, we introduce \"Stochastic Context Learning\" as a new training procedure.\nWe demonstrate that the resulting model adeptly handles single- and\nmulti-conditional organic molecule generation with up to four conditions, yet\nmore are possible. The model generates valid molecular structures in SMILES\nnotation while flexibly incorporating three numerical and/or one token sequence\ninto the generative process, just as requested. The generated compounds are\nvery satisfactory in all scenarios tested. In detail, we showcase the model's\ncapability to utilize token sequences for conditioning, either individually or\nin combination with numerical properties, making LLamol a potent tool for de\nnovo molecule design, easily expandable with new properties.",
                "authors": [
                    "Niklas Dobberstein",
                    "Astrid Maass",
                    "Jan Hamaekers"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14407v1",
                    "http://arxiv.org/pdf/2311.14407v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "physics.chem-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14404v1/1.0",
                "title": "BHGNN-RT: Network embedding for directed heterogeneous graphs",
                "year": 2023,
                "abstract": "Networks are one of the most valuable data structures for modeling problems\nin the real world. However, the most recent node embedding strategies have\nfocused on undirected graphs, with limited attention to directed graphs,\nespecially directed heterogeneous graphs. In this study, we first investigated\nthe network properties of directed heterogeneous graphs. Based on network\nanalysis, we proposed an embedding method, a bidirectional heterogeneous graph\nneural network with random teleport (BHGNN-RT), for directed heterogeneous\ngraphs, that leverages bidirectional message-passing process and network\nheterogeneity. With the optimization of teleport proportion, BHGNN-RT is\nbeneficial to overcome the over-smoothing problem. Extensive experiments on\nvarious datasets were conducted to verify the efficacy and efficiency of\nBHGNN-RT. Furthermore, we investigated the effects of message components, model\nlayer, and teleport proportion on model performance. The performance comparison\nwith all other baselines illustrates that BHGNN-RT achieves state-of-the-art\nperformance, outperforming the benchmark methods in both node classification\nand unsupervised clustering tasks.",
                "authors": [
                    "Xiyang Sun",
                    "Fumiyasu Komaki"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14404v1",
                    "http://arxiv.org/pdf/2311.14404v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14403v1/1.0",
                "title": "Introduction to stellar and substellar physics in modified gravity",
                "year": 2023,
                "abstract": "We discuss the standard Lane-Emden formalism as well as the one related to\nthe slowly rotating objects. It is preceded by a brief introduction of\ndifferent forms of the polytropic equation of state. This allows to study a\nwide class of astrophysical objects in the framework of a given theory of\ngravity, as demonstrated in a few examples. We will discuss light elements\nburning processes and cooling models in stars and substellar objects with the\nuse of the Lane-Emden formalism.",
                "authors": [
                    "Aneta Wojnar"
                ],
                "url": [
                    "http://dx.doi.org/10.1007/978-3-031-42096-2_7",
                    "http://arxiv.org/abs/2311.14403v1",
                    "http://arxiv.org/pdf/2311.14403v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc",
                    "astro-ph.EP",
                    "astro-ph.SR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14402v1/1.0",
                "title": "TEA: Test-time Energy Adaptation",
                "year": 2023,
                "abstract": "Test-time adaptation (TTA) aims to improve model generalizability when test\ndata diverges from training distribution, offering the distinct advantage of\nnot requiring access to training data and processes, especially valuable in the\ncontext of large pre-trained models. However, current TTA methods fail to\naddress the fundamental issue: covariate shift, i.e., the decreased\ngeneralizability can be attributed to the model's reliance on the marginal\ndistribution of the training data, which may impair model calibration and\nintroduce confirmation bias. To address this, we propose a novel energy-based\nperspective, enhancing the model's perception of target data distributions\nwithout requiring access to training data or processes. Building on this\nperspective, we introduce $\\textbf{T}$est-time $\\textbf{E}$nergy\n$\\textbf{A}$daptation ($\\textbf{TEA}$), which transforms the trained classifier\ninto an energy-based model and aligns the model's distribution with the test\ndata's, enhancing its ability to perceive test distributions and thus improving\noverall generalizability. Extensive experiments across multiple tasks,\nbenchmarks and architectures demonstrate TEA's superior generalization\nperformance against state-of-the-art methods. Further in-depth analyses reveal\nthat TEA can equip the model with a comprehensive perception of test\ndistribution, ultimately paving the way toward improved generalization and\ncalibration.",
                "authors": [
                    "Yige Yuan",
                    "Bingbing Xu",
                    "Liang Hou",
                    "Fei Sun",
                    "Huawei Shen",
                    "Xueqi Cheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14402v1",
                    "http://arxiv.org/pdf/2311.14402v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00042v2/1.0",
                "title": "DeepTreeGANv2: Iterative Pooling of Point Clouds",
                "year": 2023,
                "abstract": "In High Energy Physics, detailed and time-consuming simulations are used for\nparticle interactions with detectors. To bypass these simulations with a\ngenerative model, the generation of large point clouds in a short time is\nrequired, while the complex dependencies between the particles must be\ncorrectly modelled. Particle showers are inherently tree-based processes, as\neach particle is produced by the decay or detector interaction of a particle of\nthe previous generation. In this work, we present a significant extension to\nDeepTreeGAN, featuring a critic, that is able to aggregate such point clouds\niteratively in a tree-based manner. We show that this model can reproduce\ncomplex distributions, and we evaluate its performance on the public JetNet 150\ndataset.",
                "authors": [
                    "Moritz Alfons Wilhelm Scham",
                    "Dirk Kr\u00fccker",
                    "Kerstin Borras"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00042v2",
                    "http://arxiv.org/pdf/2312.00042v2"
                ],
                "primary_category": "physics.data-an",
                "categories": [
                    "physics.data-an",
                    "cs.LG",
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14401v1/1.0",
                "title": "Prototype of deployment of Federated Learning with IoT devices",
                "year": 2023,
                "abstract": "In the age of technology, data is an increasingly important resource. This\nimportance is growing in the field of Artificial Intelligence (AI), where sub\nfields such as Machine Learning (ML) need more and more data to achieve better\nresults. Internet of Things (IoT) is the connection of sensors and smart\nobjects to collect and exchange data, in addition to achieving many other\ntasks. A huge amount of the resource desired, data, is stored in mobile\ndevices, sensors and other Internet of Things (IoT) devices, but remains there\ndue to data protection restrictions. At the same time these devices do not have\nenough data or computational capacity to train good models. Moreover,\ntransmitting, storing and processing all this data on a centralised server is\nproblematic. Federated Learning (FL) provides an innovative solution that\nallows devices to learn in a collaborative way. More importantly, it\naccomplishes this without violating data protection laws. FL is currently\ngrowing, and there are several solutions that implement it. This article\npresents a prototype of a FL solution where the IoT devices used were raspberry\npi boards. The results compare the performance of a solution of this type with\nthose obtained in traditional approaches. In addition, the FL solution\nperformance was tested in a hostile environment. A convolutional neural network\n(CNN) and a image data set were used. The results show the feasibility and\nusability of these techniques, although in many cases they do not reach the\nperformance of traditional approaches.",
                "authors": [
                    "Pablo Garc\u00eda Santaclara",
                    "Ana Fern\u00e1ndez Vilas",
                    "Rebeca P. D\u00edaz Redondo"
                ],
                "url": [
                    "http://dx.doi.org/10.1145/3551663.3558681",
                    "http://arxiv.org/abs/2311.14401v1",
                    "http://arxiv.org/pdf/2311.14401v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14394v1/1.0",
                "title": "Odd Khovanov homology and higher representation theory",
                "year": 2023,
                "abstract": "We define a supercategorification of the $q$-Schur algebra of level two and\nan odd analogue of $\\mathfrak{gl}_2$-foams. Using these constructions, we\ndefine a homological invariant of tangles, and show that it coincides with odd\nKhovanov homology when restricted to links. This gives a representation\ntheoretic construction of odd Khovanov homology. In the process, we define a\ntensor product on the category of chain complexes in super-2-categories which\nis compatible with homotopies. This could be of independent interest.",
                "authors": [
                    "L\u00e9o Schelstraete",
                    "Pedro Vaz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14394v1",
                    "http://arxiv.org/pdf/2311.14394v1"
                ],
                "primary_category": "math.GT",
                "categories": [
                    "math.GT",
                    "math.QA",
                    "math.RT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14393v1/1.0",
                "title": "On the structure factor of jammed particle configurations on the\n  one-dimensional lattice",
                "year": 2023,
                "abstract": "A broad class of blocked or jammed configurations of particles on the\none-dimensional lattice can be characterized in terms of local rules involving\nonly the lengths of clusters of particles (occupied sites) and of holes (empty\nsites). Examples of physical relevance include the metastable states reached by\nkinetically constrained spin chains, the attractors of totally irreversible\nprocesses such as random sequential adsorption, and arrays of Rydberg atoms in\nthe blockade regime. The configurational entropy of ensembles of such blocked\nconfigurations has been investigated recently by means of an approach inspired\nfrom the theory of stochastic renewal processes. This approach provides a\nvaluable alternative to the more traditional transfer-matrix formalism. We show\nthat the renewal approach is also an efficient tool to investigate a range of\nobservables in uniform ensembles of blocked configurations, besides their\nconfigurational entropy. The main emphasis is on their structure factor and\ncorrelation function.",
                "authors": [
                    "Jean-Marc Luck"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14393v1",
                    "http://arxiv.org/pdf/2311.14393v1"
                ],
                "primary_category": "cond-mat.stat-mech",
                "categories": [
                    "cond-mat.stat-mech",
                    "cond-mat.dis-nn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14391v2/1.0",
                "title": "\u00daFAL CorPipe at CRAC 2023: Larger Context Improves Multilingual\n  Coreference Resolution",
                "year": 2023,
                "abstract": "We present CorPipe, the winning entry to the CRAC 2023 Shared Task on\nMultilingual Coreference Resolution. Our system is an improved version of our\nearlier multilingual coreference pipeline, and it surpasses other participants\nby a large margin of 4.5 percent points. CorPipe first performs mention\ndetection, followed by coreference linking via an antecedent-maximization\napproach on the retrieved spans. Both tasks are trained jointly on all\navailable corpora using a shared pretrained language model. Our main\nimprovements comprise inputs larger than 512 subwords and changing the mention\ndecoding to support ensembling. The source code is available at\nhttps://github.com/ufal/crac2023-corpipe.",
                "authors": [
                    "Milan Straka"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14391v2",
                    "http://arxiv.org/pdf/2311.14391v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14386v1/1.0",
                "title": "Collective Memory, Consensus, and Learning explained by Network\n  Connectivity",
                "year": 2023,
                "abstract": "Humans cluster in social groups where they discuss their shared past,\nproblems, and potential solutions, learn collectively when they repeat\nactivities, synchronize when they sing or dance together, and bond through\nsocial cohesion. By representing a group network by a Laplacian matrix, the\noutcomes of these activities, as well as group's cohesion, can be predicted by\nits second smallest eigenvalue, called algebraic connectivity. It predicts well\nwhen processes converge towards a consensus or focal activity, but it cannot\npredict divergence, such as division of labor or polarization.",
                "authors": [
                    "Jeroen Bruggeman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14386v1",
                    "http://arxiv.org/pdf/2311.14386v1"
                ],
                "primary_category": "cs.SI",
                "categories": [
                    "cs.SI",
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14381v1/1.0",
                "title": "Potential Societal Biases of ChatGPT in Higher Education: A Scoping\n  Review",
                "year": 2023,
                "abstract": "ChatGPT and other Generative Artificial Intelligence (GAI) models tend to\ninherit and even amplify prevailing societal biases as they are trained on\nlarge amounts of existing data. Given the increasing usage of ChatGPT and other\nGAI by students, faculty members, and staff in higher education institutions\n(HEIs), there is an urgent need to examine the ethical issues involved such as\nits potential biases. In this scoping review, we clarify the ways in which\nbiases related to GAI in higher education settings have been discussed in\nrecent academic publications and identify what type of potential biases are\ncommonly reported in this body of literature. We searched for academic articles\nwritten in English, Chinese, and Japanese across four main databases concerned\nwith GAI usage in higher education and bias. Our findings show that while there\nis an awareness of potential biases around large language models (LLMs) and\nGAI, the majority of articles touch on ``bias'' at a relatively superficial\nlevel. Few identify what types of bias may occur under what circumstances.\nNeither do they discuss the possible implications for the higher education,\nstaff, faculty members, or students. There is a notable lack of empirical work\nat this point, and we call for higher education researchers and AI experts to\nconduct more research in this area.",
                "authors": [
                    "Ming Li",
                    "Ariunaa Enkhtur",
                    "Beverley Anne Yamamoto",
                    "Fei Cheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14381v1",
                    "http://arxiv.org/pdf/2311.14381v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14379v1/1.0",
                "title": "Robot Learning in the Era of Foundation Models: A Survey",
                "year": 2023,
                "abstract": "The proliferation of Large Language Models (LLMs) has s fueled a shift in\nrobot learning from automation towards general embodied Artificial Intelligence\n(AI). Adopting foundation models together with traditional learning methods to\nrobot learning has increasingly gained recent interest research community and\nshowed potential for real-life application. However, there are few literatures\ncomprehensively reviewing the relatively new technologies combined with\nrobotics. The purpose of this review is to systematically assess the\nstate-of-the-art foundation model techniques in the robot learning and to\nidentify future potential areas. Specifically, we first summarized the\ntechnical evolution of robot learning and identified the necessary preliminary\npreparations for foundation models including the simulators, datasets,\nfoundation model framework. In addition, we focused on the following four\nmainstream areas of robot learning including manipulation, navigation,\nplanning, and reasoning and demonstrated how the foundation model techniques\ncan be adopted in the above scenarios. Furthermore, critical issues which are\nneglected in the current literatures including robot hardware and software\ndecoupling, dynamic data, generalization performance with the presence of\nhuman, etc. were discussed. This review highlights the state-of-the-art\nprogress of foundation models in robot learning and future research should\nfocus on multimodal interaction especially dynamics data, exclusive foundation\nmodels for robots, and AI alignment, etc.",
                "authors": [
                    "Xuan Xiao",
                    "Jiahang Liu",
                    "Zhipeng Wang",
                    "Yanmin Zhou",
                    "Yong Qi",
                    "Qian Cheng",
                    "Bin He",
                    "Shuo Jiang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14379v1",
                    "http://arxiv.org/pdf/2311.14379v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14378v1/1.0",
                "title": "Ethical implications of ChatGPT in higher education: A scoping review",
                "year": 2023,
                "abstract": "This scoping review explores the ethical challenges of using ChatGPT in\neducation, focusing particularly on issues related to higher education. By\nreviewing recent academic articles written in English, Chinese, and Japanese,\nwe aimed to provide a comprehensive overview of relevant research while\nidentifying gaps for future considerations. Drawing on Arksey and O'Malley's\n(2005) five-stage scoping review framework, we identified research questions,\nsearch terms, and conducted article search from four databases in the target\nthree languages. Each article was reviewed by at least two researchers\nidentifying the main ethical issues of utilizing AI in education, particularly\nhigher education. Our analysis of ethical issues followed the framework\ndeveloped by DeepMind (Weiginger et al., 2021) to identify six main areas of\nethical concern in Language Models. The majority of papers were concerned with\nmisinformation harms (n=25) and/or human-computer interaction related harms\n(n=24). Given the rapid deployment of Generative Artificial Intelligence (GAI),\nit is imperative for educators to conduct more empirical studies to develop\nsound ethical policies for the use of GAI.",
                "authors": [
                    "Ming Li",
                    "Ariunaa Enkhtur",
                    "Fei Cheng",
                    "Beverley Anne Yamamoto"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14378v1",
                    "http://arxiv.org/pdf/2311.14378v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14376v1/1.0",
                "title": "Orthogonal thermal noise and transmission signals: A new coherent\n  perfect absorption's feature",
                "year": 2023,
                "abstract": "Coherent perfect absorption (CPA) is an interference process associated with\nthe zeros of the scattering matrix that enables light-with-light interactions\nin linear systems, of interest for optical computing, data processing and\nsensing. However, the noise properties of CPA remain relatively unexplored.\nHere, we demonstrate that CPA thermal noise signals exhibit a unique property:\nthey are orthogonal to the signals transmitted through the network. In turn,\nsuch property enables a variety of thermal noise management effects, such as\nthe physical separability of thermal noise and transmitted signals, and\n\"externally lossless\" networks that internally host radiative heat transfer\nprocesses. We believe that our results provide a new perspective on the many\nCPA technologies currently under development.",
                "authors": [
                    "Douglas O\u00f1a",
                    "Angel Ortega-Gomez",
                    "Osmery Hern\u00e1ndez",
                    "I\u00f1igo Liberal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14376v1",
                    "http://arxiv.org/pdf/2311.14376v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14369v1/1.0",
                "title": "Elastic Kink-Meson Scattering",
                "year": 2023,
                "abstract": "In classical field theory, radiation does not reflect off of reflectionless\nkinks. In quantum field theory, radiation quanta, called mesons, can be\nreflected. We provide a general analytical formula for the leading order\namplitude and probability for the elastic scattering of mesons off of\nreflectionless quantum kinks. In the case of the Sine-Gordon model we verify\nthat, due to a cancellation of six contributing processes, our general formula\nyields an amplitude of zero, as is required by integrability.",
                "authors": [
                    "Jarah Evslin",
                    "Hui Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14369v1",
                    "http://arxiv.org/pdf/2311.14369v1"
                ],
                "primary_category": "hep-th",
                "categories": [
                    "hep-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14365v3/1.0",
                "title": "Contrasting observables related to the $N^*(1535)$ from the molecular or\n  a genuine structure",
                "year": 2023,
                "abstract": "In this work we compare the predictions for the scattering length and\neffective range of the channels $K^0 \\Sigma^+, K^+ \\Sigma^0 , K^+ \\Lambda$ and\n$\\eta p$, assuming the $N^*(1535)$ state as a molecular state of these\nchannels, or an original genuine state, made for instance from three quarks.\nLooking at very different scenarios, what we conclude is that the predictions\nof these two pictures are drastically different, to the point that we advise\nthe measurement of these magnitudes, accessible for instance by measuring\ncorrelation functions, in order to gain much valuable information concerning\nthe nature of this state.",
                "authors": [
                    "Hai-Peng Li",
                    "Jing Song",
                    "Wei-Hong Liang",
                    "R. Molina",
                    "E. Oset"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14365v3",
                    "http://arxiv.org/pdf/2311.14365v3"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "nucl-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14360v1/1.0",
                "title": "The physics of solar spectral imaging observations in dm-cm wavelengths\n  and the application on space weather",
                "year": 2023,
                "abstract": "Recently, several new solar radio telescopes have been put into operation and\nprovided spectral-imaging observations with much higher resolutions in\ndecimeter (dm) and centimeter (cm) wavelengths. These telescopes include the\nMingantu Spectral Radioheliograph (MUSER, at frequencies of 0.4 - 15 GHz), the\nExpanded Owens Valley Solar Array (EOVSA, at frequencies of 1 - 18 GHz), and\nthe Siberian Radio Heliograph (SRH, at frequencies of 3 - 24 GHz). These\nobservations offer unprecedented opportunities to study solar physics and space\nweather, especially to diagnose the coronal magnetic fields, reveal the basic\nnature of solar eruptions and the related non-thermal energy release, particle\naccelerations and propagation, and the related emission mechanisms. These\nresults might be the important input to the space weather modeling for\npredicting the occurrence of disastrous powerful space weather events. In order\nto provide meaningful reference for other solar physicists and space weather\nresearchers, this paper mainly focus on discussing the potential scientific\nproblems of solar radio spectral-imaging observations in dm-cm wavelengths and\nits possible applications in the field of space weather. These results will\nprovide a helpful reference for colleagues to make full use of the latest and\nfuture observation data obtained from the above solar radio telescopes.",
                "authors": [
                    "Baolin Tan",
                    "Yihua Yan",
                    "Jing Huang",
                    "Yin Zhang",
                    "Chengming Tan",
                    "Xiaoshuai Zhu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14360v1",
                    "http://arxiv.org/pdf/2311.14360v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "astro-ph.GA",
                    "physics.space-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14357v1/1.0",
                "title": "Emergence of long-range angular correlations in low-multiplicity\n  proton-proton collisions",
                "year": 2023,
                "abstract": "This Letter presents the measurement of near-side associated per-trigger\nyields, denoted ridge yields, from the analysis of angular correlations of\ncharged hadrons in proton-proton collisions at $\\sqrt{s}$ = 13 TeV. Long-range\nridge yields are extracted for pairs of charged particles with a pseudorapidity\ndifference of $1.4 < |\\Delta\\eta| < 1.8$ and a transverse momentum of $1 <\np_{\\rm T} < 2$ GeV/$c$, as a function of the charged-particle multiplicity\nmeasured at midrapidity. This study extends the measurements of the ridge yield\nto the low multiplicity region, where in hadronic collisions it is typically\nconjectured that a strongly-interacting medium is unlikely to be formed. The\nprecision of the new results allows for the first direct quantitative\ncomparison with the results obtained in $\\mathrm {e^{+}e^{-}}$ collisions at\n$\\sqrt{s}$ = 91 GeV, where initial-state effects such as pre-equilibrium\ndynamics and collision geometry are not expected to play a role. In the\nmultiplicity range where the $\\mathrm {e^{+}e^{-}}$ results have good\nprecision, the measured ridge yields in pp collisions are substantially larger\nthan the limits set in $\\mathrm {e^{+}e^{-}}$ annihilations. Consequently, the\nfindings presented in this Letter suggest that the processes involved in\n$\\mathrm {e^{+}e^{-}}$ annihilations do not contribute significantly to the\nemergence of long-range correlations in pp collisions.",
                "authors": [
                    "ALICE Collaboration"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14357v1",
                    "http://arxiv.org/pdf/2311.14357v1"
                ],
                "primary_category": "nucl-ex",
                "categories": [
                    "nucl-ex",
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14353v2/1.0",
                "title": "Average Token Delay: A Duration-aware Latency Metric for Simultaneous\n  Translation",
                "year": 2023,
                "abstract": "Simultaneous translation is a task in which the translation begins before the\nend of an input speech segment. Its evaluation should be conducted based on\nlatency in addition to quality, and for users, the smallest possible amount of\nlatency is preferable. Most existing metrics measure latency based on the start\ntimings of partial translations and ignore their duration. This means such\nmetrics do not penalize the latency caused by long translation output, which\ndelays the comprehension of users and subsequent translations. In this work, we\npropose a novel latency evaluation metric for simultaneous translation called\n\\emph{Average Token Delay} (ATD) that focuses on the duration of partial\ntranslations. We demonstrate its effectiveness through analyses simulating\nuser-side latency based on Ear-Voice Span (EVS). In our experiment, ATD had the\nhighest correlation with EVS among baseline latency metrics under most\nconditions.",
                "authors": [
                    "Yasumasa Kano",
                    "Katsuhito Sudoh",
                    "Satoshi Nakamura"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14353v2",
                    "http://arxiv.org/pdf/2311.14353v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14348v1/1.0",
                "title": "Testing an instrument to measure the BPMS-KM Support Model",
                "year": 2023,
                "abstract": "BPMS (Business Process Management System) represents a type of software that\nautomates the organizational processes looking for efficiency. Since the\nknowledge of organizations lies in their processes, it seems probable that a\nBPMS can be used to manage the knowledge applied in these processes. Through\nthe BPMS-KM Support Model, this study aims to determine the reliability and\nvalidity of a 65-item instrument to measure the utility and the use of a BPMS\nfor knowledge management (KM). A questionnaire was sent to 242 BPMS users and\nto determine its validity, a factorial analysis was conducted. The results\nshowed that the measuring instrument is trustworthy and valid. It represents\nimplications for research, since it provides an instrument validated for\nresearch on the success of a BPMS for KM. There would also be practical\nimplications, since managers can evaluate the use of BPMS, in addition to\nautomating processes to manage knowledge.",
                "authors": [
                    "Alicia Martin-Navarro",
                    "Maria Paula Lechuga Sancho",
                    "Jose Aurelio Medina-Garrido"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/j.eswa.2021.115005",
                    "http://arxiv.org/abs/2311.14348v1",
                    "http://arxiv.org/pdf/2311.14348v1"
                ],
                "primary_category": "econ.GN",
                "categories": [
                    "econ.GN",
                    "q-fin.EC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14347v1/1.0",
                "title": "Typed compositional quantum computation with lenses",
                "year": 2023,
                "abstract": "We propose a type-theoretic framework for describing and proving properties\nof quantum computations, in particular those presented as quantum circuits. Our\nproposal is based on an observation that, in the polymorphic type system of\nCoq, currying on quantum states allows us to apply quantum gates directly\ninside a complex circuit. By introducing a discrete notion of lens to control\nthis currying, we are further able to separate the combinatorics of the circuit\nstructure from the computational content of gates. We apply our development to\ndefine quantum circuits recursively from the bottom up, and prove their\ncorrectness compositionally.",
                "authors": [
                    "Jacques Garrigue",
                    "Takafumi Saikawa"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14347v1",
                    "http://arxiv.org/pdf/2311.14347v1"
                ],
                "primary_category": "cs.PL",
                "categories": [
                    "cs.PL",
                    "cs.LO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14343v1/1.0",
                "title": "Highly Detailed and Temporal Consistent Video Stylization via\n  Synchronized Multi-Frame Diffusion",
                "year": 2023,
                "abstract": "Text-guided video-to-video stylization transforms the visual appearance of a\nsource video to a different appearance guided on textual prompts. Existing\ntext-guided image diffusion models can be extended for stylized video\nsynthesis. However, they struggle to generate videos with both highly detailed\nappearance and temporal consistency. In this paper, we propose a synchronized\nmulti-frame diffusion framework to maintain both the visual details and the\ntemporal consistency. Frames are denoised in a synchronous fashion, and more\nimportantly, information of different frames is shared since the beginning of\nthe denoising process. Such information sharing ensures that a consensus, in\nterms of the overall structure and color distribution, among frames can be\nreached in the early stage of the denoising process before it is too late. The\noptical flow from the original video serves as the connection, and hence the\nvenue for information sharing, among frames. We demonstrate the effectiveness\nof our method in generating high-quality and diverse results in extensive\nexperiments. Our method shows superior qualitative and quantitative results\ncompared to state-of-the-art video editing methods.",
                "authors": [
                    "Minshan Xie",
                    "Hanyuan Liu",
                    "Chengze Li",
                    "Tien-Tsin Wong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14343v1",
                    "http://arxiv.org/pdf/2311.14343v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14342v2/1.0",
                "title": "AI-based Attack Graph Generation",
                "year": 2023,
                "abstract": "With the advancement of IoT technology, many electronic devices are\ninterconnected through networks, communicating with each other and performing\nspecific roles. However, as numerous devices join networks, the threat of\ncyberattacks also escalates. Preventing and detecting cyber threats are\ncrucial, and one method of preventing such threats involves using attack\ngraphs. Attack graphs are widely used to assess security threats within\nnetworks. However, a drawback emerges as the network scales, as generating\nattack graphs becomes time-consuming. To overcome this limitation, artificial\nintelligence models can be employed. By utilizing AI models, attack graphs can\nbe created within a short period, approximating optimal outcomes. AI models\ndesigned for attack graph generation consist of encoders and decoders, trained\nusing reinforcement learning algorithms. After training the AI models, we\nconfirmed the model's learning effectiveness by observing changes in loss and\nreward values. Additionally, we compared attack graphs generated by the AI\nmodel with those created through conventional methods.",
                "authors": [
                    "Sangbeom Park",
                    "Jaesung Lee",
                    "Jeong Do Yoo",
                    "Min Geun Song",
                    "Hyosun Lee",
                    "Jaewoong Choi",
                    "Chaeyeon Sagong",
                    "Huy Kang Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14342v2",
                    "http://arxiv.org/pdf/2311.14342v2"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14339v1/1.0",
                "title": "Towards Concept-based Interpretability of Skin Lesion Diagnosis using\n  Vision-Language Models",
                "year": 2023,
                "abstract": "Concept-based models naturally lend themselves to the development of\ninherently interpretable skin lesion diagnosis, as medical experts make\ndecisions based on a set of visual patterns of the lesion. Nevertheless, the\ndevelopment of these models depends on the existence of concept-annotated\ndatasets, whose availability is scarce due to the specialized knowledge and\nexpertise required in the annotation process. In this work, we show that\nvision-language models can be used to alleviate the dependence on a large\nnumber of concept-annotated samples. In particular, we propose an embedding\nlearning strategy to adapt CLIP to the downstream task of skin lesion\nclassification using concept-based descriptions as textual embeddings. Our\nexperiments reveal that vision-language models not only attain better accuracy\nwhen using concepts as textual embeddings, but also require a smaller number of\nconcept-annotated samples to attain comparable performance to approaches\nspecifically devised for automatic concept generation.",
                "authors": [
                    "Cristiano Patr\u00edcio",
                    "Lu\u00eds F. Teixeira",
                    "Jo\u00e3o C. Neves"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14339v1",
                    "http://arxiv.org/pdf/2311.14339v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14335v1/1.0",
                "title": "Comparative Analysis of Transformers for Modeling Tabular Data: A\n  Casestudy using Industry Scale Dataset",
                "year": 2023,
                "abstract": "We perform a comparative analysis of transformer-based models designed for\nmodeling tabular data, specifically on an industry-scale dataset. While earlier\nstudies demonstrated promising outcomes on smaller public or synthetic\ndatasets, the effectiveness did not extend to larger industry-scale datasets.\nThe challenges identified include handling high-dimensional data, the necessity\nfor efficient pre-processing of categorical and numerical features, and\naddressing substantial computational requirements.\n  To overcome the identified challenges, the study conducts an extensive\nexamination of various transformer-based models using both synthetic datasets\nand the default prediction Kaggle dataset (2022) from American Express. The\npaper presents crucial insights into optimal data pre-processing, compares\npre-training and direct supervised learning methods, discusses strategies for\nmanaging categorical and numerical features, and highlights trade-offs between\ncomputational resources and performance. Focusing on temporal financial data\nmodeling, the research aims to facilitate the systematic development and\ndeployment of transformer-based models in real-world scenarios, emphasizing\nscalability.",
                "authors": [
                    "Usneek Singh",
                    "Piyush Arora",
                    "Shamika Ganesan",
                    "Mohit Kumar",
                    "Siddhant Kulkarni",
                    "Salil R. Joshi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14335v1",
                    "http://arxiv.org/pdf/2311.14335v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14332v1/1.0",
                "title": "GATGPT: A Pre-trained Large Language Model with Graph Attention Network\n  for Spatiotemporal Imputation",
                "year": 2023,
                "abstract": "The analysis of spatiotemporal data is increasingly utilized across diverse\ndomains, including transportation, healthcare, and meteorology. In real-world\nsettings, such data often contain missing elements due to issues like sensor\nmalfunctions and data transmission errors. The objective of spatiotemporal\nimputation is to estimate these missing values by understanding the inherent\nspatial and temporal relationships in the observed multivariate time series.\nTraditionally, spatiotemporal imputation has relied on specific, intricate\narchitectures designed for this purpose, which suffer from limited\napplicability and high computational complexity. In contrast, our approach\nintegrates pre-trained large language models (LLMs) into spatiotemporal\nimputation, introducing a groundbreaking framework, GATGPT. This framework\nmerges a graph attention mechanism with LLMs. We maintain most of the LLM\nparameters unchanged to leverage existing knowledge for learning temporal\npatterns, while fine-tuning the upper layers tailored to various applications.\nThe graph attention component enhances the LLM's ability to understand spatial\nrelationships. Through tests on three distinct real-world datasets, our\ninnovative approach demonstrates comparable results to established deep\nlearning benchmarks.",
                "authors": [
                    "Yakun Chen",
                    "Xianzhi Wang",
                    "Guandong Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14332v1",
                    "http://arxiv.org/pdf/2311.14332v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14329v1/1.0",
                "title": "Enabling Feedback-Free MIMO Transmission for FD-RAN: A Data-driven\n  Approach",
                "year": 2023,
                "abstract": "To enhance flexibility and facilitate resource cooperation, a novel\nfully-decoupled radio access network (FD-RAN) architecture is proposed for 6G.\nHowever, the decoupling of uplink (UL) and downlink (DL) in FD-RAN makes the\nexisting feedback mechanism ineffective. To this end, we propose an end-to-end\ndata-driven MIMO solution without the conventional channel feedback procedure.\nData-driven MIMO can alleviate the drawbacks of feedback including overheads\nand delay, and can provide customized precoding design for different BSs based\non their historical channel data. It essentially learns a mapping from\ngeolocation to MIMO transmission parameters. We first present a codebook-based\napproach, which selects transmission parameters from the statistics of discrete\nchannel state information (CSI) values and utilizes integer interpolation for\nspatial inference. We further present a non-codebook-based approach, which 1)\nderives the optimal precoder from the singular value decomposition (SVD) of the\nchannel; 2) utilizes variational autoencoder (VAE) to select the representative\nprecoder from the latent Gaussian representations; and 3) exploits Gaussian\nprocess regression (GPR) to predict unknown precoders in the space domain.\nExtensive simulations are performed on a link-level 5G simulator using\nrealistic ray-tracing channel data. The results demonstrate the effectiveness\nof data-driven MIMO, showcasing its potential for application in FD-RAN and 6G.",
                "authors": [
                    "Jingbo Liu",
                    "Jiacheng Chen",
                    "Zongxi Liu",
                    "Haibo Zhou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14329v1",
                    "http://arxiv.org/pdf/2311.14329v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14327v2/1.0",
                "title": "C-ITS Environment Modeling and Attack Modeling",
                "year": 2023,
                "abstract": "As technology advances, cities are evolving into smart cities, with the\nability to process large amounts of data and the increasing complexity and\ndiversification of various elements within urban areas. Among the core systems\nof a smart city is the Cooperative-Intelligent Transport Systems (C-ITS). C-ITS\nis a system where vehicles provide real-time information to drivers about\nsurrounding traffic conditions, sudden stops, falling objects, and other\naccident risks through roadside base stations. It consists of road\ninfrastructure, C-ITS centers, and vehicle terminals. However, as smart cities\nintegrate many elements through networks and electronic control, they are\nsusceptible to cybersecurity issues. In the case of cybersecurity problems in\nC-ITS, there is a significant risk of safety issues arising. This technical\ndocument aims to model the C-ITS environment and the services it provides, with\nthe purpose of identifying the attack surface where security incidents could\noccur in a smart city environment. Subsequently, based on the identified attack\nsurface, the document aims to construct attack scenarios and their respective\nstages. The document provides a description of the concept of C-ITS, followed\nby the description of the C-ITS environment model, service model, and attack\nscenario model defined by us.",
                "authors": [
                    "Jaewoong Choi",
                    "Min Geun Song",
                    "Hyosun Lee",
                    "Chaeyeon Sagong",
                    "Sangbeom Park",
                    "Jaesung Lee",
                    "Jeong Do Yoo",
                    "Huy Kang Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14327v2",
                    "http://arxiv.org/pdf/2311.14327v2"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14324v1/1.0",
                "title": "Large Language Models as Topological Structure Enhancers for\n  Text-Attributed Graphs",
                "year": 2023,
                "abstract": "The latest advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing (NLP). Inspired by the success of LLMs\nin NLP tasks, some recent work has begun investigating the potential of\napplying LLMs in graph learning tasks. However, most of the existing work\nfocuses on utilizing LLMs as powerful node feature augmenters, leaving\nemploying LLMs to enhance graph topological structures an understudied problem.\nIn this work, we explore how to leverage the information retrieval and text\ngeneration capabilities of LLMs to refine/enhance the topological structure of\ntext-attributed graphs (TAGs) under the node classification setting. First, we\npropose using LLMs to help remove unreliable edges and add reliable ones in the\nTAG. Specifically, we first let the LLM output the semantic similarity between\nnode attributes through delicate prompt designs, and then perform edge deletion\nand edge addition based on the similarity. Second, we propose using\npseudo-labels generated by the LLM to improve graph topology, that is, we\nintroduce the pseudo-label propagation as a regularization to guide the graph\nneural network (GNN) in learning proper edge weights. Finally, we incorporate\nthe two aforementioned LLM-based methods for graph topological refinement into\nthe process of GNN training, and perform extensive experiments on four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nLLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain\non public benchmarks).",
                "authors": [
                    "Shengyin Sun",
                    "Yuxiang Ren",
                    "Chen Ma",
                    "Xuecang Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14324v1",
                    "http://arxiv.org/pdf/2311.14324v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14321v1/1.0",
                "title": "Hypercontractivity for Quantum Erasure Channels via Multipartite\n  Log-Sobolev Inequality",
                "year": 2023,
                "abstract": "We prove an almost optimal hypercontractive inequality for quantum erasure\nchannels, generalizing the hypercontractivity for classical binary erasure\nchannels [NW16]. To our knowledge, this is the first hypercontractivity bound\nfor non-unital quantum channels. The traditional inductive arguments for\nclassical hypercontractivity cannot be generalized to the quantum setting due\nto the nature of non-commutativity of matrices. To overcome the difficulty, we\nestablish a multipartite quantum log-Sobolev inequality, which includes the\nclassical log-Sobolev inequality [DSC96] and the quantum log-Sobolev inequality\n[KT13] as one-partite cases. We establish a connection between our multipartite\nquantum log-Sobolev inequality and the hypercontractivity bound for quantum\nerasure channels via a refined quantum Gross' lemma [Gro75a], extending the\nanalogous connection [Kin14] between the quantum log-Sobolev inequality and the\nhypercontractivity for qubit unital channels. As an application, we prove an\nalmost tight bound (up to a constant factor) on the classical communication\ncomplexity of two-party common randomness generation assisted with erased-noisy\nEPR states, generalizing the tight bound on the same task assisted with\nerased-noisy random strings due to Guruswami and Radhakrishnan [GR16].",
                "authors": [
                    "Zongbo Bao",
                    "Yangjing Dong",
                    "Fengning Ou",
                    "Penghui Yao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14321v1",
                    "http://arxiv.org/pdf/2311.14321v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14318v1/1.0",
                "title": "On optimal tracking portfolio in incomplete markets: The classical\n  control and the reinforcement learning approaches",
                "year": 2023,
                "abstract": "This paper studies an infinite horizon optimal tracking portfolio problem\nusing capital injection in incomplete market models. We consider the benchmark\nprocess modelled by a geometric Brownian motion with zero drift driven by some\nunhedgeable risk. The relaxed tracking formulation is adopted where the\nportfolio value compensated by the injected capital needs to outperform the\nbenchmark process at any time, and the goal is to minimize the cost of the\ndiscounted total capital injection. In the first part, we solve the stochastic\ncontrol problem when the market model is known, for which the equivalent\nauxiliary control problem with reflections and the associated HJB equation with\na Neumann boundary condition are studied. In the second part, the market model\nis assumed to be unknown, for which we consider the exploratory formulation of\nthe control problem with entropy regularizer and develop the continuous-time\nq-learning algorithm for the stochastic control problem with state reflections.\nIn an illustrative example, we show the satisfactory performance of the\nq-learning algorithm.",
                "authors": [
                    "Lijun Bo",
                    "Yijie Huang",
                    "Xiang Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14318v1",
                    "http://arxiv.org/pdf/2311.14318v1"
                ],
                "primary_category": "q-fin.PM",
                "categories": [
                    "q-fin.PM",
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14316v1/1.0",
                "title": "Windformer:Bi-Directional Long-Distance Spatio-Temporal Network For Wind\n  Speed Prediction",
                "year": 2023,
                "abstract": "Wind speed prediction is critical to the management of wind power generation.\nDue to the large range of wind speed fluctuations and wake effect, there may\nalso be strong correlations between long-distance wind turbines. This\ndifficult-to-extract feature has become a bottleneck for improving accuracy.\nHistory and future time information includes the trend of airflow changes,\nwhether this dynamic information can be utilized will also affect the\nprediction effect. In response to the above problems, this paper proposes\nWindformer. First, Windformer divides the wind turbine cluster into multiple\nnon-overlapping windows and calculates correlations inside the windows, then\nshifts the windows partially to provide connectivity between windows, and\nfinally fuses multi-channel features based on detailed and global information.\nTo dynamically model the change process of wind speed, this paper extracts time\nseries in both history and future directions simultaneously. Compared with\nother current-advanced methods, the Mean Square Error (MSE) of Windformer is\nreduced by 0.5\\% to 15\\% on two datasets from NERL.",
                "authors": [
                    "Xuewei Li",
                    "Zewen Shang",
                    "Zhiqiang Liu",
                    "Jian Yu",
                    "Wei Xiong",
                    "Mei Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14316v1",
                    "http://arxiv.org/pdf/2311.14316v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14311v1/1.0",
                "title": "RelJoin: Relative-cost-based Selection of Distributed Join Methods for\n  Query Plan Optimization",
                "year": 2023,
                "abstract": "Selecting appropriate distributed join methods for logical join operations in\na query plan is crucial for the performance of data-intensive scalable\ncomputing (DISC). Different network communication patterns in the data exchange\nphase generate varying network communication workloads and significantly affect\nthe distributed join performance. However, most cost-based query optimizers\nfocus on the local computing cost and do not precisely model the network\ncommunication cost. We propose a cost model for various distributed join\nmethods to optimize join queries in DISC platforms. Our method precisely\nmeasures the network and local computing workloads in different execution\nphases, using information on the size and cardinality statistics of datasets\nand cluster join parallelism. Our cost model reveals the importance of the\nrelative size of the joining datasets. We implement an efficient distributed\njoin selection strategy, known as RelJoin in SparkSQL, which is an\nindustry-prevalent distributed data processing framework. RelJoin uses runtime\nadaptive statistics for accurate cost estimation and selects optimal\ndistributed join methods for logical joins to optimize the physical query plan.\nThe evaluation results on the TPC-DS benchmark show that RelJoin performs best\nin 62 of the 97 queries and can reduce the average query time by 21% compared\nwith other strategies.",
                "authors": [
                    "F. Liang",
                    "F. C. M. Lau",
                    "H. Cui",
                    "Y. Li",
                    "B. Lin",
                    "C. Li",
                    "X. Hu"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/j.ins.2023.120022",
                    "http://arxiv.org/abs/2311.14311v1",
                    "http://arxiv.org/pdf/2311.14311v1"
                ],
                "primary_category": "cs.DB",
                "categories": [
                    "cs.DB",
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14309v1/1.0",
                "title": "Meson production in $J/\u03c8$ decays and $J/\u03c8\\to N\\bar{N}\u03b3$\n  process",
                "year": 2023,
                "abstract": "It is shown that an account for the final-state interaction of real or\nvirtual nucleon and antinucleon produced in the processes $J/\\psi\\to\np\\bar{p}\\gamma$, $\\psi(2S)\\to p\\bar{p}\\gamma$, $J/\\psi\\to p\\bar{p}\\omega$, and\n$J/\\psi\\to3\\left(\\pi^{+}\\pi^{-}\\right)\\gamma$ near the threshold of $N\\bar{N}$\npair production allows one to obtain self-consistent description of these\nprocesses. Predictions of our model are in good agreement with experimental\ndata available. The proposed potential model also reproduces the corresponding\npartial cross sections of $p\\bar{p}$ scattering.",
                "authors": [
                    "S. G. Salnikov",
                    "A. I. Milstein"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14309v1",
                    "http://arxiv.org/pdf/2311.14309v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14307v1/1.0",
                "title": "Cosine Similarity Knowledge Distillation for Individual Class\n  Information Transfer",
                "year": 2023,
                "abstract": "Previous logits-based Knowledge Distillation (KD) have utilized predictions\nabout multiple categories within each sample (i.e., class predictions) and have\nemployed Kullback-Leibler (KL) divergence to reduce the discrepancy between the\nstudent and teacher predictions. Despite the proliferation of KD techniques,\nthe student model continues to fall short of achieving a similar level as\nteachers. In response, we introduce a novel and effective KD method capable of\nachieving results on par with or superior to the teacher models performance. We\nutilize teacher and student predictions about multiple samples for each\ncategory (i.e., batch predictions) and apply cosine similarity, a commonly used\ntechnique in Natural Language Processing (NLP) for measuring the resemblance\nbetween text embeddings. This metric's inherent scale-invariance property,\nwhich relies solely on vector direction and not magnitude, allows the student\nto dynamically learn from the teacher's knowledge, rather than being bound by a\nfixed distribution of the teacher's knowledge. Furthermore, we propose a method\ncalled cosine similarity weighted temperature (CSWT) to improve the\nperformance. CSWT reduces the temperature scaling in KD when the cosine\nsimilarity between the student and teacher models is high, and conversely, it\nincreases the temperature scaling when the cosine similarity is low. This\nadjustment optimizes the transfer of information from the teacher to the\nstudent model. Extensive experimental results show that our proposed method\nserves as a viable alternative to existing methods. We anticipate that this\napproach will offer valuable insights for future research on model compression.",
                "authors": [
                    "Gyeongdo Ham",
                    "Seonghak Kim",
                    "Suin Lee",
                    "Jae-Hyeok Lee",
                    "Daeshik Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14307v1",
                    "http://arxiv.org/pdf/2311.14307v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14304v1/1.0",
                "title": "AdaMedGraph: Adaboosting Graph Neural Networks for Personalized Medicine",
                "year": 2023,
                "abstract": "Precision medicine tailored to individual patients has gained significant\nattention in recent times. Machine learning techniques are now employed to\nprocess personalized data from various sources, including images, genetics, and\nassessments. These techniques have demonstrated good outcomes in many clinical\nprediction tasks. Notably, the approach of constructing graphs by linking\nsimilar patients and then applying graph neural networks (GNNs) stands out,\nbecause related information from analogous patients are aggregated and\nconsidered for prediction. However, selecting the appropriate edge feature to\ndefine patient similarity and construct the graph is challenging, given that\neach patient is depicted by high-dimensional features from diverse sources.\nPrevious studies rely on human expertise to select the edge feature, which is\nneither scalable nor efficient in pinpointing crucial edge features for complex\ndiseases. In this paper, we propose a novel algorithm named \\ours, which can\nautomatically select important features to construct multiple patient\nsimilarity graphs, and train GNNs based on these graphs as weak learners in\nadaptive boosting. \\ours{} is evaluated on two real-world medical scenarios and\nshows superiors performance.",
                "authors": [
                    "Jie Lian",
                    "Xufang Luo",
                    "Caihua Shan",
                    "Dongqi Han",
                    "Varut Vardhanabhuti",
                    "Dongsheng Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14304v1",
                    "http://arxiv.org/pdf/2311.14304v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14303v1/1.0",
                "title": "RFI Detection with Spiking Neural Networks",
                "year": 2023,
                "abstract": "Radio Frequency Interference (RFI) detection and mitigation is critical for\nenabling and maximising the scientific output of radio telescopes. The\nemergence of machine learning methods capable of handling large datasets has\nled to their application in radio astronomy, particularly in RFI detection.\nSpiking Neural Networks (SNNs), inspired by biological systems, are well-suited\nfor processing spatio-temporal data. This study introduces the first\napplication of SNNs to an astronomical data-processing task, specifically RFI\ndetection. We adapt the nearest-latent-neighbours (NLN) algorithm and\nauto-encoder architecture proposed by previous authors to SNN execution by\ndirect ANN2SNN conversion, enabling simplified downstream RFI detection by\nsampling the naturally varying latent space from the internal spiking neurons.\nWe evaluate performance with the simulated HERA telescope and hand-labelled\nLOFAR dataset that the original authors provided. We additionally evaluate\nperformance with a new MeerKAT-inspired simulation dataset. This dataset\nfocuses on satellite-based RFI, an increasingly important class of RFI and is,\ntherefore, an additional contribution. Our SNN approach remains competitive\nwith the original NLN algorithm and AOFlagger in AUROC, AUPRC and F1 scores for\nthe HERA dataset but exhibits difficulty in the LOFAR and MeerKAT datasets.\nHowever, our method maintains this performance while completely removing the\ncompute and memory-intense latent sampling step found in NLN. This work\ndemonstrates the viability of SNNs as a promising avenue for\nmachine-learning-based RFI detection in radio telescopes by establishing a\nminimal performance baseline on traditional and nascent satellite-based RFI\nsources and is the first work to our knowledge to apply SNNs in astronomy.",
                "authors": [
                    "Nicholas J. Pritchard",
                    "Andreas Wicenec",
                    "Mohammed Bennamoun",
                    "Richard Dodson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14303v1",
                    "http://arxiv.org/pdf/2311.14303v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "cs.NE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14301v1/1.0",
                "title": "GeoViT: A Versatile Vision Transformer Architecture for Geospatial Image\n  Analysis",
                "year": 2023,
                "abstract": "Greenhouse gases are pivotal drivers of climate change, necessitating precise\nquantification and source identification to foster mitigation strategies. We\nintroduce GeoViT, a compact vision transformer model adept in processing\nsatellite imagery for multimodal segmentation, classification, and regression\ntasks targeting CO2 and NO2 emissions. Leveraging GeoViT, we attain superior\naccuracy in estimating power generation rates, fuel type, plume coverage for\nCO2, and high-resolution NO2 concentration mapping, surpassing previous\nstate-of-the-art models while significantly reducing model size. GeoViT\ndemonstrates the efficacy of vision transformer architectures in harnessing\nsatellite-derived data for enhanced GHG emission insights, proving instrumental\nin advancing climate change monitoring and emission regulation efforts\nglobally.",
                "authors": [
                    "Madhav Khirwar",
                    "Ankur Narang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14301v1",
                    "http://arxiv.org/pdf/2311.14301v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14298v1/1.0",
                "title": "Light Shining Through Wall Bounds on Axions From Obscured Magnetars",
                "year": 2023,
                "abstract": "Coupling of axions or axion-like particles (ALPs) with photons may lead to\nphotons escaping optically opaque regions by oscillating into ALPs. This\nphenomenon may be viewed as the Light Shining through Wall (LSW) scenario.\nWhile this LSW technique has been used previously in controlled laboratory\nsettings to constrain the ALP-photon coupling ($g_{a\\gamma}$), we show that\nthis can also be applied in astrophysical environments. We find that obscured\nmagnetars in particular are excellent candidates for this purpose. A fraction\nof photons emitted by the magnetar may convert to ALPs in the magnetar\nneighborhood, cross the large absorption column densities, and convert back\ninto photons due to the interstellar magnetic field. Comparing the observed\nflux with the estimated intrinsic flux from the magnetar, we can constrain the\ncontribution of this process, and hence constrain $g_{a\\gamma}$. The effects of\nresonant conversion near the magnetar as well as ALP-photon oscillations in the\ninterstellar medium are carefully considered. Taking a suitable magnetar\ncandidate PSR J1622-4950, we find that the ALP-photon coupling can be\nconstrained at $g_{a\\gamma} \\lesssim (10^{-10} - 10^{-11})$ GeV$^{-1}$ for low\nmass axions ($m_a \\lesssim 10^{-12}$ eV). Our study reveals the previously\nunrealized potential for employing the LSW technique for obscured magnetars for\nprobing and constraining ALP-photon couplings.",
                "authors": [
                    "Dibya S. Chattopadhyay",
                    "Basudeb Dasgupta",
                    "Amol Dighe",
                    "Mayank Narang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14298v1",
                    "http://arxiv.org/pdf/2311.14298v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.09429v1/1.0",
                "title": "Deep Learning-Enabled Swallowing Monitoring and Postoperative Recovery\n  Biosensing System",
                "year": 2023,
                "abstract": "This study introduces an innovative 3D printed dry electrode tailored for\nbiosensing in postoperative recovery scenarios. Fabricated through a drop\ncoating process, the electrode incorporates a novel 2D material.",
                "authors": [
                    "Chih-Ning Tsai",
                    "Pei-Wen Yang",
                    "Tzu-Yen Huang",
                    "Jung-Chih Chen",
                    "Hsin-Yi Tseng",
                    "Che-Wei Wu",
                    "Amrit Sarmah",
                    "Tzu-En Lin"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.09429v1",
                    "http://arxiv.org/pdf/2312.09429v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.LG",
                    "NA",
                    "A.0"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14295v1/1.0",
                "title": "Exploiting Active RIS in NOMA Networks with Hardware Impairments",
                "year": 2023,
                "abstract": "Active reconfigurable intelligent surface (ARIS) is a promising way to\ncompensate for multiplicative fading attenuation by amplifying and reflecting\nevent signals to selected users. This paper investigates the performance of\nARIS assisted non-orthogonal multiple access (NOMA) networks over cascaded\nNakagami-m fading channels. The effects of hardware impairments (HIS) and\nreflection coefficients on ARIS-NOMA networks with imperfect successive\ninterference cancellation (ipSIC) and perfect successive interference\ncancellation (pSIC) are considered. More specifically, we develop new precise\nand asymptotic expressions of outage probability and ergodic data rate with\nipSIC/pSIC for ARIS-NOMA-HIS networks. According to the approximated analyses,\nthe diversity orders and multiplexing gains for couple of non-orthogonal users\nare attained in detail. Additionally, the energy efficiency of ARIS-NOMA-HIS\nnetworks is surveyed in delay-limited and delay-tolerant transmission schemes.\nThe simulation findings are presented to demonstrate that: i) The outage\nbehaviors and ergodic data rates of ARIS-NOMA-HIS networks precede that of ARIS\naided orthogonal multiple access (OMA) and passive reconfigurable intelligent\nsurface (PRIS) aided OMA; ii) As the reflection coefficient of ARIS increases,\nARIS-NOMA-HIS networks have the ability to provide the strengthened outage\nperformance; and iii) ARIS-NOMA-HIS networks are more energy efficient than\nARIS/PRIS-OMA networks and conventional cooperative schemes.",
                "authors": [
                    "Xinwei Yue",
                    "Meiqi Song",
                    "Chongjun Ouyang",
                    "Yuanwei Liu",
                    "Tian Li",
                    "Tianwei Hou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14295v1",
                    "http://arxiv.org/pdf/2311.14295v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14291v1/1.0",
                "title": "Possibilities for methanogenic and acetogenic life in molecular cloud",
                "year": 2023,
                "abstract": "There are life forms in space and the ancestor of Earth life came from\ninterstellar space according to models like panspermia. Naturally, life may\nalso exist in molecular clouds. Here the author discusses the possibility of\nmethanogenic life in Molecular Cloud with methane as the final metabolism\nproduct. According to the calculations, it is easy to see that the chemical\nreaction through methanogenesis can release sufficient free energy. If\nmethanogenic life exist in the pre-solar nebula, then they may be the ancestor\nof Earth's life and there are already some tentative evidences by several\nmolecular biology studies.",
                "authors": [
                    "Lei Feng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14291v1",
                    "http://arxiv.org/pdf/2311.14291v1"
                ],
                "primary_category": "physics.pop-ph",
                "categories": [
                    "physics.pop-ph",
                    "astro-ph.EP",
                    "astro-ph.SR",
                    "physics.bio-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14290v1/1.0",
                "title": "Electron and proton energization in 3D reconnecting current sheets in\n  semirelativistic plasma with guide magnetic field",
                "year": 2023,
                "abstract": "Using 3D particle-in-cell simulation, we characterize energy conversion, as a\nfunction of guide magnetic field, in a thin current sheet in semirelativistic\nplasma, with relativistic electrons and subrelativistic protons. There,\nmagnetic reconnection, the drift-kink instability (DKI), and the flux-rope kink\ninstability all compete and interact in their nonlinear stages to convert\nmagnetic energy to plasma energy. We compare fully 3D simulations with 2D in\ntwo different planes to isolate reconnection and DKI effects. In zero guide\nfield, these processes yield distinct energy conversion signatures: ions gain\nmore energy than electrons in 2Dxy (reconnection), while the opposite is true\nin 2Dyz (DKI), and the 3D result falls in between. The flux-rope instability,\nwhich occurs only in 3D, allows more magnetic energy to be released than in 2D,\nbut the rate of energy conversion in 3D tends to be lower. Increasing the guide\nmagnetic field strongly suppresses DKI, and in all cases slows and reduces the\noverall amount of energy conversion; it also favors electron energization\nthrough a process by which energy is first stored in the motional electric\nfield of flux ropes before energizing particles. Understanding the evolution of\nthe energy partition thus provides insight into the role of various plasma\nprocesses, and is important for modeling radiation from astrophysical sources\nsuch as accreting black holes and their jets.",
                "authors": [
                    "Gregory R. Werner",
                    "Dmitri A. Uzdensky"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14290v1",
                    "http://arxiv.org/pdf/2311.14290v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE",
                    "physics.plasm-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14289v1/1.0",
                "title": "Four-set Hypergraphlets for Characterization of Directed Hypergraphs",
                "year": 2023,
                "abstract": "A directed hypergraph, which consists of nodes and hyperarcs, is a\nhigher-order data structure that naturally models directional group\ninteractions (e.g., chemical reactions of molecules). Although there have been\nextensive studies on local structures of (directed) graphs in the real world,\nthose of directed hypergraphs remain unexplored. In this work, we focus on\nmeasurements, findings, and applications related to local structures of\ndirected hypergraphs, and they together contribute to a systematic\nunderstanding of various real-world systems interconnected by directed group\ninteractions. Our first contribution is to define 91 directed hypergraphlets\n(DHGs), which disjointly categorize directed connections and overlaps among\nfour node sets that compose two incident hyperarcs. Our second contribution is\nto develop exact and approximate algorithms for counting the occurrences of\neach DHG. Our last contribution is to characterize 11 real-world directed\nhypergraphs and individual hyperarcs in them using the occurrences of DHGs,\nwhich reveals clear domain-based local structural patterns. Our experiments\ndemonstrate that our DHG-based characterization gives up to 12% and 33% better\nperformances on hypergraph clustering and hyperarc prediction, respectively,\nthan baseline characterization methods. Moreover, we show that CODA-A, which is\nour proposed approximate algorithm, is up to 32X faster than its competitors\nwith similar characterization quality.",
                "authors": [
                    "Heechan Moon",
                    "Hyunju Kim",
                    "Sunwoo Kim",
                    "Kijung Shin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14289v1",
                    "http://arxiv.org/pdf/2311.14289v1"
                ],
                "primary_category": "cs.DS",
                "categories": [
                    "cs.DS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14284v2/1.0",
                "title": "Paragraph-to-Image Generation with Information-Enriched Diffusion Model",
                "year": 2023,
                "abstract": "Text-to-image (T2I) models have recently experienced rapid development,\nachieving astonishing performance in terms of fidelity and textual alignment\ncapabilities. However, given a long paragraph (up to 512 words), these\ngeneration models still struggle to achieve strong alignment and are unable to\ngenerate images depicting complex scenes. In this paper, we introduce an\ninformation-enriched diffusion model for paragraph-to-image generation task,\ntermed ParaDiffusion, which delves into the transference of the extensive\nsemantic comprehension capabilities of large language models to the task of\nimage generation. At its core is using a large language model (e.g., Llama V2)\nto encode long-form text, followed by fine-tuning with LORA to alignthe\ntext-image feature spaces in the generation task. To facilitate the training of\nlong-text semantic alignment, we also curated a high-quality paragraph-image\npair dataset, namely ParaImage. This dataset contains a small amount of\nhigh-quality, meticulously annotated data, and a large-scale synthetic dataset\nwith long text descriptions being generated using a vision-language model.\nExperiments demonstrate that ParaDiffusion outperforms state-of-the-art models\n(SD XL, DeepFloyd IF) on ViLG-300 and ParaPrompts, achieving up to 15% and 45%\nhuman voting rate improvements for visual appeal and text faithfulness,\nrespectively. The code and dataset will be released to foster community\nresearch on long-text alignment.",
                "authors": [
                    "Weijia Wu",
                    "Zhuang Li",
                    "Yefei He",
                    "Mike Zheng Shou",
                    "Chunhua Shen",
                    "Lele Cheng",
                    "Yan Li",
                    "Tingting Gao",
                    "Di Zhang",
                    "Zhongyuan Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14284v2",
                    "http://arxiv.org/pdf/2311.14284v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14283v1/1.0",
                "title": "Strong Interference HVSR Data Processing and Denoising: HVSR Curve\n  Reconstruction Method based on UPEMD",
                "year": 2023,
                "abstract": "Urban areas pose a challenge for the application of the H/V method due to a\nhigh degree of artificial noise. The existing methods fall short in reducing\nthe noise of strong interference data. To solve this issue, a new approach\ncalled the HVSR curve reconstruction method is introduced in this paper. The\nmethod employs the UPEMD technique to analyze the data component, and the\nextracted signal is evaluated based on the correlation coefficient between the\nIMFs and the original micro-motion data, trend extraction of micro-motion data,\nand secondary extraction. This signal is then utilized to retrieve information\nabout the layers, and the effectiveness of the proposed method is demonstrated.",
                "authors": [
                    "Bingxuan Song",
                    "Fuxing Han",
                    "Yubei Chen",
                    "Linjun Wu",
                    "Mengting Huang",
                    "Yanjie Pan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14283v1",
                    "http://arxiv.org/pdf/2311.14283v1"
                ],
                "primary_category": "physics.geo-ph",
                "categories": [
                    "physics.geo-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14282v1/1.0",
                "title": "Image Super-Resolution with Text Prompt Diffusion",
                "year": 2023,
                "abstract": "Image super-resolution (SR) methods typically model degradation to improve\nreconstruction accuracy in complex and unknown degradation scenarios. However,\nextracting degradation information from low-resolution images is challenging,\nwhich limits the model performance. To boost image SR performance, one feasible\napproach is to introduce additional priors. Inspired by advancements in\nmulti-modal methods and text prompt image processing, we introduce text prompts\nto image SR to provide degradation priors. Specifically, we first design a\ntext-image generation pipeline to integrate text into SR dataset through the\ntext degradation representation and degradation model. The text representation\napplies a discretization manner based on the binning method to describe the\ndegradation abstractly. This representation method can also maintain the\nflexibility of language. Meanwhile, we propose the PromptSR to realize the text\nprompt SR. The PromptSR employs the diffusion model and the pre-trained\nlanguage model (e.g., T5 and CLIP). We train the model on the generated\ntext-image dataset. Extensive experiments indicate that introducing text\nprompts into image SR, yields excellent results on both synthetic and\nreal-world images. Code: https://github.com/zhengchen1999/PromptSR.",
                "authors": [
                    "Zheng Chen",
                    "Yulun Zhang",
                    "Jinjin Gu",
                    "Xin Yuan",
                    "Linghe Kong",
                    "Guihai Chen",
                    "Xiaokang Yang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14282v1",
                    "http://arxiv.org/pdf/2311.14282v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14280v1/1.0",
                "title": "Latent Diffusion Prior Enhanced Deep Unfolding for Spectral Image\n  Reconstruction",
                "year": 2023,
                "abstract": "Snapshot compressive spectral imaging reconstruction aims to reconstruct\nthree-dimensional spatial-spectral images from a single-shot two-dimensional\ncompressed measurement. Existing state-of-the-art methods are mostly based on\ndeep unfolding structures but have intrinsic performance bottlenecks: $i$) the\nill-posed problem of dealing with heavily degraded measurement, and $ii$) the\nregression loss-based reconstruction models being prone to recover images with\nfew details. In this paper, we introduce a generative model, namely the latent\ndiffusion model (LDM), to generate degradation-free prior to enhance the\nregression-based deep unfolding method. Furthermore, to overcome the large\ncomputational cost challenge in LDM, we propose a lightweight model to generate\nknowledge priors in deep unfolding denoiser, and integrate these priors to\nguide the reconstruction process for compensating high-quality spectral signal\ndetails. Numeric and visual comparisons on synthetic and real-world datasets\nillustrate the superiority of our proposed method in both reconstruction\nquality and computational efficiency. Code will be released.",
                "authors": [
                    "Zongliang Wu",
                    "Ruiying Lu",
                    "Ying Fu",
                    "Xin Yuan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14280v1",
                    "http://arxiv.org/pdf/2311.14280v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14277v1/1.0",
                "title": "Anisotropy-induced Coulomb phase and quasiparticle zoo in the atomic\n  monopole-spin hybrid system",
                "year": 2023,
                "abstract": "Quantum simulation of a monopole-spin hybrid system is performed on basis of\na dipolar ultracold gas in a ladder lattice. The site-occupation states of the\ndipolar ladder lattice gas can spontaneously emulate both the monopole and spin\nexcitations. The hopping of the atoms induces a particle conversion process\nbetween spin and monopole pairs, and the dipole-dipole interaction determines\nthe spin-spin, spin-monopole and monopole-monopole interactions. The\nanisotropic nature of the dipole-dipole interaction allows hereby for a\nflexible engineering of the designed hybrid system, and for a significant\ntunability of the interaction strengths. As a result, we encounter a rich phase\ndiagram, and specifically a self-assembled Coulomb phase arises, in which\nmonopoles and spins coexist and are orderly arranged according to the local\nGauss's law. The Coulomb phase hosts a zoo of different types of\nquasiparticles, and provides the possibility to simulate various phenomena in\nparticle physics, such as a degenerate vacuum, particle decay and conversion\nprocesses. Our work provides a significant extension of the scope of quantum\nsimulations based on the anisotropy of dipolar interactions.",
                "authors": [
                    "Shao-Jun Li",
                    "Xiang Gao",
                    "Xue-Ting Fang",
                    "Lushuai Cao",
                    "Peter Schmelcher",
                    "Zhong-Kun Hu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14277v1",
                    "http://arxiv.org/pdf/2311.14277v1"
                ],
                "primary_category": "cond-mat.quant-gas",
                "categories": [
                    "cond-mat.quant-gas",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14275v1/1.0",
                "title": "Cooperative Dual Attention for Audio-Visual Speech Enhancement with\n  Facial Cues",
                "year": 2023,
                "abstract": "In this work, we focus on leveraging facial cues beyond the lip region for\nrobust Audio-Visual Speech Enhancement (AVSE). The facial region, encompassing\nthe lip region, reflects additional speech-related attributes such as gender,\nskin color, nationality, etc., which contribute to the effectiveness of AVSE.\nHowever, static and dynamic speech-unrelated attributes also exist, causing\nappearance changes during speech. To address these challenges, we propose a\nDual Attention Cooperative Framework, DualAVSE, to ignore speech-unrelated\ninformation, capture speech-related information with facial cues, and\ndynamically integrate it with the audio signal for AVSE. Specifically, we\nintroduce a spatial attention-based visual encoder to capture and enhance\nvisual speech information beyond the lip region, incorporating global facial\ncontext and automatically ignoring speech-unrelated information for robust\nvisual feature extraction. Additionally, a dynamic visual feature fusion\nstrategy is introduced by integrating a temporal-dimensional self-attention\nmodule, enabling the model to robustly handle facial variations. The acoustic\nnoise in the speaking process is variable, impacting audio quality. Therefore,\na dynamic fusion strategy for both audio and visual features is introduced to\naddress this issue. By integrating cooperative dual attention in the visual\nencoder and audio-visual fusion strategy, our model effectively extracts\nbeneficial speech information from both audio and visual cues for AVSE.\nThorough analysis and comparison on different datasets, including normal and\nchallenging cases with unreliable or absent visual information, consistently\nshow our model outperforming existing methods across multiple metrics.",
                "authors": [
                    "Feixiang Wang",
                    "Shuang Yang",
                    "Shiguang Shan",
                    "Xilin Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14275v1",
                    "http://arxiv.org/pdf/2311.14275v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14271v1/1.0",
                "title": "Segmentation-Based Parametric Painting",
                "year": 2023,
                "abstract": "We introduce a novel image-to-painting method that facilitates the creation\nof large-scale, high-fidelity paintings with human-like quality and stylistic\nvariation. To process large images and gain control over the painting process,\nwe introduce a segmentation-based painting process and a dynamic attention map\napproach inspired by human painting strategies, allowing optimization of brush\nstrokes to proceed in batches over different image regions, thereby capturing\nboth large-scale structure and fine details, while also allowing stylistic\ncontrol over detail. Our optimized batch processing and patch-based loss\nframework enable efficient handling of large canvases, ensuring our painted\noutputs are both aesthetically compelling and functionally superior as compared\nto previous methods, as confirmed by rigorous evaluations. Code available at:\nhttps://github.com/manuelladron/semantic\\_based\\_painting.git",
                "authors": [
                    "Manuel Ladron de Guevara",
                    "Matthew Fisher",
                    "Aaron Hertzmann"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14271v1",
                    "http://arxiv.org/pdf/2311.14271v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14270v1/1.0",
                "title": "Efficient Open-world Reinforcement Learning via Knowledge Distillation\n  and Autonomous Rule Discovery",
                "year": 2023,
                "abstract": "Deep reinforcement learning suffers from catastrophic forgetting and sample\ninefficiency making it less applicable to the ever-changing real world.\nHowever, the ability to use previously learned knowledge is essential for AI\nagents to quickly adapt to novelties. Often, certain spatial information\nobserved by the agent in the previous interactions can be leveraged to infer\ntask-specific rules. Inferred rules can then help the agent to avoid\npotentially dangerous situations in the previously unseen states and guide the\nlearning process increasing agent's novelty adaptation speed. In this work, we\npropose a general framework that is applicable to deep reinforcement learning\nagents. Our framework provides the agent with an autonomous way to discover the\ntask-specific rules in the novel environments and self-supervise it's learning.\nWe provide a rule-driven deep Q-learning agent (RDQ) as one possible\nimplementation of that framework. We show that RDQ successfully extracts\ntask-specific rules as it interacts with the world and uses them to drastically\nincrease its learning efficiency. In our experiments, we show that the RDQ\nagent is significantly more resilient to the novelties than the baseline\nagents, and is able to detect and adapt to novel situations faster.",
                "authors": [
                    "Ekaterina Nikonova",
                    "Cheng Xue",
                    "Jochen Renz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14270v1",
                    "http://arxiv.org/pdf/2311.14270v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14269v1/1.0",
                "title": "A Scalable, High-Efficiency, Low-Energy-Spread, Laser Wakefield\n  Accelerator using a Tri-plateau Plasma Channel",
                "year": 2023,
                "abstract": "The emergence of multi-petawatt laser facilities is expected to push forward\nthe maximum energy gain that can be achieved in a single stage of a LWFA to\ntens of GeV, which begs the question - is it likely to impact particle physics\nby providing a truly compact particle collider? Colliders have very stringent\nrequirements on beam energy, acceleration efficiency and beam quality. In this\narticle, we propose a LWFA scheme that can for the first time simultaneously\nachieve hitherto unrealized acceleration efficiency from the laser to the\nelectron beam of >20% and a sub-one percent energy spread using a stepwise\nplasma structure and a nonlinearly chirped laser pulse. Three-dimensional\nhigh-fidelity simulations show that the nonlinear chirp can effectively\nmitigate the laser waveform distortion and lengthen the acceleration distance.\nThis combined with an inter-stage rephasing process in the stepwise plasma can\ntriple the beam energy gain compared to that in a uniform plasma for a fixed\nlaser energy thereby dramatically increasing the efficiency. A dynamic beam\nloading effect can almost perfectly cancel the energy chirp that arises during\nthe acceleration, leading to the sub-percent energy spread. This scheme is\nhighly scalable and can be applied to peta-watt LWFA scenarios. Scaling laws\nare obtained that suggest electron beams with energy gain of >100 GeV, charge\nof 2 nC, and with an energy spread <1% can be realized with a high laser pulse\nto particle beam energy transfer efficiency in a LWFA driven by a peta-watt\nlaser, which could be the basis for a proof of concept of one arm of a future\nelectron-positron collider.",
                "authors": [
                    "Shuang Liu",
                    "Fei Li",
                    "Shiyu Zhou",
                    "Jianfei Hua",
                    "Warren B. Mori",
                    "Chan Joshi",
                    "Wei Lu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14269v1",
                    "http://arxiv.org/pdf/2311.14269v1"
                ],
                "primary_category": "physics.acc-ph",
                "categories": [
                    "physics.acc-ph",
                    "physics.plasm-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14265v1/1.0",
                "title": "Bursting Spikes: Efficient and High-performance SNNs for Event-based\n  Vision",
                "year": 2023,
                "abstract": "Advancing event-driven vision through spiking neural networks (SNNs) is\ncrucial to empowering high-speed and efficient perception. While directly\nconverting the pre-trained artificial neural networks (ANNs) - by replacing the\nnon-linear activation with spiking neurons - can provide SNNs with good\nperformance, the resultant SNNs typically demand long timesteps and high energy\nconsumption to achieve their optimal performance. To address this challenge, we\nintroduce the burst-spike mechanism inspired by the biological nervous system,\nallowing multiple spikes per timestep to reduce conversion errors and produce\nlow-latency SNNs. To further bolster this enhancement, we leverage the Pareto\nFrontier-driven algorithm to reallocate burst-firing patterns. Moreover, to\nreduce energy consumption during the conversion process, we propose a\nsensitivity-driven spike compression technique, which automatically locates the\noptimal threshold ratio according to layer-specific sensitivity. Extensive\nexperiments demonstrate our approach outperforms state-of-the-art SNN methods,\nshowcasing superior performance and reduced energy usage across classification\nand object detection. Our code will be available at\nhttps://github.com/bic-L/burst-ann2snn.",
                "authors": [
                    "Ziqing Wang",
                    "Yuetong Fang",
                    "Jiahang Cao",
                    "Renjing Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14265v1",
                    "http://arxiv.org/pdf/2311.14265v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14264v1/1.0",
                "title": "An ADMM-Based Geometric Configuration Optimization in RSSD-Based Source\n  Localization By UAVs with Spread Angle Constraint",
                "year": 2023,
                "abstract": "Deploying multiple unmanned aerial vehicles (UAVs) to locate a\nsignal-emitting source covers a wide range of military and civilian\napplications like rescue and target tracking. It is well known that the\nUAVs-source (sensors-target) geometry, namely geometric configuration,\nsignificantly affects the final localization accuracy. This paper focuses on\nthe geometric configuration optimization for received signal strength\ndifference (RSSD)-based passive source localization by drone swarm. Different\nfrom prior works, this paper considers a general measuring condition where the\nspread angle of drone swarm centered on the source is constrained. Subject to\nthis constraint, a geometric configuration optimization problem with the aim of\nmaximizing the determinant of Fisher information matrix (FIM) is formulated.\nAfter transforming this problem using matrix theory, an alternating direction\nmethod of multipliers (ADMM)-based optimization framework is proposed. To solve\nthe subproblems in this framework, two global optimal solutions based on the\nVon Neumann matrix trace inequality theorem and majorize-minimize (MM)\nalgorithm are proposed respectively. Finally, the effectiveness as well as the\npracticality of the proposed ADMM-based optimization algorithm are demonstrated\nby extensive simulations.",
                "authors": [
                    "Xin Cheng",
                    "Weiqiang Zhu",
                    "Feng Shu",
                    "Jiangzhou Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14264v1",
                    "http://arxiv.org/pdf/2311.14264v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14262v2/1.0",
                "title": "ZeroPS: High-quality Cross-modal Knowledge Transfer for Zero-Shot 3D\n  Part Segmentation",
                "year": 2023,
                "abstract": "Recently, many 2D pretrained foundational models have demonstrated impressive\nzero-shot prediction capabilities. In this work, we design a novel pipeline for\nzero-shot 3D part segmentation, called ZeroPS. It high-quality transfers\nknowledge from 2D pretrained foundational models to 3D point clouds. The main\nidea of our approach is to explore the natural relationship between multi-view\ncorrespondences and the prompt mechanism of foundational models and build\nbridges on it. Our pipeline consists of two components: 1) a self-extension\ncomponent that extends 2D groups from a single viewpoint to spatial\nglobal-level 3D groups; 2) a multi-modal labeling component that introduces a\ntwo-dimensional checking mechanism to vote each 2D predicted bounding box to\nthe best matching 3D part, and a Class Non-highest Vote Penalty function to\nrefine the Vote Matrix. Additionally, a merging algorithm is included to merge\npart-level 3D groups. Extensive evaluation of three zero-shot segmentation\ntasks on PartnetE datasets, achieving state-of-the-art results with significant\nimprovements (+19.6%, +5.2% and +4.9%, respectively) over existing methods. Our\nproposed approach does not need any training, fine-tuning or learnable\nparameters. It is hardly affected by domain shift. The code will be released.",
                "authors": [
                    "Yuheng Xue",
                    "Nenglun Chen",
                    "Jun Liu",
                    "Wenyun Sun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14262v2",
                    "http://arxiv.org/pdf/2311.14262v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.17067v1/1.0",
                "title": "Hypergraphs Demonstrate Anastomoses During Divergent Integration",
                "year": 2023,
                "abstract": "Complex networks can be used to analyze structures and systems in the embryo.\nNot only can we characterize growth and the emergence of form, but also\ndifferentiation. The process of differentiation from precursor cell populations\nto distinct functional tissues is of particular interest. These phenomena can\nbe captured using a hypergraph consisting of nodes represented by cell type\ncategories and arranged as a directed cyclic graph (lineage hypergraph) and a\ncomplex network (spatial hypergraph). The lineage hypergraph models the\ndevelopmental process as an n-ary tree, which can model two or more descendent\ncategories per division event. A lineage tree based on the mosaic development\nof the nematode C. elegans (2-ary tree), is used to capture this process. Each\nround of divisions produces a new set of categories that allow for exchange of\ncells between types. An example from single-cell morphogenesis based on the\ncyanobacterial species Nostoc punctiforme (multiple discontinuous 2-ary tree)\nis also used to demonstrate the flexibility of this method. This model allows\nfor new structures to emerge (such as a connectome) while also demonstrating\nhow precursor categories are maintained for purposes such as dedifferentiation\nor other forms of cell fate plasticity. To understand this process of divergent\nintegration, we analyze the directed hypergraph and categorical models, in\naddition to considering the role of network fistulas (spaces that conjoin two\nfunctional modules) and spatial restriction.",
                "authors": [
                    "Bradly Alicea"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.17067v1",
                    "http://arxiv.org/pdf/2311.17067v1"
                ],
                "primary_category": "q-bio.QM",
                "categories": [
                    "q-bio.QM",
                    "q-bio.NC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14255v1/1.0",
                "title": "Out-of-Distribution Generalized Dynamic Graph Neural Network with\n  Disentangled Intervention and Invariance Promotion",
                "year": 2023,
                "abstract": "Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive\nabilities by exploiting graph structural and temporal dynamics. However, the\nexisting DyGNNs fail to handle distribution shifts, which naturally exist in\ndynamic graphs, mainly because the patterns exploited by DyGNNs may be variant\nwith respect to labels under distribution shifts. In this paper, we propose\nDisentangled Intervention-based Dynamic graph Attention networks with\nInvariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in\ndynamic graphs by discovering and utilizing invariant patterns, i.e.,\nstructures and features whose predictive abilities are stable across\ndistribution shifts. Specifically, we first propose a disentangled\nspatio-temporal attention network to capture the variant and invariant\npatterns. By utilizing the disentangled patterns, we design a spatio-temporal\nintervention mechanism to create multiple interventional distributions and an\nenvironment inference module to infer the latent spatio-temporal environments,\nand minimize the variance of predictions among these intervened distributions\nand environments, so that our model can make predictions based on invariant\npatterns with stable predictive abilities under distribution shifts. Extensive\nexperiments demonstrate the superiority of our method over state-of-the-art\nbaselines under distribution shifts. Our work is the first study of\nspatio-temporal distribution shifts in dynamic graphs, to the best of our\nknowledge.",
                "authors": [
                    "Zeyang Zhang",
                    "Xin Wang",
                    "Ziwei Zhang",
                    "Haoyang Li",
                    "Wenwu Zhu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14255v1",
                    "http://arxiv.org/pdf/2311.14255v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14252v1/1.0",
                "title": "The origin of the metallicity distributions of the NE and W stellar\n  shelves in the Andromeda Galaxy",
                "year": 2023,
                "abstract": "Tidal streams and stellar shells are naturally formed in galaxy interactions\nand mergers. The Giant Stellar Stream (GSS), the North-East (NE), and Western\n(W) stellar shelves observed in Andromeda galaxy (M31) are examples of these\nstructures and were formed through the merger of M31 and a satellite galaxy.\nRecent observational papers have provided strong evidence that the shells and\nGSS originate from a single progenitor. In this paper, we investigate the\nformation of these two stellar shelves and the detailed nature of their\nrelationship to the GSS. We present numerical simulations of tidal disruption\nof a satellite galaxy assuming that it is a progenitor of the GSS and the shell\nsystem. We represent the progenitor as a dwarf spheroidal galaxy with the\nstellar mass of $10^{9} M_{\\odot}$ and evolve its merger with M31 for 3 Gyrs to\nreproduce the chemodynamical properties of the NE and W shelves. We find that\nan initial metallicity of the progenitor with a negative radial gradient of\n$\\Delta$ FeH = -0.3 $\\pm$ 0.2, successfully reproduces observed metallicities\nof the NE, W shelves, and the GSS, showing that all these structures can\noriginate from the same merger event.",
                "authors": [
                    "Stanislav Milo\u0161evi\u0107",
                    "Miroslav Mi\u0107i\u0107",
                    "Geraint F. Lewis"
                ],
                "url": [
                    "http://dx.doi.org/10.1093/mnras/stad3503",
                    "http://arxiv.org/abs/2311.14252v1",
                    "http://arxiv.org/pdf/2311.14252v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14246v1/1.0",
                "title": "Constant-Time Wasmtime, for Real This Time: End-to-End Verified\n  Zero-Overhead Constant-Time Programming for the Web and Beyond",
                "year": 2023,
                "abstract": "We claim that existing techniques and tools for generating and verifying\nconstant-time code are incomplete, since they rely on assumptions that compiler\noptimization passes do not break constant-timeness or that certain operations\nexecute in constant time on the hardware. We present the first end-to-end\nconstant-time-aware compilation process that preserves constant-time semantics\nat every step from a high-level language down to microarchitectural guarantees,\nprovided by the forthcoming ARM PSTATE.DIT feature. First, we present a new\ncompiler-verifier suite based on the JIT-style runtime Wasmtime, modified to\ncompile ct-wasm, a preexisting type-safe constant-time extension of\nWebAssembly, into ARM machine code while maintaining the constant-time property\nthroughout all optimization passes. The resulting machine code is then fed into\nan automated verifier that requires no human intervention and uses static\ndataflow analysis in Ghidra to check the constant-timeness of the output. Our\nverifier leverages characteristics unique to ct-wasm-generated code in order to\nspeed up verification while preserving both soundness and wide applicability.\nWe also consider the resistance of our compilation and verification against\nspeculative timing leakages such as Spectre. Finally, in order to expose\nct-Wasmtime at a high level, we present a port of FaCT, a preexisting\nconstant-time-aware DSL, to target ct-wasm.",
                "authors": [
                    "Garrett Gu",
                    "Hovav Shacham"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14246v1",
                    "http://arxiv.org/pdf/2311.14246v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14242v1/1.0",
                "title": "RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with\n  Occlusion Handling",
                "year": 2023,
                "abstract": "In the domain of 3D Human Pose Estimation, which finds widespread daily\napplications, the requirement for convenient acquisition equipment continues to\ngrow. To satisfy this demand, we set our sights on a short-baseline binocular\nsetting that offers both portability and a geometric measurement property that\nradically mitigates depth ambiguity. However, as the binocular baseline\nshortens, two serious challenges emerge: first, the robustness of 3D\nreconstruction against 2D errors deteriorates; and second, occlusion reoccurs\ndue to the limited visual differences between two views. To address the first\nchallenge, we propose the Stereo Co-Keypoints Estimation module to improve the\nview consistency of 2D keypoints and enhance the 3D robustness. In this module,\nthe disparity is utilized to represent the correspondence of binocular 2D\npoints and the Stereo Volume Feature is introduced to contain binocular\nfeatures across different disparities. Through the regression of SVF, two-view\n2D keypoints are simultaneously estimated in a collaborative way which\nrestricts their view consistency. Furthermore, to deal with occlusions, a\nPre-trained Pose Transformer module is introduced. Through this module, 3D\nposes are refined by perceiving pose coherence, a representation of joint\ncorrelations. This perception is injected by the Pose Transformer network and\nlearned through a pre-training task that recovers iterative masked joints.\nComprehensive experiments carried out on H36M and MHAD datasets, complemented\nby visualizations, validate the effectiveness of our approach in the\nshort-baseline binocular 3D Human Pose Estimation and occlusion handling.",
                "authors": [
                    "Xiaoyue Wan",
                    "Zhuo Chen",
                    "Yiming Bao",
                    "Xu Zhao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14242v1",
                    "http://arxiv.org/pdf/2311.14242v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14239v1/1.0",
                "title": "Allpass impulse response modelling",
                "year": 2023,
                "abstract": "This document defines a method for FIR system modelling which is very trivial\nas it only depends on phase introduction and removal (allpass filters). As\nmagnitude is not altered, the processing is numerically stable. It is limited\nto phase alteration which maintains the time domain magnitude to force a system\nwithin its linear limits.",
                "authors": [
                    "Matt R. Flax"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14239v1",
                    "http://arxiv.org/pdf/2311.14239v1"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "eess.AS",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16973v2/1.0",
                "title": "DemoFusion: Democratising High-Resolution Image Generation With No $$$",
                "year": 2023,
                "abstract": "High-resolution image generation with Generative Artificial Intelligence\n(GenAI) has immense potential but, due to the enormous capital investment\nrequired for training, it is increasingly centralised to a few large\ncorporations, and hidden behind paywalls. This paper aims to democratise\nhigh-resolution GenAI by advancing the frontier of high-resolution generation\nwhile remaining accessible to a broad audience. We demonstrate that existing\nLatent Diffusion Models (LDMs) possess untapped potential for higher-resolution\nimage generation. Our novel DemoFusion framework seamlessly extends open-source\nGenAI models, employing Progressive Upscaling, Skip Residual, and Dilated\nSampling mechanisms to achieve higher-resolution image generation. The\nprogressive nature of DemoFusion requires more passes, but the intermediate\nresults can serve as \"previews\", facilitating rapid prompt iteration.",
                "authors": [
                    "Ruoyi Du",
                    "Dongliang Chang",
                    "Timothy Hospedales",
                    "Yi-Zhe Song",
                    "Zhanyu Ma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16973v2",
                    "http://arxiv.org/pdf/2311.16973v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14227v1/1.0",
                "title": "Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using\n  Adversarial Training",
                "year": 2023,
                "abstract": "The novel 2019 Coronavirus disease (COVID-19) global pandemic is a defining\nhealth crisis. Recent efforts have been increasingly directed towards achieving\nquick and accurate detection of COVID-19 across symptomatic patients to\nmitigate the intensity and spread of the disease. Artificial intelligence (AI)\nalgorithms applied to chest X-ray (CXR) images have emerged as promising\ndiagnostic tools, and previous work has demonstrated impressive classification\nperformances. However, such methods have faced criticisms from physicians due\nto their black-box reasoning process and unpredictable nature. In contrast to\nprofessional radiologist diagnosis, AI systems often lack generalizability,\nexplainability, and robustness in the clinical decision making process. In our\nwork, we address these issues by first proposing an extensive baseline study,\ntraining and evaluating 21 convolutional neural network (CNN) models on a\ndiverse set of 33,000+ CXR images to classify between healthy, COVID-19, and\nnon-COVID-19 pneumonia CXRs. Our resulting models achieved a 3-way\nclassification accuracy, recall, and precision of up to 97.03\\%, 97.97\\%, and\n99.95\\%, respectively. Next, we investigate the effectiveness of adversarial\ntraining on model robustness and explainability via Gradient-weighted Class\nActivation Mapping (Grad-CAM) heatmaps. We find that adversarially trained\nmodels not only significantly outperform their standard counterparts on\nclassifying perturbed images, but also yield saliency maps that 1) better\nspecify clinically relevant features, 2) are robust against extraneous\nartifacts, and 3) agree considerably more with expert radiologist findings.",
                "authors": [
                    "Karina Yang",
                    "Alexis Bennett",
                    "Dominique Duncan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14227v1",
                    "http://arxiv.org/pdf/2311.14227v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14226v1/1.0",
                "title": "Uncovering Gender Stereotypes in Video Game Character Designs: A\n  Multi-Modal Analysis of Honor of Kings",
                "year": 2023,
                "abstract": "In this paper, we conduct a comprehensive analysis of gender stereotypes in\nthe character design of Honor of Kings, a popular multiplayer online battle\narena (MOBA) game in China. We probe gender stereotypes through the lens of\nrole assignments, visual designs, spoken lines, and background stories,\ncombining qualitative analysis and text mining based on the moral foundation\ntheory. Male heroes are commonly designed as masculine fighters with power and\nfemale heroes as feminine \"ornaments\" with ideal looks. We contribute with a\nculture-aware and multi-modal understanding of gender stereotypes in games,\nleveraging text-, visual-, and role-based evidence.",
                "authors": [
                    "Bingqing Liu",
                    "Kyrie Zhixuan Zhou",
                    "Danlei Zhu",
                    "Jaihyun Park"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14226v1",
                    "http://arxiv.org/pdf/2311.14226v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC",
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14223v1/1.0",
                "title": "Information Velocity of Cascaded Gaussian Channels with Feedback",
                "year": 2023,
                "abstract": "We consider a line network of nodes, connected by additive white Gaussian\nnoise channels, equipped with local feedback. We study the velocity at which\ninformation spreads over this network. For transmission of a data packet, we\ngive an explicit positive lower bound on the velocity, for any packet size.\nFurthermore, we consider streaming, that is, transmission of data packets\ngenerated at a given average arrival rate. We show that a positive velocity\nexists as long as the arrival rate is below the individual Gaussian channel\ncapacity, and provide an explicit lower bound. Our analysis involves applying\npulse-amplitude modulation to the data (successively in the streaming case),\nand using linear mean-squared error estimation at the network nodes. Due to the\nanalog linear nature of the scheme, the results extend to any additive noise.\nFor general noise, we derive exponential error-probability bounds. Moreover,\nfor (sub-)Gaussian noise we show a doubly-exponential behavior, which reduces\nto the celebrated Schalkwijk-Kailath scheme when considering a single node.\nViewing the constellation as an \"analog source\", we also provide bounds on the\nexponential decay of the mean-squared error of source transmission over the\nnetwork.",
                "authors": [
                    "Elad Domanovitz",
                    "Anatoly Khina",
                    "Tal Philosof",
                    "Yuval Kochman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14223v1",
                    "http://arxiv.org/pdf/2311.14223v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14216v1/1.0",
                "title": "Reconstructing the growth index $\u03b3$ with Gaussian Processes",
                "year": 2023,
                "abstract": "Alternative cosmological models have been proposed to alleviate the tensions\nreported in the concordance cosmological model, or to explain the current\naccelerated phase of the universe. One way to distinguish between General\nRelativity and modified gravity models is using current astronomical data to\nmeasure the growth index $\\gamma$, a parameter related to the growth of matter\nperturbations, which behaves differently in different metric theories. We\npropose a model independent methodology for determining $\\gamma$, where our\nanalyses combine diverse cosmological data sets, namely $\\{ f(z_i) \\}$, $\\{\n[f\\sigma_8](z_i) \\}$, and $\\{ H(z_i) \\}$, and use Gaussian Processes, a\nnon-parametric approach suitable to reconstruct functions. This methodology is\na new consistency test for $\\gamma$ constant. Our results show that, for the\nredshift interval $0 < z < 1$, $\\gamma$ is consistent with the constant value\n$\\gamma = 0.55$, expected in General Relativity theory, within $2 \\sigma$\nconfidence level (CL). Moreover, we find $\\gamma(z=0)$ = $0.311 \\pm 0.229$ and\n$\\gamma(z=0) = 0.336 \\pm 0.107$ for the reconstructions using the $\\{ f(z_i)\n\\}$ and $\\{ [f\\sigma_8](z_i) \\}$ data sets, respectively, values that also\nagree at a 2$\\sigma$ CL with $\\gamma = 0.55$. Our main results are a third way\nin light of the current discussion in literature that point out to some\npossible evidence for the growth index evolution.",
                "authors": [
                    "Fernanda Oliveira",
                    "Felipe Avila",
                    "Armando Bernui",
                    "Alexander Bonilla",
                    "Rafael C. Nunes"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14216v1",
                    "http://arxiv.org/pdf/2311.14216v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14215v1/1.0",
                "title": "Refinement calculus of quantum programs with projective assertions",
                "year": 2023,
                "abstract": "Refinement calculus provides a structured framework for the progressive and\nmodular development of programs, ensuring their correctness throughout the\nrefinement process. This paper introduces a refinement calculus tailored for\nquantum programs. To this end, we first study the partial correctness of\nnondeterministic programs within a quantum while language featuring\nprescription statements. Orthogonal projectors, which are equivalent to\nsubspaces of the state Hilbert space, are taken as assertions for quantum\nstates. In addition to the denotational semantics where a nondeterministic\nprogram is associated with a set of trace-nonincreasing super-operators, we\nalso present their semantics in transforming a postcondition to the weakest\nliberal postconditions and, conversely, transforming a precondition to the\nstrongest postconditions. Subsequently, refinement rules are introduced based\non these dual semantics, offering a systematic approach to the incremental\ndevelopment of quantum programs applicable in various contexts. To illustrate\nthe practical application of the refinement calculus, we examine examples such\nas the implementation of a $Z$-rotation gate, the repetition code, and the\nquantum-to-quantum Bernoulli factory. Furthermore, we present Quire, a\nPython-based interactive prototype tool that provides practical support to\nprogrammers engaged in the stepwise development of correct quantum programs.",
                "authors": [
                    "Yuan Feng",
                    "Li Zhou",
                    "Yingte Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14215v1",
                    "http://arxiv.org/pdf/2311.14215v1"
                ],
                "primary_category": "cs.LO",
                "categories": [
                    "cs.LO",
                    "quant-ph",
                    "F.3.1; F.3.2"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14214v1/1.0",
                "title": "Extending Variability-Aware Model Selection with Bias Detection in\n  Machine Learning Projects",
                "year": 2023,
                "abstract": "Data science projects often involve various machine learning (ML) methods\nthat depend on data, code, and models. One of the key activities in these\nprojects is the selection of a model or algorithm that is appropriate for the\ndata analysis at hand. ML model selection depends on several factors, which\ninclude data-related attributes such as sample size, functional requirements\nsuch as the prediction algorithm type, and non-functional requirements such as\nperformance and bias. However, the factors that influence such selection are\noften not well understood and explicitly represented. This paper describes\nongoing work on extending an adaptive variability-aware model selection method\nwith bias detection in ML projects. The method involves: (i) modeling the\nvariability of the factors that affect model selection using feature models\nbased on heuristics proposed in the literature; (ii) instantiating our\nvariability model with added features related to bias (e.g., bias-related\nmetrics); and (iii) conducting experiments that illustrate the method in a\nspecific case study to illustrate our approach based on a heart failure\nprediction project. The proposed approach aims to advance the state of the art\nby making explicit factors that influence model selection, particularly those\nrelated to bias, as well as their interactions. The provided representations\ncan transform model selection in ML projects into a non ad hoc, adaptive, and\nexplainable process.",
                "authors": [
                    "Cristina Tavares",
                    "Nathalia Nascimento",
                    "Paulo Alencar",
                    "Donald Cowan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14214v1",
                    "http://arxiv.org/pdf/2311.14214v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14213v1/1.0",
                "title": "Learning to Solve Inverse Problems for Perceptual Sound Matching",
                "year": 2023,
                "abstract": "Perceptual sound matching (PSM) aims to find the input parameters to a\nsynthesizer so as to best imitate an audio target. Deep learning for PSM\noptimizes a neural network to analyze and reconstruct prerecorded samples. In\nthis context, our article addresses the problem of designing a suitable loss\nfunction when the training set is generated by a differentiable synthesizer.\nOur main contribution is perceptual-neural-physical loss (PNP), which aims at\naddressing a tradeoff between perceptual relevance and computational\nefficiency. The key idea behind PNP is to linearize the effect of synthesis\nparameters upon auditory features in the vicinity of each training sample. The\nlinearization procedure is massively paralellizable, can be precomputed, and\noffers a 100-fold speedup during gradient descent compared to differentiable\ndigital signal processing (DDSP). We demonstrate PNP on two datasets of\nnonstationary sounds: an AM/FM arpeggiator and a physical model of rectangular\nmembranes. We show that PNP is able to accelerate DDSP with joint\ntime-frequency scattering transform (JTFS) as auditory feature, while\npreserving its perceptual fidelity. Additionally, we evaluate the impact of\nother design choices in PSM: parameter rescaling, pretraining, auditory\nrepresentation, and gradient clipping. We report state-of-the-art results on\nboth datasets and find that PNP-accelerated JTFS has greater influence on PSM\nperformance than any other design choice.",
                "authors": [
                    "Han Han",
                    "Vincent Lostanlen",
                    "Mathieu Lagrange"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14213v1",
                    "http://arxiv.org/pdf/2311.14213v1"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14212v1/1.0",
                "title": "Annotation Sensitivity: Training Data Collection Methods Affect Model\n  Performance",
                "year": 2023,
                "abstract": "When training data are collected from human annotators, the design of the\nannotation instrument, the instructions given to annotators, the\ncharacteristics of the annotators, and their interactions can impact training\ndata. This study demonstrates that design choices made when creating an\nannotation instrument also impact the models trained on the resulting\nannotations.\n  We introduce the term annotation sensitivity to refer to the impact of\nannotation data collection methods on the annotations themselves and on\ndownstream model performance and predictions.\n  We collect annotations of hate speech and offensive language in five\nexperimental conditions of an annotation instrument, randomly assigning\nannotators to conditions. We then fine-tune BERT models on each of the five\nresulting datasets and evaluate model performance on a holdout portion of each\ncondition. We find considerable differences between the conditions for 1) the\nshare of hate speech/offensive language annotations, 2) model performance, 3)\nmodel predictions, and 4) model learning curves.\n  Our results emphasize the crucial role played by the annotation instrument\nwhich has received little attention in the machine learning literature. We call\nfor additional research into how and why the instrument impacts the annotations\nto inform the development of best practices in instrument design.",
                "authors": [
                    "Christoph Kern",
                    "Stephanie Eckman",
                    "Jacob Beck",
                    "Rob Chew",
                    "Bolei Ma",
                    "Frauke Kreuter"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14212v1",
                    "http://arxiv.org/pdf/2311.14212v1"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.CL",
                    "cs.LG",
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14208v1/1.0",
                "title": "ECRF: Entropy-Constrained Neural Radiance Fields Compression with\n  Frequency Domain Optimization",
                "year": 2023,
                "abstract": "Explicit feature-grid based NeRF models have shown promising results in terms\nof rendering quality and significant speed-up in training. However, these\nmethods often require a significant amount of data to represent a single scene\nor object. In this work, we present a compression model that aims to minimize\nthe entropy in the frequency domain in order to effectively reduce the data\nsize. First, we propose using the discrete cosine transform (DCT) on the\ntensorial radiance fields to compress the feature-grid. This feature-grid is\ntransformed into coefficients, which are then quantized and entropy encoded,\nfollowing a similar approach to the traditional video coding pipeline.\nFurthermore, to achieve a higher level of sparsity, we propose using an entropy\nparameterization technique for the frequency domain, specifically for DCT\ncoefficients of the feature-grid. Since the transformed coefficients are\noptimized during the training phase, the proposed model does not require any\nfine-tuning or additional information. Our model only requires a lightweight\ncompression pipeline for encoding and decoding, making it easier to apply\nvolumetric radiance field methods for real-world applications. Experimental\nresults demonstrate that our proposed frequency domain entropy model can\nachieve superior compression performance across various datasets. The source\ncode will be made publicly available.",
                "authors": [
                    "Soonbin Lee",
                    "Fangwen Shu",
                    "Yago Sanchez",
                    "Thomas Schierl",
                    "Cornelius Hellge"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14208v1",
                    "http://arxiv.org/pdf/2311.14208v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14205v3/1.0",
                "title": "Geometric aspects of a spin chain",
                "year": 2023,
                "abstract": "We discuss non-equilibrium thermodynamics of the mean field Ising chain from\na geometric perspective. We combine the language of Legendrian submanifolds and\ntheir generating functions borrowed from contact geometry with the Wasserstein\ngeometry on probability densities on the space of microscopic states. This\nenables us to describe relaxation of the chain towards the equilibrium in terms\nof a version of the Fokker-Planck equation. We show that in the thermodynamic\nlimit this description is closely related to the seminal model of relaxation\nproposed by Glauber.",
                "authors": [
                    "Michael Entov",
                    "Leonid Polterovich",
                    "Lenya Ryzhik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14205v3",
                    "http://arxiv.org/pdf/2311.14205v3"
                ],
                "primary_category": "math-ph",
                "categories": [
                    "math-ph",
                    "math.MP",
                    "math.SG",
                    "82Cxx, 53Dxx, 49Q20"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14203v1/1.0",
                "title": "Data-Driven Risk Modeling for Infrastructure Projects Using Artificial\n  Intelligence Techniques",
                "year": 2023,
                "abstract": "Managing project risk is a key part of the successful implementation of any\nlarge project and is widely recognized as a best practice for public agencies\nto deliver infrastructures. The conventional method of identifying and\nevaluating project risks involves getting input from subject matter experts at\nrisk workshops in the early phases of a project. As a project moves through its\nlife cycle, these identified risks and their assessments evolve. Some risks are\nrealized to become issues, some are mitigated, and some are retired as no\nlonger important. Despite the value provided by conventional expert-based\napproaches, several challenges remain due to the time-consuming and expensive\nprocesses involved. Moreover, limited is known about how risks evolve from\nex-ante to ex-post over time. How well does the project team identify and\nevaluate risks in the initial phase compared to what happens during project\nexecution? Using historical data and artificial intelligence techniques, this\nstudy addressed these limitations by introducing a data-driven framework to\nidentify risks automatically and to examine the quality of early risk registers\nand risk assessments. Risk registers from more than 70 U.S. major\ntransportation projects form the input dataset.",
                "authors": [
                    "Abdolmajid Erfani"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14203v1",
                    "http://arxiv.org/pdf/2311.14203v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14200v1/1.0",
                "title": "Prebunking Design as a Defense Mechanism Against Misinformation\n  Propagation on Social Networks",
                "year": 2023,
                "abstract": "The growing reliance on social media for news consumption necessitates\neffective countermeasures to mitigate the rapid spread of misinformation.\nPrebunking, a proactive method that arms users with accurate information before\nthey come across false content, has garnered support from journalism and\npsychology experts. We formalize the problem of optimal prebunking as\noptimizing the timing of delivering accurate information, ensuring users\nencounter it before receiving misinformation while minimizing the disruption to\nuser experience. Utilizing a susceptible-infected epidemiological process to\nmodel the propagation of misinformation, we frame optimal prebunking as a\npolicy synthesis problem with safety constraints. We then propose a policy that\napproximates the optimal solution to a relaxed problem. The experiments show\nthat this policy cuts the user experience cost of repeated information delivery\nin half, compared to delivering accurate information immediately after\nidentifying a misinformation propagation.",
                "authors": [
                    "Yigit Ege Bayiz",
                    "Ufuk Topcu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14200v1",
                    "http://arxiv.org/pdf/2311.14200v1"
                ],
                "primary_category": "cs.SI",
                "categories": [
                    "cs.SI",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14199v1/1.0",
                "title": "A Systematic Review of Deep Learning-based Research on Radiology Report\n  Generation",
                "year": 2023,
                "abstract": "Radiology report generation (RRG) aims to automatically generate free-text\ndescriptions from clinical radiographs, e.g., chest X-Ray images. RRG plays an\nessential role in promoting clinical automation and presents significant help\nto provide practical assistance for inexperienced doctors and alleviate\nradiologists' workloads. Therefore, consider these meaningful potentials,\nresearch on RRG is experiencing explosive growth in the past half-decade,\nespecially with the rapid development of deep learning approaches. Existing\nstudies perform RRG from the perspective of enhancing different modalities,\nprovide insights on optimizing the report generation process with elaborated\nfeatures from both visual and textual information, and further facilitate RRG\nwith the cross-modal interactions among them. In this paper, we present a\ncomprehensive review of deep learning-based RRG from various perspectives.\nSpecifically, we firstly cover pivotal RRG approaches based on the\ntask-specific features of radiographs, reports, and the cross-modal relations\nbetween them, and then illustrate the benchmark datasets conventionally used\nfor this task with evaluation metrics, subsequently analyze the performance of\ndifferent approaches and finally offer our summary on the challenges and the\ntrends in future directions. Overall, the goal of this paper is to serve as a\ntool for understanding existing literature and inspiring potential valuable\nresearch in the field of RRG.",
                "authors": [
                    "Chang Liu",
                    "Yuanhe Tian",
                    "Yan Song"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14199v1",
                    "http://arxiv.org/pdf/2311.14199v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14197v1/1.0",
                "title": "Enhancing mTBI Diagnosis with Residual Triplet Convolutional Neural\n  Network Using 3D CT",
                "year": 2023,
                "abstract": "Mild Traumatic Brain Injury (mTBI) is a common and challenging condition to\ndiagnose accurately. Timely and precise diagnosis is essential for effective\ntreatment and improved patient outcomes. Traditional diagnostic methods for\nmTBI often have limitations in terms of accuracy and sensitivity. In this\nstudy, we introduce an innovative approach to enhance mTBI diagnosis using 3D\nComputed Tomography (CT) images and a metric learning technique trained with\ntriplet loss. To address these challenges, we propose a Residual Triplet\nConvolutional Neural Network (RTCNN) model to distinguish between mTBI cases\nand healthy ones by embedding 3D CT scans into a feature space. The triplet\nloss function maximizes the margin between similar and dissimilar image pairs,\noptimizing feature representations. This facilitates better context placement\nof individual cases, aids informed decision-making, and has the potential to\nimprove patient outcomes. Our RTCNN model shows promising performance in mTBI\ndiagnosis, achieving an average accuracy of 94.3%, a sensitivity of 94.1%, and\na specificity of 95.2%, as confirmed through a five-fold cross-validation.\nImportantly, when compared to the conventional Residual Convolutional Neural\nNetwork (RCNN) model, the RTCNN exhibits a significant improvement, showcasing\na remarkable 22.5% increase in specificity, a notable 16.2% boost in accuracy,\nand an 11.3% enhancement in sensitivity. Moreover, RTCNN requires lower memory\nresources, making it not only highly effective but also resource-efficient in\nminimizing false positives while maximizing its diagnostic accuracy in\ndistinguishing normal CT scans from mTBI cases. The quantitative performance\nmetrics provided and utilization of occlusion sensitivity maps to visually\nexplain the model's decision-making process further enhance the\ninterpretability and transparency of our approach.",
                "authors": [
                    "Hanem Ellethy",
                    "Shekhar S. Chandra",
                    "Viktor Vegh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14197v1",
                    "http://arxiv.org/pdf/2311.14197v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14194v1/1.0",
                "title": "Symmedians as Hyperbolic Barycenters",
                "year": 2023,
                "abstract": "The symmedian point of a triangle enjoys several geometric and optimality\nproperties, which also serve to define it. We develop a new dynamical\ncoordinatization of the symmedian, which naturally generalizes to other ideal\nhyperbolic polygons beyond triangles. We prove that in general this point still\nsatisfies analogous geometric and optimality properties to those of the\nsymmedian, making it into a hyperbolic barycenter. We initiate a study of\nmoduli spaces of ideal polygons with fixed hyperbolic barycenter, and of some\nadditional optimality properties of this point for harmonic (and sufficiently\nregular) ideal polygons.",
                "authors": [
                    "Maxim Arnold",
                    "Carlos E. Arreche"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14194v1",
                    "http://arxiv.org/pdf/2311.14194v1"
                ],
                "primary_category": "math.DG",
                "categories": [
                    "math.DG",
                    "math.MG",
                    "53A70, 51M15"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14189v1/1.0",
                "title": "HACD: Hand-Aware Conditional Diffusion for Monocular Hand-Held Object\n  Reconstruction",
                "year": 2023,
                "abstract": "Reconstructing hand-held objects from a single RGB image without known 3D\nobject templates, category prior, or depth information is a vital yet\nchallenging problem in computer vision. In contrast to prior works that utilize\ndeterministic modeling paradigms, which make it hard to account for the\nuncertainties introduced by hand- and self-occlusion, we employ a probabilistic\npoint cloud denoising diffusion model to tackle the above challenge. In this\nwork, we present Hand-Aware Conditional Diffusion for monocular hand-held\nobject reconstruction (HACD), modeling the hand-object interaction in two\naspects. First, we introduce hand-aware conditioning to model hand-object\ninteraction from both semantic and geometric perspectives. Specifically, a\nunified hand-object semantic embedding compensates for the 2D local feature\ndeficiency induced by hand occlusion, and a hand articulation embedding further\nencodes the relationship between object vertices and hand joints. Second, we\npropose a hand-constrained centroid fixing scheme, which utilizes hand vertices\npriors to restrict the centroid deviation of partially denoised point cloud\nduring diffusion and reverse process. Removing the centroid bias interference\nallows the diffusion models to focus on the reconstruction of shape, thus\nenhancing the stability and precision of local feature projection. Experiments\non the synthetic ObMan dataset and two real-world datasets, HO3D and MOW,\ndemonstrate our approach surpasses all existing methods by a large margin.",
                "authors": [
                    "Bowen Fu",
                    "Yan Di",
                    "Chenyangguang Zhang",
                    "Gu Wang",
                    "Ziqin Huang",
                    "Zhiying Leng",
                    "Fabian Manhardt",
                    "Xiangyang Ji",
                    "Federico Tombari"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14189v1",
                    "http://arxiv.org/pdf/2311.14189v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14186v1/1.0",
                "title": "Anyone Can Code: Algorithmic Thinking",
                "year": 2023,
                "abstract": "As the second book in the Anyone Can Code series, Algorithmic Thinking\nfocuses on the logic behind computer programming and software design. With a\ndata-centred approach, it starts with simple algorithms that work on simple\ndata items and advances to more complex ones covering data structures and\nclasses. Examples are given in C/C++ and Python and use both plain text and\ngraphics applications to illustrate the concepts in different languages and\nforms. With the advances in artificial intelligence and automated code\ngenerators, it is essential to learn about the logic of what a code needs to\ndo, not just how to write the code. Anyone Can Code: Algorithmic Thinking is\nsuitable for anyone who aims to improve their programming skills and go beyond\nthe simple craft of programming, stepping into the world of algorithm design.",
                "authors": [
                    "Ali Arya"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14186v1",
                    "http://arxiv.org/pdf/2311.14186v1"
                ],
                "primary_category": "cs.PL",
                "categories": [
                    "cs.PL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14185v1/1.0",
                "title": "Disc Tearing in a Be Star: Predicted 3D Observations",
                "year": 2023,
                "abstract": "We build on our previous work involving smoothed particle hydrodynamic\nsimulations of Be stars, by using the model that exhibited disc tearing as\ninput into the three-dimensional Monte Carlo radiative transfer code HDUST to\npredict observables from a variety of viewing angles throughout the disc\ntearing process. We run one simulation at the start of each orbital period from\n20 to 72 orbital periods, which covers two complete disc tearing events. The\nresulting trends in observables are found to be dependent on the relative\nposition of the observer and the tearing disc. The $\\rm H\\alpha$ equivalent\nwidth, $V$ magnitude, and polarization can all increase or decrease in any\ncombination depending on the viewpoint of the observer. The $\\rm H\\alpha$ line\nprofile also displays changes in strength and peak separation throughout the\ntearing process. We show how the outer disc of the torn system can have a large\neffect on the $\\rm H\\alpha$ line profile, and also contributes to a\nwavelength-dependent polarization position angle, resulting in a similar\nsawtooth shape to the polarization percentage. Finally, we compare our\npredictions to Pleione (28 Tau) where evidence has suggested that a disc\ntearing event has occurred in the past. We find that our tearing disc model can\nbroadly match the trends seen in Pleione's observables, as well as produce the\ntwo-component $\\rm H\\alpha$ lines observed in Pleione. This is the strongest\nevidence, thus far, of Pleione's disc having indeed experienced a tearing\nevent.",
                "authors": [
                    "M. W. Suffak",
                    "C. E. Jones",
                    "A. C. Carciofi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14185v1",
                    "http://arxiv.org/pdf/2311.14185v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00802v1/1.0",
                "title": "Continuous Authentication Using Mouse Clickstream Data Analysis",
                "year": 2023,
                "abstract": "Biometrics is used to authenticate an individual based on physiological or\nbehavioral traits. Mouse dynamics is an example of a behavioral biometric that\ncan be used to perform continuous authentication as protection against security\nbreaches. Recent research on mouse dynamics has shown promising results in\nidentifying users; however, it has not yet reached an acceptable level of\naccuracy. In this paper, an empirical evaluation of different classification\ntechniques is conducted on a mouse dynamics dataset, the Balabit Mouse\nChallenge dataset. User identification is carried out using three mouse\nactions: mouse move, point and click, and drag and drop. Verification and\nauthentication methods are conducted using three machine-learning classifiers:\nthe Decision Tree classifier, the K-Nearest Neighbors classifier, and the\nRandom Forest classifier. The results show that the three classifiers can\ndistinguish between a genuine user and an impostor with a relatively high\ndegree of accuracy. In the verification mode, all the classifiers achieve a\nperfect accuracy of 100%. In authentication mode, all three classifiers\nachieved the highest accuracy (ACC) and Area Under Curve (AUC) from scenario B\nusing the point and click action data: (Decision Tree ACC:87.6%, AUC:90.3%),\n(K-Nearest Neighbors ACC:99.3%, AUC:99.9%), and (Random Forest ACC:89.9%,\nAUC:92.5%).",
                "authors": [
                    "Sultan Almalki",
                    "Prosenjit Chatterjee",
                    "Kaushik Roy"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00802v1",
                    "http://arxiv.org/pdf/2312.00802v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.AI",
                    "cs.CR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14183v2/1.0",
                "title": "Effect of shoaling length on rogue wave occurrence",
                "year": 2023,
                "abstract": "The impact of shoaling on linear water waves is well-known, but it has only\nbeen recently found to significantly amplify both the intensity and frequency\nof rogue waves in nonlinear irregular wave trains atop coastal shoals. At least\nqualitatively, this effect has been partially attributed to the \"rapid'\" nature\nof the shoaling process, i.e., shoaling occurs over a distance far shorter than\nthat required for waves to modulate themselves and adapt to the reduced water\ndepth. Through the development of a theoretical model and highly accurate\nnonlinear simulations, we disentangle the respective effects of the slope\nlength and the slope gradient of a shoal and focus on the slope length to\ninvestigate the rapidness of the shoaling process on the evolution of key\nstatistical and spectral sea-state parameters. Provided the shoal slope is 1/10\nor steeper, our results indicate that the non-equilibrium dynamics is involved\neven for rather short shoaling lengths and becomes dominant in the regime of\nlarge lengths. When the non-equilibrium dynamics governs the wave evolution,\nfurther extending the slope length no longer influences the statistical and\nspectral measures. Thus, the shoaling effect on rogue waves is mainly driven by\nthe slope magnitude rather than the slope length. Moreover, the simulations\nshow that a higher cut-off frequency of the wave spectrum has a smaller impact\non wave statistics than expected for a flat bottom in deep water and that\ninsufficient attenuation of low-frequency waves at the downstream domain\nboundary has notable influence on wave statistics atop the shoal.",
                "authors": [
                    "Jie Zhang",
                    "Saulo Mendes",
                    "Michel Benoit",
                    "J\u00e9r\u00f4me Kasparian"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14183v2",
                    "http://arxiv.org/pdf/2311.14183v2"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "physics.ao-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14761v1/1.0",
                "title": "From Spin States to Social Consensus: Ising Approach to Dimer\n  Configurations in Opinion Formation",
                "year": 2023,
                "abstract": "The field of opinion dynamics has evolved steadily since the earliest studies\napplying magnetic physics methods to better understand social opinion\nformation. However, in the real world, complete agreement of opinions is rare,\nand biaxial consensus, especially on social issues, is rare. To address this\nchallenge, Ishii and Kawabata (2018) proposed an extended version of the\nBounded Confidence Model that introduces new parameters indicating dissent and\ndistrust, as well as the influence of mass media. Their model aimed to capture\nmore realistic social opinion dynamics by introducing coefficients representing\nthe degree of trust and distrust, rather than assuming convergence of opinions.\nIn this paper, we propose a new approach to opinion dynamics based on this\nTrust-Distrust Model (TDM), applying the dimer allocation and Ising model. Our\ngoal is to explore how the interaction between trust and distrust affects\nsocial opinion formation. In particular, we analyze through mathematical models\nhow various external stimuli, such as mass media, third-party opinions, and\neconomic and political factors, affect people's opinions. Our approach is to\nmathematically represent the dynamics of trust and distrust, which traditional\nmodels have not addressed. This theoretical framework provides new insights\ninto the polarization of opinions, the process of consensus building, and how\nthese are reflected in social behavior. In addition to developing the\ntheoretical framework by applying the dimer configuration, the dimer model and\nthe Ising model, this paper uses numerical simulations to show how the proposed\nmodel applies to actual social opinion formation. This research aims to\ncontribute to a deeper understanding of social opinion formation by providing\nnew perspectives in the fields of social science, physics, and computational\nmodeling.",
                "authors": [
                    "Yasuko Kawahata"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14761v1",
                    "http://arxiv.org/pdf/2311.14761v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph",
                    "cs.SI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14176v1/1.0",
                "title": "Concentration and local smoothness of the averaging process",
                "year": 2023,
                "abstract": "We consider the averaging process on the discrete $d$-dimensional torus. On\nthis graph, the process is known to converge to equilibrium on diffusive\ntimescales, not exhibiting cutoff. In this work, we refine this picture in two\nways. Firstly, we prove a concentration phenomenon of the averaging process\naround its mean, occurring on a shorter timescale than the one of its\nrelaxation to equilibrium. Secondly, we establish sharp gradient estimates,\nwhich capture its fast local smoothness property. This is the first setting in\nwhich these two features of the averaging process -- concentration and local\nsmoothness -- can be quantified. These features carry useful information on a\nnumber of large scale properties of the averaging process. As an illustration\nof this fact, we determine the limit profile of its distance to equilibrium and\nderive a quantitative hydrodynamic limit for it. Finally, we discuss their\nimplications on cutoff for the binomial splitting process, the particle\nanalogue of the averaging process.",
                "authors": [
                    "Federico Sau"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14176v1",
                    "http://arxiv.org/pdf/2311.14176v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "math-ph",
                    "math.FA",
                    "math.MP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14173v1/1.0",
                "title": "Entangling entanglement: coupling frequency and polarization of\n  biphotons on demand",
                "year": 2023,
                "abstract": "Quantum information is often carried in the frequency and polarization\ndegrees of freedom (DoFs) in single photons and entangled photons. We\ndemonstrate a new approach to couple and decouple the frequency and\npolarization DoFs of broadband biphotons. Our approach is based on a\ncommon-path nonlinear interferometer (CP-NLI) with a linear dispersive medium\nand a polarization controller sandwiched in between two nonlinear media that\ngenerate the interfering biphotons. By adjusting the polarization controller,\nwe can effectively manipulate the two DoFs. When the two DoFs are decoupled,\nmaximally polarization-entangled biphotons are observed in the polarization\nDoF, while interference fringes are observed in the spectral intensity of the\nbiphotons. When the two DoFs are coupled, however, interference fringes\ndisappear from the spectral intensity and instead appear in the degree of\npolarization entanglement. The degree of polarization entanglement quantified\nby concurrence in principle can vary from 0 to 1 depending on the signal and\nidler photon frequencies. Our approach offers a convenient means of tuning the\npolarization entanglement and can be employed for arbitrary biphoton\npolarization state generation, with applications in quantum information\nprocessing and the study of fundamental physics.",
                "authors": [
                    "Arash Riazi",
                    "Eric Y. Zhu",
                    "Dan Xu",
                    "Li Qian"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14173v1",
                    "http://arxiv.org/pdf/2311.14173v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14171v1/1.0",
                "title": "OpenMP behavior in low resource and high stress mobile environment",
                "year": 2023,
                "abstract": "This paper investigates the use of OpenMP for parallel post processing in\nobejct detection on personal Android devices, where resources like\ncomputational power, memory, and battery are limited. Specifically, it explores\nvarious configurations of thread count, CPU affinity, and chunk size on a Redmi\nNote 10 Pro with an ARM Cortex A76 CPU. The study finds that using four threads\noffers a maximum post processing speedup of 2.3x but increases overall\ninference time by 2.7x. A balanced configuration of two threads achieves a 1.8x\nspeedup in post processing and a 2% improvement in overall program performance.",
                "authors": [
                    "Kaijun Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14171v1",
                    "http://arxiv.org/pdf/2311.14171v1"
                ],
                "primary_category": "cs.PF",
                "categories": [
                    "cs.PF",
                    "cs.OS, cs.PF, cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14169v1/1.0",
                "title": "Evaluating GPT-4's Vision Capabilities on Brazilian University Admission\n  Exams",
                "year": 2023,
                "abstract": "Recent advancements in language models have showcased human-comparable\nperformance in academic entrance exams. However, existing studies often\noverlook questions that require the integration of visual comprehension, thus\ncompromising the full spectrum and complexity inherent in real-world scenarios.\nTo address this gap, we present a comprehensive framework to evaluate language\nmodels on entrance exams, which incorporates both textual and visual elements.\nWe evaluate the two most recent editions of Exame Nacional do Ensino M\\'edio\n(ENEM), the main standardized entrance examination adopted by Brazilian\nuniversities. Our study not only reaffirms the capabilities of GPT-4 as the\nstate of the art for handling complex multidisciplinary questions, but also\npioneers in offering a realistic assessment of multimodal language models on\nPortuguese examinations. One of the highlights is that text captions\ntranscribing visual content outperform the direct use of images, suggesting\nthat the vision model has room for improvement. Yet, despite improvements\nafforded by images or captions, mathematical questions remain a challenge for\nthese state-of-the-art models. The code and data used on experiments are\navailable at https://github.com/piresramon/gpt-4-enem.",
                "authors": [
                    "Ramon Pires",
                    "Thales Sales Almeida",
                    "Hugo Abonizio",
                    "Rodrigo Nogueira"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14169v1",
                    "http://arxiv.org/pdf/2311.14169v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14164v1/1.0",
                "title": "Hybrid Circuit Mapping: Leveraging the Full Spectrum of Computational\n  Capabilities of Neutral Atom Quantum Computers",
                "year": 2023,
                "abstract": "Quantum computing based on Neutral Atoms (NAs) provides a wide range of\ncomputational capabilities, encompassing high-fidelity long-range interactions\nwith native multi-qubit gates, and the ability to shuttle arrays of qubits.\nWhile previously these capabilities have been studied individually, we propose\nthe first approach of a fast hybrid compiler to perform circuit mapping and\nrouting based on both high-fidelity gate interactions and qubit shuttling. We\ndelve into the intricacies of the compilation process when combining multiple\ncapabilities and present effective solutions to address resulting challenges.\nThe final compilation strategy is then showcased across various hardware\nsettings, revealing its versatility, and highlighting potential fidelity\nenhancements achieved through the strategic utilization of combined gate- and\nshuttling-based routing. With the additional multi-qubit gate support for both\nrouting capabilities, the proposed approach is able to take advantage of the\nfull spectrum of computational capabilities offered by NAs.",
                "authors": [
                    "Ludwig Schmid",
                    "Sunghye Park",
                    "Seokhyeong Kang",
                    "Robert Wille"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14164v1",
                    "http://arxiv.org/pdf/2311.14164v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "cs.ET"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14162v1/1.0",
                "title": "Generalized imaginary units in quantum mechanics",
                "year": 2023,
                "abstract": "The generalization of the imaginary unit is examined within the instances of\nthe complex quantum mechanics ($\\mathbb C$QM), and of the quaternionic quantum\nmechanics ($\\mathbb H$QM) as well. Whereas the complex theory describes\nnon-stationary quantum processes, the quaternionic theory does not admit such\nan interpretation, and associates the generalized imaginary unit to a novel\ntime evolution function. Various possibilities are opened as future directions\nfor future research.",
                "authors": [
                    "Sergio Giardino"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14162v1",
                    "http://arxiv.org/pdf/2311.14162v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14160v1/1.0",
                "title": "Efficient and Robust Jet Tagging at the LHC with Knowledge Distillation",
                "year": 2023,
                "abstract": "The challenging environment of real-time data processing systems at the Large\nHadron Collider (LHC) strictly limits the computational complexity of\nalgorithms that can be deployed. For deep learning models, this implies that\nonly models with low computational complexity that have weak inductive bias are\nfeasible. To address this issue, we utilize knowledge distillation to leverage\nboth the performance of large models and the reduced computational complexity\nof small ones. In this paper, we present an implementation of knowledge\ndistillation, demonstrating an overall boost in the student models' performance\nfor the task of classifying jets at the LHC. Furthermore, by using a teacher\nmodel with a strong inductive bias of Lorentz symmetry, we show that we can\ninduce the same inductive bias in the student model which leads to better\nrobustness against arbitrary Lorentz boost.",
                "authors": [
                    "Ryan Liu",
                    "Abhijith Gandrakota",
                    "Jennifer Ngadiuba",
                    "Maria Spiropulu",
                    "Jean-Roch Vlimant"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14160v1",
                    "http://arxiv.org/pdf/2311.14160v1"
                ],
                "primary_category": "hep-ex",
                "categories": [
                    "hep-ex",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14153v1/1.0",
                "title": "Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC\n  using Tube-Guided Data Augmentation and NeRFs",
                "year": 2023,
                "abstract": "Imitation learning (IL) can train computationally-efficient sensorimotor\npolicies from a resource-intensive Model Predictive Controller (MPC), but it\noften requires many samples, leading to long training times or limited\nrobustness. To address these issues, we combine IL with a variant of robust MPC\nthat accounts for process and sensing uncertainties, and we design a data\naugmentation (DA) strategy that enables efficient learning of vision-based\npolicies. The proposed DA method, named Tube-NeRF, leverages Neural Radiance\nFields (NeRFs) to generate novel synthetic images, and uses properties of the\nrobust MPC (the tube) to select relevant views and to efficiently compute the\ncorresponding actions. We tailor our approach to the task of localization and\ntrajectory tracking on a multirotor, by learning a visuomotor policy that\ngenerates control actions using images from the onboard camera as only source\nof horizontal position. Our evaluations numerically demonstrate learning of a\nrobust visuomotor policy with an 80-fold increase in demonstration efficiency\nand a 50% reduction in training time over current IL methods. Additionally, our\npolicies successfully transfer to a real multirotor, achieving accurate\nlocalization and low tracking errors despite large disturbances, with an\nonboard inference time of only 1.5 ms.",
                "authors": [
                    "Andrea Tagliabue",
                    "Jonathan P. How"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14153v1",
                    "http://arxiv.org/pdf/2311.14153v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14152v1/1.0",
                "title": "Differential aperture photometry and digital coronagraphy with PRAIA",
                "year": 2023,
                "abstract": "PRAIA - Package for the Reduction of Astronomical Images Automatically - is a\nsuite of photometric and astrometric tasks designed to cope with huge amounts\nof heterogeneous observations with fast processing, no human intervention,\nminimum parametrization and yet maximum possible accuracy and precision. It is\nthe main tool used to analyse astronomical observations by an international\ncollaboration involving Brazilian, French and Spanish researchers under the\nLucky Star umbrella for Solar System studies. Here, we focus on the concepts of\ndifferential aperture photometry and digital coronagraphy underneath PRAIA,\nused in the reduction of stellar occultations, rotational light curves, mutual\nphenomena and natural satellite observations. We highlight novelties developed\nby us and never before reported in the literature, which significantly enhance\nthe precision and automation of photometry and digital coronagraphy, such as:\na) PRAIA's pixelized aperture photometry (PCAP); b) fully automatic object\ndetection and aperture determination (BOIA); c) better astrometry improving the\naperture and coronagraphy centre, including the new Photogravity Center Method\nbesides circular and elliptical Gaussian and Lorentzian generalized profiles;\nd) coronagraphy of faint objects close to bright ones and vice-versa; e) use of\nelliptical rings for the coronagraphy of elongated profiles; f) refined\nquartile ring statistics; g) multiprocessing image capabilities for faster\ncomputation speed. We give examples showing the photometry performance, discuss\nthe advantages of PRAIA over other popular packages, and point out the\nuniqueness of its digital coronagraphy in comparison with other coronagraphy\ntools. Besides Solar System works, PRAIA can also be used in the differential\nphotometry and digital coronagraphy of any astrophysical observations. PRAIA\ncodes are publicly available at: https://ov.ufrj.br/en/PRAIA/.",
                "authors": [
                    "M. Assafin"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/j.pss.2023.105816",
                    "http://arxiv.org/abs/2311.14152v1",
                    "http://arxiv.org/pdf/2311.14152v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14150v1/1.0",
                "title": "Logarithmic enumerative geometry for curves and sheaves",
                "year": 2023,
                "abstract": "We propose a logarithmic enhancement of the Gromov-Witten/Donaldson-Thomas\ncorrespondence, with descendants, and study the behaviour of the correspondence\nunder simple normal crossings degenerations. The formulation of the logarithmic\ncorrespondence requires a matching of tangency conditions and relative\ninsertions. This is achieved via a version of the Nakajima basis for the\ncohomology of the Hilbert schemes of points on logarithmic surfaces.\n  We then establish a strong form of the degeneration formula in logarithmic DT\ntheory - the numerical DT invariants of the general fiber of a degeneration are\ndetermined by the numerical DT invariants attached to strata of the special\nfiber. The GW version of this result, which we also prove here, is a\nstrengthening of the currently known formulas. A key role is played by a\ncertain exotic class of insertions, introduced here, and can be thought of as\nnon-local incidence conditions coupled across multiple boundary strata of the\ntarget geometry.\n  Finally, we prove compatiblity of the new logarithmic GW/DT correspondence\nwith degenerations, and in particular, knowledge of the conjecture on the\nstrata of the special fiber of a degeneration implies it on the general fiber.\nSeveral examples are included to illustrate the nature and utility of the\nformula.",
                "authors": [
                    "Davesh Maulik",
                    "Dhruv Ranganathan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14150v1",
                    "http://arxiv.org/pdf/2311.14150v1"
                ],
                "primary_category": "math.AG",
                "categories": [
                    "math.AG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14149v1/1.0",
                "title": "Toward organ shortage resilient allocation policies using real-time\n  queueing models for liver transplantation",
                "year": 2023,
                "abstract": "We report in this paper on the potential interest of real-time queueing\nmodels to optimize organ allocation policies. We especially focus on building\norgan shortage resilient policies in terms of equity, as we experienced\ndifferential impact of the COVID epidemic organ shortage on transplant access,\naccording to the cause of liver failure. Patient's death on the waiting list or\ndropout for being too sick, resulting from the absence of a timely available\norgan, is chosen as the main equity metric. Results obtained with the composite\nallocation score used in France is challenged against the so-called Early\nSimulated Deadline First (ESDF) real-time queueing discipline, under increasing\nlevels of organ shortage, by extensive simulations. The ESDF policy is a\nvariant of the well-know Earliest Deadline First (EDF) policy, which was shown\nas optimal in various contexts in the queueing literature. In the present case,\nthe time to the deadline represents the remaining life duration of patients -\nwhich is of course unknown. So we propose to simulate a fictional\nlife-duration, and give priority to the earliest simulated deadline. This leads\nto a simple and comprehensive representation of the system at hand by a Markov\nprocess. Our simulation results clearly show that the ESDF policy allows to\nmaintain equity between indications, conversely to the scoring policy, which\nwas not resilient to increasing levels of organ shortage.",
                "authors": [
                    "Thomas Masanet",
                    "Beno\u00eet Audry",
                    "Christian Jacquelinet",
                    "Pascal Moyal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14149v1",
                    "http://arxiv.org/pdf/2311.14149v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14148v1/1.0",
                "title": "Automated 3D Tumor Segmentation using Temporal Cubic PatchGAN (TCuP-GAN)",
                "year": 2023,
                "abstract": "Development of robust general purpose 3D segmentation frameworks using the\nlatest deep learning techniques is one of the active topics in various\nbio-medical domains. In this work, we introduce Temporal Cubic PatchGAN\n(TCuP-GAN), a volume-to-volume translational model that marries the concepts of\na generative feature learning framework with Convolutional Long Short-Term\nMemory Networks (LSTMs), for the task of 3D segmentation. We demonstrate the\ncapabilities of our TCuP-GAN on the data from four segmentation challenges\n(Adult Glioma, Meningioma, Pediatric Tumors, and Sub-Saharan Africa subset)\nfeatured within the 2023 Brain Tumor Segmentation (BraTS) Challenge and\nquantify its performance using LesionWise Dice similarity and $95\\%$ Hausdorff\nDistance metrics. We demonstrate the successful learning of our framework to\npredict robust multi-class segmentation masks across all the challenges. This\nbenchmarking work serves as a stepping stone for future efforts towards\napplying TCuP-GAN on other multi-class tasks such as multi-organelle\nsegmentation in electron microscopy imaging.",
                "authors": [
                    "Kameswara Bharadwaj Mantha",
                    "Ramanakumar Sankar",
                    "Lucy Fortson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14148v1",
                    "http://arxiv.org/pdf/2311.14148v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14143v1/1.0",
                "title": "Exciting high-frequency short-wavelength spin waves using high harmonics\n  of a magnonic cavity mode",
                "year": 2023,
                "abstract": "Confined spin-wave modes are a promising object for studying nonlinear\neffects and future quantum technologies. Here, using micromagnetic simulations,\nwe use a microwave magnetic field from a coplanar waveguide (CPW) to pump a\nstanding spin-wave confined in the cavity of magnonic crystal. We find that the\nfrequency of the fundamental cavity mode is equal to the ferromagnetic\nresonance frequency of the plane film and overlaps with the magnonic bandgap,\nallowing high magnetic field tunability. Multi-frequency harmonics of the\ncavity mode are generated once the microwave amplitude surpasses a certain\nthreshold. Specifically, the second and third harmonics at 0.5 T equate to 48.6\nand 72.9 GHz with wavelengths of 44 and 22 nm respectively, which propagate\ninto the crystal. This effect reaches saturation when the CPW covers the entire\ncavity, making the system feasible for realization. These processes show\npotential for the advancement of magnonics at high-frequencies and very\nshort-wavelengths.",
                "authors": [
                    "Nikhil Kumar",
                    "Pawe\u0142 Gruszecki",
                    "Mateusz Go\u0142\u0119biewski",
                    "Jaros\u0142aw W. K\u0142os",
                    "Maciej Krawczyk"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14143v1",
                    "http://arxiv.org/pdf/2311.14143v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "cond-mat.other"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14139v1/1.0",
                "title": "Machine Learning For An Explainable Cost Prediction of Medical Insurance",
                "year": 2023,
                "abstract": "Predictive modeling in healthcare continues to be an active actuarial\nresearch topic as more insurance companies aim to maximize the potential of\nMachine Learning approaches to increase their productivity and efficiency. In\nthis paper, the authors deployed three regression-based ensemble ML models that\ncombine variations of decision trees through Extreme Gradient Boosting,\nGradient-boosting Machine, and Random Forest) methods in predicting medical\ninsurance costs. Explainable Artificial Intelligence methods SHapley Additive\nexPlanations and Individual Conditional Expectation plots were deployed to\ndiscover and explain the key determinant factors that influence medical\ninsurance premium prices in the dataset. The dataset used comprised 986 records\nand is publicly available in the KAGGLE repository. The models were evaluated\nusing four performance evaluation metrics, including R-squared, Mean Absolute\nError, Root Mean Squared Error, and Mean Absolute Percentage Error. The results\nshow that all models produced impressive outcomes; however, the XGBoost model\nachieved a better overall performance although it also expanded more\ncomputational resources, while the RF model recorded a lesser prediction error\nand consumed far fewer computing resources than the XGBoost model. Furthermore,\nwe compared the outcome of both XAi methods in identifying the key determinant\nfeatures that influenced the PremiumPrices for each model and whereas both XAi\nmethods produced similar outcomes, we found that the ICE plots showed in more\ndetail the interactions between each variable than the SHAP analysis which\nseemed to be more high-level. It is the aim of the authors that the\ncontributions of this study will help policymakers, insurers, and potential\nmedical insurance buyers in their decision-making process for selecting the\nright policies that meet their specific needs.",
                "authors": [
                    "Ugochukwu Orji",
                    "Elochukwu Ukwandu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14139v1",
                    "http://arxiv.org/pdf/2311.14139v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14133v1/1.0",
                "title": "A robust framework for quantum computation using quasi-hidden molecular\n  degrees of freedom",
                "year": 2023,
                "abstract": "We discuss a novel approach to quantum information processing with molecules\nbased on molecular degrees of freedom which are isolated from the environment\nas well as from the rest of the molecule. Such a degree of freedom can provide\nlong-term quantum storage even in a noisy environment, and provides an\nindependent protected quantum memory while quantum operations are performed\nbetween the rest of the molecule and external systems. We present several\npossibilities for realizing a quasi-hidden degree of freedom in a molecule, and\ndiscuss a number of examples for using such a degree of freedom in practice.\nUsing quasi-hidden degrees of freedom could substantially improve the prospects\nfor a molecule-based quantum computer.",
                "authors": [
                    "Martin Zeppenfeld"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14133v1",
                    "http://arxiv.org/pdf/2311.14133v1"
                ],
                "primary_category": "physics.atom-ph",
                "categories": [
                    "physics.atom-ph",
                    "physics.chem-ph",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14130v1/1.0",
                "title": "Unified Treatment of Null and Spatial Infinity III: Asymptotically\n  Minkowski Space-times",
                "year": 2023,
                "abstract": "The Spi framework provides a 4-dimensional approach to investigate the\nasymptotic properties of gravitational fields as one recedes from isolated\nsystems in any space-like direction, without reference to a Cauchy surface. It\nis well suited to unify descriptions at null and spatial infinity because\n$\\mathscr{I}$ arises as the null cone of $i^\\circ$. The goal of this work is to\ncomplete this task by introducing a natural extension of the asymptotic\nconditions at null and spatial infinity, by 'gluing' the two descriptions\nappropriately. Space-times satisfying these conditions are asymptotically flat\nin both regimes and thus represent isolated gravitating systems. They will be\nsaid to be Asymptotically Minkowskian at $i^\\circ$. We show that in these\nspace-times the Spi group $\\mathfrak{S}$ as well as the BMS group $\\mathcal{B}$\nnaturally reduce to a single Poincar\\'e group, denoted by\n$\\mathfrak{p}_{i^\\circ}$ to highlight the fact that it arises from the gluing\nprocedure at $i^\\circ$. The asymptotic conditions are sufficiently weak to\nallow for the possibility that the Newman-Penrose component $\\Psi^\\circ_1$\ndiverges in the distant past along $\\mathscr{I}^+$. This can occur in\nastrophysical sources that are not asymptotically stationary in the past, e.g.\nin scattering situations. Nonetheless, as we show in the companion paper, the\nenergy momentum and angular momentum defined at $i^\\circ$ equals the sum of\nthat defined at a cross-section $S$ of $\\mathscr{I}^+$ and corresponding flux\nacross $\\mathscr{I}^+$ to the past of $S$, when the quantities refer to the\npreferred Poincar\\'e subgroup $\\mathfrak{p}_{i^\\circ}$.",
                "authors": [
                    "Abhay Ashtekar",
                    "Neev Khera"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14130v1",
                    "http://arxiv.org/pdf/2311.14130v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14126v1/1.0",
                "title": "Towards Auditing Large Language Models: Improving Text-based Stereotype\n  Detection",
                "year": 2023,
                "abstract": "Large Language Models (LLM) have made significant advances in the recent past\nbecoming more mainstream in Artificial Intelligence (AI) enabled human-facing\napplications. However, LLMs often generate stereotypical output inherited from\nhistorical data, amplifying societal biases and raising ethical concerns. This\nwork introduces i) the Multi-Grain Stereotype Dataset, which includes 52,751\ninstances of gender, race, profession and religion stereotypic text and ii) a\nnovel stereotype classifier for English text. We design several experiments to\nrigorously test the proposed model trained on the novel dataset. Our\nexperiments show that training the model in a multi-class setting can\noutperform the one-vs-all binary counterpart. Consistent feature importance\nsignals from different eXplainable AI tools demonstrate that the new model\nexploits relevant text features. We utilise the newly created model to assess\nthe stereotypic behaviour of the popular GPT family of models and observe the\nreduction of bias over time. In summary, our work establishes a robust and\npractical framework for auditing and evaluating the stereotypic bias in LLM.",
                "authors": [
                    "Wu Zekun",
                    "Sahan Bulathwela",
                    "Adriano Soares Koshiyama"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14126v1",
                    "http://arxiv.org/pdf/2311.14126v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.CY",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14123v1/1.0",
                "title": "Exponential Quantum Space Advantage for Approximating Maximum Directed\n  Cut in the Streaming Model",
                "year": 2023,
                "abstract": "While the search for quantum advantage typically focuses on speedups in\nexecution time, quantum algorithms also offer the potential for advantage in\nspace complexity. Previous work has shown such advantages for data stream\nproblems, in which elements arrive and must be processed sequentially without\nrandom access, but these have been restricted to specially-constructed problems\n[Le Gall, SPAA `06] or polynomial advantage [Kallaugher, FOCS `21]. We show an\nexponential quantum space advantage for the maximum directed cut problem. This\nis the first known exponential quantum space advantage for any natural\nstreaming problem. This also constitutes the first unconditional exponential\nquantum resource advantage for approximating a discrete optimization problem in\nany setting.\n  Our quantum streaming algorithm $0.4844$-approximates the value of the\nlargest directed cut in a graph stream with $n$ vertices using polylog$(n)$\nspace, while previous work by Chou, Golovnev, and Velusamy [FOCS '20] implies\nthat obtaining an approximation ratio better than $4/9 \\approx 0.4444$ requires\n$\\Omega(\\sqrt{n})$ space for any classical streaming algorithm. Our result is\nbased on a recent $\\widetilde{\\text{O}}(\\sqrt{n})$ space classical streaming\napproach by Saxena, Singer, Sudan, and Velusamy [FOCS '23], with an additional\nimprovement in the approximation ratio due to recent work by Singer [APPROX\n'23].",
                "authors": [
                    "John Kallaugher",
                    "Ojas Parekh",
                    "Nadezhda Voronova"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14123v1",
                    "http://arxiv.org/pdf/2311.14123v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "cs.DS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14115v2/1.0",
                "title": "A density estimation perspective on learning from pairwise human\n  preferences",
                "year": 2023,
                "abstract": "Learning from human feedback (LHF) -- and in particular learning from\npairwise preferences -- has recently become a crucial ingredient in training\nlarge language models (LLMs), and has been the subject of much research. Most\nrecent works frame it as a reinforcement learning problem, where a reward\nfunction is learned from pairwise preference data and the LLM is treated as a\npolicy which is adapted to maximize the rewards, often under additional\nregularization constraints. We propose an alternative interpretation which\ncenters on the generative process for pairwise preferences and treats LHF as a\ndensity estimation problem. We provide theoretical and empirical results\nshowing that for a family of generative processes defined via preference\nbehavior distribution equations, training a reward function on pairwise\npreferences effectively models an annotator's implicit preference distribution.\nFinally, we discuss and present findings on \"annotator misspecification\" --\nfailure cases where wrong modeling assumptions are made about annotator\nbehavior, resulting in poorly-adapted models -- suggesting that approaches that\nlearn from pairwise human preferences could have trouble learning from a\npopulation of annotators with diverse viewpoints.",
                "authors": [
                    "Vincent Dumoulin",
                    "Daniel D. Johnson",
                    "Pablo Samuel Castro",
                    "Hugo Larochelle",
                    "Yann Dauphin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14115v2",
                    "http://arxiv.org/pdf/2311.14115v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14109v1/1.0",
                "title": "Boosting the Power of Small Multimodal Reasoning Models to Match Larger\n  Models with Self-Consistency Training",
                "year": 2023,
                "abstract": "Multimodal reasoning is a challenging task that requires models to reason\nacross multiple modalities to answer questions. Existing approaches have made\nprogress by incorporating language and visual modalities into a two-stage\nreasoning framework, separating rationale generation from answer inference.\nHowever, these approaches often fall short due to the inadequate quality of the\ngenerated rationales. In this work, we delve into the importance of rationales\nin model reasoning. We observe that when rationales are completely accurate,\nthe model's accuracy significantly improves, highlighting the need for\nhigh-quality rationale generation. Motivated by this, we propose MC-CoT, a\nself-consistency training strategy that generates multiple rationales and\nanswers, subsequently selecting the most accurate through a voting process.\nThis approach not only enhances the quality of generated rationales but also\nleads to more accurate and robust answers. Through extensive experiments, we\ndemonstrate that our approach significantly improves model performance across\nvarious benchmarks. Remarkably, we show that even smaller base models, when\nequipped with our proposed approach, can achieve results comparable to those of\nlarger models, illustrating the potential of our approach in harnessing the\npower of rationales for improved multimodal reasoning. The code is available at\nhttps://github.com/chengtan9907/mc-cot.",
                "authors": [
                    "Cheng Tan",
                    "Jingxuan Wei",
                    "Zhangyang Gao",
                    "Linzhuang Sun",
                    "Siyuan Li",
                    "Xihong Yang",
                    "Stan Z. Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14109v1",
                    "http://arxiv.org/pdf/2311.14109v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14108v1/1.0",
                "title": "MINTY: Rule-based Models that Minimize the Need for Imputing Features\n  with Missing Values",
                "year": 2023,
                "abstract": "Rule models are often preferred in prediction tasks with tabular inputs as\nthey can be easily interpreted using natural language and provide predictive\nperformance on par with more complex models. However, most rule models'\npredictions are undefined or ambiguous when some inputs are missing, forcing\nusers to rely on statistical imputation models or heuristics like zero\nimputation, undermining the interpretability of the models. In this work, we\npropose fitting concise yet precise rule models that learn to avoid relying on\nfeatures with missing values and, therefore, limit their reliance on imputation\nat test time. We develop MINTY, a method that learns rules in the form of\ndisjunctions between variables that act as replacements for each other when one\nor more is missing. This results in a sparse linear rule model, regularized to\nhave small dependence on features with missing values, that allows a trade-off\nbetween goodness of fit, interpretability, and robustness to missing values at\ntest time. We demonstrate the value of MINTY in experiments using synthetic and\nreal-world data sets and find its predictive performance comparable or\nfavorable to baselines, with smaller reliance on features with missing values.",
                "authors": [
                    "Lena Stempfle",
                    "Fredrik D. Johansson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14108v1",
                    "http://arxiv.org/pdf/2311.14108v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14099v1/1.0",
                "title": "Explaining ATOMKI, $(g-2)_\u03bc$, and MiniBooNE anomalies with light\n  mediators in $U(1)_H$ extended model",
                "year": 2023,
                "abstract": "We consider $U(1)_H$ extensions of Type-I 2HDM plus a singlet scalar\n$\\phi_H$, introducing a new Higgs doublet $H_2$ and a singlet $\\phi_H$ charged\nunder $U(1)_H$. The SM Higgs doublet $H_1$ as well as all the SM fermions and\nthree right-handed singlet neutrinos, introduced to generate nonzero neutrino\nmasses and mixings, are neutral under $U(1)_H$. We also introduce a SM singlet\nDirac fermion, charged under $U(1)_H$ and utilize it as sterile neutrinos\nrelevant to the MiniBooNE experiment. The $U(1)_H$ symmetry breaks due to the\nvacuum expectation values of $H_2$ and $\\phi_H$, leading to the emergence of a\nlight vector boson with a mass of approximately 17 MeV. This vector boson\ninteracts with fermions through mass mixing and kinetic mixing process\ninvolving other neutral gauge bosons. Furthermore, alongside the light vector\nboson, another light scalar particle with a mass around 10--100 MeV may arise\nfrom scalar sector mixing. By utilizing the gauge couplings of the light vector\nboson and the Yukawa couplings of the light scalar, this model can\nsimultaneously provide an explanation for the Beryllium anomaly observed in the\nATOMKI experiment, the anomalous magnetic moment of charged leptons and the\nexcess of electron-like events detected at the MiniBooNE experiment.",
                "authors": [
                    "Sumit Ghosh",
                    "Pyungwon Ko"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14099v1",
                    "http://arxiv.org/pdf/2311.14099v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14096v1/1.0",
                "title": "Auditing and Mitigating Cultural Bias in LLMs",
                "year": 2023,
                "abstract": "Culture fundamentally shapes people's reasoning, behavior, and communication.\nGenerative artificial intelligence (AI) technologies may cause a shift towards\na dominant culture. As people increasingly use AI to expedite and even automate\nvarious professional and personal tasks, cultural values embedded in AI models\nmay bias authentic expression. We audit large language models for cultural\nbias, comparing their responses to nationally representative survey data, and\nevaluate country-specific prompting as a mitigation strategy. We find that\nGPT-4, 3.5 and 3 exhibit cultural values resembling English-speaking and\nProtestant European countries. Our mitigation strategy reduces cultural bias in\nrecent models but not for all countries/territories. To avoid cultural bias in\ngenerative AI, especially in high-stakes contexts, we suggest using culture\nmatching and ongoing cultural audits.",
                "authors": [
                    "Yan Tao",
                    "Olga Viberg",
                    "Ryan S. Baker",
                    "Rene F. Kizilcec"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14096v1",
                    "http://arxiv.org/pdf/2311.14096v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14093v1/1.0",
                "title": "Color Confinement and Random Matrices -- A random walk down group\n  manifold toward Casimir scaling --",
                "year": 2023,
                "abstract": "We explain the microscopic origin of linear confinement potential with the\nCasimir scaling in generic confining gauge theories. In the low-temperature\nregime of confining gauge theories such as QCD, Polyakov lines are slowly\nvarying Haar random modulo exponentially small corrections with respect to the\ninverse temperature, as shown by one of the authors (M.H.) and Watanabe. With\nexact Haar randomness, computation of the two-point correlator of Polyakov\nloops reduces to the problem of random walk on group manifold. Linear\nconfinement potential with approximate Casimir scaling except at short\ndistances follows naturally from slowly varying Haar randomness. With\nexponentially small corrections to Haar randomness, string breaking and loss of\nCasimir scaling at long distance follow. Hence we obtain the Casimir scaling\nwhich is only approximate and holds only at intermediate distance, which is\nprecisely needed to explain the results of lattice simulations. For\n$(1+1)$-dimensional theories, there is a simplification that admits the Casimir\nscaling at short distances as well.",
                "authors": [
                    "Georg Bergner",
                    "Vaibhav Gautam",
                    "Masanori Hanada"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14093v1",
                    "http://arxiv.org/pdf/2311.14093v1"
                ],
                "primary_category": "hep-th",
                "categories": [
                    "hep-th",
                    "hep-lat",
                    "hep-ph",
                    "nucl-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14091v1/1.0",
                "title": "PortfolioMentor: Multimodal Generative AI Companion for Learning and\n  Crafting Interactive Digital Art Portfolios",
                "year": 2023,
                "abstract": "Digital art portfolios serve as impactful mediums for artists to convey their\nvisions, weaving together visuals, audio, interactions, and narratives.\nHowever, without technical backgrounds, design students often find it\nchallenging to translate creative ideas into tangible codes and designs, given\nthe lack of tailored resources for the non-technical, academic support in art\nschools, and a comprehensive guiding tool throughout the mentally demanding\nprocess. Recognizing the role of companionship in code learning and leveraging\ngenerative AI models' capabilities in supporting creative tasks, we present\nPortfolioMentor, a coding companion chatbot for IDEs. This tool guides and\ncollaborates with students through proactive suggestions and responsible Q&As\nfor learning, inspiration, and support. In detail, the system starts with the\nunderstanding of the task and artist's visions, follows the co-creation of\nvisual illustrations, audio or music suggestions and files, click-scroll\neffects for interactions, and creative vision conceptualization, and finally\nsynthesizes these facets into a polished interactive digital portfolio.",
                "authors": [
                    "Tao Long",
                    "Weirui Peng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14091v1",
                    "http://arxiv.org/pdf/2311.14091v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC",
                    "cs.AI",
                    "cs.CY",
                    "cs.MM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14087v1/1.0",
                "title": "Question Answering in Natural Language: the Special Case of Temporal\n  Expressions",
                "year": 2023,
                "abstract": "Although general question answering has been well explored in recent years,\ntemporal question answering is a task which has not received as much focus. Our\nwork aims to leverage a popular approach used for general question answering,\nanswer extraction, in order to find answers to temporal questions within a\nparagraph. To train our model, we propose a new dataset, inspired by SQuAD,\nspecifically tailored to provide rich temporal information. We chose to adapt\nthe corpus WikiWars, which contains several documents on history's greatest\nconflicts. Our evaluation shows that a deep learning model trained to perform\npattern matching, often used in general question answering, can be adapted to\ntemporal question answering, if we accept to ask questions whose answers must\nbe directly present within a text.",
                "authors": [
                    "Armand Stricker"
                ],
                "url": [
                    "http://dx.doi.org/10.26615/issn.2603-2821.2021_026",
                    "http://arxiv.org/abs/2311.14087v1",
                    "http://arxiv.org/pdf/2311.14087v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14086v1/1.0",
                "title": "Brain MRI Screening Tool with Federated Learning",
                "year": 2023,
                "abstract": "In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.",
                "authors": [
                    "Roman Stoklasa",
                    "Ioannis Stathopoulos",
                    "Efstratios Karavasilis",
                    "Efstathios Efstathopoulos",
                    "Marek Dost\u00e1l",
                    "Milo\u0161 Ke\u0159kovsk\u00fd",
                    "Michal Kozubek",
                    "Luigi Serio"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14086v1",
                    "http://arxiv.org/pdf/2311.14086v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG",
                    "q-bio.NC",
                    "D.2.2; H.1.2; H.5.2; I.4.8; I.4.6; I.5.1; I.5.4; J.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14085v1/1.0",
                "title": "Measurement of $J/\u03c8$-pair production in $pp$ collisions at\n  $\\sqrt{s}=13$ TeV and study of gluon transverse-momentum dependent PDFs",
                "year": 2023,
                "abstract": "The production cross-section of $J/\\psi$ pairs in proton-proton collisions at\na centre-of-mass energy of $\\sqrt{s}=13$ TeV is measured using a data sample\ncorresponding to an integrated luminosity of 4.2 fb$^{-1}$ collected by the\nLHCb experiment. The measurement is performed with both $J/\\psi$ mesons in the\ntransverse momentum range $0<p_{\\text{T}}<14$ GeV/$c$ and rapidity range\n$2.0<y<4.5$. The cross-section of this process is measured to be\n16.36$\\pm$0.28(stat)$\\pm$0.88(syst) nb. The contributions from single-parton\nscattering and double-parton scattering are separated based on the dependence\nof the cross-section on the absolute rapidity difference $\\Delta y$ between the\ntwo $J/\\psi$ mesons. The effective cross-section of double-parton scattering is\nmeasured to be $\\sigma_{\\text{eff}}=$13.1$\\pm$1.8(stat)$\\pm$2.3(syst) mb. The\ndistribution of the azimuthal angle $\\phi_{\\text{CS}}$ of one of the $J/\\psi$\nmesons in the Collins-Soper frame and the $p_{\\text{T}}$-spectrum of the\n$J/\\psi$ pairs are also measured for the study of the gluon transverse-momentum\ndependent distributions inside protons. The extracted values of\n$\\langle\\cos2\\phi_{\\text{CS}}\\rangle$ and $\\langle\\cos4\\phi_{\\text{CS}}\\rangle$\nare consistent with zero, but the presence of azimuthal asymmetry at a few\npercent level is allowed.",
                "authors": [
                    "LHCb collaboration",
                    "R. Aaij",
                    "A. S. W. Abdelmotteleb",
                    "C. Abellan Beteta",
                    "F. Abudin\u00e9n",
                    "T. Ackernley",
                    "B. Adeva",
                    "M. Adinolfi",
                    "P. Adlarson",
                    "H. Afsharnia",
                    "C. Agapopoulou",
                    "C. A. Aidala",
                    "Z. Ajaltouni",
                    "S. Akar",
                    "K. Akiba",
                    "P. Albicocco",
                    "J. Albrecht",
                    "F. Alessio",
                    "M. Alexander",
                    "A. Alfonso Albero",
                    "Z. Aliouche",
                    "P. Alvarez Cartelle",
                    "R. Amalric",
                    "S. Amato",
                    "J. L. Amey",
                    "Y. Amhis",
                    "L. An",
                    "L. Anderlini",
                    "M. Andersson",
                    "A. Andreianov",
                    "P. Andreola",
                    "M. Andreotti",
                    "D. Andreou",
                    "A. Anelli",
                    "D. Ao",
                    "F. Archilli",
                    "S. Arguedas Cuendis",
                    "A. Artamonov",
                    "M. Artuso",
                    "E. Aslanides",
                    "M. Atzeni",
                    "B. Audurier",
                    "D. Bacher",
                    "I. Bachiller Perea",
                    "S. Bachmann",
                    "M. Bachmayer",
                    "J. J. Back",
                    "A. Bailly-reyre",
                    "P. Baladron Rodriguez",
                    "V. Balagura",
                    "W. Baldini",
                    "J. Baptista de Souza Leite",
                    "M. Barbetti",
                    "I. R. Barbosa",
                    "R. J. Barlow",
                    "S. Barsuk",
                    "W. Barter",
                    "M. Bartolini",
                    "F. Baryshnikov",
                    "J. M. Basels",
                    "G. Bassi",
                    "B. Batsukh",
                    "A. Battig",
                    "A. Bay",
                    "A. Beck",
                    "M. Becker",
                    "F. Bedeschi",
                    "I. B. Bediaga",
                    "A. Beiter",
                    "S. Belin",
                    "V. Bellee",
                    "K. Belous",
                    "I. Belov",
                    "I. Belyaev",
                    "G. Benane",
                    "G. Bencivenni",
                    "E. Ben-Haim",
                    "A. Berezhnoy",
                    "R. Bernet",
                    "S. Bernet Andres",
                    "H. C. Bernstein",
                    "C. Bertella",
                    "A. Bertolin",
                    "C. Betancourt",
                    "F. Betti",
                    "J. Bex",
                    "Ia. Bezshyiko",
                    "J. Bhom",
                    "M. S. Bieker",
                    "N. V. Biesuz",
                    "P. Billoir",
                    "A. Biolchini",
                    "M. Birch",
                    "F. C. R. Bishop",
                    "A. Bitadze",
                    "A. Bizzeti",
                    "M. P. Blago",
                    "T. Blake",
                    "F. Blanc",
                    "J. E. Blank",
                    "S. Blusk",
                    "D. Bobulska",
                    "V. Bocharnikov",
                    "J. A. Boelhauve",
                    "O. Boente Garcia",
                    "T. Boettcher",
                    "A. Bohare",
                    "A. Boldyrev",
                    "C. S. Bolognani",
                    "R. Bolzonella",
                    "N. Bondar",
                    "F. Borgato",
                    "S. Borghi",
                    "M. Borsato",
                    "J. T. Borsuk",
                    "S. A. Bouchiba",
                    "T. J. V. Bowcock",
                    "A. Boyer",
                    "C. Bozzi",
                    "M. J. Bradley",
                    "S. Braun",
                    "A. Brea Rodriguez",
                    "N. Breer",
                    "J. Brodzicka",
                    "A. Brossa Gonzalo",
                    "J. Brown",
                    "D. Brundu",
                    "A. Buonaura",
                    "L. Buonincontri",
                    "A. T. Burke",
                    "C. Burr",
                    "A. Bursche",
                    "A. Butkevich",
                    "J. S. Butter",
                    "J. Buytaert",
                    "W. Byczynski",
                    "S. Cadeddu",
                    "H. Cai",
                    "R. Calabrese",
                    "L. Calefice",
                    "S. Cali",
                    "M. Calvi",
                    "M. Calvo Gomez",
                    "J. Cambon Bouzas",
                    "P. Campana",
                    "D. H. Campora Perez",
                    "A. F. Campoverde Quezada",
                    "S. Capelli",
                    "L. Capriotti",
                    "A. Carbone",
                    "L. Carcedo Salgado",
                    "R. Cardinale",
                    "A. Cardini",
                    "P. Carniti",
                    "L. Carus",
                    "A. Casais Vidal",
                    "R. Caspary",
                    "G. Casse",
                    "J. Castro Godinez",
                    "M. Cattaneo",
                    "G. Cavallero",
                    "V. Cavallini",
                    "S. Celani",
                    "J. Cerasoli",
                    "D. Cervenkov",
                    "S. Cesare",
                    "A. J. Chadwick",
                    "I. Chahrour",
                    "M. Charles",
                    "Ph. Charpentier",
                    "C. A. Chavez Barajas",
                    "M. Chefdeville",
                    "C. Chen",
                    "S. Chen",
                    "A. Chernov",
                    "S. Chernyshenko",
                    "V. Chobanova",
                    "S. Cholak",
                    "M. Chrzaszcz",
                    "A. Chubykin",
                    "V. Chulikov",
                    "P. Ciambrone",
                    "M. F. Cicala",
                    "X. Cid Vidal",
                    "G. Ciezarek",
                    "P. Cifra",
                    "P. E. L. Clarke",
                    "M. Clemencic",
                    "H. V. Cliff",
                    "J. Closier",
                    "J. L. Cobbledick",
                    "C. Cocha Toapaxi",
                    "V. Coco",
                    "J. Cogan",
                    "E. Cogneras",
                    "L. Cojocariu",
                    "P. Collins",
                    "T. Colombo",
                    "A. Comerma-Montells",
                    "L. Congedo",
                    "A. Contu",
                    "N. Cooke",
                    "I. Corredoira",
                    "A. Correia",
                    "G. Corti",
                    "J. J. Cottee Meldrum",
                    "B. Couturier",
                    "D. C. Craik",
                    "M. Cruz Torres",
                    "R. Currie",
                    "C. L. Da Silva",
                    "S. Dadabaev",
                    "L. Dai",
                    "X. Dai",
                    "E. Dall'Occo",
                    "J. Dalseno",
                    "C. D'Ambrosio",
                    "J. Daniel",
                    "A. Danilina",
                    "P. d'Argent",
                    "A. Davidson",
                    "J. E. Davies",
                    "A. Davis",
                    "O. De Aguiar Francisco",
                    "C. De Angelis",
                    "J. de Boer",
                    "K. De Bruyn",
                    "S. De Capua",
                    "M. De Cian",
                    "U. De Freitas Carneiro Da Graca",
                    "E. De Lucia",
                    "J. M. De Miranda",
                    "L. De Paula",
                    "M. De Serio",
                    "D. De Simone",
                    "P. De Simone",
                    "F. De Vellis",
                    "J. A. de Vries",
                    "F. Debernardis",
                    "D. Decamp",
                    "V. Dedu",
                    "L. Del Buono",
                    "B. Delaney",
                    "H. -P. Dembinski",
                    "J. Deng",
                    "V. Denysenko",
                    "O. Deschamps",
                    "F. Dettori",
                    "B. Dey",
                    "P. Di Nezza",
                    "I. Diachkov",
                    "S. Didenko",
                    "S. Ding",
                    "V. Dobishuk",
                    "A. D. Docheva",
                    "A. Dolmatov",
                    "C. Dong",
                    "A. M. Donohoe",
                    "F. Dordei",
                    "A. C. dos Reis",
                    "L. Douglas",
                    "A. G. Downes",
                    "W. Duan",
                    "P. Duda",
                    "M. W. Dudek",
                    "L. Dufour",
                    "V. Duk",
                    "P. Durante",
                    "M. M. Duras",
                    "J. M. Durham",
                    "D. Dutta",
                    "A. Dziurda",
                    "A. Dzyuba",
                    "S. Easo",
                    "E. Eckstein",
                    "U. Egede",
                    "A. Egorychev",
                    "V. Egorychev",
                    "C. Eirea Orro",
                    "S. Eisenhardt",
                    "E. Ejopu",
                    "S. Ek-In",
                    "L. Eklund",
                    "M. Elashri",
                    "J. Ellbracht",
                    "S. Ely",
                    "A. Ene",
                    "E. Epple",
                    "S. Escher",
                    "J. Eschle",
                    "S. Esen",
                    "T. Evans",
                    "F. Fabiano",
                    "L. N. Falcao",
                    "Y. Fan",
                    "B. Fang",
                    "L. Fantini",
                    "M. Faria",
                    "K. Farmer",
                    "D. Fazzini",
                    "L. Felkowski",
                    "M. Feng",
                    "M. Feo",
                    "M. Fernandez Gomez",
                    "A. D. Fernez",
                    "F. Ferrari",
                    "F. Ferreira Rodrigues",
                    "S. Ferreres Sole",
                    "M. Ferrillo",
                    "M. Ferro-Luzzi",
                    "S. Filippov",
                    "R. A. Fini",
                    "M. Fiorini",
                    "M. Firlej",
                    "K. M. Fischer",
                    "D. S. Fitzgerald",
                    "C. Fitzpatrick",
                    "T. Fiutowski",
                    "F. Fleuret",
                    "M. Fontana",
                    "F. Fontanelli",
                    "L. F. Foreman",
                    "R. Forty",
                    "D. Foulds-Holt",
                    "M. Franco Sevilla",
                    "M. Frank",
                    "E. Franzoso",
                    "G. Frau",
                    "C. Frei",
                    "D. A. Friday",
                    "L. Frontini",
                    "J. Fu",
                    "Q. Fuehring",
                    "Y. Fujii",
                    "T. Fulghesu",
                    "E. Gabriel",
                    "G. Galati",
                    "M. D. Galati",
                    "A. Gallas Torreira",
                    "D. Galli",
                    "S. Gambetta",
                    "M. Gandelman",
                    "P. Gandini",
                    "H. Gao",
                    "R. Gao",
                    "Y. Gao",
                    "Y. Gao",
                    "Y. Gao",
                    "M. Garau",
                    "L. M. Garcia Martin",
                    "P. Garcia Moreno",
                    "J. Garc\u00eda Pardi\u00f1as",
                    "B. Garcia Plana",
                    "K. G. Garg",
                    "L. Garrido",
                    "C. Gaspar",
                    "R. E. Geertsema",
                    "L. L. Gerken",
                    "E. Gersabeck",
                    "M. Gersabeck",
                    "T. Gershon",
                    "Z. Ghorbanimoghaddam",
                    "L. Giambastiani",
                    "F. I. Giasemis",
                    "V. Gibson",
                    "H. K. Giemza",
                    "A. L. Gilman",
                    "M. Giovannetti",
                    "A. Giovent\u00f9",
                    "P. Gironella Gironell",
                    "C. Giugliano",
                    "M. A. Giza",
                    "E. L. Gkougkousis",
                    "F. C. Glaser",
                    "V. V. Gligorov",
                    "C. G\u00f6bel",
                    "E. Golobardes",
                    "D. Golubkov",
                    "A. Golutvin",
                    "A. Gomes",
                    "S. Gomez Fernandez",
                    "F. Goncalves Abrantes",
                    "M. Goncerz",
                    "G. Gong",
                    "J. A. Gooding",
                    "I. V. Gorelov",
                    "C. Gotti",
                    "J. P. Grabowski",
                    "L. A. Granado Cardoso",
                    "E. Graug\u00e9s",
                    "E. Graverini",
                    "L. Grazette",
                    "G. Graziani",
                    "A. T. Grecu",
                    "L. M. Greeven",
                    "N. A. Grieser",
                    "L. Grillo",
                    "S. Gromov",
                    "C. Gu",
                    "M. Guarise",
                    "M. Guittiere",
                    "V. Guliaeva",
                    "P. A. G\u00fcnther",
                    "A. -K. Guseinov",
                    "E. Gushchin",
                    "Y. Guz",
                    "T. Gys",
                    "T. Hadavizadeh",
                    "C. Hadjivasiliou",
                    "G. Haefeli",
                    "C. Haen",
                    "J. Haimberger",
                    "M. Hajheidari",
                    "T. Halewood-leagas",
                    "M. M. Halvorsen",
                    "P. M. Hamilton",
                    "J. Hammerich",
                    "Q. Han",
                    "X. Han",
                    "S. Hansmann-Menzemer",
                    "L. Hao",
                    "N. Harnew",
                    "T. Harrison",
                    "M. Hartmann",
                    "C. Hasse",
                    "J. He",
                    "K. Heijhoff",
                    "F. Hemmer",
                    "C. Henderson",
                    "R. D. L. Henderson",
                    "A. M. Hennequin",
                    "K. Hennessy",
                    "L. Henry",
                    "J. Herd",
                    "J. Heuel",
                    "A. Hicheur",
                    "D. Hill",
                    "S. E. Hollitt",
                    "J. Horswill",
                    "R. Hou",
                    "Y. Hou",
                    "N. Howarth",
                    "J. Hu",
                    "J. Hu",
                    "W. Hu",
                    "X. Hu",
                    "W. Huang",
                    "W. Hulsbergen",
                    "R. J. Hunter",
                    "M. Hushchyn",
                    "D. Hutchcroft",
                    "M. Idzik",
                    "D. Ilin",
                    "P. Ilten",
                    "A. Inglessi",
                    "A. Iniukhin",
                    "A. Ishteev",
                    "K. Ivshin",
                    "R. Jacobsson",
                    "H. Jage",
                    "S. J. Jaimes Elles",
                    "S. Jakobsen",
                    "E. Jans",
                    "B. K. Jashal",
                    "A. Jawahery",
                    "V. Jevtic",
                    "E. Jiang",
                    "X. Jiang",
                    "Y. Jiang",
                    "Y. J. Jiang",
                    "M. John",
                    "D. Johnson",
                    "C. R. Jones",
                    "T. P. Jones",
                    "S. Joshi",
                    "B. Jost",
                    "N. Jurik",
                    "I. Juszczak",
                    "D. Kaminaris",
                    "S. Kandybei",
                    "Y. Kang",
                    "M. Karacson",
                    "D. Karpenkov",
                    "M. Karpov",
                    "A. M. Kauniskangas",
                    "J. W. Kautz",
                    "F. Keizer",
                    "D. M. Keller",
                    "M. Kenzie",
                    "T. Ketel",
                    "B. Khanji",
                    "A. Kharisova",
                    "S. Kholodenko",
                    "G. Khreich",
                    "T. Kirn",
                    "V. S. Kirsebom",
                    "O. Kitouni",
                    "S. Klaver",
                    "N. Kleijne",
                    "K. Klimaszewski",
                    "M. R. Kmiec",
                    "S. Koliiev",
                    "L. Kolk",
                    "A. Konoplyannikov",
                    "P. Kopciewicz",
                    "P. Koppenburg",
                    "M. Korolev",
                    "I. Kostiuk",
                    "O. Kot",
                    "S. Kotriakhova",
                    "A. Kozachuk",
                    "P. Kravchenko",
                    "L. Kravchuk",
                    "M. Kreps",
                    "S. Kretzschmar",
                    "P. Krokovny",
                    "W. Krupa",
                    "W. Krzemien",
                    "J. Kubat",
                    "S. Kubis",
                    "W. Kucewicz",
                    "M. Kucharczyk",
                    "V. Kudryavtsev",
                    "E. Kulikova",
                    "A. Kupsc",
                    "B. K. Kutsenko",
                    "D. Lacarrere",
                    "G. Lafferty",
                    "A. Lai",
                    "A. Lampis",
                    "D. Lancierini",
                    "C. Landesa Gomez",
                    "J. J. Lane",
                    "R. Lane",
                    "C. Langenbruch",
                    "J. Langer",
                    "O. Lantwin",
                    "T. Latham",
                    "F. Lazzari",
                    "C. Lazzeroni",
                    "R. Le Gac",
                    "S. H. Lee",
                    "R. Lef\u00e8vre",
                    "A. Leflat",
                    "S. Legotin",
                    "M. Lehuraux",
                    "O. Leroy",
                    "T. Lesiak",
                    "B. Leverington",
                    "A. Li",
                    "H. Li",
                    "K. Li",
                    "L. Li",
                    "P. Li",
                    "P. -R. Li",
                    "S. Li",
                    "T. Li",
                    "T. Li",
                    "Y. Li",
                    "Y. Li",
                    "Z. Li",
                    "Z. Lian",
                    "X. Liang",
                    "C. Lin",
                    "T. Lin",
                    "R. Lindner",
                    "V. Lisovskyi",
                    "R. Litvinov",
                    "G. Liu",
                    "H. Liu",
                    "K. Liu",
                    "Q. Liu",
                    "S. Liu",
                    "Y. Liu",
                    "Y. Liu",
                    "Y. L. Liu",
                    "A. Lobo Salvia",
                    "A. Loi",
                    "J. Lomba Castro",
                    "T. Long",
                    "J. H. Lopes",
                    "A. Lopez Huertas",
                    "S. L\u00f3pez Soli\u00f1o",
                    "G. H. Lovell",
                    "C. Lucarelli",
                    "D. Lucchesi",
                    "S. Luchuk",
                    "M. Lucio Martinez",
                    "V. Lukashenko",
                    "Y. Luo",
                    "A. Lupato",
                    "E. Luppi",
                    "K. Lynch",
                    "X. -R. Lyu",
                    "G. M. Ma",
                    "R. Ma",
                    "S. Maccolini",
                    "F. Machefert",
                    "F. Maciuc",
                    "I. Mackay",
                    "L. R. Madhan Mohan",
                    "M. M. Madurai",
                    "A. Maevskiy",
                    "D. Magdalinski",
                    "D. Maisuzenko",
                    "M. W. Majewski",
                    "J. J. Malczewski",
                    "S. Malde",
                    "B. Malecki",
                    "L. Malentacca",
                    "A. Malinin",
                    "T. Maltsev",
                    "G. Manca",
                    "G. Mancinelli",
                    "C. Mancuso",
                    "R. Manera Escalero",
                    "D. Manuzzi",
                    "D. Marangotto",
                    "J. F. Marchand",
                    "R. Marchevski",
                    "U. Marconi",
                    "S. Mariani",
                    "C. Marin Benito",
                    "J. Marks",
                    "A. M. Marshall",
                    "P. J. Marshall",
                    "G. Martelli",
                    "G. Martellotti",
                    "L. Martinazzoli",
                    "M. Martinelli",
                    "D. Martinez Santos",
                    "F. Martinez Vidal",
                    "A. Massafferri",
                    "M. Materok",
                    "R. Matev",
                    "A. Mathad",
                    "V. Matiunin",
                    "C. Matteuzzi",
                    "K. R. Mattioli",
                    "A. Mauri",
                    "E. Maurice",
                    "J. Mauricio",
                    "M. Mazurek",
                    "M. McCann",
                    "L. Mcconnell",
                    "T. H. McGrath",
                    "N. T. McHugh",
                    "A. McNab",
                    "R. McNulty",
                    "B. Meadows",
                    "G. Meier",
                    "D. Melnychuk",
                    "M. Merk",
                    "A. Merli",
                    "L. Meyer Garcia",
                    "D. Miao",
                    "H. Miao",
                    "M. Mikhasenko",
                    "D. A. Milanes",
                    "A. Minotti",
                    "E. Minucci",
                    "T. Miralles",
                    "S. E. Mitchell",
                    "B. Mitreska",
                    "D. S. Mitzel",
                    "A. Modak",
                    "A. M\u00f6dden",
                    "R. A. Mohammed",
                    "R. D. Moise",
                    "S. Mokhnenko",
                    "T. Momb\u00e4cher",
                    "M. Monk",
                    "I. A. Monroy",
                    "S. Monteil",
                    "A. Morcillo Gomez",
                    "G. Morello",
                    "M. J. Morello",
                    "M. P. Morgenthaler",
                    "J. Moron",
                    "A. B. Morris",
                    "A. G. Morris",
                    "R. Mountain",
                    "H. Mu",
                    "Z. M. Mu",
                    "E. Muhammad",
                    "F. Muheim",
                    "M. Mulder",
                    "K. M\u00fcller",
                    "F. M\u0169noz-Rojas",
                    "R. Murta",
                    "P. Naik",
                    "T. Nakada",
                    "R. Nandakumar",
                    "T. Nanut",
                    "I. Nasteva",
                    "M. Needham",
                    "N. Neri",
                    "S. Neubert",
                    "N. Neufeld",
                    "P. Neustroev",
                    "R. Newcombe",
                    "J. Nicolini",
                    "D. Nicotra",
                    "E. M. Niel",
                    "N. Nikitin",
                    "P. Nogga",
                    "N. S. Nolte",
                    "C. Normand",
                    "J. Novoa Fernandez",
                    "G. Nowak",
                    "C. Nunez",
                    "H. N. Nur",
                    "A. Oblakowska-Mucha",
                    "V. Obraztsov",
                    "T. Oeser",
                    "S. Okamura",
                    "R. Oldeman",
                    "F. Oliva",
                    "M. Olocco",
                    "C. J. G. Onderwater",
                    "R. H. O'Neil",
                    "J. M. Otalora Goicochea",
                    "T. Ovsiannikova",
                    "P. Owen",
                    "A. Oyanguren",
                    "O. Ozcelik",
                    "K. O. Padeken",
                    "B. Pagare",
                    "P. R. Pais",
                    "T. Pajero",
                    "A. Palano",
                    "M. Palutan",
                    "G. Panshin",
                    "L. Paolucci",
                    "A. Papanestis",
                    "M. Pappagallo",
                    "L. L. Pappalardo",
                    "C. Pappenheimer",
                    "C. Parkes",
                    "B. Passalacqua",
                    "G. Passaleva",
                    "D. Passaro",
                    "A. Pastore",
                    "M. Patel",
                    "J. Patoc",
                    "C. Patrignani",
                    "C. J. Pawley",
                    "A. Pellegrino",
                    "M. Pepe Altarelli",
                    "S. Perazzini",
                    "D. Pereima",
                    "A. Pereiro Castro",
                    "P. Perret",
                    "A. Perro",
                    "K. Petridis",
                    "A. Petrolini",
                    "S. Petrucci",
                    "H. Pham",
                    "L. Pica",
                    "M. Piccini",
                    "B. Pietrzyk",
                    "G. Pietrzyk",
                    "D. Pinci",
                    "F. Pisani",
                    "M. Pizzichemi",
                    "V. Placinta",
                    "M. Plo Casasus",
                    "F. Polci",
                    "M. Poli Lener",
                    "A. Poluektov",
                    "N. Polukhina",
                    "I. Polyakov",
                    "E. Polycarpo",
                    "S. Ponce",
                    "D. Popov",
                    "S. Poslavskii",
                    "K. Prasanth",
                    "L. Promberger",
                    "C. Prouve",
                    "V. Pugatch",
                    "V. Puill",
                    "G. Punzi",
                    "H. R. Qi",
                    "W. Qian",
                    "N. Qin",
                    "S. Qu",
                    "R. Quagliani",
                    "B. Rachwal",
                    "J. H. Rademacker",
                    "M. Rama",
                    "M. Ram\u00edrez Garc\u00eda",
                    "M. Ramos Pernas",
                    "M. S. Rangel",
                    "F. Ratnikov",
                    "G. Raven",
                    "M. Rebollo De Miguel",
                    "F. Redi",
                    "J. Reich",
                    "F. Reiss",
                    "Z. Ren",
                    "P. K. Resmi",
                    "R. Ribatti",
                    "G. R. Ricart",
                    "D. Riccardi",
                    "S. Ricciardi",
                    "K. Richardson",
                    "M. Richardson-Slipper",
                    "K. Rinnert",
                    "P. Robbe",
                    "G. Robertson",
                    "E. Rodrigues",
                    "E. Rodriguez Fernandez",
                    "J. A. Rodriguez Lopez",
                    "E. Rodriguez Rodriguez",
                    "A. Rogovskiy",
                    "D. L. Rolf",
                    "A. Rollings",
                    "P. Roloff",
                    "V. Romanovskiy",
                    "M. Romero Lamas",
                    "A. Romero Vidal",
                    "G. Romolini",
                    "F. Ronchetti",
                    "M. Rotondo",
                    "S. R. Roy",
                    "M. S. Rudolph",
                    "T. Ruf",
                    "M. Ruiz Diaz",
                    "R. A. Ruiz Fernandez",
                    "J. Ruiz Vidal",
                    "A. Ryzhikov",
                    "J. Ryzka",
                    "J. J. Saborido Silva",
                    "R. Sadek",
                    "N. Sagidova",
                    "N. Sahoo",
                    "B. Saitta",
                    "M. Salomoni",
                    "C. Sanchez Gras",
                    "I. Sanderswood",
                    "R. Santacesaria",
                    "C. Santamarina Rios",
                    "M. Santimaria",
                    "L. Santoro",
                    "E. Santovetti",
                    "A. Saputi",
                    "D. Saranin",
                    "G. Sarpis",
                    "M. Sarpis",
                    "A. Sarti",
                    "C. Satriano",
                    "A. Satta",
                    "M. Saur",
                    "D. Savrina",
                    "H. Sazak",
                    "L. G. Scantlebury Smead",
                    "A. Scarabotto",
                    "S. Schael",
                    "S. Scherl",
                    "A. M. Schertz",
                    "M. Schiller",
                    "H. Schindler",
                    "M. Schmelling",
                    "B. Schmidt",
                    "S. Schmitt",
                    "H. Schmitz",
                    "O. Schneider",
                    "A. Schopper",
                    "N. Schulte",
                    "S. Schulte",
                    "M. H. Schune",
                    "R. Schwemmer",
                    "G. Schwering",
                    "B. Sciascia",
                    "A. Sciuccati",
                    "S. Sellam",
                    "A. Semennikov",
                    "M. Senghi Soares",
                    "A. Sergi",
                    "N. Serra",
                    "L. Sestini",
                    "A. Seuthe",
                    "Y. Shang",
                    "D. M. Shangase",
                    "M. Shapkin",
                    "I. Shchemerov",
                    "L. Shchutska",
                    "T. Shears",
                    "L. Shekhtman",
                    "Z. Shen",
                    "S. Sheng",
                    "V. Shevchenko",
                    "B. Shi",
                    "E. B. Shields",
                    "Y. Shimizu",
                    "E. Shmanin",
                    "R. Shorkin",
                    "J. D. Shupperd",
                    "R. Silva Coutinho",
                    "G. Simi",
                    "S. Simone",
                    "N. Skidmore",
                    "R. Skuza",
                    "T. Skwarnicki",
                    "M. W. Slater",
                    "J. C. Smallwood",
                    "E. Smith",
                    "K. Smith",
                    "M. Smith",
                    "A. Snoch",
                    "L. Soares Lavra",
                    "M. D. Sokoloff",
                    "F. J. P. Soler",
                    "A. Solomin",
                    "A. Solovev",
                    "I. Solovyev",
                    "R. Song",
                    "Y. Song",
                    "Y. Song",
                    "Y. S. Song",
                    "F. L. Souza De Almeida",
                    "B. Souza De Paula",
                    "E. Spadaro Norella",
                    "E. Spedicato",
                    "J. G. Speer",
                    "E. Spiridenkov",
                    "P. Spradlin",
                    "V. Sriskaran",
                    "F. Stagni",
                    "M. Stahl",
                    "S. Stahl",
                    "S. Stanislaus",
                    "E. N. Stein",
                    "O. Steinkamp",
                    "O. Stenyakin",
                    "H. Stevens",
                    "D. Strekalina",
                    "Y. Su",
                    "F. Suljik",
                    "J. Sun",
                    "L. Sun",
                    "Y. Sun",
                    "P. N. Swallow",
                    "K. Swientek",
                    "F. Swystun",
                    "A. Szabelski",
                    "T. Szumlak",
                    "M. Szymanski",
                    "Y. Tan",
                    "S. Taneja",
                    "M. D. Tat",
                    "A. Terentev",
                    "F. Terzuoli",
                    "F. Teubert",
                    "E. Thomas",
                    "D. J. D. Thompson",
                    "H. Tilquin",
                    "V. Tisserand",
                    "S. T'Jampens",
                    "M. Tobin",
                    "L. Tomassetti",
                    "G. Tonani",
                    "X. Tong",
                    "D. Torres Machado",
                    "L. Toscano",
                    "D. Y. Tou",
                    "C. Trippl",
                    "G. Tuci",
                    "N. Tuning",
                    "L. H. Uecker",
                    "A. Ukleja",
                    "D. J. Unverzagt",
                    "E. Ursov",
                    "A. Usachov",
                    "A. Ustyuzhanin",
                    "U. Uwer",
                    "V. Vagnoni",
                    "A. Valassi",
                    "G. Valenti",
                    "N. Valls Canudas",
                    "H. Van Hecke",
                    "E. van Herwijnen",
                    "C. B. Van Hulse",
                    "R. Van Laak",
                    "M. van Veghel",
                    "R. Vazquez Gomez",
                    "P. Vazquez Regueiro",
                    "C. V\u00e1zquez Sierra",
                    "S. Vecchi",
                    "J. J. Velthuis",
                    "M. Veltri",
                    "A. Venkateswaran",
                    "M. Vesterinen",
                    "D. Vieira",
                    "M. Vieites Diaz",
                    "X. Vilasis-Cardona",
                    "E. Vilella Figueras",
                    "A. Villa",
                    "P. Vincent",
                    "F. C. Volle",
                    "D. vom Bruch",
                    "V. Vorobyev",
                    "N. Voropaev",
                    "K. Vos",
                    "C. Vrahas",
                    "J. Walsh",
                    "E. J. Walton",
                    "G. Wan",
                    "C. Wang",
                    "G. Wang",
                    "J. Wang",
                    "J. Wang",
                    "J. Wang",
                    "J. Wang",
                    "M. Wang",
                    "N. W. Wang",
                    "R. Wang",
                    "X. Wang",
                    "X. W. Wang",
                    "Y. Wang",
                    "Z. Wang",
                    "Z. Wang",
                    "Z. Wang",
                    "J. A. Ward",
                    "N. K. Watson",
                    "D. Websdale",
                    "Y. Wei",
                    "B. D. C. Westhenry",
                    "D. J. White",
                    "M. Whitehead",
                    "A. R. Wiederhold",
                    "D. Wiedner",
                    "G. Wilkinson",
                    "M. K. Wilkinson",
                    "M. Williams",
                    "M. R. J. Williams",
                    "R. Williams",
                    "F. F. Wilson",
                    "W. Wislicki",
                    "M. Witek",
                    "L. Witola",
                    "C. P. Wong",
                    "G. Wormser",
                    "S. A. Wotton",
                    "H. Wu",
                    "J. Wu",
                    "Y. Wu",
                    "K. Wyllie",
                    "S. Xian",
                    "Z. Xiang",
                    "Y. Xie",
                    "A. Xu",
                    "J. Xu",
                    "L. Xu",
                    "L. Xu",
                    "M. Xu",
                    "Z. Xu",
                    "Z. Xu",
                    "Z. Xu",
                    "D. Yang",
                    "S. Yang",
                    "X. Yang",
                    "Y. Yang",
                    "Z. Yang",
                    "Z. Yang",
                    "V. Yeroshenko",
                    "H. Yeung",
                    "H. Yin",
                    "C. Y. Yu",
                    "J. Yu",
                    "X. Yuan",
                    "E. Zaffaroni",
                    "M. Zavertyaev",
                    "M. Zdybal",
                    "M. Zeng",
                    "C. Zhang",
                    "D. Zhang",
                    "J. Zhang",
                    "L. Zhang",
                    "S. Zhang",
                    "S. Zhang",
                    "Y. Zhang",
                    "Y. Zhang",
                    "Y. Z. Zhang",
                    "Y. Zhao",
                    "A. Zharkova",
                    "A. Zhelezov",
                    "X. Z. Zheng",
                    "Y. Zheng",
                    "T. Zhou",
                    "X. Zhou",
                    "Y. Zhou",
                    "V. Zhovkovska",
                    "L. Z. Zhu",
                    "X. Zhu",
                    "X. Zhu",
                    "Z. Zhu",
                    "V. Zhukov",
                    "J. Zhuo",
                    "Q. Zou",
                    "D. Zuliani",
                    "G. Zunica"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14085v1",
                    "http://arxiv.org/pdf/2311.14085v1"
                ],
                "primary_category": "hep-ex",
                "categories": [
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14760v1/1.0",
                "title": "SinSR: Diffusion-Based Image Super-Resolution in a Single Step",
                "year": 2023,
                "abstract": "While super-resolution (SR) methods based on diffusion models exhibit\npromising results, their practical application is hindered by the substantial\nnumber of required inference steps. Recent methods utilize degraded images in\nthe initial state, thereby shortening the Markov chain. Nevertheless, these\nsolutions either rely on a precise formulation of the degradation process or\nstill necessitate a relatively lengthy generation path (e.g., 15 iterations).\nTo enhance inference speed, we propose a simple yet effective method for\nachieving single-step SR generation, named SinSR. Specifically, we first derive\na deterministic sampling process from the most recent state-of-the-art (SOTA)\nmethod for accelerating diffusion-based SR. This allows the mapping between the\ninput random noise and the generated high-resolution image to be obtained in a\nreduced and acceptable number of inference steps during training. We show that\nthis deterministic mapping can be distilled into a student model that performs\nSR within only one inference step. Additionally, we propose a novel\nconsistency-preserving loss to simultaneously leverage the ground-truth image\nduring the distillation process, ensuring that the performance of the student\nmodel is not solely bound by the feature manifold of the teacher model,\nresulting in further performance improvement. Extensive experiments conducted\non synthetic and real-world datasets demonstrate that the proposed method can\nachieve comparable or even superior performance compared to both previous SOTA\nmethods and the teacher model, in just one sampling step, resulting in a\nremarkable up to x10 speedup for inference. Our code will be released at\nhttps://github.com/wyf0912/SinSR",
                "authors": [
                    "Yufei Wang",
                    "Wenhan Yang",
                    "Xinyuan Chen",
                    "Yaohui Wang",
                    "Lanqing Guo",
                    "Lap-Pui Chau",
                    "Ziwei Liu",
                    "Yu Qiao",
                    "Alex C. Kot",
                    "Bihan Wen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14760v1",
                    "http://arxiv.org/pdf/2311.14760v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14759v1/1.0",
                "title": "Forecasting Cryptocurrency Prices Using Deep Learning: Integrating\n  Financial, Blockchain, and Text Data",
                "year": 2023,
                "abstract": "This paper explores the application of Machine Learning (ML) and Natural\nLanguage Processing (NLP) techniques in cryptocurrency price forecasting,\nspecifically Bitcoin (BTC) and Ethereum (ETH). Focusing on news and social\nmedia data, primarily from Twitter and Reddit, we analyse the influence of\npublic sentiment on cryptocurrency valuations using advanced deep learning NLP\nmethods. Alongside conventional price regression, we treat cryptocurrency price\nforecasting as a classification problem. This includes both the prediction of\nprice movements (up or down) and the identification of local extrema. We\ncompare the performance of various ML models, both with and without NLP data\nintegration. Our findings reveal that incorporating NLP data significantly\nenhances the forecasting performance of our models. We discover that\npre-trained models, such as Twitter-RoBERTa and BART MNLI, are highly effective\nin capturing market sentiment, and that fine-tuning Large Language Models\n(LLMs) also yields substantial forecasting improvements. Notably, the BART MNLI\nzero-shot classification model shows considerable proficiency in extracting\nbullish and bearish signals from textual data. All of our models consistently\ngenerate profit across different validation scenarios, with no observed decline\nin profits or reduction in the impact of NLP data over time. The study\nhighlights the potential of text analysis in improving financial forecasts and\ndemonstrates the effectiveness of various NLP techniques in capturing nuanced\nmarket sentiment.",
                "authors": [
                    "Vincent Gurgul",
                    "Stefan Lessmann",
                    "Wolfgang Karl H\u00e4rdle"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14759v1",
                    "http://arxiv.org/pdf/2311.14759v1"
                ],
                "primary_category": "q-fin.ST",
                "categories": [
                    "q-fin.ST",
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14077v1/1.0",
                "title": "RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation",
                "year": 2023,
                "abstract": "Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to\naid chemists in finding appropriate reactant molecules and synthetic pathways\ngiven determined product molecules. With the reactant and product represented\nas 2D graphs, retrosynthesis constitutes a conditional graph-to-graph\ngenerative task. Inspired by the recent advancements in discrete diffusion\nmodels for graph generation, we introduce Retrosynthesis Diffusion (RetroDiff),\na novel diffusion-based method designed to address this problem. However,\nintegrating a diffusion-based graph-to-graph framework while retaining\nessential chemical reaction template information presents a notable challenge.\nOur key innovation is to develop a multi-stage diffusion process. In this\nmethod, we decompose the retrosynthesis procedure to first sample external\ngroups from the dummy distribution given products and then generate the\nexternal bonds to connect the products and generated groups. Interestingly,\nsuch a generation process is exactly the reverse of the widely adapted\nsemi-template retrosynthesis procedure, i.e. from reaction center\nidentification to synthon completion, which significantly reduces the error\naccumulation. Experimental results on the benchmark have demonstrated the\nsuperiority of our method over all other semi-template methods.",
                "authors": [
                    "Yiming Wang",
                    "Yuxuan Song",
                    "Minkai Xu",
                    "Rui Wang",
                    "Hao Zhou",
                    "Weiying Ma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14077v1",
                    "http://arxiv.org/pdf/2311.14077v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14076v1/1.0",
                "title": "Searching for Snippets of Open-Domain Dialogue in Task-Oriented Dialogue\n  Datasets",
                "year": 2023,
                "abstract": "Most existing dialogue corpora and models have been designed to fit into 2\npredominant categories : task-oriented dialogues portray functional goals, such\nas making a restaurant reservation or booking a plane ticket, while\nchit-chat/open-domain dialogues focus on holding a socially engaging talk with\na user. However, humans tend to seamlessly switch between modes and even use\nchitchat to enhance task-oriented conversations. To bridge this gap, new\ndatasets have recently been created, blending both communication modes into\nconversation examples. The approaches used tend to rely on adding chit-chat\nsnippets to pre-existing, human-generated task-oriented datasets. Given the\ntendencies observed in humans, we wonder however if the latter do not\n\\textit{already} hold chit-chat sequences. By using topic modeling and\nsearching for topics which are most similar to a set of keywords related to\nsocial talk, we explore the training sets of Schema-Guided Dialogues and\nMultiWOZ. Our study shows that sequences related to social talk are indeed\nnaturally present, motivating further research on ways chitchat is combined\ninto task-oriented dialogues.",
                "authors": [
                    "Armand Stricker",
                    "Patrick Paroubek"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14076v1",
                    "http://arxiv.org/pdf/2311.14076v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14068v2/1.0",
                "title": "Interactive Dual-Conformer with Scene-Inspired Mask for Soft Sound Event\n  Detection",
                "year": 2023,
                "abstract": "Traditional binary hard labels for sound event detection (SED) lack details\nabout the complexity and variability of sound event distributions. Recently, a\nnovel annotation workflow is proposed to generate fine-grained non-binary soft\nlabels, resulting in a new real-life dataset named MAESTRO Real for SED. In\nthis paper, we first propose an interactive dual-conformer (IDC) module, in\nwhich a cross-interaction mechanism is applied to effectively exploit the\ninformation from soft labels. In addition, a novel scene-inspired mask (SIM)\nbased on soft labels is incorporated for more precise SED predictions. The SIM\nis initially generated through a statistical approach, referred as SIM-V1.\nHowever, the fixed artificial mask may mismatch the SED model, resulting in\nlimited effectiveness. Therefore, we further propose SIM-V2, which employs a\nword embedding model for adaptive SIM estimation. Experimental results show\nthat the proposed IDC module can effectively utilize the information from soft\nlabels, and the integration of SIM-V1 can further improve the accuracy. In\naddition, the impact of different word embedding dimensions on SIM-V2 is\nexplored, and the results show that the appropriate dimension can enable SIM-V2\nachieve superior performance than SIM-V1. In DCASE 2023 Challenge Task4B, the\nproposed system achieved the top ranking performance on the evaluation dataset\nof MAESTRO Real.",
                "authors": [
                    "Han Yin",
                    "Jisheng Bai",
                    "Mou Wang",
                    "Dongyuan Shi",
                    "Woon-Seng Gan",
                    "Jianfeng Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14068v2",
                    "http://arxiv.org/pdf/2311.14068v2"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14067v1/1.0",
                "title": "Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study\n  Based on Lexical Diversity and Divergence",
                "year": 2023,
                "abstract": "As a recent development, task-oriented dialogues (TODs) have been enriched\nwith chitchat in an effort to make dialogues more diverse and engaging. This\nenhancement is particularly valuable as TODs are often confined to narrow\ndomains, making the mitigation of repetitive and predictable responses a\nsignificant challenge. This paper presents a comparative analysis of three\nchitchat enhancements, aiming to identify the most effective approach in terms\nof diversity. Additionally, we quantify the divergence between the added\nchitchat, the original task-oriented language, and chitchat typically found in\nchitchat datasets, highlighting the top 20 divergent keywords for each\ncomparison. Our findings drive a discussion on future enhancements for\naugmenting TODs, emphasizing the importance of grounding dialogues beyond the\ntask to achieve more diverse and natural exchanges.",
                "authors": [
                    "Armand Stricker",
                    "Patrick Paroubek"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14067v1",
                    "http://arxiv.org/pdf/2311.14067v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14065v1/1.0",
                "title": "3D Printed Discrete Dielectric Lens With Improved Matching Layers",
                "year": 2023,
                "abstract": "This paper presents a non-zoned discrete dielectric lens comprising two or\nthree matching layers to reduce the 50-110 GHz frequency range reflections.\nBased on Chebyshev and binomial multi-section transformers, the designed models\nuse matching layers at the top and bottom. In addition, the presented designs\nuse pins instead of the conventional slots for the matching layers, thus easing\nthe manufacturing process. The results show that the broadband realized gain\nobtained using the proposed design is higher for both the two- and three-layer\ndesign than the commonly used quarter-wave transformer. A Binomial lens with\ntwo matchings layers using 38 unit cells is fabricated and illuminated by an\nopen-ended waveguide to validate the simulation results obtained using CST\nMicrowave Studio. The fabrication process uses stereolithography additive\nmanufacturing.",
                "authors": [
                    "Juan Andr\u00e9s V\u00e1squez-Peralvo",
                    "Jos\u00e9 Manuel Fern\u00e1ndez-Gonz\u00e1lez",
                    "Thomas Wong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14065v1",
                    "http://arxiv.org/pdf/2311.14065v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14064v1/1.0",
                "title": "HGCLIP: Exploring Vision-Language Models with Graph Representations for\n  Hierarchical Understanding",
                "year": 2023,
                "abstract": "Object categories are typically organized into a multi-granularity taxonomic\nhierarchy. When classifying categories at different hierarchy levels,\ntraditional uni-modal approaches focus primarily on image features, revealing\nlimitations in complex scenarios. Recent studies integrating Vision-Language\nModels (VLMs) with class hierarchies have shown promise, yet they fall short of\nfully exploiting the hierarchical relationships. These efforts are constrained\nby their inability to perform effectively across varied granularity of\ncategories. To tackle this issue, we propose a novel framework (HGCLIP) that\neffectively combines CLIP with a deeper exploitation of the Hierarchical class\nstructure via Graph representation learning. We explore constructing the class\nhierarchy into a graph, with its nodes representing the textual or image\nfeatures of each category. After passing through a graph encoder, the textual\nfeatures incorporate hierarchical structure information, while the image\nfeatures emphasize class-aware features derived from prototypes through the\nattention mechanism. Our approach demonstrates significant improvements on both\ngeneric and fine-grained visual recognition benchmarks. Our codes are fully\navailable at https://github.com/richard-peng-xia/HGCLIP.",
                "authors": [
                    "Peng Xia",
                    "Xingtong Yu",
                    "Ming Hu",
                    "Lie Ju",
                    "Zhiyong Wang",
                    "Peibo Duan",
                    "Zongyuan Ge"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14064v1",
                    "http://arxiv.org/pdf/2311.14064v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14063v1/1.0",
                "title": "Do VSR Models Generalize Beyond LRS3?",
                "year": 2023,
                "abstract": "The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of\nintense research in visual speech recognition (VSR) during the last few years.\nAs a result, there is an increased risk of overfitting to its excessively used\ntest set, which is only one hour duration. To alleviate this issue, we build a\nnew VSR test set named WildVSR, by closely following the LRS3 dataset creation\nprocesses. We then evaluate and analyse the extent to which the current VSR\nmodels generalize to the new test data. We evaluate a broad range of publicly\navailable VSR models and find significant drops in performance on our test set,\ncompared to their corresponding LRS3 results. Our results suggest that the\nincrease in word error rates is caused by the models inability to generalize to\nslightly harder and in the wild lip sequences than those found in the LRS3 test\nset. Our new test benchmark is made public in order to enable future research\ntowards more robust VSR models.",
                "authors": [
                    "Yasser Abdelaziz Dahou Djilali",
                    "Sanath Narayan",
                    "Eustache Le Bihan",
                    "Haithem Boussaid",
                    "Ebtessam Almazrouei",
                    "Merouane Debbah"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14063v1",
                    "http://arxiv.org/pdf/2311.14063v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14061v1/1.0",
                "title": "Towards Explainable Strategy Templates using NLP Transformers",
                "year": 2023,
                "abstract": "This paper bridges the gap between mathematical heuristic strategies learned\nfrom Deep Reinforcement Learning (DRL) in automated agent negotiation, and\ncomprehensible, natural language explanations. Our aim is to make these\nstrategies more accessible to non-experts. By leveraging traditional Natural\nLanguage Processing (NLP) techniques and Large Language Models (LLMs) equipped\nwith Transformers, we outline how parts of DRL strategies composed of parts\nwithin strategy templates can be transformed into user-friendly, human-like\nEnglish narratives. To achieve this, we present a top-level algorithm that\ninvolves parsing mathematical expressions of strategy templates, semantically\ninterpreting variables and structures, generating rule-based primary\nexplanations, and utilizing a Generative Pre-trained Transformer (GPT) model to\nrefine and contextualize these explanations. Subsequent customization for\nvaried audiences and meticulous validation processes in an example illustrate\nthe applicability and potential of this approach.",
                "authors": [
                    "Pallavi Bagga",
                    "Kostas Stathis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14061v1",
                    "http://arxiv.org/pdf/2311.14061v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14049v3/1.0",
                "title": "Assessment of Deep Learning Segmentation for Real-Time Free-Breathing\n  Cardiac Magnetic Resonance Imaging",
                "year": 2023,
                "abstract": "In recent years, a variety of deep learning networks for cardiac MRI (CMR)\nsegmentation have been developed and analyzed. However, nearly all of them are\nfocused on cine CMR under breathold. In this work, accuracy of deep learning\nmethods is assessed for volumetric analysis (via segmentation) of the left\nventricle in real-time free-breathing CMR at rest and under exercise stress.\nData from healthy volunteers (n=15) for cine and real-time free-breathing CMR\nwere analyzed retrospectively. Segmentations of a commercial software (comDL)\nand a freely available neural network (nnU-Net), were compared to a reference\ncreated via the manual correction of comDL segmentation. Segmentation of left\nventricular endocardium (LV), left ventricular myocardium (MYO), and right\nventricle (RV) is evaluated for both end-systolic and end-diastolic phases and\nanalyzed with Dice's coefficient (DC). The volumetric analysis includes LV\nend-diastolic volume (EDV), LV end-systolic volume (ESV), and LV ejection\nfraction (EF). For cine CMR, nnU-Net and comDL achieve a DC above 0.95 for LV\nand 0.9 for MYO, and RV. For real-time CMR, the accuracy of nnU-Net exceeds\nthat of comDL overall. For real-time CMR at rest, nnU-Net achieves a DC of 0.94\nfor LV, 0.89 for MYO, and 0.90 for RV; mean absolute differences between\nnnU-Net and reference are 2.9mL for EDV, 3.5mL for ESV and 2.6% for EF. For\nreal-time CMR under exercise stress, nnU-Net achieves a DC of 0.92 for LV, 0.85\nfor MYO, and 0.83 for RV; mean absolute differences between nnU-Net and\nreference are 11.4mL for EDV, 2.9mL for ESV and 3.6% for EF. Deep learning\nmethods designed or trained for cine CMR segmentation can perform well on\nreal-time CMR. For real-time free-breathing CMR at rest, the performance of\ndeep learning methods is comparable to inter-observer variability in cine CMR\nand is usable or fully automatic segmentation.",
                "authors": [
                    "Martin Schilling",
                    "Christina Unterberg-Buchwald",
                    "Joachim Lotz",
                    "Martin Uecker"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14049v3",
                    "http://arxiv.org/pdf/2311.14049v3"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14043v1/1.0",
                "title": "On the continuity of the projection mapping from strategic measures to\n  occupation measures in absorbing Markov decision processes",
                "year": 2023,
                "abstract": "In this paper, we prove the following assertion for an absorbing Markov\ndecision process (MDP) with the given initial distribution, which is also\nassumed to be semi-continuous: the continuity of the projection mapping from\nthe space of strategic measures to the space of occupation measures, both\nendowed with their weak topologies, is equivalent to the MDP model being\nuniformly absorbing. An example demonstrates, among other interesting\nscenarios, that for an absorbing (but not uniformly absorbing) semi-continuous\nMDP with the given initial distribution, the space of occupation measures can\nfail to be compact in the weak topology.",
                "authors": [
                    "Alexey Piunovskiy",
                    "Yi Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14043v1",
                    "http://arxiv.org/pdf/2311.14043v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14030v1/1.0",
                "title": "PrivateLoRA For Efficient Privacy Preserving LLM",
                "year": 2023,
                "abstract": "End users face a choice between privacy and efficiency in current Large\nLanguage Model (LLM) service paradigms. In cloud-based paradigms, users are\nforced to compromise data locality for generation quality and processing speed.\nConversely, edge device paradigms maintain data locality but fail to deliver\nsatisfactory performance. In this work, we propose a novel LLM service paradigm\nthat distributes privacy-sensitive computation on edge devices and shared\ncomputation in the cloud. Only activations are transmitted between the central\ncloud and edge devices to ensure data locality. Our core innovation,\nPrivateLoRA, addresses the challenging communication overhead by exploiting the\nlow rank of residual activations, achieving over 95% communication reduction.\nConsequently, PrivateLoRA effectively maintains data locality and is extremely\nresource efficient. Under standard 5G networks, PrivateLoRA achieves throughput\nover 300% of device-only solutions for 7B models and over 80% of an A100 GPU\nfor 33B models. PrivateLoRA also provides tuning performance comparable to LoRA\nfor advanced personalization. Our approach democratizes access to\nstate-of-the-art generative AI for edge devices, paving the way for more\ntailored LLM experiences for the general public. To our knowledge, our proposed\nframework is the first efficient and privacy-preserving LLM solution in the\nliterature.",
                "authors": [
                    "Yiming Wang",
                    "Yu Lin",
                    "Xiaodong Zeng",
                    "Guannan Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14030v1",
                    "http://arxiv.org/pdf/2311.14030v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14029v1/1.0",
                "title": "Understanding the Vulnerability of CLIP to Image Compression",
                "year": 2023,
                "abstract": "CLIP is a widely used foundational vision-language model that is used for\nzero-shot image recognition and other image-text alignment tasks. We\ndemonstrate that CLIP is vulnerable to change in image quality under\ncompression. This surprising result is further analysed using an attribution\nmethod-Integrated Gradients. Using this attribution method, we are able to\nbetter understand both quantitatively and qualitatively exactly the nature in\nwhich the compression affects the zero-shot recognition accuracy of this model.\nWe evaluate this extensively on CIFAR-10 and STL-10. Our work provides the\nbasis to understand this vulnerability of CLIP and can help us develop more\neffective methods to improve the robustness of CLIP and other vision-language\nmodels.",
                "authors": [
                    "Cangxiong Chen",
                    "Vinay P. Namboodiri",
                    "Julian Padget"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14029v1",
                    "http://arxiv.org/pdf/2311.14029v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14028v1/1.0",
                "title": "Continual Learning of Diffusion Models with Generative Distillation",
                "year": 2023,
                "abstract": "Diffusion models are powerful generative models that achieve state-of-the-art\nperformance in tasks such as image synthesis. However, training them demands\nsubstantial amounts of data and computational resources. Continual learning\nwould allow for incrementally learning new tasks and accumulating knowledge,\nthus reusing already trained models would be possible. One potentially suitable\napproach is generative replay, where a copy of a generative model trained on\nprevious tasks produces synthetic data that are interleaved with data from the\ncurrent task. However, standard generative replay applied to diffusion models\nresults in a catastrophic loss in denoising capabilities. In this paper, we\npropose generative distillation, an approach that distils the entire reverse\nprocess of a diffusion model. We demonstrate that our approach significantly\nimproves the continual learning performance of generative replay with only a\nmoderate increase in the computational costs.",
                "authors": [
                    "Sergi Masip",
                    "Pau Rodriguez",
                    "Tinne Tuytelaars",
                    "Gido M. van de Ven"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14028v1",
                    "http://arxiv.org/pdf/2311.14028v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14025v2/1.0",
                "title": "Incompleteness of boundedly axiomatizable theories",
                "year": 2023,
                "abstract": "Our main result (Theorem A) shows the incompleteness of any consistent\nsequential theory T formulated in a finite language such that T is axiomatized\nby a collection of sentences of bounded quantifier-alternation-depth. Our proof\nemploys an appropriate reduction mechanism to rule out the possibility of\ncompleteness by simply invoking Tarski's Undefinability of Truth theorem. We\nalso use the proof strategy of Theorem A to obtain other incompleteness results\n(as in Theorems A+; B and B+).",
                "authors": [
                    "Ali Enayat",
                    "Albert Visser"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14025v2",
                    "http://arxiv.org/pdf/2311.14025v2"
                ],
                "primary_category": "math.LO",
                "categories": [
                    "math.LO",
                    "03F40"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14022v1/1.0",
                "title": "Invariable generation of certain branch groups",
                "year": 2023,
                "abstract": "We investigate invariable generation among key examples of branch groups. In\nparticular, we prove that all generating sets of the torsion Grigorchuk groups,\nof the branch Grigorchuk-Gupta-Sidki groups and of the torsion multi-EGS groups\n(which are natural generalisations of the Grigorchuk-Gupta-Sidki groups) are\ninvariable generating sets. Furthermore, for the first Grigorchuk group and the\ntorsion Grigorchuk-Gupta-Sidki groups, every finitely generated subgroup has a\nfinite invariable generating set. We also show that a branch\nGrigorchuk-Gupta-Sidki group is almost $\\frac32$-generated, that the diameter\nof its generating subgraph $\\Delta(G)$ is 2 and its total domination number is\n2. Some of our results apply to groups for which every maximal subgroup is\nnormal. This class, known as $\\mathcal{MN}$, includes all nilpotent groups.",
                "authors": [
                    "Charles Garnet Cox",
                    "Anitha Thillaisundaram"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14022v1",
                    "http://arxiv.org/pdf/2311.14022v1"
                ],
                "primary_category": "math.GR",
                "categories": [
                    "math.GR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14018v1/1.0",
                "title": "Fabrication and extreme micromechanics of additive metal\n  microarchitectures",
                "year": 2023,
                "abstract": "Metal microarchitectures with 3-dimensional solid frames can exhibit\nmechanical performance coming from the geometrical effect and characteristic\nsize effect of material under dynamic and extreme temperature conditions. In\nthis study, for the first time, full-metal Cu microlattices were fabricated via\nlocalized electrodeposition in liquid (LEL) process which enables\nhigh-precision additive manufacturing of metal at micro-scale. The\nmicrolattices possess a unique microstructure with micron sized grains that are\nrich with randomly oriented growth twins. They also have smooth surfaces and\nnear-ideal nodal connectivity. Furthermore, Cu microlattices exhibited unique\ntemperature (-150 and 25 Celcius degrees) and strain rate (0.001-100 s-1)\ndependent deformation behavior during in situ micromechanical testing.\nSystematic compression test of fully dense Cu micropillars, equivalent in\ndiameter and length to the strut of microlattice at comparable extreme loading\nconditions, and post-mortem microstructural analysis revealed substantial\nshifts in deformation mechanisms depending on the temperature and strain rate.\nOn one hand, at room temperature (25 Celcius degree), dislocation slip based\nplastic deformation occurs and leads to localized deformation of micropillars.\nOn the other hand, at cryogenic temperature (-150 Celcius degree), mechanical\ntwinning occurs and leads to relatively homogeneous deformation of\nmicropillars. Based on the intrinsic deformation mechanisms at the component\nlevel, the temperature and strain rate dependent deformation behavior of\nmicrolattices is explained. Our findings provide valuable insights into the\nintricate mechanical responses and potential applications of metallic\nmicroarchitectures under dynamic and extreme temperature conditions.",
                "authors": [
                    "Sung-Gyu Kang",
                    "Barbara Bellon",
                    "Lalithkumar Bhaskar",
                    "Siyuan Zhang",
                    "Alexander Gotz",
                    "Janis Wirth",
                    "Benjamin Apeleo Zubiri",
                    "Szilvia Kalacska",
                    "Manish Jain",
                    "Amit Sharma",
                    "Wabe Koelmans",
                    "Giorgio Ercolano",
                    "Erdmann Spiecker",
                    "Johann Michler",
                    "Jakob Schwiedrzik",
                    "Gerhard Dehm",
                    "Rajaprakash Ramachandramoorthy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14018v1",
                    "http://arxiv.org/pdf/2311.14018v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14014v1/1.0",
                "title": "On the Hyperparameter Landscapes of Machine Learning Algorithms",
                "year": 2023,
                "abstract": "Despite the recent success in a plethora of hyperparameter optimization (HPO)\nmethods for machine learning (ML) models, the intricate interplay between model\nhyperparameters (HPs) and predictive losses (a.k.a fitness), which is a key\nprerequisite for understanding HPO, remain notably underexplored in our\ncommunity. This results in limited explainability in the HPO process, rendering\na lack of human trust and difficulties in pinpointing algorithm bottlenecks. In\nthis paper, we aim to shed light on this black box by conducting large-scale\nfitness landscape analysis (FLA) on 1,500 HP loss landscapes of 6 ML models\nwith more than 11 model configurations, across 67 datasets and different levels\nof fidelities. We reveal the first unified, comprehensive portrait of their\ntopographies in terms of smoothness, neutrality and modality. We also show that\nsuch properties are highly transferable across datasets and fidelities,\nproviding fundamental evidence for the success of multi-fidelity and transfer\nlearning methods. These findings are made possible by developing a dedicated\nFLA framework that incorporates a combination of visual and quantitative\nmeasures. We further demonstrate the potential of this framework by analyzing\nthe NAS-Bench-101 landscape, and we believe it is able to faciliate fundamental\nunderstanding of a broader range of AutoML tasks.",
                "authors": [
                    "Mingyu Huang",
                    "Ke Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14014v1",
                    "http://arxiv.org/pdf/2311.14014v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14753v1/1.0",
                "title": "Fundamentos para a Constru\u00e7\u00e3o no GeoGebra de Tessela\u00e7\u00f5es\n  Aperi\u00f3dicas usando um \u00danico Pol\u00edgono",
                "year": 2023,
                "abstract": "In this work, we will explore some polygons that individually are capable of\nfilling the plane in an aperiodic way. These polygons were recently discovered\nby some researchers and constitute a great discovery for Mathematics. We will\npresent two ways of constructing these polygons, the first of which is based on\nthe juxtaposition of copies of a particular kite and the second consists of\nconstructing, with a ruler and compass, the polygonal line formed by the sides\nof each of these polygons. The constructions are made in GeoGebra with great\ndetail to allow reproduction.",
                "authors": [
                    "Astor Santos Neto",
                    "Sandra Maria Barbosa",
                    "Alcebiades Dal Col"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14753v1",
                    "http://arxiv.org/pdf/2311.14753v1"
                ],
                "primary_category": "math.GM",
                "categories": [
                    "math.GM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14013v1/1.0",
                "title": "Few-femtosecond electronic and structural rearrangements of CH$_4^+$\n  driven by the Jahn-Teller effect",
                "year": 2023,
                "abstract": "The Jahn-Teller effect (JTE) is central to the understanding of the physical\nand chemical properties of a broad variety of molecules and materials. Whereas\nthe manifestations of the JTE on stationary properties of matter are relatively\nwell studied, the study of JTE-induced dynamics is still in its infancy,\nlargely owing to its ultrafast and non-adiabatic nature. For example, the time\nscales reported for the distortion of CH$_4^+$ from the initial $T_{\\rm d}$\ngeometry to a nominal $C_{\\rm 2v}$ relaxed structure range from 1.85~fs over\n10$\\pm$2~fs to 20$\\pm$7~fs. Here, by combining element-specific attosecond\ntransient-absorption spectroscopy and quantum-dynamics simulations, we show\nthat the initial electronic relaxation occurs within 5~fs and that the\nsubsequent nuclear dynamics are dominated by the $Q_2$ scissoring and $Q_1$\nsymmetric stretching modes, which dephase in 41$\\pm$10~fs and 13$\\pm$3~fs,\nrespectively. Significant structural relaxation is found to take place only\nalong the e-symmetry $Q_2$ mode. These results demonstrate that CH$_4^+$\ncreated by ionization of CH$_4$ is best thought of as a highly fluxional\nspecies that possesses a long-time-averaged vibrational distribution centered\naround a $D_{\\rm 2d}$ structure. The methods demonstrated in our work provide\nguidelines for the understanding of Jahn-Teller driven non-adiabatic dynamics\nin other, more complex systems.",
                "authors": [
                    "Kristina S. Zinchenko",
                    "Fernando Ardana-Lamas",
                    "Valentina Utrio Lanfaloni",
                    "Nicholas Monahan",
                    "Issaka Seidu",
                    "Michael S. Schuurman",
                    "Simon P. Neville",
                    "Hans Jakob Woerner"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14013v1",
                    "http://arxiv.org/pdf/2311.14013v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14006v1/1.0",
                "title": "High-resolution Population Maps Derived from Sentinel-1 and Sentinel-2",
                "year": 2023,
                "abstract": "Detailed population maps play an important role in diverse fields ranging\nfrom humanitarian action to urban planning. Generating such maps in a timely\nand scalable manner presents a challenge, especially in data-scarce regions. To\naddress it we have developed POPCORN, a population mapping method whose only\ninputs are free, globally available satellite images from Sentinel-1 and\nSentinel-2; and a small number of aggregate population counts over coarse\ncensus districts for calibration. Despite the minimal data requirements our\napproach surpasses the mapping accuracy of existing schemes, including several\nthat rely on building footprints derived from high-resolution imagery. E.g., we\nwere able to produce population maps for Rwanda with 100m GSD based on less\nthan 400 regional census counts. In Kigali, those maps reach an $R^2$ score of\n66% w.r.t. a ground truth reference map, with an average error of only $\\pm$10\ninhabitants/ha. Conveniently, POPCORN retrieves explicit maps of built-up areas\nand of local building occupancy rates, making the mapping process interpretable\nand offering additional insights, for instance about the distribution of\nbuilt-up, but unpopulated areas, e.g., industrial warehouses. Moreover, we find\nthat, once trained, the model can be applied repeatedly to track population\nchanges; and that it can be transferred to geographically similar regions,\ne.g., from Uganda to Rwanda). With our work we aim to democratize access to\nup-to-date and high-resolution population maps, recognizing that some regions\nfaced with particularly strong population dynamics may lack the resources for\ncostly micro-census campaigns.",
                "authors": [
                    "Nando Metzger",
                    "Rodrigo Caye Daudt",
                    "Devis Tuia",
                    "Konrad Schindler"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14006v1",
                    "http://arxiv.org/pdf/2311.14006v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13999v1/1.0",
                "title": "A quantum Otto-type heat engine with fixed frequency",
                "year": 2023,
                "abstract": "In this work, we analyze an Otto-type cycle operating with a working\nsubstance composed of a quantum harmonic oscillator (QHO). Unlike other studies\nin which the work extraction is done by varying the frequency of the QHO and\nletting it thermalize with a squeezed reservoir, here we submit the QHO to a\nparametric pumping controlled by the squeezing parameter and let it thermalize\nwith a thermal reservoir. We then investigate the role of the squeezing\nparameter in our Otto-type engine powered by parametric pumping and show that\nit is possible to reach the Carnot limit by arbitrarily increasing the\nsqueezing parameter. Notably, for certain squeezing parameters $r$, e.g.\n$r=0.4$, the quasi-static Otto limit can be reached even at non-zero power. We\nalso investigated the role of entropy production in the efficiency behavior\nduring the unitary strokes, showing that positive (negative) changes in entropy\nproduction correspond to increases (decreases) in engine efficiency, as\nexpected. Furthermore, we show that under thermal reservoirs a work extraction\nprocess that is more efficient than the Carnot engine is impossible, regardless\nof the quantum resource introduced via the Hamiltonian of the system.",
                "authors": [
                    "Richard Q. Matos",
                    "Rogerio J. de Assis",
                    "Norton G. de Almeida"
                ],
                "url": [
                    "http://dx.doi.org/10.1103/PhysRevE.108.054131",
                    "http://arxiv.org/abs/2311.13999v1",
                    "http://arxiv.org/pdf/2311.13999v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13995v1/1.0",
                "title": "Explicit Refinement Types",
                "year": 2023,
                "abstract": "We present {\\lambda}ert, a type theory supporting refinement types with\nexplicit proofs. Instead of solving refinement constraints with an SMT solver\nlike DML and Liquid Haskell, our system requires and permits programmers to\nembed proofs of properties within the program text, letting us support a rich\nlogic of properties including quantifiers and induction. We show that the type\nsystem is sound by showing that every refined program erases to a simply-typed\nprogram, and by means of a denotational semantics, we show that every erased\nprogram has all of the properties demanded by its refined type. All of our\nproofs are formalised in Lean 4.",
                "authors": [
                    "Jad Elkhaleq Ghalayini",
                    "Neel Krishnaswami"
                ],
                "url": [
                    "http://dx.doi.org/10.1145/3607837",
                    "http://arxiv.org/abs/2311.13995v1",
                    "http://arxiv.org/pdf/2311.13995v1"
                ],
                "primary_category": "cs.PL",
                "categories": [
                    "cs.PL",
                    "D.3.1; D.3.4; F.3.2; F.3.1"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13993v1/1.0",
                "title": "EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity\n  Information Extraction from Document Images",
                "year": 2023,
                "abstract": "Information Extraction (IE) from document images is challenging due to the\nhigh variability of layout formats. Deep models such as LayoutLM and BROS have\nbeen proposed to address this problem and have shown promising results.\nHowever, they still require a large amount of field-level annotations for\ntraining these models. Other approaches using rule-based methods have also been\nproposed based on the understanding of the layout and semantics of a form such\nas geometric position, or type of the fields, etc. In this work, we propose a\nnovel approach, EIGEN (Expert-Informed Joint Learning aGgrEatioN), which\ncombines rule-based methods with deep learning models using data programming\napproaches to circumvent the requirement of annotation of large amounts of\ntraining data. Specifically, EIGEN consolidates weak labels induced from\nmultiple heuristics through generative models and use them along with a small\nnumber of annotated labels to jointly train a deep model. In our framework, we\npropose the use of labeling functions that include incorporating contextual\ninformation thus capturing the visual and language context of a word for\naccurate categorization. We empirically show that our EIGEN framework can\nsignificantly improve the performance of state-of-the-art deep models with the\navailability of very few labeled data instances. The source code is available\nat\nhttps://github.com/ayushayush591/EIGEN-High-Fidelity-Extraction-Document-Images.",
                "authors": [
                    "Abhishek Singh",
                    "Venkatapathy Subramanian",
                    "Ayush Maheshwari",
                    "Pradeep Narayan",
                    "Devi Prasad Shetty",
                    "Ganesh Ramakrishnan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13993v1",
                    "http://arxiv.org/pdf/2311.13993v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13991v1/1.0",
                "title": "Semi-organised structures and turbulence in the atmospheric convection",
                "year": 2023,
                "abstract": "The atmospheric convective boundary layer (CBL) consists in three basic\nparts: (i) the surface layer unstably stratified and dominated by small-scale\nturbulence of very complex nature; (ii) the CBL core dominated by the energy-,\nmomentum- and mass-transport of semi-organised structures (large-scale\ncirculations), with a small contribution from small-scale turbulence produced\nby local structural shears; (iii) turbulent entrainment layer at the upper\nboundary, characterised by essentially stable stratification with negative\n(downward) turbulent flux of potential temperature. The energy- and flux budget\n(EFB) theory developed previously for atmospheric stably-stratified turbulence\nand the surface layer in atmospheric convective turbulence is extended to the\nCBL core using budget equations for turbulent energies and turbulent fluxes of\nbuoyancy and momentum. For the CBL core, we determine global turbulent\ncharacteristics (averaged over the entire volume of the semi-organised\nstructure) as well as kinetic and thermal energies of the semi-organised\nstructures as the functions of the aspect ratio of the semi-organised structure\nand the scale separation parameter between the vertical size of the structures\nand the integral scale of turbulence. The obtained theoretical relationships\nare potentially useful in modelling applications in the atmospheric convective\nboundary-layer.",
                "authors": [
                    "I. Rogachevskii",
                    "N. Kleeorin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13991v1",
                    "http://arxiv.org/pdf/2311.13991v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "astro-ph.EP",
                    "physics.ao-ph",
                    "physics.geo-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13987v1/1.0",
                "title": "Jam-ALT: A Formatting-Aware Lyrics Transcription Benchmark",
                "year": 2023,
                "abstract": "Current automatic lyrics transcription (ALT) benchmarks focus exclusively on\nword content and ignore the finer nuances of written lyrics including\nformatting and punctuation, which leads to a potential misalignment with the\ncreative products of musicians and songwriters as well as listeners'\nexperiences. For example, line breaks are important in conveying information\nabout rhythm, emotional emphasis, rhyme, and high-level structure. To address\nthis issue, we introduce Jam-ALT, a new lyrics transcription benchmark based on\nthe JamendoLyrics dataset. Our contribution is twofold. Firstly, a complete\nrevision of the transcripts, geared specifically towards ALT evaluation by\nfollowing a newly created annotation guide that unifies the music industry's\nguidelines, covering aspects such as punctuation, line breaks, spelling,\nbackground vocals, and non-word sounds. Secondly, a suite of evaluation metrics\ndesigned, unlike the traditional word error rate, to capture such phenomena. We\nhope that the proposed benchmark contributes to the ALT task, enabling more\nprecise and reliable assessments of transcription systems and enhancing the\nuser experience in lyrics applications such as subtitle renderings for live\ncaptioning or karaoke.",
                "authors": [
                    "Ond\u0159ej C\u00edfka",
                    "Constantinos Dimitriou",
                    "Cheng-i Wang",
                    "Hendrik Schreiber",
                    "Luke Miner",
                    "Fabian-Robert St\u00f6ter"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13987v1",
                    "http://arxiv.org/pdf/2311.13987v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.CL",
                    "cs.LG",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13986v1/1.0",
                "title": "FViT-Grasp: Grasping Objects With Using Fast Vision Transformers",
                "year": 2023,
                "abstract": "This study addresses the challenge of manipulation, a prominent issue in\nrobotics. We have devised a novel methodology for swiftly and precisely\nidentifying the optimal grasp point for a robot to manipulate an object. Our\napproach leverages a Fast Vision Transformer (FViT), a type of neural network\ndesigned for processing visual data and predicting the most suitable grasp\nlocation. Demonstrating state-of-the-art performance in terms of speed while\nmaintaining a high level of accuracy, our method holds promise for potential\ndeployment in real-time robotic grasping applications. We believe that this\nstudy provides a baseline for future research in vision-based robotic grasp\napplications. Its high speed and accuracy bring researchers closer to real-life\napplications.",
                "authors": [
                    "Arda Sarp Yenicesu",
                    "Berk Cicek",
                    "Ozgur S. Oguz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13986v1",
                    "http://arxiv.org/pdf/2311.13986v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13984v2/1.0",
                "title": "Harnessing Large Language Models to Enhance Self-Regulated Learning via\n  Formative Feedback",
                "year": 2023,
                "abstract": "Effectively supporting students in mastering all facets of self-regulated\nlearning is a central aim of teachers and educational researchers. Prior\nresearch could demonstrate that formative feedback is an effective way to\nsupport students during self-regulated learning (SRL). However, for formative\nfeedback to be effective, it needs to be tailored to the learners, requiring\ninformation about their learning progress. In this work, we introduce LEAP, a\nnovel platform that utilizes advanced large language models (LLMs), such as\nChatGPT, to provide formative feedback to students. LEAP empowers teachers with\nthe ability to effectively pre-prompt and assign tasks to the LLM, thereby\nstimulating students' cognitive and metacognitive processes and promoting\nself-regulated learning. We demonstrate that a systematic prompt design based\non theoretical principles can provide a wide range of types of scaffolds to\nstudents, including sense-making, elaboration, self-explanation, partial\ntask-solution scaffolds, as well as metacognitive and motivational scaffolds.\nIn this way, we emphasize the critical importance of synchronizing educational\ntechnological advances with empirical research and theoretical frameworks.",
                "authors": [
                    "Steffen Steinert",
                    "Karina E. Avila",
                    "Stefan Ruzika",
                    "Jochen Kuhn",
                    "Stefan K\u00fcchemann"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13984v2",
                    "http://arxiv.org/pdf/2311.13984v2"
                ],
                "primary_category": "physics.ed-ph",
                "categories": [
                    "physics.ed-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13983v1/1.0",
                "title": "Learning Dynamic Selection and Pricing of Out-of-Home Deliveries",
                "year": 2023,
                "abstract": "Home delivery failures, traffic congestion, and relatively large handling\ntimes have a negative impact on the profitability of last-mile logistics. These\nexternal factors contribute to up to $28\\%$ of the overall costs and $25\\%$ of\nemissions for the home delivery supply chain. A potential solution, showing\nannual growth rates up to $36\\%$, is the delivery to parcel lockers or parcel\nshops, denoted by out-of-home (OOH) delivery. In the academic literature,\nmodels of customer behavior with respect to OOH delivery were so far limited to\ndeterministic settings, contrasting with the stochastic nature of actual\ncustomer choices. We model the sequential decision-making problem of which OOH\nlocation to offer against what incentive for each incoming customer, taking\ninto account future customer arrivals and choices. We propose Dynamic Selection\nand Pricing of OOH (DSPO), an algorithmic pipeline that uses a novel\nspatial-temporal state encoding as input to a convolutional neural network. We\ndemonstrate the performance of our method by benchmarking it against three\nstate-of-the-art approaches. Our extensive numerical study, guided by\nreal-world data, reveals that DSPO can save $20.8\\%$ in costs compared to a\nsituation without OOH locations, $8.1\\%$ compared to a static selection and\npricing policy, and $4.6\\%$ compared to a state-of-the-art demand management\nbenchmark. We provide comprehensive insights into the complex interplay between\nOOH delivery dynamics and customer behavior influenced by pricing strategies.\nThe implications of our findings suggest practitioners to adopt dynamic\nselection and pricing policies as OOH delivery gains a larger market share.",
                "authors": [
                    "Fabian Akkerman",
                    "Peter Dieter",
                    "Martijn Mes"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13983v1",
                    "http://arxiv.org/pdf/2311.13983v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13982v1/1.0",
                "title": "Probabilistic Tree-of-thought Reasoning for Answering\n  Knowledge-intensive Complex Questions",
                "year": 2023,
                "abstract": "Large language models (LLMs) are capable of answering knowledge-intensive\ncomplex questions with chain-of-thought (CoT) reasoning. However, they tend to\ngenerate factually incorrect reasoning steps when the required knowledge is not\navailable or up-to-date in models' parameters. Recent works turn to retrieving\nexternal knowledge to augment CoT reasoning. Despite being promising, these\nchain-based methods suffer from: 1) Negative retrieval. Unnecessary or\nincorrect retrieval may mislead the reasoning; 2) Limited sight. Lacking the\nability to look backward or forward, a local error in one step will propagate\nalong the chain.\n  In this paper, we propose a novel approach: Probabilistic Tree-of-thought\nReasoning (ProbTree). First, LLMs translate a complex question into a query\ntree, in which each non-root node denotes a sub-question of its parent node.\nThen, probabilistic reasoning is conducted over the tree, by solving questions\nfrom leaf to root considering the confidence of both question decomposing and\nanswering. During reasoning, for leaf nodes, LLMs choose a more confident\nanswer from Closed-book QA that employs parametric knowledge and Open-book QA\nthat employs retrieved external knowledge, thus eliminating the negative\nretrieval problem. For non-leaf nodes, with the hierarchical structure, LLMs\nhave broader sights and are able to globally reason with the information from\nchild nodes, thus recovering from local errors. The experiments on three\nComplex QA datasets under the open-domain setting show that our approach\noutperforms SOTA methods significantly, demonstrating the effect of\nprobabilistic tree-of-thought reasoning.",
                "authors": [
                    "Shulin Cao",
                    "Jiajie Zhang",
                    "Jiaxin Shi",
                    "Xin Lv",
                    "Zijun Yao",
                    "Qi Tian",
                    "Juanzi Li",
                    "Lei Hou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13982v1",
                    "http://arxiv.org/pdf/2311.13982v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13981v1/1.0",
                "title": "Overview of the distributed image processing infrastructure to produce\n  the Legacy Survey of Space and Time",
                "year": 2023,
                "abstract": "The Vera C. Rubin Observatory is preparing to execute the most ambitious\nastronomical survey ever attempted, the Legacy Survey of Space and Time (LSST).\nCurrently the final phase of construction is under way in the Chilean Andes,\nwith the Observatory's ten-year science mission scheduled to begin in 2025.\nRubin's 8.4-meter telescope will nightly scan the southern hemisphere\ncollecting imagery in the wavelength range 320-1050 nm covering the entire\nobservable sky every 4 nights using a 3.2 gigapixel camera, the largest imaging\ndevice ever built for astronomy. Automated detection and classification of\ncelestial objects will be performed by sophisticated algorithms on\nhigh-resolution images to progressively produce an astronomical catalog\neventually composed of 20 billion galaxies and 17 billion stars and their\nassociated physical properties.\n  In this article we present an overview of the system currently being\nconstructed to perform data distribution as well as the annual campaigns which\nreprocess the entire image dataset collected since the beginning of the survey.\nThese processing campaigns will utilize computing and storage resources\nprovided by three Rubin data facilities (one in the US and two in Europe). Each\nyear a Data Release will be produced and disseminated to science collaborations\nfor use in studies comprising four main science pillars: probing dark matter\nand dark energy, taking inventory of solar system objects, exploring the\ntransient optical sky and mapping the Milky Way.\n  Also presented is the method by which we leverage some of the common tools\nand best practices used for management of large-scale distributed data\nprocessing projects in the high energy physics and astronomy communities. We\nalso demonstrate how these tools and practices are utilized within the Rubin\nproject in order to overcome the specific challenges faced by the Observatory.",
                "authors": [
                    "Fabio Hernandez",
                    "George Beckett",
                    "Peter Clark",
                    "Matt Doidge",
                    "Tim Jenness",
                    "Edward Karavakis",
                    "Quentin Le Boulc'h",
                    "Peter Love",
                    "Gabriele Mainetti",
                    "Timothy Noble",
                    "Brandon White",
                    "Wei Yang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13981v1",
                    "http://arxiv.org/pdf/2311.13981v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13978v1/1.0",
                "title": "MedISure: Towards Assuring Machine Learning-based Medical Image\n  Classifiers using Mixup Boundary Analysis",
                "year": 2023,
                "abstract": "Machine learning (ML) models are becoming integral in healthcare\ntechnologies, presenting a critical need for formal assurance to validate their\nsafety, fairness, robustness, and trustworthiness. These models are inherently\nprone to errors, potentially posing serious risks to patient health and could\neven cause irreparable harm. Traditional software assurance techniques rely on\nfixed code and do not directly apply to ML models since these algorithms are\nadaptable and learn from curated datasets through a training process. However,\nadapting established principles, such as boundary testing using synthetic test\ndata can effectively bridge this gap. To this end, we present a novel technique\ncalled Mix-Up Boundary Analysis (MUBA) that facilitates evaluating image\nclassifiers in terms of prediction fairness. We evaluated MUBA for two\nimportant medical imaging tasks -- brain tumour classification and breast\ncancer classification -- and achieved promising results. This research aims to\nshowcase the importance of adapting traditional assurance principles for\nassessing ML models to enhance the safety and reliability of healthcare\ntechnologies. To facilitate future research, we plan to publicly release our\ncode for MUBA.",
                "authors": [
                    "Adam Byfield",
                    "William Poulett",
                    "Ben Wallace",
                    "Anusha Jose",
                    "Shatakshi Tyagi",
                    "Smita Shembekar",
                    "Adnan Qayyum",
                    "Junaid Qadir",
                    "Muhammad Bilal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13978v1",
                    "http://arxiv.org/pdf/2311.13978v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13977v1/1.0",
                "title": "Information dynamics efficiently discriminates high $\u03b3$-rhythms in\n  EEG brain waves",
                "year": 2023,
                "abstract": "Discriminating between physiological waves, linked to functional brain\nproperties, and pathological waves, due to brain malfunction, is problematic,\ne. g., for high-frequency oscillations (HFO) as high $\\gamma$ waves. Brain\nrhythms observed in EEG can also be observed in excitatory/inhibitory (E/I) NN\nmodels. Such models allow to study the relationship between waves and neuronal\ncircuit functions, which could lead to fundamental insights to discriminating\nwaves. To address this and other questions, we explore the emergence of high\ngamma rhythms in an E/I balanced neural population of integrated and fire\nneurons with short-term synaptic plasticity. This model generates a rich\nrepertoire of EEG-like rhythms, including high-frequency excitatory and\ninhibitory oscillations. Using the integrated information decomposition\nframework (Phi-ID), we explore the information dynamics of the network and its\nrelationship with excitatory and inhibitory activity and high-frequency\nrhythms. In regions where high gamma rhythms emerge only in the excitatory\npopulation, we see informational properties in the network more favorable for\ncomputation and processing information, corresponding then to functional\nregimes. However, regions where high gamma rhythms also emerge in the\ninhibitory population present lower mutual information in general, and the\nsystem becomes less predictable, a fact that can be linked to a less functional\nor ``pathological\" regime. In the second case, we observe that both excitatory\nand inhibitory populations oscillate with the same dominant frequency, which is\nhigher than in the first case. Higher frequency oscillations and\nsynchronization are commonly associated with epileptic seizures so adopting an\ninformation dynamics approach could help differentiate between high-frequency\noscillations related to cognitive functions from those related to neuronal\ndisorders such as epilepsy.",
                "authors": [
                    "Gustavo Menesse",
                    "Joaquin J. Torres"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13977v1",
                    "http://arxiv.org/pdf/2311.13977v1"
                ],
                "primary_category": "q-bio.NC",
                "categories": [
                    "q-bio.NC",
                    "cond-mat.dis-nn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13976v1/1.0",
                "title": "Low Latency Instance Segmentation by Continuous Clustering for Rotating\n  LiDAR Sensors",
                "year": 2023,
                "abstract": "Low-latency instance segmentation of LiDAR point clouds is crucial in\nreal-world applications because it serves as an initial and frequently-used\nbuilding block in a robot's perception pipeline, where every task adds further\ndelay. Particularly in dynamic environments, this total delay can result in\nsignificant positional offsets of dynamic objects, as seen in highway\nscenarios. To address this issue, we employ continuous clustering of obstacle\npoints in order to obtain an instance-segmented point cloud. Unlike most\nexisting approaches, which use a full revolution of the LiDAR sensor, we\nprocess the data stream in a continuous and seamless fashion. More\nspecifically, each column of a range image is processed as soon it is\navailable. Obstacle points are clustered to existing instances in real-time and\nit is checked at a high-frequency which instances are completed and are ready\nto be published. An additional advantage is that no problematic discontinuities\nbetween the points of the start and the end of a scan are observed. In this\nwork we describe the two-layered data structure and the corresponding algorithm\nfor continuous clustering, which is able to cluster the incoming data in real\ntime. We explain the importance of a large perceptive field of view.\nFurthermore, we describe and evaluate important architectural design choices,\nwhich could be relevant to design an architecture for deep learning based\nlow-latency instance segmentation. We are publishing the source code at\nhttps://github.com/UniBwTAS/continuous_clustering.",
                "authors": [
                    "Andreas Reich",
                    "Hans-Joachim Wuensche"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13976v1",
                    "http://arxiv.org/pdf/2311.13976v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13973v1/1.0",
                "title": "Facilitating Human-Robot Collaboration through Natural Vocal\n  Conversations",
                "year": 2023,
                "abstract": "In the rapidly evolving landscape of human-robot collaboration, effective\ncommunication between humans and robots is crucial for complex task execution.\nTraditional request-response systems often lack naturalness and may hinder\nefficiency. In this study, we propose a novel approach that employs human-like\nconversational interactions for vocal communication between human operators and\nrobots. The framework emphasizes the establishment of a natural and interactive\ndialogue, enabling human operators to engage in vocal conversations with\nrobots. Through a comparative experiment, we demonstrate the efficacy of our\napproach in enhancing task performance and collaboration efficiency. The\nrobot's ability to engage in meaningful vocal conversations enables it to seek\nclarification, provide status updates, and ask for assistance when required,\nleading to improved coordination and a smoother workflow. The results indicate\nthat the adoption of human-like conversational interactions positively\ninfluences the human-robot collaborative dynamic. Human operators find it\neasier to convey complex instructions and preferences, fostering a more\nproductive and satisfying collaboration experience.",
                "authors": [
                    "Davide Ferrari",
                    "Filippo Alberi",
                    "Cristian Secchi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13973v1",
                    "http://arxiv.org/pdf/2311.13973v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13964v1/1.0",
                "title": "Deep Interactive Segmentation of Medical Images: A Systematic Review and\n  Taxonomy",
                "year": 2023,
                "abstract": "Interactive segmentation is a crucial research area in medical image analysis\naiming to boost the efficiency of costly annotations by incorporating human\nfeedback. This feedback takes the form of clicks, scribbles, or masks and\nallows for iterative refinement of the model output so as to efficiently guide\nthe system towards the desired behavior. In recent years, deep learning-based\napproaches have propelled results to a new level causing a rapid growth in the\nfield with 121 methods proposed in the medical imaging domain alone. In this\nreview, we provide a structured overview of this emerging field featuring a\ncomprehensive taxonomy, a systematic review of existing methods, and an\nin-depth analysis of current practices. Based on these contributions, we\ndiscuss the challenges and opportunities in the field. For instance, we find\nthat there is a severe lack of comparison across methods which needs to be\ntackled by standardized baselines and benchmarks.",
                "authors": [
                    "Zdravko Marinov",
                    "Paul F. J\u00e4ger",
                    "Jan Egger",
                    "Jens Kleesiek",
                    "Rainer Stiefelhagen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13964v1",
                    "http://arxiv.org/pdf/2311.13964v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.AI",
                    "cs.CV",
                    "cs.HC",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13963v1/1.0",
                "title": "Investigating the use of publicly available natural videos to learn\n  Dynamic MR image reconstruction",
                "year": 2023,
                "abstract": "Purpose: To develop and assess a deep learning (DL) pipeline to learn dynamic\nMR image reconstruction from publicly available natural videos (Inter4K).\n  Materials and Methods: Learning was performed for a range of DL architectures\n(VarNet, 3D UNet, FastDVDNet) and corresponding sampling patterns (Cartesian,\nradial, spiral) either from true multi-coil cardiac MR data (N=692) or from\npseudo-MR data simulated from Inter4K natural videos (N=692). Real-time\nundersampled dynamic MR images were reconstructed using DL networks trained\nwith cardiac data and natural videos, and compressed sensing (CS). Differences\nwere assessed in simulations (N=104 datasets) in terms of MSE, PSNR, and SSIM\nand prospectively for cardiac (short axis, four chambers, N=20) and speech\n(N=10) data in terms of subjective image quality ranking, SNR and Edge\nsharpness. Friedman Chi Square tests with post-hoc Nemenyi analysis were\nperformed to assess statistical significance.\n  Results: For all simulation metrics, DL networks trained with cardiac data\noutperformed DL networks trained with natural videos, which outperformed CS\n(p<0.05). However, in prospective experiments DL reconstructions using both\ntraining datasets were ranked similarly (and higher than CS) and presented no\nstatistical differences in SNR and Edge Sharpness for most conditions.\nAdditionally, high SSIM was measured between the DL methods with cardiac data\nand natural videos (SSIM>0.85).\n  Conclusion: The developed pipeline enabled learning dynamic MR reconstruction\nfrom natural videos preserving DL reconstruction advantages such as high\nquality fast and ultra-fast reconstructions while overcoming some limitations\n(data scarcity or sharing). The natural video dataset, code and pre-trained\nnetworks are made readily available on github.\n  Key Words: real-time; dynamic MRI; deep learning; image reconstruction;\nmachine learning;",
                "authors": [
                    "Olivier Jaubert",
                    "Michele Pascale",
                    "Javier Montalt-Tordera",
                    "Julius Akesson",
                    "Ruta Virsinskaite",
                    "Daniel Knight",
                    "Simon Arridge",
                    "Jennifer Steeden",
                    "Vivek Muthurangu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13963v1",
                    "http://arxiv.org/pdf/2311.13963v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13961v1/1.0",
                "title": "Heterogeneous integration of single InAs/InP quantum dots with the SOI\n  chip using direct bonding",
                "year": 2023,
                "abstract": "Quantum information processing with photons in small-footprint and highly\nintegrated silicon-based photonic chips requires incorporating non-classical\nlight sources. In this respect, self-assembled III-V semiconductor quantum dots\n(QDs) are an attractive solution, however, they must be combined with the\nsilicon platform. Here, by utilizing the large-area direct bonding technique,\nwe demonstrate the hybridization of InP and SOI chips, which allows for\ncoupling single photons to the SOI chip interior, offering cost-effective\nscalability in setting up a multi-source environment for quantum photonic\nchips. We fabricate devices consisting of self-assembled InAs QDs embedded in\nthe tapered InP waveguide (WG) positioned over the SOI-defined Si WG. Focusing\non devices generating light in the telecom C-band compatible with the low-loss\noptical fiber networks, we demonstrate the light coupling between InP and SOI\nplatforms by observing photons outcoupled at the InP-made circular Bragg\ngrating outcoupler fabricated at the end of an 80 $\\mu$m-long Si WG, and at the\ncleaved edge of the Si WG. Finally, for a device with suppressed multi-photon\ngeneration events exhibiting 80% single photon generation purity, we measure\nthe photon number outcoupled at the cleaved facet of the Si WG. We estimate the\ndirectional on-chip photon coupling between the source and the Si WG to 5.1%.",
                "authors": [
                    "Marek Burakowski",
                    "Pawe\u0142 Holewa",
                    "Aurimas Sakanas",
                    "Anna Musia\u0142",
                    "Grzegorz S\u0119k",
                    "Pawe\u0142 Mrowi\u0144ski",
                    "Kresten Yvind",
                    "Elizaveta Semenova",
                    "Marcin Syperek"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13961v1",
                    "http://arxiv.org/pdf/2311.13961v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.07556v1/1.0",
                "title": "Federated Learning for Short Text Clustering",
                "year": 2023,
                "abstract": "Short text clustering has been popularly studied for its significance in\nmining valuable insights from many short texts. In this paper, we focus on the\nfederated short text clustering (FSTC) problem, i.e., clustering short texts\nthat are distributed in different clients, which is a realistic problem under\nprivacy requirements. Compared with the centralized short text clustering\nproblem that short texts are stored on a central server, the FSTC problem has\nnot been explored yet. To fill this gap, we propose a Federated Robust Short\nText Clustering (FSTC) framework. FSTC includes two main modules, i.e., robust\nshort text clustering module and federated cluster center aggregation module.\nThe robust short text clustering module aims to train an effective short text\nclustering model with local data in each client. We innovatively combine\noptimal transport to generate pseudo-labels with Gaussian-uniform mixture model\nto ensure the reliability of the pseudo-supervised data. The federated cluster\ncenter aggregation module aims to exchange knowledge across clients without\nsharing local raw data in an efficient way. The server aggregates the local\ncluster centers from different clients and then sends the global centers back\nto all clients in each communication round. Our empirical studies on three\nshort text clustering datasets demonstrate that FSTC significantly outperforms\nthe federated short text clustering baselines.",
                "authors": [
                    "Mengling Hu",
                    "Chaochao Chen",
                    "Weiming Liu",
                    "Xinting Liao",
                    "Xiaolin Zheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.07556v1",
                    "http://arxiv.org/pdf/2312.07556v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13960v1/1.0",
                "title": "Human Machine Co-Creation. A Complementary Cognitive Approach to\n  Creative Character Design Process Using GANs",
                "year": 2023,
                "abstract": "Recent advances in Generative Adversarial Networks GANs applications continue\nto attract the attention of researchers in different fields. In such a\nframework, two neural networks compete adversely to generate new visual\ncontents indistinguishable from the original dataset. The objective of this\nresearch is to create a complementary codesign process between humans and\nmachines to augment character designers abilities in visualizing and creating\nnew characters for multimedia projects such as games and animation. Driven by\ndesign cognitive scaffolding, the proposed approach aims to inform the process\nof perceiving, knowing, and making. The machine generated concepts are used as\na launching platform for character designers to conceptualize new characters. A\nlabelled dataset of 22,000 characters was developed for this work and deployed\nusing different GANs to evaluate the most suited for the context, followed by\nmixed methods evaluation for the machine output and human derivations. The\ndiscussed results substantiate the value of the proposed cocreation framework\nand elucidate how the generated concepts are used as cognitive substances that\ninteract with designers competencies in a versatile manner to influence the\ncreative processes of conceptualizing novel characters.",
                "authors": [
                    "Mohammad Lataifeh",
                    "Xavier A Carrascoa",
                    "Ashraf M Elnagara",
                    "Naveed Ahmeda",
                    "Imran Junejo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13960v1",
                    "http://arxiv.org/pdf/2311.13960v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13958v1/1.0",
                "title": "High-Order Tensor Recovery with A Tensor $U_1$ Norm",
                "year": 2023,
                "abstract": "Recently, numerous tensor SVD (t-SVD)-based tensor recovery methods have\nemerged, showing promise in processing visual data. However, these methods\noften suffer from performance degradation when confronted with high-order\ntensor data exhibiting non-smooth changes, commonly observed in real-world\nscenarios but ignored by the traditional t-SVD-based methods. Our objective in\nthis study is to provide an effective tensor recovery technique for handling\nnon-smooth changes in tensor data and efficiently explore the correlations of\nhigh-order tensor data across its various dimensions without introducing\nnumerous variables and weights. To this end, we introduce a new tensor\ndecomposition and a new tensor norm called the Tensor $U_1$ norm. We utilize\nthese novel techniques in solving the problem of high-order tensor completion\nproblem and provide theoretical guarantees for the exact recovery of the\nresulting tensor completion models. An optimization algorithm is proposed to\nsolve the resulting tensor completion model iteratively by combining the\nproximal algorithm with the Alternating Direction Method of Multipliers.\nTheoretical analysis showed the convergence of the algorithm to the\nKarush-Kuhn-Tucker (KKT) point of the optimization problem. Numerical\nexperiments demonstrated the effectiveness of the proposed method in high-order\ntensor completion, especially for tensor data with non-smooth changes.",
                "authors": [
                    "Jingjing Zheng",
                    "Wenzhe Wang",
                    "Xiaoqin Zhang",
                    "Yankai Cao",
                    "Xianta Jiang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13958v1",
                    "http://arxiv.org/pdf/2311.13958v1"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13957v1/1.0",
                "title": "Efficient Trigger Word Insertion",
                "year": 2023,
                "abstract": "With the boom in the natural language processing (NLP) field these years,\nbackdoor attacks pose immense threats against deep neural network models.\nHowever, previous works hardly consider the effect of the poisoning rate. In\nthis paper, our main objective is to reduce the number of poisoned samples\nwhile still achieving a satisfactory Attack Success Rate (ASR) in text backdoor\nattacks. To accomplish this, we propose an efficient trigger word insertion\nstrategy in terms of trigger word optimization and poisoned sample selection.\nExtensive experiments on different datasets and models demonstrate that our\nproposed method can significantly improve attack effectiveness in text\nclassification tasks. Remarkably, our approach achieves an ASR of over 90% with\nonly 10 poisoned samples in the dirty-label setting and requires merely 1.5% of\nthe training data in the clean-label setting.",
                "authors": [
                    "Yueqi Zeng",
                    "Ziqiang Li",
                    "Pengfei Xia",
                    "Lei Liu",
                    "Bin Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13957v1",
                    "http://arxiv.org/pdf/2311.13957v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13956v1/1.0",
                "title": "Reducing Histopathology Slide Magnification Improves the Accuracy and\n  Speed of Ovarian Cancer Subtyping",
                "year": 2023,
                "abstract": "Artificial intelligence has found increasing use for ovarian cancer\nmorphological subtyping from histopathology slides, but the optimal\nmagnification for computational interpretation is unclear. Higher\nmagnifications offer abundant cytological information, whereas lower\nmagnifications give a broader histoarchitectural overview. Using\nattention-based multiple instance learning, we performed the most extensive\nanalysis of ovarian cancer tissue magnifications to date, with data at six\nmagnifications subjected to the same preprocessing, hyperparameter tuning,\ncross-validation and hold-out testing procedures. The lowest magnifications\n(1.25x and 2.5x) performed best in cross-validation, and intermediate\nmagnifications (5x and 10x) performed best in hold-out testing (62% and 61%\naccuracy, respectively). Lower magnification models were also significantly\nfaster, with the 5x model taking 5% as long to train and 31% as long to\nevaluate slides compared to 40x. This indicates that the standard usage of high\nmagnifications for computational ovarian cancer subtyping may be unnecessary,\nwith lower magnifications giving faster, more accurate alternatives.",
                "authors": [
                    "Jack Breen",
                    "Katie Allen",
                    "Kieran Zucker",
                    "Nicolas M. Orsi",
                    "Nishant Ravikumar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13956v1",
                    "http://arxiv.org/pdf/2311.13956v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13952v1/1.0",
                "title": "A self-similar model of galaxy formation and dark halo relaxation",
                "year": 2023,
                "abstract": "We develop a spherical self-similar model for the formation of a galaxy\nthrough gas collapsing in an isolated self-gravitating dark matter halo. We\nimprove upon the existing literature on self-similar collapse in two ways.\nFirst, we include the effects of radiative cooling and the formation of a\npseudo-disk at the center of collapse, in a parametrised manner. More\nimportantly, for the first time we solve for the evolution of gas and dark\nmatter simultaneously and self-consistently using a novel iterative approach.\nAs a result, our model produces shell trajectories of both gas and dark matter\nthat qualitatively agree with the results of full hydrodynamical simulations.\nWe discuss the impact of various ingredients such as the accretion rate, gas\nequation of state, disk radius and cooling rate amplitude on the evolution of\nthe gas shells. The self-consistent evolution of gas and dark matter allows us\nto study the response of the dark matter trajectories to the presence of\ncollapsing gas, an effect that has gained increasing importance recently in the\ncontext of precision estimates of small-scale statistics like the matter power\nspectrum. Our default configuration produces a relaxation relation in\nqualitative agreement with that seen in cosmological hydrodynamical\nsimulations, and further allows us to easily study the impact of the model\ningredients mentioned above. As an initial application, we vary one ingredient\nat a time and find that the accretion rate and gas equation of state have the\nlargest impact on the relaxation relation, while the cooling amplitude plays\nonly a minor role. Our model thus provides a convenient framework to rapidly\nexplore the coupled nonlinear impact of multiple astrophysical processes on the\nmass and velocity profiles of dark matter in galactic halos. (Abridged)",
                "authors": [
                    "Premvijay Velmani",
                    "Aseem Paranjape"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13952v1",
                    "http://arxiv.org/pdf/2311.13952v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA",
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13951v1/1.0",
                "title": "MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V",
                "year": 2023,
                "abstract": "In the pursuit of Artificial General Intelligence (AGI), the integration of\nvision in language models has marked a significant milestone. The advent of\nvision-language models (MLLMs) like GPT-4V have expanded AI applications,\naligning with the multi-modal capabilities of the human brain. However,\nevaluating the efficacy of MLLMs poses a substantial challenge due to the\nsubjective nature of tasks that lack definitive answers. Existing automatic\nevaluation methodologies on multi-modal large language models rely on objective\nqueries that have standard answers, inadequately addressing the nuances of\ncreative and associative multi-modal tasks. To address this, we introduce\nMLLM-Bench, an innovative benchmark inspired by Vicuna, spanning a diverse\narray of scenarios, including Perception, Understanding, Applying, Analyzing,\nEvaluating, and Creation along with the ethical consideration. MLLM-Bench is\ndesigned to reflect user experience more accurately and provide a more holistic\nassessment of model performance. Comparative evaluations indicate a significant\nperformance gap between existing open-source models and GPT-4V. We posit that\nMLLM-Bench will catalyze progress in the open-source community towards\ndeveloping user-centric vision-language models that meet a broad spectrum of\nreal-world applications. See online leaderboard in\n\\url{https://mllm-bench.llmzoo.com}.",
                "authors": [
                    "Wentao Ge",
                    "Shunian Chen",
                    "Guiming Chen",
                    "Junying Chen",
                    "Zhihong Chen",
                    "Shuo Yan",
                    "Chenghao Zhu",
                    "Ziyue Lin",
                    "Wenya Xie",
                    "Xidong Wang",
                    "Anningzhe Gao",
                    "Zhiyi Zhang",
                    "Jianquan Li",
                    "Xiang Wan",
                    "Benyou Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13951v1",
                    "http://arxiv.org/pdf/2311.13951v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13950v1/1.0",
                "title": "Object Location Prediction in Real-time using LSTM Neural Network and\n  Polynomial Regression",
                "year": 2023,
                "abstract": "This paper details the design and implementation of a system for predicting\nand interpolating object location coordinates. Our solution is based on\nprocessing inertial measurements and global positioning system data through a\nLong Short-Term Memory (LSTM) neural network and polynomial regression. LSTM is\na type of recurrent neural network (RNN) particularly suited for processing\ndata sequences and avoiding the long-term dependency problem. We employed data\nfrom real-world vehicles and the global positioning system (GPS) sensors. A\ncritical pre-processing step was developed to address varying sensor\nfrequencies and inconsistent GPS time steps and dropouts. The LSTM-based\nsystem's performance was compared with the Kalman Filter. The system was tuned\nto work in real-time with low latency and high precision. We tested our system\non roads under various driving conditions, including acceleration, turns,\ndeceleration, and straight paths. We tested our proposed solution's accuracy\nand inference time and showed that it could perform in real-time. Our\nLSTM-based system yielded an average error of 0.11 meters with an inference\ntime of 2 ms. This represents a 76\\% reduction in error compared to the\ntraditional Kalman filter method, which has an average error of 0.46 meters\nwith a similar inference time to the LSTM-based system.",
                "authors": [
                    "Petar Stojkovi\u0107",
                    "Predrag Tadi\u0107"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13950v1",
                    "http://arxiv.org/pdf/2311.13950v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13946v1/1.0",
                "title": "Weakly-Supervised Video Moment Retrieval via Regularized Two-Branch\n  Proposal Networks with Erasing Mechanism",
                "year": 2023,
                "abstract": "Video moment retrieval is to identify the target moment according to the\ngiven sentence in an untrimmed video. Due to temporal boundary annotations of\nthe video are extremely time-consuming to acquire, modeling in the\nweakly-supervised setting is increasingly focused, where we only have access to\nthe video-sentence pairs during training. Most existing weakly-supervised\nmethods adopt a MIL-based framework to develop inter-sample confrontment, but\nneglect the intra-sample confrontment between moments with similar semantics.\nTherefore, these methods fail to distinguish the correct moment from plausible\nnegative moments. Further, the previous attention models in cross-modal\ninteraction tend to focus on a few dominant words exorbitantly, ignoring the\ncomprehensive video-sentence correspondence. In this paper, we propose a novel\nRegularized Two-Branch Proposal Network with Erasing Mechanism to consider the\ninter-sample and intra-sample confrontments simultaneously. Concretely, we\nfirst devise a language-aware visual filter to generate both enhanced and\nsuppressed video streams. Then, we design the sharable two-branch proposal\nmodule to generate positive and plausible negative proposals from the enhanced\nand suppressed branch respectively, contributing to sufficient confrontment.\nBesides, we introduce an attention-guided dynamic erasing mechanism in enhanced\nbranch to discover the complementary video-sentence relation. Moreover, we\napply two types of proposal regularization to stabilize the training process\nand improve model performance. The extensive experiments on ActivityCaption,\nCharades-STA and DiDeMo datasets show the effectiveness of our method.",
                "authors": [
                    "Haoyuan Li",
                    "Zhou Zhao",
                    "Zhu Zhang",
                    "Zhijie Lin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13946v1",
                    "http://arxiv.org/pdf/2311.13946v1"
                ],
                "primary_category": "cs.MM",
                "categories": [
                    "cs.MM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13939v1/1.0",
                "title": "5G Edge Vision: Wearable Assistive Technology for People with Blindness\n  and Low Vision",
                "year": 2023,
                "abstract": "In an increasingly visual world, people with blindness and low vision (pBLV)\nface substantial challenges in navigating their surroundings and interpreting\nvisual information. From our previous work, VIS4ION is a smart wearable that\nhelps pBLV in their day-to-day challenges. It enables multiple artificial\nintelligence (AI)-based microservices such as visual scene processing,\nnavigation, and vision-language inference. These microservices require powerful\ncomputational resources and, in some cases, stringent inference times, hence\nthe need to offload computation to edge servers. This paper introduces a novel\nvideo streaming platform that improves the capabilities of VIS4ION by providing\nreal-time support of the microservices at the network edge. When video is\noffloaded wirelessly to the edge, the time-varying nature of the wireless\nnetwork requires the use of adaptation strategies for a seamless video service.\nWe demonstrate the performance of an adaptive real-time video streaming\nplatform through experimentation with an open-source 5G deployment based on\nopen air interface (OAI). The experiments demonstrate the ability to provide\nthe microservices robustly in time-varying network loads.",
                "authors": [
                    "Tommy Azzino",
                    "Marco Mezzavilla",
                    "Sundeep Rangan",
                    "Yao Wang",
                    "John-Ross Rizzo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13939v1",
                    "http://arxiv.org/pdf/2311.13939v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13937v1/1.0",
                "title": "Exploring Methods for Cross-lingual Text Style Transfer: The Case of\n  Text Detoxification",
                "year": 2023,
                "abstract": "Text detoxification is the task of transferring the style of text from toxic\nto neutral. While here are approaches yielding promising results in monolingual\nsetup, e.g., (Dale et al., 2021; Hallinan et al., 2022), cross-lingual transfer\nfor this task remains a challenging open problem (Moskovskiy et al., 2022). In\nthis work, we present a large-scale study of strategies for cross-lingual text\ndetoxification -- given a parallel detoxification corpus for one language; the\ngoal is to transfer detoxification ability to another language for which we do\nnot have such a corpus. Moreover, we are the first to explore a new task where\ntext translation and detoxification are performed simultaneously, providing\nseveral strong baselines for this task. Finally, we introduce new automatic\ndetoxification evaluation metrics with higher correlations with human judgments\nthan previous benchmarks. We assess the most promising approaches also with\nmanual markup, determining the answer for the best strategy to transfer the\nknowledge of text detoxification between languages.",
                "authors": [
                    "Daryna Dementieva",
                    "Daniil Moskovskiy",
                    "David Dale",
                    "Alexander Panchenko"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13937v1",
                    "http://arxiv.org/pdf/2311.13937v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14751v2/1.0",
                "title": "Efficient prediction of attosecond two-colour pulses from an X-ray\n  free-electron laser with machine learning",
                "year": 2023,
                "abstract": "X-ray free-electron lasers are sources of coherent, high-intensity X-rays\nwith numerous applications in ultra-fast measurements and dynamic structural\nimaging. Due to the stochastic nature of the self-amplified spontaneous\nemission process and the difficulty in controlling injection of electrons,\noutput pulses exhibit significant noise and limited temporal coherence.\nStandard measurement techniques used for characterizing two-coloured X-ray\npulses are challenging, as they are either invasive or diagnostically\nexpensive. In this work, we employ machine learning methods such as neural\nnetworks and decision trees to predict the central photon energies of pairs of\nattosecond fundamental and second harmonic pulses using parameters that are\neasily recorded at the high-repetition rate of a single shot. Using real\nexperimental data, we apply a detailed feature analysis on the input parameters\nwhile optimizing the training time of the machine learning methods. Our\npredictive models are able to make predictions of central photon energy for one\nof the pulses without measuring the other pulse, thereby leveraging the use of\nthe spectrometer without having to extend its detection window. We anticipate\napplications in X-ray spectroscopy using XFELs, such as in time-resolved X-ray\nabsorption and photoemission spectroscopy, where improved measurement of input\nspectra will lead to better experimental outcomes.",
                "authors": [
                    "Karim K. Alaa El-Din",
                    "Oliver G. Alexander",
                    "Leszek J. Frasinski",
                    "Florian Mintert",
                    "Zhaoheng Guo",
                    "Joseph Duris",
                    "Zhen Zhang",
                    "David B. Cesar",
                    "Paris Franz",
                    "Taran Driver",
                    "Peter Walter",
                    "James P. Cryan",
                    "Agostino Marinelli",
                    "Jon P. Marangos",
                    "Rick Mukherjee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14751v2",
                    "http://arxiv.org/pdf/2311.14751v2"
                ],
                "primary_category": "physics.acc-ph",
                "categories": [
                    "physics.acc-ph",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13936v1/1.0",
                "title": "Process-Commutative Distributed Objects: From Cryptocurrencies to\n  Byzantine-Fault-Tolerant CRDTs",
                "year": 2023,
                "abstract": "This paper explores the territory that lies between best-effort\nByzantine-Fault-Tolerant Conflict-free Replicated Data Types (BFT CRDTs) and\ntotally ordered distributed ledgers. It formally characterizes a novel class of\ndistributed objects that only requires a First In First Out (FIFO) order on the\nobject operations from each process (taken individually). The formalization\nrelies on Mazurkiewicz traces to define legal sequences of operations and\nensure a combination of Strong Eventual Consistency (SEC) and Pipleline\nConsistency (PC). The paper presents a generic algorithm that implements this\nnovel class of distributed objects in both crash- and Byzantine setting.\nFinally, the proposed approach is illustrated with four instances of this class\nof objects, namely money transfer, Petri nets, multi-sets, and concurrent work\nstealing dequeues.",
                "authors": [
                    "Davide Frey",
                    "Lucie Guillou",
                    "Michel Raynal",
                    "Fran\u00e7ois Ta\u00efani"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13936v1",
                    "http://arxiv.org/pdf/2311.13936v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13934v1/1.0",
                "title": "Robustness-Reinforced Knowledge Distillation with Correlation Distance\n  and Network Pruning",
                "year": 2023,
                "abstract": "The improvement in the performance of efficient and lightweight models (i.e.,\nthe student model) is achieved through knowledge distillation (KD), which\ninvolves transferring knowledge from more complex models (i.e., the teacher\nmodel). However, most existing KD techniques rely on Kullback-Leibler (KL)\ndivergence, which has certain limitations. First, if the teacher distribution\nhas high entropy, the KL divergence's mode-averaging nature hinders the\ntransfer of sufficient target information. Second, when the teacher\ndistribution has low entropy, the KL divergence tends to excessively focus on\nspecific modes, which fails to convey an abundant amount of valuable knowledge\nto the student. Consequently, when dealing with datasets that contain numerous\nconfounding or challenging samples, student models may struggle to acquire\nsufficient knowledge, resulting in subpar performance. Furthermore, in previous\nKD approaches, we observed that data augmentation, a technique aimed at\nenhancing a model's generalization, can have an adverse impact. Therefore, we\npropose a Robustness-Reinforced Knowledge Distillation (R2KD) that leverages\ncorrelation distance and network pruning. This approach enables KD to\neffectively incorporate data augmentation for performance improvement.\nExtensive experiments on various datasets, including CIFAR-100, FGVR,\nTinyImagenet, and ImageNet, demonstrate our method's superiority over current\nstate-of-the-art methods.",
                "authors": [
                    "Seonghak Kim",
                    "Gyeongdo Ham",
                    "Yucheol Cho",
                    "Daeshik Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13934v1",
                    "http://arxiv.org/pdf/2311.13934v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13930v1/1.0",
                "title": "Periodically Exchange Teacher-Student for Source-Free Object Detection",
                "year": 2023,
                "abstract": "Source-free object detection (SFOD) aims to adapt the source detector to\nunlabeled target domain data in the absence of source domain data. Most SFOD\nmethods follow the same self-training paradigm using mean-teacher (MT)\nframework where the student model is guided by only one single teacher model.\nHowever, such paradigm can easily fall into a training instability problem that\nwhen the teacher model collapses uncontrollably due to the domain shift, the\nstudent model also suffers drastic performance degradation. To address this\nissue, we propose the Periodically Exchange Teacher-Student (PETS) method, a\nsimple yet novel approach that introduces a multiple-teacher framework\nconsisting of a static teacher, a dynamic teacher, and a student model. During\nthe training phase, we periodically exchange the weights between the static\nteacher and the student model. Then, we update the dynamic teacher using the\nmoving average of the student model that has already been exchanged by the\nstatic teacher. In this way, the dynamic teacher can integrate knowledge from\npast periods, effectively reducing error accumulation and enabling a more\nstable training process within the MT-based framework. Further, we develop a\nconsensus mechanism to merge the predictions of two teacher models to provide\nhigher-quality pseudo labels for student model. Extensive experiments on\nmultiple SFOD benchmarks show that the proposed method achieves\nstate-of-the-art performance compared with other related methods, demonstrating\nthe effectiveness and superiority of our method on SFOD task.",
                "authors": [
                    "Qipeng Liu",
                    "Luojun Lin",
                    "Zhifeng Shen",
                    "Zhifeng Yang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13930v1",
                    "http://arxiv.org/pdf/2311.13930v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13925v1/1.0",
                "title": "Predicting Recovery or Decease of COVID-19 Patients with Clinical and\n  RT-PCR Using Machine Learning Classification Algorithms",
                "year": 2023,
                "abstract": "The COVID-19 pandemic has disrupted the global economy and people's daily\nlives in unprecedented ways. To make appropriate decisions, it is necessary to\ndiagnose COVID-19 rapidly and accurately. Clinical decision making is\ninfluenced by data collected from patients. With the aid of artificial\nintelligence, COVID-19 has been diagnosed quickly by analyzing symptoms,\npolymerase chain reaction (PCR), computed tomography scans, chest X-rays,\nroutine laboratory blood tests and even cough sounds. Furthermore, these data\ncan be used to predict a patient's morality, although there is a question about\nwhich data makes the most accurate predictions. Therefore, this study consists\nof two parts. Our first objective is to examine whether machine learning\nalgorithms can predict the outcome of COVID-19 cases (recovery or death), based\non the features present in the dataset. In the second part of the research, we\ninvestigated the impact of clinical and RT-PCR on prediction of recovery and\ndecease to determine which one is more reliable. We defined four stages with\ndifferent feature sets and use six machine learning methods to build prediction\nmodel. With an accuracy of 78.7%, random forest showed promising results for\npredicting death and recovery of patients. Based on this, it appears that\nrecovery and decease of patients are predictable using machine learning. For\nsecond objective, results indicate that clinical alone (without using RT-PCR),\ntrained with AdaBoost algorithm, is the most accurate with an accuracy of\n82.1%. This study can provide guidance for medical professionals in the event\nof a crisis or outbreak similar to COVID-19.",
                "authors": [
                    "Mohammad Dehghani",
                    "Zahra Yazdanparast"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13925v1",
                    "http://arxiv.org/pdf/2311.13925v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13921v1/1.0",
                "title": "Some Like It Small: Czech Semantic Embedding Models for Industry\n  Applications",
                "year": 2023,
                "abstract": "This article focuses on the development and evaluation of Small-sized Czech\nsentence embedding models. Small models are important components for real-time\nindustry applications in resource-constrained environments. Given the limited\navailability of labeled Czech data, alternative approaches, including\npre-training, knowledge distillation, and unsupervised contrastive fine-tuning,\nare investigated. Comprehensive intrinsic and extrinsic analyses are conducted,\nshowcasing the competitive performance of our models compared to significantly\nlarger counterparts, with approximately 8 times smaller size and 5 times faster\nspeed than conventional Base-sized models. To promote cooperation and\nreproducibility, both the models and the evaluation pipeline are made publicly\naccessible. Ultimately, this article presents practical applications of the\ndeveloped sentence embedding models in Seznam.cz, the Czech search engine.\nThese models have effectively replaced previous counterparts, enhancing the\noverall search experience for instance, in organic search, featured snippets,\nand image search. This transition has yielded improved performance.",
                "authors": [
                    "Ji\u0159\u00ed Bedn\u00e1\u0159",
                    "Jakub N\u00e1plava",
                    "Petra Baran\u010d\u00edkov\u00e1",
                    "Ond\u0159ej Lisick\u00fd"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13921v1",
                    "http://arxiv.org/pdf/2311.13921v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13917v1/1.0",
                "title": "Exploring the impact of social stress on the adaptive dynamics of\n  COVID-19: Typing the behavior of na\u00efve populations faced with epidemics",
                "year": 2023,
                "abstract": "In the context of natural disasters, human responses inevitably intertwine\nwith natural factors. The COVID-19 pandemic, as a significant stress factor,\nhas brought to light profound variations among different countries in terms of\ntheir adaptive dynamics in addressing the spread of infection outbreaks across\ndifferent regions. This emphasizes the crucial role of cultural characteristics\nin natural disaster analysis. The theoretical understanding of large-scale\nepidemics primarily relies on mean-field kinetic models. However, conventional\nSIR-like models failed to fully explain the observed phenomena at the onset of\nthe COVID-19 outbreak. These phenomena included the unexpected cessation of\nexponential growth, the reaching of plateaus, and the occurrence of multi-wave\ndynamics. In situations where an outbreak of a highly virulent and unfamiliar\ninfection arises, it becomes crucial to respond swiftly at a non-medical level\nto mitigate the negative socio-economic impact. Here we present a theoretical\nexamination of the first wave of the epidemic based on a simple SIRSS model\n(SIR with Social Stress). We conduct an analysis of the socio-cultural features\nof na\\\"ive population behaviors across various countries worldwide. The unique\ncharacteristics of each country/territory are encapsulated in only a few\nconstants within our model, derived from the fitted COVID-19 statistics. These\nconstants also reflect the societal response dynamics to the external stress\nfactor, underscoring the importance of studying the mutual behavior of humanity\nand natural factors during global social disasters. Based on these distinctive\ncharacteristics of specific regions, local authorities can optimize their\nstrategies to effectively combat epidemics until vaccines are developed.",
                "authors": [
                    "Innokentiy Kastalskiy",
                    "Andrei Zinovyev",
                    "Evgeny Mirkes",
                    "Victor Kazantsev",
                    "Alexander N. Gorban"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13917v1",
                    "http://arxiv.org/pdf/2311.13917v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13916v1/1.0",
                "title": "Van der Waals functionalization of ultrahigh-Q silica microcavities for\n  $\u03c7^{(2)}$-$\u03c7^{(3)}$ hybrid nonlinear photonics",
                "year": 2023,
                "abstract": "Optical nonlinear processes are indispensable in a wide range of applications\nincluding ultrafast laser sources, microscopy, metrology, and quantum\ninformation technologies. Combinations of the diverse nonlinear processes\nshould further lead to the development of unique functionalities, but\nsimultaneous use of second- and third-order nonlinear processes is generally\ndifficult. Second-order effects usually overwhelm the higher-order ones, except\nin centrosymmetric systems where the second-order susceptibility vanishes to\nallow the use of the third-order nonlinearity. Here we demonstrate a hybrid\nphotonic platform whereby the balance between second- and third-order\nsusceptibilities can be tuned flexibly. Ultrahigh-Q silica microcavities\ncapable of generating third-order effects are functionalized by atomically thin\ntungsten diselenide, and we observe cavity-enhanced second-harmonic generation\nand sum-frequency generation with continuous-wave excitation at a power level\nof only a few hundred microwatts. Pump power dependence exhibits drastic\nincrease and saturation of the second-harmonic light, originating from the\ndynamic phase-matching process. We show that the coexistence of second- and\nthird-order nonlinearities in a single device can be achieved by carefully\nchoosing the size and the location of the two-dimensional material. Our\napproach can be generalized to other types of cavities, unlocking the potential\nof hybrid systems with controlled nonlinear susceptibilities for novel\napplications.",
                "authors": [
                    "Shun Fujii",
                    "Nan Fang",
                    "Daiki Yamashita",
                    "Daichi Kozawa",
                    "Chee Fai Fong",
                    "Yuichiro K. Kato"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13916v1",
                    "http://arxiv.org/pdf/2311.13916v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13915v1/1.0",
                "title": "First passage times in compact domains exhibits bi-scaling",
                "year": 2023,
                "abstract": "The study of first passage times for diffusing particles reaching target\nstates is foundational in various practical applications, including\ndiffusion-controlled reactions. In this work, we present a bi-scaling theory\nfor the probability density function of first passage times in confined compact\nprocesses, applicable to both Euclidean and Fractal domains, diverse\ngeometries, and scenarios with or without external force fields, accommodating\nMarkovian and semi-Markovian random walks. In large systems, first passage time\nstatistics exhibit a bi-scaling behavior, challenging the use of a single time\nscale. Our theory employs two distinct scaling functions: one for short times,\ncapturing initial dynamics in unbounded systems, and the other for long times\nis sensitive to finite size effects. The combined framework provides a complete\nexpression for first passage time statistics across all time scales.",
                "authors": [
                    "Talia Baravi",
                    "Eli Barkai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13915v1",
                    "http://arxiv.org/pdf/2311.13915v1"
                ],
                "primary_category": "cond-mat.stat-mech",
                "categories": [
                    "cond-mat.stat-mech"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13912v1/1.0",
                "title": "Expanding the deep-learning model to diagnosis LVNC: Limitations and\n  trade-offs",
                "year": 2023,
                "abstract": "Hyper-trabeculation or non-compaction in the left ventricle of the myocardium\n(LVNC) is a recently classified form of cardiomyopathy. Several methods have\nbeen proposed to quantify the trabeculae accurately in the left ventricle, but\nthere is no general agreement in the medical community to use a particular\napproach. In previous work, we proposed DL-LVTQ, a deep learning approach for\nleft ventricular trabecular quantification based on a U-Net CNN architecture.\nDL-LVTQ was an automatic diagnosis tool developed from a dataset of patients\nwith the same cardiomyopathy (hypertrophic cardiomyopathy).\n  In this work, we have extended and adapted DL-LVTQ to cope with patients with\ndifferent cardiomyopathies. The dataset consists of up 379 patients in three\ngroups with different particularities and cardiomyopathies. Patient images were\ntaken from different scanners and hospitals. We have modified and adapted the\nU-Net convolutional neural network to account for the different particularities\nof a heterogeneous group of patients with various unclassifiable or mixed and\ninherited cardiomyopathies.\n  The inclusion of new groups of patients has increased the accuracy,\nspecificity and kappa values while maintaining the sensitivity of the automatic\ndeep learning method proposed. Therefore, a better-prepared diagnosis tool is\nready for various cardiomyopathies with different characteristics.\nCardiologists have considered that 98.9% of the evaluated outputs are verified\nclinically for diagnosis. Therefore, the high precision to segment the\ndifferent cardiac structures allows us to make a robust diagnostic system\nobjective and faster, decreasing human error and time spent.",
                "authors": [
                    "Gregorio Bernab\u00e9",
                    "Pilar Gonz\u00e1lez-F\u00e9rez",
                    "Jos\u00e9 M. Garc\u00eda",
                    "Guillem Casas",
                    "Josefa Gonz\u00e1lez-Carrillo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13912v1",
                    "http://arxiv.org/pdf/2311.13912v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13910v1/1.0",
                "title": "Dialogue Quality and Emotion Annotations for Customer Support\n  Conversations",
                "year": 2023,
                "abstract": "Task-oriented conversational datasets often lack topic variability and\nlinguistic diversity. However, with the advent of Large Language Models (LLMs)\npretrained on extensive, multilingual and diverse text data, these limitations\nseem overcome. Nevertheless, their generalisability to different languages and\ndomains in dialogue applications remains uncertain without benchmarking\ndatasets. This paper presents a holistic annotation approach for emotion and\nconversational quality in the context of bilingual customer support\nconversations. By performing annotations that take into consideration the\ncomplete instances that compose a conversation, one can form a broader\nperspective of the dialogue as a whole. Furthermore, it provides a unique and\nvaluable resource for the development of text classification models. To this\nend, we present benchmarks for Emotion Recognition and Dialogue Quality\nEstimation and show that further research is needed to leverage these models in\na production setting.",
                "authors": [
                    "John Mendon\u00e7a",
                    "Patr\u00edcia Pereira",
                    "Miguel Menezes",
                    "Vera Cabarr\u00e3o",
                    "Ana C. Farinha",
                    "Helena Moniz",
                    "Jo\u00e3o Paulo Carvalho",
                    "Alon Lavie",
                    "Isabel Trancoso"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13910v1",
                    "http://arxiv.org/pdf/2311.13910v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13908v1/1.0",
                "title": "Antimony Doping Effect on the Superconducting Properties of SmFeAs(O,F)",
                "year": 2023,
                "abstract": "We report the synthesis and characterization of a series of antimony-doped\nSmFeAs1-xSbxO0.8F0.2 (x = 0, 0.01, 0.03, 0.05, 0.1, 0.2, and 0.3) bulks to\ninvestigate the twin doping effects on the superconducting properties of\nSmFeAs(O,F) caused by fluorine (F) incorporation at O-site in SmO layer and\nantimony (Sb) substitution at As-site in the conducting layer (FeAs). Since the\nantimony (Sb) has a larger size than arsenic (As), the enhancement of lattice\nparameters has been confirmed by the XRD analysis. Microstructural analysis\nconfirms that Sb-doping leads to a small improvement in the sample density and\nan increase in the inhomogeneity of the constituent elements, especially at\nhigher Sb-doping levels. The parent compound SmFeAsO0.8F0.2 has shown the\nsuperconducting transition (Tc) at ~54 K, which is systematically reduced with\nthe antimony doping contents (x). Our investigation indicates that the Sb-doped\nSmFeAs(O,F) phase at low levels is less prone to the multiphase formation than\nat high levels, which affects the inter- and intragranular behaviour\noriginating from the microstructure nature of 1111 bulks. The critical current\ndensity (Jc) of the parent compound has almost the same value as previously\nreported, which is suppressed slowly with increased Sb-doping. It could be due\nto the reduced grain connections and the effective pinning centers. This study\nconfirms that the superconducting FeAs layer doping with larger ions at arsenic\nsites does not support the superconducting properties of Sm1111, which is a\ndistinct behavior from that of Sb-doped CeFeAs(O,F) and LaFeAs(O,F).",
                "authors": [
                    "Mohammad Azam",
                    "Manasa Manasa",
                    "Tatiana Zajarniuk",
                    "Ryszard Diduszko",
                    "Tomasz Cetner",
                    "Andrzej Morawski",
                    "Andrzej Wisniewski",
                    "Shiv J. Singh"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/TASC.2023.3343328",
                    "http://arxiv.org/abs/2311.13908v1",
                    "http://arxiv.org/pdf/2311.13908v1"
                ],
                "primary_category": "cond-mat.supr-con",
                "categories": [
                    "cond-mat.supr-con",
                    "cond-mat.mtrl-sci",
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13906v1/1.0",
                "title": "Threat-Based Resource Allocation Strategy for Target Tracking in a\n  Cognitive Radar Network",
                "year": 2023,
                "abstract": "Cognitive radar is developed to utilize the feedback of its operating\nenvironment obtained from a beam to make resource allocation decisions by\nsolving optimization problems. Previous works focused on target tracking\naccuracy by designing an evaluation metric for an optimization problem.\nHowever, in a real combat situation, not only the tracking performance of the\ntarget but also its operational perspective should be considered. In this\nstudy, the usage of threats in the allocation of radar resource is proposed for\na cognitive radar framework. Resource allocation regarding radar dwell time is\nconsidered to reflect the operational importance of target effects. The dwell\ntime allocation problem is solved using a Second-Order Cone Program (SOCP).\nNumerical simulations are performed to verify the effectiveness of the proposed\nframework.",
                "authors": [
                    "JiYe Lee",
                    "J. H Park"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13906v1",
                    "http://arxiv.org/pdf/2311.13906v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13904v1/1.0",
                "title": "3D microstructure characterization of Cu 25Cr solid state sintered alloy\n  using X-ray computed tomography and machine learning assisted segmentation",
                "year": 2023,
                "abstract": "Cu-Cr-based alloys with Cr content from 5 to 50 wt.% are widely used as\nelectrical contacts for vacuum interrupters for medium voltage applications\nbecause of their excellent combination of mechanical, thermal, and electrical\nconductivity. Cu-Cr electrical contacts are usually processed by sintering or\ncasting processes. For solid-state sintered Cu-Cr materials, the physical\nproperties vary as a function of the Cr content, phase morphology and porosity\nvolume fraction. Some studies have investigated the effect of the\nmicrostructural characteristics of Cu-Cr alloys with different Cr content and\nmorphology on their properties. However, the porosity characterization and Cr\nspatial distribution and how they affect these alloys' physical properties are\nnot as well documented. In this study, we report an in-depth 3D\ncharacterization of the porosity and Cr-phase of solid-state sintered Cu-25Cr\nalloys with three final relative densities using X-ray Computed Tomography\n(XCT). An image analysis algorithm assisted by a machine learning-based\nsegmentation method has been specifically developed. Results show that for\nCu-25Cr solid sintered alloys there are mainly two types of pores, pores\nlocated at the Cu/Cr interfaces, and pores within the Cu matrix. The\ninterfacial porosity represents the larger volume fraction, over 75% of the\ntotal porosity for all cases, forming a large network of interconnected pores.\nWith the increase of final density, the Cu-matrix becomes nearly fully dense\nwhile interfacial pores still represent the largest fraction decreases in size\nand volume. These interfacial pores networks are believed to be formed due to\npoor filling and packing of Cu around the percolated Cr-phase. These\nobservations might be helpful to optimize the functional properties of Cu-Cr\nsintered alloys.",
                "authors": [
                    "Lucas Varoto",
                    "Jean-Jacques Blandin",
                    "Pierre Lhuissier",
                    "Sophie Roure",
                    "Anthony Papillon",
                    "M\u00e9lissa Chosson",
                    "Guilhem Martin"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/j.matchar.2023.113107",
                    "http://arxiv.org/abs/2311.13904v1",
                    "http://arxiv.org/pdf/2311.13904v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph",
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13900v1/1.0",
                "title": "Efficient generation and amplification of intense vortex and vector\n  laser pulses via strongly coupled stimulated Brillouin scattering in plasmas",
                "year": 2023,
                "abstract": "The past decade has seen tremendous progress in the production and\nutilization of vortex and vector laser pulses. Although both are considered as\nstructured light beams, the vortex lasers have helical phase fronts and phase\nsingularities, while the vector lasers have spatially variable polarization\nstates and polarization singularities. In contrast to the vortex pulses that\ncarry orbital angular momentum (OAM), the vector laser pulses have a complex\nspin angular momentum (SAM) and OAM coupling. Despite many potential\napplications enabled by such pulses, the generation of high-power/-intensity\nvortex and vector beams remains challenging. Here, we demonstrate using theory\nand three-dimensional simulations that the strongly-coupled stimulated\nBrillouin scattering (SC-SBS) process in plasmas can be used as a promising\namplification technique with up to 65% energy transfer efficiency from the pump\nbeam to the seed beam for both vortex and vector pulses. We also show that\nSC-SBS is strongly polarization-dependent in plasmas, enabling an all-optical\npolarization control of the amplified seed beam. Additionally, the interaction\nof such structured lasers with plasmas leads to various angular momentum\ncouplings and decouplings that produce intense new light structures with\ncontrollable OAM and SAM. This scheme paves the way for novel optical devices\nsuch as plasma-based amplifiers and light field manipulators.",
                "authors": [
                    "Yipeng Wu",
                    "Chaojie Zhang",
                    "Zan Nie",
                    "Mitchell Sinclair",
                    "Audrey Farrell",
                    "Kenneth A Marsh",
                    "E. Paulo Alves",
                    "Frank Tsung",
                    "Warren B. Mori",
                    "Chan Joshi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13900v1",
                    "http://arxiv.org/pdf/2311.13900v1"
                ],
                "primary_category": "physics.plasm-ph",
                "categories": [
                    "physics.plasm-ph",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13897v1/1.0",
                "title": "Super-resolution capacity of variance-based stochastic fluorescence\n  microscopy",
                "year": 2023,
                "abstract": "Improving the resolution of fluorescence microscopy beyond the diffraction\nlimit can be achievedby acquiring and processing multiple images of the sample\nunder different illumination conditions.One of the simplest techniques, Random\nIllumination Microscopy (RIM), forms the super-resolvedimage from the variance\nof images obtained with random speckled illuminations. However, thevalidity of\nthis process has not been fully theorized. In this work, we characterize\nmathematicallythe sample information contained in the variance of\ndiffraction-limited speckled images as a functionof the statistical properties\nof the illuminations. We show that an unambiguous two-fold resolutiongain is\nobtained when the speckle correlation length coincides with the width of the\nobservationpoint spread function. Last, we analyze the difference between the\nvariance-based techniques usingrandom speckled illuminations (as in RIM) and\nthose obtained using random fluorophore activation(as in Super-resolution\nOptical Fluctuation Imaging, SOFI).",
                "authors": [
                    "Simon Labouesse",
                    "Marc Allain",
                    "Guillaume Giroussens",
                    "Thomas Mangeat",
                    "Anne Sentenac",
                    "J\u00e9r\u00f4me Idier"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13897v1",
                    "http://arxiv.org/pdf/2311.13897v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13893v1/1.0",
                "title": "Beamforming Design for Hybrid IRS-aided AF Relay Wireless Networks",
                "year": 2023,
                "abstract": "In this paper, a hybrid IRS-aided amplify-and-forward (AF) relay wireless\nnetwork is put forward, where the hybrid IRS is made up of passive and active\nelements. For maximum signal-to-noise ratio (SNR), a low-complexity method\nbased on successive convex approximation and fractional programming (LC-SCA-FP)\nis proposed to jointly optimize the beamforming matrix at AF relay and the\nreflecting coefficient matrices at IRS. Simulation results verify that the rate\nachieved by the proposed LC-SCA-FP method surpass those of the benchmark\nschemes, namely the passive IRS-aided AF relay and only AF relay network.",
                "authors": [
                    "Xuehui Wang",
                    "Yifan Zhao",
                    "Feng Shu",
                    "Yan Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13893v1",
                    "http://arxiv.org/pdf/2311.13893v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13892v2/1.0",
                "title": "General Phrase Debiaser: Debiasing Masked Language Models at a\n  Multi-Token Level",
                "year": 2023,
                "abstract": "The social biases and unwelcome stereotypes revealed by pretrained language\nmodels are becoming obstacles to their application. Compared to numerous\ndebiasing methods targeting word level, there has been relatively less\nattention on biases present at phrase level, limiting the performance of\ndebiasing in discipline domains. In this paper, we propose an automatic\nmulti-token debiasing pipeline called \\textbf{General Phrase Debiaser}, which\nis capable of mitigating phrase-level biases in masked language models.\nSpecifically, our method consists of a \\textit{phrase filter stage} that\ngenerates stereotypical phrases from Wikipedia pages as well as a \\textit{model\ndebias stage} that can debias models at the multi-token level to tackle bias\nchallenges on phrases. The latter searches for prompts that trigger model's\nbias, and then uses them for debiasing. State-of-the-art results on standard\ndatasets and metrics show that our approach can significantly reduce gender\nbiases on both career and multiple disciplines, across models with varying\nparameter sizes.",
                "authors": [
                    "Bingkang Shi",
                    "Xiaodan Zhang",
                    "Dehan Kong",
                    "Yulei Wu",
                    "Zongzhen Liu",
                    "Honglei Lyu",
                    "Longtao Huang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13892v2",
                    "http://arxiv.org/pdf/2311.13892v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13886v1/1.0",
                "title": "On transitions in water wave propagation through consolidated to broken\n  sea ice covers",
                "year": 2023,
                "abstract": "A theoretical model is used to study water waves propagating into and through\na region containing thin floating ice, for ice covers transitioning from\nconsolidated (large floe sizes) to fully broken (small floe sizes). The degree\nof breaking is simulated by a mean floe length. It is shown that there are\ndeterministic limits for consolidated and fully broken ice covers where the\nwave fields do not depend on the particular realisation of the ice cover for a\ngiven mean floe length. The consolidated ice limit is consistent with classic\nflexural-gravity wave theory, and the fully broken limit is well modelled by\nBloch waves in a periodic ice cover. In the transition between the limits, the\nwave field depends on the ice cover realisation, as multiple wave scattering is\na dominant process. The effects of the ice cover on the wave field are\nquantified using a wavelength, attenuation rate, and a transferred amplitude\nmeasuring the amplitude drop at the ice edge. It is shown that as the ice cover\nbreaks up (mean floe size gets smaller), the wavelength and amplitude drop\ndecreases (transferred amplitude increases) and the attenuation rate increases.\nThe results provide a new interpretation of field observations.",
                "authors": [
                    "Jordan P. A Pitt",
                    "Luke G. Bennetts"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13886v1",
                    "http://arxiv.org/pdf/2311.13886v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "physics.ao-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13885v1/1.0",
                "title": "Can Physics Informed Neural Operators Self Improve?",
                "year": 2023,
                "abstract": "Self-training techniques have shown remarkable value across many deep\nlearning models and tasks. However, such techniques remain largely unexplored\nwhen considered in the context of learning fast solvers for systems of partial\ndifferential equations (Eg: Neural Operators). In this work, we explore the use\nof self-training for Fourier Neural Operators (FNO). Neural Operators emerged\nas a data driven technique, however, data from experiments or traditional\nsolvers is not always readily available. Physics Informed Neural Operators\n(PINO) overcome this constraint by utilizing a physics loss for the training,\nhowever the accuracy of PINO trained without data does not match the\nperformance obtained by training with data. In this work we show that\nself-training can be used to close this gap in performance. We examine\ncanonical examples, namely the 1D-Burgers and 2D-Darcy PDEs, to showcase the\nefficacy of self-training. Specifically, FNOs, when trained exclusively with\nphysics loss through self-training, approach 1.07x for Burgers and 1.02x for\nDarcy, compared to FNOs trained with both data and physics loss. Furthermore,\nwe discover that pseudo-labels can be used for self-training without\nnecessarily training to convergence in each iteration. A consequence of this is\nthat we are able to discover self-training schedules that improve upon the\nbaseline performance of PINO in terms of accuracy as well as time.",
                "authors": [
                    "Ritam Majumdar",
                    "Amey Varhade",
                    "Shirish Karande",
                    "Lovekesh Vig"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13885v1",
                    "http://arxiv.org/pdf/2311.13885v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "math.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13884v2/1.0",
                "title": "Controlling Large Language Model-based Agents for Large-Scale\n  Decision-Making: An Actor-Critic Approach",
                "year": 2023,
                "abstract": "The significant advancements in large language models (LLMs) have presented\nnovel opportunities for tackling planning and decision-making within\nmulti-agent systems. However, as the number of agents increases, the issues of\nhallucination in LLMs and coordination in multi-agent systems (MAS) have become\nincreasingly pronounced. Additionally, the efficient utilization of tokens\nbecomes a critical consideration when employing LLMs to facilitate the\ninteractions of large numbers of agents. In this paper, we present a novel\nframework aimed at enhancing coordination and decision-making capabilities of\nLLMs within large-scale multi-agent environments. Our approach draws\ninspiration from the actor-critic framework employed in multi-agent\nreinforcement learning, and we develop a modular and token-efficient solution\nthat effectively addresses challenges presented by LLMs and MAS. Through\nevaluations conducted in experiments involving system resource allocation and\nrobot grid transportation, we demonstrate the considerable advantages afforded\nby our proposed approach.",
                "authors": [
                    "Bin Zhang",
                    "Hangyu Mao",
                    "Jingqing Ruan",
                    "Ying Wen",
                    "Yang Li",
                    "Shao Zhang",
                    "Zhiwei Xu",
                    "Dapeng Li",
                    "Ziyue Li",
                    "Rui Zhao",
                    "Lijuan Li",
                    "Guoliang Fan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13884v2",
                    "http://arxiv.org/pdf/2311.13884v2"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14749v1/1.0",
                "title": "Compositional Zero-shot Learning via Progressive Language-based\n  Observations",
                "year": 2023,
                "abstract": "Compositional zero-shot learning aims to recognize unseen state-object\ncompositions by leveraging known primitives (state and object) during training.\nHowever, effectively modeling interactions between primitives and generalizing\nknowledge to novel compositions remains a perennial challenge. There are two\nkey factors: object-conditioned and state-conditioned variance, i.e., the\nappearance of states (or objects) can vary significantly when combined with\ndifferent objects (or states). For instance, the state \"old\" can signify a\nvintage design for a \"car\" or an advanced age for a \"cat\". In this paper, we\nargue that these variances can be mitigated by predicting composition\ncategories based on pre-observed primitive. To this end, we propose Progressive\nLanguage-based Observations (PLO), which can dynamically determine a better\nobservation order of primitives. These observations comprise a series of\nconcepts or languages that allow the model to understand image content in a\nstep-by-step manner. Specifically, PLO adopts pre-trained vision-language\nmodels (VLMs) to empower the model with observation capabilities. We further\ndevise two variants: 1) PLO-VLM: a two-step method, where a pre-observing\nclassifier dynamically determines the observation order of two primitives. 2)\nPLO-LLM: a multi-step scheme, which utilizes large language models (LLMs) to\ncraft composition-specific prompts for step-by-step observing. Extensive\nablations on three challenging datasets demonstrate the superiority of PLO\ncompared with state-of-the-art methods, affirming its abilities in\ncompositional recognition.",
                "authors": [
                    "Lin Li",
                    "Guikun Chen",
                    "Jun Xiao",
                    "Long Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14749v1",
                    "http://arxiv.org/pdf/2311.14749v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13881v1/1.0",
                "title": "A Multi-solution Study on GDPR AI-enabled Completeness Checking of DPAs",
                "year": 2023,
                "abstract": "Specifying legal requirements for software systems to ensure their compliance\nwith the applicable regulations is a major concern to requirements engineering\n(RE). Personal data which is collected by an organization is often shared with\nother organizations to perform certain processing activities. In such cases,\nthe General Data Protection Regulation (GDPR) requires issuing a data\nprocessing agreement (DPA) which regulates the processing and further ensures\nthat personal data remains protected. Violating GDPR can lead to huge fines\nreaching to billions of Euros. Software systems involving personal data\nprocessing must adhere to the legal obligations stipulated in GDPR and outlined\nin DPAs. Requirements engineers can elicit from DPAs legal requirements for\nregulating the data processing activities in software systems. Checking the\ncompleteness of a DPA according to the GDPR provisions is therefore an\nessential prerequisite to ensure that the elicited requirements are complete.\nAnalyzing DPAs entirely manually is time consuming and requires adequate legal\nexpertise. In this paper, we propose an automation strategy to address the\ncompleteness checking of DPAs against GDPR. Specifically, we pursue ten\nalternative solutions which are enabled by different technologies, namely\ntraditional machine learning, deep learning, language modeling, and few-shot\nlearning. The goal of our work is to empirically examine how these different\ntechnologies fare in the legal domain. We computed F2 score on a set of 30 real\nDPAs. Our evaluation shows that best-performing solutions yield F2 score of\n86.7% and 89.7% are based on pre-trained BERT and RoBERTa language models. Our\nanalysis further shows that other alternative solutions based on deep learning\n(e.g., BiLSTM) and few-shot learning (e.g., SetFit) can achieve comparable\naccuracy, yet are more efficient to develop.",
                "authors": [
                    "Muhammad Ilyas Azeem",
                    "Sallam Abualhaija"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13881v1",
                    "http://arxiv.org/pdf/2311.13881v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13880v1/1.0",
                "title": "PointPCA+: Extending PointPCA objective quality assessment metric",
                "year": 2023,
                "abstract": "A computationally-simplified and descriptor-richer Point Cloud Quality\nAssessment (PCQA) metric, namely PointPCA+, is proposed in this paper, which is\nan extension of PointPCA. PointPCA proposed a set of perceptually-relevant\ndescriptors based on PCA decomposition that were applied to both the geometry\nand texture data of point clouds for full reference PCQA. PointPCA+ employs PCA\nonly on the geometry data while enriching existing geometry and texture\ndescriptors, that are computed more efficiently. Similarly to PointPCA, a total\nquality score is obtained through a learning-based fusion of individual\npredictions from geometry and texture descriptors that capture local shape and\nappearance properties, respectively. Before feature fusion, a feature selection\nmodule is introduced to choose the most effective features from a proposed\nsuper-set. Experimental results show that PointPCA+ achieves high predictive\nperformance against subjective ground truth scores obtained from publicly\navailable datasets. The code is available at\n\\url{https://github.com/cwi-dis/pointpca_suite/}.",
                "authors": [
                    "Xuemei Zhou",
                    "Evangelos Alexiou",
                    "Irene Viola",
                    "Pablo Cesar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13880v1",
                    "http://arxiv.org/pdf/2311.13880v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13878v1/1.0",
                "title": "Minimizing Factual Inconsistency and Hallucination in Large Language\n  Models",
                "year": 2023,
                "abstract": "Large Language Models (LLMs) are widely used in critical fields such as\nhealthcare, education, and finance due to their remarkable proficiency in\nvarious language-related tasks. However, LLMs are prone to generating factually\nincorrect responses or \"hallucinations,\" which can lead to a loss of\ncredibility and trust among users. To address this issue, we propose a\nmulti-stage framework that generates the rationale first, verifies and refines\nincorrect ones, and uses them as supporting references to generate the answer.\nThe generated rationale enhances the transparency of the answer and our\nframework provides insights into how the model arrived at this answer, by using\nthis rationale and the references to the context. In this paper, we demonstrate\nits effectiveness in improving the quality of responses to drug-related\ninquiries in the life sciences industry. Our framework improves traditional\nRetrieval Augmented Generation (RAG) by enabling OpenAI GPT-3.5-turbo to be\n14-25% more faithful and 16-22% more accurate on two datasets. Furthermore,\nfine-tuning samples based on our framework improves the accuracy of smaller\nopen-access LLMs by 33-42% and competes with RAG on commercial models.",
                "authors": [
                    "Muneeswaran I",
                    "Shreya Saxena",
                    "Siva Prasad",
                    "M V Sai Prakash",
                    "Advaith Shankar",
                    "Varun V",
                    "Vishal Vaddina",
                    "Saisubramaniam Gopalakrishnan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13878v1",
                    "http://arxiv.org/pdf/2311.13878v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13876v1/1.0",
                "title": "EEG Connectivity Analysis Using Denoising Autoencoders for the Detection\n  of Dyslexia",
                "year": 2023,
                "abstract": "The Temporal Sampling Framework (TSF) theorizes that the characteristic\nphonological difficulties of dyslexia are caused by an atypical oscillatory\nsampling at one or more temporal rates. The LEEDUCA study conducted a series of\nElectroencephalography (EEG) experiments on children listening to amplitude\nmodulated (AM) noise with slow-rythmic prosodic (0.5-1 Hz), syllabic (4-8 Hz)\nor the phoneme (12-40 Hz) rates, aimed at detecting differences in perception\nof oscillatory sampling that could be associated with dyslexia. The purpose of\nthis work is to check whether these differences exist and how they are related\nto children's performance in different language and cognitive tasks commonly\nused to detect dyslexia. To this purpose, temporal and spectral inter-channel\nEEG connectivity was estimated, and a denoising autoencoder (DAE) was trained\nto learn a low-dimensional representation of the connectivity matrices. This\nrepresentation was studied via correlation and classification analysis, which\nrevealed ability in detecting dyslexic subjects with an accuracy higher than\n0.8, and balanced accuracy around 0.7. Some features of the DAE representation\nwere significantly correlated ($p<0.005$) with children's performance in\nlanguage and cognitive tasks of the phonological hypothesis category such as\nphonological awareness and rapid symbolic naming, as well as reading efficiency\nand reading comprehension. Finally, a deeper analysis of the adjacency matrix\nrevealed a reduced bilateral connection between electrodes of the temporal lobe\n(roughly the primary auditory cortex) in DD subjects, as well as an increased\nconnectivity of the F7 electrode, placed roughly on Broca's area. These results\npave the way for a complementary assessment of dyslexia using more objective\nmethodologies such as EEG.",
                "authors": [
                    "Francisco Jesus Martinez-Murcia",
                    "Andr\u00e9s Ortiz",
                    "Juan Manuel G\u00f3rriz",
                    "Javier Ram\u00edrez",
                    "Pedro Javier Lopez-Perez",
                    "Miguel L\u00f3pez-Zamora",
                    "Juan Luis Luque"
                ],
                "url": [
                    "http://dx.doi.org/10.1142/S0129065720500379",
                    "http://arxiv.org/abs/2311.13876v1",
                    "http://arxiv.org/pdf/2311.13876v1"
                ],
                "primary_category": "q-bio.NC",
                "categories": [
                    "q-bio.NC",
                    "cs.NE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13874v1/1.0",
                "title": "Transitive inference as probabilistic preference learning",
                "year": 2023,
                "abstract": "Transitive Inference (TI) is a cognitive task that assesses an organism's\nability to infer novel relations between items based on previously acquired\nknowledge. TI is known for exhibiting various behavioral and neural signatures,\nsuch as the Serial Position Effect (SPE), Symbolic Distance Effect (SDE), and\nthe brain's capacity to maintain and merge separate ranking models. We propose\na novel framework that casts TI as a probabilistic preference learning task,\nusing one-parameter Mallows models. We present a series of simulations that\nhighlight the effectiveness of our novel approach. We show that the Mallows\nranking model natively reproduces SDE and SPE. Furthermore, extending the model\nusing Bayesian selection showcases its capacity to generate and merge ranking\nhypotheses as pairs with connecting symbols are encountered. Finally, we employ\nneural networks to replicate Mallows models, demonstrating how this framework\naligns with observed prefrontal neural activity during TI. Our innovative\napproach sheds new light on the nature of TI, emphasizing the potential of\nprobabilistic preference learning for unraveling its underlying neural\nmechanisms.",
                "authors": [
                    "Francesco Mannella",
                    "Giovanni Pezzulo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13874v1",
                    "http://arxiv.org/pdf/2311.13874v1"
                ],
                "primary_category": "q-bio.NC",
                "categories": [
                    "q-bio.NC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13871v1/1.0",
                "title": "Legal Requirements Analysis",
                "year": 2023,
                "abstract": "Modern software has been an integral part of everyday activities in many\ndisciplines and application contexts. Introducing intelligent automation by\nleveraging artificial intelligence (AI) led to break-throughs in many fields.\nThe effectiveness of AI can be attributed to several factors, among which is\nthe increasing availability of data. Regulations such as the general data\nprotection regulation (GDPR) in the European Union (EU) are introduced to\nensure the protection of personal data. Software systems that collect, process,\nor share personal data are subject to compliance with such regulations.\nDeveloping compliant software depends heavily on addressing legal requirements\nstipulated in applicable regulations, a central activity in the requirements\nengineering (RE) phase of the software development process. RE is concerned\nwith specifying and maintaining requirements of a system-to-be, including legal\nrequirements. Legal agreements which describe the policies organizations\nimplement for processing personal data can provide an additional source to\nregulations for eliciting legal requirements. In this chapter, we explore a\nvariety of methods for analyzing legal requirements and exemplify them on GDPR.\nSpecifically, we describe possible alternatives for creating machine-analyzable\nrepresentations from regulations, survey the existing automated means for\nenabling compliance verification against regulations, and further reflect on\nthe current challenges of legal requirements analysis.",
                "authors": [
                    "Sallam Abualhaija",
                    "Marcello Ceci",
                    "Lionel Briand"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13871v1",
                    "http://arxiv.org/pdf/2311.13871v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13870v1/1.0",
                "title": "L(M)V-IQL: Multiple Intention Inverse Reinforcement Learning for Animal\n  Behavior Characterization",
                "year": 2023,
                "abstract": "In advancing the understanding of decision-making processes, mathematical\nmodels, particularly Inverse Reinforcement Learning (IRL), have proven\ninstrumental in reconstructing animal's multiple intentions amidst complex\nbehaviors. Given the recent development of a continuous-time multi-intention\nIRL framework, there has been persistent inquiry into inferring discrete\ntime-varying reward functions with multiple intention IRL approaches. To tackle\nthe challenge, we introduce the Latent (Markov) Variable Inverse Q-learning\n(L(M)V-IQL) algorithms, a novel IRL framework tailored for accommodating\ndiscrete intrinsic rewards. Leveraging an Expectation-Maximization approach, we\ncluster observed trajectories into distinct intentions and independently solve\nthe IRL problem for each. Demonstrating the efficacy of L(M)V-IQL through\nsimulated experiments and its application to different real mouse behavior\ndatasets, our approach surpasses current benchmarks in animal behavior\nprediction, producing interpretable reward functions. This advancement holds\npromise for neuroscience and psychology, contributing to a deeper understanding\nof animal decision-making and uncovering underlying brain mechanisms.",
                "authors": [
                    "Hao Zhu",
                    "Brice De La Crompe",
                    "Gabriel Kalweit",
                    "Artur Schneider",
                    "Maria Kalweit",
                    "Ilka Diester",
                    "Joschka Boedecker"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13870v1",
                    "http://arxiv.org/pdf/2311.13870v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "q-bio.NC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13869v1/1.0",
                "title": "Rate- and temperature-dependent ductile-to-brittle fracture transition:\n  Experimental investigation and phase-field analysis for toffee",
                "year": 2023,
                "abstract": "The mechanical behaviour of many materials, including polymers or natural\nmaterials, significantly depends on the rate of deformation. As a consequence,\na rate-dependent ductile-to-brittle fracture transition may be observed. For\ntoffee-like caramel, this effect is particularly pronounced. At room\ntemperature, this confectionery may be extensively deformed at low strain\nrates, while it can behave highly brittle when the rate of deformation is\nraised. Likewise, the material behaviour does significantly depend on\ntemperature, and even a slight cooling may cause a significant embrittlement.\n  In this work, a thorough experimental investigation of the rate-dependent\ndeformation and fracture behaviour is presented. In addition, the influence of\ntemperature on the material response is studied. The experimental results form\nthe basis for a phase-field modelling of fracture. In order to derive the\ngoverning equations of the model, an incremental variational principle is\nintroduced. By means of the validated model, an analysis of the experimentally\nobserved ductile-to-brittle fracture transition is performed. In particular,\nthe coupling between the highly dissipative deformation behaviour of the bulk\nmaterial and the rate-dependent fracture resistance is discussed.",
                "authors": [
                    "Franz Damma\u00df",
                    "Dennis Schab",
                    "Harald Rohm",
                    "Markus K\u00e4stner"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13869v1",
                    "http://arxiv.org/pdf/2311.13869v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13865v1/1.0",
                "title": "Language-guided Few-shot Semantic Segmentation",
                "year": 2023,
                "abstract": "Few-shot learning is a promising way for reducing the label cost in new\ncategories adaptation with the guidance of a small, well labeled support set.\nBut for few-shot semantic segmentation, the pixel-level annotations of support\nimages are still expensive. In this paper, we propose an innovative solution to\ntackle the challenge of few-shot semantic segmentation using only language\ninformation, i.e.image-level text labels. Our approach involves a\nvision-language-driven mask distillation scheme, which contains a\nvision-language pretraining (VLP) model and a mask refiner, to generate high\nquality pseudo-semantic masks from text prompts. We additionally introduce a\ndistributed prototype supervision method and complementary correlation matching\nmodule to guide the model in digging precise semantic relations among support\nand query images. The experiments on two benchmark datasets demonstrate that\nour method establishes a new baseline for language-guided few-shot semantic\nsegmentation and achieves competitive results to recent vision-guided methods.",
                "authors": [
                    "Jing Wang",
                    "Yuang Liu",
                    "Qiang Zhou",
                    "Fan Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13865v1",
                    "http://arxiv.org/pdf/2311.13865v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13861v1/1.0",
                "title": "A Deep Reinforcement Learning Approach for Improving Age of Information\n  in Mission-Critical IoT",
                "year": 2023,
                "abstract": "The emerging mission-critical Internet of Things (IoT) play a vital role in\nremote healthcare, haptic interaction, and industrial automation, where timely\ndelivery of status updates is crucial. The Age of Information (AoI) is an\neffective metric to capture and evaluate information freshness at the\ndestination. A system design based solely on the optimization of the average\nAoI might not be adequate to capture the requirements of mission-critical\napplications, since averaging eliminates the effects of extreme events. In this\npaper, we introduce a Deep Reinforcement Learning (DRL)-based algorithm to\nimprove AoI in mission-critical IoT applications. The objective is to minimize\nan AoI-based metric consisting of the weighted sum of the average AoI and the\nprobability of exceeding an AoI threshold. We utilize the actor-critic method\nto train the algorithm to achieve optimized scheduling policy to solve the\nformulated problem. The performance of our proposed method is evaluated in a\nsimulated setup and the results show a significant improvement in terms of the\naverage AoI and the AoI violation probability compared to the related-work.",
                "authors": [
                    "Hossam Farag",
                    "Mikael Gidlund",
                    "Cedomir Stefanovic"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13861v1",
                    "http://arxiv.org/pdf/2311.13861v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13857v1/1.0",
                "title": "Challenges of Large Language Models for Mental Health Counseling",
                "year": 2023,
                "abstract": "The global mental health crisis is looming with a rapid increase in mental\ndisorders, limited resources, and the social stigma of seeking treatment. As\nthe field of artificial intelligence (AI) has witnessed significant\nadvancements in recent years, large language models (LLMs) capable of\nunderstanding and generating human-like text may be used in supporting or\nproviding psychological counseling. However, the application of LLMs in the\nmental health domain raises concerns regarding the accuracy, effectiveness, and\nreliability of the information provided. This paper investigates the major\nchallenges associated with the development of LLMs for psychological\ncounseling, including model hallucination, interpretability, bias, privacy, and\nclinical effectiveness. We explore potential solutions to these challenges that\nare practical and applicable to the current paradigm of AI. From our experience\nin developing and deploying LLMs for mental health, AI holds a great promise\nfor improving mental health care, if we can carefully navigate and overcome\npitfalls of LLMs.",
                "authors": [
                    "Neo Christopher Chung",
                    "George Dyer",
                    "Lennart Brocki"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13857v1",
                    "http://arxiv.org/pdf/2311.13857v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13856v1/1.0",
                "title": "Contagion dynamics in time-varying metapopulation networks with node's\n  activity and attractiveness",
                "year": 2023,
                "abstract": "The metapopulation network model is effectively used to study the spatial\nspread of epidemics with individuals mobility. Considering the time-varying\nnature of individual activity and the preferences for attractive destinations\nin population mobility, this paper develops a time-varying network model in\nwhich activity of a population is correlated with its attractiveness. Based on\nthe model, the spreading processes of the SIR disease on different correlated\nnetworks are studied, and global migration thresholds are derived. It is\nobserved that increasing the correlation between activity and attractiveness\nresults in a reduced outbreak threshold but suppresses the disease outbreak\nsize and introduces greater heterogeneity in the spatial distribution of\ninfected individuals. We also investigate the impact of non-pharmacological\ninterventions (self-isolation and self-protection) on the spread of epidemics\nin different correlation networks. The results show that the simultaneous\nimplementation of these measures is more effective in negatively correlated\nnetworks than in positively correlated or non-correlated networks, and the\nprevalence is reduced significantly. In addition, both self-isolation and\nself-protection strategies increase the migration threshold of the spreading\nand thus slow the spread of the epidemic. However, the effectiveness of each\nstrategy in reducing the density of infected populations varies depending on\ndifferent correlated networks. Self-protection is more effective in positively\ncorrelated networks, whereas self-isolation is more effective in negatively\ncorrelated networks. These findings contribute to a better understanding of\nepidemic spreading in large-scale time-varying metapopulation networks and\nprovide insights for epidemic prevention and control.",
                "authors": [
                    "Lang Zeng",
                    "Ming Tang",
                    "Ying Liu",
                    "Seung Yeop Yang",
                    "Younghae Do"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13856v1",
                    "http://arxiv.org/pdf/2311.13856v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13852v1/1.0",
                "title": "A Cross Attention Approach to Diagnostic Explainability using Clinical\n  Practice Guidelines for Depression",
                "year": 2023,
                "abstract": "The lack of explainability using relevant clinical knowledge hinders the\nadoption of Artificial Intelligence-powered analysis of unstructured clinical\ndialogue. A wealth of relevant, untapped Mental Health (MH) data is available\nin online communities, providing the opportunity to address the explainability\nproblem with substantial potential impact as a screening tool for both online\nand offline applications. We develop a method to enhance attention in popular\ntransformer models and generate clinician-understandable explanations for\nclassification by incorporating external clinical knowledge. Inspired by how\nclinicians rely on their expertise when interacting with patients, we leverage\nrelevant clinical knowledge to model patient inputs, providing meaningful\nexplanations for classification. This will save manual review time and engender\ntrust. We develop such a system in the context of MH using clinical practice\nguidelines (CPG) for diagnosing depression, a mental health disorder of global\nconcern. We propose an application-specific language model called ProcesS\nknowledge-infused cross ATtention (PSAT), which incorporates CPGs when\ncomputing attention. Through rigorous evaluation on three expert-curated\ndatasets related to depression, we demonstrate application-relevant\nexplainability of PSAT. PSAT also surpasses the performance of nine baseline\nmodels and can provide explanations where other baselines fall short. We\ntransform a CPG resource focused on depression, such as the Patient Health\nQuestionnaire (e.g. PHQ-9) and related questions, into a machine-readable\nontology using SNOMED-CT. With this resource, PSAT enhances the ability of\nmodels like GPT-3.5 to generate application-relevant explanations.",
                "authors": [
                    "Sumit Dalal",
                    "Deepa Tilwani",
                    "Manas Gaur",
                    "Sarika Jain",
                    "Valerie Shalin",
                    "Amit Seth"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13852v1",
                    "http://arxiv.org/pdf/2311.13852v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13848v1/1.0",
                "title": "Grammatical Error Correction via Mixed-Grained Weighted Training",
                "year": 2023,
                "abstract": "The task of Grammatical Error Correction (GEC) aims to automatically correct\ngrammatical errors in natural texts. Almost all previous works treat annotated\ntraining data equally, but inherent discrepancies in data are neglected. In\nthis paper, the inherent discrepancies are manifested in two aspects, namely,\naccuracy of data annotation and diversity of potential annotations. To this\nend, we propose MainGEC, which designs token-level and sentence-level training\nweights based on inherent discrepancies in accuracy and potential diversity of\ndata annotation, respectively, and then conducts mixed-grained weighted\ntraining to improve the training effect for GEC. Empirical evaluation shows\nthat whether in the Seq2Seq or Seq2Edit manner, MainGEC achieves consistent and\nsignificant performance improvements on two benchmark datasets, demonstrating\nthe effectiveness and superiority of the mixed-grained weighted training.\nFurther ablation experiments verify the effectiveness of designed weights of\nboth granularities in MainGEC.",
                "authors": [
                    "Jiahao Li",
                    "Quan Wang",
                    "Chiwei Zhu",
                    "Zhendong Mao",
                    "Yongdong Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13848v1",
                    "http://arxiv.org/pdf/2311.13848v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13847v2/1.0",
                "title": "Perceptual Image Compression with Cooperative Cross-Modal Side\n  Information",
                "year": 2023,
                "abstract": "The explosion of data has resulted in more and more associated text being\ntransmitted along with images. Inspired by from distributed source coding, many\nworks utilize image side information to enhance image compression. However,\nexisting methods generally do not consider using text as side information to\nenhance perceptual compression of images, even though the benefits of\nmultimodal synergy have been widely demonstrated in research. This begs the\nfollowing question: How can we effectively transfer text-level semantic\ndependencies to help image compression, which is only available to the decoder?\nIn this work, we propose a novel deep image compression method with text-guided\nside information to achieve a better rate-perception-distortion tradeoff.\nSpecifically, we employ the CLIP text encoder and an effective Semantic-Spatial\nAware block to fuse the text and image features. This is done by predicting a\nsemantic mask to guide the learned text-adaptive affine transformation at the\npixel level. Furthermore, we design a text-conditional generative adversarial\nnetworks to improve the perceptual quality of reconstructed images. Extensive\nexperiments involving four datasets and ten image quality assessment metrics\ndemonstrate that the proposed approach achieves superior results in terms of\nrate-perception trade-off and semantic distortion.",
                "authors": [
                    "Shiyu Qin",
                    "Bin Chen",
                    "Yujun Huang",
                    "Baoyi An",
                    "Tao Dai",
                    "Shu-Tao Xia"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13847v2",
                    "http://arxiv.org/pdf/2311.13847v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.IT",
                    "eess.IV",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13842v1/1.0",
                "title": "Fast neutrino-flavor swap in high-energy astrophysical environments",
                "year": 2023,
                "abstract": "We assert that non-linear features of fast neutrino-flavor conversion (FFC)\ncan be qualitatively different between core-collapse supernovae (CCSNe) and\nbinary neutron star mergers (BNSMs). This argument arises from recent global\nFFC simulations in BNSM, in which fast flavor swap (FFS) emerges in very narrow\nspatial regions, whereas neutrinos in CCSN tend to evolve towards flavor\nequipartition. In this {\\it Letter}, we provide the physical mechanism of FFS\nbased on a colliding neutrino beam model. Neutrinos/antineutrinos can undergo\nFFS when they propagate in ambient neutrino gas that propagates in the opposite\ndirection and also has the opposite sign of ELN-XLN, where ELN and XLN denote\nelectron- and heavy-leptonic neutrino number, respectively. Such environments\ncan be naturally realized in BNSMs, whereas they are unlikely in CCSNe unless\nthe neutrino sphere is strongly deformed aspherically. Our study exhibits the\ndiversity of non-linear dynamics of FFC.",
                "authors": [
                    "Masamichi Zaizen",
                    "Hiroki Nagakura"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13842v1",
                    "http://arxiv.org/pdf/2311.13842v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE",
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13841v1/1.0",
                "title": "Adversarial defense based on distribution transfer",
                "year": 2023,
                "abstract": "The presence of adversarial examples poses a significant threat to deep\nlearning models and their applications. Existing defense methods provide\ncertain resilience against adversarial examples, but often suffer from\ndecreased accuracy and generalization performance, making it challenging to\nachieve a trade-off between robustness and generalization. To address this, our\npaper interprets the adversarial example problem from the perspective of sample\ndistribution and proposes a defense method based on distribution shift,\nleveraging the distribution transfer capability of a diffusion model for\nadversarial defense. The core idea is to exploit the discrepancy between normal\nand adversarial sample distributions to achieve adversarial defense using a\npretrained diffusion model. Specifically, an adversarial sample undergoes a\nforward diffusion process, moving away from the source distribution, followed\nby a reverse process guided by the protected model (victim model) output to map\nit back to the normal distribution. Experimental evaluations on CIFAR10 and\nImageNet30 datasets are conducted, comparing with adversarial training and\ninput preprocessing methods. For infinite-norm attacks with 8/255 perturbation,\naccuracy rates of 78.1% and 83.5% are achieved, respectively. For 2-norm\nattacks with 128/255 perturbation, accuracy rates are 74.3% and 82.5%.\nAdditional experiments considering perturbation amplitude, diffusion\niterations, and adaptive attacks also validate the effectiveness of the\nproposed method. Results demonstrate that even when the attacker has knowledge\nof the defense, the proposed distribution-based method effectively withstands\nadversarial examples. It fills the gaps of traditional approaches, restoring\nhigh-quality original samples and showcasing superior performance in model\nrobustness and generalization.",
                "authors": [
                    "Jiahao Chen",
                    "Diqun Yan",
                    "Li Dong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13841v1",
                    "http://arxiv.org/pdf/2311.13841v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13839v1/1.0",
                "title": "Circular orbits and accretion disk around AdS black holes surrounded by\n  dark fluid with Chaplygin-like equation of state",
                "year": 2023,
                "abstract": "In the present work we study the geodesic motion and accretion process of a\ntest particle near an Anti-de Sitter (ADS) BH surrounded by a dark fluid with a\nChaplygin-like equation. Within the defined paradigm, we investigate on the\nequatorial plane and examine circular geodesics along with their features\nrelated to stabilities, radiation energy flux, oscillations and orbits. The\ngeneral form of the fluid accretion onto the AdS BH through dynamical analysis\nand mass expansion also has discussed in a depth. Additionally, a few more\ninteresting topics, e.g. the effective potential, angular momentum, specific\nenergy, radiation energy and epicyclic frequencies have also been examined\nthoroughly. All the attributes are physically acceptable within the\nobservational signatures and ranges.",
                "authors": [
                    "G. Mustafa",
                    "S. K. Maurya",
                    "A. Ditta",
                    "Saibal Ray",
                    "Farruh Atamurotov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13839v1",
                    "http://arxiv.org/pdf/2311.13839v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13834v1/1.0",
                "title": "Asymptotically Tight Bayesian Cram\u00e9r-Rao Bound",
                "year": 2023,
                "abstract": "Performance bounds for parameter estimation play a crucial role in\nstatistical signal processing theory and applications. Two widely recognized\nbounds are the Cram\\'{e}r-Rao bound (CRB) in the non-Bayesian framework, and\nthe Bayesian CRB (BCRB) in the Bayesian framework. However, unlike the CRB, the\nBCRB is asymptotically unattainable in general, and its equality condition is\nrestrictive. This paper introduces an extension of the\nBobrovsky--Mayer-Wolf--Zakai class of bounds, also known as the weighted BCRB\n(WBCRB). The WBCRB is optimized by tuning the weighting function in the scalar\ncase. Based on this result, we propose an asymptotically tight version of the\nbound called AT-BCRB. We prove that the AT-BCRB is asymptotically attained by\nthe maximum {\\it a-posteriori} probability (MAP) estimator. Furthermore, we\nextend the WBCRB and the AT-BCRB to the case of vector parameters. The proposed\nbounds are evaluated in several fundamental signal processing examples, such as\nvariance estimation of white Gaussian process, direction-of-arrival estimation,\nand mean estimation of Gaussian process with unknown variance and prior\nstatistical information. It is shown that unlike the BCRB, the proposed bounds\nare asymptotically attainable and coincide with the expected CRB (ECRB). The\nECRB, which imposes uniformly unbiasedness, cannot serve as a valid lower bound\nin the Bayesian framework, while the proposed bounds are valid for any\nestimator.",
                "authors": [
                    "Ori Aharon",
                    "Joseph Tabrikian"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13834v1",
                    "http://arxiv.org/pdf/2311.13834v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13833v1/1.0",
                "title": "Lego: Learning to Disentangle and Invert Concepts Beyond Object\n  Appearance in Text-to-Image Diffusion Models",
                "year": 2023,
                "abstract": "Diffusion models have revolutionized generative content creation and\ntext-to-image (T2I) diffusion models in particular have increased the creative\nfreedom of users by allowing scene synthesis using natural language. T2I models\nexcel at synthesizing concepts such as nouns, appearances, and styles. To\nenable customized content creation based on a few example images of a concept,\nmethods such as Textual Inversion and DreamBooth invert the desired concept and\nenable synthesizing it in new scenes. However, inverting more general concepts\nthat go beyond object appearance and style (adjectives and verbs) through\nnatural language, remains a challenge. Two key characteristics of these\nconcepts contribute to the limitations of current inversion methods. 1)\nAdjectives and verbs are entangled with nouns (subject) and can hinder\nappearance-based inversion methods, where the subject appearance leaks into the\nconcept embedding and 2) describing such concepts often extends beyond single\nword embeddings (being frozen in ice, walking on a tightrope, etc.) that\ncurrent methods do not handle.\n  In this study, we introduce Lego, a textual inversion method designed to\ninvert subject entangled concepts from a few example images. Lego disentangles\nconcepts from their associated subjects using a simple yet effective Subject\nSeparation step and employs a Context Loss that guides the inversion of\nsingle/multi-embedding concepts. In a thorough user study, Lego-generated\nconcepts were preferred over 70% of the time when compared to the baseline.\nAdditionally, visual question answering using a large language model suggested\nLego-generated concepts are better aligned with the text description of the\nconcept.",
                "authors": [
                    "Saman Motamed",
                    "Danda Pani Paudel",
                    "Luc Van Gool"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13833v1",
                    "http://arxiv.org/pdf/2311.13833v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13832v1/1.0",
                "title": "Dynamic Operating Envelopes Embedded Peer-to-Peer-to-Grid Energy Trading",
                "year": 2023,
                "abstract": "A novel decentralized peer-to-peer-to-grid (P2P2G) trading mechanism\nconsidering distribution network integrity is proposed. In order to direct\nprosumers' peer-to-peer (P2P) trading behavior to be grid-friendly, the\nproposed method incorporates Dynamic Operating Envelopes (DOEs) into the\nexisting P2P2G trading. Moreover, DOEs are determined through negotiations\nbetween the distribution system operator (DSO) and prosumers alongside the\nprocess of P2P trading, avoiding compromising prosumers' privacy and network\nparameters leakage. To reduce communication costs during P2P trading, a variant\nof the alternating direction method of multipliers (ADMM), i.e.,\ncommunication-censored ADMM (COCA) is used to solve the P2P2G trading problem.\nFinally, the DOE price is shown to be comprised of several economically\ninterpretable components. Simulations validate the effectiveness of the\nproposed mechanism.",
                "authors": [
                    "Zhisen Jiang",
                    "Ye Guo",
                    "Hongbin Sun",
                    "Jianxiao Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13832v1",
                    "http://arxiv.org/pdf/2311.13832v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13831v1/1.0",
                "title": "Posterior Distillation Sampling",
                "year": 2023,
                "abstract": "We introduce Posterior Distillation Sampling (PDS), a novel optimization\nmethod for parametric image editing based on diffusion models. Existing\noptimization-based methods, which leverage the powerful 2D prior of diffusion\nmodels to handle various parametric images, have mainly focused on generation.\nUnlike generation, editing requires a balance between conforming to the target\nattribute and preserving the identity of the source content. Recent 2D image\nediting methods have achieved this balance by leveraging the stochastic latent\nencoded in the generative process of diffusion models. To extend the editing\ncapabilities of diffusion models shown in pixel space to parameter space, we\nreformulate the 2D image editing method into an optimization form named PDS.\nPDS matches the stochastic latents of the source and the target, enabling the\nsampling of targets in diverse parameter spaces that align with a desired\nattribute while maintaining the source's identity. We demonstrate that this\noptimization resembles running a generative process with the target attribute,\nbut aligning this process with the trajectory of the source's generative\nprocess. Extensive editing results in Neural Radiance Fields and Scalable\nVector Graphics representations demonstrate that PDS is capable of sampling\ntargets to fulfill the aforementioned balance across various parameter spaces.",
                "authors": [
                    "Juil Koo",
                    "Chanho Park",
                    "Minhyuk Sung"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13831v1",
                    "http://arxiv.org/pdf/2311.13831v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13830v1/1.0",
                "title": "Self-organized biodiversity in biotic resource systems",
                "year": 2023,
                "abstract": "What determines biodiversity in nature is a prominent issue in ecology,\nespecially in biotic resource systems that are typically devoid of\ncross-feeding. Here, we show that by incorporating pairwise encounters among\nconsumer individuals within the same species, a multitude of consumer species\ncan self-organize to coexist in a well-mixed system with one or a few biotic\nresource species. The coexistence modes can manifest as either stable steady\nstates or self-organized oscillations. Importantly, all coexistence states are\nrobust to stochasticity, whether employing the stochastic simulation algorithm\nor individual-based modeling. Our model quantitatively illustrates species\ndistribution patterns across a wide range of ecological communities and can be\nbroadly used to explain biodiversity in many biotic resource systems.",
                "authors": [
                    "Ju Kang",
                    "Shijie Zhang",
                    "Yiyuan Niu",
                    "Xin Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13830v1",
                    "http://arxiv.org/pdf/2311.13830v1"
                ],
                "primary_category": "q-bio.PE",
                "categories": [
                    "q-bio.PE",
                    "cond-mat.stat-mech",
                    "nlin.AO",
                    "physics.bio-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13828v1/1.0",
                "title": "All-antiferromagnetic electrically controlled memory on silicon\n  featuring large tunneling magnetoresistance",
                "year": 2023,
                "abstract": "Antiferromagnetic (AFM) materials are a pathway to spintronic memory and\ncomputing devices with unprecedented speed, energy efficiency, and bit density.\nRealizing this potential requires AFM devices with simultaneous electrical\nwriting and reading of information, which are also compatible with established\nsilicon-based manufacturing. Recent experiments have shown tunneling\nmagnetoresistance (TMR) readout in epitaxial AFM tunnel junctions. However,\nthese TMR structures were not grown using a silicon-compatible deposition\nprocess, and controlling their AFM order required external magnetic fields.\nHere we show three-terminal AFM tunnel junctions based on the noncollinear\nantiferromagnet PtMn3, sputter-deposited on silicon. The devices simultaneously\nexhibit electrical switching using electric currents, and electrical readout by\na large room-temperature TMR effect. First-principles calculations explain the\nTMR in terms of the momentum-resolved spin-dependent tunneling conduction in\ntunnel junctions with noncollinear AFM electrodes.",
                "authors": [
                    "Jiacheng Shi",
                    "Victor Lopez-Dominguez",
                    "Sevdenur Arpaci",
                    "Vinod K. Sangwan",
                    "Farzad Mahfouzi",
                    "Jinwoong Kim",
                    "Jordan G. Athas",
                    "Mohammad Hamdi",
                    "Can Aygen",
                    "Charudatta Phatak",
                    "Mario Carpentieri",
                    "Jidong S. Jiang",
                    "Matthew A. Grayson",
                    "Nicholas Kioussis",
                    "Giovanni Finocchio",
                    "Mark C. Hersam",
                    "Pedram Khalili Amiri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13828v1",
                    "http://arxiv.org/pdf/2311.13828v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13824v1/1.0",
                "title": "Constraint-Guided Online Data Selection for Scalable Data-Driven Safety\n  Filters in Uncertain Robotic Systems",
                "year": 2023,
                "abstract": "As the use of autonomous robotic systems expands in tasks that are complex\nand challenging to model, the demand for robust data-driven control methods\nthat can certify safety and stability in uncertain conditions is increasing.\nHowever, the practical implementation of these methods often faces scalability\nissues due to the growing amount of data points with system complexity, and a\nsignificant reliance on high-quality training data. In response to these\nchallenges, this study presents a scalable data-driven controller that\nefficiently identifies and infers from the most informative data points for\nimplementing data-driven safety filters. Our approach is grounded in the\nintegration of a model-based certificate function-based method and Gaussian\nProcess (GP) regression, reinforced by a novel online data selection algorithm\nthat reduces time complexity from quadratic to linear relative to dataset size.\nEmpirical evidence, gathered from successful real-world cart-pole swing-up\nexperiments and simulated locomotion of a five-link bipedal robot, demonstrates\nthe efficacy of our approach. Our findings reveal that our efficient online\ndata selection algorithm, which strategically selects key data points, enhances\nthe practicality and efficiency of data-driven certifying filters in complex\nrobotic systems, significantly mitigating scalability concerns inherent in\nnonparametric learning-based control methods.",
                "authors": [
                    "Jason J. Choi",
                    "Fernando Casta\u00f1eda",
                    "Wonsuhk Jung",
                    "Bike Zhang",
                    "Claire J. Tomlin",
                    "Koushil Sreenath"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13824v1",
                    "http://arxiv.org/pdf/2311.13824v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13821v1/1.0",
                "title": "HypUC: Hyperfine Uncertainty Calibration with Gradient-boosted\n  Corrections for Reliable Regression on Imbalanced Electrocardiograms",
                "year": 2023,
                "abstract": "The automated analysis of medical time series, such as the electrocardiogram\n(ECG), electroencephalogram (EEG), pulse oximetry, etc, has the potential to\nserve as a valuable tool for diagnostic decisions, allowing for remote\nmonitoring of patients and more efficient use of expensive and time-consuming\nmedical procedures. Deep neural networks (DNNs) have been demonstrated to\nprocess such signals effectively. However, previous research has primarily\nfocused on classifying medical time series rather than attempting to regress\nthe continuous-valued physiological parameters central to diagnosis. One\nsignificant challenge in this regard is the imbalanced nature of the dataset,\nas a low prevalence of abnormal conditions can lead to heavily skewed data that\nresults in inaccurate predictions and a lack of certainty in such predictions\nwhen deployed. To address these challenges, we propose HypUC, a framework for\nimbalanced probabilistic regression in medical time series, making several\ncontributions. (i) We introduce a simple kernel density-based technique to\ntackle the imbalanced regression problem with medical time series. (ii)\nMoreover, we employ a probabilistic regression framework that allows\nuncertainty estimation for the predicted continuous values. (iii) We also\npresent a new approach to calibrate the predicted uncertainty further. (iv)\nFinally, we demonstrate a technique to use calibrated uncertainty estimates to\nimprove the predicted continuous value and show the efficacy of the calibrated\nuncertainty estimates to flag unreliable predictions. HypUC is evaluated on a\nlarge, diverse, real-world dataset of ECGs collected from millions of patients,\noutperforming several conventional baselines on various diagnostic tasks,\nsuggesting a potential use-case for the reliable clinical deployment of deep\nlearning models.",
                "authors": [
                    "Uddeshya Upadhyay",
                    "Sairam Bade",
                    "Arjun Puranik",
                    "Shahir Asfahan",
                    "Melwin Babu",
                    "Francisco Lopez-Jimenez",
                    "Samuel J. Asirvatham",
                    "Ashim Prasad",
                    "Ajit Rajasekharan",
                    "Samir Awasthi",
                    "Rakesh Barve"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13821v1",
                    "http://arxiv.org/pdf/2311.13821v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CE",
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13806v1/1.0",
                "title": "AdaTyper: Adaptive Semantic Column Type Detection",
                "year": 2023,
                "abstract": "Understanding the semantics of relational tables is instrumental for\nautomation in data exploration and preparation systems. A key source for\nunderstanding a table is the semantics of its columns. With the rise of deep\nlearning, learned table representations are now available, which can be applied\nfor semantic type detection and achieve good performance on benchmarks.\nNevertheless, we observe a gap between this performance and its applicability\nin practice. In this paper, we propose AdaTyper to address one of the most\ncritical deployment challenges: adaptation. AdaTyper uses weak-supervision to\nadapt a hybrid type predictor towards new semantic types and shifted data\ndistributions at inference time, using minimal human feedback. The hybrid type\npredictor of AdaTyper combines rule-based methods and a light machine learning\nmodel for semantic column type detection. We evaluate the adaptation\nperformance of AdaTyper on real-world database tables hand-annotated with\nsemantic column types through crowdsourcing and find that the f1-score improves\nfor new and existing types. AdaTyper approaches an average precision of 0.6\nafter only seeing 5 examples, significantly outperforming existing adaptation\nmethods based on human-provided regular expressions or dictionaries.",
                "authors": [
                    "Madelon Hulsebos",
                    "Paul Groth",
                    "\u00c7a\u011fatay Demiralp"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13806v1",
                    "http://arxiv.org/pdf/2311.13806v1"
                ],
                "primary_category": "cs.DB",
                "categories": [
                    "cs.DB",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13795v2/1.0",
                "title": "Model Independent Dark Matter Properties from Cosmic Growth",
                "year": 2023,
                "abstract": "Dark matter dominates the matter budget of the universe but its nature is\nunknown. Deviations from the standard model, where dark matter clusters with\nthe same gravitational strength as baryons, and has the same pressureless\nequation of state as baryons, can be tested by cosmic growth measurements. We\ntake a model independent approach, allowing deviations in bins of redshift, and\ncompute the constraints enabled by ongoing cosmic structure surveys through\nredshift space distortions and peculiar velocities. These can produce\nconstraints at the $3-14\\%$ level in four independent redshift bins over\n$z=[0,4]$.",
                "authors": [
                    "Tilek Zhumabek",
                    "Mikhail Denissenya",
                    "Eric V. Linder"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13795v2",
                    "http://arxiv.org/pdf/2311.13795v2"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13793v1/1.0",
                "title": "Evidential Active Recognition: Intelligent and Prudent Open-World\n  Embodied Perception",
                "year": 2023,
                "abstract": "Active recognition enables robots to intelligently explore novel\nobservations, thereby acquiring more information while circumventing undesired\nviewing conditions. Recent approaches favor learning policies from simulated or\ncollected data, wherein appropriate actions are more frequently selected when\nthe recognition is accurate. However, most recognition modules are developed\nunder the closed-world assumption, which makes them ill-equipped to handle\nunexpected inputs, such as the absence of the target object in the current\nobservation. To address this issue, we propose treating active recognition as a\nsequential evidence-gathering process, providing by-step uncertainty\nquantification and reliable prediction under the evidence combination theory.\nAdditionally, the reward function developed in this paper effectively\ncharacterizes the merit of actions when operating in open-world environments.\nTo evaluate the performance, we collect a dataset from an indoor simulator,\nencompassing various recognition challenges such as distance, occlusion levels,\nand visibility. Through a series of experiments on recognition and robustness\nanalysis, we demonstrate the necessity of introducing uncertainties to active\nrecognition and the superior performance of the proposed method.",
                "authors": [
                    "Lei Fan",
                    "Mingfu Liang",
                    "Yunxuan Li",
                    "Gang Hua",
                    "Ying Wu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13793v1",
                    "http://arxiv.org/pdf/2311.13793v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13789v1/1.0",
                "title": "Knowledge Distillation Based Semantic Communications For Multiple Users",
                "year": 2023,
                "abstract": "Deep learning (DL) has shown great potential in revolutionizing the\ntraditional communications system. Many applications in communications have\nadopted DL techniques due to their powerful representation ability. However,\nthe learning-based methods can be dependent on the training dataset and perform\nworse on unseen interference due to limited model generalizability and\ncomplexity. In this paper, we consider the semantic communication (SemCom)\nsystem with multiple users, where there is a limited number of training samples\nand unexpected interference. To improve the model generalization ability and\nreduce the model size, we propose a knowledge distillation (KD) based system\nwhere Transformer based encoder-decoder is implemented as the semantic\nencoder-decoder and fully connected neural networks are implemented as the\nchannel encoder-decoder. Specifically, four types of knowledge transfer and\nmodel compression are analyzed. Important system and model parameters are\nconsidered, including the level of noise and interference, the number of\ninterfering users and the size of the encoder and decoder. Numerical results\ndemonstrate that KD significantly improves the robustness and the\ngeneralization ability when applied to unexpected interference, and it reduces\nthe performance loss when compressing the model size.",
                "authors": [
                    "Chenguang Liu",
                    "Yuxin Zhou",
                    "Yunfei Chen",
                    "Shuang-Hua Yang"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/TWC.2023.3336941",
                    "http://arxiv.org/abs/2311.13789v1",
                    "http://arxiv.org/pdf/2311.13789v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13787v1/1.0",
                "title": "A Fast Power Spectrum Sensing Solution for Generalized Coprime Sampling",
                "year": 2023,
                "abstract": "The growing scarcity of spectrum resources, wideband spectrum sensing is\nrequired to process a prohibitive volume of data at a high sampling rate. For\nsome applications, spectrum estimation only requires second-order statistics.\nIn this case, a fast power spectrum sensing solution is proposed based on the\ngeneralized coprime sampling. By exploring the sensing vector inherent\nstructure, the autocorrelation sequence of inputs can be reconstructed from\nsub-Nyquist samples by only utilizing the parallel Fourier transform and simple\nmultiplication operations. Thus, it takes less time than the state-of-the-art\nmethods while maintaining the same performance, and it achieves higher\nperformance than the existing methods within the same execution time, without\nthe need for pre-estimating the number of inputs. Furthermore, the influence of\nthe model mismatch has only a minor impact on the estimation performance, which\nallows for more efficient use of the spectrum resource in a distributed swarm\nscenario. Simulation results demonstrate the low complexity in sampling and\ncomputation, making it a more practical solution for real-time and distributed\nwideband spectrum sensing applications.",
                "authors": [
                    "Kaili Jiang",
                    "Dechang Wang",
                    "Kailun Tian",
                    "Hancong Feng",
                    "Yuxin Zhao",
                    "Junyu Yuan",
                    "Bin Tang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13787v1",
                    "http://arxiv.org/pdf/2311.13787v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13785v1/1.0",
                "title": "Federated Learning Assisted Distributed Energy Optimization",
                "year": 2023,
                "abstract": "The increased penetration of distributed energy resources and the adoption of\nsensing and control technologies are driving the transition from our current\ncentralized electric grid to a distributed system controlled by multiple\nentities (agents). The Transactive Energy Community (TEC) serves as an\nestablished example of this transition. Distributed energy management\napproaches can effectively address the scalability, resilience, and privacy\nrequirements of the evolving grid. In this context, the accuracy of agents'\nestimations becomes crucial for the performance of distributed and multi-agent\ndecision-making paradigms. This paper specifically focuses on integrating\nFederated Learning (FL) with the multi-agent energy management procedure. FL is\nutilized to forecast agents' local energy generation and demand, aiming to\naccelerate the convergence of the distributed decision-making process. To\nenhance energy aggregation in TECs, we propose an FL-assisted distributed\nConsensus + Innovations approach. The results demonstrate that employing FL\nsignificantly reduces errors in predicting net power demand. The improved\nforecast accuracy, in turn, introduces less error in the distributed\noptimization process, thereby enhancing its convergence behavior.",
                "authors": [
                    "Yuhan Du",
                    "Nuno Mendes",
                    "Simin Rasouli",
                    "Javad Mohammadi",
                    "Pedro Moura"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13785v1",
                    "http://arxiv.org/pdf/2311.13785v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13784v1/1.0",
                "title": "DaG LLM ver 1.0: Pioneering Instruction-Tuned Language Modeling for\n  Korean NLP",
                "year": 2023,
                "abstract": "This paper presents the DaG LLM (David and Goliath Large Language Model), a\nlanguage model specialized for Korean and fine-tuned through Instruction Tuning\nacross 41 tasks within 13 distinct categories.",
                "authors": [
                    "Dongjun Jang",
                    "Sangah Lee",
                    "Sungjoo Byun",
                    "Jinwoong Kim",
                    "Jean Seo",
                    "Minseok Kim",
                    "Soyeon Kim",
                    "Chaeyoung Oh",
                    "Jaeyoon Kim",
                    "Hyemi Jo",
                    "Hyopil Shin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13784v1",
                    "http://arxiv.org/pdf/2311.13784v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13779v1/1.0",
                "title": "Detection and Identification Accuracy of PCA-Accelerated Real-Time\n  Processing of Hyperspectral Imagery",
                "year": 2023,
                "abstract": "Real-time or near real-time hyperspectral detection and identification are\nextremely useful and needed in many fields. These data sets can be quite large,\nand the algorithms can require numerous computations that slow the process\ndown. A common way of speeding up the process is to use principal component\nanalysis (PCA) for dimension reduction. In the reduced dimensional space,\nprovided by a subset of the principal components, fewer computations are needed\nto process the data resulting in a faster run time. In this paper, we propose a\nway to further decrease the time required to use PCA by investigating how many\nprincipal components may be omitted with minimal impact on the detection rate.\nUsing ACE to perform the detection, and then probability, and spectral fit for\nidentification, we find that the number of principal components can be reduced\nby a substantial amount before seeing a noticeable change in detection rates.",
                "authors": [
                    "Abigail Basener",
                    "Meagan Herald"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13779v1",
                    "http://arxiv.org/pdf/2311.13779v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13778v1/1.0",
                "title": "Accurate Prediction of Experimental Band Gaps from Large Language\n  Model-Based Data Extraction",
                "year": 2023,
                "abstract": "Machine learning is transforming materials discovery by providing rapid\npredictions of material properties, which enables large-scale screening for\ntarget materials. However, such models require training data. While automated\ndata extraction from scientific literature has potential, current\nauto-generated datasets often lack sufficient accuracy and critical structural\nand processing details of materials that influence the properties. Using band\ngap as an example, we demonstrate Large language model (LLM)-prompt-based\nextraction yields an order of magnitude lower error rate. Combined with\nadditional prompts to select a subset of experimentally measured properties\nfrom pure, single-crystalline bulk materials, this results in an automatically\nextracted dataset that's larger and more diverse than the largest existing\nhuman-curated database of experimental band gaps. Compared to the existing\nhuman-curated database, we show the model trained on our extracted database\nachieves a 19% reduction in the mean absolute error of predicted band gaps.\nFinally, we demonstrate that LLMs are able to train models predicting band gap\non the extracted data, achieving an automated pipeline of data extraction to\nmaterials property prediction.",
                "authors": [
                    "Samuel J. Yang",
                    "Shutong Li",
                    "Subhashini Venugopalan",
                    "Vahe Tshitoyan",
                    "Muratahan Aykol",
                    "Amil Merchant",
                    "Ekin Dogus Cubuk",
                    "Gowoon Cheon"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13778v1",
                    "http://arxiv.org/pdf/2311.13778v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00039v1/1.0",
                "title": "Acoustic Cybersecurity: Exploiting Voice-Activated Systems",
                "year": 2023,
                "abstract": "In this study, we investigate the emerging threat of inaudible acoustic\nattacks targeting digital voice assistants, a critical concern given their\nprojected prevalence to exceed the global population by 2024. Our research\nextends the feasibility of these attacks across various platforms like Amazon's\nAlexa, Android, iOS, and Cortana, revealing significant vulnerabilities in\nsmart devices. The twelve attack vectors identified include successful\nmanipulation of smart home devices and automotive systems, potential breaches\nin military communication, and challenges in critical infrastructure security.\nWe quantitatively show that attack success rates hover around 60%, with the\nability to activate devices remotely from over 100 feet away. Additionally,\nthese attacks threaten critical infrastructure, emphasizing the need for\nmultifaceted defensive strategies combining acoustic shielding, advanced signal\nprocessing, machine learning, and robust user authentication to mitigate these\nrisks.",
                "authors": [
                    "Forrest McKee",
                    "David Noever"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00039v1",
                    "http://arxiv.org/pdf/2312.00039v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR",
                    "cs.LG",
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13775v1/1.0",
                "title": "Mesoscopic ultrafast nonlinear optics -- The emergence of multimode\n  quantum non-Gaussian physics",
                "year": 2023,
                "abstract": "Over the last few decades, nonlinear optics has become significantly more\nnonlinear, traversing nearly a billionfold improvement in energy efficiency,\nwith ultrafast nonlinear nanophotonics in particular emerging as a frontier for\ncombining both spatial and temporal engineering. At present, cutting-edge\nexperiments in nonlinear nanophotonics place us just above the mesoscopic\nregime, where a few hundred photons suffice to trigger nonlinear saturation. In\ncontrast to classical or deep-quantum optics, the mesoscale is characterized by\ndynamical interactions between mean-field, Gaussian, and non-Gaussian quantum\nfeatures, all within a close hierarchy of scales. When combined with the\ninherent multimode complexity of optical fields, such hybrid quantum-classical\ndynamics present theoretical, experimental, and engineering challenges to the\ncontemporary framework of quantum optics. In this review, we highlight the\nunique physics that emerges in multimode nonlinear optics at the mesoscale and\noutline key principles for exploiting both classical and quantum features to\nengineer novel functionalities. We briefly survey the experimental landscape\nand draw attention to outstanding technical challenges in materials, dispersion\nengineering, and device design for accessing mesoscopic operation. Finally, we\nspeculate on how these capabilities might usher in some new paradigms in\nquantum photonics, from quantum-augmented information processing to\nnonclassical-light-driven dynamics and phenomena to all-optical non-Gaussian\nmeasurement and sensing. The physics unlocked at the mesoscale present\nsignificant challenges and opportunities in theory and experiment alike, and\nthis review is intended to serve as a guidepost as we begin to navigate this\nnew frontier in ultrafast quantum nonlinear optics.",
                "authors": [
                    "Ryotatsu Yanagimoto",
                    "Edwin Ng",
                    "Marc Jankowski",
                    "Rajveer Nehra",
                    "Timothy P. McKenna",
                    "Tatsuhiro Onodera",
                    "Logan G. Wright",
                    "Ryan Hamerly",
                    "Alireza Marandi",
                    "M. M. Fejer",
                    "Hideo Mabuchi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13775v1",
                    "http://arxiv.org/pdf/2311.13775v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13774v1/1.0",
                "title": "Learning Hierarchical Polynomials with Three-Layer Neural Networks",
                "year": 2023,
                "abstract": "We study the problem of learning hierarchical polynomials over the standard\nGaussian distribution with three-layer neural networks. We specifically\nconsider target functions of the form $h = g \\circ p$ where $p : \\mathbb{R}^d\n\\rightarrow \\mathbb{R}$ is a degree $k$ polynomial and $g: \\mathbb{R}\n\\rightarrow \\mathbb{R}$ is a degree $q$ polynomial. This function class\ngeneralizes the single-index model, which corresponds to $k=1$, and is a\nnatural class of functions possessing an underlying hierarchical structure. Our\nmain result shows that for a large subclass of degree $k$ polynomials $p$, a\nthree-layer neural network trained via layerwise gradient descent on the square\nloss learns the target $h$ up to vanishing test error in\n$\\widetilde{\\mathcal{O}}(d^k)$ samples and polynomial time. This is a strict\nimprovement over kernel methods, which require $\\widetilde \\Theta(d^{kq})$\nsamples, as well as existing guarantees for two-layer networks, which require\nthe target function to be low-rank. Our result also generalizes prior works on\nthree-layer neural networks, which were restricted to the case of $p$ being a\nquadratic. When $p$ is indeed a quadratic, we achieve the\ninformation-theoretically optimal sample complexity\n$\\widetilde{\\mathcal{O}}(d^2)$, which is an improvement over prior\nwork~\\citep{nichani2023provable} requiring a sample size of\n$\\widetilde\\Theta(d^4)$. Our proof proceeds by showing that during the initial\nstage of training the network performs feature learning to recover the feature\n$p$ with $\\widetilde{\\mathcal{O}}(d^k)$ samples. This work demonstrates the\nability of three-layer neural networks to learn complex features and as a\nresult, learn a broad class of hierarchical functions.",
                "authors": [
                    "Zihao Wang",
                    "Eshaan Nichani",
                    "Jason D. Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13774v1",
                    "http://arxiv.org/pdf/2311.13774v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13773v1/1.0",
                "title": "Dynamics and rheology of 2D colloidal crystals with active anisotropic\n  impurities",
                "year": 2023,
                "abstract": "Active motion at complex fluid-fluid interfaces is a ubiquitous phenomenon in\nnature. However, an intriguing question that is not fully addressed is how\nactive motion affects and gets influenced by its complex environment. Here, we\ndesign a 2D colloidal crystal containing active particles as a model system to\nunderstand the mechanics of complex interfaces in the presence of activity. We\ncharacterize the dynamics, rheology and phase behavior of 2D colloidal crystals\nformed using spherical polystyrene (PS) particles in the presence of active\nPS-Platinum Janus particles. In the presence of activity, the overall crystal\nbecomes dynamic with a heterogeneous spatial distribution of disorder. Through\nparticle-tracking microrheology and interfacial shear rheology, we report the\ndiscovery of a phase transition from solid-like to liquid-like interface driven\nby the active motion of a small number of active impurities in the crystal. The\nlocal perturbations induced by the active impurities have long-range effects on\nthe dynamics of particles in 2D colloidal crystals modifying their overall\nviscoelasticity. The correlations between microstructure and dynamics from our\nexperiments can provide insights into the behavior of a broad range of complex\nsystems such as, motion of particles at oil-water interfaces in Pickering\nemulsion microreactors and the motion of molecular motors on cell membranes.",
                "authors": [
                    "Jacob John",
                    "Giovanniantonio Natale"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13773v1",
                    "http://arxiv.org/pdf/2311.13773v1"
                ],
                "primary_category": "cond-mat.soft",
                "categories": [
                    "cond-mat.soft"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13770v2/1.0",
                "title": "Archiving Body Movements: Collective Generation of Chinese Calligraphy",
                "year": 2023,
                "abstract": "As a communication channel, body movements have been widely explored in\nbehavioral studies and kinesics. Performing and visual arts share the same\ninterests but focus on documenting and representing human body movements, such\nas for dance notation and visual work creation. This paper investigates body\nmovements in oriental calligraphy and how to apply calligraphy principles to\nstimulate and archive body movements. Through an artwork (Wushu), the authors\nexperiment with an interactive and generative approach to engage the audience's\nbodily participation and archive the body movements as a compendium of\ngenerated calligraphy. The audience assumes the role of both writers and\nreaders; creating (\"writing\") and appreciating (\"reading\") the generated\ncalligraphy becomes a cyclical process within this infinite \"Book,\" which can\nmotivate further attention and discussions concerning Chinese characters and\ncalligraphy.",
                "authors": [
                    "Aven Le Zhou",
                    "Jiayi Ye",
                    "Tianchen Liu",
                    "Kang Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13770v2",
                    "http://arxiv.org/pdf/2311.13770v2"
                ],
                "primary_category": "cs.MM",
                "categories": [
                    "cs.MM",
                    "cs.AI",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13764v1/1.0",
                "title": "Work-Efficient Parallel Derandomization I: Chernoff-like Concentrations\n  via Pairwise Independence",
                "year": 2023,
                "abstract": "We present a novel technique for work-efficient parallel derandomization, for\nalgorithms that rely on the concentration of measure bounds such as Chernoff,\nHoeffding, and Bernstein inequalities. Our method increases the algorithm's\ncomputational work and depth by only polylogarithmic factors. Before our work,\nthe only known method to obtain parallel derandomization with such strong\nconcentrations was by the results of [Motwani, Naor, and Naor FOCS'89; Berger\nand Rompel FOCS'89], which perform a binary search in a $k$-wise independent\nspace for $k=poly(\\log n)$. However, that method blows up the computational\nwork by a high $poly(n)$ factor and does not yield work-efficient parallel\nalgorithms. Their method was an extension of the approach of [Luby FOCS'88],\nwhich gave a work-efficient derandomization but was limited to algorithms\nanalyzed with only pairwise independence. Pushing the method from pairwise to\nthe higher $k$-wise analysis resulted in the $poly(n)$ factor computational\nwork blow-up. Our work can be viewed as an alternative extension from the\npairwise case, which yields the desired strong concentrations while retaining\nwork efficiency up to logarithmic factors.\n  Our approach works by casting the problem of determining the random variables\nas an iterative process with $poly(\\log n)$ iterations, where different\niterations have independent randomness. This is done so that for the desired\nconcentrations, we need only pairwise independence inside each iteration. In\nparticular, we model each binary random variable as a result of a gradual\nrandom walk, and our method shows that the desired Chernoff-like concentrations\nabout the endpoints of these walks can be boiled down to some pairwise analysis\non the steps of these random walks in each iteration (while having independence\nacross iterations).",
                "authors": [
                    "Mohsen Ghaffari",
                    "Christoph Grunau",
                    "V\u00e1clav Rozho\u0148"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13764v1",
                    "http://arxiv.org/pdf/2311.13764v1"
                ],
                "primary_category": "cs.DS",
                "categories": [
                    "cs.DS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13762v1/1.0",
                "title": "Quasi-periodic sub-pulse structure as a unifying feature for\n  radio-emitting neutron stars",
                "year": 2023,
                "abstract": "Magnetars are highly-magnetised rotating neutron stars that are predominantly\nobserved as high-energy sources. Six of this class of neutron star are known to\nalso emit radio emission, and magnetars are, thus, a favoured model for the\norigin for at least some of the Fast Radio Bursts (FRBs). If magnetars, or\nneutron stars in general, are indeed responsible, sharp empirical constraints\non the mechanism producing radio emission are required. Here we report on the\ndetection of polarised quasi-periodic sub-structure in the emission of all\nwell-studied radio-detected magnetars. A correlation previously seen, relating\nsub-structure in pulsed emission of radio emitting neutron stars to their\nrotational period, is extended, and shown to now span more than six of orders\nof magnitude in pulse period. This behaviour is not only seen in magnetars but\nin members of all classes of radio-emitting rotating neutron stars, regardless\nof their evolutionary history, their power source or their inferred magnetic\nfield strength. If magnetars are responsible for FRBs, it supports the idea of\nbeing able to infer underlying periods from sub-burst timescales in FRBs.",
                "authors": [
                    "Michael Kramer",
                    "Kuo Liu",
                    "Gregory Desvignes",
                    "Ramesh Karuppusamy",
                    "Ben W. Stappers"
                ],
                "url": [
                    "http://dx.doi.org/10.1038/s41550-023-02125-3",
                    "http://arxiv.org/abs/2311.13762v1",
                    "http://arxiv.org/pdf/2311.13762v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13757v2/1.0",
                "title": "Exceptional times for the instantaneous propagation of superprocess",
                "year": 2023,
                "abstract": "For a Dawson-Watanabe superprocess $X$ on $\\mathbb{R}^d$, it is shown in\nPerkins (1990) that if the underlying spatial motion belongs to a certain class\nof L\\'evy processes that admit jumps, then with probability one the closed\nsupport of $X_t$ is the whole space for almost all $t>0$ before extinction, the\nso-called ``instantaneous propagation'' property. In this paper for\nsuperprocesses on $\\mathbb{R}^1$ whose spatial motion is the symmetric stable\nprocess of index $\\alpha \\in (0,2/3)$, we prove that there exist exceptional\ntimes at which the support is compact and nonempty. Moreover, we show that the\nset of exceptional times is dense with full Hausdorff dimension. Besides, we\nprove that near extinction, the support of the superprocess is concentrated\narbitrarily close to the distinction point, thus upgrading the corresponding\nresults in Tribe (1992) from $\\alpha \\in (0,1/2)$ to $\\alpha \\in (0,2/3)$, and\nwe further show that the set of such exceptional times also admits a full\nHausdorff dimension.",
                "authors": [
                    "Jieliang Hong",
                    "Leonid Mytnik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13757v2",
                    "http://arxiv.org/pdf/2311.13757v2"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "60J68, 60G17"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13755v1/1.0",
                "title": "Transformer-based Named Entity Recognition in Construction Supply Chain\n  Risk Management in Australia",
                "year": 2023,
                "abstract": "The construction industry in Australia is characterized by its intricate\nsupply chains and vulnerability to myriad risks. As such, effective supply\nchain risk management (SCRM) becomes imperative. This paper employs different\ntransformer models, and train for Named Entity Recognition (NER) in the context\nof Australian construction SCRM. Utilizing NER, transformer models identify and\nclassify specific risk-associated entities in news articles, offering a\ndetailed insight into supply chain vulnerabilities. By analysing news articles\nthrough different transformer models, we can extract relevant entities and\ninsights related to specific risk taxonomies local (milieu) to the Australian\nconstruction landscape. This research emphasises the potential of NLP-driven\nsolutions, like transformer models, in revolutionising SCRM for construction in\ngeo-media specific contexts.",
                "authors": [
                    "Milad Baghalzadeh Shishehgarkhaneh",
                    "Robert C. Moehler",
                    "Yihai Fang",
                    "Amer A. Hijazi",
                    "Hamed Aboutorab"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13755v1",
                    "http://arxiv.org/pdf/2311.13755v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13745v1/1.0",
                "title": "Sample-Efficient Training for Diffusion",
                "year": 2023,
                "abstract": "Score-based diffusion models have become the most popular approach to deep\ngenerative modeling of images, largely due to their empirical performance and\nreliability. Recently, a number of theoretical works \\citep{chen2022,\nChen2022ImprovedAO, Chenetal23flowode, benton2023linear} have shown that\ndiffusion models can efficiently sample, assuming $L^2$-accurate score\nestimates. The score-matching objective naturally approximates the true score\nin $L^2$, but the sample complexity of existing bounds depends\n\\emph{polynomially} on the data radius and desired Wasserstein accuracy. By\ncontrast, the time complexity of sampling is only logarithmic in these\nparameters. We show that estimating the score in $L^2$ \\emph{requires} this\npolynomial dependence, but that a number of samples that scales\npolylogarithmically in the Wasserstein accuracy actually do suffice for\nsampling. We show that with a polylogarithmic number of samples, the ERM of the\nscore-matching objective is $L^2$ accurate on all but a probability $\\delta$\nfraction of the true distribution, and that this weaker guarantee is sufficient\nfor efficient sampling.",
                "authors": [
                    "Shivam Gupta",
                    "Aditya Parulekar",
                    "Eric Price",
                    "Zhiyang Xun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13745v1",
                    "http://arxiv.org/pdf/2311.13745v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CV",
                    "cs.IT",
                    "math.IT",
                    "math.ST",
                    "stat.ML",
                    "stat.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13744v1/1.0",
                "title": "Security and Privacy Challenges in Deep Learning Models",
                "year": 2023,
                "abstract": "These days, deep learning models have achieved great success in multiple\nfields, from autonomous driving to medical diagnosis. These models have\nexpanded the abilities of artificial intelligence by offering great solutions\nto complex problems that were very difficult to solve earlier. In spite of\ntheir unseen success in various, it has been identified, through research\nconducted, that deep learning models can be subjected to various attacks that\ncompromise model security and data privacy of the Deep Neural Network models.\nDeep learning models can be subjected to various attacks at different stages of\ntheir lifecycle. During the testing phase, attackers can exploit\nvulnerabilities through different kinds of attacks such as Model Extraction\nAttacks, Model Inversion attacks, and Adversarial attacks. Model Extraction\nAttacks are aimed at reverse-engineering a trained deep learning model, with\nthe primary objective of revealing its architecture and parameters. Model\ninversion attacks aim to compromise the privacy of the data used in the Deep\nlearning model. These attacks are done to compromise the confidentiality of the\nmodel by going through the sensitive training data from the model's\npredictions. By analyzing the model's responses, attackers aim to reconstruct\nsensitive information. In this way, the model's data privacy is compromised.\nAdversarial attacks, mainly employed on computer vision models, are made to\ncorrupt models into confidently making incorrect predictions through malicious\ntesting data. These attacks subtly alter the input data, making it look normal\nbut misleading deep learning models to make incorrect decisions. Such attacks\ncan happen during both the model's evaluation and training phases. Data\nPoisoning Attacks add harmful data to the training set, disrupting the learning\nprocess and reducing the reliability of the deep learning mode.",
                "authors": [
                    "Gopichandh Golla"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13744v1",
                    "http://arxiv.org/pdf/2311.13744v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13743v2/1.0",
                "title": "FinMem: A Performance-Enhanced LLM Trading Agent with Layered Memory and\n  Character Design",
                "year": 2023,
                "abstract": "Recent advancements in Large Language Models (LLMs) have exhibited notable\nefficacy in question-answering (QA) tasks across diverse domains. Their prowess\nin integrating extensive web knowledge has fueled interest in developing\nLLM-based autonomous agents. While LLMs are efficient in decoding human\ninstructions and deriving solutions by holistically processing historical\ninputs, transitioning to purpose-driven agents requires a supplementary\nrational architecture to process multi-source information, establish reasoning\nchains, and prioritize critical tasks. Addressing this, we introduce\n\\textsc{FinMem}, a novel LLM-based agent framework devised for financial\ndecision-making. It encompasses three core modules: Profiling, to customize the\nagent's characteristics; Memory, with layered message processing, to aid the\nagent in assimilating hierarchical financial data; and Decision-making, to\nconvert insights gained from memories into investment decisions. Notably,\n\\textsc{FinMem}'s memory module aligns closely with the cognitive structure of\nhuman traders, offering robust interpretability and real-time tuning. Its\nadjustable cognitive span allows for the retention of critical information\nbeyond human perceptual limits, thereby enhancing trading outcomes. This\nframework enables the agent to self-evolve its professional knowledge, react\nagilely to new investment cues, and continuously refine trading decisions in\nthe volatile financial environment. We first compare \\textsc{FinMem} with\nvarious algorithmic agents on a scalable real-world financial dataset,\nunderscoring its leading trading performance in stocks. We then fine-tuned the\nagent's perceptual span and character setting to achieve a significantly\nenhanced trading performance. Collectively, \\textsc{FinMem} presents a\ncutting-edge LLM agent framework for automated trading, boosting cumulative\ninvestment returns.",
                "authors": [
                    "Yangyang Yu",
                    "Haohang Li",
                    "Zhi Chen",
                    "Yuechen Jiang",
                    "Yang Li",
                    "Denghui Zhang",
                    "Rong Liu",
                    "Jordan W. Suchow",
                    "Khaldoun Khashanah"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13743v2",
                    "http://arxiv.org/pdf/2311.13743v2"
                ],
                "primary_category": "q-fin.CP",
                "categories": [
                    "q-fin.CP",
                    "cs.AI",
                    "cs.CE",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13735v1/1.0",
                "title": "Surpassing GPT-4 Medical Coding with a Two-Stage Approach",
                "year": 2023,
                "abstract": "Recent advances in large language models (LLMs) show potential for clinical\napplications, such as clinical decision support and trial recommendations.\nHowever, the GPT-4 LLM predicts an excessive number of ICD codes for medical\ncoding tasks, leading to high recall but low precision. To tackle this\nchallenge, we introduce LLM-codex, a two-stage approach to predict ICD codes\nthat first generates evidence proposals using an LLM and then employs an\nLSTM-based verification stage. The LSTM learns from both the LLM's high recall\nand human expert's high precision, using a custom loss function. Our model is\nthe only approach that simultaneously achieves state-of-the-art results in\nmedical coding accuracy, accuracy on rare codes, and sentence-level evidence\nidentification to support coding decisions without training on human-annotated\nevidence according to experiments on the MIMIC dataset.",
                "authors": [
                    "Zhichao Yang",
                    "Sanjit Singh Batra",
                    "Joel Stremmel",
                    "Eran Halperin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13735v1",
                    "http://arxiv.org/pdf/2311.13735v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13730v1/1.0",
                "title": "Computation of Riesz $\u03b1$-capacity $C_\u03b1$ of general sets in\n  $\\mathbb{R}^d$ using stable random walks",
                "year": 2023,
                "abstract": "A method for computing the Riesz $\\alpha$-capacity, $0 < \\alpha \\le 2$, of a\ngeneral set $K \\subset \\mathbb{R}^d$ is given. The method is based on\nsimulations of isotropic $\\alpha$-stable motion paths in $d$-dimensions. The\nfamiliar Walk-On-Spheres method, often utilized for simulating Brownian motion,\nis modified to a novel Walk-In-Out-Balls method adapted for modeling the stable\npath process on the exterior of regions ``probed'' by this type of generalized\nrandom walk. It accounts for the propensity of this class of random walk to\njump through boundaries because of the path discontinuity. This method allows\nfor the computationally efficient simulation of hitting locations of stable\npaths launched from the exterior of probed sets. Reliable methods of computing\ncapacity from these locations are given, along with non-standard confidence\nintervals. Illustrative calculations are performed for representative types of\nsets K, where both $\\alpha$ and $d$ are varied.",
                "authors": [
                    "John P. Nolan",
                    "Debra J. Audus",
                    "Jack F. Douglas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13730v1",
                    "http://arxiv.org/pdf/2311.13730v1"
                ],
                "primary_category": "stat.CO",
                "categories": [
                    "stat.CO",
                    "31B02, 31B15, 31A15, 31C02, 60G52"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13729v1/1.0",
                "title": "Comparison of pipeline, sequence-to-sequence, and GPT models for\n  end-to-end relation extraction: experiments with the rare disease use-case",
                "year": 2023,
                "abstract": "End-to-end relation extraction (E2ERE) is an important and realistic\napplication of natural language processing (NLP) in biomedicine. In this paper,\nwe aim to compare three prevailing paradigms for E2ERE using a complex dataset\nfocused on rare diseases involving discontinuous and nested entities. We use\nthe RareDis information extraction dataset to evaluate three competing\napproaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to\nsequence models, and generative pre-trained transformer (GPT) models. We use\ncomparable state-of-the-art models and best practices for each of these\napproaches and conduct error analyses to assess their failure modes. Our\nfindings reveal that pipeline models are still the best, while\nsequence-to-sequence models are not far behind; GPT models with eight times as\nmany parameters are worse than even sequence-to-sequence models and lose to\npipeline models by over 10 F1 points. Partial matches and discontinuous\nentities caused many NER errors contributing to lower overall E2E performances.\nWe also verify these findings on a second E2ERE dataset for chemical-protein\ninteractions. Although generative LM-based methods are more suitable for\nzero-shot settings, when training data is available, our results show that it\nis better to work with more conventional models trained and tailored for E2ERE.\nMore innovative methods are needed to marry the best of the both worlds from\nsmaller encoder-decoder pipeline models and the larger GPT models to improve\nE2ERE. As of now, we see that well designed pipeline models offer substantial\nperformance gains at a lower cost and carbon footprint for E2ERE. Our\ncontribution is also the first to conduct E2ERE for the RareDis dataset.",
                "authors": [
                    "Shashank Gupta",
                    "Xuguang Ai",
                    "Ramakanth Kavuluru"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13729v1",
                    "http://arxiv.org/pdf/2311.13729v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13726v1/1.0",
                "title": "Controlling selection rules for magnon scattering in nanomagnets by\n  spatial symmetry breaking",
                "year": 2023,
                "abstract": "Nanomagnets are the building blocks of many existing and emergent spintronic\ntechnologies. Magnetization dynamics of nanomagnets is often dominated by\nnonlinear processes, which have been recently shown to have many surprising\nfeatures and far-reaching implications for applications. Here we develop a\ntheoretical framework uncovering the selection rules for multimagnon processes\nand discuss their underlying mechanisms. For its technological relevance, we\nfocus on the degenerate three-magnon process in thin elliptical nanodisks to\nillustrate our findings. We parameterize the selection rules through a set of\nmagnon interaction coefficients which we calculate using micromagnetic\nsimulations. We postulate the selection rules and investigate how they are\naltered by perturbations, that break the symmetry of static magnetization\nconfiguration and spatial spin-wave profiles and that can be realized by\napplying off-symmetry-axis or nonuniform magnetic fields. Our work provides the\nphenomenological understanding into the mechanics of magnon interaction as well\nas the formalism for determining the interaction coefficients from simulations\nand experimental data. Our results serve as a guide to analyze magnon processes\ninherently present in spin-torque devices for boosting their performance or to\nengineer a specific nonlinear response of a nanomagnet used in neuromorphic or\nquantum magnonic application.",
                "authors": [
                    "Arezoo Etesamirad",
                    "Julia Kharlan",
                    "Rodolfo Rodriguez",
                    "Igor Barsukov",
                    "Roman Verba"
                ],
                "url": [
                    "http://dx.doi.org/10.1103/PhysRevApplied.19.044087",
                    "http://arxiv.org/abs/2311.13726v1",
                    "http://arxiv.org/pdf/2311.13726v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13722v1/1.0",
                "title": "Deep Learning as a Method for Inversion of NMR Signals",
                "year": 2023,
                "abstract": "The concept of deep learning is employed for the inversion of NMR signals and\nit is shown that NMR signal inversion can be considered as an image-to-image\nregression problem, which can be treated with a convolutional neural net. It is\nfurther outlined, that inversion through deep learning provides a clear\nefficiency and usability advantage compared to regularization techniques such\nas Tikhonov and modified total generalized variation (MTGV), because no\nhyperparemeter selection prior to reconstruction is necessary. The inversion\nnetwork is applied to simulated NMR signals and the results compared with\nTikhonov- and MTGV-regularization. The comparison shows that inversion via deep\nlearning is significantly faster than the latter regularization methods and\nalso outperforms both regularization techniques in nearly all instances.",
                "authors": [
                    "Julian B. B. Beckmann",
                    "Mick D. Mantle",
                    "Andrew J. Sederman",
                    "Lynn F. Gladden"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13722v1",
                    "http://arxiv.org/pdf/2311.13722v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "cs.LG",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13721v2/1.0",
                "title": "Nova$^+$: Generative Language Models for Binaries",
                "year": 2023,
                "abstract": "Generative large language models (LLMs) pre-trained on code have shown\nimpressive effectiveness in code generation, program repair, and document\nanalysis. However, existing generative LLMs focus on source code and are not\nspecialized for binaries. There are three main challenges for LLMs to model and\nlearn binary code: hex-decimal values, complex global dependencies, and\ncompiler optimization levels. To bring the benefit of LLMs to the binary\ndomain, we develop Nova and Nova$^+$, which are LLMs pre-trained on binary\ncorpora. Nova is pre-trained with the standard language modeling task, showing\nsignificantly better capability on five benchmarks for three downstream tasks:\nbinary code similarity detection (BCSD), binary code translation (BCT), and\nbinary code recovery (BCR), over GPT-3.5 and other existing techniques. We\nbuild Nova$^+$ to further boost Nova using two new pre-training tasks, i.e.,\noptimization generation and optimization level prediction, which are designed\nto learn binary optimization and align equivalent binaries. Nova$^+$ shows\noverall the best performance for all three downstream tasks on five benchmarks,\ndemonstrating the contributions of the new pre-training tasks.",
                "authors": [
                    "Nan Jiang",
                    "Chengxiao Wang",
                    "Kevin Liu",
                    "Xiangzhe Xu",
                    "Lin Tan",
                    "Xiangyu Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13721v2",
                    "http://arxiv.org/pdf/2311.13721v2"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13720v1/1.0",
                "title": "Towards More Likely Models for AI Planning",
                "year": 2023,
                "abstract": "This is the first work to look at the application of large language models\n(LLMs) for the purpose of model space edits in automated planning tasks. To set\nthe stage for this sangam, we explore two different flavors of model space\nproblems that have been studied in the AI planning literature and explore the\neffect of an LLM on those tasks. We empirically demonstrate how the performance\nof an LLM contrasts with combinatorial search (CS) - an approach that has been\ntraditionally used to solve model space tasks in planning, both with the LLM in\nthe role of a standalone model space reasoner as well as in the role of a\nstatistical signal in concert with the CS approach as part of a two-stage\nprocess. Our experiments show promising results suggesting further forays of\nLLMs into the exciting world of model space reasoning for planning tasks in the\nfuture.",
                "authors": [
                    "Turgay Caglar",
                    "Sirine Belhaj",
                    "Tathagata Chakraborti",
                    "Michael Katz",
                    "Sarath Sreedharan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13720v1",
                    "http://arxiv.org/pdf/2311.13720v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13719v1/1.0",
                "title": "Deep learning-based instance segmentation for the precise automated\n  quantification of digital breast cancer immunohistochemistry images",
                "year": 2023,
                "abstract": "The quantification of biomarkers on immunohistochemistry breast cancer images\nis essential for defining appropriate therapy for breast cancer patients, as\nwell as for extracting relevant information on disease prognosis. This is an\narduous and time-consuming task that may introduce a bias in the results due to\nintra- and inter-observer variability which could be alleviated by making use\nof automatic quantification tools. However, this is not a simple processing\ntask given the heterogeneity of breast tumors that results in non-uniformly\ndistributed tumor cells exhibiting different staining colors and intensity,\nsize, shape, and texture, of the nucleus, cytoplasm and membrane. In this\nresearch work, we demonstrate the feasibility of using a deep learning-based\ninstance segmentation architecture for the automatic quantification of both\nnuclear and membrane biomarkers applied to IHC-stained slides. We have solved\nthe cumbersome task of training set generation with the design and\nimplementation of a web platform, which has served as a hub for communication\nand feedback between researchers and pathologists as well as a system for the\nvalidation of the automatic image processing models. Through this tool, we have\ncollected annotations over samples of HE, ER and Ki-67 (nuclear biomarkers) and\nHER2 (membrane biomarker) IHC-stained images. Using the same deep learning\nnetwork architecture, we have trained two models, so-called nuclei- and\nmembrane-aware segmentation models, which, once successfully validated, have\nrevealed to be a promising method to segment nuclei instances in IHC-stained\nimages. The quantification method proposed in this work has been integrated\ninto the developed web platform and is currently being used as a\ndecision-support tool by pathologists.",
                "authors": [
                    "Blanca Maria Priego-Torresa",
                    "Barbara Lobato-Delgado",
                    "Lidia Atienza-Cuevas",
                    "Daniel Sanchez-Morillo"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/j.eswa.2021.116471",
                    "http://arxiv.org/abs/2311.13719v1",
                    "http://arxiv.org/pdf/2311.13719v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.AI",
                    "cs.CV",
                    "J.6; I.4"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13718v1/1.0",
                "title": "A Unified Approach to Count-Based Weakly-Supervised Learning",
                "year": 2023,
                "abstract": "High-quality labels are often very scarce, whereas unlabeled data with\ninferred weak labels occurs more naturally. In many cases, these weak labels\ndictate the frequency of each respective class over a set of instances. In this\npaper, we develop a unified approach to learning from such weakly-labeled data,\nwhich we call count-based weakly-supervised learning. At the heart of our\napproach is the ability to compute the probability of exactly k out of n\noutputs being set to true. This computation is differentiable, exact, and\nefficient. Building upon the previous computation, we derive a count loss\npenalizing the model for deviations in its distribution from an arithmetic\nconstraint defined over label counts. We evaluate our approach on three common\nweakly-supervised learning paradigms and observe that our proposed approach\nachieves state-of-the-art or highly competitive results across all three of the\nparadigms.",
                "authors": [
                    "Vinay Shukla",
                    "Zhe Zeng",
                    "Kareem Ahmed",
                    "Guy Van den Broeck"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13718v1",
                    "http://arxiv.org/pdf/2311.13718v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13716v1/1.0",
                "title": "DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation\n  Networks for Remote Sensing Imagery",
                "year": 2023,
                "abstract": "Semi-supervised learning is designed to help reduce the cost of the manual\nlabelling process by exploiting the use of useful features from a large\nquantity of unlabelled data during training. Since pixel-level manual labelling\nin large-scale remote sensing imagery is expensive, semi-supervised learning\nbecomes an appropriate solution to this. However, most of the existing\nsemi-supervised learning methods still lack efficient perturbation methods to\npromote diversity of features and the precision of pseudo labels during\ntraining. In order to fill this gap, we propose DiverseNet architectures which\nexplore multi-head and multi-model semi-supervised learning algorithms by\nsimultaneously promoting precision and diversity during training. The two\nproposed methods of DiverseNet, namely the DiverseHead and DiverseModel,\nachieve the highest semantic segmentation performance in four widely utilised\nremote sensing imagery data sets compared to state-of-the-art semi-supervised\nlearning methods. Meanwhile, the proposed DiverseHead architecture is\nrelatively lightweight in terms of parameter space compared to the\nstate-of-the-art methods whilst reaching high-performance results for all the\ntested data sets.",
                "authors": [
                    "Wanli Ma",
                    "Oktay Karakus",
                    "Paul L. Rosin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13716v1",
                    "http://arxiv.org/pdf/2311.13716v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13712v1/1.0",
                "title": "Data Acquisition: A New Frontier in Data-centric AI",
                "year": 2023,
                "abstract": "As Machine Learning (ML) systems continue to grow, the demand for relevant\nand comprehensive datasets becomes imperative. There is limited study on the\nchallenges of data acquisition due to ad-hoc processes and lack of consistent\nmethodologies. We first present an investigation of current data marketplaces,\nrevealing lack of platforms offering detailed information about datasets,\ntransparent pricing, standardized data formats. With the objective of inciting\nparticipation from the data-centric AI community, we then introduce the DAM\nchallenge, a benchmark to model the interaction between the data providers and\nacquirers. The benchmark was released as a part of DataPerf. Our evaluation of\nthe submitted strategies underlines the need for effective data acquisition\nstrategies in ML.",
                "authors": [
                    "Lingjiao Chen",
                    "Bilge Acun",
                    "Newsha Ardalani",
                    "Yifan Sun",
                    "Feiyang Kang",
                    "Hanrui Lyu",
                    "Yongchan Kwon",
                    "Ruoxi Jia",
                    "Carole-Jean Wu",
                    "Matei Zaharia",
                    "James Zou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13712v1",
                    "http://arxiv.org/pdf/2311.13712v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13711v1/1.0",
                "title": "Neutrino signal from Cygnus region of the Milky Way",
                "year": 2023,
                "abstract": "Interactions of cosmic ray protons and nuclei in their sources and in the\ninterstellar medium produce \"hadronic\" gamma-ray emission. Gamma-rays can also\nbe of \"leptonic\" origin, i.e. originating from high-energy electrons\naccelerated together with protons. It is difficult to distinguish between\nhadronic and leptonic emission mechanisms based on gamma-ray data alone. This\ncan be done via detection of neutrinos, because only hadronic processes lead to\nneutrino production. We use publicly available ten-year IceCube neutrino\ntelescope dataset to demonstrate the hadronic nature of high-energy emission\nfrom the direction of Cygnus region of the Milky Way. We find a 3-sigma excess\nof neutrino events from an extended Cygnus Cocoon, with the flux comparable to\nthe flux of gamma-rays in the multi-TeV energy range seen by HAWC and LHAASO\ntelescopes.",
                "authors": [
                    "A. Neronov",
                    "D. Semikoz",
                    "D. Savchenko"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13711v1",
                    "http://arxiv.org/pdf/2311.13711v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13710v1/1.0",
                "title": "A Comprehensive Review of Artificial Intelligence Applications in Major\n  Retinal Conditions",
                "year": 2023,
                "abstract": "This paper provides a systematic survey of retinal diseases that cause visual\nimpairments or blindness, emphasizing the importance of early detection for\neffective treatment. It covers both clinical and automated approaches for\ndetecting retinal disease, focusing on studies from the past decade. The survey\nevaluates various algorithms for identifying structural abnormalities and\ndiagnosing retinal diseases, and it identifies future research directions based\non a critical analysis of existing literature. This comprehensive study, which\nreviews both clinical and automated detection methods using different\nmodalities, appears to be unique in its scope. Additionally, the survey serves\nas a helpful guide for researchers interested in digital retinopathy.",
                "authors": [
                    "Hina Raja",
                    "Taimur Hassan",
                    "Bilal Hassan",
                    "Muhammad Usman Akram",
                    "Hira Raja",
                    "Alaa A Abd-alrazaq",
                    "Siamak Yousefi",
                    "Naoufel Werghi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13710v1",
                    "http://arxiv.org/pdf/2311.13710v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13708v1/1.0",
                "title": "Dynamic Analysis Method for Hidden Dangers in Substation Based on\n  Knowledge Graph",
                "year": 2023,
                "abstract": "To address the challenge of identifying and understanding hidden dangers in\nsubstations from unstructured text data, a novel dynamic analysis method is\nproposed. This approach begins by analyzing and extracting data from the\nunstructured text related to hidden dangers. It then leverages a flexible,\ndistributed data search engine built on Elastic-Search to handle this\ninformation. Following this, the hidden Markov model is employed to train the\ndata within the engine. The Viterbi algorithm is integrated to decipher the\nhidden state sequences, facilitating the segmentation and labeling of entities\nrelated to hidden dangers. The final step involves using the Neo4j graph\ndatabase to dynamically create a knowledge map that visualizes hidden dangers\nin the substation. This method's effectiveness is demonstrated through an\nexample analysis using data from a specific substation's hidden dangers.",
                "authors": [
                    "Weiwei Li",
                    "Xing Liu",
                    "Wei Wang",
                    "Lu Chen",
                    "Sizhe Li",
                    "Hui Fan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13708v1",
                    "http://arxiv.org/pdf/2311.13708v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13706v1/1.0",
                "title": "Multi-view Hybrid Graph Convolutional Network for Volume-to-mesh\n  Reconstruction in Cardiovascular MRI",
                "year": 2023,
                "abstract": "Cardiovascular magnetic resonance imaging is emerging as a crucial tool to\nexamine cardiac morphology and function. Essential to this endeavour are\nanatomical 3D surface and volumetric meshes derived from CMR images, which\nfacilitate computational anatomy studies, biomarker discovery, and in-silico\nsimulations. However, conventional surface mesh generation methods, such as\nactive shape models and multi-atlas segmentation, are highly time-consuming and\nrequire complex processing pipelines to generate simulation-ready 3D meshes. In\nresponse, we introduce HybridVNet, a novel architecture for direct\nimage-to-mesh extraction seamlessly integrating standard convolutional neural\nnetworks with graph convolutions, which we prove can efficiently handle surface\nand volumetric meshes by encoding them as graph structures. To further enhance\naccuracy, we propose a multiview HybridVNet architecture which processes both\nlong axis and short axis CMR, showing that it can increase the performance of\ncardiac MR mesh generation. Our model combines traditional convolutional\nnetworks with variational graph generative models, deep supervision and\nmesh-specific regularisation. Experiments on a comprehensive dataset from the\nUK Biobank confirm the potential of HybridVNet to significantly advance cardiac\nimaging and computational cardiology by efficiently generating high-fidelity\nand simulation ready meshes from CMR images.",
                "authors": [
                    "Nicol\u00e1s Gaggion",
                    "Benjamin A. Matheson",
                    "Yan Xia",
                    "Rodrigo Bonazzola",
                    "Nishant Ravikumar",
                    "Zeike A. Taylor",
                    "Diego H. Milone",
                    "Alejandro F. Frangi",
                    "Enzo Ferrante"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13706v1",
                    "http://arxiv.org/pdf/2311.13706v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13703v1/1.0",
                "title": "Single-shot Quantum Signal Processing Interferometry",
                "year": 2023,
                "abstract": "Quantum systems of infinite dimension, such as bosonic oscillators, provide\nvast resources for quantum sensing. Yet, a general theory on how to manipulate\nsuch bosonic modes for sensing beyond parameter estimation is unknown. We\npresent a general algorithmic framework, quantum signal processing\ninterferometry (QSPI), for quantum sensing at the fundamental limits of quantum\nmechanics, i.e., the Heisenberg sensing limit, by generalizing Ramsey-type\ninterferometry. Our QSPI sensing protocol relies on performing nonlinear\npolynomial transformations on the oscillator's quadrature operators by\ngeneralizing quantum signal processing (QSP) from qubits to hybrid\nqubit-oscillator systems. We use our QSPI sensing framework to make binary\ndecisions on a displacement channel in the single-shot limit. Theoretical\nanalysis suggests the sensing accuracy given a single-shot qubit measurement\ncan approach the Heisenberg-limit scaling. We further concatenate a series of\nsuch binary decisions to perform parameter estimation in a bit-by-bit fashion.\nNumerical simulations are performed to support these statements. Our QSPI\nprotocol offers a unified framework for quantum sensing using\ncontinuous-variable bosonic systems beyond parameter estimation and establishes\na promising avenue toward efficient and scalable quantum control and quantum\nsensing schemes beyond the NISQ era.",
                "authors": [
                    "Jasmine Sinanan-Singh",
                    "Gabriel L. Mintzer",
                    "Isaac L. Chuang",
                    "Yuan Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13703v1",
                    "http://arxiv.org/pdf/2311.13703v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13700v1/1.0",
                "title": "Stellar populations and origin of thick disks in AURIGA simulations",
                "year": 2023,
                "abstract": "The origin of thick disks and their evolutionary connection with thin disks\nare still a matter of debate. We provide new insights into this topic by\nconnecting the stellar populations of thick disks at redshift $z=0$ with their\npast formation and growth, in 24 Milky Way-mass galaxies from the AURIGA\nzoom-in cosmological simulations. We projected each galaxy edge on, and\ndecomposed it morphologically into two disk components, in order to define\ngeometrically the thin and the thick disks as usually done in observations. We\nproduced age, metallicity and [Mg/Fe] edge-on maps. We quantified the impact of\nsatellite mergers by mapping the distribution of ex-situ stars. Thick disks are\non average $\\sim 3$~Gyr older, $\\sim 0.25$~dex more metal poor and $\\sim\n0.06$~dex more [Mg/Fe]-enhanced than thin disks. Their average ages range from\n$\\sim 6$ to $\\sim 9$~Gyr, metallicities from $\\sim -0.15$ to $\\sim 0.1$~dex,\nand [Mg/Fe] from $\\sim 0.12$ to $\\sim 0.16$~dex. These properties are the\nresult of an early initial in-situ formation, followed by a later growth driven\nby the combination of direct accretion of stars, some in-situ star formation\nfueled by mergers, and dynamical heating of stars. The balance between these\nprocesses varies from galaxy to galaxy. Mergers play a key role in the mass\nassembly of thick disks, contributing an average accreted mass fraction of\n$\\sim 22$\\% in the analyzed thick-disk dominated regions. In two galaxies,\nabout half of the geometric thick-disk mass was directly accreted. While\nprimordial thick disks form at high redshift in all galaxies, young metal-rich\nthin disks, with much lower [Mg/Fe] abundances, start to form later but at\ndifferent times (higher or lower redshift) depending on the galaxy. We conclude\nthat thick disks result from the interplay of external processes with the\ninternal evolution of the galaxy.",
                "authors": [
                    "Francesca Pinna",
                    "Daniel Walo-Mart\u00edn",
                    "Robert J. J. Grand",
                    "Marie Martig",
                    "Francesca Fragkoudi",
                    "Facundo A. G\u00f3mez",
                    "Federico Marinacci",
                    "R\u00fcdiger Pakmor"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13700v1",
                    "http://arxiv.org/pdf/2311.13700v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13697v1/1.0",
                "title": "Floquet Engineering of a Diatomic Molecule Through a Bichromatic\n  Radiation Field",
                "year": 2023,
                "abstract": "We report on a theoretical study of a Cs$_2$ molecule illuminated by two\nlasers and show how it can result in novel quantum dynamics. We reveal that\nthese interactions facilitate the bypass of the non-crossing rule, forming\nLight-Induced Conical Intersections and modifiable avoided crossings. Our\nfindings show how laser field orientation and strength, along with initial\nphase differences, can control molecular state transitions, especially on the\nmicromotion scale. We also discuss extensively how the interaction of radiation\nwith matter gives rise to the emergence of potential energy surfaces of hybrids\nof radiation and molecular states. This research advances a technique for\nmanipulating photoassociation processes in Cs$_2$ molecules, offering potential\nnew avenues in quantum control.",
                "authors": [
                    "Edgar Barriga",
                    "Luis E. F. Foa Torres",
                    "Carlos C\u00e1rdenas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13697v1",
                    "http://arxiv.org/pdf/2311.13697v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13695v1/1.0",
                "title": "BackboneLearn: A Library for Scaling Mixed-Integer Optimization-Based\n  Machine Learning",
                "year": 2023,
                "abstract": "We present BackboneLearn: an open-source software package and framework for\nscaling mixed-integer optimization (MIO) problems with indicator variables to\nhigh-dimensional problems. This optimization paradigm can naturally be used to\nformulate fundamental problems in interpretable supervised learning (e.g.,\nsparse regression and decision trees), in unsupervised learning (e.g.,\nclustering), and beyond; BackboneLearn solves the aforementioned problems\nfaster than exact methods and with higher accuracy than commonly used\nheuristics. The package is built in Python and is user-friendly and easily\nextensible: users can directly implement a backbone algorithm for their MIO\nproblem at hand. The source code of BackboneLearn is available on GitHub (link:\nhttps://github.com/chziakas/backbone_learn).",
                "authors": [
                    "Vassilis Digalakis Jr",
                    "Christos Ziakas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13695v1",
                    "http://arxiv.org/pdf/2311.13695v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.OC",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13692v1/1.0",
                "title": "Molly: A Verified Compiler for Cryptoprotocol Roles",
                "year": 2023,
                "abstract": "Molly is a program that compiles cryptographic protocol roles written in a\nhigh-level notation into straight-line programs in an intermediate-level\nimperative language, suitable for implementation in a conventional programming\nlanguage. We define a denotational semantics for protocol roles based on an\naxiomatization of the runtime. A notable feature of our approach is that we\nassume that encryption is randomized. Thus, at the runtime level we treat\nencryption as a relation rather than a function. Molly is written in Coq, and\ngenerates a machine-checked proof that the procedure it constructs is correct\nwith respect to the runtime semantics. Using Coq's extraction mechanism, one\ncan build an efficient functional program for compilation.",
                "authors": [
                    "Daniel J. Dougherty",
                    "Joshua D. Guttman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13692v1",
                    "http://arxiv.org/pdf/2311.13692v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13690v1/1.0",
                "title": "The 85-electrode AO system of the Swedish 1-m Solar Telescope",
                "year": 2023,
                "abstract": "We discuss the chosen concepts, detailed design, implementation and\ncalibration of the 85-electrode adaptive optics (AO) system of the Swedish\n1-meter Solar Telescope (SST). The AO system includes a 52 mm diameter\nmonomorph deformable mirror with 34 mm pupil diameter, and an Intel PC\nworkstation that performs the heavy image processing associated with cross\ncorrelations and real-time control at 2 kHz update rate with very low latency.\nThe AO system is unusual by using a combination of a monomorph mirror with a\nShack-Hartmann (SH) wavefront sensor (WFS), and uses a second high-resolution\nSH microlens array to aid the DM characterization, calibration, and modal\ncontrol. The computer and software continue the successful implementation since\n1995 of earlier generations of correlation tracker and AO systems at SST and\nits predecessor SVST by relying entirely on work station technology and an\nextremely efficient algorithm for implementing cross correlations with the\nlarge field-of-view of the WFS. We describe critical aspects of the design,\ncalibrations, software and functioning of the AO system. The exceptionally high\nperformance is testified through the highest Strehl ratio (as inferred from the\nmeasured granulation contrast) of existing meter-class solar telescopes, and in\nparticular the unparalleled image quality achieved at wavelengths below 400 nm.\nWe expect that some aspects of this AO system may be of interest also outside\nthe solar community.",
                "authors": [
                    "G. B. Scharmer",
                    "G. Sliepen",
                    "J. -C. Sinquin",
                    "M. G. L\u00f6fdahl",
                    "B. Lindberg",
                    "P. S\u00fctterlin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13690v1",
                    "http://arxiv.org/pdf/2311.13690v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13688v1/1.0",
                "title": "Masked Conditional Diffusion Models for Image Analysis with Application\n  to Radiographic Diagnosis of Infant Abuse",
                "year": 2023,
                "abstract": "The classic metaphyseal lesion (CML) is a distinct injury that is highly\nspecific for infant abuse. It commonly occurs in the distal tibia. To aid\nradiologists detect these subtle fractures, we need to develop a model that can\nflag abnormal distal tibial radiographs (i.e. those with CMLs). Unfortunately,\nthe development of such a model requires a large and diverse training database,\nwhich is often not available. To address this limitation, we propose a novel\ngenerative model for data augmentation. Unlike previous models that fail to\ngenerate data that span the diverse radiographic appearance of the distal\ntibial CML, our proposed masked conditional diffusion model (MaC-DM) not only\ngenerates realistic-appearing and wide-ranging synthetic images of the distal\ntibial radiographs with and without CMLs, it also generates their associated\nsegmentation labels. To achieve these tasks, MaC-DM combines the weighted\nsegmentation masks of the tibias and the CML fracture sites as additional\nconditions for classifier guidance. The augmented images from our model\nimproved the performances of ResNet-34 in classifying normal radiographs and\nthose with CMLs. Further, the augmented images and their associated\nsegmentation masks enhanced the performance of the U-Net in labeling areas of\nthe CMLs on distal tibial radiographs.",
                "authors": [
                    "Shaoju Wu",
                    "Sila Kurugol",
                    "Andy Tsai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13688v1",
                    "http://arxiv.org/pdf/2311.13688v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13687v1/1.0",
                "title": "Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts",
                "year": 2023,
                "abstract": "In the heart of \"rhythm games\" - games where players must perform actions in\nsync with a piece of music - are \"charts\", the directives to be given to\nplayers. We newly formulate chart generation as a sequence generation task and\ntrain a Transformer using a large dataset. We also introduce tempo-informed\npreprocessing and training procedures, some of which are suggested to be\nintegral for a successful training. Our model is found to outperform the\nbaselines on a large dataset, and is also found to benefit from pretraining and\nfinetuning.",
                "authors": [
                    "Jayeon Yi",
                    "Sungho Lee",
                    "Kyogu Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13687v1",
                    "http://arxiv.org/pdf/2311.13687v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.MM",
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13682v1/1.0",
                "title": "Single-Shot Plug-and-Play Methods for Inverse Problems",
                "year": 2023,
                "abstract": "The utilisation of Plug-and-Play (PnP) priors in inverse problems has become\nincreasingly prominent in recent years. This preference is based on the\nmathematical equivalence between the general proximal operator and the\nregularised denoiser, facilitating the adaptation of various off-the-shelf\ndenoiser priors to a wide range of inverse problems. However, existing PnP\nmodels predominantly rely on pre-trained denoisers using large datasets. In\nthis work, we introduce Single-Shot PnP methods (SS-PnP), shifting the focus to\nsolving inverse problems with minimal data. First, we integrate Single-Shot\nproximal denoisers into iterative methods, enabling training with single\ninstances. Second, we propose implicit neural priors based on a novel function\nthat preserves relevant frequencies to capture fine details while avoiding the\nissue of vanishing gradients. We demonstrate, through extensive numerical and\nvisual experiments, that our method leads to better approximations.",
                "authors": [
                    "Yanqi Cheng",
                    "Lipei Zhang",
                    "Zhenda Shen",
                    "Shujun Wang",
                    "Lequan Yu",
                    "Raymond H. Chan",
                    "Carola-Bibiane Sch\u00f6nlieb",
                    "Angelica I Aviles-Rivero"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13682v1",
                    "http://arxiv.org/pdf/2311.13682v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13680v1/1.0",
                "title": "Qudit Stabilizer Codes, CFTs, and Topological Surfaces",
                "year": 2023,
                "abstract": "We study general maps from the space of rational CFTs with a fixed chiral\nalgebra and associated Chern-Simons (CS) theories to the space of qudit\nstabilizer codes with a fixed generalized Pauli group. We consider certain\nnatural constraints on such a map and show that the map can be described as a\ngraph homomorphism from an orbifold graph, which captures the orbifold\nstructure of CFTs, to a code graph, which captures the structure of self-dual\nstabilizer codes. By studying explicit examples, we show that this graph\nhomomorphism cannot always be a graph embedding. However, we construct a\nphysically motivated map from universal orbifold subgraphs of CFTs to operators\nin a generalized Pauli group. We show that this map results in a self-dual\nstabilizer code if and only if the surface operators in the bulk CS theories\ncorresponding to the CFTs in question are self-dual. For CFTs admitting a\nstabilizer code description, we show that the full abelianized generalized\nPauli group can be obtained from twisted sectors of certain 0-form symmetries\nof the CFT. Finally, we connect our construction with SymTFTs, and we argue\nthat many equivalences between codes that arise in our setup correspond to\nequivalence classes of bulk topological surfaces under fusion with invertible\nsurfaces.",
                "authors": [
                    "Matthew Buican",
                    "Rajath Radhakrishnan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13680v1",
                    "http://arxiv.org/pdf/2311.13680v1"
                ],
                "primary_category": "hep-th",
                "categories": [
                    "hep-th",
                    "cond-mat.str-el",
                    "math-ph",
                    "math.MP",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13679v2/1.0",
                "title": "Parity vs. AC0 with simple quantum preprocessing",
                "year": 2023,
                "abstract": "A recent line of work has shown the unconditional advantage of constant-depth\nquantum computation, or $\\mathsf{QNC^0}$, over $\\mathsf{NC^0}$,\n$\\mathsf{AC^0}$, and related models of classical computation. Problems\nexhibiting this advantage include search and sampling tasks related to the\nparity function, and it is natural to ask whether $\\mathsf{QNC^0}$ can be used\nto help compute parity itself. We study $\\mathsf{AC^0\\circ QNC^0}$ -- a hybrid\ncircuit model where $\\mathsf{AC^0}$ operates on measurement outcomes of a\n$\\mathsf{QNC^0}$ circuit, and conjecture $\\mathsf{AC^0\\circ QNC^0}$ cannot\nachieve $\\Omega(1)$ correlation with parity. As evidence for this conjecture,\nwe prove:\n  $\\bullet$ When the $\\mathsf{QNC^0}$ circuit is ancilla-free, this model\nachieves only negligible correlation with parity.\n  $\\bullet$ For the general (non-ancilla-free) case, we show via a connection\nto nonlocal games that the conjecture holds for any class of postprocessing\nfunctions that has approximate degree $o(n)$ and is closed under restrictions,\neven when the $\\mathsf{QNC^0}$ circuit is given arbitrary quantum advice. By\nknown results this confirms the conjecture for linear-size $\\mathsf{AC^0}$\ncircuits.\n  $\\bullet$ Towards a switching lemma for $\\mathsf{AC^0\\circ QNC^0}$, we study\nthe effect of quantum preprocessing on the decision tree complexity of Boolean\nfunctions. We find that from this perspective, nonlocal channels are no better\nthan randomness: a Boolean function $f$ precomposed with an $n$-party nonlocal\nchannel is together equal to a randomized decision tree with worst-case depth\nat most $\\mathrm{DT}_\\mathrm{depth}[f]$.\n  Our results suggest that while $\\mathsf{QNC^0}$ is surprisingly powerful for\nsearch and sampling tasks, that power is \"locked away\" in the global\ncorrelations of its output, inaccessible to simple classical computation for\nsolving decision problems.",
                "authors": [
                    "Joseph Slote"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13679v2",
                    "http://arxiv.org/pdf/2311.13679v2"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "cs.CC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13678v1/1.0",
                "title": "End-to-end Transfer Learning for Speaker-independent Cross-language\n  Speech Emotion Recognition",
                "year": 2023,
                "abstract": "Data-driven models achieve successful results in Speech Emotion Recognition\n(SER). However, these models, which are based on general acoustic features or\nend-to-end approaches, show poor performance when the testing set has a\ndifferent language (i.e., the cross-language setting) than the training set or\nwhen they come from a different dataset (i.e., the cross-corpus setting). To\nalleviate this problem, this paper presents an end-to-end Deep Neural Network\n(DNN) model based on transfer learning for cross-language SER. We use the\nwav2vec 2.0 pre-trained model to transform audio time-domain waveforms from\ndifferent languages, different speakers and different recording conditions into\na feature space shared by multiple languages, thereby it reduces the language\nvariabilities in the speech features. Next, we propose a new Deep-Within-Class\nCo-variance Normalisation (Deep-WCCN) layer that can be inserted into the DNN\nmodel and it aims to reduce other variabilities including speaker variability,\nchannel variability and so on. The whole model is fine-tuned in an end-to-end\nmanner on a combined loss and is validated on datasets from three languages\n(i.e., English, German, Chinese). Experiment results show that our proposed\nmethod not only outperforms the baseline model that is based on common acoustic\nfeature sets for SER in the within-language setting, but also significantly\noutperforms the baseline model for cross-language setting. In addition, we also\nexperimentally validate the effectiveness of Deep-WCCN, which can further\nimprove the model performance. Finally, to comparing the results in the recent\nliteratures that use the same testing datasets, our proposed model shows\nsignificantly better performance than other state-of-the-art models in\ncross-language SER.",
                "authors": [
                    "Duowei Tang",
                    "Peter Kuppens",
                    "Luc Geurts",
                    "Toon van Waterschoot"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13678v1",
                    "http://arxiv.org/pdf/2311.13678v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13676v1/1.0",
                "title": "Depth-Based Statistical Inferences in the Spike Train Space",
                "year": 2023,
                "abstract": "Metric-based summary statistics such as mean and covariance have been\nintroduced in neural spike train space. They can properly describe template and\nvariability in spike train data, but are often sensitive to outliers and\nexpensive to compute. Recent studies also examine outlier detection and\nclassification methods on point processes. These tools provide reasonable and\nefficient result, whereas the accuracy remains at a low level in certain cases.\nIn this study, we propose to adopt a well-established notion of statistical\ndepth to the spike train space. This framework can naturally define the median\nin a set of spike trains, which provides a robust description of the 'center'\nor 'template' of the observations. It also provides a principled method to\nidentify 'outliers' in the data and classify data from different categories. We\nsystematically compare the median with the state-of-the-art 'mean spike trains'\nin terms of robustness and efficiency. The performance of our novel outlier\ndetection and classification tools will be compared with previous methods. The\nresult shows the median has superior description for 'template' than the mean.\nMoreover, the proposed outlier detection and classification perform more\naccurately than previous methods. The advantages and superiority are well\nillustrated with simulations and real data.",
                "authors": [
                    "Xinyu Zhou",
                    "Wei Wu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13676v1",
                    "http://arxiv.org/pdf/2311.13676v1"
                ],
                "primary_category": "stat.AP",
                "categories": [
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13670v1/1.0",
                "title": "An explicit error correction scheme and code distance for bosonic codes\n  with rotational symmetry",
                "year": 2023,
                "abstract": "Bosonic codes with rotational symmetry are currently one of the\nbest-performing quantum error-correcting codes. Little is known about error\npropagation and code distance for these rotation codes in contrast to qubit\ncodes and Bosonic codes with translation symmetry. We use a general-purpose\nerror basis that is naturally suited to codes with rotation symmetry to compute\nhow errors propagate through gates. This error basis allows us to give an\nexplicit error detection, decoding, and correction scheme for any code with\nrotation symmetry. We also prove that codes with an $N$-fold rotation symmetry\nhave a distance of $(d_n, d_\\theta)=(N, \\pi/N)$ with respect to number and\nrotation errors.",
                "authors": [
                    "Benjamin Marinoff",
                    "Miles Bush",
                    "Joshua Combes"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13670v1",
                    "http://arxiv.org/pdf/2311.13670v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13668v1/1.0",
                "title": "MAIRA-1: A specialised large multimodal model for radiology report\n  generation",
                "year": 2023,
                "abstract": "We present a radiology-specific multimodal model for the task for generating\nradiological reports from chest X-rays (CXRs). Our work builds on the idea that\nlarge language model(s) can be equipped with multimodal capabilities through\nalignment with pre-trained vision encoders. On natural images, this has been\nshown to allow multimodal models to gain image understanding and description\ncapabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image\nencoder in conjunction with a fine-tuned large language model based on\nVicuna-7B, and text-based data augmentation, to produce reports with\nstate-of-the-art quality. In particular, MAIRA-1 significantly improves on the\nradiologist-aligned RadCliQ metric and across all lexical metrics considered.\nManual review of model outputs demonstrates promising fluency and accuracy of\ngenerated reports while uncovering failure modes not captured by existing\nevaluation practices. More information and resources can be found on the\nproject website: https://aka.ms/maira.",
                "authors": [
                    "Stephanie L. Hyland",
                    "Shruthi Bannur",
                    "Kenza Bouzid",
                    "Daniel C. Castro",
                    "Mercy Ranjit",
                    "Anton Schwaighofer",
                    "Fernando P\u00e9rez-Garc\u00eda",
                    "Valentina Salvatelli",
                    "Shaury Srivastav",
                    "Anja Thieme",
                    "Noel Codella",
                    "Matthew P. Lungren",
                    "Maria Teodora Wetscherek",
                    "Ozan Oktay",
                    "Javier Alvarez-Valle"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13668v1",
                    "http://arxiv.org/pdf/2311.13668v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13657v1/1.0",
                "title": "Efficient Transformer Knowledge Distillation: A Performance Review",
                "year": 2023,
                "abstract": "As pretrained transformer language models continue to achieve\nstate-of-the-art performance, the Natural Language Processing community has\npushed for advances in model compression and efficient attention mechanisms to\naddress high computational requirements and limited input sequence length.\nDespite these separate efforts, no investigation has been done into the\nintersection of these two fields. In this work, we provide an evaluation of\nmodel compression via knowledge distillation on efficient attention\ntransformers. We provide cost-performance trade-offs for the compression of\nstate-of-the-art efficient attention architectures and the gains made in\nperformance in comparison to their full attention counterparts. Furthermore, we\nintroduce a new long-context Named Entity Recognition dataset, GONERD, to train\nand test the performance of NER models on long sequences. We find that\ndistilled efficient attention transformers can preserve a significant amount of\noriginal model performance, preserving up to 98.6% across short-context tasks\n(GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context\nQuestion-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on\nlong-context Named Entity Recognition (GONERD), while decreasing inference\ntimes by up to 57.8%. We find that, for most models on most tasks, performing\nknowledge distillation is an effective method to yield high-performing\nefficient attention models with low costs.",
                "authors": [
                    "Nathan Brown",
                    "Ashton Williamson",
                    "Tahj Anderson",
                    "Logan Lawrence"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13657v1",
                    "http://arxiv.org/pdf/2311.13657v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13649v1/1.0",
                "title": "Probing Dark Sectors with Neutron Stars",
                "year": 2023,
                "abstract": "Tensions in measurements of neutron and kaon weak decays, such as of the\nneutron lifetime, may speak to the existence of new particles and dynamics not\npresent in the Standard Model (SM). In scenarios with dark sectors, particles\nthat couple feebly to those of the SM appear. We offer a focused overview of\nsuch possibilities and describe how observations of neutron stars, that probe\neither their structure or dynamics, limit them. In realizing these constraints\nwe highlight how the assessment of particle processes within dense baryonic\nmatter impacts the emerging picture -- and we emphasize both the flavor\nstructure of the constraints and their broader connections to cogenesis models\nof dark matter and baryogenesis.",
                "authors": [
                    "Susan Gardner",
                    "Mohammadreza Zakeri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13649v1",
                    "http://arxiv.org/pdf/2311.13649v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "astro-ph.HE",
                    "nucl-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13647v1/1.0",
                "title": "Language Model Inversion",
                "year": 2023,
                "abstract": "Language models produce a distribution over the next token; can we use this\ninformation to recover the prompt tokens? We consider the problem of language\nmodel inversion and show that next-token probabilities contain a surprising\namount of information about the preceding text. Often we can recover the text\nin cases where it is hidden from the user, motivating a method for recovering\nunknown prompts given only the model's current distribution output. We consider\na variety of model access scenarios, and show how even without predictions for\nevery token in the vocabulary we can recover the probability vector through\nsearch. On Llama-2 7b, our inversion method reconstructs prompts with a BLEU of\n$59$ and token-level F1 of $78$ and recovers $27\\%$ of prompts exactly. Code\nfor reproducing all experiments is available at\nhttp://github.com/jxmorris12/vec2text.",
                "authors": [
                    "John X. Morris",
                    "Wenting Zhao",
                    "Justin T. Chiu",
                    "Vitaly Shmatikov",
                    "Alexander M. Rush"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13647v1",
                    "http://arxiv.org/pdf/2311.13647v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13642v1/1.0",
                "title": "Gravitational lenses in hydrodynamical simulations",
                "year": 2023,
                "abstract": "The gravitational lensing signal produced by a galaxy or a galaxy cluster is\ndetermined by its total matter distribution, providing us with a way to\ndirectly constrain their dark matter content. State-of-the-art numerical\nsimulations successfully reproduce many observed properties of galaxies and can\nbe used as a source of mock observations and predictions. Many gravitational\nlensing studies aim at constraining the nature of dark matter, discriminating\nbetween cold dark matter and alternative models. However, many past results are\nbased on the comparison to simulations that did not include baryonic physics.\nHere we show that the presence of baryons can significantly alter the\npredictions: we look at the structural properties (profiles and shapes) of\nelliptical galaxies and at the inner density slope of subhaloes. Our results\ndemonstrate that future simulations must model the interplay between baryons\nand alternative dark matter, to generate realistic predictions that could\nsignificantly modify the current constraints.",
                "authors": [
                    "Giulia Despali",
                    "Felix M. Heinze",
                    "Claudio Mastromarino"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13642v1",
                    "http://arxiv.org/pdf/2311.13642v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13640v2/1.0",
                "title": "Primordial Black Holes from Conformal Higgs",
                "year": 2023,
                "abstract": "Scale-invariant extensions of the electroweak theory are not only attractive\nbecause they can dynamically generate the weak scale, but also due to their\nrole in facilitating supercooled first-order phase transitions. We study the\nminimal scale-invariant $U(1)_{\\rm D}$ extension of the standard model and show\nthat Primordial Black Holes (PBHs) can be abundantly produced. The mass of\nthese PBHs is bounded from above by that of the moon due to QCD catalysis\nlimiting the amount of supercooling. Lunar-mass PBHs, which are produced for\ndark Higgs vev $v_\\phi\\simeq 20~\\rm TeV$, correspond to the best likelihood to\nexplain the HSC lensing anomaly. For $v_\\phi\\gtrsim 400~\\rm TeV$, the model can\nexplain hundred per cent of dark matter. At even larger hierarchy of scales, it\ncan contribute to the $511~\\rm keV$ excess. While the gravitational wave (GW)\nsignal produced by the HSC anomaly interpretation is large and detectable by\nLISA above astrophysical foreground, the dark matter interpretation in terms of\nPBHs can not be entirely probed by future GW detection. This is due to the\ndilution of the signal by the entropy injected during the decay of the\nlong-lived $U(1)_{\\rm D}$ scalar. This extended lifetime is a natural\nconsequence of the large hierarchy of scales.",
                "authors": [
                    "Yann Gouttenoire"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13640v2",
                    "http://arxiv.org/pdf/2311.13640v2"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "astro-ph.CO",
                    "gr-qc",
                    "hep-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13641v2/1.0",
                "title": "Emergent chiral metal near a Kondo breakdown quantum phase transition",
                "year": 2023,
                "abstract": "The destruction of the Kondo effect in a local-moment metal can lead to a\ntopological non-Fermi-liquid phase, dubbed fractionalized Fermi liquid, with\nspinon-type excitations and an emergent gauge field. We demonstrate that, if\nthe latter displays an internal $\\pi$-flux structure, a chiral heavy-fermion\nmetal naturally emerges near the Kondo-breakdown transition. Utilizing a parton\nmean-field theory describing the transition between a conventional heavy Fermi\nliquid and a U(1) fractionalized Fermi liquid, we find a novel intermediate\nphase near the transition whose emergent flux pattern spontaneously breaks both\ntranslation and time-reversal symmetries. This phase is an orbital\nantiferromagnet, and we discuss its relevance to pertinent experiments.",
                "authors": [
                    "Tom Drechsler",
                    "Matthias Vojta"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13641v2",
                    "http://arxiv.org/pdf/2311.13641v2"
                ],
                "primary_category": "cond-mat.str-el",
                "categories": [
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13629v1/1.0",
                "title": "Diffusion models meet image counter-forensics",
                "year": 2023,
                "abstract": "From its acquisition in the camera sensors to its storage, different\noperations are performed to generate the final image. This pipeline imprints\nspecific traces into the image to form a natural watermark. Tampering with an\nimage disturbs these traces; these disruptions are clues that are used by most\nmethods to detect and locate forgeries. In this article, we assess the\ncapabilities of diffusion models to erase the traces left by forgers and,\ntherefore, deceive forensics methods. Such an approach has been recently\nintroduced for adversarial purification, achieving significant performance. We\nshow that diffusion purification methods are well suited for counter-forensics\ntasks. Such approaches outperform already existing counter-forensics techniques\nboth in deceiving forensics methods and in preserving the natural look of the\npurified images. The source code is publicly available at\nhttps://github.com/mtailanian/diff-cf.",
                "authors": [
                    "Mat\u00edas Tailanian",
                    "Marina Gardella",
                    "\u00c1lvaro Pardo",
                    "Pablo Mus\u00e9"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13629v1",
                    "http://arxiv.org/pdf/2311.13629v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13601v1/1.0",
                "title": "Visual In-Context Prompting",
                "year": 2023,
                "abstract": "In-context prompting in large language models (LLMs) has become a prevalent\napproach to improve zero-shot capabilities, but this idea is less explored in\nthe vision domain. Existing visual prompting methods focus on referring\nsegmentation to segment the most relevant object, falling short of addressing\nmany generic vision tasks like open-set segmentation and detection. In this\npaper, we introduce a universal visual in-context prompting framework for both\ntasks. In particular, we build on top of an encoder-decoder architecture, and\ndevelop a versatile prompt encoder to support a variety of prompts like\nstrokes, boxes, and points. We further enhance it to take an arbitrary number\nof reference image segments as the context. Our extensive explorations show\nthat the proposed visual in-context prompting elicits extraordinary referring\nand generic segmentation capabilities to refer and detect, yielding competitive\nperformance to close-set in-domain datasets and showing promising results on\nmany open-set segmentation datasets. By joint training on COCO and SA-1B, our\nmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be\navailable at https://github.com/UX-Decoder/DINOv.",
                "authors": [
                    "Feng Li",
                    "Qing Jiang",
                    "Hao Zhang",
                    "Tianhe Ren",
                    "Shilong Liu",
                    "Xueyan Zou",
                    "Huaizhe Xu",
                    "Hongyang Li",
                    "Chunyuan Li",
                    "Jianwei Yang",
                    "Lei Zhang",
                    "Jianfeng Gao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13601v1",
                    "http://arxiv.org/pdf/2311.13601v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13598v1/1.0",
                "title": "Cram\u00e9r-Rao Bounds for the Simultaneous Estimation of Power System\n  Electromechanical Modes and Forced Oscillations",
                "year": 2023,
                "abstract": "In this paper, the Cram\\'{e}r-Rao Bounds (CRB) for the simultaneous\nestimation of power system electromechanical modes and forced oscillations (FO)\nare derived. Two cases are considered; in the first case only the steady-state\nresponse to the FO is present in the measured system output used by estimation\nalgorithms. In the second, the startup transient of the FO is present in\naddition to the steady-state response. The CRBs are analyzed numerically to\nexplore sensitivities to FO frequency, signal-to-noise ratio (SNR) and\nobservation window length. It is demonstrated that 1) the CRB of FO parameters\nis not affected by the presence of the transient response, 2) the CRB of the\nsystem modes is not affected by the presence of an FO in steady-state and 3)\nthe CRB of the system modes can be drastically reduced by the presence of a FO\nstartup transient.",
                "authors": [
                    "Luke Dosiek"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13598v1",
                    "http://arxiv.org/pdf/2311.13598v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13595v1/1.0",
                "title": "Covariance alignment: from maximum likelihood estimation to\n  Gromov-Wasserstein",
                "year": 2023,
                "abstract": "Feature alignment methods are used in many scientific disciplines for data\npooling, annotation, and comparison. As an instance of a permutation learning\nproblem, feature alignment presents significant statistical and computational\nchallenges. In this work, we propose the covariance alignment model to study\nand compare various alignment methods and establish a minimax lower bound for\ncovariance alignment that has a non-standard dimension scaling because of the\npresence of a nuisance parameter. This lower bound is in fact minimax optimal\nand is achieved by a natural quasi MLE. However, this estimator involves a\nsearch over all permutations which is computationally infeasible even when the\nproblem has moderate size. To overcome this limitation, we show that the\ncelebrated Gromov-Wasserstein algorithm from optimal transport which is more\namenable to fast implementation even on large-scale problems is also minimax\noptimal. These results give the first statistical justification for the\ndeployment of the Gromov-Wasserstein algorithm in practice.",
                "authors": [
                    "Yanjun Han",
                    "Philippe Rigollet",
                    "George Stepaniants"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13595v1",
                    "http://arxiv.org/pdf/2311.13595v1"
                ],
                "primary_category": "math.ST",
                "categories": [
                    "math.ST",
                    "cs.LG",
                    "stat.ME",
                    "stat.ML",
                    "stat.TH",
                    "Primary 62C20, 90B80, 49Q22, secondary 62R07, 05C60",
                    "G.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13594v1/1.0",
                "title": "Labeling Neural Representations with Inverse Recognition",
                "year": 2023,
                "abstract": "Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning\ncomplex hierarchical data representations, but the nature of these\nrepresentations remains largely unknown. Existing global explainability\nmethods, such as Network Dissection, face limitations such as reliance on\nsegmentation masks, lack of statistical significance testing, and high\ncomputational demands. We propose Inverse Recognition (INVERT), a scalable\napproach for connecting learned representations with human-understandable\nconcepts by leveraging their capacity to discriminate between these concepts.\nIn contrast to prior work, INVERT is capable of handling diverse types of\nneurons, exhibits less computational complexity, and does not rely on the\navailability of segmentation masks. Moreover, INVERT provides an interpretable\nmetric assessing the alignment between the representation and its corresponding\nexplanation and delivering a measure of statistical significance, emphasizing\nits utility and credibility. We demonstrate the applicability of INVERT in\nvarious scenarios, including the identification of representations affected by\nspurious correlations, and the interpretation of the hierarchical structure of\ndecision-making within the models.",
                "authors": [
                    "Kirill Bykov",
                    "Laura Kopf",
                    "Shinichi Nakajima",
                    "Marius Kloft",
                    "Marina M. -C. H\u00f6hne"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13594v1",
                    "http://arxiv.org/pdf/2311.13594v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13593v1/1.0",
                "title": "Partial Resolutions of Affine Symplectic Singularities",
                "year": 2023,
                "abstract": "We explore the relationship between the Poisson deformation theory,\nbirational geometry, and Springer theory of crepant partial resolutions of\nconical affine symplectic singularities. We show that given any crepant partial\nresolution $X'$, the Poisson deformation functor of $X'$ is prorepresentable\nand unobstructed. Additionally, we define a version of the Namikawa Weyl group\n$W_{X'}$ for partial resolutions, such that $W_{X'}$ is a parabolic subgroup of\nthe Namikawa Weyl group $W_X$ determined by the birational geometry of $X'$, in\nparticular by a face of a relative movable cone. If $Y$ is a Q-factorial\nterminalization which covers $X'$, we show there is a natural morphism from\nPoisson deformations of $Y$ to those of $X'$, and that this morphism is a\nGalois covering with Galois group $W_{X'}$, building on work of Namikawa.\nFinally, we put these partial resolutions and their universal deformations into\nthe context of work of McGerty and Nevins, obtaining some preliminary results\nconcerning their Springer theory.",
                "authors": [
                    "Alberto San Miguel Malaney"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13593v1",
                    "http://arxiv.org/pdf/2311.13593v1"
                ],
                "primary_category": "math.RT",
                "categories": [
                    "math.RT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13592v2/1.0",
                "title": "High-efficiency high-NA metalens designed by maximizing the efficiency\n  limit",
                "year": 2023,
                "abstract": "Theoretical bounds are commonly used to assess the limitations of photonic\ndesign. Here we introduce a more active way to use theoretical bounds,\nintegrating them into part of the design process and identifying optimal system\nparameters that maximize the efficiency limit itself. As an example, we\nconsider wide-field-of-view high-numerical-aperture metalenses, which can be\nused for high-resolution imaging in microscopy and endoscopy, but no existing\ndesign has achieved a high efficiency. By choosing aperture sizes to maximize\nan efficiency bound, setting the thickness according to a thickness bound, and\nthen performing inverse design, we come up with high-numerical-aperture (NA =\n0.9) metalens designs with record-high 98% transmission efficiency and 92%\nStrehl ratio across all incident angles within a 60-deg field of view, reaching\nthe maximized bound. This maximizing-efficiency-limit approach applies to any\nmulti-channel system and can help a wide range of optical devices reach their\nhighest possible performance.",
                "authors": [
                    "Shiyu Li",
                    "Ho-Chun Lin",
                    "Chia Wei Hsu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13592v2",
                    "http://arxiv.org/pdf/2311.13592v2"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13628v1/1.0",
                "title": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of\n  Large Language Models",
                "year": 2023,
                "abstract": "The recent explosion in the capabilities of large language models has led to\na wave of interest in how best to prompt a model to perform a given task. While\nit may be tempting to simply choose a prompt based on average performance on a\nvalidation set, this can lead to a deployment where unexpectedly poor responses\nare generated, especially for the worst-off users. To mitigate this prospect,\nwe propose Prompt Risk Control, a lightweight framework for selecting a prompt\nbased on rigorous upper bounds on families of informative risk measures. We\noffer methods for producing bounds on a diverse set of metrics, including\nquantities that measure worst-case responses and disparities in generation\nquality across the population of users. In addition, we extend the underlying\nstatistical bounding techniques to accommodate the possibility of distribution\nshifts in deployment. Experiments on applications such as open-ended chat,\nmedical question summarization, and code generation highlight how such a\nframework can foster responsible deployment by reducing the risk of the worst\noutcomes.",
                "authors": [
                    "Thomas P. Zollo",
                    "Todd Morrill",
                    "Zhun Deng",
                    "Jake C. Snell",
                    "Toniann Pitassi",
                    "Richard Zemel"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13628v1",
                    "http://arxiv.org/pdf/2311.13628v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13589v1/1.0",
                "title": "Risk-sensitive Markov Decision Process and Learning under General\n  Utility Functions",
                "year": 2023,
                "abstract": "Reinforcement Learning (RL) has gained substantial attention across diverse\napplication domains and theoretical investigations. Existing literature on RL\ntheory largely focuses on risk-neutral settings where the decision-maker learns\nto maximize the expected cumulative reward. However, in practical scenarios\nsuch as portfolio management and e-commerce recommendations, decision-makers\noften persist in heterogeneous risk preferences subject to outcome\nuncertainties, which can not be well-captured by the risk-neural framework.\nIncorporating these preferences can be approached through utility theory, yet\nthe development of risk-sensitive RL under general utility functions remains an\nopen question for theoretical exploration.\n  In this paper, we consider a scenario where the decision-maker seeks to\noptimize a general utility function of the cumulative reward in the framework\nof a Markov decision process (MDP). To facilitate the Dynamic Programming\nPrinciple and Bellman equation, we enlarge the state space with an additional\ndimension that accounts for the cumulative reward. We propose a discretized\napproximation scheme to the MDP under enlarged state space, which is tractable\nand key for algorithmic design. We then propose a modified value iteration\nalgorithm that employs an epsilon-covering over the space of cumulative reward.\nWhen a simulator is accessible, our algorithm efficiently learns a near-optimal\npolicy with guaranteed sample complexity. In the absence of a simulator, our\nalgorithm, designed with an upper-confidence-bound exploration approach,\nidentifies a near-optimal policy while ensuring a guaranteed regret bound. For\nboth algorithms, we match the theoretical lower bounds for the risk-neutral\nsetting.",
                "authors": [
                    "Zhengqi Wu",
                    "Renyuan Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13589v1",
                    "http://arxiv.org/pdf/2311.13589v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13588v1/1.0",
                "title": "User-guided Page Merging for Memory Deduplication in Serverless Systems",
                "year": 2023,
                "abstract": "Serverless computing is an emerging cloud paradigm that offers an elastic and\nscalable allocation of computing resources with pay-as-you-go billing. In the\nFunction-as-a-Service (FaaS) programming model, applications comprise\nshort-lived and stateless serverless functions executed in isolated containers\nor microVMs, which can quickly scale to thousands of instances and process\nterabytes of data. This flexibility comes at the cost of duplicated runtimes,\nlibraries, and user data spread across many function instances, and cloud\nproviders do not utilize this redundancy. The memory footprint of serverless\nforces removing idle containers to make space for new ones, which decreases\nperformance through more cold starts and fewer data caching opportunities. We\naddress this issue by proposing deduplicating memory pages of serverless\nworkers with identical content, based on the content-based page-sharing concept\nof Linux Kernel Same-page Merging (KSM). We replace the background memory\nscanning process of KSM, as it is too slow to locate sharing candidates in\nshort-lived functions. Instead, we design User-Guided Page Merging (UPM), a\nbuilt-in Linux kernel module that leverages the madvise system call: we enable\nusers to advise the kernel of memory areas that can be shared with others. We\nshow that UPM reduces memory consumption by up to 55% on 16 concurrent\ncontainers executing a typical image recognition function, more than doubling\nthe density for containers of the same function that can run on a system.",
                "authors": [
                    "Wei Qiu",
                    "Marcin Copik",
                    "Yun Wang",
                    "Alexandru Calotoiu",
                    "Torsten Hoefler"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13588v1",
                    "http://arxiv.org/pdf/2311.13588v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13587v1/1.0",
                "title": "A Survey of Serverless Machine Learning Model Inference",
                "year": 2023,
                "abstract": "Recent developments in Generative AI, Computer Vision, and Natural Language\nProcessing have led to an increased integration of AI models into various\nproducts. This widespread adoption of AI requires significant efforts in\ndeploying these models in production environments. When hosting machine\nlearning models for real-time predictions, it is important to meet defined\nService Level Objectives (SLOs), ensuring reliability, minimal downtime, and\noptimizing operational costs of the underlying infrastructure. Large machine\nlearning models often demand GPU resources for efficient inference to meet\nSLOs. In the context of these trends, there is growing interest in hosting AI\nmodels in a serverless architecture while still providing GPU access for\ninference tasks. This survey aims to summarize and categorize the emerging\nchallenges and optimization opportunities for large-scale deep learning serving\nsystems. By providing a novel taxonomy and summarizing recent trends, we hope\nthat this survey could shed light on new optimization perspectives and motivate\nnovel works in large-scale deep learning serving systems.",
                "authors": [
                    "Kamil Kojs"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13587v1",
                    "http://arxiv.org/pdf/2311.13587v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13584v1/1.0",
                "title": "On diffusion-based generative models and their error bounds: The\n  log-concave case with full convergence estimates",
                "year": 2023,
                "abstract": "We provide full theoretical guarantees for the convergence behaviour of\ndiffusion-based generative models under the assumption of strongly logconcave\ndata distributions while our approximating class of functions used for score\nestimation is made of Lipschitz continuous functions. We demonstrate via a\nmotivating example, sampling from a Gaussian distribution with unknown mean,\nthe powerfulness of our approach. In this case, explicit estimates are provided\nfor the associated optimization problem, i.e. score approximation, while these\nare combined with the corresponding sampling estimates. As a result, we obtain\nthe best known upper bound estimates in terms of key quantities of interest,\nsuch as the dimension and rates of convergence, for the Wasserstein-2 distance\nbetween the data distribution (Gaussian with unknown mean) and our sampling\nalgorithm.\n  Beyond the motivating example and in order to allow for the use of a diverse\nrange of stochastic optimizers, we present our results using an $L^2$-accurate\nscore estimation assumption, which crucially is formed under an expectation\nwith respect to the stochastic optimizer and our novel auxiliary process that\nuses only known information. This approach yields the best known convergence\nrate for our sampling algorithm.",
                "authors": [
                    "Stefano Bruno",
                    "Ying Zhang",
                    "Dong-Young Lim",
                    "\u00d6mer Deniz Akyildiz",
                    "Sotirios Sabanis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13584v1",
                    "http://arxiv.org/pdf/2311.13584v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.OC",
                    "math.PR",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13581v1/1.0",
                "title": "PaSS: Parallel Speculative Sampling",
                "year": 2023,
                "abstract": "Scaling the size of language models to tens of billions of parameters has led\nto impressive performance on a wide range of tasks. At generation, these models\nare used auto-regressively, requiring a forward pass for each generated token,\nand thus reading the full set of parameters from memory. This memory access\nforms the primary bottleneck for generation and it worsens as the model size\nincreases. Moreover, executing a forward pass for multiple tokens in parallel\noften takes nearly the same time as it does for just one token. These two\nobservations lead to the development of speculative sampling, where a second\nsmaller model is used to draft a few tokens, that are then validated or\nrejected using a single forward pass of the large model. Unfortunately, this\nmethod requires two models that share the same tokenizer and thus limits its\nadoption. As an alternative, we propose to use parallel decoding as a way to\ndraft multiple tokens from a single model with no computational cost, nor the\nneed for a second model. Our approach only requires an additional input token\nthat marks the words that will be generated simultaneously. We show promising\nperformance (up to $30\\%$ speed-up) while requiring only as few as $O(d_{emb})$\nadditional parameters.",
                "authors": [
                    "Giovanni Monea",
                    "Armand Joulin",
                    "Edouard Grave"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13581v1",
                    "http://arxiv.org/pdf/2311.13581v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13579v1/1.0",
                "title": "Nucleation phenomena and extreme vulnerability of spatial k-core systems",
                "year": 2023,
                "abstract": "K-core percolation is a fundamental dynamical process in complex networks\nwith applications that span numerous real-world systems. Earlier studies focus\nprimarily on random networks without spatial constraints and reveal intriguing\nmixed-order transitions. However, real-world systems, ranging from\ntransportation and communication networks to complex brain networks, are not\nrandom but are spatially embedded. Here, we study k-core percolation on\ntwo-dimensional spatially embedded networks and show that, in contrast to\nregular percolation, the length of connections can control the transition type,\nleading to four different types of phase transitions associated with novel\nphenomena and a rich phase diagram. A key finding is the existence of a\nmetastable phase in which microscopic localized damage, independent of system\nsize, can cause a macroscopic phase transition, a result which cannot be\nachieved in traditional percolation. In this case, local failures can\nspontaneously propagate the damage radially until the system entirely\ncollapses, a phenomenon analogous to the nucleation process. These findings\nsuggest novel features and extreme vulnerabilities of spatially embedded k-core\nnetwork systems, and highlight the necessity to take into account the\ncharacteristic length of links when designing robust spatial networks.\nFurthermore, our insight about the microscopic processes and their origin\nduring the mixed order and first order abrupt transitions in k-core networks\ncould shed light on the mechanisms of many systems where such transitions\noccur.",
                "authors": [
                    "Leyang Xue",
                    "Shengling Gao",
                    "Lazaros K. Gallos",
                    "Orr Levy",
                    "Bnaya Gross",
                    "Zengru Di",
                    "Shlomo Havlin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13579v1",
                    "http://arxiv.org/pdf/2311.13579v1"
                ],
                "primary_category": "physics.soc-ph",
                "categories": [
                    "physics.soc-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13578v1/1.0",
                "title": "Hadronic Mono-$W'$ Probes of Dark Matter at Colliders",
                "year": 2023,
                "abstract": "Particle collisions at the energy frontier can probe the nature of invisible\ndark matter via production in association with recoiling visible objects. We\npropose a new potential production mode, in which dark matter is produced by\nthe decay of a heavy dark Higgs boson radiated from a heavy $W'$ boson. In such\na model, motivated by left-right symmetric theories, dark matter would not be\npair produced in association with other recoiling objects due to its lack of\ndirect coupling to quarks or gluons. We study the hadronic decay mode via\n$W'\\rightarrow tb$ and estimate the LHC exclusion sensitivity at 95\\%\nconfidence level to be $10^2-10^5$ fb for $W'$ boson masses between 250 and\n1750 GeV.",
                "authors": [
                    "Ryan Holder",
                    "John Reddick",
                    "Matteo Cremonesi",
                    "Doug Berry",
                    "Kun Cheng",
                    "Matthew Low",
                    "Tim M. P. Tait",
                    "Daniel Whiteson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13578v1",
                    "http://arxiv.org/pdf/2311.13578v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13577v1/1.0",
                "title": "Physical Reasoning and Object Planning for Household Embodied Agents",
                "year": 2023,
                "abstract": "In this study, we explore the sophisticated domain of task planning for\nrobust household embodied agents, with a particular emphasis on the intricate\ntask of selecting substitute objects. We introduce the CommonSense Object\nAffordance Task (COAT), a novel framework designed to analyze reasoning\ncapabilities in commonsense scenarios. This approach is centered on\nunderstanding how these agents can effectively identify and utilize alternative\nobjects when executing household tasks, thereby offering insights into the\ncomplexities of practical decision-making in real-world environments.Drawing\ninspiration from human decision-making, we explore how large language models\ntackle this challenge through three meticulously crafted commonsense\nquestion-and-answer datasets, featuring refined rules and human annotations.\nOur evaluation of state-of-the-art language models on these datasets sheds\nlight on three pivotal considerations: 1) aligning an object's inherent utility\nwith the task at hand, 2) navigating contextual dependencies (societal norms,\nsafety, appropriateness, and efficiency), and 3) accounting for the current\nphysical state of the object. To maintain accessibility, we introduce five\nabstract variables reflecting an object's physical condition, modulated by\nhuman insights to simulate diverse household scenarios. Our contributions\ninclude insightful Object-Utility mappings addressing the first consideration\nand two extensive QA datasets (15k and 130k questions) probing the intricacies\nof contextual dependencies and object states. The datasets, along with our\nfindings, are accessible at: \\url{https://github.com/com-phy-affordance/COAT}.\nThis research not only advances our understanding of physical commonsense\nreasoning in language models but also paves the way for future improvements in\nhousehold agent intelligence.",
                "authors": [
                    "Ayush Agrawal",
                    "Raghav Prabhakar",
                    "Anirudh Goyal",
                    "Dianbo Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13577v1",
                    "http://arxiv.org/pdf/2311.13577v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13575v2/1.0",
                "title": "Large-Sample Properties of the Synthetic Control Method under Selection\n  on Unobservables",
                "year": 2023,
                "abstract": "We analyze the synthetic control (SC) method in panel data settings with many\nunits. We assume the treatment assignment is based on unobserved heterogeneity\nand pre-treatment information, allowing for both strictly and sequentially\nexogenous assignment processes. We show that the critical property that\ndetermines the behavior of the SC method is the ability of input features to\napproximate the unobserved heterogeneity. Our results imply that the SC method\ndelivers asymptotically normal estimators for a large class of linear panel\ndata models as long as the number of pre-treatment periods is sufficiently\nlarge, making it a natural alternative to the Difference-in-Differences.",
                "authors": [
                    "Dmitry Arkhangelsky",
                    "David Hirshberg"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13575v2",
                    "http://arxiv.org/pdf/2311.13575v2"
                ],
                "primary_category": "econ.EM",
                "categories": [
                    "econ.EM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13565v1/1.0",
                "title": "Drilling Down into the Discourse Structure with LLMs for Long Document\n  Question Answering",
                "year": 2023,
                "abstract": "We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.",
                "authors": [
                    "Inderjeet Nair",
                    "Shwetha Somasundaram",
                    "Apoorv Saxena",
                    "Koustava Goswami"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13565v1",
                    "http://arxiv.org/pdf/2311.13565v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13562v2/1.0",
                "title": "Soulstyler: Using Large Language Model to Guide Image Style Transfer for\n  Target Object",
                "year": 2023,
                "abstract": "Image style transfer occupies an important place in both computer graphics\nand computer vision. However, most current methods require reference to\nstylized images and cannot individually stylize specific objects. To overcome\nthis limitation, we propose the \"Soulstyler\" framework, which allows users to\nguide the stylization of specific objects in an image through simple textual\ndescriptions. We introduce a large language model to parse the text and\nidentify stylization goals and specific styles. Combined with a CLIP-based\nsemantic visual embedding encoder, the model understands and matches text and\nimage content. We also introduce a novel localized text-image block matching\nloss that ensures that style transfer is performed only on specified target\nobjects, while non-target regions remain in their original style. Experimental\nresults demonstrate that our model is able to accurately perform style transfer\non target objects according to textual descriptions without affecting the style\nof background regions. Our code will be available at\nhttps://github.com/yisuanwang/Soulstyler.",
                "authors": [
                    "Junhao Chen",
                    "Peng Rong",
                    "Jingbo Sun",
                    "Chao Li",
                    "Xiang Li",
                    "Hongwu Lv"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13562v2",
                    "http://arxiv.org/pdf/2311.13562v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13553v2/1.0",
                "title": "Tachyon condensation in a chromomagnetic center-vortex background",
                "year": 2023,
                "abstract": "The chromomagnetic vacuum of SU(2) gluodynamics is considered in the\nbackground of a finite radius flux tube (center-vortex) with homogeneous field\ninside and zero field outside. In this background there are tachyonic modes.\nThese modes cause an instability. It is assumed that the selfinteraction of\nthese modes stops the creation of gluons and that a condensate will be formed.\nFor constant condensates, the minimum of the effective potential is found on\nthe tree level. In the background of these condensates, all tachyonic modes\nacquire nonzero, real masses which will result in a real effective potential of\nthis system.\n  Considering only the tachyonic modes and adding the energy of the background\nfield, the total energy is found to have a minimum at some value of the\nbackground field, which depends on the coupling of the initial SU(2) model. For\nsmall coupling, this dependence is polynomial in distinction from the Savvidy\nvacuum where it is exponentially suppressed. The minimum of this energy will\ndeepens with shrinking radius of the flux tube. It can be expected that this\nprocess can be stopped by adding quantum effects. Using the high temperature\nexpansion of the effective potential, it can be expected that the symmetry,\nwhich is broken by the condensate, will be restored at sufficiently high\ntemperature.",
                "authors": [
                    "M. Bordag"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13553v2",
                    "http://arxiv.org/pdf/2311.13553v2"
                ],
                "primary_category": "hep-th",
                "categories": [
                    "hep-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13549v1/1.0",
                "title": "ADriver-I: A General World Model for Autonomous Driving",
                "year": 2023,
                "abstract": "Typically, autonomous driving adopts a modular design, which divides the full\nstack into perception, prediction, planning and control parts. Though\ninterpretable, such modular design tends to introduce a substantial amount of\nredundancy. Recently, multimodal large language models (MLLM) and diffusion\ntechniques have demonstrated their superior performance on comprehension and\ngeneration ability. In this paper, we first introduce the concept of\ninterleaved vision-action pair, which unifies the format of visual features and\ncontrol signals. Based on the vision-action pairs, we construct a general world\nmodel based on MLLM and diffusion model for autonomous driving, termed\nADriver-I. It takes the vision-action pairs as inputs and autoregressively\npredicts the control signal of the current frame. The generated control signals\ntogether with the historical vision-action pairs are further conditioned to\npredict the future frames. With the predicted next frame, ADriver-I performs\nfurther control signal prediction. Such a process can be repeated infinite\ntimes, ADriver-I achieves autonomous driving in the world created by itself.\nExtensive experiments are conducted on nuScenes and our large-scale private\ndatasets. ADriver-I shows impressive performance compared to several\nconstructed baselines. We hope our ADriver-I can provide some new insights for\nfuture autonomous driving and embodied intelligence.",
                "authors": [
                    "Fan Jia",
                    "Weixin Mao",
                    "Yingfei Liu",
                    "Yucheng Zhao",
                    "Yuqing Wen",
                    "Chi Zhang",
                    "Xiangyu Zhang",
                    "Tiancai Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13549v1",
                    "http://arxiv.org/pdf/2311.13549v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.RO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13627v1/1.0",
                "title": "Vamos: Versatile Action Models for Video Understanding",
                "year": 2023,
                "abstract": "What makes good video representations for video understanding, such as\nanticipating future activities, or answering video-conditioned questions? While\nearlier approaches focus on end-to-end learning directly from video pixels, we\npropose to revisit text-based representations, such as discrete action labels,\nor free-form video captions, which are interpretable and can be directly\nconsumed by large language models (LLMs). Intuitively, different video\nunderstanding tasks may require representations that are complementary and at\ndifferent granularities. To this end, we propose versatile action models\n(Vamos), a learning framework powered by a large language model as the\n\"reasoner\", and can flexibly leverage visual embeddings, action labels, and\nfree-form descriptions extracted from videos as its input. We evaluate Vamos on\nfour complementary video understanding benchmarks, Ego4D, Next-QA, IntentQA,\nand EgoSchema, on its capability to model temporal dynamics, encode visual\nhistory, and perform reasoning. Surprisingly, we observe that text-based\nrepresentations consistently achieve competitive performance on all benchmarks,\nand that visual embeddings provide marginal or no performance improvement,\ndemonstrating the effectiveness of text-based video representation in the LLM\nera. We perform extensive ablation study and qualitative analysis to support\nour observations, and achieve state-of-the-art performance on three benchmarks.",
                "authors": [
                    "Shijie Wang",
                    "Qi Zhao",
                    "Minh Quan Do",
                    "Nakul Agarwal",
                    "Kwonjoon Lee",
                    "Chen Sun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13627v1",
                    "http://arxiv.org/pdf/2311.13627v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13626v1/1.0",
                "title": "Physics-driven generative adversarial networks empower single-pixel\n  infrared hyperspectral imaging",
                "year": 2023,
                "abstract": "A physics-driven generative adversarial network (GAN) was established here\nfor single-pixel hyperspectral imaging (HSI) in the infrared spectrum, to\neliminate the extensive data training work required by traditional data-driven\nmodel. Within the GAN framework, the physical process of single-pixel imaging\n(SPI) was integrated into the generator, and the actual and estimated\none-dimensional (1D) bucket signals were employed as constraints in the\nobjective function to update the network's parameters and optimize the\ngenerator with the assistance of the discriminator. In comparison to\nsingle-pixel infrared HSI methods based on compressed sensing and\nphysics-driven convolution neural networks, our physics-driven GAN-based\nsingle-pixel infrared HSI can achieve higher imaging performance but with fewer\nmeasurements. We believe that this physics-driven GAN will promote practical\napplications of computational imaging, especially various SPI-based techniques.",
                "authors": [
                    "Dong-Yin Wang",
                    "Shu-Hang Bie",
                    "Xi-Hao Chen",
                    "Wen-Kai Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13626v1",
                    "http://arxiv.org/pdf/2311.13626v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.AI",
                    "cs.IR",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13541v1/1.0",
                "title": "Linear Log-Normal Attention with Unbiased Concentration",
                "year": 2023,
                "abstract": "Transformer models have achieved remarkable results in a wide range of\napplications. However, their scalability is hampered by the quadratic time and\nmemory complexity of the self-attention mechanism concerning the sequence\nlength. This limitation poses a substantial obstacle when dealing with long\ndocuments or high-resolution images. In this work, we study the self-attention\nmechanism by analyzing the distribution of the attention matrix and its\nconcentration ability. Furthermore, we propose instruments to measure these\nquantities and introduce a novel self-attention mechanism, Linear Log-Normal\nAttention, designed to emulate the distribution and concentration behavior of\nthe original self-attention. Our experimental results on popular natural\nlanguage benchmarks reveal that our proposed Linear Log-Normal Attention\noutperforms other linearized attention alternatives, offering a promising\navenue for enhancing the scalability of transformer models. Our code is\navailable in supplementary materials.",
                "authors": [
                    "Yury Nahshan",
                    "Joseph Kampeas",
                    "Emir Haleva"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13541v1",
                    "http://arxiv.org/pdf/2311.13541v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "I.7.0; G.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13539v1/1.0",
                "title": "Learned Nonlinear Predictor for Critically Sampled 3D Point Cloud\n  Attribute Compression",
                "year": 2023,
                "abstract": "We study 3D point cloud attribute compression via a volumetric approach:\nassuming point cloud geometry is known at both encoder and decoder, parameters\n$\\theta$ of a continuous attribute function $f: \\mathbb{R}^3 \\mapsto\n\\mathbb{R}$ are quantized to $\\hat{\\theta}$ and encoded, so that discrete\nsamples $f_{\\hat{\\theta}}(\\mathbf{x}_i)$ can be recovered at known 3D points\n$\\mathbf{x}_i \\in \\mathbb{R}^3$ at the decoder. Specifically, we consider a\nnested sequences of function subspaces $\\mathcal{F}^{(p)}_{l_0} \\subseteq\n\\cdots \\subseteq \\mathcal{F}^{(p)}_L$, where $\\mathcal{F}_l^{(p)}$ is a family\nof functions spanned by B-spline basis functions of order $p$, $f_l^*$ is the\nprojection of $f$ on $\\mathcal{F}_l^{(p)}$ and encoded as low-pass coefficients\n$F_l^*$, and $g_l^*$ is the residual function in orthogonal subspace\n$\\mathcal{G}_l^{(p)}$ (where $\\mathcal{G}_l^{(p)} \\oplus \\mathcal{F}_l^{(p)} =\n\\mathcal{F}_{l+1}^{(p)}$) and encoded as high-pass coefficients $G_l^*$. In\nthis paper, to improve coding performance over [1], we study predicting\n$f_{l+1}^*$ at level $l+1$ given $f_l^*$ at level $l$ and encoding of $G_l^*$\nfor the $p=1$ case (RAHT($1$)). For the prediction, we formalize RAHT(1) linear\nprediction in MPEG-PCC in a theoretical framework, and propose a new nonlinear\npredictor using a polynomial of bilateral filter. We derive equations to\nefficiently compute the critically sampled high-pass coefficients $G_l^*$\namenable to encoding. We optimize parameters in our resulting feed-forward\nnetwork on a large training set of point clouds by minimizing a rate-distortion\nLagrangian. Experimental results show that our improved framework outperformed\nthe MPEG G-PCC predictor by $11$ to $12\\%$ in bit rate reduction.",
                "authors": [
                    "Tam Thuc Do",
                    "Philip A. Chou",
                    "Gene Cheung"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13539v1",
                    "http://arxiv.org/pdf/2311.13539v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.LG",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13538v1/1.0",
                "title": "Speak Like a Native: Prompting Large Language Models in a Native Style",
                "year": 2023,
                "abstract": "Existing work has found that the prompt engineering heavily influences the\nperformance of large language models (LLMs). Chain-of-thought (CoT), as a\npopular prompt engineering technique, prompted LLMs using in-context examples\nwith reasoning steps. In current studies, the few-shot examples of CoT are\ngenerally handcrafted by humans. However, how the text style of in-context\nexamples influence the outputs of LLMs still remains under-explored. This paper\npresents a novel and effective approach, named \\textbf{AlignCoT}, to improve\nthe reasoning capability of LLMs by aligning the in-context examples with the\nnative style of LLMs. ``Native'' refers to the inherent characteristic style of\nLLMs which can be probed by original zero-shot scenarios. AlignCoT is\northogonal to other prompt engineering methods, making it easy to combine with\nstate-of-the-art techniques to further improve the LLMs' performance. We\nconduct extensive and comprehensive experiments on several benchmarks. The\nempirical results demonstrate that our AlignCoTsignificantly improves\nperformance over the carefully handcrafted in-context examples. For instance,\nwith GPT-3.5-turbo, we observed a +2.5\\% improvement on GSM8K. Furthermore, our\nAlignCoT consistently improve the performance when combined with other\nstate-of-the-art prompt engineering methods. The source code and dataset will\nbe available at\n\\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.",
                "authors": [
                    "Zhicheng Yang",
                    "Yiwei Wang",
                    "Yinya Huang",
                    "Jing Xiong",
                    "Xiaodan Liang",
                    "Jing Tang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13538v1",
                    "http://arxiv.org/pdf/2311.13538v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13535v1/1.0",
                "title": "DiffusionMat: Alpha Matting as Sequential Refinement Learning",
                "year": 2023,
                "abstract": "In this paper, we introduce DiffusionMat, a novel image matting framework\nthat employs a diffusion model for the transition from coarse to refined alpha\nmattes. Diverging from conventional methods that utilize trimaps merely as\nloose guidance for alpha matte prediction, our approach treats image matting as\na sequential refinement learning process. This process begins with the addition\nof noise to trimaps and iteratively denoises them using a pre-trained diffusion\nmodel, which incrementally guides the prediction towards a clean alpha matte.\nThe key innovation of our framework is a correction module that adjusts the\noutput at each denoising step, ensuring that the final result is consistent\nwith the input image's structures. We also introduce the Alpha Reliability\nPropagation, a novel technique designed to maximize the utility of available\nguidance by selectively enhancing the trimap regions with confident alpha\ninformation, thus simplifying the correction task. To train the correction\nmodule, we devise specialized loss functions that target the accuracy of the\nalpha matte's edges and the consistency of its opaque and transparent regions.\nWe evaluate our model across several image matting benchmarks, and the results\nindicate that DiffusionMat consistently outperforms existing methods. Project\npage at~\\url{https://cnnlstm.github.io/DiffusionMat",
                "authors": [
                    "Yangyang Xu",
                    "Shengfeng He",
                    "Wenqi Shao",
                    "Kwan-Yee K. Wong",
                    "Yu Qiao",
                    "Ping Luo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13535v1",
                    "http://arxiv.org/pdf/2311.13535v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13534v4/1.0",
                "title": "LM-Cocktail: Resilient Tuning of Language Models via Model Merging",
                "year": 2023,
                "abstract": "The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose LM-Cocktail which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging, where the fine-tuned language model is merged with the\npre-trained base model or the peer models from other domains through weighted\naverage. Despite simplicity, LM-Cocktail is surprisingly effective: the\nresulted model is able to achieve a strong empirical performance in the whole\nscope of general tasks while preserving a superior capacity in its targeted\ndomain. We conduct comprehensive experiments with LLama and BGE model on\npopular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail.",
                "authors": [
                    "Shitao Xiao",
                    "Zheng Liu",
                    "Peitian Zhang",
                    "Xingrun Xing"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13534v4",
                    "http://arxiv.org/pdf/2311.13534v4"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.17065v2/1.0",
                "title": "Efficient Deep Speech Understanding at the Edge",
                "year": 2023,
                "abstract": "In contemporary speech understanding (SU), a sophisticated pipeline is\nemployed, encompassing the ingestion of streaming voice input. The pipeline\nexecutes beam search iteratively, invoking a deep neural network to generate\ntentative outputs (referred to as hypotheses) in an autoregressive manner.\nPeriodically, the pipeline assesses attention and Connectionist Temporal\nClassification (CTC) scores.\n  This paper aims to enhance SU performance on edge devices with limited\nresources. Adopting a hybrid strategy, our approach focuses on accelerating\non-device execution and offloading inputs surpassing the device's capacity.\nWhile this approach is established, we tackle SU's distinctive challenges\nthrough innovative techniques: (1) Late Contextualization: This involves the\nparallel execution of a model's attentive encoder during input ingestion. (2)\nPilot Inference: Addressing temporal load imbalances in the SU pipeline, this\ntechnique aims to mitigate them effectively. (3) Autoregression Offramps:\nDecisions regarding offloading are made solely based on hypotheses, presenting\na novel approach.\n  These techniques are designed to seamlessly integrate with existing speech\nmodels, pipelines, and frameworks, offering flexibility for independent or\ncombined application. Collectively, they form a hybrid solution for edge SU.\nOur prototype, named XYZ, has undergone testing on Arm platforms featuring 6 to\n8 cores, demonstrating state-of-the-art accuracy. Notably, it achieves a 2x\nreduction in end-to-end latency and a corresponding 2x decrease in offloading\nrequirements.",
                "authors": [
                    "Rongxiang Wang",
                    "Felix Xiaozhu Lin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.17065v2",
                    "http://arxiv.org/pdf/2311.17065v2"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13533v1/1.0",
                "title": "Volumetric 3D Point Cloud Attribute Compression: Learned polynomial\n  bilateral filter for prediction",
                "year": 2023,
                "abstract": "We extend a previous study on 3D point cloud attribute compression scheme\nthat uses a volumetric approach: given a target volumetric attribute function\n$f : \\mathbb{R}^3 \\mapsto \\mathbb{R}$, we quantize and encode parameters\n$\\theta$ that characterize $f$ at the encoder, for reconstruction\n$f_{\\hat{\\theta}}(\\mathbf(x))$ at known 3D points $\\mathbf(x)$ at the decoder.\nSpecifically, parameters $\\theta$ are quantized coefficients of B-spline basis\nvectors $\\mathbf{\\Phi}_l$ (for order $p \\geq 2$) that span the function space\n$\\mathcal{F}_l^{(p)}$ at a particular resolution $l$, which are coded from\ncoarse to fine resolutions for scalability. In this work, we focus on the\nprediction of finer-grained coefficients given coarser-grained ones by learning\nparameters of a polynomial bilateral filter (PBF) from data. PBF is a\npseudo-linear filter that is signal-dependent with a graph spectral\ninterpretation common in the graph signal processing (GSP) field. We\ndemonstrate PBF's predictive performance over a linear predictor inspired by\nMPEG standardization over a wide range of point cloud datasets.",
                "authors": [
                    "Tam Thuc Do",
                    "Philip A. Chou",
                    "Gene Cheung"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13533v1",
                    "http://arxiv.org/pdf/2311.13533v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13531v1/1.0",
                "title": "Leveraging CNNs and Ensemble Learning for Automated Disaster Image\n  Classification",
                "year": 2023,
                "abstract": "Natural disasters act as a serious threat globally, requiring effective and\nefficient disaster management and recovery. This paper focuses on classifying\nnatural disaster images using Convolutional Neural Networks (CNNs). Multiple\nCNN architectures were built and trained on a dataset containing images of\nearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach\nproved to be the most effective, achieving 95% accuracy and an F1 score going\nup to 0.96 for individual classes. Tuning hyperparameters of individual models\nfor optimization was critical to maximize the models' performance. The stacking\nof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN\nand ResNet models to improve the overall accuracy of the classification.\nResults obtained from the models illustrated the potency of CNN-based models\nfor automated disaster image classification. This lays the foundation for\nexpanding these techniques to build robust systems for disaster response,\ndamage assessment, and recovery management.",
                "authors": [
                    "Archit Rathod",
                    "Veer Pariawala",
                    "Mokshit Surana",
                    "Kumkum Saxena"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13531v1",
                    "http://arxiv.org/pdf/2311.13531v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13529v1/1.0",
                "title": "Euclid preparation TBD. Modelling spectroscopic clustering on mildly\n  nonlinear scales in beyond-$\u039b$CDM models",
                "year": 2023,
                "abstract": "We investigate the approximations needed to efficiently predict the\nlarge-scale clustering of matter and dark matter halos in beyond-$\\Lambda$CDM\nscenarios. We examine the normal branch of the Dvali-Gabadadze-Porrati model,\nthe Hu-Sawicki $f(R)$ model, a slowly evolving dark energy, an interacting dark\nenergy model and massive neutrinos. For each, we test approximations for the\nperturbative kernel calculations, including the omission of screening terms and\nthe use of perturbative kernels based on the Einstein-de Sitter universe; we\nexplore different infrared-resummation schemes, tracer bias models and a linear\ntreatment of massive neutrinos; we employ two models for redshift space\ndistortions, the Taruya-Nishimishi-Saito prescription and the Effective Field\nTheory of Large-Scale Structure. This work further provides a preliminary\nvalidation of the codes being considered by Euclid for the spectroscopic\nclustering probe in beyond-$\\Lambda$CDM scenarios. We calculate and compare the\n$\\chi^2$ statistic to assess the different modelling choices. This is done by\nfitting the spectroscopic clustering predictions to measurements from numerical\nsimulations and perturbation theory-based mock data. We compare the behaviour\nof this statistic in the beyond-$\\Lambda$CDM cases, as a function of the\nmaximum scale included in the fit, to the baseline $\\Lambda$CDM case. We find\nthat the Einstein-de Sitter approximation without screening is surprisingly\naccurate for all cases when comparing to the halo clustering monopole and\nquadrupole obtained from simulations. Our results suggest that the inclusion of\nmultiple redshift bins, higher-order multipoles, higher-order clustering\nstatistics (such as the bispectrum) and photometric probes such as weak\nlensing, will be essential to extract information on massive neutrinos,\nmodified gravity and dark energy.",
                "authors": [
                    "Euclid Collaboration",
                    "B. Bose",
                    "P. Carrilho",
                    "M. Marinucci",
                    "C. Moretti",
                    "M. Pietroni",
                    "E. Carella",
                    "L. Piga",
                    "B. S. Wright",
                    "F. Vernizzi",
                    "C. Carbone",
                    "S. Casas",
                    "G. D'Amico",
                    "N. Frusciante",
                    "K. Koyama",
                    "F. Pace",
                    "A. Pourtsidou",
                    "M. Baldi",
                    "L. F. de la Bella",
                    "B. Fiorini",
                    "C. Giocoli",
                    "L. Lombriser",
                    "N. Aghanim",
                    "A. Amara",
                    "S. Andreon",
                    "N. Auricchio",
                    "S. Bardelli",
                    "C. Bodendorf",
                    "D. Bonino",
                    "E. Branchini",
                    "M. Brescia",
                    "J. Brinchmann",
                    "S. Camera",
                    "V. Capobianco",
                    "V. F. Cardone",
                    "J. Carretero",
                    "M. Castellano",
                    "S. Cavuoti",
                    "A. Cimatti",
                    "G. Congedo",
                    "C. J. Conselice",
                    "L. Conversi",
                    "Y. Copin",
                    "A. Costille",
                    "F. Courbin",
                    "H. M. Courtois",
                    "A. Da Silva",
                    "H. Degaudenzi",
                    "A. M. Di Giorgio",
                    "F. Dubath",
                    "C. A. J. Duncan",
                    "X. Dupac",
                    "S. Dusini",
                    "M. Farina",
                    "S. Farrens",
                    "S. Ferriol",
                    "P. Fosalba",
                    "M. Frailis",
                    "E. Franceschi",
                    "S. Galeotta",
                    "B. Garilli",
                    "B. Gillis",
                    "A. Grazian",
                    "F. Grupp",
                    "L. Guzzo",
                    "S. V. H. Haugan",
                    "F. Hormuth",
                    "A. Hornstrup",
                    "K. Jahnke",
                    "B. Joachimi",
                    "E. Keih\u00e4nen",
                    "S. Kermiche",
                    "A. Kiessling",
                    "M. Kilbinger",
                    "T. Kitching",
                    "M. Kunz",
                    "H. Kurki-Suonio",
                    "S. Ligori",
                    "P. B. Lilje",
                    "V. Lindholm",
                    "I. Lloro",
                    "D. Maino",
                    "E. Maiorano",
                    "O. Mansutti",
                    "O. Marggraf",
                    "K. Markovic",
                    "N. Martinet",
                    "F. Marulli",
                    "R. Massey",
                    "E. Medinaceli",
                    "M. Meneghetti",
                    "G. Meylan",
                    "M. Moresco",
                    "L. Moscardini",
                    "E. Munari",
                    "S. -M. Niemi",
                    "C. Padilla",
                    "S. Paltani",
                    "F. Pasian",
                    "K. Pedersen",
                    "W. J. Percival",
                    "V. Pettorino",
                    "S. Pires",
                    "G. Polenta",
                    "M. Poncet",
                    "L. A. Popa",
                    "L. Pozzetti",
                    "F. Raison",
                    "A. Renzi",
                    "J. Rhodes",
                    "G. Riccio",
                    "E. Romelli",
                    "M. Roncarelli",
                    "R. Saglia",
                    "D. Sapone",
                    "B. Sartoris",
                    "P. Schneider",
                    "A. Secroun",
                    "G. Seidel",
                    "M. Seiffert",
                    "S. Serrano",
                    "C. Sirignano",
                    "G. Sirri",
                    "L. Stanco",
                    "J. -L. Starck",
                    "P. Tallada-Cresp\u00ed",
                    "A. N. Taylor",
                    "I. Tereno",
                    "R. Toledo-Moreo",
                    "F. Torradeflot",
                    "I. Tutusaus",
                    "E. A. Valentijn",
                    "L. Valenziano",
                    "T. Vassallo",
                    "A. Veropalumbo",
                    "Y. Wang",
                    "J. Weller",
                    "G. Zamorani",
                    "J. Zoubian",
                    "E. Zucca",
                    "A. Biviano",
                    "E. Bozzo",
                    "C. Burigana",
                    "C. Colodro-Conde",
                    "D. Di Ferdinando",
                    "J. Graci\u00e1-Carpio",
                    "N. Mauri",
                    "C. Neissner",
                    "Z. Sakr",
                    "V. Scottez",
                    "M. Tenti",
                    "M. Viel",
                    "M. Wiesmann",
                    "Y. Akrami",
                    "V. Allevato",
                    "S. Anselmi",
                    "M. Ballardini",
                    "F. Bernardeau",
                    "S. Borgani",
                    "S. Bruton",
                    "R. Cabanac",
                    "A. Cappi",
                    "C. S. Carvalho",
                    "G. Castignani",
                    "T. Castro",
                    "G. Ca\u00f1as-Herrera",
                    "K. C. Chambers",
                    "A. R. Cooray",
                    "J. Coupon",
                    "S. Davini",
                    "S. de la Torre",
                    "G. De Lucia",
                    "G. Desprez",
                    "S. Di Domizio",
                    "H. Dole",
                    "A. D\u00edaz-S\u00e1nchez",
                    "J. A. Escartin Vigo",
                    "S. Escoffier",
                    "P. G. Ferreira",
                    "I. Ferrero",
                    "F. Finelli",
                    "L. Gabarra",
                    "K. Ganga",
                    "J. Garc\u00eda-Bellido",
                    "F. Giacomini",
                    "G. Gozaliasl",
                    "D. Guinet",
                    "A. Hall",
                    "S. Joudaki",
                    "J. J. E. Kajava",
                    "V. Kansal",
                    "D. Karagiannis",
                    "C. C. Kirkpatrick",
                    "L. Legrand",
                    "A. Loureiro",
                    "J. Macias-Perez",
                    "M. Magliocchetti",
                    "R. Maoli",
                    "M. Martinelli",
                    "C. J. A. P. Martins",
                    "S. Matthew",
                    "M. Maturi",
                    "L. Maurin",
                    "R. B. Metcalf",
                    "M. Migliaccio",
                    "P. Monaco",
                    "G. Morgante",
                    "S. Nadathur",
                    "Nicholas A. Walton",
                    "L. Patrizii",
                    "A. Pezzotta",
                    "V. Popa",
                    "C. Porciani",
                    "D. Potter",
                    "M. P\u00f6ntinen",
                    "P. Reimberg",
                    "P. -F. Rocci",
                    "A. G. S\u00e1nchez",
                    "A. Schneider",
                    "E. Sefusatti",
                    "M. Sereno",
                    "A. Silvestri",
                    "A. Spurio Mancini",
                    "J. Steinwagner",
                    "G. Testera",
                    "R. Teyssier",
                    "S. Toft",
                    "S. Tosi",
                    "A. Troja",
                    "M. Tucci",
                    "J. Valiviita",
                    "D. Vergani"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13529v1",
                    "http://arxiv.org/pdf/2311.13529v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13528v1/1.0",
                "title": "Improvements on Device Independent and Semi-Device Independent Protocols\n  of Randomness Expansion",
                "year": 2023,
                "abstract": "To generate genuine random numbers, random number generators based on quantum\ntheory are essential. However, ensuring that the process used to produce\nrandomness meets desired security standards can pose challenges for traditional\nquantum random number generators. This thesis delves into Device Independent\n(DI) and Semi-Device Independent (semi-DI) protocols of randomness expansion,\nbased on a minimal set of experimentally verifiable security assumptions. The\nsecurity in DI protocols relies on the violation of Bell inequalities, which\ncertify the quantum behavior of devices. The semi-DI protocols discussed in\nthis thesis require the characterization of only one device - a power meter.\nThese protocols exploit the fact that quantum states can be prepared such that\nthey cannot be distinguished with certainty, thereby creating a randomness\nresource. In this study, we introduce enhanced DI and semi-DI protocols that\nsurpass existing ones in terms of output randomness rate, security, or in some\ninstances, both. Our analysis employs the Entropy Accumulation Theorem (EAT) to\ndetermine the extractable randomness for finite rounds. A notable contribution\nis the introduction of randomness expansion protocols that recycle input\nrandomness, significantly enhancing finite round randomness rates for DI\nprotocols based on the CHSH inequality violation. In the final section of the\nthesis, we delve into Generalized Probability Theories (GPTs), with a focus on\nBoxworld, the largest GPT capable of producing correlations consistent with\nrelativity. A tractable criterion for identifying a Boxworld channel is\npresented.",
                "authors": [
                    "Rutvij Bhavsar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13528v1",
                    "http://arxiv.org/pdf/2311.13528v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13526v1/1.0",
                "title": "Assessing the Probability of Extremely Low Wind Energy Production in\n  Europe at Sub-seasonal to Seasonal Time Scales",
                "year": 2023,
                "abstract": "The European energy system will undergo major transformations in the coming\ndecades to implement mitigation measures and comply with the Paris Agreement.\nIn particular, the share of weather-dependent wind generation will increase\nsignificantly in the European energy mix. The most extreme fluctuations of the\nproduction at all time scales need to be taken into account in the design of\nthe power system. In particular, extreme long-lasting low wind energy\nproduction events constitute a specific challenge, as most flexibility\nsolutions do not apply at time scales beyond a few days. However, the\nprobability and amplitude of such events has to a large extent eluded\nquantitative study so far due to lack of sufficiently long data. In this\nletter, using a 1000-year climate simulation, we study rare events of wind\nenergy production that last from a few weeks to a few months over the\nJanuary-February period, at the scale of a continent (Europe) and a country\n(France). The results show that the fluctuations of the capacity factor over\nEurope exhibit nearly Gaussian statistics at all time scales. A similar result\nholds over France for events longer than about two weeks and return times up to\na few decades. In that case, the return time curves follow a universal curve.\nFurthermore, a simple Gaussian process with the same covariance structure as\nthe data gives good estimates of the amplitude of the most extreme events. This\nmethod allows to estimate return times for rare events from shorter but more\naccurate data sources. We demonstrate this possibility with reanalysis data.",
                "authors": [
                    "Bastien Cozian",
                    "Corentin Herbert",
                    "Freddy Bouchet"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13526v1",
                    "http://arxiv.org/pdf/2311.13526v1"
                ],
                "primary_category": "physics.ao-ph",
                "categories": [
                    "physics.ao-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13519v1/1.0",
                "title": "Varieties of truth definitions",
                "year": 2023,
                "abstract": "We study the structure of the partial order induced by the definability\nrelation on definitions of truth for the language of arithmetic. Formally, a\ndefinition of truth is any sentence $\\alpha$ which extends a weak arithmetical\ntheory (which we take to be EA) such that for some formula $\\Theta$ and any\narithmetical sentence $\\varphi$, $\\Theta(\\ulcorner\\varphi\\urcorner)\\equiv\n\\varphi$ is provable in $\\alpha$. We say that a sentence $\\beta$ is definable\nin a sentence $\\alpha$, if there exists an unrelativized translation from the\nlanguage of $\\beta$ to the language of $\\alpha$ which is identity on the\narithmetical symbols and such that the translation of $\\beta$ is provable in\n$\\alpha$. Our main result is that the structure consisting of truth definitions\nwhich are conservative over the basic arithmetical theory forms a countable\nuniversal distributive lattice. Additionally, we generalize the result of\nPakhomov and Visser showing that the set of (G\\\"odel codes of) definitions of\ntruth is not $\\Sigma_2$-definable in the standard model of arithmetic. We\nconclude by remarking that no $\\Sigma_2$-sentence, satisfying certain further\nnatural conditions, can be a definition of truth for the language of\narithmetic.",
                "authors": [
                    "Piotr Gruza",
                    "Mateusz \u0141e\u0142yk"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13519v1",
                    "http://arxiv.org/pdf/2311.13519v1"
                ],
                "primary_category": "math.LO",
                "categories": [
                    "math.LO",
                    "03F30 (Primary), 03F40, 03A05 (Secondary)"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13513v1/1.0",
                "title": "The SOPHIE search for northern extrasolar planets-XIX. A system\n  including a cold sub-Neptune potentially transiting a V = 6.5 star HD88986",
                "year": 2023,
                "abstract": "Transiting planets with orbital periods longer than 40 d are extremely rare\namong the 5000+ planets discovered so far. The lack of discoveries of this\npopulation poses a challenge to research into planetary demographics,\nformation, and evolution. Here, we present the detection and characterization\nof HD88986b, a potentially transiting sub-Neptune, possessing the longest\norbital period among known transiting small planets (< 4 R$_{\\oplus}$) with a\nprecise mass measurement ($\\sigma_M/M$ > 25%). Additionally, we identified the\npresence of a massive companion in a wider orbit around HD88986. Our analysis\nreveals that HD88986b, based on two potential single transits on sector 21 and\nsector 48 which are both consistent with the predicted transit time from the RV\nmodel, is potentially transiting. The joint analysis of RV and photometric data\nshow that HD88986b has a radius of 2.49$\\pm$0.18 R$_{\\oplus}$, a mass of\n17.2$^{+4.0}_{-3.8}$ M$_{\\oplus}$, and it orbits every 146.05$^{+0.43}_{-0.40}$\nd around a subgiant HD88986 which is one of the closest and brightest exoplanet\nhost stars (G2V type, R=1.543 $\\pm$0.065 R$_{\\odot}$, V=$6.47\\pm 0.01$ mag,\ndistance=33.37$\\pm$0.04 pc). The nature of the outer, massive companion is\nstill to be confirmed; a joint analysis of RVs, Hipparcos, and Gaia astrometric\ndata shows that with a 3$\\sigma$ confidence interval, its semi-major axis is\nbetween 16.7 and 38.8 au and its mass is between 68 and 284 M$_{Jup}$.\nHD88986b's wide orbit suggests the planet did not undergo significant mass loss\ndue to extreme-ultraviolet radiation from its host star. Therefore, it probably\nmaintained its primordial composition, allowing us to probe its formation\nscenario. Furthermore, the cold nature of HD88986b (460$\\pm$8 K), thanks to its\nlong orbital period, will open up exciting opportunities for future studies of\ncold atmosphere composition characterization.",
                "authors": [
                    "N. Heidari",
                    "I. Boisse",
                    "N. C. Hara",
                    "T. G. Wilson",
                    "F. Kiefer",
                    "G. H\u00e9brard",
                    "F. Philipot",
                    "S. Hoyer",
                    "K. G. Stassun",
                    "G. W. Henry",
                    "N. C. Santos",
                    "L. Acu\u00f1a",
                    "D. Almasian",
                    "L. Arnold",
                    "N. Astudillo-Defru",
                    "O. Attia",
                    "X. Bonfils",
                    "F. Bouchy",
                    "V. Bourrier",
                    "B. Collet",
                    "P. Cort\u00e9s-Zuleta",
                    "A. Carmona",
                    "X. Delfosse",
                    "S. Dalal",
                    "M. Deleuil",
                    "O. D. S. Demangeon",
                    "R. F. D\u00edaz",
                    "X. Dumusque",
                    "D. Ehrenreich",
                    "T. Forveille",
                    "M. J. Hobson",
                    "J. S. Jenkins",
                    "J. M. Jenkins",
                    "A. M. Lagrange",
                    "D. W. Latham",
                    "P. Larue",
                    "J. Liu",
                    "C. Moutou",
                    "L. Mignon",
                    "H. P. Osborn",
                    "F. Pepe",
                    "D. Rapetti",
                    "J. Rodrigues",
                    "A. Santerne",
                    "D. Segransan",
                    "A. Shporer",
                    "S. Sulis",
                    "G. Torres",
                    "S. Udry",
                    "F. Vakili",
                    "A. Vanderburg",
                    "O. Venot",
                    "H. G. Vivien",
                    "J. I. Vines"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13513v1",
                    "http://arxiv.org/pdf/2311.13513v1"
                ],
                "primary_category": "astro-ph.EP",
                "categories": [
                    "astro-ph.EP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13512v1/1.0",
                "title": "Hybrid Whale-Mud-Ring Optimization for Precise Color Skin Cancer Image\n  Segmentation",
                "year": 2023,
                "abstract": "Timely identification and treatment of rapidly progressing skin cancers can\nsignificantly contribute to the preservation of patients' health and\nwell-being. Dermoscopy, a dependable and accessible tool, plays a pivotal role\nin the initial stages of skin cancer detection. Consequently, the effective\nprocessing of digital dermoscopy images holds significant importance in\nelevating the accuracy of skin cancer diagnoses. Multilevel thresholding is a\nkey tool in medical imaging that extracts objects within the image to\nfacilitate its analysis. In this paper, an enhanced version of the Mud Ring\nAlgorithm hybridized with the Whale Optimization Algorithm, named WMRA, is\nproposed. The proposed approach utilizes bubble-net attack and mud ring\nstrategy to overcome stagnation in local optima and obtain optimal thresholds.\nThe experimental results show that WMRA is powerful against a cluster of recent\nmethods in terms of fitness, Peak Signal to Noise Ratio (PSNR), and Mean Square\nError (MSE).",
                "authors": [
                    "Amir Hamza",
                    "Badis Lekouaghet",
                    "Yassine Himeur"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13512v1",
                    "http://arxiv.org/pdf/2311.13512v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13509v1/1.0",
                "title": "Energy and Time-Aware Inference Offloading for DNN-based Applications in\n  LEO Satellites",
                "year": 2023,
                "abstract": "In recent years, Low Earth Orbit (LEO) satellites have witnessed rapid\ndevelopment, with inference based on Deep Neural Network (DNN) models emerging\nas the prevailing technology for remote sensing satellite image recognition.\nHowever, the substantial computation capability and energy demands of DNN\nmodels, coupled with the instability of the satellite-ground link, pose\nsignificant challenges, burdening satellites with limited power intake and\nhindering the timely completion of tasks. Existing approaches, such as\ntransmitting all images to the ground for processing or executing DNN models on\nthe satellite, is unable to effectively address this issue. By exploiting the\ninternal hierarchical structure of DNNs and treating each layer as an\nindependent subtask, we propose a satellite-ground collaborative computation\npartial offloading approach to address this challenge. We formulate the problem\nof minimizing the inference task execution time and onboard energy consumption\nthrough offloading as an integer linear programming (ILP) model. The complexity\nin solving the problem arises from the combinatorial explosion in the discrete\nsolution space. To address this, we have designed an improved optimization\nalgorithm based on branch and bound. Simulation results illustrate that,\ncompared to the existing approaches, our algorithm improve the performance by\n10%-18%",
                "authors": [
                    "Yijie Chen",
                    "Qiyang Zhang",
                    "Yiran Zhang",
                    "Xiao Ma",
                    "Ao Zhou"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13509v1",
                    "http://arxiv.org/pdf/2311.13509v1"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13508v1/1.0",
                "title": "Naturalness of Attention: Revisiting Attention in Code Language Models",
                "year": 2023,
                "abstract": "Language models for code such as CodeBERT offer the capability to learn\nadvanced source code representation, but their opacity poses barriers to\nunderstanding of captured properties. Recent attention analysis studies provide\ninitial interpretability insights by focusing solely on attention weights\nrather than considering the wider context modeling of Transformers. This study\naims to shed some light on the previously ignored factors of the attention\nmechanism beyond the attention weights. We conduct an initial empirical study\nanalyzing both attention distributions and transformed representations in\nCodeBERT. Across two programming languages, Java and Python, we find that the\nscaled transformation norms of the input better capture syntactic structure\ncompared to attention weights alone. Our analysis reveals characterization of\nhow CodeBERT embeds syntactic code properties. The findings demonstrate the\nimportance of incorporating factors beyond just attention weights for\nrigorously understanding neural code models. This lays the groundwork for\ndeveloping more interpretable models and effective uses of attention mechanisms\nin program analysis.",
                "authors": [
                    "Mootez Saad",
                    "Tushar Sharma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13508v1",
                    "http://arxiv.org/pdf/2311.13508v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13507v1/1.0",
                "title": "Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for\n  Classifying Imagery and Motor Signals in ECoG-Based BCIs",
                "year": 2023,
                "abstract": "Motor impairments, frequently caused by neurological incidents like strokes\nor traumatic brain injuries, present substantial obstacles in rehabilitation\ntherapy. This research aims to elevate the field by optimizing motor imagery\nclassification algorithms within Brain-Computer Interfaces (BCIs). By improving\nthe efficiency of BCIs, we offer a novel approach that holds significant\npromise for enhancing motor rehabilitation outcomes. Utilizing unsupervised\ntechniques for dimensionality reduction, namely Uniform Manifold Approximation\nand Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate the\nnecessity of employing supervised methods such as Long Short-Term Memory (LSTM)\nand Convolutional Neural Networks (CNNs) for classification tasks. Importantly,\nparticipants who exhibited high KNN scores following UMAP dimensionality\nreduction also achieved high accuracy in supervised deep learning (DL) models.\nDue to individualized model requirements and massive neural training data,\ndimensionality reduction becomes an effective preprocessing step that minimizes\nthe need for extensive data labeling and supervised deep learning techniques.\nThis approach has significant implications not only for targeted therapies in\nmotor dysfunction but also for addressing regulatory, safety, and reliability\nconcerns in the rapidly evolving BCI field.",
                "authors": [
                    "Soham Bafana"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13507v1",
                    "http://arxiv.org/pdf/2311.13507v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.HC",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13504v1/1.0",
                "title": "Quantum Sensing of Magnetic Fields with Molecular Spins",
                "year": 2023,
                "abstract": "Spins are prototypical systems with the potential to probe magnetic fields\ndown to the atomic scale limit. Exploiting their quantum nature through\nappropriate sensing protocols allows to enlarge their applicability to fields\nnot always accessible by classical sensors. Here we first show that quantum\nsensing protocols for AC magnetic fields can be implemented on molecular spin\nensembles embedded into hybrid quantum circuits. We then show that, using only\necho detection at microwave frequency and no optical readout, Dynamical\nDecoupling protocols synchronized with the AC magnetic fields can enhance the\nsensitivity up to $S = 10^{-10}-10^{-9}T/\\sqrt{Hz}$ with a low (4-5) number of\napplied pulses. These results paves the way for the development of strategies\nto exploit molecular spins as quantum sensors.",
                "authors": [
                    "Claudio Bonizzoni",
                    "Alberto Ghirri",
                    "Fabio Santanni",
                    "Marco Affronte"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13504v1",
                    "http://arxiv.org/pdf/2311.13504v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13502v1/1.0",
                "title": "Bitformer: An efficient Transformer with bitwise operation-based\n  attention for Big Data Analytics at low-cost low-precision devices",
                "year": 2023,
                "abstract": "In the current landscape of large models, the Transformer stands as a\ncornerstone, playing a pivotal role in shaping the trajectory of modern models.\nHowever, its application encounters challenges attributed to the substantial\ncomputational intricacies intrinsic to its attention mechanism. Moreover, its\nreliance on high-precision floating-point operations presents specific hurdles,\nparticularly evident in computation-intensive scenarios such as edge computing\nenvironments. These environments, characterized by resource-constrained devices\nand a preference for lower precision, necessitate innovative solutions.\n  To tackle the exacting data processing demands posed by edge devices, we\nintroduce the Bitformer model, an inventive extension of the Transformer\nparadigm. Central to this innovation is a novel attention mechanism that\nadeptly replaces conventional floating-point matrix multiplication with bitwise\noperations. This strategic substitution yields dual advantages. Not only does\nit maintain the attention mechanism's prowess in capturing intricate long-range\ninformation dependencies, but it also orchestrates a profound reduction in the\ncomputational complexity inherent in the attention operation. The transition\nfrom an $O(n^2d)$ complexity, typical of floating-point operations, to an\n$O(n^2T)$ complexity characterizing bitwise operations, substantiates this\nadvantage. Notably, in this context, the parameter $T$ remains markedly smaller\nthan the conventional dimensionality parameter $d$.\n  The Bitformer model in essence endeavors to reconcile the indomitable\nrequirements of modern computing landscapes with the constraints posed by edge\ncomputing scenarios. By forging this innovative path, we bridge the gap between\nhigh-performing models and resource-scarce environments, thus unveiling a\npromising trajectory for further advancements in the field.",
                "authors": [
                    "Gaoxiang Duan",
                    "Junkai Zhang",
                    "Xiaoying Zheng",
                    "Yongxin Zhu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13502v1",
                    "http://arxiv.org/pdf/2311.13502v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13498v1/1.0",
                "title": "Unveiling $\u03a9_{\\rm m0}$ independently: a journey and consistency\n  quest with first-order perturbation theory",
                "year": 2023,
                "abstract": "This study combines cosmic chronometer (CC) Hubble parameter data with growth\nrate (f) observations to constrain the $\\Omega_{\\rm m0}$ parameter. Utilizing a\nconsistency relation independent of cosmological models, we employ Gaussian\nprocess regression to reconstruct Hubble parameter and growth rate values. The\nresulting $\\Omega_{\\rm m0}h^2$ constraint is $\\Omega_{\\rm\nm0}h^2=0.139\\pm0.017$. Incorporating $H_0$ measurements, we find $\\Omega_{\\rm\nm0}$ values from CC data ($0.308\\pm0.057$), tip of the Red Giant Branch\n($0.285\\pm0.038$), and SHOES measurements ($0.259\\pm0.033$). Interestingly, a\nhigher mean $H_0$ correlates with a lower mean $\\Omega_{\\rm m0}$. In summary,\nour cosmological model-independent approach offers valuable constraints on\n$\\Omega_{\\rm m0}$, affirming the consistency of FLRW and Newtonian perturbation\ntheory.",
                "authors": [
                    "Bikash R. Dinda"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13498v1",
                    "http://arxiv.org/pdf/2311.13498v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13495v1/1.0",
                "title": "Current Topological and Machine Learning Applications for Bias Detection\n  in Text",
                "year": 2023,
                "abstract": "Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.",
                "authors": [
                    "Colleen Farrelly",
                    "Yashbir Singh",
                    "Quincy A. Hathaway",
                    "Gunnar Carlsson",
                    "Ashok Choudhary",
                    "Rahul Paul",
                    "Gianfranco Doretto",
                    "Yassine Himeur",
                    "Shadi Atalls",
                    "Wathiq Mansoor"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13495v1",
                    "http://arxiv.org/pdf/2311.13495v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13494v1/1.0",
                "title": "A Comparative Analysis of Supportive Navigation on Movie Recommenders",
                "year": 2023,
                "abstract": "This literature review covers the research and thought process that went into\nmaking a solution for the infinite scrolling problem faced in streaming\nservices such as Netflix. Using the data collected, we have come to the\nconclusion that an alternate layout can somewhat alleviate the problems it\ntakes in navigating a list of movies. We also found out by a comparative\nanalysis that some layouts, the circular one in particular, is advantageous in\ncertain settings making it an ideal candidate for a movie recommender system.",
                "authors": [
                    "Mohammad Sualeh Ali",
                    "Muhammed Maaz Tariq",
                    "Alina Ahmed",
                    "Abdul Razaque Soomro",
                    "Danysh Syed"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13494v1",
                    "http://arxiv.org/pdf/2311.13494v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13490v1/1.0",
                "title": "Benchmarking Toxic Molecule Classification using Graph Neural Networks\n  and Few Shot Learning",
                "year": 2023,
                "abstract": "Traditional methods like Graph Convolutional Networks (GCNs) face challenges\nwith limited data and class imbalance, leading to suboptimal performance in\ngraph classification tasks during toxicity prediction of molecules as a whole.\nTo address these issues, we harness the power of Graph Isomorphic Networks,\nMulti Headed Attention and Free Large-scale Adversarial Augmentation separately\non Graphs for precisely capturing the structural data of molecules and their\ntoxicological properties. Additionally, we incorporate Few-Shot Learning to\nimprove the model's generalization with limited annotated samples. Extensive\nexperiments on a diverse toxicology dataset demonstrate that our method\nachieves an impressive state-of-art AUC-ROC value of 0.816, surpassing the\nbaseline GCN model by 11.4%. This highlights the significance of our proposed\nmethodology and Few Shot Learning in advancing Toxic Molecular Classification,\nwith the potential to enhance drug discovery and environmental risk assessment\nprocesses.",
                "authors": [
                    "Bhavya Mehta",
                    "Kush Kothari",
                    "Reshmika Nambiar",
                    "Seema Shrawne"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13490v1",
                    "http://arxiv.org/pdf/2311.13490v1"
                ],
                "primary_category": "q-bio.QM",
                "categories": [
                    "q-bio.QM",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.12385v1/1.0",
                "title": "Input Compression with Positional Consistency for Efficient Training and\n  Inference of Transformer Neural Networks",
                "year": 2023,
                "abstract": "Transformers have rapidly increased in popularity in recent years, achieving\nstate-of-the-art performance in processing text, images, audio and video.\nHowever, Transformers present large computational requirements for both\ntraining and inference, and are prone to overfitting during training. To\naddress these challenges, we present Input Compression with Positional\nConsistency (ICPC), a new data augmentation method that, unlike prior\naugmentation techniques, simultaneously improves both generalization and\ntraining efficiency. ICPC applies varying levels of compression to each\ntraining sample in each epoch. This leads to smaller input sequences being\nprocessed by the Transformer, and hence faster training, while also alleviating\noverfitting by presenting each input with different compression levels. We\nintroduce a consistency-aware position selection method in ICPC that enables\naccurate processing of compressed inputs without any changes to the underlying\nTransformer architecture. We detail compression-based augmentation methods for\nfour different modalities -- insignificant word pruning for text, resolution\nmodulation for images, spatio-temporal resolution modulation for videos, and\nspectogram size modulation for audio. ICPC also enables efficient\nvariable-effort inference, where samples are first inferred at high compression\nlevels, and progressively re-evaluated with lower compression for more\nchallenging inputs. On 9 diverse tasks spanning 4 different modalities, ICPC\nimproves accuracy by up to 1%, while also accelerating training and inference\nby up to 2.9X and 2.6X, respectively. Code is available at\nhttps://github.com/amrnag/ICPC.",
                "authors": [
                    "Amrit Nagarajan",
                    "Anand Raghunathan"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.12385v1",
                    "http://arxiv.org/pdf/2312.12385v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13486v1/1.0",
                "title": "Evidence for enhanced star formation rates in z~0.35 cluster galaxies\n  undergoing ram pressure stripping",
                "year": 2023,
                "abstract": "Ram pressure stripping (RPS) is one of the most invoked mechanisms to explain\nthe observed differences between cluster and field galaxies. In the local\nUniverse, its effect on the galaxy star forming properties has been largely\ntackled and the general consensus is that this process first compresses the gas\navailable in the galaxy disks, boosting the star formation for a limited amount\nof time, and then removes the remaining gas leading to quenching. Much less is\nknown on the effect and preponderance of RPS at higher redshift, due to the\nlack of statistical samples. Exploiting VLT/MUSE observations of galaxies at\n0.2<z<0.55 and the catalog of ram pressure stripped galaxies by Moretti et al.,\nwe compare the global star formation rate-mass (SFR-M*) relation of 29 cluster\ngalaxies undergoing RPS to that of 26 field and cluster undisturbed galaxies\nthat constitute our control sample. Stripping galaxies occupy the upper\nenvelope of the control sample SFR-M* relation, showing a systematic\nenhancement of the SFR at any given mass. The boost is >3sigma when considering\nthe SFR occurring in both the tail and disk of galaxies. The enhancement is\nretrieved also on local scales: considering spatially resolved data, ram\npressure stripped galaxies overall have large {\\Sigma}SFR values, especially\nfor Sigma_*>10^7.5M_sun kpc~2. RPS seems to leave the same imprint on the\nSFR-M* and Sigma_SFR-Sigma_* relations both in the Local Universe and at\nz~0.35.",
                "authors": [
                    "Benedetta Vulcani",
                    "Alessia Moretti",
                    "Bianca M. Poggianti",
                    "Mario Radovich",
                    "Ariel Werle",
                    "Marco Gullieuszik",
                    "Jacopo Fritz",
                    "Cecilia Bacchini",
                    "Johan Richard"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13486v1",
                    "http://arxiv.org/pdf/2311.13486v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13485v1/1.0",
                "title": "Deep-learning-based acceleration of MRI for radiotherapy planning of\n  pediatric patients with brain tumors",
                "year": 2023,
                "abstract": "Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and\nradiotherapy (RT) planning tool, offering detailed insights into the anatomy of\nthe human body. The extensive scan time is stressful for patients, who must\nremain motionless in a prolonged imaging procedure that prioritizes reduction\nof imaging artifacts. This is challenging for pediatric patients who may\nrequire measures for managing voluntary motions such as anesthesia. Several\ncomputational approaches reduce scan time (fast MRI), by recording fewer\nmeasurements and digitally recovering full information via post-acquisition\nreconstruction. However, most fast MRI approaches were developed for diagnostic\nimaging, without addressing reconstruction challenges specific to RT planning.\nIn this work, we developed a deep learning-based method (DeepMRIRec) for MRI\nreconstruction from undersampled data acquired with RT-specific receiver coil\narrangements. We evaluated our method against fully sampled data of T1-weighted\nMR images acquired from 73 children with brain tumors/surgical beds using loop\nand posterior coils (12 channels), with and without applying virtual\ncompression of coil elements. DeepMRIRec reduced scanning time by a factor of\nfour producing a structural similarity score surpassing the evaluated\nstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential\nfor accelerating MRI scanning for RT planning.",
                "authors": [
                    "Shahinur Alam",
                    "Jinsoo Uh",
                    "Alexander Dresner",
                    "Chia-ho Hua",
                    "Khaled Khairy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13485v1",
                    "http://arxiv.org/pdf/2311.13485v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13482v1/1.0",
                "title": "Higher twist corrections to $B$-meson decays into a proton and dark\n  antibaryon from QCD light-cone sum rules",
                "year": 2023,
                "abstract": "The $B$-Mesogenesis framework anticipates decays of $B$ mesons into a dark\nantibaryon $\\Psi$ and various Standard Model baryons. Here, we focus on the\nexclusive decay process $B\\to p \\Psi$ observed as a proton and missing energy\nin the final state and determine the decay width by employing the QCD\nlight-cone sum rule framework. We include all contributions up to twist six to\nthe nucleon distribution amplitudes in order to parameterize the\nnon-perturbative effects in the operator product expansion. We obtain the decay\nwidth and branching fraction with respect to the mass $m_{\\Psi}$ of the dark\nantibaryon $\\Psi$, normalized to the model-dependent effective four-fermion\ncoupling.",
                "authors": [
                    "Anastasia Boushmelev",
                    "Marcel Wald"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13482v1",
                    "http://arxiv.org/pdf/2311.13482v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13481v2/1.0",
                "title": "Synergizing Roughness Penalization and Basis Selection in Bayesian\n  Spline Regression",
                "year": 2023,
                "abstract": "Bayesian P-splines and basis determination through Bayesian model selection\nare both commonly employed strategies for nonparametric regression using spline\nbasis expansions within the Bayesian framework. Despite their widespread use,\neach method has particular limitations that may introduce potential estimation\nbias depending on the nature of the target function. To overcome the\nlimitations associated with each method while capitalizing on their respective\nstrengths, we propose a new prior distribution that integrates the essentials\nof both approaches. The proposed prior distribution assesses the complexity of\nthe spline model based on a penalty term formed by a convex combination of the\npenalties from both methods. The proposed method exhibits adaptability to the\nunknown level of smoothness, while achieving the minimax-optimal posterior\ncontraction rate up to a logarithmic factor. We provide an efficient Markov\nchain Monte Carlo algorithm for implementing the proposed approach. Our\nextensive simulation study reveals that the proposed method outperforms other\ncompetitors in terms of performance metrics or model complexity.",
                "authors": [
                    "Sunwoo Lim",
                    "Seonghyun Jeong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13481v2",
                    "http://arxiv.org/pdf/2311.13481v2"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13475v1/1.0",
                "title": "Machine Translation to Control Formality Features in the Target Language",
                "year": 2023,
                "abstract": "Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.",
                "authors": [
                    "Harshita Tyagi",
                    "Prashasta Jung",
                    "Hyowon Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13475v1",
                    "http://arxiv.org/pdf/2311.13475v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.HC",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13474v1/1.0",
                "title": "Alternative robust ways of witnessing nonclassicality in the simplest\n  scenario",
                "year": 2023,
                "abstract": "In this work we relate notions of nonclassicality in the simplest nontrivial\nscenario (a prepare and measure scenario composed of four preparations and two\nbinary-outcome tomographically complete measurements). Specifically, we relate\nthe established method developed in [Pusey, PRA 98,022112(2018)] to witness a\nviolation of preparation noncontextuality, that is not suitable in experiments\nwhere the operational equivalences to be tested are specified in advance, with\na novel approach based on the notion of bounded ontological distinctness for\npreparations, defined in [Chaturvedi and Saha, Quantum 4, 345 (2020)]. In our\napproach, we test bounded ontological distinctness for two particular\npreparations that are relevant in certain information processing tasks in that\nthey are associated with the even and odd parity of the bits to communicate.\nWhen there exists an ontological model where this distance is preserved we talk\nof parity preservation. Our main result provides a noise threshold under which\nviolating parity preservation (and so bounded ontological distinctness) agrees\nwith the established method for witnessing preparation contextuality in the\nsimplest nontrivial scenario. This is achieved by first relating the violation\nof parity preservation to the quantification of contextuality in terms of\ninaccessible information as developed in [Marvian, arXiv:2003.05984(2020)],\nthat we also show, given the way we quantify noise, to be more robust in\nwitnessing contextuality than Pusey's noncontextuality inequality. As an\napplication of our findings, we treat the case of 2 bit parity-oblivious\nmultiplexing in the presence of noise. In particular, we provide a condition\nfor which the result establishing preparation contextuality as a resource for\nthe quantum advantage of the protocol in the noiseless case still holds in the\nnoisy case.",
                "authors": [
                    "Massy Khoshbin",
                    "Lorenzo Catani",
                    "Matthew Leifer"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13474v1",
                    "http://arxiv.org/pdf/2311.13474v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13473v1/1.0",
                "title": "$Z$ polarization at an $e^+e^-$ collider and properties of decay-lepton\n  angular asymmetries",
                "year": 2023,
                "abstract": "$Z$ production at an $e^+e^-$ collider, associated with production of other\nparticles, can be an accurate source of information of details of electroweak\ninteractions, including possible interactions beyond the standard model. We\ndiscuss from a general physical point of view the properties of the density\nmatrix as well as lepton angular asymmetries. While most considerations will be\napplicable to processes of $Z$ production associated with any other particle or\nparticles, for some discussions, we specialize to a $HZ$ final state. While\nmany of the results can be found in earlier literature, especially for the\nprocess $e^+e^- \\to HZ$, we give details of the reasoning, which are not always\nfound. We discuss the properties of the spin density matrix under C, P and T\ntransformations, and combinations thereof, as also the predictions of these for\nthe corresponding leptonic asymmetries. The specific transformations P, CP, T\nand CPT are of special importance and we discuss the consequences of these\nsymmetries or their absence for the leptonic asymmetries. A specific issue\nwhich has been given attention to is the role of beam polarization, and how one\ncan infer on general grounds which asymmetries get enhanced by the use of beam\npolarization. Similarly, we also discuss which asymmetries would be sensitive\nto the measurement of tau polarization in $Z$ decay in to $\\tau^+\\tau^-$.",
                "authors": [
                    "Kumar Rao",
                    "Saurabh D. Rindani",
                    "Priyanka Sarmah",
                    "Balbeer Singh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13473v1",
                    "http://arxiv.org/pdf/2311.13473v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13472v1/1.0",
                "title": "Complexity-Guided Curriculum Learning for Text Graphs",
                "year": 2023,
                "abstract": "Curriculum learning provides a systematic approach to training. It refines\ntraining progressively, tailors training to task requirements, and improves\ngeneralization through exposure to diverse examples. We present a curriculum\nlearning approach that builds on existing knowledge about text and graph\ncomplexity formalisms for training with text graph data. The core part of our\napproach is a novel data scheduler, which employs \"spaced repetition\" and\ncomplexity formalisms to guide the training process. We demonstrate the\neffectiveness of the proposed approach on several text graph tasks and graph\nneural network architectures. The proposed model gains more and uses less data;\nconsistently prefers text over graph complexity indices throughout training,\nwhile the best curricula derived from text and graph complexity indices are\nequally effective; and it learns transferable curricula across GNN models and\ndatasets. In addition, we find that both node-level (local) and graph-level\n(global) graph complexity indices, as well as shallow and traditional text\ncomplexity indices play a crucial role in effective curriculum learning.",
                "authors": [
                    "Nidhi Vakil",
                    "Hadi Amiri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13472v1",
                    "http://arxiv.org/pdf/2311.13472v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13471v1/1.0",
                "title": "Comparative Analysis of Linear Regression, Gaussian Elimination, and LU\n  Decomposition for CT Real Estate Purchase Decisions",
                "year": 2023,
                "abstract": "This paper presents a comprehensive evaluation of three distinct\ncomputational algorithms applied to the decision-making process of real estate\npurchases. Specifically, we analyze the efficacy of Linear Regression from\nScikit-learn library, Gaussian Elimination with partial pivoting, and LU\nDecomposition in predicting the advisability of buying a house in the State of\nConnecticut based on a set of financial and market-related parameters. The\nalgorithms' performances were compared using a dataset encompassing\ntown-specific details, yearly data, interest rates, and median sale ratios. Our\nresults demonstrate significant differences in predictive accuracy, with Linear\nRegression and LU Decomposition providing the most reliable recommendations and\nGaussian Elimination showing limitations in stability and performance. The\nstudy's findings emphasize the importance of algorithm selection in predictive\nanalytic and offer insights into the practical applications of computational\nmethods in real estate investment strategies. By evaluating model efficacy\nthrough metrics such as R-squared scores and Mean Squared Error, we provide a\nnuanced understanding of each method's strengths and weaknesses, contributing\nvaluable knowledge to the fields of real estate analysis and predictive\nmodeling.",
                "authors": [
                    "Xilin Cheng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13471v1",
                    "http://arxiv.org/pdf/2311.13471v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CC",
                    "cs.CE",
                    "cs.NA",
                    "math.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13470v1/1.0",
                "title": "Analysis of a multi-species Cahn-Hilliard-Keller-Segel tumor growth\n  model with chemotaxis and angiogenesis",
                "year": 2023,
                "abstract": "We introduce a multi-species diffuse interface model for tumor growth,\ncharacterized by its incorporation of essential features related to chemotaxis,\nangiogenesis and proliferation mechanisms. We establish the weak well-posedness\nof the system within an appropriate variational framework, accommodating\nvarious choices for the nonlinear potentials. One of the primary novelties of\nthe work lies in the rigorous establishment of the existence of a weak solution\nthrough the introduction of delicate approximation schemes. To our knowledge,\nthis represents a novel advancement for both the intricate\nCahn-Hilliard-Keller-Segel system and the Keller-Segel subsystem with source\nterms. Moreover, when specific conditions are met, such as having more regular\ninitial data, a smallness condition on the chemotactic constant with respect to\nthe magnitude of initial conditions and potentially focusing solely on the\ntwo-dimensional case, we provide regularity results for the weak solutions.\nFinally, we derive a continuous dependence estimate, which, in turn, leads to\nthe uniqueness of the smoothed solution as a natural consequence.",
                "authors": [
                    "Abramo Agosti",
                    "Andrea Signori"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13470v1",
                    "http://arxiv.org/pdf/2311.13470v1"
                ],
                "primary_category": "math.AP",
                "categories": [
                    "math.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13469v1/1.0",
                "title": "Span-Based Optimal Sample Complexity for Average Reward MDPs",
                "year": 2023,
                "abstract": "We study the sample complexity of learning an $\\varepsilon$-optimal policy in\nan average-reward Markov decision process (MDP) under a generative model. We\nestablish the complexity bound $\\widetilde{O}\\left(SA\\frac{H}{\\varepsilon^2}\n\\right)$, where $H$ is the span of the bias function of the optimal policy and\n$SA$ is the cardinality of the state-action space. Our result is the first that\nis minimax optimal (up to log factors) in all parameters $S,A,H$ and\n$\\varepsilon$, improving on existing work that either assumes uniformly bounded\nmixing times for all policies or has suboptimal dependence on the parameters.\n  Our result is based on reducing the average-reward MDP to a discounted MDP.\nTo establish the optimality of this reduction, we develop improved bounds for\n$\\gamma$-discounted MDPs, showing that\n$\\widetilde{O}\\left(SA\\frac{H}{(1-\\gamma)^2\\varepsilon^2} \\right)$ samples\nsuffice to learn a $\\varepsilon$-optimal policy in weakly communicating MDPs\nunder the regime that $\\gamma \\geq 1 - \\frac{1}{H}$, circumventing the\nwell-known lower bound of\n$\\widetilde{\\Omega}\\left(SA\\frac{1}{(1-\\gamma)^3\\varepsilon^2} \\right)$ for\ngeneral $\\gamma$-discounted MDPs. Our analysis develops upper bounds on certain\ninstance-dependent variance parameters in terms of the span parameter. These\nbounds are tighter than those based on the mixing time or diameter of the MDP\nand may be of broader use.",
                "authors": [
                    "Matthew Zurek",
                    "Yudong Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13469v1",
                    "http://arxiv.org/pdf/2311.13469v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.IT",
                    "math.IT",
                    "math.OC",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13461v1/1.0",
                "title": "An exact bandit model for the risk-volatility tradeoff",
                "year": 2023,
                "abstract": "We revisit the two-armed bandit (TAB) problem where both arms are driven by\ndiffusive stochastic processes with a common instantaneous reward. We focus on\nsituations where the Radon-Nikodym derivative between the transition\nprobability densities of the first arm with respect to the second is explicitly\nknown. We calculate how the corresponding Gittins' indices behave under such a\nchange of probability measure. This general framework is used to solve the\noptimal allocation of a TAB problem where the first arm is driven by a pure\nBrownian motion and the second is driven by a centered super-diffusive\nnon-Gaussian process with variance quadratically growing in time. The\nprobability spread due to the super-diffusion introduces an extra risk into the\nallocation problem. This drastically affects the optimal decision rule. Our\nmodeling illustrates the interplay between the notions of risk and volatility.",
                "authors": [
                    "Max-Olivier Hongler",
                    "Renaud Rivier"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13461v1",
                    "http://arxiv.org/pdf/2311.13461v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "math.OC",
                    "60"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13458v1/1.0",
                "title": "Controlling crystal cleavage in Focused Ion Beam shaped specimens for\n  surface spectroscopy",
                "year": 2023,
                "abstract": "Our understanding of quantum materials is commonly based on precise\ndeterminations of their electronic spectrum by spectroscopic means, most\nnotably angle-resolved photoemission spectroscopy (ARPES) and scanning\ntunneling microscopy (STM). Both require atomically clean and flat crystal\nsurfaces which traditionally are prepared by in-situ mechanical cleaving in\nultrahigh vacuum chambers. We present a new approach that addresses three main\nissues of the current state-of-the-art methods: 1) Cleaving is a highly\nstochastic and thus inefficient process; 2) Fracture processes are governed by\nthe bonds in a bulk crystal, and many materials and surfaces simply do not\ncleave; 3) The location of the cleave is random, preventing data collection at\nspecified regions of interest. Our new workflow is based on Focused Ion Beam\n(FIB) machining of micro-stress lenses in which shape (rather than crystalline)\nanisotropy dictates the plane of cleavage, which can be placed at a specific\ntarget layer. As proof-of-principle we show ARPES results from micro-cleaves of\nSr$_2$RuO$_4$ along the ac plane and from two surface orientations of\nSrTiO$_3$, a notoriously difficult to cleave cubic perovskite.",
                "authors": [
                    "A. Hunter",
                    "C. Putzke",
                    "I. Gaponenko",
                    "A. Tamai",
                    "F. Baumberger",
                    "P. J. W. Moll"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13458v1",
                    "http://arxiv.org/pdf/2311.13458v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13457v1/1.0",
                "title": "Real-time unobtrusive sleep monitoring of in-patients with affective\n  disorders: a feasibility study",
                "year": 2023,
                "abstract": "Sleep and mental health are highly related concepts, and it is an important\nresearch and clinical priority to understand their interactions. In-bed sensors\nusing ballistocardiography provide the possibility of unobtrusive measurements\nof sleep. In this study, we examined the feasibility of ballistocardiography in\nmeasuring key aspects of sleep in psychiatric in-patients. Specifically, we\nexamined a sample of patients diagnosed with depression and bipolar disorder.\nThe subjective experiences of the researchers conducting the study are explored\nand descriptive analyses of patient sleep are subsequently presented. The\npracticalities of using the ballistocardiography device seem to be favourable.\nThere were no apparent issues regarding data quality or data integrity. Of\nclinical interest, we found no link between length of stay and reduced time in\nbed (b = -0.06, SE = 0.03, t = -1.76, p = .08). Using ballistocardiography for\nmeasurements on in-patients with affective disorders seems to be a feasible\napproach.",
                "authors": [
                    "Samuel Askjer",
                    "Kim Mathiasen",
                    "Ali Amidi",
                    "Christine Parsons",
                    "Nicolai Ladegaard"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13457v1",
                    "http://arxiv.org/pdf/2311.13457v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13455v1/1.0",
                "title": "Generation of Explanations for Logic Reasoning",
                "year": 2023,
                "abstract": "This thesis delves into a fortiori arguments in deductive reasoning,\nunderscoring their relevance in various domains such as law, philosophy, and\nartificial intelligence. The research is centred on employing GPT-3.5-turbo to\nautomate the analysis of these arguments, with a focus on understanding\nintricate reasoning processes, generating clear and coherent explanations, and\ncreating novel arguments. The methodology encompasses a series of tasks\nincluding detailed reasoning, interpretation, and the augmentation of a\nfortiori arguments. It involves meticulously identifying these arguments in\ndiverse contexts, differentiating comparative elements, and categorizing them\nbased on their logical structure.\n  Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in\naccurately detecting and classifying a fortiori arguments. Nevertheless, the\nmodel demonstrates a performance that rivals specialized models, particularly\nin extracting key components and interpreting underlying properties. The\nintegration of external information into the model's processing significantly\nelevates the quality of the generated explanations. Additionally, the model\nexhibits a noteworthy capability in augmenting arguments, thus contributing to\nthe enrichment of the data set.\n  Despite facing certain limitations, this thesis makes significant\ncontributions to the fields of artificial intelligence and logical reasoning.\nIt introduces novel methodologies, establishes a rigorous evaluation framework,\nand provides deep insights that set the stage for future advancements in\nautomated logical reasoning. The findings and methodologies presented herein\nnot only underscore the potential of AI in complex reasoning tasks but also\nhighlight areas for future research and development.",
                "authors": [
                    "Yanyi Pu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13455v1",
                    "http://arxiv.org/pdf/2311.13455v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13448v1/1.0",
                "title": "Millimeter Wave Thin-Film Bulk Acoustic Resonator in Sputtered Scandium\n  Aluminum Nitride Using Platinum Electrodes",
                "year": 2023,
                "abstract": "This work describes sputtered scandium aluminum nitride (ScAlN) thin-film\nbulk acoustic resonators (FBAR) at millimeter wave (mmWave) with high quality\nfactor (Q) using platinum (Pt) electrodes. FBARs with combinations of Pt and\naluminum (Al) electrodes, i.e., Al top Al bottom, Pt top Al bottom, Al top Pt\nbottom, and Pt top Pt bottom, are built to study the impact of electrodes on\nmmWave FBARs. The demonstrated FBAR with Pt top and bottom electrodes achieve\nelectromechanical coupling (k2) of 4.0% and Q of 116 for the first-order\nsymmetric (S1) mode at 13.7 GHz, and k2 of 1.8% and Q of 94 for third-order\nsymmetric (S3) mode at 61.6 GHz. Through these results, we confirmed that even\nin the frequency band of approximately 60 GHz, ScAlN FBAR can achieve a Q\nfactor approaching 100 with optimized fabrication and acoustic/EM design.\nFurther development calls for stacks with better quality in piezoelectric and\nmetallic layers.",
                "authors": [
                    "Sinwoo Cho",
                    "Omar Barrera",
                    "Pietro Simeoni",
                    "Ellie Y. Wang",
                    "Jack Kramer",
                    "Vakhtang Chulukhadze",
                    "Joshua Campbell",
                    "Matteo Rinaldi",
                    "Ruochen Lu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13448v1",
                    "http://arxiv.org/pdf/2311.13448v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13445v1/1.0",
                "title": "Transfer Attacks and Defenses for Large Language Models on Coding Tasks",
                "year": 2023,
                "abstract": "Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.",
                "authors": [
                    "Chi Zhang",
                    "Zifan Wang",
                    "Ravi Mangal",
                    "Matt Fredrikson",
                    "Limin Jia",
                    "Corina Pasareanu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13445v1",
                    "http://arxiv.org/pdf/2311.13445v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13442v1/1.0",
                "title": "Temporal Network Analysis of Email Communication Patterns in a Long\n  Standing Hierarchy",
                "year": 2023,
                "abstract": "An important concept in organisational behaviour is how hierarchy affects the\nvoice of individuals, whereby members of a given organisation exhibit differing\npower relations based on their hierarchical position. Although there have been\nprior studies of the relationship between hierarchy and voice, they tend to\nfocus on more qualitative small-scale methods and do not account for structural\naspects of the organisation. This paper develops large-scale computational\ntechniques utilising temporal network analysis to measure the effect that\norganisational hierarchy has on communication patterns within an organisation,\nfocusing on the structure of pairwise interactions between individuals. We\nfocus on one major organisation as a case study - the Internet Engineering Task\nForce (IETF) - a major technical standards development organisation for the\nInternet. A particularly useful feature of the IETF is a transparent hierarchy,\nwhere participants take on explicit roles (e.g. Area Directors, Working Group\nChairs). Its processes are also open, so we have visibility into the\ncommunication of people at different hierarchy levels over a long time period.\nWe utilise a temporal network dataset of 989,911 email interactions among\n23,741 participants to study how hierarchy impacts communication patterns. We\nshow that the middle levels of the IETF are growing in terms of their dominance\nin communications. Higher levels consistently experience a higher proportion of\nincoming communication than lower levels, with higher levels initiating more\ncommunications too. We find that communication tends to flow \"up\" the hierarchy\nmore than \"down\". Finally, we find that communication with higher-levels is\nassociated with future communication more than for lower-levels, which we\ninterpret as \"facilitation\". We conclude by discussing the implications this\nhas on patterns within the wider IETF and for other organisations.",
                "authors": [
                    "Matthew Russell Barnes",
                    "Mladen Karan",
                    "Stephen McQuistin",
                    "Colin Perkins",
                    "Gareth Tyson",
                    "Matthew Purver",
                    "Ignacio Castro",
                    "Richard G. Clegg"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13442v1",
                    "http://arxiv.org/pdf/2311.13442v1"
                ],
                "primary_category": "cs.SI",
                "categories": [
                    "cs.SI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13441v1/1.0",
                "title": "On convergence of points to limiting processes, with an application to\n  zeta zeros",
                "year": 2023,
                "abstract": "This paper considers sequences of points on the real line which have been\nrandomly translated, and provides conditions under which various notions of\nconvergence to a limiting point process are equivalent. In particular we\nconsider convergence in correlation, convergence in distribution, and\nconvergence of spacings between points. We also prove a simple Tauberian\ntheorem regarding rescaled correlations. The results are applied to zeros of\nthe Riemann zeta-function to show that several ways to state the GUE Hypothesis\nare equivalent. The proof relies on a moment bound of A. Fujii.",
                "authors": [
                    "Juan Arias de Reyna",
                    "Brad Rodgers"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13441v1",
                    "http://arxiv.org/pdf/2311.13441v1"
                ],
                "primary_category": "math.NT",
                "categories": [
                    "math.NT",
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13436v2/1.0",
                "title": "Sparsity-Driven EEG Channel Selection for Brain-Assisted Speech\n  Enhancement",
                "year": 2023,
                "abstract": "Speech enhancement is widely used as a front-end to improve the speech\nquality in many audio systems, while it is still hard to extract the target\nspeech in multi-talker conditions without prior information on the speaker\nidentity. It was shown by auditory attention decoding that the attended speaker\ncan be revealed by the electroencephalogram (EEG) of the listener implicitly.\nIn this work, we therefore propose a novel end-to-end brain-assisted speech\nenhancement network (BASEN), which incorporates the listeners' EEG signals and\nadopts a temporal convolutional network together with a convolutional\nmulti-layer cross attention module to fuse EEG-audio features. Considering that\nan EEG cap with sparse channels exhibits multiple benefits and in practice many\nelectrodes might contribute marginally, we further propose two channel\nselection methods, called residual Gumbel selection and convolutional\nregularization selection. They are dedicated to tackling the issues of training\ninstability and duplicated channel selections, respectively. Experimental\nresults on a public dataset show the superiority of the proposed baseline BASEN\nover existing approaches. The proposed channel selection methods can\nsignificantly reduce the amount of informative EEG channels with a negligible\nimpact on the performance.",
                "authors": [
                    "Jie Zhang",
                    "Qing-Tian Xu",
                    "Zhen-Hua Ling"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13436v2",
                    "http://arxiv.org/pdf/2311.13436v2"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13435v2/1.0",
                "title": "PG-Video-LLaVA: Pixel Grounding Large Video-Language Models",
                "year": 2023,
                "abstract": "Extending image-based Large Multimodal Models (LMMs) to videos is challenging\ndue to the inherent complexity of video data. The recent approaches extending\nimage-based LMMs to videos either lack the grounding capabilities (e.g.,\nVideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals for\nbetter video understanding (e.g., Video-ChatGPT). Addressing these gaps, we\npropose PG-Video-LLaVA, the first LMM with pixel-level grounding capability,\nintegrating audio cues by transcribing them into text to enrich video-context\nunderstanding. Our framework uses an off-the-shelf tracker and a novel\ngrounding module, enabling it to spatially localize objects in videos following\nuser instructions. We evaluate PG-Video-LLaVA using video-based generative and\nquestion-answering benchmarks and introduce new benchmarks specifically\ndesigned to measure prompt-based object grounding performance in videos.\nFurther, we propose the use of Vicuna over GPT-3.5, as utilized in\nVideo-ChatGPT, for video-based conversation benchmarking, ensuring\nreproducibility of results which is a concern with the proprietary nature of\nGPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends its\nadvantages to the video domain, delivering promising gains on video-based\nconversation and grounding tasks. Project Page:\nhttps://github.com/mbzuai-oryx/Video-LLaVA",
                "authors": [
                    "Shehan Munasinghe",
                    "Rusiru Thushara",
                    "Muhammad Maaz",
                    "Hanoona Abdul Rasheed",
                    "Salman Khan",
                    "Mubarak Shah",
                    "Fahad Khan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13435v2",
                    "http://arxiv.org/pdf/2311.13435v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13432v1/1.0",
                "title": "Modelling the propagation of coronal mass ejections with COCONUT:\n  implementation of the Regularized Biot-Savart Laws flux rope model",
                "year": 2023,
                "abstract": "Context: Coronal mass ejections (CMEs) are rapid eruptions of magnetized\nplasma that occur on the Sun, which are known as the main drivers of adverse\nspace weather. Accurately tracking their evolution in the heliosphere in\nnumerical models is of utmost importance for space weather forecasting. Aims:\nThe main objective of this paper is to implement the Regularized Biot-Savart\nLaws (RBSL) method in a new global corona model COCONUT. This approach has the\ncapability to construct the magnetic flux rope with an axis of arbitrary shape.\nMethods: We present the implementation process of the RBSL flux rope model in\nCOCONUT, which is superposed onto a realistic solar wind reconstructed from the\nobserved magnetogram around the minimum of solar activity. Based on this, we\nsimulate the propagation of an S-shaped flux rope from the solar surface to a\ndistance of 25 solar radii. Results: Our simulation successfully reproduces the\nbirth process of a CME originating from a sigmoid in a self-consistent way. The\nmodel effectively captures various physical processes and retrieves the\nprominent features of the CMEs in observations. In addition, the simulation\nresults indicate that the magnetic topology of the CME flux rope at around 20\nsolar radii deviates from a coherent structure, and manifests as a mix of open\nand closed field lines with diverse footpoints. Conclusions: This work\ndemonstrates the potential of the RBSL flux rope model in reproducing CME\nevents that are more consistent with observations. Moreover, our findings\nstrongly suggest that magnetic reconnection during the CME propagation plays a\ncritical role in destroying the coherent characteristic of a CME flux rope.",
                "authors": [
                    "Jinhan Guo",
                    "L. Linan",
                    "S. Poedts",
                    "Y. Guo",
                    "A. Lani",
                    "B. Schmieder",
                    "M. Brchnelova",
                    "B. Perri",
                    "T. Baratashvili",
                    "Y. W. Ni",
                    "P. F. Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13432v1",
                    "http://arxiv.org/pdf/2311.13432v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "physics.plasm-ph",
                    "physics.space-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13426v1/1.0",
                "title": "Numerical investigation of effective nonlinear coefficient model for\n  coupled third harmonic generation",
                "year": 2023,
                "abstract": "In this paper, the optimal solution of effective nonlinear coefficient of\nquasi-phase-matching (QPM) crystals for coupled third harmonic generation\n(CTHG) was numerically investigated. The effective nonlinear coefficient of\nCTHG was converted to an Ising model for optimizing domain length distributions\nof aperiodically poled lithium niobate (APPLN) crystals with lengths as 0.5 mm\nand 1 mm, and fundamental wavelengths ranging from 1000 nm to 6000 nm. A method\nfor reconstructing crystal domain poling weight curve of coupled nonlinear\nprocesses was also proposed, which demonstrated the optimal conversion ratio\nbetween two coupled nonlinear processes at each place along the crystal. In\naddition, by applying the semidefinite programming, the upper bound on the\neffective nonlinear coefficients deff for different fundamental wavelengths\nwere calculated. The research can be extended to any coupled dual \\c{hi}(2)\nprocess and will help us to understand better the dynamics of coupled nonlinear\ninteractions based on QPM crystals.",
                "authors": [
                    "Zihua Zheng",
                    "Ziwen Tang",
                    "Zhiyi Wei",
                    "Jinghua Sun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13426v1",
                    "http://arxiv.org/pdf/2311.13426v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13419v1/1.0",
                "title": "Simulation of universal optical logic gates under energy sharing\n  collisions of Manakov solitons and fulfillment of practical optical logic\n  criteria",
                "year": 2023,
                "abstract": "The universal optical logic gates, namely NAND and NOR gates, have been\ntheoretically simulated by employing the energy sharing collision of bright\noptical solitons in the Manakov system, governing pulse propagation in a highly\nbirefringent fiber. Further, we also realize the two input optical logic gates\nsuch as AND, OR, XOR, XNOR for completeness of our scheme. Interestingly, our\nidea behind the simulation naturally satisfies all the criteria for practical\noptical logic which in turn displays the strength and versatility of our\ntheoretical simulation of universal optical logic gates. Hence, our approach\npaves the way for the experimentalists to create a new avenue in this direction\nif the energy sharing collisions of Manakov solitons are experimentally\nrealized in the future.",
                "authors": [
                    "M. Vijayajayanthi",
                    "T. Kanna",
                    "M. Lakshmanan"
                ],
                "url": [
                    "http://dx.doi.org/10.1103/PhysRevE.108.054213",
                    "http://arxiv.org/abs/2311.13419v1",
                    "http://arxiv.org/pdf/2311.13419v1"
                ],
                "primary_category": "nlin.SI",
                "categories": [
                    "nlin.SI",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13418v1/1.0",
                "title": "Liouville theorem for quasilinear elliptic equations in $\\mathbb R^N$",
                "year": 2023,
                "abstract": "We prove Liouville theorem for the equation $\\Delta_m v + v^p + M |\\nabla\nv|^{q}= 0$ in a domain $\\Omega\\subset\\mathbb R^n$, with $M\\in \\mathbb{R}$ in\nthe critical and subcritical case. As a natural extension of our recent work\n\\cite{MWZ}, the proof is based on an integral identity and Young's inequality.",
                "authors": [
                    "Wangzhe Wu",
                    "Qiqi Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13418v1",
                    "http://arxiv.org/pdf/2311.13418v1"
                ],
                "primary_category": "math.AP",
                "categories": [
                    "math.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13417v1/1.0",
                "title": "Reproducible image-based profiling with Pycytominer",
                "year": 2023,
                "abstract": "Technological advances in high-throughput microscopy have facilitated the\nacquisition of cell images at a rapid pace, and data pipelines can now extract\nand process thousands of image-based features from microscopy images. These\nfeatures represent valuable single-cell phenotypes that contain information\nabout cell state and biological processes. The use of these features for\nbiological discovery is known as image-based or morphological profiling.\nHowever, these raw features need processing before use and image-based\nprofiling lacks scalable and reproducible open-source software. Inconsistent\nprocessing across studies makes it difficult to compare datasets and processing\nsteps, further delaying the development of optimal pipelines, methods, and\nanalyses. To address these issues, we present Pycytominer, an open-source\nsoftware package with a vibrant community that establishes an image-based\nprofiling standard. Pycytominer has a simple, user-friendly Application\nProgramming Interface (API) that implements image-based profiling functions for\nprocessing high-dimensional morphological features extracted from microscopy\nimages of cells. Establishing Pycytominer as a standard image-based profiling\ntoolkit ensures consistent data processing pipelines with data provenance,\ntherefore minimizing potential inconsistencies and enabling researchers to\nconfidently derive accurate conclusions and discover novel insights from their\ndata, thus driving progress in our field.",
                "authors": [
                    "Erik Serrano",
                    "Srinivas Niranj Chandrasekaran",
                    "Dave Bunten",
                    "Kenneth I. Brewer",
                    "Jenna Tomkinson",
                    "Roshan Kern",
                    "Michael Bornholdt",
                    "Stephen Fleming",
                    "Ruifan Pei",
                    "John Arevalo",
                    "Hillary Tsang",
                    "Vincent Rubinetti",
                    "Callum Tromans-Coia",
                    "Tim Becker",
                    "Erin Weisbart",
                    "Charlotte Bunne",
                    "Alexandr A. Kalinin",
                    "Rebecca Senft",
                    "Stephen J. Taylor",
                    "Nasim Jamali",
                    "Adeniyi Adeboye",
                    "Hamdah Shafqat Abbasi",
                    "Allen Goodman",
                    "Juan C. Caicedo",
                    "Anne E. Carpenter",
                    "Beth A. Cimini",
                    "Shantanu Singh",
                    "Gregory P. Way"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13417v1",
                    "http://arxiv.org/pdf/2311.13417v1"
                ],
                "primary_category": "q-bio.QM",
                "categories": [
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13407v1/1.0",
                "title": "Lozenge Tilings of a Hexagon and q-Racah Ensembles",
                "year": 2023,
                "abstract": "We study the limiting behavior of random lozenge tilings of the hexagon with\na q-Racah weight as the size of the hexagon grows large. Based on the\nasymptotic behavior of the recurrence coefficients of the q-Racah polynomials,\nwe give a new proof for the fact that that the height function for a random\ntiling concentrates near a deterministic limit shape and that the global\nfluctuations are described by the Gaussian Free Field. These results were\nrecently proved using (dynamic) loop equation techniques. In this paper we\nextend the recurrence coefficient approach that was developed for (dynamic)\northogonal polynomial ensembles to the setting of q-orthogonal polynomials. An\ninteresting feature is that the complex structure is easily found from the\nlimiting behavior of the (explicitly known) recurrence coefficients. A\nparticular motivation for studying this model is that the variational\ncharacterization of the limiting height function has an inhomogeneous term. The\nstudy of the regularity properties of the minimizer for general variation\nproblems with such inhomogeuous terms is a challenging open problem. We show\nthat, in a general setup, the variational problem gives rise to a natural\ncomplex structure that is associated to the same Beltrami equation as in the\nhomogeneous situation. We also derive a relation between the complex structure\nand the complex slope. In case of the q-Racah weighting of lozenge tilings of\nthe hexagon, our representation of the limit shape and their fluctuations in\nterms of the recurrence coefficients allows us to verify this relation\nexplicitly.",
                "authors": [
                    "Maurice Duits",
                    "Erik Duse",
                    "Wenkui Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13407v1",
                    "http://arxiv.org/pdf/2311.13407v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13406v1/1.0",
                "title": "Zig-zag dynamics in a Stern-Gerlach spin measurement",
                "year": 2023,
                "abstract": "The one-century-old Stern-Gerlach setup is paradigmatic for a quantum\nmeasurement. We visualize the electron trajectories following the Bohmian\nzig-zag dynamics. This dynamics was developed in order to deal with the\nfundamentally massless nature of particles (with mass emerging from the\nBrout-Englert-Higgs mechanism). The corresponding trajectories exhibit a\nstochastic zig-zagging, as the result of the coupling between left- and\nright-handed chiral Weyl states. This zig-zagging persists in the\nnon-relativistic limit, which will be considered here, and which is described\nthe Pauli equation for a nonuniform external magnetic field. Our results\nclarify the different meanings of \"spin\" as a property of the wave function and\nas a random variable in the Stern-Gerlach setup, and they illustrate the notion\nof effective collapse. We also examine the case of an EPR-pair. By letting one\nof the entangled particles pass through a Stern-Gerlach device, the nonlocal\ninfluence (action-at-a-distance) on the other particle is manifest in its\ntrajectory, e.g. by initiating its zig-zagging.",
                "authors": [
                    "Simon Krekels",
                    "Christian Maes",
                    "Kasper Meerts",
                    "Ward Struyve"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13406v1",
                    "http://arxiv.org/pdf/2311.13406v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13402v3/1.0",
                "title": "Condensed Matter Systems Exposed to Radiation: Multiscale Theory,\n  Simulations, and Experiment",
                "year": 2023,
                "abstract": "This paper reviews the new highly interdisciplinary research field studying\nthe behavior of condensed matter systems exposed to radiation. The paper\nhighlights several relevant examples of recent advances in the field and\nprovides a roadmap for the development of the field in the next decade.\nCondensed matter systems exposed to radiation may have very different natures,\nbeing inorganic, organic or biological, finite or infinite, be composed of many\ndifferent molecular species or materials, existing in different phases (solid,\nliquid, gaseous or plasma) and operating under different thermodynamic\nconditions. The essential and novel element of this research is that, despite\nthe vast diversity of such systems, many of the key phenomena related to the\nbehavior of irradiated systems (such as radiation-induced damage, mechanisms of\ndamage repair and control, radiation protection, etc.) are very similar and can\nbe understood based on the same fundamental theoretical principles and\ncomputational approaches. One of the essential features of the aforementioned\nphenomena concerns their multiscale nature as the manifestation of the\nradiation-induced effects occurring at different spatial and temporal scales\nranging from the atomic to the macroscopic. The multiscale nature of the\neffects and similarity of their manifestation in systems of different origins\nnecessarily brings together different disciplines, such as physics, chemistry,\nbiology, materials and nano-science, and biomedical research, demonstrating\nnumerous interlinks and commonalities between them. This research field is\nhighly relevant to many novel and emerging technologies and medical\napplications.",
                "authors": [
                    "Andrey V. Solov'yov",
                    "Alexey V. Verkhovtsev",
                    "Nigel J. Mason",
                    "Richard A. Amos",
                    "Ilko Bald",
                    "G\u00e9rard Baldacchino",
                    "Brendan Dromey",
                    "Martin Falk",
                    "Juraj Fedor",
                    "Luca Gerhards",
                    "Michael Hausmann",
                    "Georg Hildenbrand",
                    "Milo\u0161 Hrabovsk\u00fd",
                    "Stanislav Kadlec",
                    "Jaroslav Ko\u010di\u0161ek",
                    "Franck L\u00e9pine",
                    "Siyi Ming",
                    "Andrew Nisbet",
                    "Kate Ricketts",
                    "Leo Sala",
                    "Thomas Schlath\u00f6lter",
                    "Andrew Wheatley",
                    "Ilia A. Solov'yov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13402v3",
                    "http://arxiv.org/pdf/2311.13402v3"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "cond-mat.mes-hall",
                    "physics.atom-ph",
                    "physics.bio-ph",
                    "physics.plasm-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13397v1/1.0",
                "title": "Spatial Audio and Individualized HRTFs using a Convolutional Neural\n  Network (CNN)",
                "year": 2023,
                "abstract": "Spatial audio and 3-Dimensional sound rendering techniques play a pivotal and\nessential role in immersive audio experiences. Head-Related Transfer Functions\n(HRTFs) are acoustic filters which represent how sound interacts with an\nindividual's unique head and ears anatomy. The use of HRTFs compliant to the\nsubjects anatomical traits is crucial to ensure a personalized and unique\nspatial experience. This work proposes the implementation of an HRTF\nindividualization method based on anthropometric features automatically\nextracted from ear images using a Convolutional Neural Network (CNN). Firstly,\na CNN is implemented and tested to assess the performance of machine learning\non positioning landmarks on ear images. The I-BUG dataset, containing ear\nimages with corresponding 55 landmarks, was used to train and test the neural\nnetwork. Subsequently, 12 relevant landmarks were selected to correspond to 7\nspecific anthropometric measurements established by the HUTUBS database. These\nlandmarks serve as a reference for distance computation in pixels in order to\nretrieve the anthropometric measurements from the ear images. Once the 7\ndistances in pixels are extracted from the ear image, they are converted in\ncentimetres using conversion factors, a best match method vector is implemented\ncomputing the Euclidean distance for each set in a database of 116 ears with\ntheir corresponding 7 anthropometric measurements provided by the HUTUBS\ndatabase. The closest match of anthropometry can be identified and the\ncorresponding set of HRTFs can be obtained for personnalized use. The method is\nevaluated in its validity instead of the accuracy of the results. The\nconceptual scope of each stage has been verified and substantiated to function\ncorrectly. The various steps and the available elements in the process are\nreviewed and challenged to define a greater algorithm entity designed for the\ndesired task.",
                "authors": [
                    "Ludovic Pirard"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13397v1",
                    "http://arxiv.org/pdf/2311.13397v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13395v1/1.0",
                "title": "Site-selective doublon-holon dynamics in a pumped one-dimensional\n  Hubbard superlattice with staggered Coulomb interactions",
                "year": 2023,
                "abstract": "Doublon-holon dynamics is investigated in a pumped one-dimensional Hubbard\nmodel with a staggered on?site Coulomb interaction at half-filling. When the\nsystem parameters are set to be in the Mott insulating regime the equilibrium\nsublattice density of states exhibits several characteristic peaks,\ncorresponding to the lower and upper Hubbard bands as well as hybridization\nbands. We study the linear absorption spectrum and find two main peaks\ncharacterizing the photon frequencies which excite the ground state to an\nexcited state. For a system driven by a laser pulse with general intensity and\nfrequency, both the energy absorption and the doublon-holon dynamics exhibit\ndistinct behaviors as a function of laser amplitude and frequency.\nSingle-photon processes are observed at low laser intensity where the energy is\nabsorbed for resonance laser frequencies. For strong laser intensity\nmulti-photon induced dynamics are observed in the system, which are confirmed\nby an evaluation of the Loschmidt amplitude. The contribution of multi-photon\nprocesses to site-specific double occupancy is also characterized by the\ngeneralized Loschmidt amplitude. The site-selective doublon-holon dynamics are\nobserved in both the one and multi-photon processes and the site-selective\nbehavior is explained within a quasiparticle picture. Our study suggests\nstrategies to optically engineer the doublon-holon dynamics in one dimensional\nstrongly correlated many-body systems.",
                "authors": [
                    "Zhenyu Cheng",
                    "Ying Li",
                    "Hantao Lu",
                    "Xiang Hu",
                    "Zhongbing Huang",
                    "Gregory A. Fiete",
                    "Liang Du"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13395v1",
                    "http://arxiv.org/pdf/2311.13395v1"
                ],
                "primary_category": "cond-mat.str-el",
                "categories": [
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13390v2/1.0",
                "title": "Performance Analysis Of Binaural Signal Matching (BSM) in the\n  Time-Frequency Domain",
                "year": 2023,
                "abstract": "The capture and reproduction of spatial audio is becoming increasingly\npopular, with the mushrooming of applications in teleconferencing,\nentertainment and virtual reality. Many binaural reproduction methods have been\ndeveloped and studied extensively for spherical and other specially designed\narrays. However, the recent increased popularity of wearable and mobile arrays\nrequires the development of binaural reproduction methods for these arrays. One\nsuch method is binaural signal matching (BSM). However, to date this method has\nonly been investigated with fixed matched filters designed for long audio\nrecordings. With the aim of making the BSM method more adaptive to dynamic\nenvironments, this paper analyzes BSM with a parameterized sound-field in the\ntime-frequency domain. The paper presents results of implementing the BSM\nmethod on a sound-field that was decomposed into its direct and reverberant\ncomponents, and compares this implementation with the BSM computed for the\nentire sound-field, to compare performance for binaural reproduction of\nreverberant speech in a simulated environment.",
                "authors": [
                    "Ami Berger",
                    "Vladimir Tourbabin",
                    "Jacob Donley",
                    "Zamir Ben-Hur",
                    "Boaz Rafaely"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13390v2",
                    "http://arxiv.org/pdf/2311.13390v2"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13387v1/1.0",
                "title": "SystemC Model of Power Side-Channel Attacks Against AI Accelerators:\n  Superstition or not?",
                "year": 2023,
                "abstract": "As training artificial intelligence (AI) models is a lengthy and hence costly\nprocess, leakage of such a model's internal parameters is highly undesirable.\nIn the case of AI accelerators, side-channel information leakage opens up the\nthreat scenario of extracting the internal secrets of pre-trained models.\nTherefore, sufficiently elaborate methods for design verification as well as\nfault and security evaluation at the electronic system level are in demand. In\nthis paper, we propose estimating information leakage from the early design\nsteps of AI accelerators to aid in a more robust architectural design. We first\nintroduce the threat scenario before diving into SystemC as a standard method\nfor early design evaluation and how this can be applied to threat modeling. We\npresent two successful side-channel attack methods executed via SystemC-based\npower modeling: correlation power analysis and template attack, both leading to\ntotal information leakage. The presented models are verified against an\nindustry-standard netlist-level power estimation to prove general feasibility\nand determine accuracy. Consequently, we explore the impact of additive noise\nin our simulation to establish indicators for early threat evaluation. The\npresented approach is again validated via a model-vs-netlist comparison,\nshowing high accuracy of the achieved results. This work hence is a solid step\ntowards fast attack deployment and, subsequently, the design of\nattack-resilient AI accelerators.",
                "authors": [
                    "Andrija Ne\u0161kovi\u0107",
                    "Saleh Mulhem",
                    "Alexander Treff",
                    "Rainer Buchty",
                    "Thomas Eisenbarth",
                    "Mladen Berekovic"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/ICCAD57390.2023.10323687",
                    "http://arxiv.org/abs/2311.13387v1",
                    "http://arxiv.org/pdf/2311.13387v1"
                ],
                "primary_category": "cs.AR",
                "categories": [
                    "cs.AR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13381v1/1.0",
                "title": "Confidant: Customizing Transformer-based LLMs via Collaborative Edge\n  Training",
                "year": 2023,
                "abstract": "Transformer-based large language models (LLMs) have demonstrated impressive\ncapabilities in a variety of natural language processing (NLP) tasks.\nNonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge\ndevices with limited computing, memory, and energy budgets. In this paper, we\npropose Confidant, a multi-backend collaborative training framework for\ncustomizing state-of-the-art LLMs on commodity mobile devices like smartphones.\nConfidant partitions an LLM into several sub-models so that each fits into a\nmobile device's memory. A pipeline parallel training mechanism is further\ndeveloped to ensure fast and efficient distributed training. In addition, we\npropose a novel backend scheduler to allocate different attention heads to\nheterogeneous compute hardware, including mobile CPU and GPUs, to maximize the\ncompute resource utilization on each edge device. Our preliminary experimental\nresults show that Confidant achieves at most 45.3% memory reduction and 8.03x\ninference speedup in practical settings.",
                "authors": [
                    "Yuhao Chen",
                    "Yuxuan Yan",
                    "Qianqian Yang",
                    "Yuanchao Shu",
                    "Shibo He",
                    "Jiming Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13381v1",
                    "http://arxiv.org/pdf/2311.13381v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13378v1/1.0",
                "title": "Point Projection Mapping System for Tracking, Registering, Labeling and\n  Validating Optical Tissue Measurements",
                "year": 2023,
                "abstract": "Validation of newly developed optical tissue sensing techniques for tumor\ndetection during cancer surgery requires an accurate correlation with\nhistological results. Additionally, such accurate correlation facilitates\nprecise data labeling for developing high-performance machine-learning tissue\nclassification models. In this paper, a newly developed Point Projection\nMapping system will be introduced, which allows non-destructive tracking of the\nmeasurement locations on tissue specimens. Additionally, a framework for\naccurate registration, validation, and labeling with histopathology results is\nproposed and validated on a case study. The proposed framework provides a more\nrobust and accurate method for tracking and validation of optical tissue\nsensing techniques, which saves time and resources compared to conventional\ntechniques available.",
                "authors": [
                    "Lianne Feenstra",
                    "Stefan D. van der Stel",
                    "Marcos Da Silva Guimaraes",
                    "Theo J. M Ruers",
                    "Behdad Dashtbozorg"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13378v1",
                    "http://arxiv.org/pdf/2311.13378v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13376v1/1.0",
                "title": "Thermal Pair Production from Photon-Photon Collision: Breit-Wheeler\n  Process at Finite Temperature",
                "year": 2023,
                "abstract": "In this paper we examine the pair production through the Breit-Wheeler\nprocess $\\gamma~\\gamma \\to e^+ e^-$ in a thermal background. We compute the\nthermal contribution to the Breit-Wheeler differential cross section within the\nthermofield dynamics formalism. We evaluate in details the cross section for\nthis process, which possess a surprisingly simple expression valid for any\ntemperature $\\beta$, from which we discuss some physically relevant aspects. We\nalso consider the high temperature regime of the cross section in order to have\na better understanding about its thermal behavior.",
                "authors": [
                    "D. S. Cabral",
                    "A. F. Santos",
                    "R. Bufalo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13376v1",
                    "http://arxiv.org/pdf/2311.13376v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph",
                    "hep-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13373v3/1.0",
                "title": "Large Language Model is a Good Policy Teacher for Training Reinforcement\n  Learning Agents",
                "year": 2023,
                "abstract": "Recent studies have shown that Large Language Models (LLMs) can be utilized\nfor solving complex sequential decision-making tasks by providing high-level\ninstructions. However, LLM-based agents face limitations in real-time dynamic\nenvironments due to their lack of specialization in solving specific target\nproblems. Moreover, the deployment of such LLM-based agents is both costly and\ntime-consuming in practical scenarios. In this paper, we introduce a novel\nframework that addresses these challenges by training a smaller scale\nspecialized student agent using instructions from an LLM-based teacher agent.\nBy leveraging guided actions provided by the teachers, the prior knowledge of\nthe LLM is distilled into the local student model. Consequently, the student\nagent can be trained with significantly less data. Furthermore, subsequent\ntraining with environment feedback empowers the student agents to surpass the\ncapabilities of their teachers. We conducted experiments on three challenging\nMiniGrid environments to evaluate the effectiveness of our framework. The\nresults demonstrate that our approach enhances sample efficiency and achieves\nsuperior performance compared to baseline methods. Our code is available at\nhttps://github.com/ZJLAB-AMMI/LLM4Teach.",
                "authors": [
                    "Zihao Zhou",
                    "Bin Hu",
                    "Pu Zhang",
                    "Chenyang Zhao",
                    "Bin Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13373v3",
                    "http://arxiv.org/pdf/2311.13373v3"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13372v2/1.0",
                "title": "MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance\n  Imaging in Individual Space",
                "year": 2023,
                "abstract": "Eye-tracking research has proven valuable in understanding numerous cognitive\nfunctions. Recently, Frey et al. provided an exciting deep learning method for\nlearning eye movements from fMRI data. However, it needed to co-register fMRI\ninto standard space to obtain eyeballs masks, and thus required additional\ntemplates and was time consuming. To resolve this issue, in this paper, we\npropose a framework named MRGazer for predicting eye gaze points from fMRI in\nindividual space. The MRGazer consisted of eyeballs extraction module and a\nresidual network-based eye gaze prediction. Compared to the previous method,\nthe proposed framework skips the fMRI co-registration step, simplifies the\nprocessing protocol and achieves end-to-end eye gaze regression. The proposed\nmethod achieved superior performance in a variety of eye movement tasks than\nthe co-registration-based method, and delivered objective results within a\nshorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Seconds\nfor each volume).",
                "authors": [
                    "Xiuwen Wu",
                    "Rongjie Hu",
                    "Jie Liang",
                    "Yanming Wang",
                    "Bensheng Qiu",
                    "Xiaoxiao Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13372v2",
                    "http://arxiv.org/pdf/2311.13372v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "q-bio.NC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13366v1/1.0",
                "title": "Direct observations of general geothermal convection in deep\n  Mediterranean waters",
                "year": 2023,
                "abstract": "Like elsewhere in the deep-sea, life in the deep Mediterranean depends on\nturbulent exchange across the stable vertical density stratification for supply\nof nutrients and oxygen. Commonly modelled, turbulent exchange is inversely\nproportional to the stratification rate. However, this proportionality depends\non the particular turbulence type, whether it is driven by vertical current\ndifferences (shear) or by buoyancy (convection). While shear-turbulence is well\nobserved in stratified seas, direct observations of convection-turbulence are\nlimited. In this paper, high-resolution moored temperature observations show\nthat Mediterranean Sea waters are not stagnant in the lower 109 m above the\nseafloor at 2480 m, although variations are in the range of only 0.0001-0.001\ndegrC. In winter, convection-turbulence is regularly observed. Fortnightly\naveraged spectra show a collapse to the inertial-subrange scaling of dominant\nshear-turbulence for data from about 100 m above the seafloor, and to the\nbuoyancy-subrange scaling of dominant convection-turbulence at about 10 m above\nthe seafloor. Time-depth images reveal details of convection-turbulence driven\nfrom below, which is considered primarily due to general geothermal heating\nthrough the Earth crust not related to volcanic vents. When its observation is\nnot masked by (sub-)mesoscale eddies that advect warmer waters from above, the\ngeothermal heat flux matches the deep-sea turbulence dissipation rate, if in\nthe calculations a mixing efficiency of 0.5 is taken typical for natural\nconvection, integration is over 250 m above the seafloor as confirmed from\nshipborne CTD, and if maximum 2-m-scale buoyancy frequency replaces its\n100-m-scale mean equivalent.",
                "authors": [
                    "Hans van Haren"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13366v1",
                    "http://arxiv.org/pdf/2311.13366v1"
                ],
                "primary_category": "physics.ao-ph",
                "categories": [
                    "physics.ao-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13361v1/1.0",
                "title": "Applying Large Language Models to Power Systems: Potential Security\n  Threats",
                "year": 2023,
                "abstract": "Applying large language models (LLMs) to power systems presents a promising\navenue for enhancing decision-making and operational efficiency. However, this\naction may also incur potential security threats, which have not been fully\nrecognized so far. To this end, this letter analyzes potential threats incurred\nby applying LLMs to power systems, emphasizing the need for urgent research and\ndevelopment of countermeasures.",
                "authors": [
                    "Jiaqi Ruan",
                    "Gaoqi Liang",
                    "Huan Zhao",
                    "Guolong Liu",
                    "Jing Qiu",
                    "Junhua Zhao",
                    "Zhao Xu",
                    "Fushuan Wen",
                    "Zhao Yang Dong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13361v1",
                    "http://arxiv.org/pdf/2311.13361v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.HC",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13357v1/1.0",
                "title": "Improvements in charged lepton and photon propagation for the software\n  PROPOSAL",
                "year": 2023,
                "abstract": "Accurate particle simulations are essential for the next generation of\nexperiments in astroparticle physics. The Monte Carlo simulation library\nPROPOSAL is a flexible tool to efficiently propagate high-energy leptons and\nphotons through large volumes of media, for example in the context of\nunderground observatories. It is written as a C++ library, including a Python\ninterface. In this paper, the most recent updates of PROPOSAL are described,\nincluding the addition of electron, positron, and photon propagation, for which\nnew interaction types have been implemented. This allows the usage of PROPOSAL\nto simulate electromagnetic particle cascades, for example in the context of\nair shower simulations. The precision of the propagation has been improved by\nincluding rare interaction processes, new photonuclear parametrizations,\ndeflections in stochastic interactions, and the possibility of propagating in\ninhomogeneous density distributions. Additional technical improvements\nregarding the interpolation routine and the propagation algorithm are\ndescribed.",
                "authors": [
                    "Jean-Marco Alameddine",
                    "Johannes Albrecht",
                    "Hans Dembinski",
                    "Pascal Gutjahr",
                    "Karl-Heinz Kampert",
                    "Wolfgang Rhode",
                    "Maximilian Sackel",
                    "Alexander Sandrock",
                    "Jan Soedingrekso"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13357v1",
                    "http://arxiv.org/pdf/2311.13357v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "hep-ex",
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13352v1/1.0",
                "title": "Fuzzy Dark Matter Dynamics and the Quasiparticle Hypothesis",
                "year": 2023,
                "abstract": "Dark matter may be composed of ultra-light bosons whose de Broglie wavelength\nin galaxies is of order 1 kpc. The standard model for this fuzzy dark matter\n(FDM) is a complex scalar field that obeys the Schr\\\"odinger-Poisson equations.\nThe wavelike nature of FDM leads to fluctuations in the gravitational field\nthat can pump energy into the stellar components of a galaxy. Heuristic\narguments and theoretical analyses suggest that these fluctuations can be\nmodelled by replacing FDM with a system of quasiparticles (QPs). We test this\nhypothesis by comparing self-consistent simulations of a Schr\\\"odinger field\nwith those using a system of QPs in one spatial dimension. Simulations of pure\nFDM systems allow us to derive a phenomenological relation between the number\nof QPs that is required to model FDM with a given de Broglie wavelength. We\nalso simulate systems of FDM and stars and find that the FDM pumps energy into\nthe stars whether it is described by QPs or a Schr\\\"odinger field with the FDM\nadiabatically contracting and the stellar system adiabatically expanding.\nHowever, we find that QPs overestimate dynamical heating.",
                "authors": [
                    "Boris Zupancic",
                    "Lawrence M. Widrow"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13352v1",
                    "http://arxiv.org/pdf/2311.13352v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13351v1/1.0",
                "title": "Gradual Verification for Smart Contracts",
                "year": 2023,
                "abstract": "Blockchains facilitate secure resource transactions through smart contracts,\nyet these digital agreements are prone to vulnerabilities, particularly when\ninteracting with external contracts, leading to substantial monetary losses.\nTraditional verification techniques fall short in providing comprehensive\nsecurity assurances, especially against re-entrancy attacks, due to the\nunavailable implementations of external contracts. This paper introduces an\nincremental approach: gradual verification. We combine static and dynamic\nverification techniques to enhance security, guarantee soundness and\nflexibility, and optimize resource usage in smart contract interactions. By\nimplementing a prototype for gradually verifying Algorand smart contracts via\nthe pyTEAL language, we demonstrate the effectiveness of our approach,\ncontributing to the safe and efficient execution of smart contracts.",
                "authors": [
                    "Haojia Sun",
                    "Kunal Singh",
                    "Jan-Paul Ramos-D\u00e1vila",
                    "Jonathan Aldrich",
                    "Jenna DiVincenzo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13351v1",
                    "http://arxiv.org/pdf/2311.13351v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR",
                    "cs.LO",
                    "cs.PL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13350v1/1.0",
                "title": "Fact-based Court Judgment Prediction",
                "year": 2023,
                "abstract": "This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.",
                "authors": [
                    "Shubham Kumar Nigam",
                    "Aniket Deroy"
                ],
                "url": [
                    "http://dx.doi.org/10.1145/3632754.3632765",
                    "http://arxiv.org/abs/2311.13350v1",
                    "http://arxiv.org/pdf/2311.13350v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.IR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13338v1/1.0",
                "title": "High-Quality Face Caricature via Style Translation",
                "year": 2023,
                "abstract": "Caricature is an exaggerated form of artistic portraiture that accentuates\nunique yet subtle characteristics of human faces. Recently, advancements in\ndeep end-to-end techniques have yielded encouraging outcomes in capturing both\nstyle and elevated exaggerations in creating face caricatures. Most of these\napproaches tend to produce cartoon-like results that could be more practical\nfor real-world applications. In this study, we proposed a high-quality,\nunpaired face caricature method that is appropriate for use in the real world\nand uses computer vision techniques and GAN models. We attain the exaggeration\nof facial features and the stylization of appearance through a two-step\nprocess: Face caricature generation and face caricature projection. The face\ncaricature generation step creates new caricature face datasets from real\nimages and trains a generative model using the real and newly created\ncaricature datasets. The Face caricature projection employs an encoder trained\nwith real and caricature faces with the pretrained generator to project real\nand caricature faces. We perform an incremental facial exaggeration from the\nreal image to the caricature faces using the encoder and generator's latent\nspace. Our projection preserves the facial identity, attributes, and\nexpressions from the input image. Also, it accounts for facial occlusions, such\nas reading glasses or sunglasses, to enhance the robustness of our model.\nFurthermore, we conducted a comprehensive comparison of our approach with\nvarious state-of-the-art face caricature methods, highlighting our process's\ndistinctiveness and exceptional realism.",
                "authors": [
                    "Lamyanba Laishram",
                    "Muhammad Shaheryar",
                    "Jong Taek Lee",
                    "Soon Ki Jung"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13338v1",
                    "http://arxiv.org/pdf/2311.13338v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13335v1/1.0",
                "title": "Quantum learning and essential cognition under the traction of\n  meta-characteristics in an open world",
                "year": 2023,
                "abstract": "Artificial intelligence has made significant progress in the Close World\nproblem, being able to accurately recognize old knowledge through training and\nclassification. However, AI faces significant challenges in the Open World\nproblem, as it involves a new and unknown exploration journey. AI is not\ninherently proactive in exploration, and its challenge lies in not knowing how\nto approach and adapt to the unknown world. How do humans acquire knowledge of\nthe unknown world. Humans identify new knowledge through intrinsic cognition.\nIn the process of recognizing new colors, the cognitive cues are different from\nknown color features and involve hue, saturation, brightness, and other\ncharacteristics. When AI encounters objects with different features in the new\nworld, it faces another challenge: where are the distinguishing features\nbetween influential features of new and old objects? AI often mistakes a new\nworld's brown bear for a known dog because it has not learned the differences\nin feature distributions between knowledge systems. This is because things in\nthe new and old worlds have different units and dimensions for their features.\nThis paper proposes an open-world model and elemental feature system that\nfocuses on fundamentally recognizing the distribution differences in objective\nfeatures between the new and old worlds. The quantum tunneling effect of\nlearning ability in the new and old worlds is realized through the tractive\nforce of meta-characteristic. The outstanding performance of the model system\nin learning new knowledge (using pedestrian re-identification datasets as an\nexample) demonstrates that AI has acquired the ability to recognize the new\nworld with an accuracy of $96.71\\%$ at most and has gained the capability to\nexplore new knowledge, similar to humans.",
                "authors": [
                    "Jin Wang",
                    "Changlin Song"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13335v1",
                    "http://arxiv.org/pdf/2311.13335v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13331v1/1.0",
                "title": "Automated generation of attack trees with optimal shape and labelling",
                "year": 2023,
                "abstract": "The problem this article addresses is, given a formal specification of a\nsystem, how to produce an attack tree that correctly and clearly describes the\nways the system can be attacked. Correctness means that the attacks displayed\nby the attack tree are indeed attacks in the system; clarity means that the\ntree is efficient in communicating the attack scenario. To pursue clarity, we\nintroduce an attack-tree generation algorithm that minimises the tree size and\nthe information length of its labels without sacrificing correctness. We\nachieve this by establishing a connection between the problem of factorising\nalgebraic expressions and the problem of minimising the tree size. Notably, our\ngeneration algorithm can handle complex attacks that execute actions in\nparallel and sequentially. For completeness, we introduce a system model that\nintegrates well with our generation approach, and validate the resulting\nframework via a running example.",
                "authors": [
                    "Olga Gadyatskaya",
                    "Sjouke Mauw",
                    "Rolando Trujillo-Rasuac",
                    "Tim A. C. Willemse"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13331v1",
                    "http://arxiv.org/pdf/2311.13331v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR",
                    "cs.FL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13329v1/1.0",
                "title": "Timely and Efficient Information Delivery in Real-Time Industrial IoT\n  Networks",
                "year": 2023,
                "abstract": "Enabling real-time communication in Industrial Internet of Things (IIoT)\nnetworks is crucial to support autonomous, self-organized and re-configurable\nindustrial automation for Industry 4.0 and the forthcoming Industry 5.0. In\nthis paper, we consider a SIC-assisted real-time IIoT network, in which sensor\nnodes generate reports according to an event-generation probability that is\nspecific for the monitored phenomena. The reports are delivered over a\nblock-fading channel to a common Access Point (AP) in slotted ALOHA fashion,\nwhich leverages the imbalances in the received powers among the contending\nusers and applies successive interference cancellation (SIC) to decode user\npackets from the collisions. We provide an extensive analytical treatment of\nthe setup, deriving the Age of Information (AoI), throughput and deadline\nviolation probability, when the AP has access to both the perfect as well as\nthe imperfect channel-state information. We show that adopting SIC improves all\nthe performance parameters with respect to the standard slotted ALOHA, as well\nas to an age-dependent access method. The analytical results agree with the\nsimulation based ones, demonstrating that investing in the SIC capability at\nthe receiver enables this simple access method to support timely and efficient\ninformation delivery in IIoT networks.",
                "authors": [
                    "Hossam Farag",
                    "Dejan Vukobratovic",
                    "Andrea Munari",
                    "Cedomir Stefanovic"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13329v1",
                    "http://arxiv.org/pdf/2311.13329v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13325v1/1.0",
                "title": "AA-DL: AoI-Aware Deep Learning Approach for D2D-Assisted Industrial IoT",
                "year": 2023,
                "abstract": "In real-time Industrial Internet of Things (IIoT), e.g., monitoring and\ncontrol scenarios, the freshness of data is crucial to maintain the system\nfunctionality and stability. In this paper, we propose an AoI-Aware Deep\nLearning (AA-DL) approach to minimize the Peak Age of Information (PAoI) in\nD2D-assisted IIoT networks. Particularly, we analyzed the success probability\nand the average PAoI via stochastic geometry, and formulate an optimization\nproblem with the objective to find the optimal scheduling policy that minimizes\nPAoI. In order to solve the non-convex scheduling problem, we develop a Neural\nNetwork (NN) structure that exploits the Geographic Location Information (GLI)\nalong with feedback stages to perform unsupervised learning over randomly\ndeployed networks. Our motivation is based on the observation that in various\ntransmission contexts, the wireless channel intensity is mainly influenced by\ndistancedependant path loss, which could be calculated using the GLI of each\nlink. The performance of the AA-DL method is evaluated via numerical results\nthat demonstrate the effectiveness of our proposed method to improve the PAoI\nperformance compared to a recent benchmark while maintains lower complexity\nagainst the conventional iterative optimization method.",
                "authors": [
                    "Hossam Farag",
                    "Mohamed Ragab",
                    "Cedomir Stefanovic"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13325v1",
                    "http://arxiv.org/pdf/2311.13325v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13320v1/1.0",
                "title": "Brownian motion of droplets induced by thermal noise",
                "year": 2023,
                "abstract": "Brownian motion (BM) is pivotal in natural science for the stochastic motion\nof microscopic droplets. In this study, we investigate BM driven by thermal\ncomposition noise at sub-micro scales, where inter-molecular diffusion and\nsurface tension both are significant. To address BM of microscopic droplets, we\ndevelop two stochastic multi-phase-field models coupled with the full\nNavier-Stokes equation, namely Allen-Cahn-Navier-Stokes (ACNS) and\nCahn-Hilliard-Navier-Stokes (CHNS). Both models are validated against capillary\nwave theory; the Einstein's relation for the Brownian coefficient at\nthermodynamic equilibrium is recovered. Moreover, by adjusting the co-action of\nthe diffusion, Marangoni effect, and viscous friction, two non-equilibrium\nphenomena are observed. (I) The droplet motion transits from the Brownian to\nBallistic with increasing Marangoni effect which is emanated from the energy\ndissipation mechanism distinct from the conventional fluctuation-dissipation\ntheorem. (II) The deterministic droplet motion is triggered by the noise\ninduced non-uniform velocity field which leads to a novel droplet coalescence\nmechanism associated with the thermal noise.",
                "authors": [
                    "Haodong Zhang",
                    "Fei Wang",
                    "Lorenz Ratke",
                    "Britta Nestler"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13320v1",
                    "http://arxiv.org/pdf/2311.13320v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "cond-mat.stat-mech",
                    "nlin.CD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13319v1/1.0",
                "title": "Deep Learning for Vascular Segmentation and Applications in Phase\n  Contrast Tomography Imaging",
                "year": 2023,
                "abstract": "Automated blood vessel segmentation is vital for biomedical imaging, as\nvessel changes indicate many pathologies. Still, precise segmentation is\ndifficult due to the complexity of vascular structures, anatomical variations\nacross patients, the scarcity of annotated public datasets, and the quality of\nimages. We present a thorough literature review, highlighting the state of\nmachine learning techniques across diverse organs. Our goal is to provide a\nfoundation on the topic and identify a robust baseline model for application to\nvascular segmentation in a new imaging modality, Hierarchical Phase Contrast\nTomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation\nFacility, HiP CT enables 3D imaging of complete organs at an unprecedented\nresolution of ca. 20mm per voxel, with the capability for localized zooms in\nselected regions down to 1mm per voxel without sectioning. We have created a\ntraining dataset with double annotator validated vascular data from three\nkidneys imaged with HiP CT in the context of the Human Organ Atlas Project.\nFinally, utilising the nnU Net model, we conduct experiments to assess the\nmodels performance on both familiar and unseen samples, employing vessel\nspecific metrics. Our results show that while segmentations yielded reasonably\nhigh scores such as clDice values ranging from 0.82 to 0.88, certain errors\npersisted. Large vessels that collapsed due to the lack of hydrostatic pressure\n(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased\nconnectivity in finer vessels and higher segmentation errors at vessel\nboundaries were observed. Such errors obstruct the understanding of the\nstructures by interrupting vascular tree connectivity. Through our review and\noutputs, we aim to set a benchmark for subsequent model evaluations using\nvarious modalities, especially with the HiP CT imaging database.",
                "authors": [
                    "Ekin Yagis",
                    "Shahab Aslani",
                    "Yashvardhan Jain",
                    "Yang Zhou",
                    "Shahrokh Rahmani",
                    "Joseph Brunet",
                    "Alexandre Bellier",
                    "Christopher Werlein",
                    "Maximilian Ackermann",
                    "Danny Jonigk",
                    "Paul Tafforeau",
                    "Peter D Lee",
                    "Claire Walsh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13319v1",
                    "http://arxiv.org/pdf/2311.13319v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13314v1/1.0",
                "title": "Mitigating Large Language Model Hallucinations via Autonomous Knowledge\n  Graph-based Retrofitting",
                "year": 2023,
                "abstract": "Incorporating factual knowledge in knowledge graph is regarded as a promising\napproach for mitigating the hallucination of large language models (LLMs).\nExisting methods usually only use the user's input to query the knowledge\ngraph, thus failing to address the factual hallucination generated by LLMs\nduring its reasoning process. To address this problem, this paper proposes\nKnowledge Graph-based Retrofitting (KGR), a new framework that incorporates\nLLMs with KGs to mitigate factual hallucination during the reasoning process by\nretrofitting the initial draft responses of LLMs based on the factual knowledge\nstored in KGs. Specifically, KGR leverages LLMs to extract, select, validate,\nand retrofit factual statements within the model-generated responses, which\nenables an autonomous knowledge verifying and refining procedure without any\nadditional manual efforts. Experiments show that KGR can significantly improve\nthe performance of LLMs on factual QA benchmarks especially when involving\ncomplex reasoning processes, which demonstrates the necessity and effectiveness\nof KGR in mitigating hallucination and enhancing the reliability of LLMs.",
                "authors": [
                    "Xinyan Guan",
                    "Yanjiang Liu",
                    "Hongyu Lin",
                    "Yaojie Lu",
                    "Ben He",
                    "Xianpei Han",
                    "Le Sun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13314v1",
                    "http://arxiv.org/pdf/2311.13314v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13313v1/1.0",
                "title": "Towards the Intuitive Understanding of Quantum World: Sonification of\n  Rabi Oscillations, Wigner functions, and Quantum Simulators",
                "year": 2023,
                "abstract": "Recently, there has been considerable interest in \"sonifying\" scientific\ndata; however, sonifying quantum processes using the newest quantum\ntechnologies, including Noise Intermediate Scale Quantum devices and quantum\nrandom number generators, is still an emerging area of research. Music\ntechnologists and composers employ the growing accessibility to diverse data\nfrom quantum mechanics as musical tools in the hope of generating new sound\nexpressions. How different is the quantum world from the classical one, and is\nit possible to express the quantum world using sounds? Quantum phenomena are\nvery different from those that we experience in our everyday lives. Thus, it is\nchallenging to understand them intuitively. In this paper, we propose\nsonification as a method toward an intuitive understanding of various quantum\nmechanical phenomena, from Rabi oscillations and resonance fluorescence of a\nsingle atom through the generation of Schr\\\"odinger cat states in strong laser\nfield physics to insulator-superfluid transition in quantum many-body systems.\nThis paper illustrates various methods we experimented with in sonification and\nscore representations of quantum data depending on the source data and\nperformance settings.",
                "authors": [
                    "Reiko Yamada",
                    "Eloy Pi\u00f1ol",
                    "Samuele Grandi",
                    "Jakub Zakrzewski",
                    "Maciej Lewenstein"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13313v1",
                    "http://arxiv.org/pdf/2311.13313v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13312v1/1.0",
                "title": "Optimization of Synthesis Parameters and Superconducting Properties of\n  GdFeAsO1-xFx",
                "year": 2023,
                "abstract": "REFeAsO (RE1111; RE: rare earth) belongs to the 1111 family of iron-based\nsuperconductors (FBS), which illustrates the enhancement of the superconducting\ntransition (Tc) with smaller radii of RE. However, the synthesis of the 1111\nphase with a heavy rare-earth is always challenging. In this paper, we report\nthe optimization of the growth and superconducting properties of F-doped\nGdFeAsO1-xFx bulks by preparing the samples in a wide temperature range\n(700-1100{\\deg}C) at ambient pressure. The optimized synthesis parameters are\nconcluded based on structural, microstructural, transport, and magnetic\nmeasurements. These findings suggest that the optimal conditions for preparing\nF-doped Gd1111 bulks involve a two-step process at 900{\\deg}C for 61 hours at\nambient pressure, which is lower than previously reported. The optimized\nsamples have revealed the superconducting transition temperature (Tconset) of\n43 K for GdFeAsO0.83F0.17. The first-time reported critical current Jc value\nfor this Gd1111 is observed of the order of 10^3 (A/cm^2) at 0 T and 5 K. Our\ninvestigation also concluded that highly pure precursors, particularly\ngadolinium metal, are required to achieve the superconducting properties of\nF-doped Gd1111. A high growth pressure of 1 GPa reduces the superconducting\nproperties of F-doped Gd1111.",
                "authors": [
                    "Mohammad Azam",
                    "Manasa Manasa",
                    "Tatiana Zajarniuk",
                    "Svitlana Stelmakh",
                    "Tomasz Cetner",
                    "Andrzej Morawski",
                    "Andrzej Wi\u015bniewski",
                    "Shiv J. Singh"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/TASC.2023.3341858",
                    "http://arxiv.org/abs/2311.13312v1",
                    "http://arxiv.org/pdf/2311.13312v1"
                ],
                "primary_category": "cond-mat.supr-con",
                "categories": [
                    "cond-mat.supr-con",
                    "cond-mat.mtrl-sci",
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13311v1/1.0",
                "title": "Liquid-solid friction on crystalline surfaces: a perspective",
                "year": 2023,
                "abstract": "Liquids flowing on solid surfaces experience a friction force. Whereas solid\nfriction is familiar to anyone gifted with the sense of touch, liquid friction\nis much more exotic. Although it was long believed to be infinite, meaning that\ninterfacial liquid molecules stick to solid surfaces, we have known for a few\ndecades that this is not the case and that some materials show extreme liquid\nslippage, which implies a dramatic enhancement of nanoscale pipes' permeability\nto liquid flows. Harnessing liquid friction bears the promise of\nhigh-efficiency membrane separation processes, heat recovery systems, or blue\nenergy harvesting, turning it into a highly strategic field to reduce carbon\nemissions and meet the climate emergency.",
                "authors": [
                    "Mathieu Liz\u00e9e",
                    "Alessandro Siria"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13311v1",
                    "http://arxiv.org/pdf/2311.13311v1"
                ],
                "primary_category": "cond-mat.soft",
                "categories": [
                    "cond-mat.soft",
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13309v1/1.0",
                "title": "Buildup and dephasing of Floquet-Bloch bands on subcycle time scales",
                "year": 2023,
                "abstract": "Strong light fields have created spectacular opportunities to tailor novel\nfunctionalities of solids. Floquet-Bloch states can form under periodic driving\nof electrons and enable exotic quantum phases. On subcycle time scales,\nlightwaves can simultaneously drive intraband currents and interband\ntransitions, which enable high-harmonic generation (HHG) and pave the way\ntowards ultrafast electronics. Yet, the interplay of intra- and interband\nexcitations as well as their relation with Floquet physics have been key open\nquestions as dynamical aspects of Floquet states have remained elusive. Here we\nprovide this pivotal link by pioneering the ultrafast buildup of Floquet-Bloch\nbands with time- and angle-resolved photoemission spectroscopy. We drive\nsurface states on a topological insulator with mid-infrared fields - strong\nenough for HHG - and directly monitor the transient band structure with\nsubcycle time resolution. Starting with strong intraband currents, we observe\nhow Floquet sidebands emerge within a single optical cycle; intraband\nacceleration simultaneously proceeds in multiple sidebands until high-energy\nelectrons scatter into bulk states and dissipation destroys the Floquet bands.\nQuantum nonequilibrium calculations explain the simultaneous occurrence of\nFloquet states with intra- and interband dynamics. Our joint experiment-theory\nstudy opens up a direct time-domain view of Floquet physics and explores the\nfundamental frontiers of ultrafast band-structure engineering.",
                "authors": [
                    "S. Ito",
                    "M. Sch\u00fcler",
                    "M. Meierhofer",
                    "S. Schlauderer",
                    "J. Freudenstein",
                    "J. Reimann",
                    "D. Afanasiev",
                    "K. A. Kokh",
                    "O. E. Tereshchenko",
                    "J. G\u00fcdde",
                    "M. A. Sentef",
                    "U. H\u00f6fer",
                    "R. Huber"
                ],
                "url": [
                    "http://dx.doi.org/10.1038/s41586-023-05850-x",
                    "http://arxiv.org/abs/2311.13309v1",
                    "http://arxiv.org/pdf/2311.13309v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "cond-mat.other"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13307v2/1.0",
                "title": "Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation",
                "year": 2023,
                "abstract": "Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of\ndisease co-occurrence as a confounder that effects the results through backdoor\npath. Unfortunately, this confounder confuses the process of report generation\nworse because of the biased RRG data distribution. In this paper, to rethink\nthis issue thoroughly, we reason about its causes and effects from a novel\nperspective of statistics and causality, where the Joint Vision Coupling and\nthe Conditional Sentence Coherence Coupling are two aspects prone to implicitly\ndecrease the accuracy of reports. Then, a counterfactual augmentation strategy\nthat contains the Counterfactual Sample Synthesis and the Counterfactual Report\nReconstruction sub-methods is proposed to break these two aspects of spurious\neffects. Experimental results and further analyses on two widely used datasets\njustify our reasoning and proposed methods.",
                "authors": [
                    "Xiao Song",
                    "Jiafan Liu",
                    "Yun Li",
                    "Wenbin Lei",
                    "Ruxin Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13307v2",
                    "http://arxiv.org/pdf/2311.13307v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL",
                    "cs.MM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13305v1/1.0",
                "title": "A tale of many $H_0$",
                "year": 2023,
                "abstract": "The Hubble parameter $H_0$, is not a univocally-defined quantity: it relates\nredshifts to distances in the near Universe, but is also a key parameter of the\n$\\Lambda$CDM standard cosmological model. As such, $H_0$ affects several\nphysical processes at different cosmic epochs, and multiple observables. We\nhave counted more than a dozen $H_0$'s which are expected to agree if a) there\nare no significant systematics in the data and their interpretation and b) the\nadopted cosmological model is correct.\n  With few exceptions (proverbially confirming the rule) these determinations\ndo not agree at high statistical significance; their values cluster around two\ncamps: the low (68 km/s/Mpc) and high (73 km/s/Mpc) camp. It appears to be a\nmatter of anchors: the shape of the Universe expansion history agrees with the\nmodel, it is the normalizations that disagree.\n  Beyond systematics in the data/analysis, if the model is incorrect there are\nonly two viable ways to \"fix\" it: by changing the early time ($z\\gtrsim 1100$)\nphysics and thus the early time normalization, or by a global modification,\npossibly touching the model's fundamental assumptions (e.g., homogeneity,\nisotropy, gravity). None of these three options has the consensus of the\ncommunity.\n  The research community has been actively looking for deviations from\n$\\Lambda$CDM for two decades; the one we might have found makes us wish we\ncould put the genie back in the bottle.",
                "authors": [
                    "Licia Verde",
                    "Nils Sch\u00f6neberg",
                    "H\u00e9ctor Gil-Mar\u00edn"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13305v1",
                    "http://arxiv.org/pdf/2311.13305v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13301v1/1.0",
                "title": "Bistability dynamics in the dissipative Dicke-Bose-Hubbard system",
                "year": 2023,
                "abstract": "We consider a driven-dissipative system consisting of an atomic Bose-Einstein\ncondensates loaded into a two-dimensional Hubbard lattice and coupled to a\nsingle mode of an optical cavity. Due to the interplay between strong,\nrepulsive atomic interaction and the atom-cavity coupling, the system exhibits\nseveral phases of atoms and photons including the atomic superfluid (SF) and\nsupersolid (SS). We investigate the dynamical behaviour of the system, where we\ninclude dissipation by means of Lindblad master equation formalism. Due to the\ndiscontinuous nature of the Dicke transition for strong atomic repulsion, we\nfind extended co-existence region of different phases. We investigate the\nresulting switching dynamics, particularly between the coexisting SF and SS\nphases, which eventually becomes damped by the dissipation.",
                "authors": [
                    "Tianyi Wu",
                    "Sayak Ray",
                    "Johann Kroha"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13301v1",
                    "http://arxiv.org/pdf/2311.13301v1"
                ],
                "primary_category": "cond-mat.quant-gas",
                "categories": [
                    "cond-mat.quant-gas",
                    "cond-mat.stat-mech",
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13294v1/1.0",
                "title": "Probabilistic Inference in Reinforcement Learning Done Right",
                "year": 2023,
                "abstract": "A popular perspective in Reinforcement learning (RL) casts the problem as\nprobabilistic inference on a graphical model of the Markov decision process\n(MDP). The core object of study is the probability of each state-action pair\nbeing visited under the optimal policy. Previous approaches to approximate this\nquantity can be arbitrarily poor, leading to algorithms that do not implement\ngenuine statistical inference and consequently do not perform well in\nchallenging problems. In this work, we undertake a rigorous Bayesian treatment\nof the posterior probability of state-action optimality and clarify how it\nflows through the MDP. We first reveal that this quantity can indeed be used to\ngenerate a policy that explores efficiently, as measured by regret.\nUnfortunately, computing it is intractable, so we derive a new variational\nBayesian approximation yielding a tractable convex optimization problem and\nestablish that the resulting policy also explores efficiently. We call our\napproach VAPOR and show that it has strong connections to Thompson sampling,\nK-learning, and maximum entropy exploration. We conclude with some experiments\ndemonstrating the performance advantage of a deep RL version of VAPOR.",
                "authors": [
                    "Jean Tarbouriech",
                    "Tor Lattimore",
                    "Brendan O'Donoghue"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13294v1",
                    "http://arxiv.org/pdf/2311.13294v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13293v1/1.0",
                "title": "The Influence of Neural Networks on Hydropower Plant Management in\n  Agriculture: Addressing Challenges and Exploring Untapped Opportunities",
                "year": 2023,
                "abstract": "Hydropower plants are crucial for stable renewable energy and serve as vital\nwater sources for sustainable agriculture. However, it is essential to assess\nthe current water management practices associated with hydropower plant\nmanagement software. A key concern is the potential conflict between\nelectricity generation and agricultural water needs. Prioritising water for\nelectricity generation can reduce irrigation availability in agriculture during\ncrucial periods like droughts, impacting crop yields and regional food\nsecurity. Coordination between electricity and agricultural water allocation is\nnecessary to ensure optimal and environmentally sound practices. Neural\nnetworks have become valuable tools for hydropower plant management, but their\nblack-box nature raises concerns about transparency in decision making.\nAdditionally, current approaches often do not take advantage of their potential\nto create a system that effectively balances water allocation.\n  This work is a call for attention and highlights the potential risks of\ndeploying neural network-based hydropower plant management software without\nproper scrutiny and control. To address these concerns, we propose the adoption\nof the Agriculture Conscious Hydropower Plant Management framework, aiming to\nmaximise electricity production while prioritising stable irrigation for\nagriculture. We also advocate reevaluating government-imposed minimum water\nguidelines for irrigation to ensure flexibility and effective water allocation.\nAdditionally, we suggest a set of regulatory measures to promote model\ntransparency and robustness, certifying software that makes conscious and\nintelligent water allocation decisions, ultimately safeguarding agriculture\nfrom undue strain during droughts.",
                "authors": [
                    "C. Coelho",
                    "M. Fernanda P. Costa",
                    "L. L. Ferr\u00e1s"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13293v1",
                    "http://arxiv.org/pdf/2311.13293v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.OC",
                    "68T07",
                    "G.1.6; J.2; I.2.m"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13291v1/1.0",
                "title": "Robust Functional Regression with Discretely Sampled Predictors",
                "year": 2023,
                "abstract": "The functional linear model is an important extension of the classical\nregression model allowing for scalar responses to be modeled as functions of\nstochastic processes. Yet, despite the usefulness and popularity of the\nfunctional linear model in recent years, most treatments, theoretical and\npractical alike, suffer either from (i) lack of resistance towards the many\ntypes of anomalies one may encounter with functional data or (ii) biases\nresulting from the use of discretely sampled functional data instead of\ncompletely observed data. To address these deficiencies, this paper introduces\nand studies the first class of robust functional regression estimators for\npartially observed functional data. The proposed broad class of estimators is\nbased on thin-plate splines with a novel computationally efficient quadratic\npenalty, is easily implementable and enjoys good theoretical properties under\nweak assumptions. We show that, in the incomplete data setting, both the sample\nsize and discretization error of the processes determine the asymptotic rate of\nconvergence of functional regression estimators and the latter cannot be\nignored. These theoretical properties remain valid even with multi-dimensional\nrandom fields acting as predictors and random smoothing parameters. The\neffectiveness of the proposed class of estimators in practice is demonstrated\nby means of a simulation study and a real-data example.",
                "authors": [
                    "Ioannis Kalogridis",
                    "Stanislav Nagy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13291v1",
                    "http://arxiv.org/pdf/2311.13291v1"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME",
                    "math.ST",
                    "stat.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13290v1/1.0",
                "title": "Softmax Acceleration with Adaptive Numeric Format for both Training and\n  Inference",
                "year": 2023,
                "abstract": "The attention mechanism is a pivotal element within the Transformer\narchitecture, making a substantial contribution to its exceptional performance.\nWithin this attention mechanism, Softmax is an imperative component that\nenables the model to assess the degree of correlation between various segments\nof the input. Yet, prior research has shown that Softmax operations can\nsignificantly increase processing latency and energy consumption in the\nTransformer network due to their internal nonlinear operations and data\ndependencies. In this work, we proposed~\\textit{Hyft}, a hardware efficient\nfloating point Softmax accelerator for both training and inference. Hyft aims\nto reduce the implementation cost of different nonlinear arithmetic operations\nby adaptively converting intermediate results into the most suitable numeric\nformat for each specific operation, leading to reconfigurable accelerator with\nhybrid numeric format. The evaluation results highlight that Hyft achieves a\nremarkable $15\\times$ reduction in hardware resource utilization and a $20\n\\times$ reduction in processing latency, all while maintaining a negligible\nimpact on Transformer accuracy.",
                "authors": [
                    "Tianhua Xia",
                    "Sai Qian Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13290v1",
                    "http://arxiv.org/pdf/2311.13290v1"
                ],
                "primary_category": "cs.AR",
                "categories": [
                    "cs.AR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13289v1/1.0",
                "title": "(Almost isometric) local retracts in metric spaces",
                "year": 2023,
                "abstract": "We introduce the notion of (almost isometric) local retracts in metric space\nas a natural non-linear version of the concepts of locally complemented and\nalmost isometric ideals from Banach spaces. We prove that given two metric\nspaces $N\\subseteq M$ there always exists an almost isometric local retract\n$S\\subseteq M$ with $N\\subseteq S$ and $dens(N)=dens(S)$. We also prove that\nmetric spaces which are local retracts (respectively almost isometric local\nretracts) can be characterised in terms of a condition of extendability of\nLipschitz functions (respectively almost isometries) between finite metric\nspaces. Different examples and counterexamples are exhibited.",
                "authors": [
                    "Andr\u00e9s Quilis",
                    "Abraham Rueda Zoca"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13289v1",
                    "http://arxiv.org/pdf/2311.13289v1"
                ],
                "primary_category": "math.FA",
                "categories": [
                    "math.FA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13285v1/1.0",
                "title": "Improving performance of heart rate time series classification by\n  grouping subjects",
                "year": 2023,
                "abstract": "Unlike the more commonly analyzed ECG or PPG data for activity\nclassification, heart rate time series data is less detailed, often noisier and\ncan contain missing data points. Using the BigIdeasLab_STEP dataset, which\nincludes heart rate time series annotated with specific tasks performed by\nindividuals, we sought to determine if general classification was achievable.\nOur analyses showed that the accuracy is sensitive to the choice of\nwindow/stride size. Moreover, we found variable classification performances\nbetween subjects due to differences in the physical structure of their hearts.\nVarious techniques were used to minimize this variability. First of all,\nnormalization proved to be a crucial step and significantly improved the\nperformance. Secondly, grouping subjects and performing classification inside a\ngroup helped to improve performance and decrease inter-subject variability.\nFinally, we show that including handcrafted features as input to a deep\nlearning (DL) network improves the classification performance further.\nTogether, these findings indicate that heart rate time series can be utilized\nfor classification tasks like predicting activity. However, normalization or\ngrouping techniques need to be chosen carefully to minimize the issue of\nsubject variability.",
                "authors": [
                    "Michael Beekhuizen",
                    "Arman Naseri",
                    "David Tax",
                    "Ivo van der Bilt",
                    "Marcel Reinders"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13285v1",
                    "http://arxiv.org/pdf/2311.13285v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13282v1/1.0",
                "title": "Modulation For Modulo: A Sampling-Efficient High-Dynamic Range ADC",
                "year": 2023,
                "abstract": "In high-dynamic range (HDR) analog-to-digital converters (ADCs), having many\nquantization bits minimizes quantization errors but results in high bit rates,\nlimiting their application scope. A strategy combining modulo-folding with a\nlow-DR ADC can create an efficient HDR-ADC with fewer bits. However, this\ntypically demands oversampling, increasing the overall bit rate. An alternative\nmethod using phase modulation (PM) achieves HDR-ADC functionality by modulating\nthe phase of a carrier signal with the analog input. This allows a low-DR ADC\nwith fewer bits. We've derived identifiability results enabling reconstruction\nof the original signal from PM samples acquired at the Nyquist rate, adaptable\nto various signals and non-uniform sampling. Using discrete phase demodulation\nalgorithms for practical implementation, our PM-based approach doesn't require\noversampling in noise-free conditions, contrasting with modulo-based ADCs. With\nnoise, our PM-based HDR method demonstrates efficiency with lower\nreconstruction errors and reduced sampling rates. Our hardware prototype\nillustrates reconstructing signals ten times greater than the ADC's DR from\nNyquist rate samples, potentially replacing high-bit rate HDR-ADCs while\nmeeting existing bit rate needs.",
                "authors": [
                    "Satish Mulleti",
                    "Resham Yashwanth Kumar",
                    "Laxmeesha Somappa"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13282v1",
                    "http://arxiv.org/pdf/2311.13282v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13281v1/1.0",
                "title": "Intention and Context Elicitation with Large Language Models in the\n  Legal Aid Intake Process",
                "year": 2023,
                "abstract": "Large Language Models (LLMs) and chatbots show significant promise in\nstreamlining the legal intake process. This advancement can greatly reduce the\nworkload and costs for legal aid organizations, improving availability while\nmaking legal assistance more accessible to a broader audience. However, a key\nchallenge with current LLMs is their tendency to overconfidently deliver an\nimmediate 'best guess' to a client's question based on the output distribution\nlearned over the training data. This approach often overlooks the client's\nactual intentions or the specifics of their legal situation. As a result,\nclients may not realize the importance of providing essential additional\ncontext or expressing their underlying intentions, which are crucial for their\nlegal cases. Traditionally, logic based decision trees have been used to\nautomate intake for specific access to justice issues, such as immigration and\neviction. But those solutions lack scalability. We demonstrate a\nproof-of-concept using LLMs to elicit and infer clients' underlying intentions\nand specific legal circumstances through free-form, language-based\ninteractions. We also propose future research directions to use supervised\nfine-tuning or offline reinforcement learning to automatically incorporate\nintention and context elicitation in chatbots without explicit prompting.",
                "authors": [
                    "Nick Goodson",
                    "Rongfei Lu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13281v1",
                    "http://arxiv.org/pdf/2311.13281v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13277v1/1.0",
                "title": "Hierarchical Matrix Factorization for Interpretable Collaborative\n  Filtering",
                "year": 2023,
                "abstract": "Matrix factorization (MF) is a simple collaborative filtering technique that\nachieves superior recommendation accuracy by decomposing the user-item rating\nmatrix into user and item latent matrices. This approach relies on learning\nfrom user-item interactions, which may not effectively capture the underlying\nshared dependencies between users or items. Therefore, there is scope to\nexplicitly capture shared dependencies to further improve recommendation\naccuracy and the interpretability of learning results by summarizing user-item\ninteractions. Based on these insights, we propose \"Hierarchical Matrix\nFactorization\" (HMF), which incorporates clustering concepts to capture the\nhierarchy, where leaf nodes and other nodes correspond to users/items and\nclusters, respectively. Central to our approach, called hierarchical\nembeddings, is the additional decomposition of the user and item latent\nmatrices (embeddings) into probabilistic connection matrices, which link the\nhierarchy, and a root cluster latent matrix. Thus, each node is represented by\nthe weighted average of the embeddings of its parent clusters. The embeddings\nare differentiable, allowing simultaneous learning of interactions and\nclustering using a single gradient descent method. Furthermore, the obtained\ncluster-specific interactions naturally summarize user-item interactions and\nprovide interpretability. Experimental results on rating and ranking\npredictions demonstrated the competitiveness of HMF over vanilla and\nhierarchical MF methods, especially its robustness in sparse interactions.\nAdditionally, it was confirmed that the clustering integration of HMF has the\npotential for faster learning convergence and mitigation of overfitting\ncompared to MF, and also provides interpretability through a cluster-centered\ncase study.",
                "authors": [
                    "Kai Sugahara",
                    "Kazushi Okamoto"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13277v1",
                    "http://arxiv.org/pdf/2311.13277v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13275v1/1.0",
                "title": "Exoplanets detection limits using spectral cross-correlation with\n  spectro-imaging. An analytical model applied to the case of ELT-HARMONI",
                "year": 2023,
                "abstract": "The combination of high-contrast imaging and medium to high spectral\nresolution spectroscopy offers new possibilities for the detection and\ncharacterization of exoplanets. The molecular mapping technique uses the\ndifference between the planetary and stellar spectra. While traditional\npost-processing techniques are quickly limited by speckle noise at short\nangular separation, it efficiently suppresses speckles. Its performance depends\non multiple parameters such as the star magnitude, the adaptive optics residual\nhalo, the companion spectrum, the telluric absorption, as well as the telescope\nand instrument properties. Exploring this parameter space through end-to-end\nsimulations to predict potential science cases and to optimize future\ninstrument designs is very time-consuming, making it difficult to draw\nconclusions. We propose to define an efficient methodology for such an\nanalysis. Explicit expressions of the estimates of signal and noise are\nderived, and they are validated through comparisons with end-to-end\nsimulations. They provide an understanding of the instrumental dependencies,\nand help to discuss optimal instrumental choices with regard to the targets of\ninterest. They are applied in the case of ELT/HARMONI, as a tool to predict the\ncontrast performance in various observational cases. We confirm the potential\nof molecular mapping for high-contrast detections, especially for cool planets\nat short separations. We provide guidelines based on quantified estimates for\ndesign trade-offs of future instruments. We discuss the planet detection\nperformances of HARMONI observing modes. While they nicely cover the\nappropriate requirements for high detection capability of warm exoplanets, a\ntransmission extended down to J band would be beneficial. A contrast of a few\n1E-7 at 50mas should be within reach on bright targets in photon noise regime\nwith molecular mapping.",
                "authors": [
                    "Alexis Bidot",
                    "David Mouillet",
                    "Alexis Carlotti"
                ],
                "url": [
                    "http://dx.doi.org/10.1051/0004-6361/202346185",
                    "http://arxiv.org/abs/2311.13275v1",
                    "http://arxiv.org/pdf/2311.13275v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13274v1/1.0",
                "title": "Enhancing Summarization Performance through Transformer-Based Prompt\n  Engineering in Automated Medical Reporting",
                "year": 2023,
                "abstract": "Customized medical prompts enable Large Language Models (LLM) to effectively\naddress medical dialogue summarization. The process of medical reporting is\noften time-consuming for healthcare professionals. Implementing medical\ndialogue summarization techniques presents a viable solution to alleviate this\ntime constraint by generating automated medical reports. The effectiveness of\nLLMs in this process is significantly influenced by the formulation of the\nprompt, which plays a crucial role in determining the quality and relevance of\nthe generated reports. In this research, we used a combination of two distinct\nprompting strategies, known as shot prompting and pattern prompting to enhance\nthe performance of automated medical reporting. The evaluation of the automated\nmedical reports is carried out using the ROUGE score and a human evaluation\nwith the help of an expert panel. The two-shot prompting approach in\ncombination with scope and domain context outperforms other methods and\nachieves the highest score when compared to the human reference set by a\ngeneral practitioner. However, the automated reports are approximately twice as\nlong as the human references, due to the addition of both redundant and\nrelevant statements that are added to the report.",
                "authors": [
                    "Daphne van Zandvoort",
                    "Laura Wiersema",
                    "Tom Huibers",
                    "Sandra van Dulmen",
                    "Sjaak Brinkkemper"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13274v1",
                    "http://arxiv.org/pdf/2311.13274v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13273v1/1.0",
                "title": "Comparative Experimentation of Accuracy Metrics in Automated Medical\n  Reporting: The Case of Otitis Consultations",
                "year": 2023,
                "abstract": "Generative Artificial Intelligence (AI) can be used to automatically generate\nmedical reports based on transcripts of medical consultations. The aim is to\nreduce the administrative burden that healthcare professionals face. The\naccuracy of the generated reports needs to be established to ensure their\ncorrectness and usefulness. There are several metrics for measuring the\naccuracy of AI generated reports, but little work has been done towards the\napplication of these metrics in medical reporting. A comparative\nexperimentation of 10 accuracy metrics has been performed on AI generated\nmedical reports against their corresponding General Practitioner's (GP) medical\nreports concerning Otitis consultations. The number of missing, incorrect, and\nadditional statements of the generated reports have been correlated with the\nmetric scores. In addition, we introduce and define a Composite Accuracy Score\nwhich produces a single score for comparing the metrics within the field of\nautomated medical reporting. Findings show that based on the correlation study\nand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics\nare the preferred metrics, which is not in line with previous work. These\nfindings help determine the accuracy of an AI generated medical report, which\naids the development of systems that generate medical reports for GPs to reduce\nthe administrative burden.",
                "authors": [
                    "Wouter Faber",
                    "Renske Eline Bootsma",
                    "Tom Huibers",
                    "Sandra van Dulmen",
                    "Sjaak Brinkkemper"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13273v1",
                    "http://arxiv.org/pdf/2311.13273v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13261v1/1.0",
                "title": "Immunohistochemistry guided segmentation of benign epithelial cells, in\n  situ lesions, and invasive epithelial cells in breast cancer slides",
                "year": 2023,
                "abstract": "Digital pathology enables automatic analysis of histopathological sections\nusing artificial intelligence (AI). Automatic evaluation could improve\ndiagnostic efficiency and help find associations between morphological features\nand clinical outcome. For development of such prediction models, identifying\ninvasive epithelial cells, and separating these from benign epithelial cells\nand in situ lesions would be the first step. In this study, we aimed to develop\nan AI model for segmentation of epithelial cells in sections from breast\ncancer. We generated epithelial ground truth masks by restaining hematoxylin\nand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'\nannotations. HE/CK image pairs were used to train a convolutional neural\nnetwork, and data augmentation was used to make the model more robust. Tissue\nmicroarrays (TMAs) from 839 patients, and whole slide images from two patients\nwere used for training and evaluation of the models. The sections were derived\nfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifth\ncohort was used as a second test set. In quantitative evaluation, a mean Dice\nscore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial\ncells, and in situ lesions, respectively, were achieved. In qualitative scoring\n(0-5) by pathologists, results were best for all epithelium and invasive\nepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in\nsitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in\nHE stained breast cancer slides well, but further work is needed for accurate\ndivision between the classes. Immunohistochemistry, together with pathologists'\nannotations, enabled the creation of accurate ground truths. The model is made\nfreely available in FastPathology and the code is available at\nhttps://github.com/AICAN-Research/breast-epithelium-segmentation",
                "authors": [
                    "Maren H\u00f8ib\u00f8",
                    "Andr\u00e9 Pedersen",
                    "Vibeke Grotnes Dale",
                    "Sissel Marie Berget",
                    "Borgny Ytterhus",
                    "Cecilia Lindskog",
                    "Elisabeth Wik",
                    "Lars A. Akslen",
                    "Ingerid Reinertsen",
                    "Erik Smistad",
                    "Marit Valla"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13261v1",
                    "http://arxiv.org/pdf/2311.13261v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG",
                    "I.4.6",
                    "I.4.6; I.4.9; I.5.4; J.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13258v1/1.0",
                "title": "ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation",
                "year": 2023,
                "abstract": "State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.",
                "authors": [
                    "Yangyi Chen",
                    "Xingyao Wang",
                    "Manling Li",
                    "Derek Hoiem",
                    "Heng Ji"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13258v1",
                    "http://arxiv.org/pdf/2311.13258v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13254v1/1.0",
                "title": "DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal\n  Consistency",
                "year": 2023,
                "abstract": "Video semantic segmentation is a pivotal aspect of video representation\nlearning. However, significant domain shifts present a challenge in effectively\nlearning invariant spatio-temporal features across the labeled source domain\nand unlabeled target domain for video semantic segmentation. To solve the\nchallenge, we propose a novel DA-STC method for domain adaptive video semantic\nsegmentation, which incorporates a bidirectional multi-level spatio-temporal\nfusion module and a category-aware spatio-temporal feature alignment module to\nfacilitate consistent learning for domain-invariant features. Firstly, we\nperform bidirectional spatio-temporal fusion at the image sequence level and\nshallow feature level, leading to the construction of two fused intermediate\nvideo domains. This prompts the video semantic segmentation model to\nconsistently learn spatio-temporal features of shared patch sequences which are\ninfluenced by domain-specific contexts, thereby mitigating the feature gap\nbetween the source and target domain. Secondly, we propose a category-aware\nfeature alignment module to promote the consistency of spatio-temporal\nfeatures, facilitating adaptation to the target domain. Specifically, we\nadaptively aggregate the domain-specific deep features of each category along\nspatio-temporal dimensions, which are further constrained to achieve\ncross-domain intra-class feature alignment and inter-class feature separation.\nExtensive experiments demonstrate the effectiveness of our method, which\nachieves state-of-the-art mIOUs on multiple challenging benchmarks.\nFurthermore, we extend the proposed DA-STC to the image domain, where it also\nexhibits superior performance for domain adaptive semantic segmentation. The\nsource code and models will be made available at\n\\url{https://github.com/ZHE-SAPI/DA-STC}.",
                "authors": [
                    "Zhe Zhang",
                    "Gaochang Wu",
                    "Jing Zhang",
                    "Chunhua Shen",
                    "Dacheng Tao",
                    "Tianyou Chai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13254v1",
                    "http://arxiv.org/pdf/2311.13254v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13253v1/1.0",
                "title": "Kardar-Parisi-Zhang fluctuations in the synchronization dynamics of\n  limit-cycle oscillators",
                "year": 2023,
                "abstract": "The space-time process whereby one-dimensional systems of self-sustained\noscillators synchronize is shown to display generic scale invariance, with\nscaling properties characteristic of the Kardar-Parisi-Zhang equation with\ncolumnar noise, and phase fluctuations that follow a Tracy-Widom probability\ndistribution. This is revealed by a numerical exploration of rings of\nStuart-Landau oscillators (the universal representation of an oscillating\nsystem close to a Hopf bifurcation) and rings of van der Pol oscillators, both\nof which are paradigms of self-sustained oscillators. The critical behavior is\nvery well-defined for limit-cycle oscillations near the bifurcation point, and\nstill dominates the behavior comparatively far from the bifurcation. In\nparticular, the Tracy-Widom fluctuation distribution seems to be an extremely\nrobust feature of the synchronization process. The nonequilibrium criticality\nhere described appears to transcend the details of the coupled dynamical\nsystems that synchronize, making plausible its experimental observation.",
                "authors": [
                    "Ricardo Guti\u00e9rrez",
                    "Rodolfo Cuerno"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13253v1",
                    "http://arxiv.org/pdf/2311.13253v1"
                ],
                "primary_category": "cond-mat.stat-mech",
                "categories": [
                    "cond-mat.stat-mech",
                    "cond-mat.dis-nn",
                    "nlin.AO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13251v1/1.0",
                "title": "The Tully-Fisher relation from SDSS-MaNGA: Physical causes of scatter\n  and variation at different radii",
                "year": 2023,
                "abstract": "The stellar mass Tully-Fisher relation (STFR) and its scatter encode valuable\ninformation about the processes shaping galaxy evolution across cosmic time.\nHowever, we are still missing a proper quantification of the STFR slope and\nscatter dependence on the baryonic tracer used to quantify rotational velocity,\non the velocity measurement radius and on galaxy integrated properties. We\npresent a catalogue of stellar and ionised gas (traced by H$\\alpha$ emission)\nkinematic measurements for a sample of galaxies drawn from the MaNGA Galaxy\nSurvey, providing an ideal tool for galaxy formation model calibration and for\ncomparison with high-redshift studies. We compute the STFRs for stellar and gas\nrotation at 1, 1.3 and 2 effective radii ($R_e$). The relations for both\nbaryonic components become shallower at 2$R_e$ compared to 1$R_e$ and 1.3$R_e$.\nWe report a steeper STFR for the stars in the inner parts ($\\leq 1.3 R_e$)\ncompared to the gas. At 2$R_e$, the relations for the two components are\nconsistent. When accounting for covariances with integrated v/$\\sigma$, scatter\nin the stellar and gas STFRs shows no strong correlation with: optical\nmorphology, star formation rate surface density, tidal interaction strength or\ngas accretion signatures. Our results suggest that the STFR scatter is driven\nby an increase in stellar/gas dispersional support, from either external\n(mergers) or internal (feedback) processes. No correlation between STFR scatter\nand environment is found. Nearby Universe galaxies have their stars and gas in\nstatistically different states of dynamical equilibrium in the inner parts\n($\\leq 1.3 R_e$), while at 2$R_{e}$ the two components are dynamically coupled.",
                "authors": [
                    "Andrei Ristea",
                    "Luca Cortese",
                    "Amelia Fraser-McKelvie",
                    "Barbara Catinella",
                    "Jesse van de Sande",
                    "Scott M. Croom",
                    "Mark Swinbank"
                ],
                "url": [
                    "http://dx.doi.org/10.1093/mnras/stad3638",
                    "http://arxiv.org/abs/2311.13251v1",
                    "http://arxiv.org/pdf/2311.13251v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13249v1/1.0",
                "title": "The Journey to Serverless Migration: An Empirical Analysis of\n  Intentions, Strategies, and Challenges",
                "year": 2023,
                "abstract": "Serverless is an emerging cloud computing paradigm that facilitates\ndevelopers to focus solely on the application logic rather than provisioning\nand managing the underlying infrastructure. The inherent characteristics such\nas scalability, flexibility, and cost efficiency of serverless computing,\nattracted many companies to migrate their legacy applications toward this\nparadigm. However, the stateless nature of serverless requires careful\nmigration planning, consideration of its subsequent implications, and potential\nchallenges. To this end, this study investigates the intentions, strategies,\nand technical and organizational challenges while migrating to a serverless\narchitecture. We investigated the migration processes of 11 systems across\ndiverse domains by conducting 15 in-depth interviews with professionals from 11\norganizations. we also presented a detailed discussion of each migration case.\nOur findings reveal that large enterprises primarily migrate to enhance\nscalability and operational efficiency, while smaller organizations intend to\nreduce the cost. Furthermore, organizations use a domain-driven design approach\nto identify the use case and gradually migrate to serverless using a strangler\npattern. However, migration encounters technical challenges i.e., testing\nevent-driven architecture, integrating with the legacy system, lack of\nstandardization, and organizational challenges i.e., mindset change and hiring\nskilled serverless developers as a prominent. The findings of this study\nprovide a comprehensive understanding that can guide future implementations and\nadvancements in the context of serverless migration.",
                "authors": [
                    "Muhammad Hamza",
                    "Muhammad Azeem Akbar",
                    "Kari Smolander"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13249v1",
                    "http://arxiv.org/pdf/2311.13249v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13248v1/1.0",
                "title": "Microstructured organic cavities with high-reflective flat reflectors\n  fabricated by using a nanoimprint-bonding process",
                "year": 2023,
                "abstract": "The integration of photonic microstructure into organic microcavities\nrepresents an effective strategy for manipulating eigenstates of cavity or\npolariton modes. However, well-established fabrication processes for\nmicrostructured organic microcavities are still lacking. In this study, we\npropose a nanoimprint-bonding process as a novel fabrication method for\nmicrostructured organic microcavities. This process relies on a UV nanoimprint\ntechnique utilizing two different photopolymer resins, enabling the independent\nfabrication of highly reflective reflectors and photonic microstructures\nwithout compromising the accuracy of each. The resulting organic microcavities\ndemonstrate spatially localized photonic modes within dot structures and their\nnonlinear responses on the pumping fluence. Furthermore, a highly precise\nphotonic band is confirmed within a honeycomb lattice structure, which is owing\nto the high quality factor of the cavity achievable with the\nnanoimprint-bonding process. Additionally, a topological edge state is also\nobservable within a zigzag lattice structure. These results highlight the\nsignificant potential of our fabrication method for advancing organic-based\nphotonic devices, including lasers and polariton devices.",
                "authors": [
                    "Takuya Enna",
                    "Yuji Adachi",
                    "Tsukasa Hirao",
                    "Shun Takahashi",
                    "Yohei Yamamoto",
                    "Kenichi Yamashita"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13248v1",
                    "http://arxiv.org/pdf/2311.13248v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14741v1/1.0",
                "title": "@ve: A Chatbot for Latin",
                "year": 2023,
                "abstract": "Dead, extinct, and endangered languages have been preserved primarily through\naudio conservation and the collection and digitization of scripts and have been\npromoted through targeted language acquisition efforts. Another possibility\nwould be to build conversational agents that can master these languages. This\nwould provide an artificial, active conversational partner which has knowledge\nof the vocabulary and grammar, and one learns with it in a different way. The\nchatbot @ve, with which one can communicate in Latin, was developed in\n2022/2023 based on GPT-3.0. It was additionally equipped with a manually\ncreated knowledge base. After conceptual groundwork, this paper presents the\npreparation and implementation of the project. In addition, it summarizes the\ntest that a Latin expert conducted with the chatbot. A critical discussion\nelaborates advantages and disadvantages. @ve could be a new tool for teaching\nLatin in a memorable and entertaining way through dialogue. However, the\npresent implementation is still too prone to glitches for stand-alone use -\ni.e., without the accompaniment of a teacher. The use of GPT-4 could be a\nsolution as well as the extension of the knowledge base. In conclusion, it can\nbe argued that conversational agents are an innovative approach to promoting\nand preserving languages.",
                "authors": [
                    "Oliver Bendel",
                    "Karim N'diaye"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14741v1",
                    "http://arxiv.org/pdf/2311.14741v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.RO",
                    "I.2; K.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13246v1/1.0",
                "title": "Automatic Instruction Optimization for Open-source LLM Instruction\n  Tuning",
                "year": 2023,
                "abstract": "Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative in\nthe training of open-source LLMs. To ensure the high quality of LLM-generated\ninstruction datasets, several approaches have been proposed. Nevertheless,\nexisting methods either compromise dataset integrity by filtering a large\nproportion of samples, or are unsuitable for industrial applications. In this\npaper, instead of discarding low-quality samples, we propose CoachLM, a novel\napproach to enhance the quality of instruction datasets through automatic\nrevisions on samples in the dataset. CoachLM is trained from the samples\nrevised by human experts and significantly increases the proportion of\nhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of\nCoachLM is further assessed on various real-world instruction test sets. The\nresults show that CoachLM improves the instruction-following capabilities of\nthe instruction-tuned LLM by an average of 29.9%, which even surpasses larger\nLLMs with nearly twice the number of parameters. Furthermore, CoachLM is\nsuccessfully deployed in a data management system for LLMs at Huawei, resulting\nin an efficiency improvement of up to 20% in the cleaning of 40k real-world\ninstruction pairs. We release the training data and code of CoachLM\n(https://github.com/lunyiliu/CoachLM).",
                "authors": [
                    "Yilun Liu",
                    "Shimin Tao",
                    "Xiaofeng Zhao",
                    "Ming Zhu",
                    "Wenbing Ma",
                    "Junhao Zhu",
                    "Chang Su",
                    "Yutai Hou",
                    "Miao Zhang",
                    "Min Zhang",
                    "Hongxia Ma",
                    "Li Zhang",
                    "Hao Yang",
                    "Yanfei Jiang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13246v1",
                    "http://arxiv.org/pdf/2311.13246v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13245v1/1.0",
                "title": "A model-free approach to fingertip slip and disturbance detection for\n  grasp stability inference",
                "year": 2023,
                "abstract": "Robotic capacities in object manipulation are incomparable to those of\nhumans. Besides years of learning, humans rely heavily on the richness of\ninformation from physical interaction with the environment. In particular,\ntactile sensing is crucial in providing such rich feedback. Despite its\npotential contributions to robotic manipulation, tactile sensing is less\nexploited; mainly due to the complexity of the time series provided by tactile\nsensors. In this work, we propose a method for assessing grasp stability using\ntactile sensing. More specifically, we propose a methodology to extract\ntask-relevant features and design efficient classifiers to detect object\nslippage with respect to individual fingertips. We compare two classification\nmodels: support vector machine and logistic regression. We use highly sensitive\nUskin tactile sensors mounted on an Allegro hand to test and validate our\nmethod. Our results demonstrate that the proposed method is effective in\nslippage detection in an online fashion.",
                "authors": [
                    "Dounia Kitouni",
                    "Mahdi Khoramshahi",
                    "Veronique Perdereau"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13245v1",
                    "http://arxiv.org/pdf/2311.13245v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "eess.SP",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13244v1/1.0",
                "title": "Hard Label Black Box Node Injection Attack on Graph Neural Networks",
                "year": 2023,
                "abstract": "While graph neural networks have achieved state-of-the-art performances in\nmany real-world tasks including graph classification and node classification,\nrecent works have demonstrated they are also extremely vulnerable to\nadversarial attacks. Most previous works have focused on attacking node\nclassification networks under impractical white-box scenarios. In this work, we\nwill propose a non-targeted Hard Label Black Box Node Injection Attack on Graph\nNeural Networks, which to the best of our knowledge, is the first of its kind.\nUnder this setting, more real world tasks can be studied because our attack\nassumes no prior knowledge about (1): the model architecture of the GNN we are\nattacking; (2): the model's gradients; (3): the output logits of the target GNN\nmodel. Our attack is based on an existing edge perturbation attack, from which\nwe restrict the optimization process to formulate a node injection attack. In\nthe work, we will evaluate the performance of the attack using three datasets,\nCOIL-DEL, IMDB-BINARY, and NCI1.",
                "authors": [
                    "Yu Zhou",
                    "Zihao Dong",
                    "Guofeng Zhang",
                    "Jingchen Tang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13244v1",
                    "http://arxiv.org/pdf/2311.13244v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CR",
                    "cs.SI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14740v1/1.0",
                "title": "AutoKG: Efficient Automated Knowledge Graph Generation for Language\n  Models",
                "year": 2023,
                "abstract": "Traditional methods of linking large language models (LLMs) to knowledge\nbases via the semantic similarity search often fall short of capturing complex\nrelational dynamics. To address these limitations, we introduce AutoKG, a\nlightweight and efficient approach for automated knowledge graph (KG)\nconstruction. For a given knowledge base consisting of text blocks, AutoKG\nfirst extracts keywords using a LLM and then evaluates the relationship weight\nbetween each pair of keywords using graph Laplace learning. We employ a hybrid\nsearch scheme combining vector similarity and graph-based associations to\nenrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a\nmore comprehensive and interconnected knowledge retrieval mechanism compared to\nthe semantic similarity search, thereby enhancing the capabilities of LLMs in\ngenerating more insightful and relevant outputs.",
                "authors": [
                    "Bohan Chen",
                    "Andrea L. Bertozzi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14740v1",
                    "http://arxiv.org/pdf/2311.14740v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13240v1/1.0",
                "title": "On the Calibration of Large Language Models and Alignment",
                "year": 2023,
                "abstract": "As large language models attract increasing attention and find widespread\napplication, concurrent challenges of reliability also arise at the same time.\nConfidence calibration, an effective analysis method for gauging the\nreliability of deep models, serves as a crucial tool for assessing and\nimproving their reliability. However, such investigation has been comparatively\nunderexplored. In this work, we conduct a systematic examination of the\ncalibration of aligned language models throughout the entire construction\nprocess, including pretraining and alignment training. At each stage, we\ninvestigate how different training settings, such as parameter scales and\ntraining data, affect model calibration. To thoroughly assess model\ncalibration, we evaluate models on three most concerned aspects: generation,\nfactuality and understanding. Our work sheds light on whether popular LLMs are\nwell-calibrated and how the training process influences model calibration.",
                "authors": [
                    "Chiwei Zhu",
                    "Benfeng Xu",
                    "Quan Wang",
                    "Yongdong Zhang",
                    "Zhendong Mao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13240v1",
                    "http://arxiv.org/pdf/2311.13240v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13239v1/1.0",
                "title": "Study of the Cygnus X-3 Microquasar with the RATAN-600 Radio telescope\n  in Multi-Azimuth Observing Mode",
                "year": 2023,
                "abstract": "We have been performing daily observations of bright microquasars at\n1.2-20~GHz with the Northern sector of RATAN-600 radio telescope for more than\nten years. During the 2019--2021 observations we recorded bright flares, which\nwe call giant flares because fluxes reach record levels -- above 20~Jy --\nduring these events. In this paper we report the results of intraday variations\nof the Cygnus~X-3} microquasar in multi-azimuth observations made with the\n\"North sector with a flat-sheet reflector\" during giant flares of Cygnus X-3.\nThese were the first such observations made simultaneously at several\nfrequencies on a short time scale (10 minutes). Observational data consists of\n31 measurement made within +/-2.7 hours of the culmination of the object. We\nare the first to discover the evolution of the spectrum of the flare emission\nof Cygnus~X-3 on a time scale comparable to the orbital period of the binary.\nThe measurement data allowed us to determine the temporal and spectral\nparameters of radio emission, which are typical for synchrotron flare emission\nin relativistic jets. Evolution of the radio emission of X-ray binaries on\nshort time scales is a key to understanding the formation of jet outbursts in\nthe process of mass accretion of the matter of the donor star onto the\nrelativistic object.",
                "authors": [
                    "S. A. Trushkin",
                    "A. V. Shevchenko",
                    "N. N. Bursov",
                    "P. G. Tsybulev",
                    "N. A. Nizhel'skii",
                    "A. N. Borisov",
                    "A. A. Kudryashova"
                ],
                "url": [
                    "http://dx.doi.org/10.1134/S1990341323020116",
                    "http://arxiv.org/abs/2311.13239v1",
                    "http://arxiv.org/pdf/2311.13239v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13238v1/1.0",
                "title": "Hegselmann-Krause and Cucker-Smale type models with attractive-repulsive\n  interaction",
                "year": 2023,
                "abstract": "In this paper, we analyze a Hegselmann-Krause opinion formation model and a\nCucker-Smale flocking model with attractive-repulsive interaction. To be\nprecise, we investigate the situation in which the individuals involved in an\nopinion formation or a flocking process attract each other in certain time\nintervals and repeal each other in other ones. Under quite general assumptions,\nwe prove the convergence to consensus for the Hegselmann-Krause model and the\nexhibition of asymptotic flocking for the Cucker-Smale model in presence of\npositive-negative interaction. With some additional conditions, we are able to\nimprove the convergence to consensus for the solutions of the Hegselmann-Krause\nmodel, namely we establish an exponential convergence to consensus result.",
                "authors": [
                    "Elisa Continelli",
                    "Cristina Pignotti"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13238v1",
                    "http://arxiv.org/pdf/2311.13238v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13236v1/1.0",
                "title": "Stability of nanoparticle laden aerosol liquid droplets",
                "year": 2023,
                "abstract": "We develop a model for the thermodynamics and evaporation dynamics of aerosol\ndroplets of a liquid such as water, surrounded by the gas. When the temperature\nand the chemical potential (or equivalently the humidity) are such that the\nvapour phase is the thermodynamic equilibrium state, then of course droplets of\nthe pure liquid evaporate over a relatively short time. However, if the\ndroplets also contain nanoparticles or any other non-volatile solute, then the\ndroplets can become thermodynamically stable. We show that the equilibrium\ndroplet size depends strongly on the amount and solubility of the nanoparticles\nwithin, i.e. on the nature of the particle interactions with the liquid, and of\ncourse also on the vapour temperature and chemical potential. We develop a\nsimple thermodynamic model for such droplets and compare predictions with\nresults from a lattice density functional theory that takes as input the same\nparticle interaction properties, finding very good agreement. We also use\ndynamical density functional theory to study the evaporation/condensation\ndynamics of liquid from/to droplets as they equilibrate with the vapour,\nthereby demonstrating droplet stability.",
                "authors": [
                    "A. J. Archer",
                    "B. D. Goddard",
                    "R. Roth"
                ],
                "url": [
                    "http://dx.doi.org/10.1063/5.0172137",
                    "http://arxiv.org/abs/2311.13236v1",
                    "http://arxiv.org/pdf/2311.13236v1"
                ],
                "primary_category": "cond-mat.soft",
                "categories": [
                    "cond-mat.soft",
                    "cond-mat.stat-mech",
                    "physics.chem-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13235v1/1.0",
                "title": "Strong Light-Matter Coupling Facilitated Charge Carrier Transport in\n  Cavity Organic Solar Cells",
                "year": 2023,
                "abstract": "Strong light-matter coupling has shown great potential for modifying the\nelectro-optical properties of semiconducting materials in recent years. In the\nstrong coupling regime, excitons and cavity photons form new states named\nexciton-polaritons, with their properties a hybrid of each constituent. Herein,\nwe report strong coupling observed in solution-processed donor:acceptor\nbulk-heterojunction organic solar cells (OSCs) evidenced by the observed Rabi\nsplitting of ~300 meV and the effects of strong coupling on OSC operations.\nCombining the transient photovoltage decay measurement and nanosecond transient\nabsorption spectroscopy, our results reveal that the effective charge carrier\nlifetimes are longer in cavity devices, attributed to the reduced bimolecular\nrecombination. It is also found that access to CT state(s) of higher energy is\nenabled in cavity devices. This study demonstrates that strong coupling can\neffectively modify the device- and photo-physics in OSCs and opens a new\npathway for engineering more efficient OSCs.",
                "authors": [
                    "Yahui Tang",
                    "Alexandra Stuart",
                    "Timothy van der Laan",
                    "Girish Lakhwani"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13235v1",
                    "http://arxiv.org/pdf/2311.13235v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph",
                    "physics.chem-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13622v1/1.0",
                "title": "TDiffDe: A Truncated Diffusion Model for Remote Sensing Hyperspectral\n  Image Denoising",
                "year": 2023,
                "abstract": "Hyperspectral images play a crucial role in precision agriculture,\nenvironmental monitoring or ecological analysis. However, due to sensor\nequipment and the imaging environment, the observed hyperspectral images are\noften inevitably corrupted by various noise. In this study, we proposed a\ntruncated diffusion model, called TDiffDe, to recover the useful information in\nhyperspectral images gradually. Rather than starting from a pure noise, the\ninput data contains image information in hyperspectral image denoising. Thus,\nwe cut the trained diffusion model from small steps to avoid the destroy of\nvalid information.",
                "authors": [
                    "Jiang He",
                    "Yajie Li",
                    "Jie L",
                    "Qiangqiang Yuan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13622v1",
                    "http://arxiv.org/pdf/2311.13622v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00037v1/1.0",
                "title": "Photonic Neural Networks and Optics-informed Deep Learning Fundamentals",
                "year": 2023,
                "abstract": "The recent explosive compute growth, mainly fueled by the boost of AI and\nDNNs, is currently instigating the demand for a novel computing paradigm that\ncan overcome the insurmountable barriers imposed by conventional electronic\ncomputing architectures. PNNs implemented on silicon integration platforms\nstand out as a promising candidate to endow NN hardware, offering the potential\nfor energy efficient and ultra-fast computations through the utilization of the\nunique primitives of photonics i.e. energy efficiency, THz bandwidth and\nlow-latency. Thus far, several demonstrations have revealed the huge potential\nof PNNs in performing both linear and non-linear NN operations at unparalleled\nspeed and energy consumption metrics. Transforming this potential into a\ntangible reality for DL applications requires, however, a deep understanding of\nthe basic PNN principles, requirements and challenges across all constituent\narchitectural, technological and training aspects. In this tutorial, we,\ninitially, review the principles of DNNs along with their fundamental building\nblocks, analyzing also the key mathematical operations needed for their\ncomputation in a photonic hardware. Then, we investigate, through an intuitive\nmathematical analysis, the interdependence of bit precision and energy\nefficiency in analog photonic circuitry, discussing the opportunities and\nchallenges of PNNs. Followingly, a performance overview of PNN architectures,\nweight technologies and activation functions is presented, summarizing their\nimpact in speed, scalability and power consumption. Finally, we provide an\nholistic overview of the optics-informed NN training framework that\nincorporates the physical properties of photonic building blocks into the\ntraining process in order to improve the NN classification accuracy and\neffectively elevate neuromorphic photonic hardware into high-performance DL\ncomputational settings.",
                "authors": [
                    "A. Tsakyridis",
                    "M. Moralis-Pegios",
                    "G. Giamougiannis",
                    "M. Kirtas",
                    "N. Passalis",
                    "A. Tefas",
                    "N. Pleros"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00037v1",
                    "http://arxiv.org/pdf/2312.00037v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "cs.ET"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13234v1/1.0",
                "title": "TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry\n  Guided Transformer",
                "year": 2023,
                "abstract": "Optical Intraoral Scanners (IOS) are widely used in digital dentistry to\nprovide detailed 3D information of dental crowns and the gingiva. Accurate 3D\ntooth segmentation in IOSs is critical for various dental applications, while\nprevious methods are error-prone at complicated boundaries and exhibit\nunsatisfactory results across patients. In this paper, we propose TSegFormer\nwhich captures both local and global dependencies among different teeth and the\ngingiva in the IOS point clouds with a multi-task 3D transformer architecture.\nMoreover, we design a geometry-guided loss based on a novel point curvature to\nrefine boundaries in an end-to-end manner, avoiding time-consuming\npost-processing to reach clinically applicable segmentation. In addition, we\ncreate a dataset with 16,000 IOSs, the largest ever IOS dataset to the best of\nour knowledge. The experimental results demonstrate that our TSegFormer\nconsistently surpasses existing state-of-the-art baselines. The superiority of\nTSegFormer is corroborated by extensive analysis, visualizations and real-world\nclinical applicability tests. Our code is available at\nhttps://github.com/huiminxiong/TSegFormer.",
                "authors": [
                    "Huimin Xiong",
                    "Kunle Li",
                    "Kaiyuan Tan",
                    "Yang Feng",
                    "Joey Tianyi Zhou",
                    "Jin Hao",
                    "Haochao Ying",
                    "Jian Wu",
                    "Zuozhu Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13234v1",
                    "http://arxiv.org/pdf/2311.13234v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13231v2/1.0",
                "title": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model",
                "year": 2023,
                "abstract": "Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels. Our code is publicly available in\nhttps://github.com/yk7333/D3PO/tree/main.",
                "authors": [
                    "Kai Yang",
                    "Jian Tao",
                    "Jiafei Lyu",
                    "Chunjiang Ge",
                    "Jiaxin Chen",
                    "Qimai Li",
                    "Weihan Shen",
                    "Xiaolong Zhu",
                    "Xiu Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13231v2",
                    "http://arxiv.org/pdf/2311.13231v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13230v1/1.0",
                "title": "Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus",
                "year": 2023,
                "abstract": "Large Language Models (LLMs) have gained significant popularity for their\nimpressive performance across diverse fields. However, LLMs are prone to\nhallucinate untruthful or nonsensical outputs that fail to meet user\nexpectations in many real-world applications. Existing works for detecting\nhallucinations in LLMs either rely on external knowledge for reference\nretrieval or require sampling multiple responses from the LLM for consistency\nverification, making these methods costly and inefficient. In this paper, we\npropose a novel reference-free, uncertainty-based method for detecting\nhallucinations in LLMs. Our approach imitates human focus in factuality\nchecking from three aspects: 1) focus on the most informative and important\nkeywords in the given text; 2) focus on the unreliable tokens in historical\ncontext which may lead to a cascade of hallucinations; and 3) focus on the\ntoken properties such as token type and token frequency. Experimental results\non relevant datasets demonstrate the effectiveness of our proposed method,\nwhich achieves state-of-the-art performance across all the evaluation metrics\nand eliminates the need for additional information.",
                "authors": [
                    "Tianhang Zhang",
                    "Lin Qiu",
                    "Qipeng Guo",
                    "Cheng Deng",
                    "Yue Zhang",
                    "Zheng Zhang",
                    "Chenghu Zhou",
                    "Xinbing Wang",
                    "Luoyi Fu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13230v1",
                    "http://arxiv.org/pdf/2311.13230v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13621v1/1.0",
                "title": "Knowledge From the Dark Side: Entropy-Reweighted Knowledge Distillation\n  for Balanced Knowledge Transfer",
                "year": 2023,
                "abstract": "Knowledge Distillation (KD) transfers knowledge from a larger \"teacher\" model\nto a compact \"student\" model, guiding the student with the \"dark knowledge\"\n$\\unicode{x2014}$ the implicit insights present in the teacher's soft\npredictions. Although existing KDs have shown the potential of transferring\nknowledge, the gap between the two parties still exists. With a series of\ninvestigations, we argue the gap is the result of the student's overconfidence\nin prediction, signaling an imbalanced focus on pronounced features while\noverlooking the subtle yet crucial dark knowledge. To overcome this, we\nintroduce the Entropy-Reweighted Knowledge Distillation (ER-KD), a novel\napproach that leverages the entropy in the teacher's predictions to reweight\nthe KD loss on a sample-wise basis. ER-KD precisely refocuses the student on\nchallenging instances rich in the teacher's nuanced insights while reducing the\nemphasis on simpler cases, enabling a more balanced knowledge transfer.\nConsequently, ER-KD not only demonstrates compatibility with various\nstate-of-the-art KD methods but also further enhances their performance at\nnegligible cost. This approach offers a streamlined and effective strategy to\nrefine the knowledge transfer process in KD, setting a new paradigm in the\nmeticulous handling of dark knowledge. Our code is available at\nhttps://github.com/cpsu00/ER-KD.",
                "authors": [
                    "Chi-Ping Su",
                    "Ching-Hsun Tseng",
                    "Shin-Jye Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13621v1",
                    "http://arxiv.org/pdf/2311.13621v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13227v1/1.0",
                "title": "Critical edge statistics for deformed GinUEs",
                "year": 2023,
                "abstract": "For an additive perturbation of the complex Ginibre ensemble under a\ndeterministic matrix $X_0$, under certain assumption on $X_0$ we prove that\nthere are only two types of local statistical patterns at the spectral\nedge--GinUE statistics and critical statistics, which corresponds to regular or\nquadratic vanishing spectral points. The latter, as a non-Hermitian analogue of\nPearcey statistics in random matrix theory, characterizes a new point process\non the complex plane and will be our major goal in this paper.",
                "authors": [
                    "Dang-Zheng Liu",
                    "Lu Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13227v1",
                    "http://arxiv.org/pdf/2311.13227v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "60B20"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13225v2/1.0",
                "title": "NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU\n  Heterogeneous Environments",
                "year": 2023,
                "abstract": "Graph Neural Networks (GNNs) have demonstrated outstanding performance in\nvarious applications. Existing frameworks utilize CPU-GPU heterogeneous\nenvironments to train GNN models and integrate mini-batch and sampling\ntechniques to overcome the GPU memory limitation. In CPU-GPU heterogeneous\nenvironments, we can divide sample-based GNN training into three steps: sample,\ngather, and train. Existing GNN systems use different task orchestrating\nmethods to employ each step on CPU or GPU. After extensive experiments and\nanalysis, we find that existing task orchestrating methods fail to fully\nutilize the heterogeneous resources, limited by inefficient CPU processing or\nGPU resource contention. In this paper, we propose NeutronOrch, a system for\nsample-based GNN training that incorporates a layer-based task orchestrating\nmethod and ensures balanced utilization of the CPU and GPU. NeutronOrch\ndecouples the training process by layer and pushes down the training task of\nthe bottom layer to the CPU. This significantly reduces the computational load\nand memory footprint of GPU training. To avoid inefficient CPU processing,\nNeutronOrch only offloads the training of frequently accessed vertices to the\nCPU and lets GPU reuse their embeddings with bounded staleness. Furthermore,\nNeutronOrch provides a fine-grained pipeline design for the layer-based task\norchestrating method, fully overlapping different tasks on heterogeneous\nresources while strictly guaranteeing bounded staleness. The experimental\nresults show that compared with the state-of-the-art GNN systems, NeutronOrch\ncan achieve up to 11.51x performance speedup.",
                "authors": [
                    "Xin Ai",
                    "Qiange Wang",
                    "Chunyu Cao",
                    "Yanfeng Zhang",
                    "Chaoyi Chen",
                    "Hao Yuan",
                    "Yu Gu",
                    "Ge Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13225v2",
                    "http://arxiv.org/pdf/2311.13225v2"
                ],
                "primary_category": "cs.DC",
                "categories": [
                    "cs.DC",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13222v1/1.0",
                "title": "Towards Detecting, Recognizing, and Parsing the Address Information from\n  Bangla Signboard: A Deep Learning-based Approach",
                "year": 2023,
                "abstract": "Retrieving textual information from natural scene images is an active\nresearch area in the field of computer vision with numerous practical\napplications. Detecting text regions and extracting text from signboards is a\nchallenging problem due to special characteristics like reflecting lights,\nuneven illumination, or shadows found in real-life natural scene images. With\nthe advent of deep learning-based methods, different sophisticated techniques\nhave been proposed for text detection and text recognition from the natural\nscene. Though a significant amount of effort has been devoted to extracting\nnatural scene text for resourceful languages like English, little has been done\nfor low-resource languages like Bangla. In this research work, we have proposed\nan end-to-end system with deep learning-based models for efficiently detecting,\nrecognizing, correcting, and parsing address information from Bangla\nsignboards. We have created manually annotated datasets and synthetic datasets\nto train signboard detection, address text detection, address text recognition,\naddress text correction, and address text parser models. We have conducted a\ncomparative study among different CTC-based and Encoder-Decoder model\narchitectures for Bangla address text recognition. Moreover, we have designed a\nnovel address text correction model using a sequence-to-sequence\ntransformer-based network to improve the performance of Bangla address text\nrecognition model by post-correction. Finally, we have developed a Bangla\naddress text parser using the state-of-the-art transformer-based pre-trained\nlanguage model.",
                "authors": [
                    "Hasan Murad",
                    "Mohammed Eunus Ali"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13222v1",
                    "http://arxiv.org/pdf/2311.13222v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13220v1/1.0",
                "title": "Monolithic MHz-frame rate digital SiPM-IC with sub-100 ps precision and\n  70$~\u03bc$m pixel pitch",
                "year": 2023,
                "abstract": "This paper presents the design and characterization of a monolithic\nintegrated circuit (IC) including digital silicon photomultipliers (dSiPMs)\narranged in a 32$~\\times~$32 pixel matrix at 70$~\\mu$m pitch. The IC provides\nper-quadrant time stamping and hit-map readout, and is fabricated in a standard\n150-nm CMOS technology. Each dSiPM pixel consists of four single-photon\navalanche diodes (SPADs) sharing a quenching and subsequent processing\ncircuitry and has a fill factor of 30$~\\%$. A sub-100$~$ps precision, 12-bit\ntime-to-digital converter (TDC) provides timestamps per quadrant with an\nacquisition rate of 3$~$MHz. Together with the hit map, the total sustained\ndata throughput of the IC amounts to 4$~$Gbps. Measurements obtained in a dark,\ntemperature-stable environment as well as by using a pulsed laser environment\nshow the full dSiPM-IC functionality. The dark-count rate (DCR) as function of\nthe overvoltage and temperature, the TDC resolution, differential and integral\nnonlinearity (DNL/INL) as well as the propagation-delay variations across the\nmatrix are presented. With aid of additional peripheral test structures, the\nmain building blocks are characterized and key parameters are presented.",
                "authors": [
                    "I. Diehl",
                    "K. Hansen",
                    "T. Vanat",
                    "G. Vignola",
                    "F. Feindt",
                    "D. Rastorguev",
                    "S. Spannagel"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13220v1",
                    "http://arxiv.org/pdf/2311.13220v1"
                ],
                "primary_category": "physics.ins-det",
                "categories": [
                    "physics.ins-det"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.03716v1/1.0",
                "title": "Co-guiding for Multi-intent Spoken Language Understanding",
                "year": 2023,
                "abstract": "Recent graph-based models for multi-intent SLU have obtained promising\nresults through modeling the guidance from the prediction of intents to the\ndecoding of slot filling. However, existing methods (1) only model the\nunidirectional guidance from intent to slot, while there are bidirectional\ninter-correlations between intent and slot; (2) adopt homogeneous graphs to\nmodel the interactions between the slot semantics nodes and intent label nodes,\nwhich limit the performance. In this paper, we propose a novel model termed\nCo-guiding Net, which implements a two-stage framework achieving the mutual\nguidances between the two tasks. In the first stage, the initial estimated\nlabels of both tasks are produced, and then they are leveraged in the second\nstage to model the mutual guidances. Specifically, we propose two heterogeneous\ngraph attention networks working on the proposed two heterogeneous semantics\nlabel graphs, which effectively represent the relations among the semantics\nnodes and label nodes. Besides, we further propose Co-guiding-SCL Net, which\nexploits the single-task and dual-task semantics contrastive relations. For the\nfirst stage, we propose single-task supervised contrastive learning, and for\nthe second stage, we propose co-guiding supervised contrastive learning, which\nconsiders the two tasks' mutual guidances in the contrastive learning\nprocedure. Experiment results on multi-intent SLU show that our model\noutperforms existing models by a large margin, obtaining a relative improvement\nof 21.3% over the previous best model on MixATIS dataset in overall accuracy.\nWe also evaluate our model on the zero-shot cross-lingual scenario and the\nresults show that our model can relatively improve the state-of-the-art model\nby 33.5% on average in terms of overall accuracy for the total 9 languages.",
                "authors": [
                    "Bowen Xing",
                    "Ivor W. Tsang"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.03716v1",
                    "http://arxiv.org/pdf/2312.03716v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13217v1/1.0",
                "title": "Controllable orbital angular momentum monopoles in chiral topological\n  semimetals",
                "year": 2023,
                "abstract": "The emerging field of orbitronics aims at generating and controlling currents\nof electronic orbital angular momentum (OAM) for information processing.\nStructurally chiral topological crystals could be particularly suitable\norbitronic materials because they have been predicted to host topological band\ndegeneracies in reciprocal space that are monopoles of OAM. Around such a\nmonopole, the OAM is locked isotopically parallel or antiparallel to the\ndirection of the electron's momentum, which could be used to generate large and\ncontrollable OAM currents. However, OAM monopoles have not yet been directly\nobserved in chiral crystals, and no handle to control their polarity has been\ndiscovered. Here, we use circular dichroism in angle-resolved photoelectron\nspectroscopy (CD-ARPES) to image OAM monopoles in the chiral topological\nsemimetals PtGa and PdGa. Moreover, we also demonstrate that the polarity of\nthe monopole can be controlled via the structural handedness of the host\ncrystal by imaging OAM monopoles and anti-monopoles in the two enantiomers of\nPdGa, respectively. For most photon energies used in our study, we observe a\nsign change in the CD-ARPES spectrum when comparing positive and negative\nmomenta along the light direction near the topological degeneracy. This is\nconsistent with the conventional view that CD-ARPES measures the projection of\nthe OAM monopole along the photon momentum. For some photon energies, however,\nthis sign change disappears, which can be understood from our numerical\nsimulations as the interference of polar atomic OAM contributions, consistent\nwith the presence of OAM monopoles. Our results highlight the potential of\nchiral crystals for orbitronic device applications, and our methodology could\nenable the discovery of even more complicated nodal OAM textures that could be\nexploited for orbitronics.",
                "authors": [
                    "Yun Yen",
                    "Jonas A. Krieger",
                    "Mengyu Yao",
                    "I\u00f1igo Robredo",
                    "Kaustuv Manna",
                    "Qun Yang",
                    "Emily C. McFarlane",
                    "Chandra Shekhar",
                    "Horst Borrmann",
                    "Samuel Stolz",
                    "Roland Widmer",
                    "Oliver Gr\u00f6ning",
                    "Vladimir N. Strocov",
                    "Stuart S. P. Parkin",
                    "Claudia Felser",
                    "Maia G. Vergniory",
                    "Michael Sch\u00fcler",
                    "Niels B. M. Schr\u00f6ter"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13217v1",
                    "http://arxiv.org/pdf/2311.13217v1"
                ],
                "primary_category": "cond-mat.str-el",
                "categories": [
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13209v1/1.0",
                "title": "Test-time Adaptive Vision-and-Language Navigation",
                "year": 2023,
                "abstract": "Vision-and-Language Navigation (VLN) has witnessed significant advancements\nin recent years, largely attributed to meticulously curated datasets and\nproficiently trained models. Nevertheless, when tested in diverse environments,\nthe trained models inevitably encounter significant shifts in data\ndistribution, highlighting that relying solely on pre-trained and fixed\nnavigation models is insufficient. To enhance models' generalization ability,\ntest-time adaptation (TTA) demonstrates significant potential in the computer\nvision field by leveraging unlabeled test samples for model updates. However,\nsimply applying existing TTA methods to the VLN task cannot well handle the\nadaptability-stability dilemma of VLN models, i.e., frequent updates can result\nin drastic changes in model parameters, while occasional updates can make the\nmodels ill-equipped to handle dynamically changing environments. Therefore, we\npropose a Fast-Slow Test-Time Adaptation (FSTTA) approach for VLN by performing\ndecomposition-accumulation analysis for both gradients and parameters in a\nunified framework. Specifically, in the fast update phase, gradients generated\nduring the recent multi-step navigation process are decomposed into components\nwith varying levels of consistency. Then, these components are adaptively\naccumulated to pinpoint a concordant direction for fast model adaptation. In\nthe slow update phase, historically recorded parameters are gathered, and a\nsimilar decomposition-accumulation analysis is conducted to revert the model to\na stable state. Extensive experiments show that our method obtains impressive\nperformance gains on four popular benchmarks.",
                "authors": [
                    "Junyu Gao",
                    "Xuan Yao",
                    "Changsheng Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13209v1",
                    "http://arxiv.org/pdf/2311.13209v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13208v1/1.0",
                "title": "Electrified Fracture of Nanotube Films",
                "year": 2023,
                "abstract": "Strong and conductive carbon nanotube films are ideal candidates for\nlightning-strike protection. Understanding their failure mechanisms by\nconsidering the anisotropic and single-fiber nature is essential to improve\nperformance. Our experimental studies show that the single-layer,\nnanometer-thick films fail under electrification by crack nucleation and\npropagation, reminiscent of brittle and ductile fracture of materials under\nmechanical loads. Sharp and diffuse patterns of fracture are identified in\naligned and non-woven films, respectively, signaling the strong effect of\nmaterial anisotropy that is absent in common engineering materials. The\nfracture is driven by local Joule heating concentrated at the crack fronts\ninstead of force-induced breakage, which is validated by experimental\ncharacterization and simulation results at both continuum and atomistic levels.",
                "authors": [
                    "Jinbo Bian",
                    "Shijun Wang",
                    "Zhaokuan Yu",
                    "Zhong Zhang",
                    "Zhiping Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13208v1",
                    "http://arxiv.org/pdf/2311.13208v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph",
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13203v1/1.0",
                "title": "Reshaping and Enzymatic Activity allow Viruses to move through the Mucus",
                "year": 2023,
                "abstract": "Filamentous viruses like influenza and torovirus often display systematic\nbends and arcs of mysterious physical origin. We propose that such viruses\nundergo an instability from a cylindrically symmetric to a toroidally curved\nstate. This \"toro-elastic\" state emerges via a spontaneous symmetry breaking\nunder prestress, induced via short range spike protein interactions and\nmagnified by the filament's surface topography. Once surface stresses become\nsufficiently large, the filament buckles and the toroidal, curved state\nconstitutes a soft mode that can propagate through the filament's material\nframe around a \"mexican-hat\" potential. In the mucus of our airways, glycan\nchains are omnipresent that influenza's spike proteins can bind to and cut. We\nshow that when coupled to such a non-equilibrium chemical reaction, the curved\ntoro-elastic state can attain a spontaneous rotation for sufficiently strong\nenzymatic activity, leading to a whole body reshaping propulsion similar to --\nbut different from -- eukaryotic flagella and spirochetes.",
                "authors": [
                    "Falko Ziebert",
                    "Kenan G. Dokonon",
                    "Igor M. Kuli\u0107"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13203v1",
                    "http://arxiv.org/pdf/2311.13203v1"
                ],
                "primary_category": "cond-mat.soft",
                "categories": [
                    "cond-mat.soft",
                    "q-bio.BM",
                    "q-bio.SC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13200v1/1.0",
                "title": "Self-guided Few-shot Semantic Segmentation for Remote Sensing Imagery\n  Based on Large Vision Models",
                "year": 2023,
                "abstract": "The Segment Anything Model (SAM) exhibits remarkable versatility and\nzero-shot learning abilities, owing largely to its extensive training data\n(SA-1B). Recognizing SAM's dependency on manual guidance given its\ncategory-agnostic nature, we identified unexplored potential within few-shot\nsemantic segmentation tasks for remote sensing imagery. This research\nintroduces a structured framework designed for the automation of few-shot\nsemantic segmentation. It utilizes the SAM model and facilitates a more\nefficient generation of semantically discernible segmentation outcomes. Central\nto our methodology is a novel automatic prompt learning approach, leveraging\nprior guided masks to produce coarse pixel-wise prompts for SAM. Extensive\nexperiments on the DLRSD datasets underline the superiority of our approach,\noutperforming other available few-shot methodologies.",
                "authors": [
                    "Xiyu Qi",
                    "Yifan Wu",
                    "Yongqiang Mao",
                    "Wenhui Zhang",
                    "Yidan Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13200v1",
                    "http://arxiv.org/pdf/2311.13200v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13197v1/1.0",
                "title": "Broadband dielectric studies in linseed oil: Supercriticality and the\n  New Insight into Melting/Freezing Discontinuous Transition",
                "year": 2023,
                "abstract": "The long-range supercritical changes of dielectric constant, resembling ones\nobserved in the isotropic phase of rod-like liquid crystalline compounds, are\nevidenced on approaching liquid-solid discontinuous phase transition. The\n'supercriticality' can be an additional factor for supporting the unique\npro-health properties of linseed oil. It can also be significant for numerous\ntechnological applications. The report also reveals properties significant for\nmelting/freezing discontinuous phase transition cognitive puzzle. Broadband\ndielectric spectroscopy studies revealed long-range premelting (heating from\nthe solid phase) and post-freezing (cooling from the liquid phase) effects with\ncritical-like parametrizations. They can be correlated with the 'grain model'\nfor premelting and its development by the Lipovsky model. The evidence for the\npost-freezing effect, with the critical-like portrayal, may indicate a specific\ngranular solidification associated with pretransitional fluctuations. Numerous\nhallmarks of liquid-liquid and solid-solid phase transitions have also been\nfound. Notably, the melting temperature surrounding is related to the minimum\nand the freezing temperature to the maximum of dielectric loss factor\nD=tan(delta). Regarding dynamics, three primary relaxation processes have been\nfound. Their changes in subsequent temperature intervals, related to the\napparent activation enthalpy, follow critical-like patterns with the same\nsingular temperature. For relaxation times evolution, it leads to optimal\nparameterizations via the 'critical and activated' equation, recently proposed.",
                "authors": [
                    "Aleksandra Drozd-Rzoska",
                    "Sylwester J. Rzoska",
                    "Joanna \u0141o\u015b"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13197v1",
                    "http://arxiv.org/pdf/2311.13197v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph",
                    "cond-mat.soft",
                    "physics.bio-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13196v1/1.0",
                "title": "Optimal Time of Arrival Estimation for MIMO Backscatter Channels",
                "year": 2023,
                "abstract": "In this paper, we propose a novel time of arrival (TOA) estimator for\nmultiple-input-multiple-output (MIMO) backscatter channels in closed form. The\nproposed estimator refines the estimation precision from the topological\nstructure of the MIMO backscatter channels, and can considerably enhance the\nestimation accuracy. Particularly, we show that for the general $M \\times N$\nbistatic topology, the mean square error (MSE) is $\\frac{M+N-1}{MN}\\sigma^2_0$,\nand for the general $M \\times M$ monostatic topology, it is\n$\\frac{2M-1}{M^2}\\sigma^2_0$ for the diagonal subchannels, and\n$\\frac{M-1}{M^2}\\sigma^2_0$ for the off-diagonal subchannels, where\n$\\sigma^2_0$ is the MSE of the conventional least square estimator. In\naddition, we derive the Cramer-Rao lower bound (CRLB) for MIMO backscatter TOA\nestimation which indicates that the proposed estimator is optimal. Simulation\nresults verify that the proposed TOA estimator can considerably improve both\nestimation and positioning accuracy, especially when the MIMO scale is large.",
                "authors": [
                    "Chen He",
                    "Luyang Han",
                    "Z. Jane Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13196v1",
                    "http://arxiv.org/pdf/2311.13196v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT",
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13616v1/1.0",
                "title": "Online Video Quality Enhancement with Spatial-Temporal Look-up Tables",
                "year": 2023,
                "abstract": "Low latency rates are crucial for online video-based applications, such as\nvideo conferencing and cloud gaming, which make improving video quality in\nonline scenarios increasingly important. However, existing quality enhancement\nmethods are limited by slow inference speed and the requirement for temporal\ninformation contained in future frames, making it challenging to deploy them\ndirectly in online tasks. In this paper, we propose a novel method, STLVQE,\nspecifically designed to address the rarely studied online video quality\nenhancement (Online-VQE) problem. Our STLVQE designs a new VQE framework which\ncontains a Module-Agnostic Feature Extractor that greatly reduces the redundant\ncomputations and redesign the propagation, alignment, and enhancement module of\nthe network. A Spatial-Temporal Look-up Tables (STL) is proposed, which\nextracts spatial-temporal information in videos while saving substantial\ninference time. To the best of our knowledge, we are the first to exploit the\nLUT structure to extract temporal information in video tasks. Extensive\nexperiments on the MFQE 2.0 dataset demonstrate that our STLVQE achieves a\nsatisfactory performance-speed trade-off.",
                "authors": [
                    "Zefan Qu",
                    "Xinyang Jiang",
                    "Yifan Yang",
                    "Dongsheng Li",
                    "Cairong Zhao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13616v1",
                    "http://arxiv.org/pdf/2311.13616v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13194v2/1.0",
                "title": "Towards Improving Document Understanding: An Exploration on\n  Text-Grounding via MLLMs",
                "year": 2023,
                "abstract": "In the field of document understanding, significant advances have been made\nin the fine-tuning of Multimodal Large Language Models (MLLMs) with\ninstruction-following data. Nevertheless, the potential of text-grounding\ncapability within text-rich scenarios remains underexplored. In this paper, we\npresent a text-grounding document understanding model, termed TGDoc, which\naddresses this deficiency by enhancing MLLMs with the ability to discern the\nspatial positioning of text within images. Empirical evidence suggests that\ntext-grounding improves the model's interpretation of textual content, thereby\nelevating its proficiency in comprehending text-rich images. Specifically, we\ncompile a dataset containing 99K PowerPoint presentations sourced from the\ninternet. We formulate instruction tuning tasks including text detection,\nrecognition, and spotting to facilitate the cohesive alignment between the\nvisual encoder and large language model. Moreover, we curate a collection of\ntext-rich images and prompt the text-only GPT-4 to generate 12K high-quality\nconversations, featuring textual locations within text-rich scenarios. By\nintegrating text location data into the instructions, TGDoc is adept at\ndiscerning text locations during the visual question process. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nacross multiple text-rich benchmarks, validating the effectiveness of our\nmethod.",
                "authors": [
                    "Yonghui Wang",
                    "Wengang Zhou",
                    "Hao Feng",
                    "Keyi Zhou",
                    "Houqiang Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13194v2",
                    "http://arxiv.org/pdf/2311.13194v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13190v1/1.0",
                "title": "Direct Observation of sp-d Exchange Interaction in Mn$^2$$^+$doped\n  All-inorganic Perovskite Quantum Dots (CsPbX$_3$: X= Cl, Br)",
                "year": 2023,
                "abstract": "The field of lead halide perovskite nanocrystal doping has witnessed notable\nprogress in recent times, leading to the creation of innovative materials that\nshowcase compelling physical characteristics and hold substantial technological\npromise. The true characteristics of these materials lie in the presence of\ndopant-carrier magnetic exchange interactions. This work presents the first\ndirect observation of such exchange interactions in colloidal Mn-doped\nCsPbX$_3$ (X= Cl, Br) quantum dots (QDs). Here, we employ magnetic circular\ndichroism (MCD) spectroscopy to unambiguously demonstrate the successful doping\nand the presence of giant excitonic Zeeman splitting in CsPbX$_3$ (X= Cl, Br)\nQDs doped with Mn$^2$$^+$. The controllable tuning of effective exciton\ng-factors (g$_e$$_f$$_f$) within the range of 2.1 to (-)314 has been achieved\nthrough the process of doping with 6.9 % Mn in CsPbCl$_3$, which will\nfacilitate their application towards future spintronics",
                "authors": [
                    "Prasenjit Mandal",
                    "Ranjani Viswanatha"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13190v1",
                    "http://arxiv.org/pdf/2311.13190v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13188v1/1.0",
                "title": "Cracking the Code of Negative Transfer: A Cooperative Game Theoretic\n  Approach for Cross-Domain Sequential Recommendation",
                "year": 2023,
                "abstract": "This paper investigates Cross-Domain Sequential Recommendation (CDSR), a\npromising method that uses information from multiple domains (more than three)\nto generate accurate and diverse recommendations, and takes into account the\nsequential nature of user interactions. The effectiveness of these systems\noften depends on the complex interplay among the multiple domains. In this\ndynamic landscape, the problem of negative transfer arises, where heterogeneous\nknowledge between dissimilar domains leads to performance degradation due to\ndifferences in user preferences across these domains. As a remedy, we propose a\nnew CDSR framework that addresses the problem of negative transfer by assessing\nthe extent of negative transfer from one domain to another and adaptively\nassigning low weight values to the corresponding prediction losses. To this\nend, the amount of negative transfer is estimated by measuring the marginal\ncontribution of each domain to model performance based on a cooperative game\ntheory. In addition, a hierarchical contrastive learning approach that\nincorporates information from the sequence of coarse-level categories into that\nof fine-level categories (e.g., item level) when implementing contrastive\nlearning was developed to mitigate negative transfer. Despite the potentially\nlow relevance between domains at the fine-level, there may be higher relevance\nat the category level due to its generalised and broader preferences. We show\nthat our model is superior to prior works in terms of model performance on two\nreal-world datasets across ten different domains.",
                "authors": [
                    "Chung Park",
                    "Taesan Kim",
                    "Taekyoon Choi",
                    "Junui Hong",
                    "Yelim Yu",
                    "Mincheol Cho",
                    "Kyunam Lee",
                    "Sungil Ryu",
                    "Hyungjun Yoon",
                    "Minsung Choi",
                    "Jaegul Choo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13188v1",
                    "http://arxiv.org/pdf/2311.13188v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13184v1/1.0",
                "title": "AS-LLM: When Algorithm Selection Meets Large Language Model",
                "year": 2023,
                "abstract": "Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.",
                "authors": [
                    "Xingyu Wu",
                    "Yan Zhong",
                    "Jibin Wu",
                    "Kay Chen Tan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13184v1",
                    "http://arxiv.org/pdf/2311.13184v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13183v1/1.0",
                "title": "No-Three-in-a-$\u0398:$ Variations on the No-Three-in-a-Line Problem",
                "year": 2023,
                "abstract": "We pose a natural generalization to the well-studied and difficult\nno-three-in-a-line problem: How many points can be chosen on an $n \\times n$\ngrid such that no three of them form an angle of $\\theta$? In this paper, we\nclassify which angles yield nontrivial problems, noting that some angles appear\nin surprising configurations on the grid. We prove a lower bound of $2n$ points\nfor angles $\\theta$ such that $135^\\circ \\leq \\theta < 180^\\circ$, and further\nexplore the case $\\theta = 135^\\circ$, utilizing geometric properties of the\ngrid to prove an upper bound of $3n - 2$ points. Lastly, we generalize the\nproof strategy used in proving the upper bound for $\\theta = 135^\\circ$ to\nprovide a general upper bound for all angles.",
                "authors": [
                    "Natalie Dodson",
                    "Anant Godbole",
                    "Dashleen Gonzalez",
                    "Ryan Lynch",
                    "Lani Southern"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13183v1",
                    "http://arxiv.org/pdf/2311.13183v1"
                ],
                "primary_category": "math.CO",
                "categories": [
                    "math.CO",
                    "math.MG",
                    "05D99"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13181v1/1.0",
                "title": "Fractional quantum Hall interface induced by geometric singularity",
                "year": 2023,
                "abstract": "The geometric response of quantum Hall liquids is an important aspect to\nunderstand their topological characteristics in addition to the electromagnetic\nresponse. According to the Wen-Zee theory, the topological spin is coupled to\nthe curvature of the space in which the electrons reside. The presence of\nconical geometry provides a local isolated geometric singularity, making it\nsuitable for exploring the geometric response. In the context of\ntwo-dimensional electrons in a perpendicular magnetic field, each Landau orbit\noccupies the same area. The cone geometry naturally provides a structure in\nwhich the distances between two adjacent orbits gradually change and can be\neasily adjusted by altering the tip angle. The presence of a cone tip\nintroduces a geometric singularity that affects the electron density and\ninteracts with the motion of electrons, which has been extensively studied.\nFurthermore, this type of geometry can automatically create a smooth interface\nor crossover between the crystalline charge-density-wave state and the\nliquid-like fractional quantum Hall state. In this work, the properties of this\ninterface are studied from multiple perspectives, shedding light on the\nbehavior of quantum Hall liquids in such geometric configurations.",
                "authors": [
                    "Qi Li",
                    "Yi Yang",
                    "Zhou Li",
                    "Hao Wang",
                    "Zi-Xiang Hu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13181v1",
                    "http://arxiv.org/pdf/2311.13181v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13173v1/1.0",
                "title": "Smoothed Particle Hydrodynamics simulations of integral multi-mode and\n  fractional viscoelastic models",
                "year": 2023,
                "abstract": "To capture specific characteristics of non-Newtonian fluids, during the past\nyears fractional constitutive models have become increasingly popular. These\nmodels are able to capture in a simple and compact way the complex behaviour of\nviscoelastic materials, such as the change in power-law relaxation pattern\nduring the relaxation process of some materials. Using the Lagrangian\nSmoothed-Particle Hydrodynamics (SPH) method we can easily track particle\nhistory; this allows us to solve integral constitutive models in a novel way,\nwithout relying on complex tasks. Hence, we develop here a SPH integral\nviscoelastic method which is first validated for simple Maxwell or Oldroyd-B\nmodels under Small Amplitude Oscillatory Shear flows (SAOS). By exploiting the\nstructure of the integral method, a multi-mode Maxwell model is then\nimplemented. Finally, the method is extended to include fractional constitutive\nmodels, validating the approach by comparing results with theory under SAOS.",
                "authors": [
                    "Luca Santelli",
                    "Adolfo Vazquez-Quesada",
                    "Marco Ellero"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13173v1",
                    "http://arxiv.org/pdf/2311.13173v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "physics.comp-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13172v1/1.0",
                "title": "Learning to Complement with Multiple Humans (LECOMH): Integrating\n  Multi-rater and Noisy-Label Learning into Human-AI Collaboration",
                "year": 2023,
                "abstract": "The advent of learning with noisy labels (LNL), multi-rater learning, and\nhuman-AI collaboration has revolutionised the development of robust\nclassifiers, enabling them to address the challenges posed by different types\nof data imperfections and complex decision processes commonly encountered in\nreal-world applications. While each of these methodologies has individually\nmade significant strides in addressing their unique challenges, the development\nof techniques that can simultaneously tackle these three problems remains\nunderexplored. This paper addresses this research gap by integrating\nnoisy-label learning, multi-rater learning, and human-AI collaboration with new\nbenchmarks and the innovative Learning to Complement with Multiple Humans\n(LECOMH) approach. LECOMH optimises the level of human collaboration during\ntesting, aiming to optimise classification accuracy while minimising\ncollaboration costs that vary from 0 to M, where M is the maximum number of\nhuman collaborators. We quantitatively compare LECOMH with leading human-AI\ncollaboration methods using our proposed benchmarks. LECOMH consistently\noutperforms the competition, with accuracy improving as collaboration costs\nincrease. Notably, LECOMH is the only method enhancing human labeller\nperformance across all benchmarks.",
                "authors": [
                    "Zheng Zhang",
                    "Kevin Wells",
                    "Gustavo Carneiro"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13172v1",
                    "http://arxiv.org/pdf/2311.13172v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13171v1/1.0",
                "title": "ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization",
                "year": 2023,
                "abstract": "Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.",
                "authors": [
                    "Prateek Yadav",
                    "Leshem Choshen",
                    "Colin Raffel",
                    "Mohit Bansal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13171v1",
                    "http://arxiv.org/pdf/2311.13171v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13170v1/1.0",
                "title": "An iterative deep learning procedure for determining electron scattering\n  cross-sections from transport coefficients",
                "year": 2023,
                "abstract": "We propose improvements to the Artificial Neural Network (ANN) method of\ndetermining electron scattering cross-sections from swarm data proposed by\ncoauthors. A limitation inherent to this problem, known as the inverse swarm\nproblem, is the non-unique nature of its solutions, particularly when there\nexists multiple cross-sections that each describe similar scattering processes.\nConsidering this, prior methods leveraged existing knowledge of a particular\ncross-section set to reduce the solution space of the problem. To reduce the\nneed for prior knowledge, we propose the following modifications to the ANN\nmethod. First, we propose a Multi-Branch ANN (MBANN) that assigns an\nindependent branch of hidden layers to each cross-section output. We show that\nin comparison with an equivalent conventional ANN, the MBANN architecture\nenables an efficient and physics informed feature map of each cross-section.\nAdditionally, we show that the MBANN solution can be improved upon by\nsuccessive networks that are each trained using perturbations of the previous\nregression. Crucially, the method requires much less input data and fewer\nrestrictive assumptions, and only assumes knowledge of energy loss thresholds\nand the number of cross-sections present.",
                "authors": [
                    "Dale L Muccignat",
                    "Gregory G Boyle",
                    "Nathan A Garland",
                    "Peter W Stokes",
                    "Ronald D White"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13170v1",
                    "http://arxiv.org/pdf/2311.13170v1"
                ],
                "primary_category": "physics.comp-ph",
                "categories": [
                    "physics.comp-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13165v1/1.0",
                "title": "Multimodal Large Language Models: A Survey",
                "year": 2023,
                "abstract": "The exploration of multimodal language models integrates multiple data types,\nsuch as images, text, language, audio, and other heterogeneity. While the\nlatest large language models excel in text-based tasks, they often struggle to\nunderstand and process other data types. Multimodal models address this\nlimitation by combining various modalities, enabling a more comprehensive\nunderstanding of diverse data. This paper begins by defining the concept of\nmultimodal and examining the historical development of multimodal algorithms.\nFurthermore, we introduce a range of multimodal products, focusing on the\nefforts of major technology companies. A practical guide is provided, offering\ninsights into the technical aspects of multimodal models. Moreover, we present\na compilation of the latest algorithms and commonly used datasets, providing\nresearchers with valuable resources for experimentation and evaluation. Lastly,\nwe explore the applications of multimodal models and discuss the challenges\nassociated with their development. By addressing these aspects, this paper aims\nto facilitate a deeper understanding of multimodal models and their potential\nin various domains.",
                "authors": [
                    "Jiayang Wu",
                    "Wensheng Gan",
                    "Zefeng Chen",
                    "Shicheng Wan",
                    "Philip S. Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13165v1",
                    "http://arxiv.org/pdf/2311.13165v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13164v1/1.0",
                "title": "Control of open quantum systems via dynamical invariants",
                "year": 2023,
                "abstract": "In this work, we confront the challenge of controlling quantum systems that\nare influenced by their environment, utilizing the theory of dynamical\ninvariants. Our strategy involves a reverse engineering method for formulating\ncontrol protocols like Shortcuts to Adiabaticity (STA), tailored to be\nresilient against environmental noise and dissipation. This technique offers\ntwo main advantages compared to other quantum control methods: firstly, it\nincorporates the time-varying aspect of the dissipation factor in the master\nequation, which arises from driving the system's Hamiltonian (the control\nfields). Secondly, our method eliminates the need for iterative propagation of\nthe system state, a process that is typically resource-intensive. The efficacy\nand practicality of our approach are demonstrated through the application to\ntwo fundamental models: a two-level quantum system and a quantum harmonic\noscillator, each interacting with a thermal bath.",
                "authors": [
                    "Loris Maria Cangemi",
                    "Hilario Espin\u00f3s",
                    "Ricardo Puebla",
                    "Erik Torrontegui",
                    "Amikam Levy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13164v1",
                    "http://arxiv.org/pdf/2311.13164v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13160v1/1.0",
                "title": "Large Language Models in Education: Vision and Opportunities",
                "year": 2023,
                "abstract": "With the rapid development of artificial intelligence technology, large\nlanguage models (LLMs) have become a hot research topic. Education plays an\nimportant role in human social development and progress. Traditional education\nfaces challenges such as individual student differences, insufficient\nallocation of teaching resources, and assessment of teaching effectiveness.\nTherefore, the applications of LLMs in the field of digital/smart education\nhave broad prospects. The research on educational large models (EduLLMs) is\nconstantly evolving, providing new methods and approaches to achieve\npersonalized learning, intelligent tutoring, and educational assessment goals,\nthereby improving the quality of education and the learning experience. This\narticle aims to investigate and summarize the application of LLMs in smart\neducation. It first introduces the research background and motivation of LLMs\nand explains the essence of LLMs. It then discusses the relationship between\ndigital education and EduLLMs and summarizes the current research status of\neducational large models. The main contributions are the systematic summary and\nvision of the research background, motivation, and application of large models\nfor education (LLM4Edu). By reviewing existing research, this article provides\nguidance and insights for educators, researchers, and policy-makers to gain a\ndeep understanding of the potential and challenges of LLM4Edu. It further\nprovides guidance for further advancing the development and application of\nLLM4Edu, while still facing technical, ethical, and practical challenges\nrequiring further research and exploration.",
                "authors": [
                    "Wensheng Gan",
                    "Zhenlian Qi",
                    "Jiayang Wu",
                    "Jerry Chun-Wei Lin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13160v1",
                    "http://arxiv.org/pdf/2311.13160v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13614v1/1.0",
                "title": "HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction\n  Data",
                "year": 2023,
                "abstract": "Multi-modal Large Language Models (MLLMs) tuned on machine-generated\ninstruction-following data have demonstrated remarkable performance in various\nmulti-modal understanding and generation tasks. However, the hallucinations\ninherent in machine-generated data, which could lead to hallucinatory outputs\nin MLLMs, remain under-explored. This work aims to investigate various\nhallucinations (i.e., object, relation, attribute hallucinations) and mitigate\nthose hallucinatory toxicities in large-scale machine-generated visual\ninstruction datasets. Drawing on the human ability to identify factual errors,\nwe present a novel hallucination detection and elimination framework,\nHalluciDoctor, based on the cross-checking paradigm. We use our framework to\nidentify and eliminate hallucinations in the training data automatically.\nInterestingly, HalluciDoctor also indicates that spurious correlations arising\nfrom long-tail object co-occurrences contribute to hallucinations. Based on\nthat, we execute counterfactual visual instruction expansion to balance data\ndistribution, thereby enhancing MLLMs' resistance to hallucinations.\nComprehensive experiments on hallucination evaluation benchmarks show that our\nmethod successfully mitigates 44.6% hallucinations relatively and maintains\ncompetitive performance compared to LLaVA.The source code will be released at\n\\url{https://github.com/Yuqifan1117/HalluciDoctor}.",
                "authors": [
                    "Qifan Yu",
                    "Juncheng Li",
                    "Longhui Wei",
                    "Liang Pang",
                    "Wentao Ye",
                    "Bosheng Qin",
                    "Siliang Tang",
                    "Qi Tian",
                    "Yueting Zhuang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13614v1",
                    "http://arxiv.org/pdf/2311.13614v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13158v1/1.0",
                "title": "From Principles to Practice: An Accountability Metrics Catalogue for\n  Managing AI Risks",
                "year": 2023,
                "abstract": "Artificial Intelligence (AI), particularly through the advent of large-scale\ngenerative AI (GenAI) models such as Large Language Models (LLMs), has become a\ntransformative element in contemporary technology. While these models have\nunlocked new possibilities, they simultaneously present significant challenges,\nsuch as concerns over data privacy and the propensity to generate misleading or\nfabricated content. Current frameworks for Responsible AI (RAI) often fall\nshort in providing the granular guidance necessary for tangible application,\nespecially for Accountability-a principle that is pivotal for ensuring\ntransparent and auditable decision-making, bolstering public trust, and meeting\nincreasing regulatory expectations. This study bridges the accountability gap\nby introducing a comprehensive metrics catalogue, formulated through a\nsystematic multivocal literature review (MLR) that integrates findings from\nboth academic and grey literature. Our catalogue delineates process metrics\nthat underpin procedural integrity, resource metrics that provide necessary\ntools and frameworks, and product metrics that reflect the outputs of AI\nsystems. This tripartite framework is designed to operationalize Accountability\nin AI, with a special emphasis on addressing the intricacies of GenAI. The\nproposed metrics catalogue provides a robust framework for instilling\nAccountability in AI systems. It offers practical, actionable guidance for\norganizations, thereby shaping responsible practices in the field.",
                "authors": [
                    "Boming Xia",
                    "Qinghua Lu",
                    "Liming Zhu",
                    "Sung Une Lee",
                    "Yue Liu",
                    "Zhenchang Xing"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13158v1",
                    "http://arxiv.org/pdf/2311.13158v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13156v2/1.0",
                "title": "Fractonic Quantum Quench in Dipole-constrained Bosons",
                "year": 2023,
                "abstract": "We investigate the quench dynamics in the dipolar Bose-Hubbard model in one\ndimension where the boson hopping is constrained by dipole conservation and\nshow fractonic dynamics. Quench processes that start deep in the Mott phase and\nend in the weak Mott phase show light-cone-like spreading in the dipole\ncorrelation function but not in the single-boson correlator, which is\nsuppressed due to the dipole conservation. The phase and the group velocities\nestimated from the dilute-dipolon approximation are in excellent agreement with\nthose of the Time-Dependent Variational Principle method. The quench from the\ndipole-condensed (DC) phase to the Mott phase shows periodic kinks in the\nLoschmidt echo and the demise and revival of Bose-condensed peaks in the dipole\nmomentum distribution function, both of which are noted features of dynamical\nquantum phase transition. The Mott-to-DC quench, on the other hand, shows none\nof these features despite the quench parameters varying across the equilibrium\nquantum critical point. Our findings on the fractonic quench dynamics can be\nchecked in the tilted optical lattice experiment.",
                "authors": [
                    "Yun-Tak Oh",
                    "Jung Hoon Han",
                    "Hyun-Yong Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13156v2",
                    "http://arxiv.org/pdf/2311.13156v2"
                ],
                "primary_category": "cond-mat.quant-gas",
                "categories": [
                    "cond-mat.quant-gas",
                    "cond-mat.other",
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13148v2/1.0",
                "title": "Building the Future of Responsible AI: A Reference Architecture for\n  Designing Large Language Model based Agents",
                "year": 2023,
                "abstract": "Large language models (LLMs) have been widely recognised as transformative\nartificial generative intelligence (AGI) technologies due to their capabilities\nto understand and generate content, including plans with reasoning\ncapabilities. Foundation model based agents derive their autonomy from the\ncapabilities of foundation models, which enable them to autonomously break down\na given goal into a set of manageable tasks and orchestrate task execution to\nmeet the goal. Despite the huge efforts put into building foundation model\nbased autonomous agents, the architecture design of the agents has not yet been\nsystematically explored. Also, while there are significant benefits of using\nautonomous agents for planning and execution, there are serious considerations\nregarding responsible AI related software quality attributes, such as security\nand accountability. Therefore, this paper presents a pattern-oriented reference\narchitecture that serves as architecture design guidance and enables\nresponsible-AI-by-design when designing foundation model based autonomous\nagents. We evaluate the completeness and utility of the proposed reference\narchitecture by mapping it to the architecture of two real-world agents.",
                "authors": [
                    "Qinghua Lu",
                    "Liming Zhu",
                    "Xiwei Xu",
                    "Zhenchang Xing",
                    "Stefan Harrer",
                    "Jon Whittle"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13148v2",
                    "http://arxiv.org/pdf/2311.13148v2"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13147v1/1.0",
                "title": "Optimal Transport with Cyclic Symmetry",
                "year": 2023,
                "abstract": "We propose novel fast algorithms for optimal transport (OT) utilizing a\ncyclic symmetry structure of input data. Such OT with cyclic symmetry appears\nuniversally in various real-world examples: image processing, urban planning,\nand graph processing. Our main idea is to reduce OT to a small optimization\nproblem that has significantly fewer variables by utilizing cyclic symmetry and\nvarious optimization techniques. On the basis of this reduction, our algorithms\nsolve the small optimization problem instead of the original OT. As a result,\nour algorithms obtain the optimal solution and the objective function value of\nthe original OT faster than solving the original OT directly. In this paper,\nour focus is on two crucial OT formulations: the linear programming OT (LOT)\nand the strongly convex-regularized OT, which includes the well-known\nentropy-regularized OT (EROT). Experiments show the effectiveness of our\nalgorithms for LOT and EROT in synthetic/real-world data that has a\nstrict/approximate cyclic symmetry structure. Through theoretical and\nexperimental results, this paper successfully introduces the concept of\nsymmetry into the OT research field for the first time.",
                "authors": [
                    "Shoichiro Takeda",
                    "Yasunori Akagi",
                    "Naoki Marumo",
                    "Kenta Niwa"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13147v1",
                    "http://arxiv.org/pdf/2311.13147v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13144v1/1.0",
                "title": "Single Image Compressed Sensing MRI via a Self-Supervised Deep Denoising\n  Approach",
                "year": 2023,
                "abstract": "Popular methods in compressed sensing (CS) are dependent on deep learning\n(DL), where large amounts of data are used to train non-linear reconstruction\nmodels. However, ensuring generalisability over and access to multiple datasets\nis challenging to realise for real-world applications. To address these\nconcerns, this paper proposes a single image, self-supervised (SS) CS-MRI\nframework that enables a joint deep and sparse regularisation of CS artefacts.\nThe approach effectively dampens structured CS artefacts, which can be\ndifficult to remove assuming sparse reconstruction, or relying solely on the\ninductive biases of CNN to produce noise-free images. Image quality is thereby\nimproved compared to either approach alone. Metrics are evaluated using\nCartesian 1D masks on a brain and knee dataset, with PSNR improving by 2-4dB on\naverage.",
                "authors": [
                    "Marlon Bran Lorenzana",
                    "Feng Liu",
                    "Shekhar S. Chandra"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13144v1",
                    "http://arxiv.org/pdf/2311.13144v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13142v1/1.0",
                "title": "Bulk--boundary correspondence in a non-Hermitian quantum spin-Hall\n  insulator",
                "year": 2023,
                "abstract": "We focus on a scenario of non-Hermitian bulk--boundary correspondence that\nuses a topological invariant defined in a bulk geometry under a modified\nperiodic boundary condition. Although this has succeeded in describing the\ntopological nature of various one-dimensional non-Hermitian systems, its\napplication to two-dimensional systems has been limited to a non-Hermitian\nChern insulator. Here, we adapt the scenario to a non-Hermitian quantum\nspin-Hall insulator to extend its applicability. We show that it properly\ndescribes the bulk--boundary correspondence in the non-Hermitian quantum\nspin-Hall insulator. A phase diagram derived from the bulk--boundary\ncorrespondence is shown to be consistent with spectra of the system under an\nopen boundary condition.",
                "authors": [
                    "Chihiro Ishii",
                    "Yositake Takane"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13142v1",
                    "http://arxiv.org/pdf/2311.13142v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13139v1/1.0",
                "title": "Joint Distributed Precoding and Beamforming for RIS-aided Cell-Free\n  Massive MIMO Systems",
                "year": 2023,
                "abstract": "The amalgamation of cell-free networks and reconfigurable intelligent surface\n(RIS) has become a prospective technique for future sixth-generation wireless\ncommunication systems. In this paper, we focus on the precoding and beamforming\ndesign for a downlink RIS-aided cell-free network. The design is formulated as\na non-convex optimization problem by jointly optimizing the combining vector,\nactive precoding, and passive RIS beamforming for minimizing the weighted sum\nof users' mean square error. A novel joint distributed precoding and\nbeamforming framework is proposed to decentralize the alternating optimization\nmethod for acquiring a suboptimal solution to the design problem. Finally,\nnumerical results validate the effectiveness of the proposed distributed\nprecoding and beamforming framework, showing its low-complexity and improved\nscalability compared with the centralized method.",
                "authors": [
                    "Peng Zhang",
                    "Jiayi Zhang",
                    "Huahua Xiao",
                    "Xiaodan Zhang",
                    "Derrick Wing Kwan Ng",
                    "Bo Ai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13139v1",
                    "http://arxiv.org/pdf/2311.13139v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13135v2/1.0",
                "title": "Magnetic-Reconnection-Heated Corona Model: Implication of Hybrid\n  Electrons for Hard X-ray Emission of Luminous Active Galactic Nuclei",
                "year": 2023,
                "abstract": "It is widely accepted that X-ray emission in luminous active galactic nuclei\n(AGNs) originates from hot corona. To prevent the corona from over-cooling by\nstrong X-ray emission, steady heating to the corona is essential, for which the\nmost promising mechanisms is the magnetic reconnection. Detailed studies of the\ncoupled disc and corona, in the frame of magnetic field transferring\naccretion-released energy from the disc to the corona, reveal that the thermal\nelectrons can only produce X-ray spectrum with $\\Gamma_{\\rm 2-10\\,keV}>2.1$,\nwhich is an inevitable consequence of the radiative coupling of the thermal\ncorona and disc. In the present work, we develop the\nmagnetic-reconnection-heated corona model by taking into account the potential\nnon-thermal electrons accelerated in the magnetic reconnection process, in\naddition to the thermal electrons. We show that the features of the structure\nand spectrum of the coupled disc and corona can be affected by the fraction of\nmagnetic energy allocated to thermal electrons. Furthermore, we investigate the\neffects of the power-law index and energy range of non-thermal electrons and\nthe magnetic field on the spectrum. It is found that the X-ray spectrum from\nthe Comptonization of the hybrid electrons can be flatter than that from\nthermal electrons only, in agreement with observations. By comparing with the\nobserved hard X-ray data, we suggest that a large fraction ($>40\\%$) of the\nmagnetic energy be allocated to the non-thermal electrons in the luminous and\nflat X-ray spectrum AGNs.",
                "authors": [
                    "Jie-Ying Liu",
                    "Jirong Mao",
                    "B. F. Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13135v2",
                    "http://arxiv.org/pdf/2311.13135v2"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13134v1/1.0",
                "title": "Lightweight High-Speed Photography Built on Coded Exposure and Implicit\n  Neural Representation of Videos",
                "year": 2023,
                "abstract": "The compact cameras recording high-speed scenes with high resolution are\nhighly demanded, but the required high bandwidth often leads to bulky, heavy\nsystems, which limits their applications on low-capacity platforms. Adopting a\ncoded exposure setup to encode a frame sequence into a blurry snapshot and\nretrieve the latent sharp video afterward can serve as a lightweight solution.\nHowever, restoring motion from blur is quite challenging due to the high\nill-posedness of motion blur decomposition, intrinsic ambiguity in motion\ndirection, and diverse motions in natural videos. In this work, by leveraging\nclassical coded exposure imaging technique and emerging implicit neural\nrepresentation for videos, we tactfully embed the motion direction cues into\nthe blurry image during the imaging process and develop a novel self-recursive\nneural network to sequentially retrieve the latent video sequence from the\nblurry image utilizing the embedded motion direction cues. To validate the\neffectiveness and efficiency of the proposed framework, we conduct extensive\nexperiments on benchmark datasets and real-captured blurry images. The results\ndemonstrate that our proposed framework significantly outperforms existing\nmethods in quality and flexibility. The code for our work is available at\nhttps://github.com/zhihongz/BDINR",
                "authors": [
                    "Zhihong Zhang",
                    "Runzhao Yang",
                    "Jinli Suo",
                    "Yuxiao Cheng",
                    "Qionghai Dai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13134v1",
                    "http://arxiv.org/pdf/2311.13134v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13133v1/1.0",
                "title": "LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms",
                "year": 2023,
                "abstract": "Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.",
                "authors": [
                    "Aditi Jha",
                    "Sam Havens",
                    "Jeremy Dohmann",
                    "Alex Trott",
                    "Jacob Portes"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13133v1",
                    "http://arxiv.org/pdf/2311.13133v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.16173v2/1.0",
                "title": "Conditions for Length Generalization in Learning Reasoning Skills",
                "year": 2023,
                "abstract": "Reasoning is a fundamental capability of AI agents. Recently, large language\nmodels (LLMs) have shown remarkable abilities to perform reasoning tasks.\nHowever, numerous evaluations of the reasoning capabilities of LLMs have also\nshowed some limitations. An outstanding limitation is length generalization,\nmeaning that when trained on reasoning problems of smaller lengths or sizes,\nthe resulting models struggle with problems of larger sizes or lengths. This\npotentially indicates some theoretical limitations of generalization in\nlearning reasoning skills. These evaluations and their observations motivated\nus to perform a theoretical study of the length generalization problem. This\nwork focuses on reasoning tasks that can be formulated as Markov dynamic\nprocesses (MDPs) and/or directed acyclic graphs (DAGs). It identifies and\nproves conditions that decide whether the length generalization problem can be\nsolved or not for a reasoning task in a particular representation. Experiments\nare also conducted to verify the theoretical results.",
                "authors": [
                    "Changnan Xiao",
                    "Bing Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.16173v2",
                    "http://arxiv.org/pdf/2311.16173v2"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13131v1/1.0",
                "title": "Pair circulas modelling for multivariate circular time series",
                "year": 2023,
                "abstract": "Modelling multivariate circular time series is considered. The\ncross-sectional and serial dependence is described by circulas, which are\nanalogs of copulas for circular distributions. In order to obtain a simple\nexpression of the dependence structure, we decompose a multivariate circula\ndensity to a product of several pair circula densities. Moreover, to reduce the\nnumber of pair circula densities, we consider strictly stationary multi-order\nMarkov processes. The real data analysis, in which the proposed model is fitted\nto multivariate time series wind direction data is also given.",
                "authors": [
                    "Hiroaki Ogata"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13131v1",
                    "http://arxiv.org/pdf/2311.13131v1"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13128v1/1.0",
                "title": "P2RBox: A Single Point is All You Need for Oriented Object Detection",
                "year": 2023,
                "abstract": "Oriented object detection, a specialized subfield in computer vision, finds\napplications across diverse scenarios, excelling particularly when dealing with\nobjects of arbitrary orientations. Conversely, point annotation, which treats\nobjects as single points, offers a cost-effective alternative to rotated and\nhorizontal bounding boxes but sacrifices performance due to the loss of size\nand orientation information. In this study, we introduce the P2RBox network,\nwhich leverages point annotations and a mask generator to create mask\nproposals, followed by filtration through our Inspector Module and Constrainer\nModule. This process selects high-quality masks, which are subsequently\nconverted into rotated box annotations for training a fully supervised\ndetector. Specifically, we've thoughtfully crafted an Inspector Module rooted\nin multi-instance learning principles to evaluate the semantic score of masks.\nWe've also proposed a more robust mask quality assessment in conjunction with\nthe Constrainer Module. Furthermore, we've introduced a Symmetry Axis\nEstimation (SAE) Module inspired by the spectral theorem for symmetric matrices\nto transform the top-performing mask proposal into rotated bounding boxes.\nP2RBox performs well with three fully supervised rotated object detectors:\nRetinaNet, Rotated FCOS, and Oriented R-CNN. By combining with Oriented R-CNN,\nP2RBox achieves 62.26% on DOTA-v1.0 test dataset. As far as we know, this is\nthe first attempt at training an oriented object detector with point\nsupervision.",
                "authors": [
                    "Guangming Cao",
                    "Xuehui Yu",
                    "Wenwen Yu",
                    "Xumeng Han",
                    "Xue Yang",
                    "Guorong Li",
                    "Jianbin Jiao",
                    "Zhenjun Han"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13128v1",
                    "http://arxiv.org/pdf/2311.13128v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13127v1/1.0",
                "title": "Toward Robust Imperceptible Perturbation against Unauthorized\n  Text-to-image Diffusion-based Synthesis",
                "year": 2023,
                "abstract": "Text-to-image diffusion models allow seamless generation of personalized\nimages from scant reference photos. Yet, these tools, in the wrong hands, can\nfabricate misleading or harmful content, endangering individuals. To address\nthis problem, existing poisoning-based approaches perturb user images in an\nimperceptible way to render them \"unlearnable\" from malicious uses. We identify\ntwo limitations of these defending approaches: i) sub-optimal due to the\nhand-crafted heuristics for solving the intractable bilevel optimization and\nii) lack of robustness against simple data transformations like Gaussian\nfiltering. To solve these challenges, we propose MetaCloak, which solves the\nbi-level poisoning problem with a meta-learning framework with an additional\ntransformation sampling process to craft transferable and robust perturbation.\nSpecifically, we employ a pool of surrogate diffusion models to craft\ntransferable and model-agnostic perturbation. Furthermore, by incorporating an\nadditional transformation process, we design a simple denoising-error\nmaximization loss that is sufficient for causing transformation-robust semantic\ndistortion and degradation in a personalized generation. Extensive experiments\non the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing\napproaches. Notably, MetaCloak can successfully fool online training services\nlike Replicate, in a black-box manner, demonstrating the effectiveness of\nMetaCloak in real-world scenarios. Our code is available at\nhttps://github.com/liuyixin-louis/MetaCloak.",
                "authors": [
                    "Yixin Liu",
                    "Chenrui Fan",
                    "Yutong Dai",
                    "Xun Chen",
                    "Pan Zhou",
                    "Lichao Sun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13127v1",
                    "http://arxiv.org/pdf/2311.13127v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13126v1/1.0",
                "title": "Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper",
                "year": 2023,
                "abstract": "This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.",
                "authors": [
                    "Chengyu Wang",
                    "Junbing Yan",
                    "Wei Zhang",
                    "Jun Huang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13126v1",
                    "http://arxiv.org/pdf/2311.13126v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13120v2/1.0",
                "title": "Multi-modal In-Context Learning Makes an Ego-evolving Scene Text\n  Recognizer",
                "year": 2023,
                "abstract": "Scene text recognition (STR) in the wild frequently encounters challenges\nwhen coping with domain variations, font diversity, shape deformations, etc. A\nstraightforward solution is performing model fine-tuning tailored to a specific\nscenario, but it is computationally intensive and requires multiple model\ncopies for various scenarios. Recent studies indicate that large language\nmodels (LLMs) can learn from a few demonstration examples in a training-free\nmanner, termed \"In-Context Learning\" (ICL). Nevertheless, applying LLMs as a\ntext recognizer is unacceptably resource-consuming. Moreover, our pilot\nexperiments on LLMs show that ICL fails in STR, mainly attributed to the\ninsufficient incorporation of contextual information from diverse samples in\nthe training stage. To this end, we introduce E$^2$STR, a STR model trained\nwith context-rich scene text sequences, where the sequences are generated via\nour proposed in-context training strategy. E$^2$STR demonstrates that a\nregular-sized model is sufficient to achieve effective ICL capabilities in STR.\nExtensive experiments show that E$^2$STR exhibits remarkable training-free\nadaptation in various scenarios and outperforms even the fine-tuned\nstate-of-the-art approaches on public benchmarks.",
                "authors": [
                    "Zhen Zhao",
                    "Jingqun Tang",
                    "Chunhui Lin",
                    "Binghong Wu",
                    "Hao Liu",
                    "Zhizhong Zhang",
                    "Xin Tan",
                    "Can Huang",
                    "Yuan Xie"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13120v2",
                    "http://arxiv.org/pdf/2311.13120v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13118v1/1.0",
                "title": "Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements",
                "year": 2023,
                "abstract": "This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.",
                "authors": [
                    "Alejandro Rodriguez Perez",
                    "Pablo Rivas"
                ],
                "url": [
                    "http://dx.doi.org/10.6084/m9.figshare.24602823.v1",
                    "http://arxiv.org/abs/2311.13118v1",
                    "http://arxiv.org/pdf/2311.13118v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL",
                    "cs.CY",
                    "cs.SI",
                    "68T50, 62H30, 91C99, 68T068T50, 62H30, 91C99, 68T01",
                    "I.2.7; I.5.4; K.4.1; K.4.2"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13117v1/1.0",
                "title": "Bile dynamics within the biliary tract and microfluidic-based bile\n  component detection: A review",
                "year": 2023,
                "abstract": "Bilestones are solid masses found in the gallbladder or biliary tract, which\nblock the normal bile flow and eventually result in severe life-threatening\ncomplications. Studies have shown that bilestone formation may be related to\nbile flow dynamics and the concentration level of bile components. The bile\nflow dynamics in the biliary tract play a critical role in disclosing the\nmechanism of bile stasis and transportation. The concentration of bile\ncomposition is closely associated with processes such as nucleation and\ncrystallization. Recently, microfluidic-based biosensors have been favored for\nmultiple advantages over traditional bench-top detection assays for their less\nsample consumption, portability, low cost, and high sensitivity for real-time\ndetection. Here, we reviewed the developments in bile dynamics study and\nmicrofluidics-based bile component detection methods. These studies may provide\nvaluable insights into the bilestone formation mechanisms and better treatment,\nalongside our opinions on the future development of in vitro lithotriptic drug\nscreening of bilestones and bile characterization tests.",
                "authors": [
                    "Tao Peng",
                    "Chenxiao Zhou",
                    "Zhexin Zhang",
                    "Yingying Liu",
                    "Xiaodong Lin",
                    "Yongqing",
                    "Yunlong Zhong",
                    "Ping Wang",
                    "Yanwei Jia"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13117v1",
                    "http://arxiv.org/pdf/2311.13117v1"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph",
                    "physics.chem-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13110v2/1.0",
                "title": "White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?",
                "year": 2023,
                "abstract": "In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .",
                "authors": [
                    "Yaodong Yu",
                    "Sam Buchanan",
                    "Druv Pai",
                    "Tianzhe Chu",
                    "Ziyang Wu",
                    "Shengbang Tong",
                    "Hao Bai",
                    "Yuexiang Zhai",
                    "Benjamin D. Haeffele",
                    "Yi Ma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13110v2",
                    "http://arxiv.org/pdf/2311.13110v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CL",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13109v1/1.0",
                "title": "Reconfigurable Image Processing Metasurfaces with Phase-Change Materials",
                "year": 2023,
                "abstract": "Optical metasurfaces have been enabling reduced footprint and power\nconsumption, as well as faster speeds, in the context of analog computing and\nimage processing. While various image processing and optical computing\nfunctionalities have been recently demonstrated using metasurfaces, most of the\nconsidered devices are static and lack reconfigurability. Yet, the ability to\ndynamically reconfigure processing operations is key for metasurfaces to be\nable to compete with practical computing systems. Here, we demonstrate a\npassive edge-detection metasurface operating in the near-infrared regime whose\nimage processing response can be drastically modified by temperature variations\nsmaller than 10{\\deg} C around a CMOS-compatible temperature of 65{\\deg} C.\nSuch reconfigurability is achieved by leveraging the insulator-to-metal phase\ntransition of a thin buried layer of vanadium dioxide which, in turn, strongly\nalters the nonlocal response of the metasurface. Importantly, this\nreconfigurability is accompanied by performance metrics - such as high\nnumerical aperture, high efficiency, isotropy, and polarization-independence -\nclose to optimal, and it is combined with a simple geometry compatible with\nlarge-scale manufacturing. Our work paves the way to a new generation of\nultra-compact, tunable, passive devices for all-optical computation, with\npotential applications in augmented reality, remote sensing and bio-medical\nimaging.",
                "authors": [
                    "Michele Cotrufo",
                    "Shaban B. Sulejman",
                    "Lukas Wesemann",
                    "Md. Ataur Rahman",
                    "Madhu Bhaskaran",
                    "Ann Roberts",
                    "Andrea Al\u00f9"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13109v1",
                    "http://arxiv.org/pdf/2311.13109v1"
                ],
                "primary_category": "physics.optics",
                "categories": [
                    "physics.optics",
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.09457v1/1.0",
                "title": "Functional Analytics for Document Ordering for Curriculum Development\n  and Comprehension",
                "year": 2023,
                "abstract": "We propose multiple techniques for automatic document order generation for\n(1) curriculum development and for (2) creation of optimal reading order for\nuse in learning, training, and other content-sequencing applications. Such\ntechniques could potentially be used to improve comprehension, identify areas\nthat need expounding, generate curricula, and improve search engine results. We\nadvance two main techniques: The first uses document similarities through\nvarious methods. The second uses entropy against the backdrop of topics\ngenerated through Latent Dirichlet Allocation (LDA). In addition, we try the\nsame methods on the summarized documents and compare them against the results\nobtained using the complete documents. Our results showed that while the\ndocument orders for our control document sets (biographies, novels, and\nWikipedia articles) could not be predicted using our methods, our test\ndocuments (textbooks, courses, journal papers, dissertations) provided more\nreliability. We also demonstrated that summarized documents were good stand-ins\nfor the complete documents for the purposes of ordering.",
                "authors": [
                    "Arturo N. Villanueva Jr.",
                    "Steven J. Simske"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.09457v1",
                    "http://arxiv.org/pdf/2312.09457v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.IR",
                    "K.3.2"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13105v1/1.0",
                "title": "Perceptual Structure in the Absence of Grounding for LLMs: The Impact of\n  Abstractedness and Subjectivity in Color Language",
                "year": 2023,
                "abstract": "The need for grounding in language understanding is an active research topic.\nPrevious work has suggested that color perception and color language appear as\na suitable test bed to empirically study the problem, given its cognitive\nsignificance and showing that there is considerable alignment between a defined\ncolor space and the feature space defined by a language model. To further study\nthis issue, we collect a large scale source of colors and their descriptions,\ncontaining almost a 1 million examples , and perform an empirical analysis to\ncompare two kinds of alignments: (i) inter-space, by learning a mapping between\nembedding space and color space, and (ii) intra-space, by means of prompting\ncomparatives between color descriptions. Our results show that while color\nspace alignment holds for monolexemic, highly pragmatic color descriptions,\nthis alignment drops considerably in the presence of examples that exhibit\nelements of real linguistic usage such as subjectivity and abstractedness,\nsuggesting that grounding may be required in such cases.",
                "authors": [
                    "Pablo Loyola",
                    "Edison Marrese-Taylor",
                    "Andres Hoyos-Idobro"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13105v1",
                    "http://arxiv.org/pdf/2311.13105v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13102v1/1.0",
                "title": "Detecting out-of-distribution text using topological features of\n  transformer-based language models",
                "year": 2023,
                "abstract": "We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.",
                "authors": [
                    "Andres Pollano",
                    "Anupam Chaudhuri",
                    "Anj Simmons"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13102v1",
                    "http://arxiv.org/pdf/2311.13102v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG",
                    "math.AT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13100v1/1.0",
                "title": "Automated Measurement of Pericoronary Adipose Tissue Attenuation and\n  Volume in CT Angiography",
                "year": 2023,
                "abstract": "Pericoronary adipose tissue (PCAT) is the deposition of fat in the vicinity\nof the coronary arteries. It is an indicator of coronary inflammation and\nassociated with coronary artery disease. Non-invasive coronary CT angiography\n(CCTA) is presently used to obtain measures of the thickness, volume, and\nattenuation of fat deposition. However, prior works solely focus on measuring\nPCAT using semi-automated approaches at the right coronary artery (RCA) over\nthe left coronary artery (LCA). In this pilot work, we developed a fully\nautomated approach for the measurement of PCAT mean attenuation and volume in\nthe region around both coronary arteries. First, we used a large subset of\npatients from the public ImageCAS dataset (n = 735) to train a 3D full\nresolution nnUNet to segment LCA and RCA. Then, we automatically measured PCAT\nin the surrounding arterial regions. We evaluated our method on a held-out test\nset of patients (n = 183) from the same dataset. A mean Dice score of 83% and\nPCAT attenuation of -73.81 $\\pm$ 12.69 HU was calculated for the RCA, while a\nmean Dice score of 81% and PCAT attenuation of -77.51 $\\pm$ 7.94 HU was\ncomputed for the LCA. To the best of our knowledge, we are the first to develop\na fully automated method to measure PCAT attenuation and volume at both the RCA\nand LCA. Our work underscores how automated PCAT measurement holds promise as a\nbiomarker for identification of inflammation and cardiac disease.",
                "authors": [
                    "Andrew M. Nguyen",
                    "Tejas Sudharshan Mathai",
                    "Liangchen Liu",
                    "Jianfei Liu",
                    "Ronald M. Summers"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13100v1",
                    "http://arxiv.org/pdf/2311.13100v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "62P10"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13095v1/1.0",
                "title": "Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications",
                "year": 2023,
                "abstract": "Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.",
                "authors": [
                    "Ha-Thanh Nguyen",
                    "Wachara Fungwacharakorn",
                    "Ken Satoh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13095v1",
                    "http://arxiv.org/pdf/2311.13095v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13092v1/1.0",
                "title": "State-Dependent Sweeping Processes: Asymptotic Behavior and Algorithmic\n  Approaches",
                "year": 2023,
                "abstract": "In this paper, we investigate the asymptotic properties of a particular class\nof state-dependent sweeping processes. While extensive research has been\nconducted on the existence and uniqueness of solutions for sweeping processes,\nthere is a scarcity of studies addressing their behavior in the limit of large\ntime. Additionally, we introduce novel algorithms designed for the resolution\nof quasi-variational inequalities. As a result, we introduce a new\nderivative-free algorithm to find zeros of nonsmooth Lipschitz continuous\nmappings with a linear convergence rate. This algorithm can be effectively used\nin nonsmooth and nonconvex optimization problems that do not possess\nnecessarily second-order differentiability conditions of the data.",
                "authors": [
                    "Samir Adly",
                    "Monica G. Cojocaru",
                    "Ba Khiet Le"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13092v1",
                    "http://arxiv.org/pdf/2311.13092v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC",
                    "28B05, 34A36, 34A60, 49J52, 49J53, 93D20"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13091v2/1.0",
                "title": "Stable Unlearnable Example: Enhancing the Robustness of Unlearnable\n  Examples via Stable Error-Minimizing Noise",
                "year": 2023,
                "abstract": "The open source of large amounts of image data promotes the development of\ndeep learning techniques. Along with this comes the privacy risk of these\nopen-source image datasets being exploited by unauthorized third parties to\ntrain deep learning models for commercial or illegal purposes. To avoid the\nabuse of public data, a poisoning-based technique, the unlearnable example, is\nproposed to significantly degrade the generalization performance of models by\nadding a kind of imperceptible noise to the data. To further enhance its\nrobustness against adversarial training, existing works leverage iterative\nadversarial training on both the defensive noise and the surrogate model.\nHowever, it still remains unknown whether the robustness of unlearnable\nexamples primarily comes from the effect of enhancement in the surrogate model\nor the defensive noise. Observing that simply removing the adversarial noise on\nthe training process of the defensive noise can improve the performance of\nrobust unlearnable examples, we identify that solely the surrogate model's\nrobustness contributes to the performance. Furthermore, we found a negative\ncorrelation exists between the robustness of defensive noise and the protection\nperformance, indicating defensive noise's instability issue. Motivated by this,\nto further boost the robust unlearnable example, we introduce stable\nerror-minimizing noise (SEM), which trains the defensive noise against random\nperturbation instead of the time-consuming adversarial perturbation to improve\nthe stability of defensive noise. Through extensive experiments, we demonstrate\nthat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,\nand ImageNet Subset in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.",
                "authors": [
                    "Yixin Liu",
                    "Kaidi Xu",
                    "Xun Chen",
                    "Lichao Sun"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13091v2",
                    "http://arxiv.org/pdf/2311.13091v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CR",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13090v1/1.0",
                "title": "On the Limitation of Diffusion Models for Synthesizing Training Datasets",
                "year": 2023,
                "abstract": "Synthetic samples from diffusion models are promising for leveraging in\ntraining discriminative models as replications of real training datasets.\nHowever, we found that the synthetic datasets degrade classification\nperformance over real datasets even when using state-of-the-art diffusion\nmodels. This means that modern diffusion models do not perfectly represent the\ndata distribution for the purpose of replicating datasets for training\ndiscriminative tasks. This paper investigates the gap between synthetic and\nreal samples by analyzing the synthetic samples reconstructed from real samples\nthrough the diffusion and reverse process. By varying the time steps starting\nthe reverse process in the reconstruction, we can control the trade-off between\nthe information in the original real data and the information added by\ndiffusion models. Through assessing the reconstructed samples and trained\nmodels, we found that the synthetic data are concentrated in modes of the\ntraining data distribution as the reverse step increases, and thus, they are\ndifficult to cover the outer edges of the distribution. Our findings imply that\nmodern diffusion models are insufficient to replicate training data\ndistribution perfectly, and there is room for the improvement of generative\nmodeling in the replication of training datasets.",
                "authors": [
                    "Shin'ya Yamaguchi",
                    "Takuma Fukuda"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13090v1",
                    "http://arxiv.org/pdf/2311.13090v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13088v1/1.0",
                "title": "Validation of Consumer-grade Digital Camera-based Human Activity\n  Evaluation for Upper Limb Exercises and Development of a Therapist-guided,\n  Automated Telerehabilitation Framework and Platform for Stroke Rehabilitation",
                "year": 2023,
                "abstract": "Timely and adequate rehabilitation is critical in facilitating post-stroke\nrecovery. However, the organization and delivery of rehabilitation are\nresource-demanding, and are only available to approximately 25% of stroke\nsurvivors in low-to-middle-income countries. Improving access to stroke\nrehabilitation services through innovative solutions is therefore urgently\nrequired. Tele-rehabilitation, which transits care to home- and community\nsettings, has emerged as a promising solution. However, current approaches\nusing video tutorial, teleconference, or other specialized devices face\ninherent shortfalls that limit their uptake. In this study, we proposed and\nvalidated the use of an open-source, markerless motion capture model with\nconsumer-grade devices to overcome these challenges. Our solution enables\nreliable measurement of the end range of motion during upper limb exercises\nwith near-perfect waveform similarity and intraclass correlation to that of the\ngold standard Kinect approach. Our multidisciplinary team developed an\nautomated telerehabilitation framework incorporating the validated markerless\ntechnique to facilitate a seamless telerehabilitation process. It enables\npersonalized rehabilitation plans with real-time feedback, and individual\nprogress reports using objective quantitative and qualitative features to\nimprove patient monitoring and management, and home-based rehabilitation\nservice uptake and compliance. This study serves as a proof-of-concept in\npreparation for the future development of a detailed model of care, and\nfeasibility, usability, and cost-effectiveness studies of an automated\ntelerehabilitation platform and framework in improving the state of post-stroke\nrehabilitation and functional outcome.",
                "authors": [
                    "Elton H. L. Yeung",
                    "Yingxian Chen",
                    "Wilton W. T. Fok",
                    "Gary K. K. Lau"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13088v1",
                    "http://arxiv.org/pdf/2311.13088v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13087v1/1.0",
                "title": "Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and\n  Optimization",
                "year": 2023,
                "abstract": "Many real-world decision processes are modeled by optimization problems whose\ndefining parameters are unknown and must be inferred from observable data. The\nPredict-Then-Optimize framework uses machine learning models to predict unknown\nparameters of an optimization problem from features before solving. Recent\nworks show that decision quality can be improved in this setting by solving and\ndifferentiating the optimization problem in the training loop, enabling\nend-to-end training with loss functions defined directly on the resulting\ndecisions. However, this approach can be inefficient and requires handcrafted,\nproblem-specific rules for backpropagation through the optimization step. This\npaper proposes an alternative method, in which optimal solutions are learned\ndirectly from the observable features by predictive models. The approach is\ngeneric, and based on an adaptation of the Learning-to-Optimize paradigm, from\nwhich a rich variety of existing techniques can be employed. Experimental\nevaluations show the ability of several Learning-to-Optimize methods to provide\nefficient, accurate, and flexible solutions to an array of challenging\nPredict-Then-Optimize problems.",
                "authors": [
                    "James Kotary",
                    "Vincenzo Di Vito",
                    "Jacob Christopher",
                    "Pascal Van Hentenryck",
                    "Ferdinando Fioretto"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13087v1",
                    "http://arxiv.org/pdf/2311.13087v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13086v1/1.0",
                "title": "Mechanistic Insights into the Hydrazine-induced Chemical Reduction\n  Pathway of Graphene Oxide",
                "year": 2023,
                "abstract": "Hydrazine stands out as the most generally used chemical-reducing agent for\nreducing graphene oxide. Despite numerous experimental and theoretical\ninvestigations into the reduction reaction, the reduction mechanism remains\nunclear. In this study, we propose that, in aqueous hydrazine solutions, both\nhydrazine and hydroxide ions could initiate the reduction of graphene oxide. We\nintroduce a chemical reaction pathway involving C-H cleavage and a\ndehydroxylation process for the reduction of graphene oxide. By utilizing\ndensity functional theory calculations, the reduction reactions mediated by\nhydrazine and hydroxide ions are separately investigated. The reaction routes\non the basal plane and edge regions of graphene oxide are discussed\nindependently. The density functional theory calculations demonstrate that the\nproposed mechanism is both thermodynamically and dynamically feasible. This\nwork might contribute to an atomic-level comprehension of a longstanding\nchallenge in the field of graphene oxide.",
                "authors": [
                    "Shu Chen",
                    "Jianqiang Guo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13086v1",
                    "http://arxiv.org/pdf/2311.13086v1"
                ],
                "primary_category": "cond-mat.dis-nn",
                "categories": [
                    "cond-mat.dis-nn",
                    "physics.chem-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13084v1/1.0",
                "title": "Contextual quantum metrology",
                "year": 2023,
                "abstract": "Quantum metrology promises higher precision measurements than classical\nmethods. Entanglement has been identified as one of quantum resources to\nenhance metrological precision. However, generating entangled states with high\nfidelity presents considerable challenges, and thus attaining metrological\nenhancement through entanglement is generally difficult. Here, we show that\ncontextuality of measurement selection can enhance metrological precision, and\nthis enhancement is attainable with a simple linear optical experiment. We call\nour methodology \"contextual quantum metrology\" (coQM). Contextuality is a\nnonclassical property known as a resource for various quantum information\nprocessing tasks. Until now, it has remained an open question whether\ncontextuality can be a resource for quantum metrology. We answer this question\nin the affirmative by showing that the coQM can elevate precision of an optical\npolarimetry by a factor of 1.4 to 6.0, much higher than the one by quantum\nFisher information, known as the limit of conventional quantum metrology. We\nachieve the contextuality-enabled enhancement with two polarization\nmeasurements which are mutually complementary, whereas, in the conventional\nmethod, some optimal measurements to achieve the precision limit are either\ntheoretically difficult to find or experimentally infeasible. These results\nhighlight that the contextuality of measurement selection is applicable in\npractice for quantum metrology.",
                "authors": [
                    "Jeongwoo Jae",
                    "Jiwon Lee",
                    "M. S. Kim",
                    "Kwang-Geol Lee",
                    "Jinhyoung Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13084v1",
                    "http://arxiv.org/pdf/2311.13084v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13078v1/1.0",
                "title": "Terminal Phase Navigation for AUV Docking: An Innovative Electromagnetic\n  Approach",
                "year": 2023,
                "abstract": "This study introduces a groundbreaking approach for real-time 3D\nlocalization, specifically focusing on achieving seamless and precise\nlocalization during an AUV's terminal guidance phase as it approaches an\nomnidirectional docking component in an automated Launch and Recovery System\n(LARS). Through the use of the AUV's magnetometer, an economical\nelectromagnetic beacon embedded in the docking station, and an advanced signal\nprocessing algorithm, this novel approach ensures the accurate localization of\nthe docking component in three dimensions without the need for direct\nline-of-sight contact. The method's real-time capabilities were rigorously\nevaluated via simulations, prototype experiments in a controlled lab setting,\nand extensive full-scale pool experiments. These assessments consistently\ndemonstrated an exceptional average positioning accuracy of under 3 cm.,\nmarking a significant advancement in AUV guidance systems.",
                "authors": [
                    "Yevgeni Gutnik",
                    "Morel Groper"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13078v1",
                    "http://arxiv.org/pdf/2311.13078v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13076v1/1.0",
                "title": "Gauged compact Q-balls and Q-shells in a multi-component $CP^N$ model",
                "year": 2023,
                "abstract": "We study a multicomponent $CP^N$ model's scalar electrodynamics. The model\ncontains Q-balls/shells, which are non-topological compact solitons with time\ndependency $e^{i\\omega t}$. Two coupled $CP^N$ models can decouple locally if\none of their $CP^N$ fields takes the vacuum value. Because of the compacton\nnature of solutions, Q-shells can shelter another compact Q-ball or Q-shell\nwithin their hollow region. Even if compactons do not overlap, they can\ninteract through the electromagnetic field. We investigate how the size of\nmulti-compacton formations is affected by electric charge. We are interested in\nstructures with non-zero or zero total net charge.",
                "authors": [
                    "P. Klimas",
                    "L. C. Kubaski",
                    "N. Sawado",
                    "S. Yanai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13076v1",
                    "http://arxiv.org/pdf/2311.13076v1"
                ],
                "primary_category": "hep-th",
                "categories": [
                    "hep-th",
                    "math-ph",
                    "math.MP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13075v1/1.0",
                "title": "Deep Audio Zooming: Beamwidth-Controllable Neural Beamformer",
                "year": 2023,
                "abstract": "Audio zooming, a signal processing technique, enables selective focusing and\nenhancement of sound signals from a specified region, attenuating others. While\ntraditional beamforming and neural beamforming techniques, centered on creating\na directional array, necessitate the designation of a singular target\ndirection, they often overlook the concept of a field of view (FOV), that\ndefines an angular area. In this paper, we proposed a simple yet effective FOV\nfeature, amalgamating all directional attributes within the user-defined field.\nIn conjunction, we've introduced a counter FOV feature capturing directional\naspects outside the desired field. Such advancements ensure refined sound\ncapture, particularly emphasizing the FOV's boundaries, and guarantee the\nenhanced capture of all desired sound sources inside the user-defined field.\nThe results from the experiment demonstrate the efficacy of the introduced\nangular FOV feature and its seamless incorporation into a low-power subband\nmodel suited for real-time applica?tions.",
                "authors": [
                    "Meng Yu",
                    "Dong Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13075v1",
                    "http://arxiv.org/pdf/2311.13075v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13074v1/1.0",
                "title": "Non-equilibrium dynamics of topological defects in the 3d O(2) model",
                "year": 2023,
                "abstract": "We present a study of the 3d O(2) non-linear $\\sigma$-model on the lattice,\nwhich exhibits topological defects in the form of vortices. They tend to\norganize into vortex lines that bear close analogies with global cosmic\nstrings. Therefore, this model serves as a testbed for studying the dynamics of\ntopological defects. It undergoes a second order phase transition, hence it is\nappropriate for investigating the Kibble-Zurek mechanism. In this regard, we\nexplore the persistence of topological defects when the temperature is rapidly\nreduced from above to below the critical temperature; this cooling (or\n\"quenching\") process takes the system out of equilibrium. We probe a wide range\nof inverse cooling rates $\\tau_{\\rm Q}$ and final temperatures, employing\ndistinct Monte Carlo algorithms. The results consistently show that the density\nof persisting topological defects follows a power-law in $\\tau_{\\rm Q}$, in\nagreement with Zurek's conjecture. On the other hand, at this point our results\ndo not confirm Zurek's prediction for the exponent in this power-law, but its\nfinal test is still under investigation.",
                "authors": [
                    "Edgar L\u00f3pez-Contreras",
                    "Jaime Fabi\u00e1n Nieto Castellanos",
                    "El\u00edas Natanael Polanco-Eu\u00e1n",
                    "Wolfgang Bietenholz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13074v1",
                    "http://arxiv.org/pdf/2311.13074v1"
                ],
                "primary_category": "hep-lat",
                "categories": [
                    "hep-lat",
                    "cond-mat.stat-mech"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14737v1/1.0",
                "title": "Positional Description Matters for Transformers Arithmetic",
                "year": 2023,
                "abstract": "Transformers, central to the successes in modern Natural Language Processing,\noften falter on arithmetic tasks despite their vast capabilities --which\nparadoxically include remarkable coding abilities. We observe that a crucial\nchallenge is their naive reliance on positional information to solve arithmetic\nproblems with a small number of digits, leading to poor performance on larger\nnumbers. Herein, we delve deeper into the role of positional encoding, and\npropose several ways to fix the issue, either by modifying the positional\nencoding directly, or by modifying the representation of the arithmetic task to\nleverage standard positional encoding differently. We investigate the value of\nthese modifications for three tasks: (i) classical multiplication, (ii) length\nextrapolation in addition, and (iii) addition in natural language context. For\n(i) we train a small model on a small dataset (100M parameters and 300k\nsamples) with remarkable aptitude in (direct, no scratchpad) 15 digits\nmultiplication and essentially perfect up to 12 digits, while usual training in\nthis context would give a model failing at 4 digits multiplication. In the\nexperiments on addition, we use a mere 120k samples to demonstrate: for (ii)\nextrapolation from 10 digits to testing on 12 digits numbers while usual\ntraining would have no extrapolation, and for (iii) almost perfect accuracy up\nto 5 digits while usual training would be correct only up to 3 digits (which is\nessentially memorization with a training set of 120k samples).",
                "authors": [
                    "Ruoqi Shen",
                    "S\u00e9bastien Bubeck",
                    "Ronen Eldan",
                    "Yin Tat Lee",
                    "Yuanzhi Li",
                    "Yi Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14737v1",
                    "http://arxiv.org/pdf/2311.14737v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13071v1/1.0",
                "title": "Tail Asymptotics of the Signature of various stochastic processes and\n  its connection to the Quadratic Variation",
                "year": 2023,
                "abstract": "The signature of a path is a sequence, whose $n$-th term contains $n$-th\norder iterated integrals of the path. These iterated integrals of sample paths\nof stochastic processes arise naturally when studying solutions of differential\nequation driven by those processes. This paper extends the work of Boedihardjo\nand Geng (arXiv:1609.08111) who found a connection between the signature of a\n$d$-dimensional Brownian motion and the time elapsed, which equals to the\nquadratic variation of Brownian motion. We prove this connection for a more\ngeneral class of processes, namely for It\\^o signature of semimartingales. We\nalso establish a connection between the fWIS Signature of fractional Brownian\nmotion and its Hurst parameter. We propose a conjecture for extension to\nmultidimensional space.",
                "authors": [
                    "Martin Albert Gb\u00far"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13071v1",
                    "http://arxiv.org/pdf/2311.13071v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "60L10 (Primary) 60H05, 60H40 (Secondary)"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13066v1/1.0",
                "title": "Gaussian-basis many-body theory calculations of positron binding to\n  negative ions and atoms",
                "year": 2023,
                "abstract": "Positron binding energies in the negative ions H$^-$, F$^-$, Cl$^-$ and\nBr$^-$, and the closed-shell atoms Be, Mg, Zn and Ca, are calculated via a\nmany-body theory approach developed by the authors [J.~Hofierka \\emph{et al.}\nNature~{\\bf 608}, 688-693 (2022)]. Specifically, the Dyson equation is solved\nusing a Gaussian basis, with the positron self energy constructed from three\ninfinite classes of diagrams that account for the strong positron-atom\ncorrelations that characterise the system including the positron-induced\npolarization of the electron cloud, screening of the electron-positron Coulomb\ninteraction, virtual-positronium formation and electron-hole and positron-hole\ninteractions. For the negative ions, binding occurs at the static level of\ntheory, and the correlations are found to enhance the binding energies by\n$\\sim$25--50\\%, yielding results in good agreement with ($\\lesssim$5\\% larger\nthan) calculations from a number of distinct methods. For the atoms, for which\nbinding is enabled exclusively by correlations, most notably virtual-Ps\nformation, the binding energies are found to be of similar order to (but\n$\\sim$10--30\\% larger than) relativistic coupled-cluster calculations of [C.\nHarabati, V.~A.~Dzuba and V.~V. Flambaum, Phys.~Rev.~A {\\bf 89}, 022517\n(2014)], both of which are systematically larger than stochastic variational\ncalculations of [M.~Bromley and J.~Mitroy, Phys.~Rev.~A {\\bf 73} (2005);\nJ.~Mitroy, J.~At.~Mol.~Sci.~{\\bf 1}, 275 (2010)].",
                "authors": [
                    "J. Hofierka",
                    "B. Cunningham",
                    "C. M. Rawlins",
                    "C. H. Patterson",
                    "D. G. Green"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13066v1",
                    "http://arxiv.org/pdf/2311.13066v1"
                ],
                "primary_category": "physics.atom-ph",
                "categories": [
                    "physics.atom-ph",
                    "physics.chem-ph",
                    "physics.comp-ph",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13064v1/1.0",
                "title": "Voltage Control of Electromagnetic Properties in Antiferromagnetic\n  Materials",
                "year": 2023,
                "abstract": "Dynamic modulation of electromagnetic responses is theoretically examined in\ndielectric antiferromagnets. While both magneto-electric and magneto-elastic\ncoupling can achieve robust electrical control of magnetic anisotropy, the\nlatter is considered in a bilayer structure with a piezoelectric material.\nNumerical calculations based on the frequency-dependent permeability tensor\nclearly illustrate that the anisotropy profile in the typical uniaxial or\nbiaxial antiferromagnets such as NiO and Cr2O3 can be modified sufficiently to\ninduce a shift in the resonance frequency by as much as tens of percent in the\nsub-mm wavelength range (thus, an electrically tunable bandwidth over 10's of\nGHz). The polarization of the electromagnetic response is also affected due to\nthe anisotropic nature of the effect, offering a possibility to encode the\nsignal. The intrinsic delay in switching may be minimized to the ns level by\nusing a sufficiently thin antiferromagnets. Application to specific devices\nsuch as a band-pass filter further illustrates the validity of the concept.",
                "authors": [
                    "Xinyi Xu",
                    "Yuriy G. Semenov",
                    "Ki Wook Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13064v1",
                    "http://arxiv.org/pdf/2311.13064v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13063v2/1.0",
                "title": "From Classification to Clinical Insights: Towards Analyzing and\n  Reasoning About Mobile and Behavioral Health Data With Large Language Models",
                "year": 2023,
                "abstract": "Passively collected behavioral health data from ubiquitous sensors holds\nsignificant promise to provide mental health professionals insights from\npatient's daily lives; however, developing analysis tools to use this data in\nclinical practice requires addressing challenges of generalization across\ndevices and weak or ambiguous correlations between the measured signals and an\nindividual's mental health. To address these challenges, we take a novel\napproach that leverages large language models (LLMs) to synthesize clinically\nuseful insights from multi-sensor data. We develop chain of thought prompting\nmethods that use LLMs to generate reasoning about how trends in data such as\nstep count and sleep relate to conditions like depression and anxiety. We first\ndemonstrate binary depression classification with LLMs achieving accuracies of\n61.1% which exceed the state of the art. While it is not robust for clinical\nuse, this leads us to our key finding: even more impactful and valued than\nclassification is a new human-AI collaboration approach in which clinician\nexperts interactively query these tools and combine their domain expertise and\ncontext about the patient with AI generated reasoning to support clinical\ndecision-making. We find models like GPT-4 correctly reference numerical data\n75% of the time, and clinician participants express strong interest in using\nthis approach to interpret self-tracking data.",
                "authors": [
                    "Zachary Englhardt",
                    "Chengqian Ma",
                    "Margaret E. Morris",
                    "Xuhai \"Orson\" Xu",
                    "Chun-Cheng Chang",
                    "Lianhui Qin",
                    "Daniel McDuff",
                    "Xin Liu",
                    "Shwetak Patel",
                    "Vikram Iyer"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13063v2",
                    "http://arxiv.org/pdf/2311.13063v2"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13061v1/1.0",
                "title": "Attribution and Alignment: Effects of Local Context Repetition on\n  Utterance Production and Comprehension in Dialogue",
                "year": 2023,
                "abstract": "Language models are often used as the backbone of modern dialogue systems.\nThese models are pre-trained on large amounts of written fluent language.\nRepetition is typically penalised when evaluating language model generations.\nHowever, it is a key component of dialogue. Humans use local and partner\nspecific repetitions; these are preferred by human users and lead to more\nsuccessful communication in dialogue. In this study, we evaluate (a) whether\nlanguage models produce human-like levels of repetition in dialogue, and (b)\nwhat are the processing mechanisms related to lexical re-use they use during\ncomprehension. We believe that such joint analysis of model production and\ncomprehension behaviour can inform the development of cognitively inspired\ndialogue generation systems.",
                "authors": [
                    "Aron Molnar",
                    "Jaap Jumelet",
                    "Mario Giulianelli",
                    "Arabella Sinclair"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13061v1",
                    "http://arxiv.org/pdf/2311.13061v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13058v1/1.0",
                "title": "Self-Supervised Music Source Separation Using Vector-Quantized Source\n  Category Estimates",
                "year": 2023,
                "abstract": "Music source separation is focused on extracting distinct sonic elements from\ncomposite tracks. Historically, many methods have been grounded in supervised\nlearning, necessitating labeled data, which is occasionally constrained in its\ndiversity. More recent methods have delved into N-shot techniques that utilize\none or more audio samples to aid in the separation. However, a challenge with\nsome of these methods is the necessity for an audio query during inference,\nmaking them less suited for genres with varied timbres and effects. This paper\noffers a proof-of-concept for a self-supervised music source separation system\nthat eliminates the need for audio queries at inference time. In the training\nphase, while it adopts a query-based approach, we introduce a modification by\nsubstituting the continuous embedding of query audios with Vector Quantized\n(VQ) representations. Trained end-to-end with up to N classes as determined by\nthe VQ's codebook size, the model seeks to effectively categorise instrument\nclasses. During inference, the input is partitioned into N sources, with some\npotentially left unutilized based on the mix's instrument makeup. This\nmethodology suggests an alternative avenue for considering source separation\nacross diverse music genres. We provide examples and additional results online.",
                "authors": [
                    "Marco Pasini",
                    "Stefan Lattner",
                    "George Fazekas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13058v1",
                    "http://arxiv.org/pdf/2311.13058v1"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13057v2/1.0",
                "title": "The HaLLMark Effect: Supporting Provenance and Transparent Use of Large\n  Language Models in Writing through Interactive Visualization",
                "year": 2023,
                "abstract": "The use of Large Language Models (LLMs) for writing has sparked controversy\nboth among readers and writers. On one hand, writers are concerned that LLMs\nwill deprive them of agency and ownership, and readers are concerned about\nspending their time on text generated by soulless machines. On the other hand,\nwriters who genuinely want to use LLMs must conform to publisher policies for\nAI-assisted writing, and readers need assurance that a text has been verified\nby a human. We argue that a system that captures the provenance of interaction\nwith an LLM can help writers retain their agency, conform to policies, and\ncommunicate their use of AI to publishers and readers transparently. Thus we\npropose HaLLMark, a tool for facilitating and visualizing writers' interaction\nwith LLMs. We evaluated HaLLMark with 13 creative writers, and found that it\nhelped them retain a sense of control and ownership of the written text.",
                "authors": [
                    "Md Naimul Hoque",
                    "Tasfia Mashiat",
                    "Bhavya Ghai",
                    "Cecilia Shelton",
                    "Fanny Chevalier",
                    "Kari Kraus",
                    "Niklas Elmqvist"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13057v2",
                    "http://arxiv.org/pdf/2311.13057v2"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13053v1/1.0",
                "title": "Beyond Text: Unveiling Multimodal Proficiency of Large Language Models\n  with MultiAPI Benchmark",
                "year": 2023,
                "abstract": "The proliferation of Large Language Models like ChatGPT has significantly\nadvanced language understanding and generation, impacting a broad spectrum of\napplications. However, these models predominantly excel in text-based tasks,\noverlooking the complexity of real-world multimodal information. This study\nintroduces MultiAPI, a pioneering comprehensive large-scale API benchmark\ndataset aimed at expanding LLMs' proficiency in multimodal contexts. Developed\ncollaboratively through ChatGPT, MultiAPI consists of 235 diverse API calls and\n2,038 contextual prompts, offering a unique platform evaluation of\ntool-augmented LLMs handling multimodal tasks. Through comprehensive\nexperiments, our findings reveal that while LLMs demonstrate proficiency in API\ncall decision-making, they face challenges in domain identification, function\nselection, and argument generation. What's more, we surprisingly notice that\nauxiliary context can actually impair the performance. An in-depth error\nanalysis paves the way for a new paradigm to address these challenges,\nsuggesting a potential direction for future LLM research.",
                "authors": [
                    "Xiao Liu",
                    "Jianfeng Lin",
                    "Jiawei Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13053v1",
                    "http://arxiv.org/pdf/2311.13053v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13052v1/1.0",
                "title": "Novel OCT mosaicking pipeline with Feature- and Pixel-based registration",
                "year": 2023,
                "abstract": "High-resolution Optical Coherence Tomography (OCT) images are crucial for\nophthalmology studies but are limited by their relatively narrow field of view\n(FoV). Image mosaicking is a technique for aligning multiple overlapping images\nto obtain a larger FoV. Current mosaicking pipelines often struggle with\nsubstantial noise and considerable displacement between the input sub-fields.\nIn this paper, we propose a versatile pipeline for stitching multi-view\nOCT/OCTA \\textit{en face} projection images. Our method combines the strengths\nof learning-based feature matching and robust pixel-based registration to align\nmultiple images effectively. Furthermore, we advance the application of a\ntrained foundational model, Segment Anything Model (SAM), to validate\nmosaicking results in an unsupervised manner. The efficacy of our pipeline is\nvalidated using an in-house dataset and a large public dataset, where our\nmethod shows superior performance in terms of both accuracy and computational\nefficiency. We also made our evaluation tool for image mosaicking and the\ncorresponding pipeline publicly available at\n\\url{https://github.com/MedICL-VU/OCT-mosaicking}.",
                "authors": [
                    "Jiacheng Wang",
                    "Hao Li",
                    "Dewei Hu",
                    "Yuankai K. Tao",
                    "Ipek Oguz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13052v1",
                    "http://arxiv.org/pdf/2311.13052v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13051v1/1.0",
                "title": "Latent Lab: Large Language Models for Knowledge Exploration",
                "year": 2023,
                "abstract": "This paper investigates the potential of AI models, particularly large\nlanguage models (LLMs), to support knowledge exploration and augment human\ncreativity during ideation. We present \"Latent Lab\" an interactive tool for\ndiscovering connections among MIT Media Lab research projects, emphasizing\n\"exploration\" over search. The work offers insights into collaborative AI\nsystems by addressing the challenges of organizing, searching, and synthesizing\ncontent. In a user study, the tool's success was evaluated based on its ability\nto introduce users to an unfamiliar knowledge base, ultimately setting the\ngroundwork for the ongoing advancement of human-AI knowledge exploration\nsystems.",
                "authors": [
                    "Kevin Dunnell",
                    "Trudy Painter",
                    "Andrew Stoddard",
                    "Andy Lippman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13051v1",
                    "http://arxiv.org/pdf/2311.13051v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13050v1/1.0",
                "title": "Multi-fidelity Bayesian Optimization in Engineering Design",
                "year": 2023,
                "abstract": "Resided at the intersection of multi-fidelity optimization (MFO) and Bayesian\noptimization (BO), MF BO has found a niche in solving expensive engineering\ndesign optimization problems, thanks to its advantages in incorporating\nphysical and mathematical understandings of the problems, saving resources,\naddressing exploitation-exploration trade-off, considering uncertainty, and\nprocessing parallel computing. The increasing number of works dedicated to MF\nBO suggests the need for a comprehensive review of this advanced optimization\ntechnique. In this paper, we survey recent developments of two essential\ningredients of MF BO: Gaussian process (GP) based MF surrogates and acquisition\nfunctions. We first categorize the existing MF modeling methods and MFO\nstrategies to locate MF BO in a large family of surrogate-based optimization\nand MFO algorithms. We then exploit the common properties shared between the\nmethods from each ingredient of MF BO to describe important GP-based MF\nsurrogate models and review various acquisition functions. By doing so, we\nexpect to provide a structured understanding of MF BO. Finally, we attempt to\nreveal important aspects that require further research for applications of MF\nBO in solving intricate yet important design optimization problems, including\nconstrained optimization, high-dimensional optimization, optimization under\nuncertainty, and multi-objective optimization.",
                "authors": [
                    "Bach Do",
                    "Ruda Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13050v1",
                    "http://arxiv.org/pdf/2311.13050v1"
                ],
                "primary_category": "cs.CE",
                "categories": [
                    "cs.CE",
                    "cs.LG",
                    "math.OC",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13044v1/1.0",
                "title": "Transferred Thin Film Lithium Niobate as Millimeter Wave Acoustic Filter\n  Platforms",
                "year": 2023,
                "abstract": "This paper reports the first high-performance acoustic filters toward\nmillimeter wave (mmWave) bands using transferred single-crystal thin film\nlithium niobate (LiNbO3). By transferring LiNbO3 on the top of silicon (Si) and\nsapphire (Al2O3) substrates with an intermediate amorphous Si (aSi) bonding and\nsacrificial layer, we demonstrate compact acoustic filters with record-breaking\nperformance beyond 20 GHz. In the LN-aSi-Al2O3 platform, the third-order ladder\nfilter exhibits low insertion loss (IL) of 1.62 dB and 3-dB fractional\nbandwidth (FBW) of 19.8% at 22.1 GHz, while in the LN-aSi-Si platform, the\nfilter shows low IL of 2.38 dB and FBW of 18.2% at 23.5 GHz. Material analysis\nvalidates the great crystalline quality of the stacks. The high-resolution\nx-ray diffraction (HRXRD) shows full width half maximum (FWHM) of 53 arcsec for\nAl2O3 and 206 arcsec for Si, both remarkably low compared to piezoelectric thin\nfilms of similar thickness. The reported results bring the state-of-the-art\n(SoA) of compact acoustic filters to much higher frequencies, and highlight\ntransferred LiNbO3 as promising platforms for mmWave filters in future wireless\nfront ends.",
                "authors": [
                    "Omar Barrera",
                    "Sinwoo Cho",
                    "Kenny Hyunh",
                    "Jack Kramer",
                    "Michael Liao",
                    "Vakhtang Chulukhadze",
                    "Lezli Matto",
                    "Mark S. Goorsky",
                    "Ruochen Lu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13044v1",
                    "http://arxiv.org/pdf/2311.13044v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13043v1/1.0",
                "title": "FedCPC: An Effective Federated Contrastive Learning Method for Privacy\n  Preserving Early-Stage Alzheimer's Speech Detection",
                "year": 2023,
                "abstract": "The early-stage Alzheimer's disease (AD) detection has been considered an\nimportant field of medical studies. Like traditional machine learning methods,\nspeech-based automatic detection also suffers from data privacy risks because\nthe data of specific patients are exclusive to each medical institution. A\ncommon practice is to use federated learning to protect the patients' data\nprivacy. However, its distributed learning process also causes performance\nreduction. To alleviate this problem while protecting user privacy, we propose\na federated contrastive pre-training (FedCPC) performed before federated\ntraining for AD speech detection, which can learn a better representation from\nraw data and enables different clients to share data in the pre-training and\ntraining stages. Experimental results demonstrate that the proposed methods can\nachieve satisfactory performance while preserving data privacy.",
                "authors": [
                    "Wenqing Wei",
                    "Zhengdong Yang",
                    "Yuan Gao",
                    "Jiyi Li",
                    "Chenhui Chu",
                    "Shogo Okada",
                    "Sheng Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13043v1",
                    "http://arxiv.org/pdf/2311.13043v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13041v1/1.0",
                "title": "Fast Adaptive Optics for High-Dimensional Quantum Communications in\n  Turbulent Channels",
                "year": 2023,
                "abstract": "Quantum Key Distribution (QKD) promises a provably secure method to transmit\ninformation from one party to another. Free-space QKD allows for this\ninformation to be sent over great distances and in places where fibre-based\ncommunications cannot be implemented, such as ground-satellite. The primary\nlimiting factor for free-space links is the effect of atmospheric turbulence,\nwhich can result in significant error rates and increased losses in QKD\nchannels. Here, we employ the use of a high-speed Adaptive Optics (AO) system\nto make real-time corrections to the wavefront distortions on spatial modes\nthat are used for high-dimensional QKD in our turbulent channel. First, we\ndemonstrate the effectiveness of the AO system in improving the coupling\nefficiency of a Gaussian mode that has propagated through turbulence. Through\nprocess tomography, we show that our system is capable of significantly\nreducing the crosstalk of spatial modes in the channel. Finally, we show that\nemploying AO reduces the quantum dit error rate for a high-dimensional orbital\nangular momentum-based QKD protocol, allowing for secure communication in a\nchannel where it would otherwise be impossible. These results are promising for\nestablishing long-distance free-space QKD systems.",
                "authors": [
                    "Lukas Scarfe",
                    "Felix Hufnagel",
                    "Manuel F. Ferrer-Garcia",
                    "Alessio D'Errico",
                    "Khabat Heshami",
                    "Ebrahim Karimi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13041v1",
                    "http://arxiv.org/pdf/2311.13041v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "physics.optics"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13037v1/1.0",
                "title": "Strong Gravity Extruding Peaks in Speed of Sound Profiles of Massive\n  Neutron Stars",
                "year": 2023,
                "abstract": "The speed of sound squared (SSS) $s^2$ in massive neutron stars (NSs)\ncharacterizes not only the stiffness of supradense neutron-rich matter within\nbut also equivalently properties of the curved geometry due to the strong-field\ngravity and matter-geometry coupling. A peaked density or radius profile of\n$s^2$ has been predicted for massive NSs using various NS Equation of State\n(EOS) models. However, the nature, cause, location and size of the peak in\n$s^2$ profiles are still very EOS model dependent. In this work, we investigate\nsystematically $s^2$ profiles in massive NSs in a new approach that is\nindependent of the nuclear EOS model and without any presumption about the NS\nstructure or composition. In terms of the small quantities (reduced radius, the\nenergy density and pressure scaled by their central values), we perform\ndouble-element perturbative expansions in solving perturbatively the scaled\nTolman--Oppenheimer--Volkoff (TOV) equations and analyzing $s^2$ profiles from\nthe Newtonian limit to the general relativistic (GR) case. The GR term in the\nTOV equations plays a twofold role: it compresses NS matter and modifies the\npressure/energy density ratio from small values in Newtonian stars showing no\n$s^2$ peak to large ones for massive NSs possessing a peak in their $s^2$\nprofiles, and eventually takes away the peak in extremely compact/massive NSs\napproaching the causality limit. These features revealed from our analyses are\nuniversal as they are intrinsic properties of the GR stellar structure\nequations independent of the still very uncertain EOS of supradense\nneutron-rich matter in NSs.",
                "authors": [
                    "Bao-Jun Cai",
                    "Bao-An Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13037v1",
                    "http://arxiv.org/pdf/2311.13037v1"
                ],
                "primary_category": "nucl-th",
                "categories": [
                    "nucl-th",
                    "astro-ph.HE",
                    "astro-ph.SR",
                    "gr-qc",
                    "nucl-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13029v1/1.0",
                "title": "Systematic word meta-sense extension",
                "year": 2023,
                "abstract": "The meaning of polysemous words often varies in a highly productive yet\npredictable way. Generalizing the regularity between conventional senses to\nderive novel word meaning is crucial for automated processing of non-literal\nlanguage uses such as figurative expressions. We introduce a novel task called\nsystematic word meta-sense extension (SWORME) to test and improve language\nmodels' ability to extend word meaning to denote new semantic domains (also\ncalled meta-senses) that bear regular semantic relations with existing senses.\nWe found that language models prefer incremental lexical semantic change toward\nconceptually similar meta-senses such as logical metonymy, and are much worse\nat predicting highly non-literal meaning extensions such as metaphors. We\npropose a novel analogy-based method of word meaning extension, and show that\nit effectively improves language model systematicity in making both gradual and\nradical types of meta-sense extension. We further demonstrate that learning\nsystematic meta-sense extensions benefits language models on multiple\nbenchmarks of figurative language understanding.",
                "authors": [
                    "Lei Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13029v1",
                    "http://arxiv.org/pdf/2311.13029v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13028v1/1.0",
                "title": "DMLR: Data-centric Machine Learning Research -- Past, Present and Future",
                "year": 2023,
                "abstract": "Drawing from discussions at the inaugural DMLR workshop at ICML 2023 and\nmeetings prior, in this report we outline the relevance of community engagement\nand infrastructure development for the creation of next-generation public\ndatasets that will advance machine learning science. We chart a path forward as\na collective effort to sustain the creation and maintenance of these datasets\nand methods towards positive scientific, societal and business impact.",
                "authors": [
                    "Luis Oala",
                    "Manil Maskey",
                    "Lilith Bat-Leah",
                    "Alicia Parrish",
                    "Nezihe Merve G\u00fcrel",
                    "Tzu-Sheng Kuo",
                    "Yang Liu",
                    "Rotem Dror",
                    "Danilo Brajovic",
                    "Xiaozhe Yao",
                    "Max Bartolo",
                    "William A Gaviria Rojas",
                    "Ryan Hileman",
                    "Rainier Aliment",
                    "Michael W. Mahoney",
                    "Meg Risdal",
                    "Matthew Lease",
                    "Wojciech Samek",
                    "Debojyoti Dutta",
                    "Curtis G Northcutt",
                    "Cody Coleman",
                    "Braden Hancock",
                    "Bernard Koch",
                    "Girmaw Abebe Tadesse",
                    "Bojan Karla\u0161",
                    "Ahmed Alaa",
                    "Adji Bousso Dieng",
                    "Natasha Noy",
                    "Vijay Janapa Reddi",
                    "James Zou",
                    "Praveen Paritosh",
                    "Mihaela van der Schaar",
                    "Kurt Bollacker",
                    "Lora Aroyo",
                    "Ce Zhang",
                    "Joaquin Vanschoren",
                    "Isabelle Guyon",
                    "Peter Mattson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13028v1",
                    "http://arxiv.org/pdf/2311.13028v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.DC",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13025v1/1.0",
                "title": "Deformation Dynamics of Nanopores upon Water Imbibition",
                "year": 2023,
                "abstract": "Capillarity-driven transport in nanoporous solids is ubiquitous in nature and\nis of increasing importance for the functionality of modern liquid-infused\nengineering materials. During imbibition, highly curved menisci are driven by\nnegative Laplace pressures of several hundred atmospheres, exerting an enormous\ncontractile load on an increasing portion of the porous matrix. Due to the\nchallenge of simultaneously monitoring imbibition and deformation with high\nspatial resolution, the resulting coupling of solid elasticity to liquid\ncapillarity has remained largely unexplored. Here, we study water imbibition in\nmesoporous silica using optical imaging, gravimetry, and high-resolution\ndilatometry. In contrast to an expected Laplace pressure-induced contraction,\nwe find a square-root-of-time expansion and an additional abrupt length\nincrease when the menisci reach the top surface. The final expansion is absent\nwhen we stop the imbibition front inside the porous medium in a dynamic\nimbibition-evaporation equilibrium, as is typical for water transport and\ntranspiration in plants. These peculiar deformation behaviors are validated by\nsingle-nanopore molecular dynamics simulations and described by a continuum\nmodel that highlights the importance of expansive surface stresses at the pore\nwalls (Bangham effect) and the buildup or release of contractile Laplace\npressures as nanoscale menisci collectively advance, arrest, or disappear. Our\nmodel predicts that these observations are valid not only for water imbibition\nin silica, but for any imbibition process in nanopores, regardless of the\nliquid/solid combination. This also suggests that simple deformation\nmeasurements can be used to quantify surface stresses and Laplace pressures or\ntransport in a wide variety of natural and artificial porous media.",
                "authors": [
                    "Juan Sanchez",
                    "Lars Dammann",
                    "Laura Gallardo",
                    "Zhuoqing Li",
                    "Michael Fr\u00f6ba",
                    "Robert Meissner",
                    "Howard A. Stone",
                    "Patrick Huber"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13025v1",
                    "http://arxiv.org/pdf/2311.13025v1"
                ],
                "primary_category": "cond-mat.soft",
                "categories": [
                    "cond-mat.soft",
                    "cond-mat.mes-hall",
                    "cond-mat.mtrl-sci",
                    "physics.app-ph",
                    "physics.flu-dyn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13022v1/1.0",
                "title": "Unsupervised Multimodal Surface Registration with Geometric Deep\n  Learning",
                "year": 2023,
                "abstract": "This paper introduces GeoMorph, a novel geometric deep-learning framework\ndesigned for image registration of cortical surfaces. The registration process\nconsists of two main steps. First, independent feature extraction is performed\non each input surface using graph convolutions, generating low-dimensional\nfeature representations that capture important cortical surface\ncharacteristics. Subsequently, features are registered in a deep-discrete\nmanner to optimize the overlap of common structures across surfaces by learning\ndisplacements of a set of control points. To ensure smooth and biologically\nplausible deformations, we implement regularization through a deep conditional\nrandom field implemented with a recurrent neural network. Experimental results\ndemonstrate that GeoMorph surpasses existing deep-learning methods by achieving\nimproved alignment with smoother deformations. Furthermore, GeoMorph exhibits\ncompetitive performance compared to classical frameworks. Such versatility and\nrobustness suggest strong potential for various neuroscience applications.",
                "authors": [
                    "Mohamed A. Suliman",
                    "Logan Z. J. Williams",
                    "Abdulah Fawaz",
                    "Emma C. Robinson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13022v1",
                    "http://arxiv.org/pdf/2311.13022v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13020v1/1.0",
                "title": "Understanding the Effect of Chiral NN Parametrization on Nuclear Shapes\n  From an Ab Initio Perspective",
                "year": 2023,
                "abstract": "The ab initio symmetry-adapted no-core shell model naturally describes\nnuclear deformation and collectivity, and is therefore well-suited to studying\nthe dynamics and coexistence of shapes in atomic nuclei. For the first time, we\nanalyze how these features in low-lying states of 6Li and 12C are impacted by\nthe underlying realistic nucleon-nucleon interaction. We find that the\ninteraction parametrization has a notable but limited effect on collective\nshapes in the lowest 6Li and 12C states, while collective structures in the\nexcited 2+ state of 12C are significantly more sensitive to the interaction\nparameters and exhibits emergent shape coexistence.",
                "authors": [
                    "Kevin S. Becker",
                    "Kristina D. Launey",
                    "Andreas Ekstr\u00f6m",
                    "Grigor H. Sargsyan",
                    "Darin C. Mumma",
                    "Tom\u00e1\u0161 Dytrych",
                    "Daniel Langr",
                    "Jerry P. Draayer"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13020v1",
                    "http://arxiv.org/pdf/2311.13020v1"
                ],
                "primary_category": "nucl-th",
                "categories": [
                    "nucl-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13019v1/1.0",
                "title": "Unveiling the cosmic dawn and epoch of reionization using cosmic 21-cm\n  signal",
                "year": 2023,
                "abstract": "The cosmological 21-cm signal from neutral hydrogen, which is considered as a\npromising tool, is being used to observe and study the cosmic dawn (CD) and\nepoch of reionization (EoR). A significant part of this thesis focuses on the\nsemi-analytical modeling of the global HI 21-cm signal from CD considering\nseveral physical processes. Further, it investigates the nature of galaxies\nthat dominate during CD and EoR using current available observations. In our\nwork, we study the redshift evolution of the primordial magnetic field (PMF)\nduring the dark ages and cosmic dawn, and prospects of constraining it in light\nof EDGES 21-cm signal in the `colder IGM' background. We find that the IGM\nheating rate due to the PMF enhances compared to the standard scenario.\nHowever, PMF is an unlikely candidate for explaining the rise of the EDGES\nabsorption signal at lower redshift. We further consider, in detail, the\nheating of the IGM owing to cosmic ray protons generated by the supernovae from\nboth early Pop~III and Pop~II stars. We show that the EDGES signal can be well\nfitted by the cosmic ray heating along with the Lyman-$\\alpha$ coupling and the\ndark matter-baryon interaction. We, further, explore the conditions by which\nthe EDGES detection is consistent with current reionization and\npost-reionization observations. By coupling a physically motivated source model\nderived from radiative transfer hydrodynamic simulations of reionization to a\nMCMC sampler, we find that high contribution from low-mass halos along with\nhigh photon escape fractions are required to simultaneously reproduce the\nexisting constraints. With the extreme effort in building more advanced and\nsophisticated telescopes, the future 21-cm signal detection would be able to\nprovide better constraints on the amplitude of PMF and the efficiencies on\ncosmic ray protons, and consequently on early star formation rates.",
                "authors": [
                    "Ankita Bera"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13019v1",
                    "http://arxiv.org/pdf/2311.13019v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.17894v1/1.0",
                "title": "Learning and Controlling Silicon Dopant Transitions in Graphene using\n  Scanning Transmission Electron Microscopy",
                "year": 2023,
                "abstract": "We introduce a machine learning approach to determine the transition dynamics\nof silicon atoms on a single layer of carbon atoms, when stimulated by the\nelectron beam of a scanning transmission electron microscope (STEM). Our method\nis data-centric, leveraging data collected on a STEM. The data samples are\nprocessed and filtered to produce symbolic representations, which we use to\ntrain a neural network to predict transition probabilities. These learned\ntransition dynamics are then leveraged to guide a single silicon atom\nthroughout the lattice to pre-determined target destinations. We present\nempirical analyses that demonstrate the efficacy and generality of our\napproach.",
                "authors": [
                    "Max Schwarzer",
                    "Jesse Farebrother",
                    "Joshua Greaves",
                    "Ekin Dogus Cubuk",
                    "Rishabh Agarwal",
                    "Aaron Courville",
                    "Marc G. Bellemare",
                    "Sergei Kalinin",
                    "Igor Mordatch",
                    "Pablo Samuel Castro",
                    "Kevin M. Roccapriore"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.17894v1",
                    "http://arxiv.org/pdf/2311.17894v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall",
                    "cond-mat.mtrl-sci",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13016v1/1.0",
                "title": "Image-Based Soil Organic Carbon Remote Sensing from Satellite Images\n  with Fourier Neural Operator and Structural Similarity",
                "year": 2023,
                "abstract": "Soil organic carbon (SOC) sequestration is the transfer and storage of\natmospheric carbon dioxide in soils, which plays an important role in climate\nchange mitigation. SOC concentration can be improved by proper land use, thus\nit is beneficial if SOC can be estimated at a regional or global scale. As\nmultispectral satellite data can provide SOC-related information such as\nvegetation and soil properties at a global scale, estimation of SOC through\nsatellite data has been explored as an alternative to manual soil sampling.\nAlthough existing studies show promising results, they are mainly based on\npixel-based approaches with traditional machine learning methods, and\nconvolutional neural networks (CNNs) are uncommon. To study the use of CNNs on\nSOC remote sensing, here we propose the FNO-DenseNet based on the Fourier\nneural operator (FNO). By combining the advantages of the FNO and DenseNet, the\nFNO-DenseNet outperformed the FNO in our experiments with hundreds of times\nfewer parameters. The FNO-DenseNet also outperformed a pixel-based random\nforest by 18% in the mean absolute percentage error.",
                "authors": [
                    "Ken C. L. Wong",
                    "Levente Klein",
                    "Ademir Ferreira da Silva",
                    "Hongzhi Wang",
                    "Jitendra Singh",
                    "Tanveer Syeda-Mahmood"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/IGARSS52108.2023.10281551",
                    "http://arxiv.org/abs/2311.13016v1",
                    "http://arxiv.org/pdf/2311.13016v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13013v1/1.0",
                "title": "Variability in Protoplanetary Nebulae: X. Multi-year Periods as an\n  Indicator of Potential Binaries",
                "year": 2023,
                "abstract": "New observations are presented of four evolved objects that display long,\nmulti-year variations in their light curves. These are interpreted as good\nevidence of their binary nature, with the modulation caused by the barycenter\nmotion of the evolved star resulting in a periodic obscuration by a\ncircumbinary disk. Although protoplanetary nebulae (PPNe) commonly possess\nbipolar nebulae, which are thought to be shaped by a binary companion, there\nare very few PPNe in which a binary companion has been found. Three of the\nobjects in this study appear to be PPNe, IRAS 07253-2001, 08005-2356, and\n17542-0603, with long periods of 5.2, 6.9, and 8.2 yrs, respectively. The\nbinary nature of IRAS 08005-2356 has recently been confirmed by a radial\nvelocity study. Two samples, one of PPNe and the other of post-AGB star\ncandidates, are investigated for further evidence on how common is a\nlong-period light curve variation. Both samples suggest such light variations\nare not common. The fourth object, IRAS 20056+1834 (QY Sge), is an obscured RV\nTau variable of the RVb subclass, with a long period of 3.9 yrs and pulsation\nperiods of 102.9 and 51.5 days. The period of this object is seen to vary by\n2%. Evidence is presented for a recent mass ejection in IRAS 17542-0603.",
                "authors": [
                    "Bruce J. Hrivnak",
                    "Wenxian Lu",
                    "Gary Henson",
                    "Todd C. Hillwig"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13013v1",
                    "http://arxiv.org/pdf/2311.13013v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13011v1/1.0",
                "title": "Ancilla quantum measurements on interacting chains: Sensitivity of\n  entanglement dynamics to the type and concentration of detectors",
                "year": 2023,
                "abstract": "We consider a quantum many-body lattice system that is coupled to ancillary\ndegrees of freedom (\"detectors\"), which are periodically measured by means of\nstrong projective measurements. The concentration $\\rho_a$ of ancillae and\ntheir coupling $M$ to the main system are considered as parameters. We explore\nthe dynamics of density and of entanglement entropy in the chain, for various\nvalues of $\\rho_a$ and $M$ for two models of the detector-chain interaction\nthat couple the local density in the chain to a detector degree of freedom. It\nis found that, for the density-density ($S_z s_z$-type in spin language)\ncoupling, the critical values $M_c$ for the measurement-induced entanglement\ntransition depends sensitively on $\\rho_a$. Moreover, our results indicate that\nfor a sufficiently small $\\rho_a$ the transition in this model disappears,\ni.e., a finite density of detectors is needed to reach a disentangling phase.\nThe behavior is qualitatively different for the second model, with\ndensity-hopping ($S_z s_x$-type) coupling. Specifically, the dynamics is much\nless sensitive to the concentration $\\rho_a$ of detectors than in the first\nmodel. Furthermore, the dependence of entanglement on the coupling strength $M$\nis strongly non-monotonic, indicating re-entrance of the entangling phase at\nlarge $M$.",
                "authors": [
                    "Elmer V. H. Doggen",
                    "Igor V. Gornyi",
                    "Alexander D. Mirlin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13011v1",
                    "http://arxiv.org/pdf/2311.13011v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph",
                    "cond-mat.dis-nn",
                    "cond-mat.mes-hall",
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13010v2/1.0",
                "title": "Beyond Catoni: Sharper Rates for Heavy-Tailed and Robust Mean Estimation",
                "year": 2023,
                "abstract": "We study the fundamental problem of estimating the mean of a $d$-dimensional\ndistribution with covariance $\\Sigma \\preccurlyeq \\sigma^2 I_d$ given $n$\nsamples. When $d = 1$, Catoni \\cite{catoni} showed an estimator with error\n$(1+o(1)) \\cdot \\sigma \\sqrt{\\frac{2 \\log \\frac{1}{\\delta}}{n}}$, with\nprobability $1 - \\delta$, matching the Gaussian error rate. For $d>1$, a\nnatural estimator outputs the center of the minimum enclosing ball of\none-dimensional confidence intervals to achieve a $1-\\delta$ confidence radius\nof $\\sqrt{\\frac{2 d}{d+1}} \\cdot \\sigma \\left(\\sqrt{\\frac{d}{n}} +\n\\sqrt{\\frac{2 \\log \\frac{1}{\\delta}}{n}}\\right)$, incurring a\n$\\sqrt{\\frac{2d}{d+1}}$-factor loss over the Gaussian rate. When the\n$\\sqrt{\\frac{d}{n}}$ term dominates by a $\\sqrt{\\log \\frac{1}{\\delta}}$ factor,\n\\cite{lee2022optimal-highdim} showed an improved estimator matching the\nGaussian rate. This raises a natural question: is the Gaussian rate achievable\nin general? Or is the $\\sqrt{\\frac{2 d}{d+1}}$ loss \\emph{necessary} when the\n$\\sqrt{\\frac{2 \\log \\frac{1}{\\delta}}{n}}$ term dominates?\n  We show that the answer to both these questions is \\emph{no} -- we show that\n\\emph{some} constant-factor loss over the Gaussian rate is necessary, but\nconstruct an estimator that improves over the above naive estimator by a\nconstant factor. We also consider robust estimation, where an adversary is\nallowed to corrupt an $\\epsilon$-fraction of samples arbitrarily: in this case,\nwe show that the above strategy of combining one-dimensional estimates and\nincurring the $\\sqrt{\\frac{2d}{d+1}}$-factor \\emph{is} optimal in the\ninfinite-sample limit.",
                "authors": [
                    "Shivam Gupta",
                    "Samuel B. Hopkins",
                    "Eric Price"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13010v2",
                    "http://arxiv.org/pdf/2311.13010v2"
                ],
                "primary_category": "math.ST",
                "categories": [
                    "math.ST",
                    "cs.DS",
                    "cs.IT",
                    "math.IT",
                    "stat.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13005v1/1.0",
                "title": "Antenna Selection For Receive Spatial Modulation System Empowered By\n  Reconfigurable Intelligent Surface",
                "year": 2023,
                "abstract": "Reconfigurable intelligent surface (RIS) enhances signal quality by adjusting\nthe phase of electromagnetic waves in wireless communication. Spatial\nmodulation (SM), a prominent index modulation (IM) technique, provides high\nspectral efficiency and low energy consumption. In this article, a new wireless\ncommunication system is proposed by combining capacity-optimized antenna\nselection (COAS), antenna correlation antenna selection (ACAS), and Euclidean\ndistance-optimized antenna selection (EDAS)-supported RIS-empowered receive SM\n(RIS-RSM) system (AS-RIS-RSM) in a single-input multiple-output (SIMO)\nstructure. The proposed AS-RIS-RSM schemes (COAS-RIS-RSM, ACAS-RIS-RSM, and\nEDAS-RIS-RSM) have superior features such as high spectral efficiency, high\nenergy efficiency, and low error data transmission. Integrating COAS, ACAS, and\nEDAS techniques into the system enables the selection of the channel with the\nbest conditions, thus increasing the error performance of the proposed system.\nAlso, using RIS increases the error performance of the system by controlling\nthe transmitted signal to a certain extent. The analytical ABER results of the\nproposed AS-RIS-RSM systems are derived and shown to overlap with simulation\nresults. For the proposed systems, an optimal maximum likelihood (ML) detector\nand a sub-optimal low-complexity greedy detector (GD) are offered. Also,\ncapacity analyses of the proposed AS-RIS-RSM systems are derived and it is\nobserved that they have higher capacity compared to RIS-QAM/PSK and RIS-RSM\nsystems. Then, computational complexity analyses of the proposed COAS-RIS-RSM,\nACAS-RIS-RSM, and EDAS-RIS-RSM systems are presented. The proposed systems have\nbeen compared to counterpart wireless communication systems including RIS-RSM,\nRIS-QAM, and RIS-PSK under equivalent conditions, demonstrating that the\nproposed systems achieve better error performance.",
                "authors": [
                    "Burak Ahmet Ozden",
                    "Erdogan Aydin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13005v1",
                    "http://arxiv.org/pdf/2311.13005v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13004v1/1.0",
                "title": "A Self-Consistent Field Solution for Robust Common Spatial Pattern\n  Analysis",
                "year": 2023,
                "abstract": "The common spatial pattern analysis (CSP) is a widely used signal processing\ntechnique in brain-computer interface (BCI) systems to increase the\nsignal-to-noise ratio in electroencephalogram (EEG) recordings. Despite its\npopularity, the CSP's performance is often hindered by the nonstationarity and\nartifacts in EEG signals. The minmax CSP improves the robustness of the CSP by\nusing data-driven covariance matrices to accommodate the uncertainties. We show\nthat by utilizing the optimality conditions, the minmax CSP can be recast as an\neigenvector-dependent nonlinear eigenvalue problem (NEPv). We introduce a\nself-consistent field (SCF) iteration with line search that solves the NEPv of\nthe minmax CSP. Local quadratic convergence of the SCF for solving the NEPv is\nillustrated using synthetic datasets. More importantly, experiments with\nreal-world EEG datasets show the improved motor imagery classification rates\nand shorter running time of the proposed SCF-based solver compared to the\nexisting algorithm for the minmax CSP.",
                "authors": [
                    "Dong Min Roh",
                    "Zhaojun Bai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13004v1",
                    "http://arxiv.org/pdf/2311.13004v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13001v1/1.0",
                "title": "Constraining Background N2 Inventories on Directly Imaged Terrestrial\n  Exoplanets to Rule Out O2 False Positives",
                "year": 2023,
                "abstract": "Direct imaging spectroscopy with future space-based telescopes will constrain\nterrestrial planet atmospheric composition and potentially detect biosignature\ngases. One promising indication of life is abundant atmospheric O2. However,\nvarious non-biological processes could also lead to O2 accumulation in the\natmospheres of potentially habitable planets around Sun-like stars. In\nparticular, the absence of non-condensible background gases such as N2 could\nresult in appreciable H escape and abiotic O2 buildup, so identifying\nbackground atmosphere composition is crucial for contextualizing any O2\ndetections. Here, we perform retrievals on simulated directly imaged\nterrestrial planets using rfast, a new exoplanet atmospheric retrieval suite\nwith direct imaging analysis capabilities. By simulating Earth-analog\nretrievals for varied atmospheric compositions, cloud properties, and surface\npressures, we determine what wavelength range, spectral resolution, and\nsignal-to-noise ratio (S/N) are necessary to constrain background gases'\nidentity and abundance. We find N2 backgrounds can be uniquely identified with\nS/N$\\sim$20 observations, provided that wavelength coverage extends beyond\n$\\sim$1.6 $\\mu$m to rule out CO-dominated atmospheres. Additionally, there is a\nlow probability of O2-dominated atmospheres due to an O2-N2 degeneracy that is\nonly totally ruled out at S/N$\\sim$40. If wavelength coverage is limited to\n0.2-1.1 $\\mu$m, then although all other cosmochemically plausible backgrounds\ncan be readily excluded, N2 and CO backgrounds cannot be distinguished.\nOverall, our simulated retrievals and associated integration time calculations\nsuggest that near-infrared coverage to at least 1.6 $\\mu$m and apertures\napproaching 8m are needed to confidently rule out O2 biosignature false\npositives within feasible integration times",
                "authors": [
                    "Sawyer Hall",
                    "Joshua Krissansen-Totton",
                    "Tyler Robinson",
                    "Arnaud Salvador",
                    "Jonathan J. Fortney"
                ],
                "url": [
                    "http://dx.doi.org/10.3847/1538-3881/ad03e9",
                    "http://arxiv.org/abs/2311.13001v1",
                    "http://arxiv.org/pdf/2311.13001v1"
                ],
                "primary_category": "astro-ph.EP",
                "categories": [
                    "astro-ph.EP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13000v1/1.0",
                "title": "Computational Explorations in Biomedicine: Unraveling Molecular Dynamics\n  for Cancer, Drug Delivery, and Biomolecular Insights using LAMMPS Simulations",
                "year": 2023,
                "abstract": "With the rapid advancement of computational techniques, Molecular Dynamics\n(MD) simulations have emerged as powerful tools in biomedical research,\nenabling in-depth investigations of biological systems at the atomic level.\nAmong the diverse range of simulation software available, LAMMPS (Large-scale\nAtomic/Molecular Massively Parallel Simulator) has gained significant\nrecognition for its versatility, scalability, and extensive range of\nfunctionalities. This literature review aims to provide a comprehensive\noverview of the utilization of LAMMPS in the field of biomedical applications.\nThis review begins by outlining the fundamental principles of MD simulations\nand highlighting the unique features of LAMMPS that make it suitable for\nbiomedical research. Subsequently, a survey of the literature is conducted to\nidentify key studies that have employed LAMMPS in various biomedical contexts,\nsuch as protein folding, drug design, biomaterials, and cellular processes. The\nreviewed studies demonstrate the remarkable contributions of LAMMPS in\nunderstanding the behavior of biological macromolecules, investigating\ndrug-protein interactions, elucidating the mechanical properties of\nbiomaterials, and studying cellular processes at the molecular level.\nAdditionally, this review explores the integration of LAMMPS with other\ncomputational tools and experimental techniques, showcasing its potential for\nsynergistic investigations that bridge the gap between theory and experiment.\nMoreover, this review discusses the challenges and limitations associated with\nusing LAMMPS in biomedical simulations, including the parameterization of force\nfields, system size limitations, and computational efficiency. Strategies\nemployed by researchers to mitigate these challenges are presented, along with\npotential future directions for enhancing LAMMPS capabilities in the biomedical\nfield.",
                "authors": [
                    "Reza Bozorgpour"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13000v1",
                    "http://arxiv.org/pdf/2311.13000v1"
                ],
                "primary_category": "q-bio.BM",
                "categories": [
                    "q-bio.BM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13610v1/1.0",
                "title": "TRIDENT: The Nonlinear Trilogy for Implicit Neural Representations",
                "year": 2023,
                "abstract": "Implicit neural representations (INRs) have garnered significant interest\nrecently for their ability to model complex, high-dimensional data without\nexplicit parameterisation. In this work, we introduce TRIDENT, a novel function\nfor implicit neural representations characterised by a trilogy of\nnonlinearities. Firstly, it is designed to represent high-order features\nthrough order compactness. Secondly, TRIDENT efficiently captures frequency\ninformation, a feature called frequency compactness. Thirdly, it has the\ncapability to represent signals or images such that most of its energy is\nconcentrated in a limited spatial region, denoting spatial compactness. We\ndemonstrated through extensive experiments on various inverse problems that our\nproposed function outperforms existing implicit neural representation\nfunctions.",
                "authors": [
                    "Zhenda Shen",
                    "Yanqi Cheng",
                    "Raymond H. Chan",
                    "Pietro Li\u00f2",
                    "Carola-Bibiane Sch\u00f6nlieb",
                    "Angelica I Aviles-Rivero"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13610v1",
                    "http://arxiv.org/pdf/2311.13610v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12999v1/1.0",
                "title": "CovarNav: Machine Unlearning via Model Inversion and Covariance\n  Navigation",
                "year": 2023,
                "abstract": "The rapid progress of AI, combined with its unprecedented public adoption and\nthe propensity of large neural networks to memorize training data, has given\nrise to significant data privacy concerns. To address these concerns, machine\nunlearning has emerged as an essential technique to selectively remove the\ninfluence of specific training data points on trained models. In this paper, we\napproach the machine unlearning problem through the lens of continual learning.\nGiven a trained model and a subset of training data designated to be forgotten\n(i.e., the \"forget set\"), we introduce a three-step process, named CovarNav, to\nfacilitate this forgetting. Firstly, we derive a proxy for the model's training\ndata using a model inversion attack. Secondly, we mislabel the forget set by\nselecting the most probable class that deviates from the actual ground truth.\nLastly, we deploy a gradient projection method to minimize the cross-entropy\nloss on the modified forget set (i.e., learn incorrect labels for this set)\nwhile preventing forgetting of the inverted samples. We rigorously evaluate\nCovarNav on the CIFAR-10 and Vggface2 datasets, comparing our results with\nrecent benchmarks in the field and demonstrating the efficacy of our proposed\napproach.",
                "authors": [
                    "Ali Abbasi",
                    "Chayne Thrash",
                    "Elaheh Akbari",
                    "Daniel Zhang",
                    "Soheil Kolouri"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12999v1",
                    "http://arxiv.org/pdf/2311.12999v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12997v1/1.0",
                "title": "How Capable Can a Transformer Become? A Study on Synthetic,\n  Interpretable Tasks",
                "year": 2023,
                "abstract": "Transformers trained on huge text corpora exhibit a remarkable set of\ncapabilities, e.g., performing simple logical operations. Given the inherent\ncompositional nature of language, one can expect the model to learn to compose\nthese capabilities, potentially yielding a combinatorial explosion of what\noperations it can perform on an input. Motivated by the above, we aim to assess\nin this paper \"how capable can a transformer become?\". Specifically, we train\nautoregressive Transformer models on a data-generating process that involves\ncompositions of a set of well-defined monolithic capabilities. Through a series\nof extensive and systematic experiments on this data-generating process, we\nshow that: (1) autoregressive Transformers can learn compositional structures\nfrom the training data and generalize to exponentially or even combinatorially\nmany functions; (2) composing functions by generating intermediate outputs is\nmore effective at generalizing to unseen compositions, compared to generating\nno intermediate outputs; (3) the training data has a significant impact on the\nmodel's ability to compose unseen combinations of functions; and (4) the\nattention layers in the latter half of the model are critical to\ncompositionality.",
                "authors": [
                    "Rahul Ramesh",
                    "Mikail Khona",
                    "Robert P. Dick",
                    "Hidenori Tanaka",
                    "Ekdeep Singh Lubana"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12997v1",
                    "http://arxiv.org/pdf/2311.12997v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12993v1/1.0",
                "title": "AI for Agriculture: the Comparison of Semantic Segmentation Methods for\n  Crop Mapping with Sentinel-2 Imagery",
                "year": 2023,
                "abstract": "Crop mapping is one of the most common tasks in artificial intelligence for\nagriculture due to higher food demands from a growing population and increased\nawareness of climate change. In case of vineyards, the texture is very\nimportant for crop segmentation: with higher resolution satellite imagery the\ntexture is easily detected by majority of state-of-the-art algorithms. However,\nthis task becomes increasingly more difficult as the resolution of satellite\nimagery decreases and the information about the texture becomes unavailable. In\nthis paper we aim to explore the main machine learning methods that can be used\nwith freely available satellite imagery and discuss how and when they can be\napplied for vineyard segmentation problem. We assess the effectiveness of\nvarious widely-used machine learning techniques and offer guidance on selecting\nthe most suitable model for specific scenarios.",
                "authors": [
                    "Irina Korotkova",
                    "Natalia Efremova"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12993v1",
                    "http://arxiv.org/pdf/2311.12993v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "eess.IV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12990v2/1.0",
                "title": "NERIF: GPT-4V for Automatic Scoring of Drawn Models",
                "year": 2023,
                "abstract": "Scoring student-drawn models is time-consuming. Recently released GPT-4V\nprovides a unique opportunity to advance scientific modeling practices by\nleveraging the powerful image processing capability. To test this ability\nspecifically for automatic scoring, we developed a method NERIF\n(Notation-Enhanced Rubric Instruction for Few-shot Learning) employing\ninstructional note and rubrics to prompt GPT-4V to score students' drawn models\nfor science phenomena. We randomly selected a set of balanced data (N = 900)\nthat includes student-drawn models for six modeling assessment tasks. Each\nmodel received a score from GPT-4V ranging at three levels: 'Beginning,'\n'Developing,' or 'Proficient' according to scoring rubrics. GPT-4V scores were\ncompared with human experts' scores to calculate scoring accuracy. Results show\nthat GPT-4V's average scoring accuracy was mean =.51, SD = .037. Specifically,\naverage scoring accuracy was .64 for the 'Beginning' class, .62 for the\n'Developing' class, and .26 for the 'Proficient' class, indicating that more\nproficient models are more challenging to score. Further qualitative study\nreveals how GPT-4V retrieves information from image input, including problem\ncontext, example evaluations provided by human coders, and students' drawing\nmodels. We also uncovered how GPT-4V catches the characteristics of\nstudent-drawn models and narrates them in natural language. At last, we\ndemonstrated how GPT-4V assigns scores to student-drawn models according to the\ngiven scoring rubric and instructional notes. Our findings suggest that the\nNERIF is an effective approach for employing GPT-4V to score drawn models. Even\nthough there is space for GPT-4V to improve scoring accuracy, some mis-assigned\nscores seemed interpretable to experts. The results of this study show that\nutilizing GPT-4V for automatic scoring of student-drawn models is promising.",
                "authors": [
                    "Gyeong-Geon Lee",
                    "Xiaoming Zhai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12990v2",
                    "http://arxiv.org/pdf/2311.12990v2"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12987v1/1.0",
                "title": "Volatility and irregularity Capturing in stock price indices using time\n  series Generative adversarial networks (TimeGAN)",
                "year": 2023,
                "abstract": "This paper captures irregularities in financial time series data,\nparticularly stock prices, in the presence of COVID-19 shock. We conjectured\nthat jumps and irregularities are embedded in stock data due to the pandemic\nshock, which brings forth irregular trends in the time series data. We put\nforward that efficient and robust forecasting methods are needed to predict\nstock closing prices in the presence of the pandemic shock. This piece of\ninformation is helpful to investors as far as confidence risk and return boost\nare concerned. Generative adversarial networks of a time series nature are used\nto provide new ways of modeling and learning the proper and suitable\ndistribution for the financial time series data under complex setups. Ideally,\nthese traditional models are liable to producing high forecasting errors, and\nthey need to be more robust to capture dependency structures and other stylized\nfacts like volatility in stock markets. The TimeGAN model is used, effectively\ndealing with this risk of poor forecasts. Using the DAX stock index from\nJanuary 2010 to November 2022, we trained the LSTM, GRU, WGAN, and TimeGAN\nmodels as benchmarks and forecasting errors were noted, and our TimeGAN\noutperformed them all as indicated by a small forecasting error.",
                "authors": [
                    "Leonard Mushunje",
                    "David Allen",
                    "Shelton Peiris"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12987v1",
                    "http://arxiv.org/pdf/2311.12987v1"
                ],
                "primary_category": "cs.CE",
                "categories": [
                    "cs.CE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12986v2/1.0",
                "title": "Unsupervised Graph Attention Autoencoder for Attributed Networks using\n  K-means Loss",
                "year": 2023,
                "abstract": "Several natural phenomena and complex systems are often represented as\nnetworks. Discovering their community structure is a fundamental task for\nunderstanding these networks. Many algorithms have been proposed, but recently,\nGraph Neural Networks (GNN) have emerged as a compelling approach for enhancing\nthis task.In this paper, we introduce a simple, efficient, and\nclustering-oriented model based on unsupervised \\textbf{G}raph Attention\n\\textbf{A}uto\\textbf{E}ncoder for community detection in attributed networks\n(GAECO). The proposed model adeptly learns representations from both the\nnetwork's topology and attribute information, simultaneously addressing dual\nobjectives: reconstruction and community discovery. It places a particular\nemphasis on discovering compact communities by robustly minimizing clustering\nerrors. The model employs k-means as an objective function and utilizes a\nmulti-head Graph Attention Auto-Encoder for decoding the representations.\nExperiments conducted on three datasets of attributed networks show that our\nmethod surpasses state-of-the-art algorithms in terms of NMI and ARI.\nAdditionally, our approach scales effectively with the size of the network,\nmaking it suitable for large-scale applications. The implications of our\nfindings extend beyond biological network interpretation and social network\nanalysis, where knowledge of the fundamental community structure is essential.",
                "authors": [
                    "Abdelfateh Bekkair",
                    "Slimane Bellaouar",
                    "Slimane Oulad-Naoui"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12986v2",
                    "http://arxiv.org/pdf/2311.12986v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "68T07",
                    "I.2.4"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13609v1/1.0",
                "title": "An Analysis on the Effects of Evolving the Monte Carlo Tree Search Upper\n  Confidence for Trees Selection Policy on Unimodal, Multimodal and Deceptive\n  Landscapes",
                "year": 2023,
                "abstract": "Monte Carlo Tree Search (MCTS) is a best-first sampling method employed in\nthe search for optimal decisions. The effectiveness of MCTS relies on the\nconstruction of its statistical tree, with the selection policy playing a\ncrucial role. A selection policy that works particularly well in MCTS is the\nUpper Confidence Bounds for Trees, referred to as UCT. The research community\nhas also put forth more sophisticated bounds aimed at enhancing MCTS\nperformance on specific problem domains. Thus, while MCTS UCT generally\nperforms well, there may be variants that outperform it. This has led to\nvarious efforts to evolve selection policies for use in MCTS. While all of\nthese previous works are inspiring, none have undertaken an in-depth analysis\nto shed light on the circumstances in which an evolved alternative to MCTS UCT\nmight prove advantageous. Most of these studies have focused on a single type\nof problem. In sharp contrast, this work explores the use of five functions of\ndifferent natures, ranging from unimodal to multimodal and deceptive functions.\nWe illustrate how the evolution of MCTS UCT can yield benefits in multimodal\nand deceptive scenarios, whereas MCTS UCT is robust in all of the functions\nused in this work.",
                "authors": [
                    "Edgar Galvan",
                    "Fred Valdez Ameneyro"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13609v1",
                    "http://arxiv.org/pdf/2311.13609v1"
                ],
                "primary_category": "cs.NE",
                "categories": [
                    "cs.NE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12983v1/1.0",
                "title": "GAIA: a benchmark for General AI Assistants",
                "year": 2023,
                "abstract": "We introduce GAIA, a benchmark for General AI Assistants that, if solved,\nwould represent a milestone in AI research. GAIA proposes real-world questions\nthat require a set of fundamental abilities such as reasoning, multi-modality\nhandling, web browsing, and generally tool-use proficiency. GAIA questions are\nconceptually simple for humans yet challenging for most advanced AIs: we show\nthat human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins.\nThis notable performance disparity contrasts with the recent trend of LLMs\noutperforming humans on tasks requiring professional skills in e.g. law or\nchemistry. GAIA's philosophy departs from the current trend in AI benchmarks\nsuggesting to target tasks that are ever more difficult for humans. We posit\nthat the advent of Artificial General Intelligence (AGI) hinges on a system's\ncapability to exhibit similar robustness as the average human does on such\nquestions. Using GAIA's methodology, we devise 466 questions and their answer.\nWe release our questions while retaining answers to 300 of them to power a\nleader-board available at https://huggingface.co/gaia-benchmark.",
                "authors": [
                    "Gr\u00e9goire Mialon",
                    "Cl\u00e9mentine Fourrier",
                    "Craig Swift",
                    "Thomas Wolf",
                    "Yann LeCun",
                    "Thomas Scialom"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12983v1",
                    "http://arxiv.org/pdf/2311.12983v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12981v1/1.0",
                "title": "SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion",
                "year": 2023,
                "abstract": "Robustly evaluating deep learning image classifiers is challenging due to\nsome limitations of standard datasets. Natural Adversarial Examples (NAEs),\narising naturally from the environment and capable of deceiving classifiers,\nare instrumental in identifying vulnerabilities in trained models. Existing\nworks collect such NAEs by filtering from a huge set of real images, a process\nthat is passive and lacks control. In this work, we propose to actively\nsynthesize NAEs with the state-of-the-art Stable Diffusion. Specifically, our\nmethod formulates a controlled optimization process, where we perturb the token\nembedding that corresponds to a specified class to synthesize NAEs. The\ngeneration is guided by the gradient of loss from the target classifier so that\nthe created image closely mimics the ground-truth class yet fools the\nclassifier. Named SD-NAE (Stable Diffusion for Natural Adversarial Examples),\nour innovative method is effective in producing valid and useful NAEs, which is\ndemonstrated through a meticulously designed experiment. Our work thereby\nprovides a valuable method for obtaining challenging evaluation data, which in\nturn can potentially advance the development of more robust deep learning\nmodels. Code is available at https://github.com/linyueqian/SD-NAE.",
                "authors": [
                    "Yueqian Lin",
                    "Jingyang Zhang",
                    "Yiran Chen",
                    "Hai Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12981v1",
                    "http://arxiv.org/pdf/2311.12981v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12978v1/1.0",
                "title": "Physics-Informed Priors with Application to Boundary Layer Velocity",
                "year": 2023,
                "abstract": "One of the most popular recent areas of machine learning predicates the use\nof neural networks augmented by information about the underlying process in the\nform of Partial Differential Equations (PDEs). These physics-informed neural\nnetworks are obtained by penalizing the inference with a PDE, and have been\ncast as a minimization problem currently lacking a formal approach to quantify\nthe uncertainty. In this work, we propose a novel model-based framework which\nregards the PDE as a prior information of a deep Bayesian neural network. The\nprior is calibrated without data to resemble the PDE solution in the prior\nmean, while our degree in confidence on the PDE with respect to the data is\nexpressed in terms of the prior variance. The information embedded in the PDE\nis then propagated to the posterior yielding physics-informed forecasts with\nuncertainty quantification. We apply our approach to a simulated viscous fluid\nand to experimentally-obtained turbulent boundary layer velocity in a wind\ntunnel using an appropriately simplified Navier-Stokes equation. Our approach\nrequires very few observations to produce physically-consistent forecasts as\nopposed to non-physical forecasts stemming from non-informed priors, thereby\nallowing forecasting complex systems where some amount of data as well as some\ncontextual knowledge is available.",
                "authors": [
                    "Luca Menicali",
                    "David H. Richter",
                    "Stefano Castruccio"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12978v1",
                    "http://arxiv.org/pdf/2311.12978v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn",
                    "stat.ME"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12973v1/1.0",
                "title": "An $\\mathcal{O}(\\log_2N)$ SMC$^2$ Algorithm on Distributed Memory with\n  an Approx. Optimal L-Kernel",
                "year": 2023,
                "abstract": "Calibrating statistical models using Bayesian inference often requires both\naccurate and timely estimates of parameters of interest. Particle Markov Chain\nMonte Carlo (p-MCMC) and Sequential Monte Carlo Squared (SMC$^2$) are two\nmethods that use an unbiased estimate of the log-likelihood obtained from a\nparticle filter (PF) to evaluate the target distribution. P-MCMC constructs a\nsingle Markov chain which is sequential by nature so cannot be readily\nparallelized using Distributed Memory (DM) architectures. This is in contrast\nto SMC$^2$ which includes processes, such as importance sampling, that are\ndescribed as \\textit{embarrassingly parallel}. However, difficulties arise when\nattempting to parallelize resampling. None-the-less, the choice of backward\nkernel, recycling scheme and compatibility with DM architectures makes SMC$^2$\nan attractive option when compared with p-MCMC. In this paper, we present an\nSMC$^2$ framework that includes the following features: an optimal (in terms of\ntime complexity) $\\mathcal{O}(\\log_2N)$ parallelization for DM architectures,\nan approximately optimal (in terms of accuracy) backward kernel, and an\nefficient recycling scheme. On a cluster of $128$ DM processors, the results on\na biomedical application show that SMC$^2$ achieves up to a $70\\times$ speed-up\nvs its sequential implementation. It is also more accurate and roughly\n$54\\times$ faster than p-MCMC. A GitHub link is given which provides access to\nthe code.",
                "authors": [
                    "Conor Rosato",
                    "Alessandro Varsi",
                    "Joshua Murphy",
                    "Simon Maskell"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12973v1",
                    "http://arxiv.org/pdf/2311.12973v1"
                ],
                "primary_category": "stat.AP",
                "categories": [
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12968v1/1.0",
                "title": "Bit Error Rate Performance and Diversity Analysis for Mediumband\n  Wireless Communication",
                "year": 2023,
                "abstract": "Mediumband wireless communication refers to wireless communication through a\nclass of channels known as mediumband that exists on the TmTs-plane. This\npaper, through statistical analysis and computer simulations, studies the\nperformance limits of this class of channels in terms of uncoded bit error rate\n(BER) and diversity order. We show that, owing mainly to the effect of the deep\nfading avoidance, which is unique to the channels in the mediumband region,\nmediumband wireless systems, if designed judiciously, have the potential to\nachieve significantly superior error rate and higher order diversity even in\nnon-line-of-sight (NLoS) propagation environments where the achievable\ndiversity order is otherwise low.",
                "authors": [
                    "Dushyantha A Basnayaka",
                    "Jiabin Jia"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12968v1",
                    "http://arxiv.org/pdf/2311.12968v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12962v1/1.0",
                "title": "The analogue of overlap-freeness for the Fibonacci morphism",
                "year": 2023,
                "abstract": "A $4^-$-power is a non-empty word of the form $XXXX^-$, where $X^-$ is\nobtained from $X$ by erasing the last letter. A binary word is called {\\em\nfaux-bonacci} if it contains no $4^-$-powers, and no factor 11. We show that\nfaux-bonacci words bear the same relationship to the Fibonacci morphism that\noverlap-free words bear to the Thue-Morse morphism. We prove the analogue of\nFife's Theorem for faux-bonacci words, and characterize the lexicographically\nleast and greatest infinite faux-bonacci words.",
                "authors": [
                    "James D. Currie",
                    "Narad Rampersad"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12962v1",
                    "http://arxiv.org/pdf/2311.12962v1"
                ],
                "primary_category": "math.CO",
                "categories": [
                    "math.CO",
                    "cs.FL",
                    "68R15"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12960v2/1.0",
                "title": "Teaching Quantum Computing using Microsoft Quantum Development Kit and\n  Azure Quantum",
                "year": 2023,
                "abstract": "This report describes my experience teaching a graduate-level quantum\ncomputing course at Northeastern University in the academic year 2022-23. The\ncourse takes a practical, software-driven approach to the course, teaching\nbasic quantum concepts and algorithms through hands-on programming assignments\nand a software-focused final project. The course guides learners through all\nstages of the quantum software development process, from solving quantum\ncomputing problems and implementing solutions to debugging quantum programs,\noptimizing the code, and running the code on quantum hardware. This report\noffers instructors who want to adopt a similar practical approach to teaching\nquantum computing a comprehensive guide to getting started.",
                "authors": [
                    "Mariia Mykhailova"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/QCE57702.2023.20320",
                    "http://arxiv.org/abs/2311.12960v2",
                    "http://arxiv.org/pdf/2311.12960v2"
                ],
                "primary_category": "physics.ed-ph",
                "categories": [
                    "physics.ed-ph",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12955v1/1.0",
                "title": "Don't forget private retrieval: distributed private similarity search\n  for large language models",
                "year": 2023,
                "abstract": "While the flexible capabilities of large language models (LLMs) allow them to\nanswer a range of queries based on existing learned knowledge, information\nretrieval to augment generation is an important tool to allow LLMs to answer\nquestions on information not included in pre-training data. Such private\ninformation is increasingly being generated in a wide array of distributed\ncontexts by organizations and individuals. Performing such information\nretrieval using neural embeddings of queries and documents always leaked\ninformation about queries and database content unless both were stored locally.\nWe present Private Retrieval Augmented Generation (PRAG), an approach that uses\nmulti-party computation (MPC) to securely transmit queries to a distributed set\nof servers containing a privately constructed database to return top-k and\napproximate top-k documents. This is a first-of-its-kind approach to dense\ninformation retrieval that ensures no server observes a client's query or can\nsee the database content. The approach introduces a novel MPC friendly protocol\nfor inverted file approximate search (IVF) that allows for fast document search\nover distributed and private data in sublinear communication complexity. This\nwork presents new avenues through which data for use in LLMs can be accessed\nand used without needing to centralize or forgo privacy.",
                "authors": [
                    "Guy Zyskind",
                    "Tobin South",
                    "Alex Pentland"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12955v1",
                    "http://arxiv.org/pdf/2311.12955v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14736v1/1.0",
                "title": "Data Diversity Matters for Robust Instruction Tuning",
                "year": 2023,
                "abstract": "Instruction tuning has emerged as a key step in aligning large language\nmodels. One of the central challenges of instruction tuning is dataset\nselection, as the composition of the instruction tuning dataset can\nsignificantly impact downstream performance. In particular, researchers have\nhypothesized that dataset diversity and dataset quality are important\nindicators of downstream performance. However, it is not clear how to\nautomatically select high quality and diverse data or how exactly quality and\ndiversity affect instruction following ability. To resolve these issues, we\npropose a new algorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT\nprovides a principled algorithm to control dataset diversity and quality,\nallowing us to conduct an in depth study on the effect of diversity and quality\non instruction tuning performance. From this study we draw two key insights (1)\nthere is a natural tradeoff between dataset diversity and quality and (2)\nincreasing dataset diversity significantly improves the worst case instruction\nfollowing performance, therefore improving robustness. We validate the\nperformance of QDIT on several large scale instruction tuning datasets, where\nwe find it can improve worst case performance by 18% while maintaining or\nimproving average performance compared to quality driven baselines.",
                "authors": [
                    "Alexander Bukharin",
                    "Tuo Zhao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14736v1",
                    "http://arxiv.org/pdf/2311.14736v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12942v1/1.0",
                "title": "Synthetic X-ray emission from white dwarf accreting planetary material",
                "year": 2023,
                "abstract": "The emission of hard X-rays associated with white dwarfs (WD) can be\ngenerated by the presence of a stellar companion either by the companion's\ncoronal emission or by an accretion disk formed by material stripped from the\ncompanion. Recent studies have suggested that a Jupiter-like planet can also be\ndonor of material whose accretion onto the WD can generate hard X-rays. We use\nthe {\\sc guacho} code to reproduce the conditions of this WD-planet scenario.\nWith the example of the hard X-ray WD KPD\\,0005+5106, we explore different\nterminal wind velocities and mass-loss rates of a donor planet for a future\nnetwork of simulations to investigate the luminosity and the spectral and\ntemporal properties of the hard X-ray emission in WD-planet systems. Our\nsimulations show that the material stripped from the planet forms a disk and\naccretes onto the WD to reach temperatures high enough to generate hard X-rays\nas usually seen in X-ray binaries with low-mass companions. For high terminal\nwind velocities, the planet material does not form a disk, but it rather\naccretes directly onto the WD surface. The simulations reproduce the X-ray\nluminosity of another X-ray accreting WD (G\\,29$-$38), and only for some times\nreaches the hard X-ray luminosity of KPD\\,0005+5106. The X-ray variability is\nstochastic and does not reproduce the period of KPD\\,0005+5106, suggesting that\nadditional physical processes (e.g., hot spots resulting from magnetic\nchannelling of the accreting material) need to be explored.",
                "authors": [
                    "S. Estrada-Dorado",
                    "V. Lora",
                    "J. A. Toal\u00e1",
                    "A. Esquivel",
                    "M. A. Guerrero",
                    "R. F. Maldonado",
                    "Y. -H. Chu"
                ],
                "url": [
                    "http://dx.doi.org/10.1093/mnras/stad3608",
                    "http://arxiv.org/abs/2311.12942v1",
                    "http://arxiv.org/pdf/2311.12942v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR",
                    "astro-ph.EP",
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12935v1/1.0",
                "title": "Sampling-accelerated First-principles Prediction of Phonon Scattering\n  Rates for Converged Thermal Conductivity and Radiative Properties",
                "year": 2023,
                "abstract": "First-principles prediction of thermal conductivity and radiative properties\nis crucial. However, computing phonon scattering, especially for four-phonon\nscattering, could be prohibitively expensive, and the thermal conductivity even\nfor silicon was still under-predicted and not converged in the literature. Here\nwe propose a method to estimate scattering rates from a small sample of\nscattering processes using maximum likelihood estimation. The computational\ncost of estimating scattering rates and associated thermal conductivity and\nradiative properties is dramatically reduced by over 99%. This allows us to use\nan unprecedented q-mesh of 32*32*32 for silicon and achieve a converged thermal\nconductivity value that agrees much better with experiments. The accuracy and\nefficiency of our approach make it ideal for the high-throughput screening of\nmaterials for thermal and optical applications.",
                "authors": [
                    "Ziqi Guo",
                    "Zherui Han",
                    "Dudong Feng",
                    "Guang Lin",
                    "Xiulin Ruan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12935v1",
                    "http://arxiv.org/pdf/2311.12935v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci",
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12934v1/1.0",
                "title": "Long-lived Searches of Vector-like Lepton and Its Accompanying Scalar at\n  Colliders",
                "year": 2023,
                "abstract": "Recently, the vector-like leptons (VLLs) as a simple extension to the\nstandard model (SM) have attracted widespread attention both in theory and\nexperiments. The present collider searches mainly focus on the studies of their\nprompt decays, which prefer a relatively large coupling. In this paper, we\nconcentrate on searches for long-lived signatures of the singlet VLLs $F$ or\ntheir accompanying scalar particles $\\phi$ both in the hadronic and electronic\ncolliders. The long-lived signatures are naturally induced from small chiral\nmass mixing between VLLs and SM leptons. Two specific models distinguished by\nwhether the VLLs couple to scalar particles are introduced to realize the\naforementioned features. For long-lived VLLs case, we find that with the kink\ntrack method the sensitivities at future HL-LHC with $\\sqrt{s}=13~\\text{TeV}$\ncan reach the regions for VLL mass $m_F \\in [200,950]~\\text{GeV}$ and the mass\nmixing parameter $\\theta_L \\in [10^{-10},10^{-7}]$. For the long-lived\naccompanying scalar particle case, by fixing VLLs or scalar mass, or the mass\nratio between VLL and the accompanying scalar, we explore the projected\nsensitivities through the time delay and displaced vertex strategies, which can\nprobe the regions for $m_F \\in [200,1200]~\\text{GeV}$ and coupling\n$y\\theta_L\\in [10^{-11},10^{-6}]$. Furthermore, we also explore the long-lived\naccompanying scalars at the future CEPC provided that the VLLs can couple to\nthe SM first-generation leptons. We find that CEPC has good performances for\n$m_\\phi < 70~\\text{GeV}$ and $m_F<1000~\\text{GeV}$. These long-lived searches\nare complementary to previous studies, which opens the door towards the smaller\ncoupling regions.",
                "authors": [
                    "Qing-Hong Cao",
                    "Jinhui Guo",
                    "Jia Liu",
                    "Yan Luo",
                    "Xiao-Ping Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12934v1",
                    "http://arxiv.org/pdf/2311.12934v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12930v2/1.0",
                "title": "Determining the spin of light primordial black holes with Hawking\n  radiation II: high spin regime",
                "year": 2023,
                "abstract": "We propose a method to determine the mass and spin of primordial black holes\nbased on measuring the energy and emission rate at the dipolar and quadrupolar\npeaks in the primary photon Hawking spectrum, applicable for dimensionless spin\nparameters $\\tilde{a}\\gtrsim 0.6$. In particular, we show that the ratio\nbetween the energies of the two peaks is only a function of the black hole\nspin, while the ratio between their emission rates depends also on the\nline-of-sight inclination. The black hole mass and distance from the Earth may\nthen be inferred from the absolute values of the peak energies and emission\nrates. This method is relevant for primordial black holes born with large spin\nparameters that are presently still in the early stages of their evaporation\nprocess.",
                "authors": [
                    "Marco Calz\u00e0",
                    "Jo\u00e3o G. Rosa"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12930v2",
                    "http://arxiv.org/pdf/2311.12930v2"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc",
                    "astro-ph.HE",
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12928v1/1.0",
                "title": "Void Probability Function inside cosmic voids: evidence for hierarchical\n  scaling of high-order correlations in real space",
                "year": 2023,
                "abstract": "We compare the reduced void probability function (VPF) inside and outside of\ncosmic voids in the TNG300-1 simulation, both in real and simulated redshift\nspace. The VPF is a special case of the counts-in-cells approach for extracting\ninformation of high-order clustering that is crucial for a full understanding\nof the distribution of galaxies. Previous studies have validated the\nhierarchical scaling paradigm of galaxy clustering moments, in good agreement\nwith the \"negative binomial\" model, in redshift surveys, but have also reported\nthat this paradigm is not valid in real space. However, in this work we find\nthat hierarchical scaling can indeed be found in real space inside cosmic\nvoids. This is well fitted by the negative binomial model. We find this result\nto be robust against changes in void identification, galaxy mass, random\ndilutions, and redshift. We also obtain that the VPF in real space at high\nredshift approaches the negative binomial model, and therefore it is similar to\nthe VPF inside voids at the present time. This study points, for the first\ntime, towards evidence of hierarchical scaling of high-order clustering of\ngalaxies in real space inside voids, preserving the pristine structure\nformation processes of the Universe.",
                "authors": [
                    "Federico D\u00e1vila-Kurb\u00e1n",
                    "Andr\u00e9s N. Ruiz",
                    "Dante Paz",
                    "Diego Garcia Lambas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12928v1",
                    "http://arxiv.org/pdf/2311.12928v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12786v1/1.0",
                "title": "Mechanistically analyzing the effects of fine-tuning on procedurally\n  defined tasks",
                "year": 2023,
                "abstract": "Fine-tuning large pre-trained models has become the de facto strategy for\ndeveloping both task-specific and general-purpose machine learning systems,\nincluding developing models that are safe to deploy. Despite its clear\nimportance, there has been minimal work that explains how fine-tuning alters\nthe underlying capabilities learned by a model during pretraining: does\nfine-tuning yield entirely novel capabilities or does it just modulate existing\nones? We address this question empirically in synthetic, controlled settings\nwhere we can use mechanistic interpretability tools (e.g., network pruning and\nprobing) to understand how the model's underlying capabilities are changing. We\nperform an extensive analysis of the effects of fine-tuning in these settings,\nand show that: (i) fine-tuning rarely alters the underlying model capabilities;\n(ii) a minimal transformation, which we call a 'wrapper', is typically learned\non top of the underlying model capabilities, creating the illusion that they\nhave been modified; and (iii) further fine-tuning on a task where such hidden\ncapabilities are relevant leads to sample-efficient 'revival' of the\ncapability, i.e., the model begins reusing these capability after only a few\ngradient steps. This indicates that practitioners can unintentionally remove a\nmodel's safety wrapper merely by fine-tuning it on a, e.g., superficially\nunrelated, downstream task. We additionally perform analysis on language models\ntrained on the TinyStories dataset to support our claims in a more realistic\nsetup.",
                "authors": [
                    "Samyak Jain",
                    "Robert Kirk",
                    "Ekdeep Singh Lubana",
                    "Robert P. Dick",
                    "Hidenori Tanaka",
                    "Edward Grefenstette",
                    "Tim Rockt\u00e4schel",
                    "David Scott Krueger"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12786v1",
                    "http://arxiv.org/pdf/2311.12786v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12785v1/1.0",
                "title": "Prompting Frameworks for Large Language Models: A Survey",
                "year": 2023,
                "abstract": "Since the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large\nlanguage models (LLMs) have made significant advancements in both academia and\nindustry, bringing about a fundamental engineering paradigm shift in many\nareas. While LLMs are powerful, it is also crucial to best use their power\nwhere \"prompt'' plays a core role. However, the booming LLMs themselves,\nincluding excellent APIs like ChatGPT, have several inherent limitations: 1)\ntemporal lag of training data, and 2) the lack of physical capabilities to\nperform external actions. Recently, we have observed the trend of utilizing\nprompt-based tools to better utilize the power of LLMs for downstream tasks,\nbut a lack of systematic literature and standardized terminology, partly due to\nthe rapid evolution of this field. Therefore, in this work, we survey related\nprompting tools and promote the concept of the \"Prompting Framework\" (PF), i.e.\nthe framework for managing, simplifying, and facilitating interaction with\nlarge language models. We define the lifecycle of the PF as a hierarchical\nstructure, from bottom to top, namely: Data Level, Base Level, Execute Level,\nand Service Level. We also systematically depict the overall landscape of the\nemerging PF field and discuss potential future research and challenges. To\ncontinuously track the developments in this area, we maintain a repository at\nhttps://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful\nresource sharing platform for both academic and industry in this field.",
                "authors": [
                    "Xiaoxia Liu",
                    "Jingyi Wang",
                    "Jun Sun",
                    "Xiaohan Yuan",
                    "Guoliang Dong",
                    "Peng Di",
                    "Wenhai Wang",
                    "Dongxia Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12785v1",
                    "http://arxiv.org/pdf/2311.12785v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12783v1/1.0",
                "title": "Suppression of thermal smearing in a feedback-driven atomic size\n  Josephson junction",
                "year": 2023,
                "abstract": "The ultimate spatial limit to establish a Josephson coupling between two\nsuperconducting electrodes is an atomic-scale vacuum tunneling junction. The\nJosephson effect in such ultrasmall junctions has been widely used to study\nsuperconducting materials, providing a powerful probe of the spatial variations\nof the superfluid density. Furthermore, studies of the supercurrent and\ncharging effects unveiled new, frequency dependent, switching dynamics and\nthermal processes emerging due to the small size of the junctions. However, the\nCooper pair current magnitude was considerably reduced by thermal fluctuations.\nHere we show that a feedback element induces a time-dependent bistable regime\nwhich periodically restores the zero voltage state. We find that the\ntime-averaged current within the bistable regime is independent of thermal\nsmearing, opening new avenues to study superconducting phenomena at the\nnanoscale.",
                "authors": [
                    "Samuel D. Escribano",
                    "V\u00edctor Barrena",
                    "David Perconte",
                    "Jose Antonio Moreno",
                    "Marta Fern\u00e1ndez Lomana",
                    "Miguel \u00c1gueda",
                    "Edwin Herrera",
                    "Beilun Wu",
                    "Jose Gabriel Rodrigo",
                    "Elsa Prada",
                    "Isabel Guillam\u00f3n",
                    "Alfredo Levy Yeyati",
                    "Hermann Suderow"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12783v1",
                    "http://arxiv.org/pdf/2311.12783v1"
                ],
                "primary_category": "cond-mat.supr-con",
                "categories": [
                    "cond-mat.supr-con"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12919v2/1.0",
                "title": "SPOT! Revisiting Video-Language Models for Event Understanding",
                "year": 2023,
                "abstract": "Understanding videos is an important research topic for multimodal learning.\nLeveraging large-scale datasets of web-crawled video-text pairs as weak\nsupervision has become a pre-training paradigm for learning joint\nrepresentations and showcased remarkable potential in video understanding\ntasks. However, videos can be multi-event and multi-grained, while these\nvideo-text pairs usually contain only broad-level video captions. This raises a\nquestion: with such weak supervision, can video representation in\nvideo-language models gain the ability to distinguish even factual\ndiscrepancies in textual description and understand fine-grained events? To\naddress this, we introduce SPOT Prober, to benchmark existing video-language\nmodels's capacities of distinguishing event-level discrepancies as an indicator\nof models' event understanding ability. Our approach involves extracting events\nas tuples (<Subject, Predicate, Object, Attribute, Timestamps>) from videos and\ngenerating false event tuples by manipulating tuple components systematically.\nWe reevaluate the existing video-language models with these positive and\nnegative captions and find they fail to distinguish most of the manipulated\nevents. Based on our findings, we propose to plug in these manipulated event\ncaptions as hard negative samples and find them effective in enhancing models\nfor event understanding.",
                "authors": [
                    "Gengyuan Zhang",
                    "Jinhe Bi",
                    "Jindong Gu",
                    "Yanyu Chen",
                    "Volker Tresp"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12919v2",
                    "http://arxiv.org/pdf/2311.12919v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14735v1/1.0",
                "title": "Generative Machine Learning for Multivariate Equity Returns",
                "year": 2023,
                "abstract": "The use of machine learning to generate synthetic data has grown in\npopularity with the proliferation of text-to-image models and especially large\nlanguage models. The core methodology these models use is to learn the\ndistribution of the underlying data, similar to the classical methods common in\nfinance of fitting statistical models to data. In this work, we explore the\nefficacy of using modern machine learning methods, specifically conditional\nimportance weighted autoencoders (a variant of variational autoencoders) and\nconditional normalizing flows, for the task of modeling the returns of\nequities. The main problem we work to address is modeling the joint\ndistribution of all the members of the S&P 500, or, in other words, learning a\n500-dimensional joint distribution. We show that this generative model has a\nbroad range of applications in finance, including generating realistic\nsynthetic data, volatility and correlation estimation, risk analysis (e.g.,\nvalue at risk, or VaR, of portfolios), and portfolio optimization.",
                "authors": [
                    "Ruslan Tepelyan",
                    "Achintya Gopal"
                ],
                "url": [
                    "http://dx.doi.org/10.1145/3604237.3626884",
                    "http://arxiv.org/abs/2311.14735v1",
                    "http://arxiv.org/pdf/2311.14735v1"
                ],
                "primary_category": "q-fin.ST",
                "categories": [
                    "q-fin.ST",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14743v6/1.0",
                "title": "A Baseline Analysis of Reward Models' Ability To Accurately Analyze\n  Foundation Models Under Distribution Shift",
                "year": 2023,
                "abstract": "Foundation models, specifically Large Language Models (LLM's), have lately\ngained wide-spread attention and adoption. Reinforcement Learning with Human\nFeedback (RLHF) involves training a reward model to capture desired behaviors,\nwhich is then used to align LLM's. These reward models are additionally used at\ninference-time to estimate LLM responses' adherence to those desired behaviors.\nHowever, there is little work measuring how robust these reward models are to\ndistribution shifts. In this work, we evaluate how reward model performance -\nmeasured via accuracy and calibration (i.e. alignment between accuracy and\nconfidence) - is affected by distribution shift. We show novel calibration\npatterns and accuracy drops due to OOD prompts and responses, and that the\nreward model is more sensitive to shifts in responses than prompts.\nAdditionally, we adapt an OOD detection technique commonly used in\nclassification to the reward model setting to detect these distribution shifts\nin prompts and responses.",
                "authors": [
                    "Will LeVine",
                    "Ben Pikus",
                    "Anthony Chen",
                    "Sean Hendryx"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14743v6",
                    "http://arxiv.org/pdf/2311.14743v6"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12772v1/1.0",
                "title": "The T-Complexity Costs of Error Correction for Control Flow in Quantum\n  Computation",
                "year": 2023,
                "abstract": "Numerous quantum algorithms require the use of quantum error correction to\novercome the intrinsic unreliability of physical qubits. However, error\ncorrection imposes a unique performance bottleneck, known as T-complexity, that\ncan make an implementation of an algorithm as a quantum program run more slowly\nthan on idealized hardware. In this work, we identify that programming\nabstractions for control flow, such as the quantum if-statement, can introduce\npolynomial increases in the T-complexity of a program. If not mitigated, this\nslowdown can diminish the computational advantage of a quantum algorithm.\n  To enable reasoning about the costs of control flow, we present a cost model,\nusing which a developer can analyze the T-complexity of a program under quantum\nerror correction and pinpoint the sources of slowdown. We also present a set of\nprogram-level optimizations, using which a developer can rewrite a program to\nreduce its T-complexity, predict the T-complexity of the optimized program\nusing the cost model, and then compile it to an efficient circuit via a\nstraightforward strategy.\n  We implement the program-level optimizations in Spire, an extension of the\nTower quantum compiler. Using a set of 11 benchmark programs that use control\nflow, we show that the cost model is accurate, and that Spire's optimizations\nrecover programs that are asymptotically efficient, meaning their runtime\nT-complexity under error correction is equal to their time complexity on\nidealized hardware.\n  Our results show that optimizing a program before it is compiled to a circuit\ncan yield better results than compiling the program to an inefficient circuit\nand then invoking a quantum circuit optimizer found in prior work. For our\nbenchmarks, only 2 of 8 existing circuit optimizers recover circuits with\nasymptotically efficient T-complexity. Compared to these 2 optimizers, Spire\nuses 54x to 2400x less compile time.",
                "authors": [
                    "Charles Yuan",
                    "Michael Carbin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12772v1",
                    "http://arxiv.org/pdf/2311.12772v1"
                ],
                "primary_category": "cs.PL",
                "categories": [
                    "cs.PL",
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12770v1/1.0",
                "title": "Swift Parameter-free Attention Network for Efficient Super-Resolution",
                "year": 2023,
                "abstract": "Single Image Super-Resolution (SISR) is a crucial task in low-level computer\nvision, aiming to reconstruct high-resolution images from low-resolution\ncounterparts. Conventional attention mechanisms have significantly improved\nSISR performance but often result in complex network structures and large\nnumber of parameters, leading to slow inference speed and large model size. To\naddress this issue, we propose the Swift Parameter-free Attention Network\n(SPAN), a highly efficient SISR model that balances parameter count, inference\nspeed, and image quality. SPAN employs a novel parameter-free attention\nmechanism, which leverages symmetric activation functions and residual\nconnections to enhance high-contribution information and suppress redundant\ninformation. Our theoretical analysis demonstrates the effectiveness of this\ndesign in achieving the attention mechanism's purpose. We evaluate SPAN on\nmultiple benchmarks, showing that it outperforms existing efficient\nsuper-resolution models in terms of both image quality and inference speed,\nachieving a significant quality-speed trade-off. This makes SPAN highly\nsuitable for real-world applications, particularly in resource-constrained\nscenarios. Notably, our model attains the best PSNR of 27.09 dB, and the test\nruntime of our team is reduced by 7.08ms in the NTIRE 2023 efficient\nsuper-resolution challenge. Our code and models are made publicly available at\n\\url{https://github.com/hongyuanyu/SPAN}.",
                "authors": [
                    "Cheng Wan",
                    "Hongyuan Yu",
                    "Zhiqi Li",
                    "Yihang Chen",
                    "Yajun Zou",
                    "Yuqing Liu",
                    "Xuanwu Yin",
                    "Kunlong Zuo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12770v1",
                    "http://arxiv.org/pdf/2311.12770v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12918v1/1.0",
                "title": "Deep Learning-Based Real-Time Quality Control of Standard Video\n  Compression for Live Streaming",
                "year": 2023,
                "abstract": "Ensuring high-quality video content for wireless users has become\nincreasingly vital. Nevertheless, maintaining a consistent level of video\nquality faces challenges due to the fluctuating encoded bitrate, primarily\ncaused by dynamic video content, especially in live streaming scenarios. Video\ncompression is typically employed to eliminate unnecessary redundancies within\nand between video frames, thereby reducing the required bandwidth for video\ntransmission. The encoded bitrate and the quality of the compressed video\ndepend on encoder parameters, specifically, the quantization parameter (QP).\nPoor choices of encoder parameters can result in reduced bandwidth efficiency\nand high likelihood of non-conformance. Non-conformance refers to the violation\nof the peak signal-to-noise ratio (PSNR) constraint for an encoded video\nsegment. To address these issues, a real-time deep learning-based H.264\ncontroller is proposed. This controller dynamically estimates the optimal\nencoder parameters based on the content of a video chunk with minimal delay.\nThe objective is to maintain video quality in terms of PSNR above a specified\nthreshold while minimizing the average bitrate of the compressed video.\nExperimental results, conducted on both QCIF dataset and a diverse range of\nrandom videos from public datasets, validate the effectiveness of this\napproach. Notably, it achieves improvements of up to 2.5 times in average\nbandwidth usage compared to the state-of-the-art adaptive bitrate video\nstreaming, with a negligible non-conformance probability below $10^{-2}$.",
                "authors": [
                    "Matin Mortaheb",
                    "Mohammad A. Amir Khojastepour",
                    "Srimat T. Chakradhar",
                    "Sennur Ulukus"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12918v1",
                    "http://arxiv.org/pdf/2311.12918v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.IT",
                    "cs.LG",
                    "cs.NI",
                    "cs.SY",
                    "eess.SY",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12916v1/1.0",
                "title": "Optimal control of sweeping processes in unmanned surface vehicle and\n  nanoparticle modeling",
                "year": 2023,
                "abstract": "This paper addresses novel applications to practical modeling of the newly\ndeveloped theory of necessary optimality conditions in controlled\nsweeping/Moreau processes with free time and pointwise control and state\nconstraints. Problems of this type appear, in particular, in dynamical models\ndealing with unmanned surface vehicles (USVs) and nanoparticles. We formulate\noptimal control problems for a general class of such dynamical systems and show\nthat the developed necessary optimality conditions for constrained free-time\ncontrolled sweeping processes lead us to designing efficient procedures to\nsolve practical models of this class. Moreover, the paper contains numerical\ncalculations of optimal solutions to marine USVs and nanoparticle models in\nspecific situations. Overall, this study contributes to the advancement of\noptimal control theory for constrained sweeping processes and its practical\napplications in the fields of marine USVs and nanoparticle modeling.",
                "authors": [
                    "Boris S. Mordukhovich",
                    "Dao Nguyen",
                    "Trang Nguyen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12916v1",
                    "http://arxiv.org/pdf/2311.12916v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC",
                    "49J52, 49J53, 49K24, 49M25, 90C30"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.13608v1/1.0",
                "title": "Breathing Life Into Sketches Using Text-to-Video Priors",
                "year": 2023,
                "abstract": "A sketch is one of the most intuitive and versatile tools humans use to\nconvey their ideas visually. An animated sketch opens another dimension to the\nexpression of ideas and is widely used by designers for a variety of purposes.\nAnimating sketches is a laborious process, requiring extensive experience and\nprofessional design skills. In this work, we present a method that\nautomatically adds motion to a single-subject sketch (hence, \"breathing life\ninto it\"), merely by providing a text prompt indicating the desired motion. The\noutput is a short animation provided in vector representation, which can be\neasily edited. Our method does not require extensive training, but instead\nleverages the motion prior of a large pretrained text-to-video diffusion model\nusing a score-distillation loss to guide the placement of strokes. To promote\nnatural and smooth motion and to better preserve the sketch's appearance, we\nmodel the learned motion through two components. The first governs small local\ndeformations and the second controls global affine transformations.\nSurprisingly, we find that even models that struggle to generate sketch videos\non their own can still serve as a useful backbone for animating abstract\nrepresentations.",
                "authors": [
                    "Rinon Gal",
                    "Yael Vinker",
                    "Yuval Alaluf",
                    "Amit H. Bermano",
                    "Daniel Cohen-Or",
                    "Ariel Shamir",
                    "Gal Chechik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.13608v1",
                    "http://arxiv.org/pdf/2311.13608v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.GR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14734v1/1.0",
                "title": "Internet of Mirrors for Connected Healthcare and Beauty: A Prospective\n  Vision",
                "year": 2023,
                "abstract": "With the shift towards smart objects and automated services in many\nindustries, the health and beauty industries are also becoming increasingly\ninvolved in AI-driven smart systems. There is a rising market demand for\npersonalised services and a need for unified platforms in many sectors,\nspecifically the cosmetics and healthcare industries. Alongside this rising\ndemand, there are two major gaps when considering the integration of autonomous\nsystems within these sectors. Firstly, the existing smart systems in the\ncosmetics industry are limited to single-purpose products and the employed\ntechnologies are not widespread enough to support the growing consumer demand\nfor personalisation. Secondly, despite the rise of smart devices in healthcare,\nthe current state-of-the-art services do not fulfil the accessibility demands\nand holistic nature of healthcare. To bridge these gaps, we propose integrating\nautonomous systems with health and beauty services through a unified visual\nplatform coined as the Internet-of-Mirrors (IoM), an interconnected system of\nsmart mirrors with sensing and communication capabilities where the smart\nmirror functions as an immersive visual dashboard to provide personalised\nservices for health and beauty consultations and routines. We aim to present an\noverview of current state-of-the-art technologies that will enable the\ndevelopment of the IoM as well as provide a practical vision of this system\nwith innovative scenarios to give a forward-looking vision for assistive\ntechnologies. We also discuss the missing capabilities and challenges the\ndevelopment of the IoM would face and outline future research directions that\nwill support the realisation of our proposed framework.",
                "authors": [
                    "Haneen Fatima",
                    "Muhammad Ali Imran",
                    "Ahmad Taha",
                    "Lina Mohjazi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14734v1",
                    "http://arxiv.org/pdf/2311.14734v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12755v1/1.0",
                "title": "Digital Twin Framework for Optimal and Autonomous Decision-Making in\n  Cyber-Physical Systems: Enhancing Reliability and Adaptability in the Oil and\n  Gas Industry",
                "year": 2023,
                "abstract": "The concept of creating a virtual copy of a complete Cyber-Physical System\nopens up numerous possibilities, including real-time assessments of the\nphysical environment and continuous learning from the system to provide\nreliable and precise information. This process, known as the twinning process\nor the development of a digital twin (DT), has been widely adopted across\nvarious industries. However, challenges arise when considering the\ncomputational demands of implementing AI models, such as those employed in\ndigital twins, in real-time information exchange scenarios. This work proposes\na digital twin framework for optimal and autonomous decision-making applied to\na gas-lift process in the oil and gas industry, focusing on enhancing the\nrobustness and adaptability of the DT. The framework combines Bayesian\ninference, Monte Carlo simulations, transfer learning, online learning, and\nnovel strategies to confer cognition to the DT, including model\nhyperdimensional reduction and cognitive tack. Consequently, creating a\nframework for efficient, reliable, and trustworthy DT identification was\npossible. The proposed approach addresses the current gap in the literature\nregarding integrating various learning techniques and uncertainty management in\ndigital twin strategies. This digital twin framework aims to provide a reliable\nand efficient system capable of adapting to changing environments and\nincorporating prediction uncertainty, thus enhancing the overall\ndecision-making process in complex, real-world scenarios. Additionally, this\nwork lays the foundation for further developments in digital twins for process\nsystems engineering, potentially fostering new advancements and applications\nacross various industrial sectors.",
                "authors": [
                    "Carine Menezes Rebello",
                    "Johannes J\u00e4schkea",
                    "Idelfonso B. R. Nogueira"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12755v1",
                    "http://arxiv.org/pdf/2311.12755v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12752v1/1.0",
                "title": "An Improved Line-Point Low-Degree Test",
                "year": 2023,
                "abstract": "We prove that the most natural low-degree test for polynomials over finite\nfields is ``robust'' in the high-error regime for linear-sized fields.\nSpecifically we consider the ``local'' agreement of a function $f:\n\\mathbb{F}_q^m \\to \\mathbb{F}_q$ from the space of degree-$d$ polynomials,\ni.e., the expected agreement of the function from univariate degree-$d$\npolynomials over a randomly chosen line in $\\mathbb{F}_q^m$, and prove that if\nthis local agreement is $\\epsilon \\geq \\Omega((\\frac{d}{q})^\\tau))$ for some\nfixed $\\tau > 0$, then there is a global degree-$d$ polynomial $Q:\n\\mathbb{F}_q^m \\to \\mathbb{F}_q$ with agreement nearly $\\epsilon$ with $f$.\nThis settles a long-standing open question in the area of low-degree testing,\nyielding an $O(d)$-query robust test in the ``high-error'' regime (i.e., when\n$\\epsilon < \\frac{1}{2}$). The previous results in this space either required\n$\\epsilon > \\frac{1}{2}$ (Polishchuk \\& Spielman, STOC 1994), or $q =\n\\Omega(d^4)$ (Arora \\& Sudan, Combinatorica 2003), or needed to measure local\ndistance on $2$-dimensional ``planes'' rather than one-dimensional lines\nleading to $\\Omega(d^2)$-query complexity (Raz \\& Safra, STOC 1997).\n  Our analysis follows the spirit of most previous analyses in first analyzing\nthe low-variable case ($m = O(1)$) and then ``bootstrapping'' to general\nmultivariate settings. Our main technical novelty is a new analysis in the\nbivariate setting that exploits a previously known connection between\nmultivariate factorization and finding (or testing) low-degree polynomials, in\na non ``black-box'' manner. A second contribution is a bootstrapping analysis\nwhich manages to lift analyses for $m=2$ directly to analyses for general $m$,\nwhere previous works needed to work with $m = 3$ or $m = 4$ -- arguably this\nbootstrapping is significantly simpler than those in prior works.",
                "authors": [
                    "Prahladh Harsha",
                    "Mrinal Kumar",
                    "Ramprasad Saptharishi",
                    "Madhu Sudan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12752v1",
                    "http://arxiv.org/pdf/2311.12752v1"
                ],
                "primary_category": "cs.CC",
                "categories": [
                    "cs.CC",
                    "68Q25, 11T06",
                    "I.1.2; E.4"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12751v1/1.0",
                "title": "Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with\n  Spatially Relation Matching",
                "year": 2023,
                "abstract": "Drone navigation through natural language commands remains a significant\nchallenge due to the lack of publicly available multi-modal datasets and the\nintricate demands of fine-grained visual-text alignment. In response to this\npressing need, we present a new human-computer interaction annotation benchmark\ncalled GeoText-1652, meticulously curated through a robust Large Language Model\n(LLM)-based data generation framework and the expertise of pre-trained vision\nmodels. This new dataset seamlessly extends the existing image dataset, \\ie,\nUniversity-1652, with spatial-aware text annotations, encompassing intricate\nimage-text-bounding box associations. Besides, we introduce a new optimization\nobjective to leverage fine-grained spatial associations, called blending\nspatial matching, for region-level spatial relation matching. Extensive\nexperiments reveal that our approach maintains an exceptional recall rate under\nvarying description complexities. This underscores the promising potential of\nour approach in elevating drone control and navigation through the seamless\nintegration of natural language commands in real-world scenarios.",
                "authors": [
                    "Meng Chu",
                    "Zhedong Zheng",
                    "Wei Ji",
                    "Tat-Seng Chua"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12751v1",
                    "http://arxiv.org/pdf/2311.12751v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.MM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12750v1/1.0",
                "title": "Learning to Optimise Wind Farms with Graph Transformers",
                "year": 2023,
                "abstract": "This work proposes a novel data-driven model capable of providing accurate\npredictions for the power generation of all wind turbines in wind farms of\narbitrary layout, yaw angle configurations and wind conditions. The proposed\nmodel functions by encoding a wind farm into a fully-connected graph and\nprocessing the graph representation through a graph transformer. The graph\ntransformer surrogate is shown to generalise well and is able to uncover latent\nstructural patterns within the graph representation of wind farms. It is\ndemonstrated how the resulting surrogate model can be used to optimise yaw\nangle configurations using genetic algorithms, achieving similar levels of\naccuracy to industrially-standard wind farm simulation tools while only taking\na fraction of the computational cost.",
                "authors": [
                    "Siyi Li",
                    "Arnaud Robert",
                    "A. Aldo Faisal",
                    "Matthew D. Piggott"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12750v1",
                    "http://arxiv.org/pdf/2311.12750v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12749v1/1.0",
                "title": "Bubble departure and sliding in high-pressure flow boiling of water",
                "year": 2023,
                "abstract": "Bubble growth, departure and sliding in low-pressure flow boiling has\nreceived considerable attention in the past. However, most applications of\nboiling heat transfer rely on high-pressure flow boiling, for which very little\nis known, as experimental data are scarce and very difficult to obtain. In this\nwork, we conduct an experiment using high-resolution optical techniques. By\ncombining backlit shadowgraphy and phase-detection imaging, we track bubble\nshape and physical footprint with high spatial (6 $\\mu$m) and temporal (33\n$\\mu$s) resolution, as well as bubble size and position as bubbles nucleate and\nslide on top of the heated surface. We show that at pressures above 1 MPa,\nbubbles grow in a heat-diffusion controlled regime and retain a spherical shape\nthroughout the growth and sliding process. We analytically derive\nnon-dimensional numbers to correlate bubble velocity and liquid velocity\nthroughout the turbulent boundary layer and predict the sliding of bubbles on\nthe surface, solely from physical properties and bubble growth rate. We also\nshow that these non-dimensional solutions can be leveraged to formulate\nelementary criteria that predict the effect of pressure and flow rate on bubble\ndeparture diameter and growth time.",
                "authors": [
                    "Artyom Kossolapov",
                    "Matthew T. Hughes",
                    "Bren Phillips",
                    "Matteo Bucci"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12749v1",
                    "http://arxiv.org/pdf/2311.12749v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12747v2/1.0",
                "title": "Effects of substrate corrugation during helium adsorption on graphene in\n  the grand canonical ensemble",
                "year": 2023,
                "abstract": "Adsorption of 4He on atomically flat substrates such as graphene provides a\nroute towards the engineering of low dimensional quantum phases including\nsuperfluids and strongly interacting insulators. In this study, we explore the\neffects of graphene corrugation on the helium adsorption process via quantum\nMonte Carlo simulations in the grand canonical ensemble. We utilize an\nempirical adsorption potential based on the superposition of individual\nhelium-carbon interactions and systematically control corrugation, from a\nsmooth membrane to the fully rough potential, via the implementation of a\ncutoff in reciprocal space. The results highlight the importance of using a\nfully corrugated potential to understand the plethora of commensurate and\nincommensurate phases in the first adsorbed layer. Surprisingly, some residual\neffects of corrugation are still present before and during the promotion and\nonset of a second adsorbed layer, where a smooth adsorption can lead to\nenhanced particle fluctuations in a helium-interaction dominated regime.",
                "authors": [
                    "Gage Erwin",
                    "Adrian Del Maestro"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12747v2",
                    "http://arxiv.org/pdf/2311.12747v2"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12746v1/1.0",
                "title": "Comparing lax functors of $(\\infty,2)$-categories",
                "year": 2023,
                "abstract": "In this work, we study oplax normalised functors of $(\\infty,2)$-categories.\nOur main theorem is a comparison between the notion of oplax normalised functor\nof scaled simplicial sets due to Gagna-Harpaz-Lanari and the corresponding\nnotion in the setting of complete Segal objects in $(\\infty,1)$-categories\nstudied by Gaitsgory and Rozenblyum. As a corollary, we derive that the Gray\ntensor product of $(\\infty,2)$-categories as defined by Gaitsgory-Rozenblyum is\nequivalent to that of Gagna-Harpaz-Lanari.\n  Moreover, we construct an $(\\infty,2)$-categorical variant of the quintet\nfunctor of Ehresmann, from the $(\\infty,2)$-category of $(\\infty,2)$-categories\nto the $(\\infty,2)$-category of double $(\\infty,1)$-categories and show that it\nis fully faithful.\n  As a key technical ingredient, given $(\\mathbb{C},E)$ an\n$(\\infty,2)$-category equipped with a collection of morphisms and a functor of\n$(\\infty,2)$-categories $f:\\mathbb{C}\\to \\mathbb{D}$, we construct a right\nadjoint to the restriction functor $f^*$ from the $(\\infty,2)$-category of\nfunctors $\\mathbb{D} \\to \\mathbb{C}\\!\\operatorname{at}_{(\\infty,2)}$ and\nnatural transformations to the $(\\infty,2)$-category of functors $\\mathbb{C}\n\\to \\mathbb{C}\\!\\operatorname{at}_{(\\infty,2)}$ and partially lax (according to\n$E$) natural transformations. We apply this new technology of partially lax Kan\nextensions to the study of complete Segal objects in $(\\infty,1)$-categories\nand double $(\\infty,1)$-categories which allows us to define the notion of an\nenhanced Segal object (resp. enhanced double $(\\infty,1)$-category), the former\nyielding yet another model for the theory of $(\\infty,2)$-categories.",
                "authors": [
                    "Fernando Abell\u00e1n"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12746v1",
                    "http://arxiv.org/pdf/2311.12746v1"
                ],
                "primary_category": "math.CT",
                "categories": [
                    "math.CT",
                    "math.AT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12745v1/1.0",
                "title": "Learn to Augment Network Simulators Towards Digital Network Twins",
                "year": 2023,
                "abstract": "Digital network twin (DNT) is a promising paradigm to replicate real-world\ncellular networks toward continual assessment, proactive management, and\nwhat-if analysis. Existing discussions have been focusing on using only deep\nlearning techniques to build DNTs, which raises widespread concerns regarding\ntheir generalization, explainability, and transparency. In this paper, we\nexplore an alternative approach to augment network simulators with\ncontext-aware neural agents. The main challenge lies in the non-trivial\nsimulation-to-reality (sim-to-real) discrepancy between offline simulators and\nreal-world networks. To solve the challenge, we propose a new learn-to-bridge\nalgorithm to cost-efficiently bridge the sim-to-real discrepancy in two\nalternative stages. In the first stage, we select states to query performances\nin real-world networks by using newly-designed cost-aware Bayesian\noptimization. In the second stage, we train the neural agent to learn the state\ncontext and bridge the probabilistic discrepancy based on Bayesian neural\nnetworks (BNN). In addition, we build a small-scale end-to-end network testbed\nbased on OpenAirInterface RAN and Core with USRP B210 and a smartphone, and\nreplicate the network in NS-3. The evaluation results show that, our proposed\nsolution substantially outperforms existing methods, with more than 92\\%\nreduction in the sim-to-real discrepancy.",
                "authors": [
                    "Yuru Zhang",
                    "Ming Zhao",
                    "Qiang Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12745v1",
                    "http://arxiv.org/pdf/2311.12745v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12739v1/1.0",
                "title": "Biomechanical Analysis Of Breast Cancer Cells: A Comparative Study Of\n  Invasive And Non-Invasive Cell Lines Using Digital Holographic Microscopy",
                "year": 2023,
                "abstract": "This study investigates the biomechanical properties of breast cancer cells,\nfocusing on the invasive MDA-MB-231 and non-invasive MCF-7 cell lines, using\nphase-shifting digital holographic microscopy and an acousto-holographic system\nfor non-invasive strain measurement. Findings reveal higher strain values in\nMDA-MB-231 cells, indicative of their aggressive, metastatic nature, compared\nto lower strain values in MCF-7 cells. This variance in mechanical properties,\npotentially linked to distinct metabolic states and responses to external\nstimuli, underscores the role of cellular mechanics in cancer progression. The\nstudy advances understanding of breast cancer cell mechanics, highlighting\nbiomechanical analysis as a crucial tool in cancer research and potential\ntherapeutic interventions.",
                "authors": [
                    "Hasan Berkay Abdioglu",
                    "Yagmur Isik",
                    "Merve Sevgi",
                    "Ufuk Gorkem Kirabali",
                    "Caner Karaca",
                    "Yunus Emre Mert",
                    "Defne Dedehayir",
                    "Berke Tuna Bostanci",
                    "Yasemin Basbinar",
                    "Huseyin Uvet"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12739v1",
                    "http://arxiv.org/pdf/2311.12739v1"
                ],
                "primary_category": "physics.bio-ph",
                "categories": [
                    "physics.bio-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12737v1/1.0",
                "title": "Exploring Graph Classification Techniques Under Low Data Constraints: A\n  Comprehensive Study",
                "year": 2023,
                "abstract": "This survey paper presents a brief overview of recent research on graph data\naugmentation and few-shot learning. It covers various techniques for graph data\naugmentation, including node and edge perturbation, graph coarsening, and graph\ngeneration, as well as the latest developments in few-shot learning, such as\nmeta-learning and model-agnostic meta-learning. The paper explores these areas\nin depth and delves into further sub classifications. Rule based approaches and\nlearning based approaches are surveyed under graph augmentation techniques.\nFew-Shot Learning on graphs is also studied in terms of metric learning\ntechniques and optimization-based techniques. In all, this paper provides an\nextensive array of techniques that can be employed in solving graph processing\nproblems faced in low-data scenarios.",
                "authors": [
                    "Kush Kothari",
                    "Bhavya Mehta",
                    "Reshmika Nambiar",
                    "Seema Shrawne"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/ICCCNT56998.2023.10307388",
                    "http://arxiv.org/abs/2311.12737v1",
                    "http://arxiv.org/pdf/2311.12737v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12735v1/1.0",
                "title": "LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource\n  Sentiment Analysis of Bangla Language",
                "year": 2023,
                "abstract": "This paper describes the system of the LowResource Team for Task 2 of\nBLP-2023, which involves conducting sentiment analysis on a dataset composed of\npublic posts and comments from diverse social media platforms. Our primary aim\nis to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus,\nusing various strategies including fine-tuning, dropping random tokens, and\nusing several external datasets. Our final model is an ensemble of the three\nbest BanglaBert variations. Our system has achieved overall 3rd in the Test Set\namong 30 participating teams with a score of 0.718. Additionally, we discuss\nthe promising systems that didn't perform well namely task-adaptive pertaining\nand paraphrasing using BanglaT5. Training codes and external datasets which are\nused for our system are publicly available at\nhttps://github.com/Aunabil4602/bnlp-workshop-task2-2023",
                "authors": [
                    "Aunabil Chakma",
                    "Masum Hasan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12735v1",
                    "http://arxiv.org/pdf/2311.12735v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12734v1/1.0",
                "title": "Optimal Transition Paths for AMOC Collapse and Recovery in a Stochastic\n  Box Model",
                "year": 2023,
                "abstract": "The present-day Atlantic Meridional Overturning Circulation (AMOC) is\nconsidered to be in a bi-stable regime and hence it is important to determine\nprobabilities and pathways for noise-induced transitions between its\nequilibrium states. Here, using Large Deviation Theory (LDT), the most probable\ntransition pathways for the collapse and recovery of the AMOC are computed in a\nstochastic box model of the World Ocean. This allows us to determine the\nphysical mechanisms of noise-induced AMOC transitions. We show that the most\nlikely path of an AMOC collapse starts paradoxically with a strengthening of\nthe AMOC followed by an immediate drop within a couple of years due to a short\nbut relatively strong freshwater pulse. The recovery on the other hand is a\nslow process, where the North Atlantic needs to be gradually salinified over a\ncourse of 20 years. The proposed method provides several benefits, including an\nestimate of probability ratios of collapse between various freshwater noise\nscenarios, showing that the AMOC is most vulnerable to freshwater forcing into\nthe Atlantic thermocline region.",
                "authors": [
                    "Jelle Soons",
                    "Tobias Grafke",
                    "Henk A. Dijkstra"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12734v1",
                    "http://arxiv.org/pdf/2311.12734v1"
                ],
                "primary_category": "physics.ao-ph",
                "categories": [
                    "physics.ao-ph",
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12731v1/1.0",
                "title": "Serial Monopoly on Blockchains",
                "year": 2023,
                "abstract": "We study the following problem that is motivated by Blockchains where\n``miners'' are serially given the monopoly for assembling transactions into the\nnext block. Our model has a single good that is sold repeatedly every day where\nnew demand for the good arrives every day. The novel element in our model is\nthat all unsatisfied demand from one day remains in the system and is added to\nthe new demand of the next day. Every day there is a new monopolist that gets\nto sell a fixed supply $s$ of the good and naturally chooses to do so at the\nmonopolist's price for the combined demand. What will the dynamics of the\nprices chosen by the sequence of monopolists be? What level of efficiency will\nbe obtained in the long term?\n  We start with a non-strategic analysis of users' behavior and our main result\nshows that prices keep fluctuating wildly and this is an endogenous property of\nthe model and happens even when demand is stable with nothing stochastic in the\nmodel. These price fluctuations underscore the necessity of an analysis under\nstrategic behavior of the users, which we show results in the prices being\nstable at the market equilibrium price.",
                "authors": [
                    "Noam Nisan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12731v1",
                    "http://arxiv.org/pdf/2311.12731v1"
                ],
                "primary_category": "cs.GT",
                "categories": [
                    "cs.GT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12727v2/1.0",
                "title": "Soft Random Sampling: A Theoretical and Empirical Analysis",
                "year": 2023,
                "abstract": "Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.",
                "authors": [
                    "Xiaodong Cui",
                    "Ashish Mittal",
                    "Songtao Lu",
                    "Wei Zhang",
                    "George Saon",
                    "Brian Kingsbury"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12727v2",
                    "http://arxiv.org/pdf/2311.12727v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12721v1/1.0",
                "title": "Satellite Swarms for Narrow Beamwidth Applications",
                "year": 2023,
                "abstract": "Satellite swarms have recently gained attention in the space industry due to\ntheir ability to provide extremely narrow beamwidths at a lower cost than\nsingle satellite systems. This paper proposes a concept for a satellite swarm\nusing a distributed subarray configuration based on a 2D normal probability\ndistribution. The swarm comprises multiple small satellites acting as subarrays\nof a big aperture array limited by a radius of 20000 wavelengths working at a\ncentral frequency of 19 GHz. The main advantage of this approach is that the\ndistributed subarrays can provide extremely directive beams and beamforming\ncapabilities that are not possible using a conventional antenna and satellite\ndesign. The proposed swarm concept is analyzed, and the simulation results show\nthat the radiation pattern achieves a beamwidth as narrow as 0.0015-degrees\nwith a maximum side lobe level of 18.8 dB and a grating lobe level of 14.8 dB.\nThis concept can be used for high data rates applications or emergency systems.",
                "authors": [
                    "Juan A. V\u00e1squez-Peralvo",
                    "Juan Carlos Merlano Duncan",
                    "Geoffrey Eappen",
                    "Symeon Chatzinotas"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12721v1",
                    "http://arxiv.org/pdf/2311.12721v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12720v1/1.0",
                "title": "LiFi: Learn to Incentivize Federated Learning in Automotive Edge\n  Computing",
                "year": 2023,
                "abstract": "Federated learning (FL) is the promising privacy-preserve approach to\ncontinually update the central machine learning (ML) model (e.g., object\ndetectors in edge servers) by aggregating the gradients obtained from local\nobservation data in distributed connected and automated vehicles (CAVs). The\nincentive mechanism is to incentivize individual selfish CAVs to participate in\nFL towards the improvement of overall model accuracy. It is, however,\nchallenging to design the incentive mechanism, due to the complex correlation\nbetween the overall model accuracy and unknown incentive sensitivity of CAVs,\nespecially under the non-independent and identically distributed (Non-IID) data\nof individual CAVs. In this paper, we propose a new learn-to-incentivize\nalgorithm to adaptively allocate rewards to individual CAVs under unknown\nsensitivity functions. First, we gradually learn the unknown sensitivity\nfunction of individual CAVs with accumulative observations, by using\ncompute-efficient Gaussian process regression (GPR). Second, we iteratively\nupdate the reward allocation to individual CAVs with new sampled gradients,\nderived from GPR. Third, we project the updated reward allocations to comply\nwith the total budget. We evaluate the performance of extensive simulations,\nwhere the simulation parameters are obtained from realistic profiling of the\nCIFAR-10 dataset and NVIDIA RTX 3080 GPU. The results show that our proposed\nalgorithm substantially outperforms existing solutions, in terms of accuracy,\nscalability, and adaptability.",
                "authors": [
                    "Ming Zhao",
                    "Yuru Zhang",
                    "Qiang Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12720v1",
                    "http://arxiv.org/pdf/2311.12720v1"
                ],
                "primary_category": "cs.NI",
                "categories": [
                    "cs.NI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12719v1/1.0",
                "title": "Development of a Legal Document AI-Chatbot",
                "year": 2023,
                "abstract": "With the exponential growth of digital data and the increasing complexity of\nlegal documentation, there is a pressing need for efficient and intelligent\ntools to streamline the handling of legal documents.With the recent\ndevelopments in the AI field, especially in chatbots, it cannot be ignored as a\nvery compelling solution to this problem.An insight into the process of\ncreating a Legal Documentation AI Chatbot with as many relevant features as\npossible within the given time frame is presented.The development of each\ncomponent of the chatbot is presented in detail.Each component's workings and\nfunctionality has been discussed.Starting from the build of the Android app and\nthe Langchain query processing code till the integration of both through a\nFlask backend and REST API methods.",
                "authors": [
                    "Pranav Nataraj Devaraj",
                    "Rakesh Teja P V",
                    "Aaryav Gangrade",
                    "Manoj Kumar R"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12719v1",
                    "http://arxiv.org/pdf/2311.12719v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12715v1/1.0",
                "title": "Attacks of fairness in Federated Learning",
                "year": 2023,
                "abstract": "Federated Learning is an important emerging distributed training paradigm\nthat keeps data private on clients. It is now well understood that by\ncontrolling only a small subset of FL clients, it is possible to introduce a\nbackdoor to a federated learning model, in the presence of certain attributes.\nIn this paper, we present a new type of attack that compromises the fairness of\nthe trained model. Fairness is understood to be the attribute-level performance\ndistribution of a trained model. It is particularly salient in domains where,\nfor example, skewed accuracy discrimination between subpopulations could have\ndisastrous consequences. We find that by employing a threat model similar to\nthat of a backdoor attack, an attacker is able to influence the aggregated\nmodel to have an unfair performance distribution between any given set of\nattributes. Furthermore, we find that this attack is possible by controlling\nonly a single client. While combating naturally induced unfairness in FL has\npreviously been discussed in depth, its artificially induced kind has been\nneglected. We show that defending against attacks on fairness should be a\ncritical consideration in any situation where unfairness in a trained model\ncould benefit a user who participated in its training.",
                "authors": [
                    "Joseph Rance",
                    "Filip Svoboda"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12715v1",
                    "http://arxiv.org/pdf/2311.12715v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12713v2/1.0",
                "title": "Alpha Zero for Physics: Application of Symbolic Regression with Alpha\n  Zero to find the analytical methods in physics",
                "year": 2023,
                "abstract": "Machine learning with neural networks is now becoming a more and more\npowerful tool for various tasks, such as natural language processing, image\nrecognition, winning the game, and even for the issues of physics. Although\nthere are many studies on the application of machine learning to numerical\ncalculation and assistance of experiments, the methods of applying machine\nlearning to find the analytical method are poorly studied. In this paper, we\npropose the frameworks of developing analytical methods in physics by using the\nsymbolic regression with the Alpha Zero algorithm, that is Alpha Zero for\nphysics (AZfP). As a demonstration, we show that AZfP can derive the\nhigh-frequency expansion in the Floquet systems. AZfP may have the possibility\nof developing a new theoretical framework in physics.",
                "authors": [
                    "Yoshihiro Michishita"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12713v2",
                    "http://arxiv.org/pdf/2311.12713v2"
                ],
                "primary_category": "physics.comp-ph",
                "categories": [
                    "physics.comp-ph",
                    "cond-mat.dis-nn",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12707v1/1.0",
                "title": "Keeping Users Engaged During Repeated Administration of the Same\n  Questionnaire: Using Large Language Models to Reliably Diversify Questions",
                "year": 2023,
                "abstract": "Standardized, validated questionnaires are vital tools in HCI research and\nhealthcare, offering dependable self-report data. However, their repeated use\nin longitudinal or pre-post studies can induce respondent fatigue, impacting\ndata quality via response biases and decreased response rates. We propose\nutilizing large language models (LLMs) to generate diverse questionnaire\nversions while retaining good psychometric properties. In a longitudinal study,\nparticipants engaged with our agent system and responded daily for two weeks to\neither a standardized depression questionnaire or one of two LLM-generated\nquestionnaire variants, alongside a validated depression questionnaire.\nPsychometric testing revealed consistent covariation between the external\ncriterion and the focal measure administered across the three conditions,\ndemonstrating the reliability and validity of the LLM-generated variants.\nParticipants found the repeated administration of the standardized\nquestionnaire significantly more repetitive compared to the variants. Our\nfindings highlight the potential of LLM-generated variants to invigorate\nquestionnaires, fostering engagement and interest without compromising\nvalidity.",
                "authors": [
                    "Hye Sun Yun",
                    "Mehdi Arjmand",
                    "Phillip Raymond Sherlock",
                    "Michael Paasche-Orlow",
                    "James W. Griffith",
                    "Timothy Bickmore"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12707v1",
                    "http://arxiv.org/pdf/2311.12707v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12706v1/1.0",
                "title": "Learning-based Array Configuration-Independent Binaural Audio\n  Telepresence with Scalable Signal Enhancement and Ambience Preservation",
                "year": 2023,
                "abstract": "Audio Telepresence (AT) aims to create an immersive experience of the audio\nscene at the far end for the user(s) at the near end. The application of AT\ncould encompass scenarios with varying degrees of emphasis on signal\nenhancement and ambience preservation. It is desirable for an AT system to be\nscalable between these two extremes. To this end, we propose an array-based\nBinaural AT (BAT) system using the DeepFilterNet as the backbone to convert the\narray microphone signals into the Head-Related Transfer Function\n(HRTF)-filtered signals, with a tunable weighting between signal enhancement\nand ambience preservation. An array configuration-independent Spatial COherence\nREpresentation (SCORE) feature is proposed for the model training so that the\nnetwork remains robust to different array geometries and sensor counts.\nmagnitude-weighted Interaural Phase Difference error (mw-IPDe),\nmagnitude-weighted Interaural Level Difference error (mw-ILDe), and modified\nScale-Invariant Signal-to-Distortion Ratio (mSI-SDR) are defined as performance\nmetrics for objective evaluation. Subjective listening tests were also\nperformed to validate the proposed BAT system. The results have shown that the\nproposed BAT system can achieve superior telepresence performance with the\ndesired balance between signal enhancement and ambience preservation, even when\nthe array configurations are unseen in the training phase.",
                "authors": [
                    "Yicheng Hsu",
                    "Mingsian R. Bai"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12706v1",
                    "http://arxiv.org/pdf/2311.12706v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12704v2/1.0",
                "title": "Cascade Learning Localises Discriminant Features in Visual Scene\n  Classification",
                "year": 2023,
                "abstract": "Lack of interpretability of deep convolutional neural networks (DCNN) is a\nwell-known problem particularly in the medical domain as clinicians want\ntrustworthy automated decisions. One way to improve trust is to demonstrate the\nlocalisation of feature representations with respect to expert labeled regions\nof interest. In this work, we investigate the localisation of features learned\nvia two varied learning paradigms and demonstrate the superiority of one\nlearning approach with respect to localisation. Our analysis on medical and\nnatural datasets show that the traditional end-to-end (E2E) learning strategy\nhas a limited ability to localise discriminative features across multiple\nnetwork layers. We show that a layer-wise learning strategy, namely cascade\nlearning (CL), results in more localised features. Considering localisation\naccuracy, we not only show that CL outperforms E2E but that it is a promising\nmethod of predicting regions. On the YOLO object detection framework, our best\nresult shows that CL outperforms the E2E scheme by $2\\%$ in mAP.",
                "authors": [
                    "Junwen Wang",
                    "Katayoun Farrahi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12704v2",
                    "http://arxiv.org/pdf/2311.12704v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12699v1/1.0",
                "title": "Can Large Language Models Understand Content and Propagation for\n  Misinformation Detection: An Empirical Study",
                "year": 2023,
                "abstract": "Large Language Models (LLMs) have garnered significant attention for their\npowerful ability in natural language understanding and reasoning. In this\npaper, we present a comprehensive empirical study to explore the performance of\nLLMs on misinformation detection tasks. This study stands as the pioneering\ninvestigation into the understanding capabilities of multiple LLMs regarding\nboth content and propagation across social media platforms. Our empirical\nstudies on five misinformation detection datasets show that LLMs with diverse\nprompts achieve comparable performance in text-based misinformation detection\nbut exhibit notably constrained capabilities in comprehending propagation\nstructure compared to existing models in propagation-based misinformation\ndetection. Besides, we further design four instruction-tuned strategies to\nenhance LLMs for both content and propagation-based misinformation detection.\nThese strategies boost LLMs to actively learn effective features from multiple\ninstances or hard instances, and eliminate irrelevant propagation structures,\nthereby achieving better detection performance. Extensive experiments further\ndemonstrate LLMs would play a better capacity in content and propagation\nstructure under these proposed strategies and achieve promising detection\nperformance. These findings highlight the potential ability of LLMs to detect\nmisinformation.",
                "authors": [
                    "Mengyang Chen",
                    "Lingwei Wei",
                    "Han Cao",
                    "Wei Zhou",
                    "Songlin Hu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12699v1",
                    "http://arxiv.org/pdf/2311.12699v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.CY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12695v1/1.0",
                "title": "The variety of extreme blazars in the AstroSat view",
                "year": 2023,
                "abstract": "Extreme blazars have exceptionally hard intrinsic X-ray/TeV spectra and\nextreme peak energies in their spectral energy distribution (SED).\nObservational evidence suggests that the non-thermal emission from extreme\nblazars is typically non-variable. We aim to explore X-ray and GeV\nobservational features of a variety of extreme blazars and also aim to test the\napplicability of various blazar emission models that could explain the very\nhard TeV spectra. We perform X-ray analysis of AstroSat and Swift-XRT data,\nalong with gamma-ray data from Fermi-LAT, for sources; 1ES 0120+340, RGB\nJ0710+591, 1ES 1101-232, 1ES 1741+196 and 1ES 2322-409. We employ three models:\n1) a steady-state one-zone synchrotron-self-Compton (SSC) code, 2) another\nleptonic scenario of co-accelerated electrons and protons on multiple shocks,\napplied only on the extreme-TeVsources and 3) a one-zone hadro-leptonic\n(OneHaLe) code. The hadro-leptonic code is used twice to explain the gamma-ray\nemission process: proton synchrotron and synchrotron emission of secondary\npairs. Our X-ray analysis provides well-constrained estimates of the\nsynchrotron peak energies for both 1ES0120+340 and 1ES1741+196. The multi-epoch\nX-ray and GeV data reveal spectral and flux variabilities in RGB J0710+591 and\n1ES 1741+196, even on time scales of days to weeks. As anticipated, the\none-zone SSC model adequately reproduces the SEDs of regular HBLs but\nencounters difficulties in explaining the hardest TeV emission. Hadronic models\noffer a reasonable fit to the hard TeV spectrum, though with the trade-off of\nrequiring extreme jet powers. On the other hand, the lepto-hadronic scenario\nfaces additional challenges in fitting the GeV spectra of extreme-TeV sources.\nFinally, e-p co-acceleration scenario naturally accounts for the observed hard\nelectron distributions and effectively matches the hardest TeV spectrum of RGB\nJ0710+591 and 1ES 1101-232.",
                "authors": [
                    "Pranjupriya Goswami",
                    "Michael Zacharias",
                    "Andreas Zech",
                    "Sunil Chandra",
                    "Markus Boettcher",
                    "Iurii Sushch"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12695v1",
                    "http://arxiv.org/pdf/2311.12695v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12692v2/1.0",
                "title": "Human perceptual decision making of nonequilibrium fluctuations",
                "year": 2023,
                "abstract": "Perceptual decision-making frequently requires making rapid, reliable choices\nupon encountering noisy sensory inputs. To better define the statistical\nprocesses underlying perceptual decision-making, here we characterize the\nchoices of human participants visualizing a system of nonequilibrium stationary\nphysical dynamics and compare such choices to the performance of an optimal\nagent computing Wald's sequential probability ratio test (SPRT). Participants\nviewed movies of a particle endowed with drifted Brownian dynamics and had to\njudge the motion as leftward or rightward. Overall, the results uncovered\nfundamental performance limits, consistent with recently established\nthermodynamic trade-offs involving speed, accuracy, and dissipation.\nSpecifically, decision times are sensitive to entropy production rates.\nMoreover, to achieve a given level of observed accuracy, participants require\nmore time than predicted by SPRT, indicating suboptimal integration of\navailable information. In view of such suboptimality, we develop an alternative\naccount based on evidence integration with a memory time constant. Setting the\ntime constant proportionately to the deviation from equilibrium in the stimuli\nsignificantly improved trial-by-trial predictions of decision metrics with\nrespect to SPRT. This study shows that perceptual psychophysics using stimuli\nrooted in nonequilibrium physical processes provides a robust platform for\nunderstanding how the brain takes decisions on stochastic information inputs.",
                "authors": [
                    "Ayb\u00fcke Durmaz",
                    "Yonathan Sarmiento",
                    "Gianfranco Fortunato",
                    "Debraj Das",
                    "Mathew Ernst Diamond",
                    "Domenica Bueti",
                    "\u00c9dgar Rold\u00e1n"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12692v2",
                    "http://arxiv.org/pdf/2311.12692v2"
                ],
                "primary_category": "cond-mat.stat-mech",
                "categories": [
                    "cond-mat.stat-mech",
                    "physics.bio-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12689v1/1.0",
                "title": "Fair Text Classification with Wasserstein Independence",
                "year": 2023,
                "abstract": "Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g. women vs. men) remains\nan open challenge. This paper presents a novel method for mitigating biases in\nneural text classification, agnostic to the model architecture. Considering the\ndifficulty to distinguish fair from unfair information in a text encoder, we\ntake inspiration from adversarial training to induce Wasserstein independence\nbetween representations learned to predict our target label and the ones\nlearned to predict some sensitive attribute. Our approach provides two\nsignificant advantages. Firstly, it does not require annotations of sensitive\nattributes in both testing and training data. This is more suitable for\nreal-life scenarios compared to existing methods that require annotations of\nsensitive attributes at train time. Second, our approach exhibits a comparable\nor better fairness-accuracy trade-off compared to existing methods.",
                "authors": [
                    "Thibaud Leteno",
                    "Antoine Gourru",
                    "Charlotte Laclau",
                    "R\u00e9mi Emonet",
                    "Christophe Gravier"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12689v1",
                    "http://arxiv.org/pdf/2311.12689v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.CY",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12687v1/1.0",
                "title": "Virtual potential created by a feedback loop: taming the feedback demon\n  to explore stochastic thermodynamics of underdamped systems",
                "year": 2023,
                "abstract": "Virtual potentials are an elegant, precise and flexible tool to manipulate\nsmall systems and explore fundamental questions in stochastic thermodynamics.\nIn particular double-well potentials have applications in information\nprocessing, such as the demonstration of Landauer's principle. In this chapter,\nwe detail the implementation of a feedback loop for an underdamped system, in\norder to build a tunable virtual double-well potential. This feedback behaves\nas a demon acting on the system depending on the outcome of a continuously\nrunning measurement. It can thus modify the energy exchanges with the\nthermostat and create an out-of-equilibrium state. To create a bi-stable\npotential, the feedback consists only in switching an external force between\ntwo steady values when the measured position crosses a threshold. We show that\na small delay of the feedback loop in the switches between the two wells\nresults in a modified velocity distribution. The latter can be interpreted as a\ncooling of the kinetic temperature of the system. Using a fast digital\nfeedback, we successfully address all experimental issues to create a virtual\npotential that is statistically indistinguishable from a physical one, with a\ntunable barrier height and energy step between the two wells.",
                "authors": [
                    "Salamb\u00f4 Dago",
                    "Nicolas Barros",
                    "Jorge Pereda",
                    "Sergio Ciliberto",
                    "Ludovic Bellon"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12687v1",
                    "http://arxiv.org/pdf/2311.12687v1"
                ],
                "primary_category": "cond-mat.stat-mech",
                "categories": [
                    "cond-mat.stat-mech",
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12686v1/1.0",
                "title": "Managing ML-Based Application Non-Functional Behavior: A Multi-Model\n  Approach",
                "year": 2023,
                "abstract": "Modern applications are increasingly driven by Machine Learning (ML) models\nwhose non-deterministic behavior is affecting the entire application life cycle\nfrom design to operation. The pervasive adoption of ML is urgently calling for\napproaches that guarantee a stable non-functional behavior of ML-based\napplications over time and across model changes. To this aim, non-functional\nproperties of ML models, such as privacy, confidentiality, fairness, and\nexplainability, must be monitored, verified, and maintained. This need is even\nmore pressing when modern applications operate in the edge-cloud continuum,\nincreasing their complexity and dynamicity. Existing approaches mostly focus on\ni) implementing classifier selection solutions according to the functional\nbehavior of ML models, ii) finding new algorithmic solutions to this need, such\nas continuous re-training. In this paper, we propose a multi-model approach\nbuilt on dynamic classifier selection, where multiple ML models showing similar\nnon-functional properties are made available to the application and one model\nis selected over time according to (dynamic and unpredictable) contextual\nchanges. Our solution goes beyond the state of the art by providing an\narchitectural and methodological approach that continuously guarantees a stable\nnon-functional behavior of ML-based applications, is applicable to different ML\nmodels, and is driven by non-functional properties assessed on the models\nthemselves. It consists of a two-step process working during application\noperation, where model assessment verifies non-functional properties of ML\nmodels trained and selected at development time, and model substitution\nguarantees a continuous and stable support of non-functional properties. We\nexperimentally evaluate our solution in a real-world scenario focusing on\nnon-functional property fairness.",
                "authors": [
                    "Marco Anisetti",
                    "Claudio A. Ardagna",
                    "Nicola Bena",
                    "Ernesto Damiani",
                    "Paolo G. Panero"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12686v1",
                    "http://arxiv.org/pdf/2311.12686v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.SE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12679v1/1.0",
                "title": "BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse\n  Multiview Videos",
                "year": 2023,
                "abstract": "Capturing smooth motions from videos using markerless techniques typically\ninvolves complex processes such as temporal constraints, multiple stages with\ndata-driven regression and optimization, and bundle solving over temporal\nwindows. These processes can be inefficient and require tuning multiple\nobjectives across stages. In contrast, BundleMoCap introduces a novel and\nefficient approach to this problem. It solves the motion capture task in a\nsingle stage, eliminating the need for temporal smoothness objectives while\nstill delivering smooth motions. BundleMoCap outperforms the state-of-the-art\nwithout increasing complexity. The key concept behind BundleMoCap is manifold\ninterpolation between latent keyframes. By relying on a local manifold\nsmoothness assumption, we can efficiently solve a bundle of frames using a\nsingle code. Additionally, the method can be implemented as a sliding window\noptimization and requires only the first frame to be properly initialized,\nreducing the overall computational burden. BundleMoCap's strength lies in its\nability to achieve high-quality motion capture results with simplicity and\nefficiency. More details can be found at https://moverseai.github.io/bundle/.",
                "authors": [
                    "Georgios Albanis",
                    "Nikolaos Zioulis",
                    "Kostas Kolomvatsos"
                ],
                "url": [
                    "http://dx.doi.org/10.1145/3626495.3626511",
                    "http://arxiv.org/abs/2311.12679v1",
                    "http://arxiv.org/pdf/2311.12679v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.GR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12677v1/1.0",
                "title": "Particularities of polaron formation in the extended Holstein model with\n  next nearest neighbor transfer",
                "year": 2023,
                "abstract": "Employing a largely unbiased variational exact diagonalization technique, we\nanalyze the consequences of longer-ranged electron hopping and electron-phonon\ninteraction on polaron formation in one dimension. Having at our disposal the\naccurate ground state energy and wavefunction, we calculate and discuss various\nphysical quantities, such as the renormalized band structure, effective mass,\nwave-function renormalization factor, phonon dressing and Drude weight,\ncharacterizing the properties of the polaronic quasiparticle. We demonstrate\nthat the electron-phonon coupling affects the relative strength of the\nnearest-neigbor (NN) and next-nearest-neigbor (NNN) hopping processes in a\ndynamic way. Most notably we observe that the minimum of the polaron band,\noccurring at a finite momentum for large negative ratio between NN and NNN\ntransfer, jumps to zero momentum as the electron-phonon coupling exceeds a\ncritical one, thereby causing a rather sharp polaron transition in the\none-dimensional extended Holstein model. The signatures of this transition are\nseen in the effective mass and polaron mobility, and therefore should be easily\ndetectable by transport measurements.",
                "authors": [
                    "Monodeep Chakraborty",
                    "Jayita Chatterjee",
                    "Holger Fehske"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12677v1",
                    "http://arxiv.org/pdf/2311.12677v1"
                ],
                "primary_category": "cond-mat.str-el",
                "categories": [
                    "cond-mat.str-el"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12674v1/1.0",
                "title": "Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for\n  HAR",
                "year": 2023,
                "abstract": "Machine learning algorithms are improving rapidly, but annotating training\ndata remains a bottleneck for many applications. In this paper, we show how\nreal data can be used for self-supervised learning without any transformations\nby taking advantage of the symmetry present in the activities. Our approach\ninvolves contrastive matching of two different sensors (left and right wrist or\nleg-worn IMUs) to make representations of co-occurring sensor data more similar\nand those of non-co-occurring sensor data more different. We test our approach\non the Opportunity and MM-Fit datasets. In MM-Fit we show significant\nimprovement over the baseline supervised and self-supervised method SimCLR,\nwhile for Opportunity there is significant improvement over the supervised\nbaseline and slight improvement when compared to SimCLR. Moreover, our method\nimproves supervised baselines even when using only a small amount of the data\nfor training. Future work should explore under which conditions our method is\nbeneficial for human activity recognition systems and other related\napplications.",
                "authors": [
                    "Dominique Nshimyimana",
                    "Vitor Fortes Rey",
                    "Paul Lukowic"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12674v1",
                    "http://arxiv.org/pdf/2311.12674v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12670v2/1.0",
                "title": "Towards a more inductive world for drug repurposing approaches",
                "year": 2023,
                "abstract": "Drug-target interaction (DTI) prediction is a challenging, albeit essential\ntask in drug repurposing. Learning on graph models have drawn special attention\nas they can significantly reduce drug repurposing costs and time commitment.\nHowever, many current approaches require high-demanding additional information\nbesides DTIs that complicates their evaluation process and usability.\nAdditionally, structural differences in the learning architecture of current\nmodels hinder their fair benchmarking. In this work, we first perform an\nin-depth evaluation of current DTI datasets and prediction models through a\nrobust benchmarking process, and show that DTI prediction methods based on\ntransductive models lack generalization and lead to inflated performance when\nevaluated as previously done in the literature, hence not being suited for drug\nrepurposing approaches. We then propose a novel biologically-driven strategy\nfor negative edge subsampling and show through in vitro validation that newly\ndiscovered interactions are indeed true. We envision this work as the\nunderpinning for future fair benchmarking and robust model design. All\ngenerated resources and tools are publicly available as a python package.",
                "authors": [
                    "Jesus de la Fuente",
                    "Guillermo Serrano",
                    "Ux\u00eda Veleiro",
                    "Mikel Casals",
                    "Laura Vera",
                    "Marija Pizurica",
                    "Antonio Pineda-Lucena",
                    "Idoia Ochoa",
                    "Silve Vicent",
                    "Olivier Gevaert",
                    "Mikel Hernaez"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12670v2",
                    "http://arxiv.org/pdf/2311.12670v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12908v1/1.0",
                "title": "Diffusion Model Alignment Using Direct Preference Optimization",
                "year": 2023,
                "abstract": "Large language models (LLMs) are fine-tuned using human comparison data with\nReinforcement Learning from Human Feedback (RLHF) methods to make them better\naligned with users' preferences. In contrast to LLMs, human preference learning\nhas not been widely explored in text-to-image diffusion models; the best\nexisting approach is to fine-tune a pretrained model using carefully curated\nhigh quality images and captions to improve visual appeal and text alignment.\nWe propose Diffusion-DPO, a method to align diffusion models to human\npreferences by directly optimizing on human comparison data. Diffusion-DPO is\nadapted from the recently developed Direct Preference Optimization (DPO), a\nsimpler alternative to RLHF which directly optimizes a policy that best\nsatisfies human preferences under a classification objective. We re-formulate\nDPO to account for a diffusion model notion of likelihood, utilizing the\nevidence lower bound to derive a differentiable objective. Using the Pick-a-Pic\ndataset of 851K crowdsourced pairwise preferences, we fine-tune the base model\nof the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with\nDiffusion-DPO. Our fine-tuned base model significantly outperforms both base\nSDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement\nmodel in human evaluation, improving visual appeal and prompt alignment. We\nalso develop a variant that uses AI feedback and has comparable performance to\ntraining on human preferences, opening the door for scaling of diffusion model\nalignment methods.",
                "authors": [
                    "Bram Wallace",
                    "Meihua Dang",
                    "Rafael Rafailov",
                    "Linqi Zhou",
                    "Aaron Lou",
                    "Senthil Purushwalkam",
                    "Stefano Ermon",
                    "Caiming Xiong",
                    "Shafiq Joty",
                    "Nikhil Naik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12908v1",
                    "http://arxiv.org/pdf/2311.12908v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.GR",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12668v1/1.0",
                "title": "From Concept to Manufacturing: Evaluating Vision-Language Models for\n  Engineering Design",
                "year": 2023,
                "abstract": "Engineering Design is undergoing a transformative shift with the advent of\nAI, marking a new era in how we approach product, system, and service planning.\nLarge language models have demonstrated impressive capabilities in enabling\nthis shift. Yet, with text as their only input modality, they cannot leverage\nthe large body of visual artifacts that engineers have used for centuries and\nare accustomed to. This gap is addressed with the release of multimodal vision\nlanguage models, such as GPT-4V, enabling AI to impact many more types of\ntasks. In light of these advancements, this paper presents a comprehensive\nevaluation of GPT-4V, a vision language model, across a wide spectrum of\nengineering design tasks, categorized into four main areas: Conceptual Design,\nSystem-Level and Detailed Design, Manufacturing and Inspection, and Engineering\nEducation Tasks. Our study assesses GPT-4V's capabilities in design tasks such\nas sketch similarity analysis, concept selection using Pugh Charts, material\nselection, engineering drawing analysis, CAD generation, topology optimization,\ndesign for additive and subtractive manufacturing, spatial reasoning\nchallenges, and textbook problems. Through this structured evaluation, we not\nonly explore GPT-4V's proficiency in handling complex design and manufacturing\nchallenges but also identify its limitations in complex engineering design\napplications. Our research establishes a foundation for future assessments of\nvision language models, emphasizing their immense potential for innovating and\nenhancing the engineering design and manufacturing landscape. It also\ncontributes a set of benchmark testing datasets, with more than 1000 queries,\nfor ongoing advancements and applications in this field.",
                "authors": [
                    "Cyril Picard",
                    "Kristen M. Edwards",
                    "Anna C. Doris",
                    "Brandon Man",
                    "Giorgio Giannone",
                    "Md Ferdous Alam",
                    "Faez Ahmed"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12668v1",
                    "http://arxiv.org/pdf/2311.12668v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12667v1/1.0",
                "title": "Error Estimates for Finite Element Approximations of Viscoelastic\n  Dynamics: The Generalized Maxwell Model",
                "year": 2023,
                "abstract": "We prove error estimates for a finite element approximation of viscoelastic\ndynamics based on continuous Galerkin in space and time, both in energy norm\nand in $L^2$ norm. The proof is based on an error representation formula using\na discrete dual problem and a stability estimate involving the kinetic,\nelastic, and viscoelastic energies. To set up the dual error analysis and to\nprove the basic stability estimates, it is natural to formulate the problem as\na system involving evolution equations for the viscoelastic stress, the\ndisplacements, and the velocities. The equations for the viscoelastic stress\ncan, however, be solved analytically in terms of the deviatoric strain\nvelocity, and therefore, the viscoelastic stress can be eliminated from the\nsystem, resulting in a system for displacements and velocities.",
                "authors": [
                    "Martin Bj\u00f6rklund",
                    "Karl Larsson",
                    "Mats G. Larson"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12667v1",
                    "http://arxiv.org/pdf/2311.12667v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12666v1/1.0",
                "title": "SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer\n  Interfaces",
                "year": 2023,
                "abstract": "Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces\n(BCIs) offer a non-invasive means of communication through high-speed speller\nsystems. However, their efficiency heavily relies on individual training data\nobtained during time-consuming calibration sessions. To address the challenge\nof data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first\ndedicated neural network model designed for aligning SSVEP data across\ndifferent domains, which can encompass various sessions, subjects, or devices.\nOur experimental results across multiple cross-domain scenarios demonstrate\nSSVEP-DAN's capability to transform existing source SSVEP data into\nsupplementary calibration data, significantly enhancing SSVEP decoding accuracy\nin scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst\nfor practical SSVEP-based BCI applications with minimal calibration. The source\ncodes in this work are available at: https://github.com/CECNL/SSVEP-DAN.",
                "authors": [
                    "Sung-Yu Chen",
                    "Chi-Min Chang",
                    "Kuan-Jung Chiang",
                    "Chun-Shu Wei"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12666v1",
                    "http://arxiv.org/pdf/2311.12666v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12664v1/1.0",
                "title": "The DURel Annotation Tool: Human and Computational Measurement of\n  Semantic Proximity, Sense Clusters and Semantic Change",
                "year": 2023,
                "abstract": "We present the DURel tool that implements the annotation of semantic\nproximity between uses of words into an online, open source interface. The tool\nsupports standardized human annotation as well as computational annotation,\nbuilding on recent advances with Word-in-Context models. Annotator judgments\nare clustered with automatic graph clustering techniques and visualized for\nanalysis. This allows to measure word senses with simple and intuitive\nmicro-task judgments between use pairs, requiring minimal preparation efforts.\nThe tool offers additional functionalities to compare the agreement between\nannotators to guarantee the inter-subjectivity of the obtained judgments and to\ncalculate summary statistics giving insights into sense frequency\ndistributions, semantic variation or changes of senses over time.",
                "authors": [
                    "Dominik Schlechtweg",
                    "Shafqat Mumtaz Virk",
                    "Pauline Sander",
                    "Emma Sk\u00f6ldberg",
                    "Lukas Theuer Linke",
                    "Tuo Zhang",
                    "Nina Tahmasebi",
                    "Jonas Kuhn",
                    "Sabine Schulte im Walde"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12664v1",
                    "http://arxiv.org/pdf/2311.12664v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12663v1/1.0",
                "title": "Similar Document Template Matching Algorithm",
                "year": 2023,
                "abstract": "This study outlines a comprehensive methodology for verifying medical\ndocuments, integrating advanced techniques in template extraction, comparison,\nand fraud detection. It begins with template extraction using sophisticated\nregion-of-interest (ROI) methods, incorporating contour analysis and edge\nidentification. Pre-processing steps ensure template clarity through\nmorphological operations and adaptive thresholding. The template comparison\nalgorithm utilizes advanced feature matching with key points and descriptors,\nenhancing robustness through histogram-based analysis for accounting\nvariations. Fraud detection involves the SSIM computation and OCR for textual\ninformation extraction. The SSIM quantifies structural similarity, aiding in\npotential match identification. OCR focuses on critical areas like patient\ndetails, provider information, and billing amounts. Extracted information is\ncompared with a reference dataset, and confidence thresholding ensures reliable\nfraud detection. Adaptive parameters enhance system flexibility for dynamic\nadjustments to varying document layouts. This methodology provides a robust\napproach to medical document verification, addressing complexities in template\nextraction, comparison, fraud detection, and adaptability to diverse document\nstructures.",
                "authors": [
                    "Harshitha Yenigalla",
                    "Bommareddy Revanth Srinivasa Reddy",
                    "Batta Venkata Rahul",
                    "Nannapuraju Hemanth Raju"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12663v1",
                    "http://arxiv.org/pdf/2311.12663v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12657v1/1.0",
                "title": "Carbohydrate NMR chemical shift predictions using E(3) equivariant graph\n  neural networks",
                "year": 2023,
                "abstract": "Carbohydrates, vital components of biological systems, are well-known for\ntheir structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays\na crucial role in understanding their intricate molecular arrangements and is\nessential in assessing and verifying the molecular structure of organic\nmolecules. An important part of this process is to predict the NMR chemical\nshift from the molecular structure. This work introduces a novel approach that\nleverages E(3) equivariant graph neural networks to predict carbohydrate NMR\nspectra. Notably, our model achieves a substantial reduction in mean absolute\nerror, up to threefold, compared to traditional models that rely solely on\ntwo-dimensional molecular structure. Even with limited data, the model excels,\nhighlighting its robustness and generalization capabilities. The implications\nare far-reaching and go beyond an advanced understanding of carbohydrate\nstructures and spectral interpretation. For example, it could accelerate\nresearch in pharmaceutical applications, biochemistry, and structural biology,\noffering a faster and more reliable analysis of molecular structures.\nFurthermore, our approach is a key step towards a new data-driven era in\nspectroscopy, potentially influencing spectroscopic techniques beyond NMR.",
                "authors": [
                    "Maria B\u00e5nkestad",
                    "Keven M. Dorst",
                    "G\u00f6ran Widmalm",
                    "Jerk R\u00f6nnols"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12657v1",
                    "http://arxiv.org/pdf/2311.12657v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "physics.chem-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12652v1/1.0",
                "title": "FedDRO: Federated Compositional Optimization for Distributionally Robust\n  Learning",
                "year": 2023,
                "abstract": "Recently, compositional optimization (CO) has gained popularity because of\nits applications in distributionally robust optimization (DRO) and many other\nmachine learning problems. Large-scale and distributed availability of data\ndemands the development of efficient federated learning (FL) algorithms for\nsolving CO problems. Developing FL algorithms for CO is particularly\nchallenging because of the compositional nature of the objective. Moreover,\ncurrent state-of-the-art methods to solve such problems rely on large batch\ngradients (depending on the solution accuracy) not feasible for most practical\nsettings. To address these challenges, in this work, we propose efficient\nFedAvg-type algorithms for solving non-convex CO in the FL setting. We first\nestablish that vanilla FedAvg is not suitable to solve distributed CO problems\nbecause of the data heterogeneity in the compositional objective at each client\nwhich leads to the amplification of bias in the local compositional gradient\nestimates. To this end, we propose a novel FL framework FedDRO that utilizes\nthe DRO problem structure to design a communication strategy that allows FedAvg\nto control the bias in the estimation of the compositional gradient. A key\nnovelty of our work is to develop solution accuracy-independent algorithms that\ndo not require large batch gradients (and function evaluations) for solving\nfederated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and\n$\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while\nachieving linear speedup with the number of clients. We corroborate our\ntheoretical findings with empirical studies on large-scale DRO problems.",
                "authors": [
                    "Prashant Khanduri",
                    "Chengyin Li",
                    "Rafi Ibn Sultan",
                    "Yao Qiang",
                    "Joerg Kliewer",
                    "Dongxiao Zhu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12652v1",
                    "http://arxiv.org/pdf/2311.12652v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "math.OC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12650v2/1.0",
                "title": "Reliable lift-off patterning of graphene dispersions for humidity\n  sensors",
                "year": 2023,
                "abstract": "Dispersion-based graphene materials are promising candidates for various\nsensing applications. They offer the advantage of relatively simple and fast\ndeposition via spin-coating, Langmuir-Blodgett deposition, or inkjet printing.\nFilm uniformity and reproducibility remain challenging in all of these\ndeposition methods. Here, we demonstrate, characterize, and successfully apply\na scalable structuring method for graphene dispersions. The method is based on\na standard lift-off process, is simple to implement, and increases the film\nuniformity of graphene devices. It is also compatible with standard\nsemiconductor manufacturing methods. We investigate two different graphene\ndispersions via Raman spectroscopy and Atomic Force Microscopy and observe no\ndegradation of the material properties by the structuring process. Furthermore,\nwe achieve high uniformity of the structured patterns and homogeneous graphene\nflake distribution. Electrical characterizations show reproducible sheet\nresistance values correlating with material quantity and uniformity. Finally,\nrepeatable humidity sensing is demonstrated with van der Pauw devices, with\nsensing limits of less than 1% relative humidity.",
                "authors": [
                    "Jorge Eduardo Adatti Est\u00e9vez",
                    "Fabian Hecht",
                    "Sebastian Wittmann",
                    "Simon Sawallich",
                    "Annika Weber",
                    "Caterina Travan",
                    "Franz Hopperdietzl",
                    "Ulrich Krumbein",
                    "Max Christian Lemme"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12650v2",
                    "http://arxiv.org/pdf/2311.12650v2"
                ],
                "primary_category": "physics.app-ph",
                "categories": [
                    "physics.app-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12649v1/1.0",
                "title": "MathGloss: Building mathematical glossaries from text",
                "year": 2023,
                "abstract": "MathGloss is a project to create a knowledge graph (KG) for undergraduate\nmathematics from text, automatically, using modern natural language processing\n(NLP) tools and resources already available on the web. MathGloss is a linked\ndatabase of undergraduate concepts in mathematics. So far, it combines five\nresources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph\nhosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses\nat the University of Chicago, (iii) the syllabus of the French undergraduate\nmathematics curriculum which includes hyperlinks to the automated theorem\nprover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by\nmathematicians, and (v) the nLab, a wiki for category theory also curated by\nmathematicians. MathGloss's goal is to bring together resources for learning\nmathematics and to allow every mathematician to tailor their learning to their\nown preferences. Moreover, by organizing different resources for learning\nundergraduate mathematics alongside those for learning formal mathematics, we\nhope to make it easier for mathematicians and formal tools (theorem provers,\ncomputer algebra systems, etc) experts to \"understand\" each other and break\ndown some of the barriers to formal math.",
                "authors": [
                    "Lucy Horowitz",
                    "Valeria de Paiva"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12649v1",
                    "http://arxiv.org/pdf/2311.12649v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12648v1/1.0",
                "title": "Dynamics of the tachocline",
                "year": 2023,
                "abstract": "The solar tachocline is an internal region of the Sun possessing strong\nradial and latitudinal shears straddling the base of the convective envelope.\nBased on helioseismic inversions, the tachocline is known to be thin (less than\n5\\% of the solar radius). Since the first theory of the solar tachocline in\n1992, this thinness has not ceased to puzzle solar physicists. In this review,\nwe lay out the grounds of our understanding of this fascinating region of the\nsolar interior. We detail the various physical mechanisms at stake in the solar\ntachocline, and put a particular focus on the mechanisms that have been\nproposed to explain its thinness. We also examine the full range of MHD\nprocesses including waves and instabilies that are likely to occur in the\ntachocline, as well as their possible connection with active region patterns\nobserved at the surface. We reflect on the most recent findings for each of\nthem, and highlight the physical understanding that is still missing and that\nwould allow the research community to understand, in a generic sense, how the\nsolar tachocline and stellar tachocline are formed, are sustained, and evolve\non secular timescales.",
                "authors": [
                    "Antoine Strugarek",
                    "Bernadett Belucz",
                    "Allan Sacha Brun",
                    "Mausumi Dikpati",
                    "Gustavo Guerrero"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12648v1",
                    "http://arxiv.org/pdf/2311.12648v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12644v1/1.0",
                "title": "Careful Selection and Thoughtful Discarding: Graph Explicit Pooling\n  Utilizing Discarded Nodes",
                "year": 2023,
                "abstract": "Graph pooling has been increasingly recognized as crucial for Graph Neural\nNetworks (GNNs) to facilitate hierarchical graph representation learning.\nExisting graph pooling methods commonly consist of two stages: selecting\ntop-ranked nodes and discarding the remaining to construct coarsened graph\nrepresentations. However, this paper highlights two key issues with these\nmethods: 1) The process of selecting nodes to discard frequently employs\nadditional Graph Convolutional Networks or Multilayer Perceptrons, lacking a\nthorough evaluation of each node's impact on the final graph representation and\nsubsequent prediction tasks. 2) Current graph pooling methods tend to directly\ndiscard the noise segment (dropped) of the graph without accounting for the\nlatent information contained within these elements. To address the first issue,\nwe introduce a novel Graph Explicit Pooling (GrePool) method, which selects\nnodes by explicitly leveraging the relationships between the nodes and final\nrepresentation vectors crucial for classification. The second issue is\naddressed using an extended version of GrePool (i.e., GrePool+), which applies\na uniform loss on the discarded nodes. This addition is designed to augment the\ntraining process and improve classification accuracy. Furthermore, we conduct\ncomprehensive experiments across 12 widely used datasets to validate our\nproposed method's effectiveness, including the Open Graph Benchmark datasets.\nOur experimental results uniformly demonstrate that GrePool outperforms 14\nbaseline methods for most datasets. Likewise, implementing GrePool+ enhances\nGrePool's performance without incurring additional computational costs.",
                "authors": [
                    "Chuang Liu",
                    "Wenhang Yu",
                    "Kuang Gao",
                    "Xueqi Ma",
                    "Yibing Zhan",
                    "Jia Wu",
                    "Bo Du",
                    "Wenbin Hu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12644v1",
                    "http://arxiv.org/pdf/2311.12644v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12643v1/1.0",
                "title": "Poisson approximation of fixed-degree nodes in weighted random\n  connection models",
                "year": 2023,
                "abstract": "We present a process-level Poisson-approximation result for the degree-k\nvertices in a high-density weighted random connection model with\npreferential-attachment kernel in the unit volume. Our main focus lies on the\nimpact of the left tails of the weight distribution for which we establish\ngeneral criteria based on their small-weight quantiles. To illustrate that our\nconditions are broadly applicable, we verify them for weight distributions with\npolynomial and stretched exponential left tails. The proofs rest on truncation\narguments and a recently established quantitative Poisson approximation result\nfor functionals of Poisson point processes.",
                "authors": [
                    "Christian Hirsch",
                    "Benedikt Jahnel",
                    "Sanjoy Kumar Jhawar",
                    "Peter Juhasz"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12643v1",
                    "http://arxiv.org/pdf/2311.12643v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR",
                    "60D05, 60G70 (Primary) 60G55, 05C80 (Secondary)"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12641v1/1.0",
                "title": "Polyhedral Object Recognition by Indexing",
                "year": 2023,
                "abstract": "In computer vision, the indexing problem is the problem of recognizing a few\nobjects in a large database of objects while avoiding the help of the classical\nimage-feature-to-object-feature matching paradigm. In this paper we address the\nproblem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both\nthe objects to be recognized and the images are represented by weighted graphs.\nThe indexing problem is therefore the problem of determining whether a graph\nextracted from the image is present or absent in a database of model graphs. We\nintroduce a novel method for performing this graph indexing process which is\nbased both on polynomial characterization of binary and weighted graphs and on\nhashing. We describe in detail this polynomial characterization and then we\nshow how it can be used in the context of polyhedral object recognition. Next\nwe describe a practical recognition-by-indexing system that includes the\norganization of the database, the representation of polyhedral objects in terms\nof 2-D characteristic views, the representation of this views in terms of\nweighted graphs, and the associated image processing. Finally, some\nexperimental results allow the evaluation of the system performance.",
                "authors": [
                    "Radu Horaud",
                    "Humberto Sossa"
                ],
                "url": [
                    "http://dx.doi.org/10.1016/0031-3203(95)00048-8",
                    "http://arxiv.org/abs/2311.12641v1",
                    "http://arxiv.org/pdf/2311.12641v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12639v1/1.0",
                "title": "KNVQA: A Benchmark for evaluation knowledge-based VQA",
                "year": 2023,
                "abstract": "Within the multimodal field, large vision-language models (LVLMs) have made\nsignificant progress due to their strong perception and reasoning capabilities\nin the visual and language systems. However, LVLMs are still plagued by the two\ncritical issues of object hallucination and factual accuracy, which limit the\npracticality of LVLMs in different scenarios. Furthermore, previous evaluation\nmethods focus more on the comprehension and reasoning of language content but\nlack a comprehensive evaluation of multimodal interactions, thereby resulting\nin potential limitations. To this end, we propose a novel KNVQA-Eval, which is\ndevoted to knowledge-based VQA task evaluation to reflect the factuality of\nmultimodal LVLMs. To ensure the robustness and scalability of the evaluation,\nwe develop a new KNVQA dataset by incorporating human judgment and perception,\naiming to evaluate the accuracy of standard answers relative to AI-generated\nanswers in knowledge-based VQA. This work not only comprehensively evaluates\nthe contextual information of LVLMs using reliable human annotations, but also\nfurther analyzes the fine-grained capabilities of current methods to reveal\npotential avenues for subsequent optimization of LVLMs-based estimators. Our\nproposed VQA-Eval and corresponding dataset KNVQA will facilitate the\ndevelopment of automatic evaluation tools with the advantages of low cost,\nprivacy protection, and reproducibility. Our code will be released upon\npublication.",
                "authors": [
                    "Sirui Cheng",
                    "Siyu Zhang",
                    "Jiayi Wu",
                    "Muchen Lan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12639v1",
                    "http://arxiv.org/pdf/2311.12639v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12636v1/1.0",
                "title": "A new paradigm for the efficient inclusion of stochasticity in\n  engineering simulations",
                "year": 2023,
                "abstract": "As a physical fact, randomness is an inherent and ineliminable aspect in all\nphysical measurements and engineering production. As a consequence, material\nparameters, serving as input data, are only known in a stochastic sense and\nthus, also output parameters, e.g., stresses, fluctuate. For the estimation of\nthose fluctuations it is imperative to incoporate randomness into engineering\nsimulations. Unfortunately, incorporating uncertain parameters into the\nmodeling and simulation of inelastic materials is often computationally\nexpensive, as many individual simulations may have to be performed. The promise\nof the proposed method is simple: using extended material models to include\nstochasticity reduces the number of needed simulations to one. This single\ncomputation is cheap, i.e., it has a comparable numerical effort as a single\nstandard simulation. The extended material models are easily derived from\nstandard deterministic material models and account for the effect of\nuncertainty by an extended set of deterministic material parameters. The\ntime-dependent and stochastic material behavior are separated, such that only\nthe deterministic time-dependent behavior of the extended material model needs\nto be simulated. The effect of stochasticity is then included during\npost-processing. The feasibility of this approach is demonstrated for three\ndifferent and highly non-linear material models: viscous damage, viscous phase\ntransformations and elasto-viscoplasticity. A comparison to the Monte Carlo\nmethod showcases that the method is indeed able to provide reliable estimates\nof the expectation and variance of internal variables and stress at a minimal\nfraction of the computation cost.",
                "authors": [
                    "Hendrik Geisler",
                    "Cem Erdogan",
                    "Jan Nagel",
                    "Philipp Junker"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12636v1",
                    "http://arxiv.org/pdf/2311.12636v1"
                ],
                "primary_category": "cs.CE",
                "categories": [
                    "cs.CE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12635v2/1.0",
                "title": "Singular Sobolev spaces and highly degenerate elliptic partial\n  differential equations",
                "year": 2023,
                "abstract": "We present the notion of\\textit{ Singular Sobolev spaces} which are naturally\nassociated with a measurable function non-null and finite almost everywhere,\ncalled \\textit{elimination (singularities) function}, and with a new notion of\nweak derivative associated with the elimination function. This new notion of\nderivative was introduced to replace the distributional derivative which is not\nwell defined in the setting of singular Sobolev spaces since these spaces\ncontain in general non-locally integrable functions. The main aim of this\nconstruction is the study of the well-posedness of highly degenerate elliptic\npartial differential equations, in particular, those that cannot be studied\nusing the theory of weighted Sobolev spaces or the theory of degenerate Sobolev\nspaces.",
                "authors": [
                    "Djamel eddine Kebiche"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12635v2",
                    "http://arxiv.org/pdf/2311.12635v2"
                ],
                "primary_category": "math.AP",
                "categories": [
                    "math.AP",
                    "35J70, 46E35"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12631v1/1.0",
                "title": "GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via\n  Blender-Oriented GPT Planning",
                "year": 2023,
                "abstract": "Recent advances in text-to-video generation have harnessed the power of\ndiffusion models to create visually compelling content conditioned on text\nprompts. However, they usually encounter high computational costs and often\nstruggle to produce videos with coherent physical motions. To tackle these\nissues, we propose GPT4Motion, a training-free framework that leverages the\nplanning capability of large language models such as GPT, the physical\nsimulation strength of Blender, and the excellent image generation ability of\ntext-to-image diffusion models to enhance the quality of video synthesis.\nSpecifically, GPT4Motion employs GPT-4 to generate a Blender script based on a\nuser textual prompt, which commands Blender's built-in physics engine to craft\nfundamental scene components that encapsulate coherent physical motions across\nframes. Then these components are inputted into Stable Diffusion to generate a\nvideo aligned with the textual prompt. Experimental results on three basic\nphysical motion scenarios, including rigid object drop and collision, cloth\ndraping and swinging, and liquid flow, demonstrate that GPT4Motion can generate\nhigh-quality videos efficiently in maintaining motion coherency and entity\nconsistency. GPT4Motion offers new insights in text-to-video research,\nenhancing its quality and broadening its horizon for future explorations.",
                "authors": [
                    "Jiaxi Lv",
                    "Yi Huang",
                    "Mingfu Yan",
                    "Jiancheng Huang",
                    "Jianzhuang Liu",
                    "Yifan Liu",
                    "Yafei Wen",
                    "Xiaoxin Chen",
                    "Shifeng Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12631v1",
                    "http://arxiv.org/pdf/2311.12631v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12628v2/1.0",
                "title": "Empirical Validation of the Impedance-Based RIS Channel Model in an\n  Indoor Scattering Environment",
                "year": 2023,
                "abstract": "Ensuring the precision of channel modeling plays a pivotal role in the\ndevelopment of wireless communication systems, and this requirement remains a\npersistent challenge within the realm of networks supported by Reconfigurable\nIntelligent Surfaces (RIS). Achieving a comprehensive and reliable\nunderstanding of channel behavior in RIS-aided networks is an ongoing and\ncomplex issue that demands further exploration. In this paper, we empirically\nvalidate a recently-proposed impedance-based RIS channel model that accounts\nfor the mutual coupling at the antenna array and precisely models the presence\nof scattering objects within the environment as a discrete array of loaded\ndipoles. To this end, we exploit real-life channel measurements collected in an\noffice environment to demonstrate the validity of such a model and its\napplicability in a practical scenario. Finally, we provide numerical results\ndemonstrating that designing the RIS configuration based upon such model leads\nto superior performance as compared to reference schemes.",
                "authors": [
                    "Placido Mursia",
                    "Taghrid Mazloum",
                    "Frederic Munoz",
                    "Vincenzo Sciancalepore",
                    "Gabriele Gradoni",
                    "Raffaele D Errico",
                    "Marco Di Renzo",
                    "Xavier Costa-Perez",
                    "Antonio Clemente",
                    "Geoffroy Lerosey"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12628v2",
                    "http://arxiv.org/pdf/2311.12628v2"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12625v1/1.0",
                "title": "The $m$-symmetric Macdonald polynomials",
                "year": 2023,
                "abstract": "The $m$-symmetric Macdonald polynomials form a basis of the space of\npolynomials that are symmetric in the variables $x_{m+1},x_{m+2},\\dots$ (while\nhaving no special symmetry in the variables $x_1,\\dots,x_m$).We establish in\nthis article the fundamental properties of the $m$-symmetric Macdonald\npolynomials. These include among other things the orthogonality with respect to\na natural scalar product, as well as formulas for the squared norm, the\nevaluation, and the inclusion. We also obtain a Cauchy-type identity for the\n$m$-symmetric Macdonald polynomials which specializes to the known Cauchy-type\nidentity for the non-symmetric Macdonald polynomials.",
                "authors": [
                    "Manuel Concha",
                    "Luc Lapointe"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12625v1",
                    "http://arxiv.org/pdf/2311.12625v1"
                ],
                "primary_category": "math.CO",
                "categories": [
                    "math.CO",
                    "05E05"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12624v1/1.0",
                "title": "Bridging Algorithmic Information Theory and Machine Learning: A New\n  Approach to Kernel Learning",
                "year": 2023,
                "abstract": "Machine Learning (ML) and Algorithmic Information Theory (AIT) look at\nComplexity from different points of view. We explore the interface between AIT\nand Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on\nthe problem of learning kernels from data, in kernel ridge regression, through\nthe method of Sparse Kernel Flows. In particular, by looking at the differences\nand commonalities between Minimal Description Length (MDL) and Regularization\nin Machine Learning (RML), we prove that the method of Sparse Kernel Flows is\nthe natural approach to adopt to learn kernels from data. This paper shows that\nit is not necessary to use the statistical route to derive Sparse Kernel Flows\nand that one can directly work with code-lengths and complexities that are\nconcepts that show up in AIT.",
                "authors": [
                    "Boumediene Hamzi",
                    "Marcus Hutter",
                    "Houman Owhadi"
                ],
                "url": [
                    "http://dx.doi.org/10.13140/RG.2.2.36344.01285",
                    "http://arxiv.org/abs/2311.12624v1",
                    "http://arxiv.org/pdf/2311.12624v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.IT",
                    "math.IT",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12620v1/1.0",
                "title": "Investigating the Lorentz Invariance Violation effect using different\n  cosmological backgrounds",
                "year": 2023,
                "abstract": "Familiar concepts in physics, such as Lorentz symmetry, are expected to be\nbroken at energies approaching the Planck energy scale as predicted by several\nquantum-gravity theories. However, such very large energies are unreachable by\ncurrent experiments on Earth. Current and future Cherenkov telescope facilities\nmay have the capability to measure the accumulated deformation from Lorentz\nsymmetry for photons traveling over large distances via energy-dependent time\ndelays. One of the best natural laboratories to test Lorentz Invariance\nViolation~(LIV) signatures are Gamma-ray bursts~(GRBs). The calculation of time\ndelays due to the LIV effect depends on the cosmic expansion history. In most\nof the previous works calculating time lags due to the LIV effect, the standard\n$\\Lambda$CDM (or concordance) cosmological model is assumed. In this paper, we\ninvestigate whether the LIV signature is significantly different when assuming\nalternatives to the $\\Lambda$CDM cosmological model. Specifically, we consider\ncosmological models with a non-trivial dark-energy equation of state ($w \\neq\n-1$), such as the standard Chevallier-Polarski-Linder~(CPL) parameterization,\nthe quadratic parameterization of the dark-energy equation of state, and the\nPade parameterizations. We find that the relative difference in the predicted\ntime lags is small, of the order of at most a few percent, and thus likely\nsmaller than the systematic errors of possible measurements currently or in the\nnear future.",
                "authors": [
                    "Hassan Abdalla",
                    "Garret Cotter",
                    "Michael Backes",
                    "Eli Kasai",
                    "Markus B\u00f6ttcher"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12620v1",
                    "http://arxiv.org/pdf/2311.12620v1"
                ],
                "primary_category": "astro-ph.HE",
                "categories": [
                    "astro-ph.HE",
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12618v1/1.0",
                "title": "Limitations of measure-first protocols in quantum machine learning",
                "year": 2023,
                "abstract": "In recent works, much progress has been made with regards to so-called\nrandomized measurement strategies, which include the famous methods of\nclassical shadows and shadow tomography. In such strategies, unknown quantum\nstates are first measured (or ``learned''), to obtain classical data that can\nbe used to later infer (or ``predict'') some desired properties of the quantum\nstates. Even if the used measurement procedure is fixed, surprisingly,\nestimations of an exponential number of vastly different quantities can be\nobtained from a polynomial amount of measurement data. This raises the question\nof just how powerful ``measure-first'' strategies are, and in particular, if\nall quantum machine learning problems can be solved with a measure-first,\nanalyze-later scheme. This paper explores the potential and limitations of\nthese measure-first protocols in learning from quantum data. We study a natural\nsupervised learning setting where quantum states constitute data points, and\nthe labels stem from an unknown measurement. We examine two types of machine\nlearning protocols: ``measure-first'' protocols, where all the quantum data is\nfirst measured using a fixed measurement strategy, and ``fully-quantum''\nprotocols where the measurements are adapted during the training process. Our\nmain result is a proof of separation. We prove that there exist learning\nproblems that can be efficiently learned by fully-quantum protocols but which\nrequire exponential resources for measure-first protocols. Moreover, we show\nthat this separation persists even for quantum data that can be prepared by a\npolynomial-time quantum process, such as a polynomially-sized quantum circuit.\nOur proofs combine methods from one-way communication complexity and\npseudorandom quantum states. Our result underscores the role of quantum data\nprocessing in machine learning and highlights scenarios where quantum\nadvantages appear.",
                "authors": [
                    "Casper Gyurik",
                    "Riccardo Molteni",
                    "Vedran Dunjko"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12618v1",
                    "http://arxiv.org/pdf/2311.12618v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12617v1/1.0",
                "title": "Leveraging Unlabeled Data for 3D Medical Image Segmentation through\n  Self-Supervised Contrastive Learning",
                "year": 2023,
                "abstract": "Current 3D semi-supervised segmentation methods face significant challenges\nsuch as limited consideration of contextual information and the inability to\ngenerate reliable pseudo-labels for effective unsupervised data use. To address\nthese challenges, we introduce two distinct subnetworks designed to explore and\nexploit the discrepancies between them, ultimately correcting the erroneous\nprediction results. More specifically, we identify regions of inconsistent\npredictions and initiate a targeted verification training process. This\nprocedure strategically fine-tunes and harmonizes the predictions of the\nsubnetworks, leading to enhanced utilization of contextual information.\nFurthermore, to adaptively fine-tune the network's representational capacity\nand reduce prediction uncertainty, we employ a self-supervised contrastive\nlearning paradigm. For this, we use the network's confidence to distinguish\nbetween reliable and unreliable predictions. The model is then trained to\neffectively minimize unreliable predictions. Our experimental results for organ\nsegmentation, obtained from clinical MRI and CT scans, demonstrate the\neffectiveness of our approach when compared to state-of-the-art methods. The\ncodebase is accessible on\n\\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}.",
                "authors": [
                    "Sanaz Karimijafarbigloo",
                    "Reza Azad",
                    "Yury Velichko",
                    "Ulas Bagci",
                    "Dorit Merhof"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12617v1",
                    "http://arxiv.org/pdf/2311.12617v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12616v1/1.0",
                "title": "DeepTreeGAN: Fast Generation of High Dimensional Point Clouds",
                "year": 2023,
                "abstract": "In High Energy Physics, detailed and time-consuming simulations are used for\nparticle interactions with detectors. To bypass these simulations with a\ngenerative model, the generation of large point clouds in a short time is\nrequired, while the complex dependencies between the particles must be\ncorrectly modelled. Particle showers are inherently tree-based processes, as\neach particle is produced by the decay or detector interaction of a particle of\nthe previous generation. In this work, we present a novel Graph Neural Network\nmodel (DeepTreeGAN) that is able to generate such point clouds in a tree-based\nmanner. We show that this model can reproduce complex distributions, and we\nevaluate its performance on the public JetNet dataset.",
                "authors": [
                    "Moritz Alfons Wilhelm Scham",
                    "Dirk Kr\u00fccker",
                    "Benno K\u00e4ch",
                    "Kerstin Borras"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12616v1",
                    "http://arxiv.org/pdf/2311.12616v1"
                ],
                "primary_category": "hep-ex",
                "categories": [
                    "hep-ex",
                    "physics.comp-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12613v1/1.0",
                "title": "Decentralised Q-Learning for Multi-Agent Markov Decision Processes with\n  a Satisfiability Criterion",
                "year": 2023,
                "abstract": "In this paper, we propose a reinforcement learning algorithm to solve a\nmulti-agent Markov decision process (MMDP). The goal, inspired by Blackwell's\nApproachability Theorem, is to lower the time average cost of each agent to\nbelow a pre-specified agent-specific bound. For the MMDP, we assume the state\ndynamics to be controlled by the joint actions of agents, but the per-stage\ncosts to only depend on the individual agent's actions. We combine the\nQ-learning algorithm for a weighted combination of the costs of each agent,\nobtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative\nWeights formalisms to modulate the averaging matrix of the gossip. We use\nmultiple timescales in our algorithm and prove that under mild conditions, it\napproximately achieves the desired bounds for each of the agents. We also\ndemonstrate the empirical performance of this algorithm in the more general\nsetting of MMDPs having jointly controlled per-stage costs.",
                "authors": [
                    "Keshav P. Keval",
                    "Vivek S. Borkar"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12613v1",
                    "http://arxiv.org/pdf/2311.12613v1"
                ],
                "primary_category": "eess.SY",
                "categories": [
                    "eess.SY",
                    "cs.LG",
                    "cs.MA",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12608v1/1.0",
                "title": "Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented\n  Object Detection",
                "year": 2023,
                "abstract": "Recently, dense pseudo-label, which directly selects pseudo labels from the\noriginal output of the teacher model without any complicated post-processing\nsteps, has received considerable attention in semi-supervised object detection\n(SSOD). However, for the multi-oriented and dense objects that are common in\naerial scenes, existing dense pseudo-label selection methods are inefficient\nand impede the performance in semi-supervised oriented object detection.\nTherefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for\nsemi-supervised oriented object detection. In ADPLS, we design a simple but\neffective adaptive mechanism to guide the selection of dense pseudo labels.\nSpecifically, we propose the mean Feature-Richness Score (mFRS) to estimate the\ndensity of potential objects and use this score to adjust the number of dense\npseudo labels. On the DOTA-v1.5 benchmark, the proposed method outperforms\nprevious methods especially when labeled data are scarce. For example, it\nachieves 49.78 mAP given only 5% of annotated data, which surpasses previous\nstate-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will\nbe available soon.",
                "authors": [
                    "Tong Zhao",
                    "Qiang Fang",
                    "Shuohao Shi",
                    "Xin Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12608v1",
                    "http://arxiv.org/pdf/2311.12608v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.14733v1/1.0",
                "title": "Thinking Outside the Box: Orthogonal Approach to Equalizing Protected\n  Attributes",
                "year": 2023,
                "abstract": "There is growing concern that the potential of black box AI may exacerbate\nhealth-related disparities and biases such as gender and ethnicity in clinical\ndecision-making. Biased decisions can arise from data availability and\ncollection processes, as well as from the underlying confounding effects of the\nprotected attributes themselves. This work proposes a machine learning-based\northogonal approach aiming to analyze and suppress the effect of the confounder\nthrough discriminant dimensionality reduction and orthogonalization of the\nprotected attributes against the primary attribute information. By doing so,\nthe impact of the protected attributes on disease diagnosis can be realized,\nundesirable feature correlations can be mitigated, and the model prediction\nperformance can be enhanced.",
                "authors": [
                    "Jiahui Liu",
                    "Xiaohao Cai",
                    "Mahesan Niranjan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.14733v1",
                    "http://arxiv.org/pdf/2311.14733v1"
                ],
                "primary_category": "cs.CY",
                "categories": [
                    "cs.CY",
                    "cs.CV",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12606v1/1.0",
                "title": "Theoretical prerequisites for the upcoming generation of precision\n  spectroscopic experiments",
                "year": 2023,
                "abstract": "Modern resonant spectroscopic experiments to measure transition frequencies\nin atoms have reached a level where a meticulous description of all aspects of\nthe processes under study has become obligatory. The precision achieved in the\nexperiments of A. Beyer, et al., Science 358, 79 (2017), has led to the fact\nthat the determination of the transition frequency based on measured data is\nsignificantly refined by theoretical treatment of the observed spectral line\nprofile. As it was predicted theoretically, a great impact of effects arising\nbeyond the resonance approximation was found experimentally. These findings\nmarked the beginning of the upcoming epoch in the resonant atomic spectroscopy\nwhen many commonly understood ideas became invalid. For example, the atomic\ntransition may be characterized by several different but equally acceptable\nfrequencies. Furthermore, we show that the picture becomes even more\ncomplicated when the observed spectral line profile is \"identified\" with one of\nthe processes - emission or absorption. Precise determination of the transition\nfrequency requires a description of the absorption line profile inseparable\nfrom the emission process and vice versa. The theoretical aspects discussed in\nthis work provide prerequisites for more accurate and yet simpler experiments\nthan those reported in Science 358, 79 (2017). Implementing the new physics\nexpected in atomic resonance spectroscopy in the near future beyond the\nresonance approximation is unfeasible without resolving these issues.",
                "authors": [
                    "D. Solovyev",
                    "T. Zalialiutdinov",
                    "A. Anikin",
                    "L. Labzowsky"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12606v1",
                    "http://arxiv.org/pdf/2311.12606v1"
                ],
                "primary_category": "physics.atom-ph",
                "categories": [
                    "physics.atom-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.17925v1/1.0",
                "title": "Free energy along drug-protein binding pathways interactively sampled in\n  virtual reality",
                "year": 2023,
                "abstract": "We describe a two-step approach for combining interactive molecular dynamics\nin virtual reality (iMD-VR) with free energy (FE) calculation to explore the\ndynamics of biological processes at the molecular level. We refer to this\ncombined approach as iMD-VR-FE. Stage one involves using a state-of-the-art\niMD-VR framework to generate a diverse range of protein-ligand unbinding\npathways, benefitting from the sophistication of human spatial and chemical\nintuition. Stage two involves using the iMD-VR-sampled pathways as initial\nguesses for defining a path-based reaction coordinate from which we can obtain\na corresponding free energy profile using FE methods. To investigate the\nperformance of the method, we apply iMD-VR-FE to investigate the unbinding of a\nbenzamidine ligand from a trypsin protein. The binding free energy calculated\nusing iMD-VR-FE is similar for each pathway, indicating internal consistency.\nMoreover, the resulting free energy profiles can distinguish energetic\ndifferences between pathways corresponding to various protein-ligand\nconformations (e.g., helping to identify pathways that are more favourable) and\nenable identification of metastable states along the pathways. The two-step\niMD-VR-FE approach offers an intuitive way for researchers to test hypotheses\nfor candidate pathways in biomolecular systems, quickly obtaining both\nqualitative and quantitative insight.",
                "authors": [
                    "Helen M. Deeks",
                    "Kirill Zinovjev",
                    "Jonathan Barnoud",
                    "Adrian J. Mulholland",
                    "Marc W. van der Kamp",
                    "David R. Glowacki"
                ],
                "url": [
                    "http://dx.doi.org/10.1038/s41598-023-43523-x",
                    "http://arxiv.org/abs/2311.17925v1",
                    "http://arxiv.org/pdf/2311.17925v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "physics.bio-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12605v1/1.0",
                "title": "Double spin correlations in the reaction dd->pnpn and in the pn-elastic\n  scattering",
                "year": 2023,
                "abstract": "An unexpectedly large double spin correlation with a sharp dependence on\nenergy, found in elastic proton-proton scattering at large angles in the c.m.s.\nenergy range $\\sqrt{s_{pp}}= 3 \\div 5.5$ GeV, may be associated with the\nformation of exotic eight-quark resonances at the thresholds of the strangeness\nand charm production. For a deeper understanding of the dynamics of this\nprocess it is important to measure double spin correlation in elastic $pn$\nscattering in the same kinematics. The possibility of obtaining this data from\nthe reaction $d d\\to pnp$ with two polarized deuterons on SPD NICA is\nconsidered in this paper.",
                "authors": [
                    "Yu. N. Uzikov",
                    "A. A. Temerbayev"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12605v1",
                    "http://arxiv.org/pdf/2311.12605v1"
                ],
                "primary_category": "nucl-th",
                "categories": [
                    "nucl-th"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12595v1/1.0",
                "title": "Start-up and Transient Response Characteristics of Natural Draft Direct\n  Dry Cooling Systems at Various Scales",
                "year": 2023,
                "abstract": "Natural draft direct dry cooling systems (NDDDCSs) combine the benefits of\ntwo traditional dry cooling systems, air-cooled condensers (ACCs) and indirect\nnatural draft dry cooling systems, to offer advantages such as reduced system\ncomplexity, high thermal efficiency, and low parasitic power losses and\noperational costs. These scalable systems can potentially operate in both large\ncoal-fired power plants (900 MWt) and medium-scale concentrated solar power\n(CSP) plants (100 MWt). While prior research focused on NDDDCS steady-state\nperformance, this study delves into the transient behaviour and start-up\ncharacteristics of this cooling system, crucial for power plants with rapid\nstart-up requirements or load ramps during electricity demand peaks. The paper\nemploys a transient 1-D mathematical model to characterize the NDDDCSs'\nresponse to start-up and load ramp conditions under no-wind, presenting results\nfor both large- and medium scales while identifying limiting factors.",
                "authors": [
                    "Wian Strydom",
                    "Johannes Pretorius",
                    "Ryno Laubscher"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12595v1",
                    "http://arxiv.org/pdf/2311.12595v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12592v1/1.0",
                "title": "Visual tracking brain computer interface",
                "year": 2023,
                "abstract": "Brain-computer interfaces (BCIs) offer a way to interact with computers\nwithout relying on physical movements. Non-invasive electroencephalography\n(EEG)-based visual BCIs, known for efficient speed and calibration ease, face\nlimitations in continuous tasks due to discrete stimulus design and decoding\nmethods. To achieve continuous control, we implemented a novel spatial encoding\nstimulus paradigm and devised a corresponding projection method to enable\ncontinuous modulation of decoded velocity. Subsequently, we conducted\nexperiments involving 17 participants and achieved Fitt's ITR of 0.55 bps for\nthe fixed tracking task and 0.37 bps for the random tracking task. The proposed\nBCI with a high Fitt's ITR was then integrated into two applications, including\npainting and gaming. In conclusion, this study proposed a visual BCI-based\ncontrol method to go beyond discrete commands, allowing natural continuous\ncontrol based on neural activity.",
                "authors": [
                    "Changxing Huang",
                    "Nanlin Shi",
                    "Yining Miao",
                    "Xiaogang Chen",
                    "Yijun Wang",
                    "Xiaorong Gao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12592v1",
                    "http://arxiv.org/pdf/2311.12592v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC",
                    "cs.AI",
                    "cs.SY",
                    "eess.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12906v1/1.0",
                "title": "Nonlinear System Identification of Swarm of UAVs Using Deep Learning\n  Methods",
                "year": 2023,
                "abstract": "This study designs and evaluates multiple nonlinear system identification\ntechniques for modeling the UAV swarm system in planar space. learning methods\nsuch as RNNs, CNNs, and Neural ODE are explored and compared. The objective is\nto forecast future swarm trajectories by accurately approximating the nonlinear\ndynamics of the swarm model. The modeling process is performed using both\ntransient and steady-state data from swarm simulations. Results show that the\ncombination of Neural ODE with a well-trained model using transient data is\nrobust for varying initial conditions and outperforms other learning methods in\naccurately predicting swarm stability.",
                "authors": [
                    "Saman Yazdannik",
                    "Morteza Tayefi",
                    "Mojtaba Farrokh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12906v1",
                    "http://arxiv.org/pdf/2311.12906v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.SY"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12583v1/1.0",
                "title": "Root generated subalgebras of symmetrizable Kac-Moody algebras",
                "year": 2023,
                "abstract": "The derived algebra of a symmetrizible Kac-Moody algebra $\\lie g$ is\ngenerated (as a Lie algebra) by its root spaces corresponding to real roots. In\nthis paper, we address the natural reverse question: given any subset of real\nroot vectors, is the Lie subalgebra of $\\lie g$ generated by these again the\nderived algebra of a Kac-Moody algebra? We call such Lie subalgebras root\ngenerated, give an affirmative answer to the above question and show that there\nis a one-to-one correspondence between them, real closed subroot systems and\n$\\pi$-systems contained in the positive system of $\\lie g$. Finally, we apply\nthese identifications to all untwised affine types in order to classify\nsymmetric regular subalgebras first introduced by Dynkin in the\nfinite-dimensional setting. We show that any root generated subalgebra\nassociated to a maximal real closed subroot system can be embedded into a\nunique maximal symmetric regular subalgebra.",
                "authors": [
                    "Irfan Habib",
                    "Deniz Kus",
                    "R. Venkatesh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12583v1",
                    "http://arxiv.org/pdf/2311.12583v1"
                ],
                "primary_category": "math.RA",
                "categories": [
                    "math.RA",
                    "math.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12582v1/1.0",
                "title": "Echocardiogram Foundation Model -- Application 1: Estimating Ejection\n  Fraction",
                "year": 2023,
                "abstract": "Cardiovascular diseases stand as the primary global cause of mortality. Among\nthe various imaging techniques available for visualising the heart and\nevaluating its function, echocardiograms emerge as the preferred choice due to\ntheir safety and low cost. Quantifying cardiac function based on\nechocardiograms is very laborious, time-consuming and subject to high\ninteroperator variability. In this work, we introduce EchoAI, an echocardiogram\nfoundation model, that is trained using self-supervised learning (SSL) on 1.5\nmillion echocardiograms. We evaluate our approach by fine-tuning EchoAI to\nestimate the ejection fraction achieving a mean absolute percentage error of\n9.40%. This level of accuracy aligns with the performance of expert\nsonographers.",
                "authors": [
                    "Adil Dahlan",
                    "Cyril Zakka",
                    "Abhinav Kumar",
                    "Laura Tang",
                    "Rohan Shad",
                    "Robyn Fong",
                    "William Hiesinger"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12582v1",
                    "http://arxiv.org/pdf/2311.12582v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12581v1/1.0",
                "title": "A Region of Interest Focused Triple UNet Architecture for Skin Lesion\n  Segmentation",
                "year": 2023,
                "abstract": "Skin lesion segmentation is of great significance for skin lesion analysis\nand subsequent treatment. It is still a challenging task due to the irregular\nand fuzzy lesion borders, and diversity of skin lesions. In this paper, we\npropose Triple-UNet to automatically segment skin lesions. It is an organic\ncombination of three UNet architectures with suitable modules. In order to\nconcatenate the first and second sub-networks more effectively, we design a\nregion of interest enhancement module (ROIE). The ROIE enhances the target\nobject region of the image by using the predicted score map of the first UNet.\nThe features learned by the first UNet and the enhanced image help the second\nUNet obtain a better score map. Finally, the results are fine-tuned by the\nthird UNet. We evaluate our algorithm on a publicly available dataset of skin\nlesion segmentation. Experiments show that Triple-UNet outperforms the\nstate-of-the-art on skin lesion segmentation.",
                "authors": [
                    "Guoqing Liu",
                    "Yu Guo",
                    "Caiying Wu",
                    "Guoqing Chen",
                    "Barintag Saheya",
                    "Qiyu Jin"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12581v1",
                    "http://arxiv.org/pdf/2311.12581v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12580v1/1.0",
                "title": "CoVOR-SLAM: Cooperative SLAM using Visual Odometry and Ranges for\n  Multi-Robot Systems",
                "year": 2023,
                "abstract": "A swarm of robots has advantages over a single robot, since it can explore\nlarger areas much faster and is more robust to single-point failures. Accurate\nrelative positioning is necessary to successfully carry out a collaborative\nmission without collisions. When Visual Simultaneous Localization and Mapping\n(VSLAM) is used to estimate the poses of each robot, inter-agent loop closing\nis widely applied to reduce the relative positioning errors. This technique can\nmitigate errors using the feature points commonly observed by different robots.\nHowever, it requires significant computing and communication capabilities to\ndetect inter-agent loops, and to process the data transmitted by multiple\nagents. In this paper, we propose Collaborative SLAM using Visual Odometry and\nRange measurements (CoVOR-SLAM) to overcome this challenge. In the framework of\nCoVOR-SLAM, robots only need to exchange pose estimates, covariances\n(uncertainty) of the estimates, and range measurements between robots. Since\nCoVOR-SLAM does not require to associate visual features and map points\nobserved by different agents, the computational and communication loads are\nsignificantly reduced. The required range measurements can be obtained using\npilot signals of the communication system, without requiring complex additional\ninfrastructure. We tested CoVOR-SLAM using real images as well as real\nultra-wideband-based ranges obtained with two rovers. In addition, CoVOR-SLAM\nis evaluated with a larger scale multi-agent setup exploiting public image\ndatasets and ranges generated using a realistic simulation. The results show\nthat CoVOR-SLAM can accurately estimate the robots' poses, requiring much less\ncomputational power and communication capabilities than the inter-agent loop\nclosing technique.",
                "authors": [
                    "Young-Hee Lee",
                    "Chen Zhu",
                    "Thomas Wiedemann",
                    "Emanuel Staudinger",
                    "Siwei Zhang",
                    "Christoph G\u00fcnther"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12580v1",
                    "http://arxiv.org/pdf/2311.12580v1"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.MA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12579v1/1.0",
                "title": "Machine-Guided Discovery of a Real-World Rogue Wave Model",
                "year": 2023,
                "abstract": "Big data and large-scale machine learning have had a profound impact on\nscience and engineering, particularly in fields focused on forecasting and\nprediction. Yet, it is still not clear how we can use the superior pattern\nmatching abilities of machine learning models for scientific discovery. This is\nbecause the goals of machine learning and science are generally not aligned. In\naddition to being accurate, scientific theories must also be causally\nconsistent with the underlying physical process and allow for human analysis,\nreasoning, and manipulation to advance the field. In this paper, we present a\ncase study on discovering a new symbolic model for oceanic rogue waves from\ndata using causal analysis, deep learning, parsimony-guided model selection,\nand symbolic regression. We train an artificial neural network on causal\nfeatures from an extensive dataset of observations from wave buoys, while\nselecting for predictive performance and causal invariance. We apply symbolic\nregression to distill this black-box model into a mathematical equation that\nretains the neural network's predictive capabilities, while allowing for\ninterpretation in the context of existing wave theory. The resulting model\nreproduces known behavior, generates well-calibrated probabilities, and\nachieves better predictive scores on unseen data than current theory. This\nshowcases how machine learning can facilitate inductive scientific discovery,\nand paves the way for more accurate rogue wave forecasting.",
                "authors": [
                    "Dion H\u00e4fner",
                    "Johannes Gemmrich",
                    "Markus Jochum"
                ],
                "url": [
                    "http://dx.doi.org/10.1073/pnas.2306275120",
                    "http://arxiv.org/abs/2311.12579v1",
                    "http://arxiv.org/pdf/2311.12579v1"
                ],
                "primary_category": "physics.geo-ph",
                "categories": [
                    "physics.geo-ph",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12574v1/1.0",
                "title": "IMGTB: A Framework for Machine-Generated Text Detection Benchmarking",
                "year": 2023,
                "abstract": "In the era of large language models generating high quality texts, it is a\nnecessity to develop methods for detection of machine-generated text to avoid\nharmful use or simply due to annotation purposes. It is, however, also\nimportant to properly evaluate and compare such developed methods. Recently, a\nfew benchmarks have been proposed for this purpose; however, integration of\nnewest detection methods is rather challenging, since new methods appear each\nmonth and provide slightly different evaluation pipelines. In this paper, we\npresent the IMGTB framework, which simplifies the benchmarking of\nmachine-generated text detection methods by easy integration of custom (new)\nmethods and evaluation datasets. Its configurability and flexibility makes\nresearch and development of new detection methods easier, especially their\ncomparison to the existing state-of-the-art detectors. The default set of\nanalyses, metrics and visualizations offered by the tool follows the\nestablished practices of machine-generated text detection benchmarking found in\nstate-of-the-art literature.",
                "authors": [
                    "Michal Spiegel",
                    "Dominik Macko"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12574v1",
                    "http://arxiv.org/pdf/2311.12574v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12571v2/1.0",
                "title": "Minkowski Functionals for composite smooth random fields",
                "year": 2023,
                "abstract": "Minkowski functionals quantify the morphology of smooth random fields. They\nare widely used to probe statistical properties of cosmological fields.\nAnalytic formulae for ensemble expectations of Minkowski functionals are well\nknown for Gaussian and mildly non-Gaussian fields. In this paper we extend the\nformulae to composite fields which are sums of two fields and explicitly derive\nthe expressions for the sum of uncorrelated mildly non-Gaussian and Gaussian\nfields. These formulae are applicable to observed data which is usually a sum\nof the true signal and one or more secondary fields that can be either noise,\nor some residual contaminating signal. Our formulae provide explicit\nquantification of the effect of the secondary field on the morphology and\nstatistical nature of the true signal. As examples, we apply the formulae to\ndetermine how the presence of Gaussian noise can bias the morphological\nproperties and statistical nature of Gaussian and non-Gaussian CMB temperature\nmaps.",
                "authors": [
                    "Pravabati Chingangbam",
                    "Fazlu Rahman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12571v2",
                    "http://arxiv.org/pdf/2311.12571v2"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12570v2/1.0",
                "title": "BEND: Benchmarking DNA Language Models on biologically meaningful tasks",
                "year": 2023,
                "abstract": "The genome sequence contains the blueprint for governing cellular processes.\nWhile the availability of genomes has vastly increased over the last decades,\nexperimental annotation of the various functional, non-coding and regulatory\nelements encoded in the DNA sequence remains both expensive and challenging.\nThis has sparked interest in unsupervised language modeling of genomic DNA, a\nparadigm that has seen great success for protein sequence data. Although\nvarious DNA language models have been proposed, evaluation tasks often differ\nbetween individual works, and might not fully recapitulate the fundamental\nchallenges of genome annotation, including the length, scale and sparsity of\nthe data. In this study, we introduce BEND, a Benchmark for DNA language\nmodels, featuring a collection of realistic and biologically meaningful\ndownstream tasks defined on the human genome. We find that embeddings from\ncurrent DNA LMs can approach performance of expert methods on some tasks, but\nonly capture limited information about long-range features. BEND is available\nat https://github.com/frederikkemarin/BEND.",
                "authors": [
                    "Frederikke Isa Marin",
                    "Felix Teufel",
                    "Marc Horlacher",
                    "Dennis Madsen",
                    "Dennis Pultz",
                    "Ole Winther",
                    "Wouter Boomsma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12570v2",
                    "http://arxiv.org/pdf/2311.12570v2"
                ],
                "primary_category": "q-bio.GN",
                "categories": [
                    "q-bio.GN",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12569v1/1.0",
                "title": "Differentiable Sampling of Categorical Distributions Using the\n  CatLog-Derivative Trick",
                "year": 2023,
                "abstract": "Categorical random variables can faithfully represent the discrete and\nuncertain aspects of data as part of a discrete latent variable model. Learning\nin such models necessitates taking gradients with respect to the parameters of\nthe categorical probability distributions, which is often intractable due to\ntheir combinatorial nature. A popular technique to estimate these otherwise\nintractable gradients is the Log-Derivative trick. This trick forms the basis\nof the well-known REINFORCE gradient estimator and its many extensions. While\nthe Log-Derivative trick allows us to differentiate through samples drawn from\ncategorical distributions, it does not take into account the discrete nature of\nthe distribution itself. Our first contribution addresses this shortcoming by\nintroducing the CatLog-Derivative trick - a variation of the Log-Derivative\ntrick tailored towards categorical distributions. Secondly, we use the\nCatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient\nestimator for the important case of products of independent categorical\ndistributions with provably lower variance than REINFORCE. Thirdly, we\nempirically show that IndeCateR can be efficiently implemented and that its\ngradient estimates have significantly lower bias and variance for the same\nnumber of samples compared to the state of the art.",
                "authors": [
                    "Lennert De Smet",
                    "Emanuele Sansone",
                    "Pedro Zuidberg Dos Martires"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12569v1",
                    "http://arxiv.org/pdf/2311.12569v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML",
                    "68T05",
                    "G.3; G.4; I.2.6"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12567v1/1.0",
                "title": "Probing of Excitonic Transitions in All Inorganic Perovskite Quantum\n  Dots (CsPbX$_3$: X= Cl, Br, I) by Magnetic Circular Dichroism Spectroscopy",
                "year": 2023,
                "abstract": "Higher-order electronic transitions of all inorganic lead halide perovskite\nquantum dots (QDs) (CsPbX$_3$: X = Cl, Br, I) are hardly detected by\ntraditional spectroscopic techniques due to the condensed electronic level of\nQDs. This work assigned the various excitonic transitions in undoped CsPbX$_3$\nQDs through a high-resolution absorption spectroscopic technique - magnetic\ncircular dichroism (MCD). Moreover, we investigated the nature of these\ntransitions through sensitive Zeeman responses to the electronic states, likely\ninvolving the interaction of spins with the applied external magnetic field.\nThe study unveiled multiple excitonic transitions in the QDs, showing unusual\ntemperature dependence and shedding light on the role of spin-orbit\ninteractions in the presence of a magnetic field. This study offers a\ncomprehensive insight into excitonic transitions, and the potential\nmanipulation of their spin through thermal means holds the promise of advancing\nelectronic and photonic devices based on these materials.",
                "authors": [
                    "Prasenjit Mandal",
                    "Ranjani Viswanatha"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12567v1",
                    "http://arxiv.org/pdf/2311.12567v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12566v1/1.0",
                "title": "Variational Elliptical Processes",
                "year": 2023,
                "abstract": "We present elliptical processes, a family of non-parametric probabilistic\nmodels that subsume Gaussian processes and Student's t processes. This\ngeneralization includes a range of new heavy-tailed behaviors while retaining\ncomputational tractability. Elliptical processes are based on a representation\nof elliptical distributions as a continuous mixture of Gaussian distributions.\nWe parameterize this mixture distribution as a spline normalizing flow, which\nwe train using variational inference. The proposed form of the variational\nposterior enables a sparse variational elliptical process applicable to\nlarge-scale problems. We highlight advantages compared to Gaussian processes\nthrough regression and classification experiments. Elliptical processes can\nsupersede Gaussian processes in several settings, including cases where the\nlikelihood is non-Gaussian or when accurate tail modeling is essential.",
                "authors": [
                    "Maria B\u00e5nkestad",
                    "Jens Sj\u00f6lund",
                    "Jalil Taghia",
                    "Thomas B. Sch\u00f6on"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12566v1",
                    "http://arxiv.org/pdf/2311.12566v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12565v1/1.0",
                "title": "$p$-multilevel Monte Carlo for acoustic scattering from large deviation\n  rough random surfaces",
                "year": 2023,
                "abstract": "We study time harmonic acoustic scattering on large deviation rough random\nscatterers. Therein, the roughness of the scatterers is caused by a low Sobolev\nregularity in the covariance function of their deformation field. The\nmotivation for this study arises from physical phenomena where small-scale\nmaterial defects can potentially introduce non-smooth deviations from a\nreference domain. The primary challenge in this scenario is that the scattered\nwave is also random, which makes computational predictions unreliable.\nTherefore, it is essential to quantify these uncertainties to ensure robust and\nwell-informed design processes. While existing methods for uncertainty\nquantification typically rely on domain mapping or perturbation approaches, it\nturns out that large and rough random deviations are not satisfactory covered.\nTo close this gap, and although counter intuitive at first, we show that the\n$p$-multilevel Monte Carlo method can provide an efficient tool for uncertainty\nquantification in this setting. To this end, we discuss the stable\nimplementation of higher-order polynomial approximation of the deformation\nfield by means of barycentric interpolation and provide a cost-to-accuracy\nanalysis. Our considerations are complemented by numerical experiments in three\ndimensions on a complex scattering geometry.",
                "authors": [
                    "J\u00fcrgen D\u00f6lz",
                    "Wei Huang",
                    "Michael Multerer"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12565v1",
                    "http://arxiv.org/pdf/2311.12565v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12564v3/1.0",
                "title": "Summary of the DISPLACE Challenge 2023 - DIarization of SPeaker and\n  LAnguage in Conversational Environments",
                "year": 2023,
                "abstract": "In multi-lingual societies, where multiple languages are spoken in a small\ngeographic vicinity, informal conversations often involve mix of languages.\nExisting speech technologies may be inefficient in extracting information from\nsuch conversations, where the speech data is rich in diversity with multiple\nlanguages and speakers. The DISPLACE (DIarization of SPeaker and LAnguage in\nConversational Environments) challenge constitutes an open-call for evaluating\nand bench-marking the speaker and language diarization technologies on this\nchallenging condition. The challenge entailed two tracks: Track-1 focused on\nspeaker diarization (SD) in multilingual situations while, Track-2 addressed\nthe language diarization (LD) in a multi-speaker scenario. Both the tracks were\nevaluated using the same underlying audio data. To facilitate this evaluation,\na real-world dataset featuring multilingual, multi-speaker conversational\nfar-field speech was recorded and distributed. Furthermore, a baseline system\nwas made available for both SD and LD task which mimicked the state-of-art in\nthese tasks. The challenge garnered a total of $42$ world-wide registrations\nand received a total of $19$ combined submissions for Track-1 and Track-2. This\npaper describes the challenge, details of the datasets, tasks, and the baseline\nsystem. Additionally, the paper provides a concise overview of the submitted\nsystems in both tracks, with an emphasis given to the top performing systems.\nThe paper also presents insights and future perspectives for SD and LD tasks,\nfocusing on the key challenges that the systems need to overcome before\nwide-spread commercial deployment on such conversations.",
                "authors": [
                    "Shikha Baghel",
                    "Shreyas Ramoji",
                    "Somil Jain",
                    "Pratik Roy Chowdhuri",
                    "Prachi Singh",
                    "Deepu Vijayasenan",
                    "Sriram Ganapathy"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12564v3",
                    "http://arxiv.org/pdf/2311.12564v3"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.LG",
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12559v1/1.0",
                "title": "The Ligo-Virgo-KAGRA Computing Infrastructure for Gravitational-wave\n  Research",
                "year": 2023,
                "abstract": "The LIGO, VIRGO and KAGRA Gravitational-wave (GW) observatories are getting\nready for their fourth observational period, O4, scheduled to begin in March\n2023, with improved sensitivities and thus higher event rates. GW-related\ncomputing has both large commonalities with HEP computing, particularly in the\ndomain of offline data processing and analysis, and important differences, for\nexample in the fact that the amount of raw data doesn't grow much with the\ninstrument sensitivity, or the need to timely generate and distribute \"event\ncandidate alerts\" to EM and neutrino observatories, thus making gravitational\nmulti-messenger astronomy possible. Data from the interferometers are exchanged\nbetween collaborations both for low-latency and offline processing; in recent\nyears, the three collaborations designed and built a common distributed\ncomputing infrastructure to prepare for a growing computing demand, and to\nreduce the maintenance burden of legacy custom-made tools, by increasingly\nadopting tools and architectures originally developed in the context of HEP\ncomputing. So, for example, HTCondor is used for workflow management, Rucio for\nmany data management needs, CVMFS for code and data distribution, and more. We\nwill present GW computing use cases and report about the architecture of the\ncomputing infrastructure as will be used during O4, as well as some planned\nupgrades for the subsequent observing run O5.",
                "authors": [
                    "Stefano Bagnasco"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12559v1",
                    "http://arxiv.org/pdf/2311.12559v1"
                ],
                "primary_category": "astro-ph.IM",
                "categories": [
                    "astro-ph.IM",
                    "cs.DC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12555v1/1.0",
                "title": "Optimal quantum metrology for two-photon absorption",
                "year": 2023,
                "abstract": "Two-photon absorption (TPA) is a nonlinear optical process with wide-ranging\napplications from spectroscopy to super-resolution imaging. Despite this, the\nprecise measurement and characterisation of TPA parameters are challenging due\nto their inherently weak nature. We study the potential of single-mode quantum\nlight to enhance TPA parameter estimation through the quantum Fisher\ninformation (QFI). Discrete variable (DV) quantum states (defined to be a\nfinite superposition of Fock states) are optimised to maximise the QFI for\ngiven absorption, revealing a quantum advantage compared to both the coherent\nstate (classical) benchmark and the single-mode squeezed vacuum state. For\nfixed average energy $\\bar{n} \\in 2\\mathbb{N}$, the Fock state is shown to be\noptimal for large TPA parameters, while a superposition of vacuum and a\nparticular Fock state is optimal for small absorption for all $\\bar{n}$. This\ndiffers from single-photon absorption where the Fock state is always optimal.\nNotably, photon counting is demonstrated to offer optimal or nearly optimal\nperformance compared to the QFI bound for all levels of TPA parameters for the\noptimised quantum probes. Our findings provide insight into known limiting\nbehaviours of Gaussian probes and their different Fisher information (FI)\nscalings under photon counting ($\\propto \\bar{n}^2$ for squeezed vacuum states\nversus $\\bar{n}^3$ for coherent states). The squeezed state outperforms\ncoherent states for small TPA parameters but underperforms in the intermediate\nregime, becoming comparable in the large absorption limit. This can be\nexplained through fundamental differences between behaviours of even and odd\nnumber Fock states: the former's QFI diverges in both large and small\nabsorption limits, while the latter diverges only in the small absorption\nlimit, dominating at intermediate scales.",
                "authors": [
                    "Athena Karsa",
                    "Ranjith Nair",
                    "Andy Chia",
                    "Kwang-Geol Lee",
                    "Changhyoup Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12555v1",
                    "http://arxiv.org/pdf/2311.12555v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12553v3/1.0",
                "title": "HoVer-UNet: Accelerating HoVerNet with UNet-based multi-class nuclei\n  segmentation via knowledge distillation",
                "year": 2023,
                "abstract": "We present HoVer-UNet, an approach to distill the knowledge of the\nmulti-branch HoVerNet framework for nuclei instance segmentation and\nclassification in histopathology. We propose a compact, streamlined single UNet\nnetwork with a Mix Vision Transformer backbone, and equip it with a custom loss\nfunction to optimally encode the distilled knowledge of HoVerNet, reducing\ncomputational requirements without compromising performances. We show that our\nmodel achieved results comparable to HoVerNet on the public PanNuke and Consep\ndatasets with a three-fold reduction in inference time. We make the code of our\nmodel publicly available at https://github.com/DIAGNijmegen/HoVer-UNet.",
                "authors": [
                    "Cristian Tommasino",
                    "Cristiano Russo",
                    "Antonio Maria Rinaldi",
                    "Francesco Ciompi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12553v3",
                    "http://arxiv.org/pdf/2311.12553v3"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12550v3/1.0",
                "title": "Explainable Time Series Anomaly Detection using Masked Latent Generative\n  Modeling",
                "year": 2023,
                "abstract": "We present a novel time series anomaly detection method that achieves\nexcellent detection accuracy while offering a superior level of explainability.\nOur proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted\nfrom the cutting-edge time series generation method known as TimeVQVAE. The\nprior model is trained on the discrete latent space of a time-frequency domain.\nNotably, the dimensional semantics of the time-frequency domain are preserved\nin the latent space, enabling us to compute anomaly scores across different\nfrequency bands, which provides a better insight into the detected anomalies.\nAdditionally, the generative nature of the prior model allows for sampling\nlikely normal states for detected anomalies, enhancing the explainability of\nthe detected anomalies through counterfactuals. Our experimental evaluation on\nthe UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD\nsignificantly surpasses the existing methods in terms of detection accuracy and\nexplainability. We provide our implementation on GitHub:\n\\url{https://github.com/ML4ITS/TimeVQVAE-AnomalyDetection}.",
                "authors": [
                    "Daesoo Lee",
                    "Sara Malacarne",
                    "Erlend Aune"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12550v3",
                    "http://arxiv.org/pdf/2311.12550v3"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12549v1/1.0",
                "title": "On the stability and pulsation in models of B[e] star MWC 137",
                "year": 2023,
                "abstract": "B[e] type stars are characterised by strong emission lines, photometric $\\&$\nspectroscopic variabilities and unsteady mass-loss rates. MWC 137 is a galactic\nB[e] type star situated in the constellation Orion. Recent photometric\nobservation of MWC 137 by TESS has revealed variabilities with a dominant\nperiod of 1.9 d. The origin of this variability is not known but suspected to\nbe from stellar pulsation. To understand the nature and origin of this\nvariability, we have constructed three different set of models of MWC 137 and\nperformed non-adiabatic linear stability analysis. Several low order modes are\nfound to be unstable in which models having mass in the range of 31 to 34\nM$_{\\odot}$ and 43 to 46 M$_{\\odot}$ have period close to 1.9 d. The evolution\nof instabilities in the non-linear regime for model having solar chemical\ncomposition and mass of 45 M$_{\\odot}$ leads to finite amplitude pulsation with\na period of 1.9 d. Therefore in the present study we confirm that this\nvariability in MWC 137 is due to pulsation. Evolutionary tracks passing through\nthe location of MWC 137 in the HR diagram indicate that the star is either in\npost main sequence evolutionary phase or about to enter in this evolutionary\nphase.",
                "authors": [
                    "Sugyan Parida",
                    "Abhay Pratap Yadav",
                    "Michaela Kraus",
                    "Wolfgang Glatzel",
                    "Yogesh Chandra Joshi",
                    "Santosh Joshi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12549v1",
                    "http://arxiv.org/pdf/2311.12549v1"
                ],
                "primary_category": "astro-ph.SR",
                "categories": [
                    "astro-ph.SR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12548v1/1.0",
                "title": "Multi-Session Budget Optimization for Forward Auction-based Federated\n  Learning",
                "year": 2023,
                "abstract": "Auction-based Federated Learning (AFL) has emerged as an important research\nfield in recent years. The prevailing strategies for FL model users (MUs)\nassume that the entire team of the required data owners (DOs) for an FL task\nmust be assembled before training can commence. In practice, an MU can trigger\nthe FL training process multiple times. DOs can thus be gradually recruited\nover multiple FL model training sessions. Existing bidding strategies for AFL\nMUs are not designed to handle such scenarios. Therefore, the problem of\nmulti-session AFL remains open. To address this problem, we propose the\nMulti-session Budget Optimization Strategy for forward Auction-based Federated\nLearning (MultiBOS-AFL). Based on hierarchical reinforcement learning,\nMultiBOS-AFL jointly optimizes inter-session budget pacing and intra-session\nbidding for AFL MUs, with the objective of maximizing the total utility.\nExtensive experiments on six benchmark datasets show that it significantly\noutperforms seven state-of-the-art approaches. On average, MultiBOS-AFL\nachieves 12.28% higher utility, 14.52% more data acquired through auctions for\na given budget, and 1.23% higher test accuracy achieved by the resulting FL\nmodel compared to the best baseline. To the best of our knowledge, it is the\nfirst budget optimization decision support method with budget pacing capability\ndesigned for MUs in multi-session forward auction-based federated learning",
                "authors": [
                    "Xiaoli Tang",
                    "Han Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12548v1",
                    "http://arxiv.org/pdf/2311.12548v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12544v1/1.0",
                "title": "Learning optimal smooth invariant subspaces for data approximation",
                "year": 2023,
                "abstract": "In this article, we consider the problem of approximating a finite set of\ndata (usually huge in applications) by invariant subspaces generated through a\nsmall set of smooth functions. The invariance is either by translations under a\nfull-rank lattice or through the action of crystallographic groups. Smoothness\nis ensured by stipulating that the generators belong to a Paley-Wiener space,\nthat is selected in an optimal way based on the characteristics of the given\ndata. To complete our investigation, we analyze the fundamental role played by\nthe lattice in the process of approximation.",
                "authors": [
                    "Davide Barbieri",
                    "Eugenio Hern\u00e1ndez",
                    "Carlos Cabrelli",
                    "Ursula Molter"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12544v1",
                    "http://arxiv.org/pdf/2311.12544v1"
                ],
                "primary_category": "math.OC",
                "categories": [
                    "math.OC",
                    "math.FA",
                    "stat.ML",
                    "41A65, 43A70"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12543v1/1.0",
                "title": "A Unified Framework for Pulse-Shaping on Delay-Doppler Plane",
                "year": 2023,
                "abstract": "Delay-Doppler multiplexing has recently stirred a great deal of attention in\nresearch community. While multiple studies have investigated pulse-shaping\naspects of this technology, it is challenging to identify the relationships\nbetween different pulse-shaping techniques and their properties. Hence, in this\npaper, we classify these techniques into two types, namely, circular and linear\npulse-shaping. This paves the way towards the development of a unified\nframework that brings deep insights into the properties, similarities, and\ndistinctions of different pulse-shaping techniques. This framework reveals that\nthe recently emerged waveform orthogonal delay-Doppler multiplexing (ODDM) is a\nlinear pulse-shaping technique with an interesting staircase spectral\nbehaviour. Using this framework, we derive a generalized input-output\nrelationship that captures the influence of pulse-shaping on the effective\nchannel. We also introduce a unified modem for delay-Doppler plane\npulse-shaping that leads to the proposal of fast convolution based\nlow-complexity structures. Based on our complexity analysis, the proposed modem\nstructures are substantially simpler than the existing ones in the literature.\nFurthermore, we propose effective techniques that not only reduce the\nout-of-band (OOB) emissions of circularly pulse-shaped signals but also improve\nthe bit-error-rate (BER) performance of both circular and linear pulse-shaping\ntechniques. Finally, we extensively compare different pulse-shaping techniques\nusing various performance metrics.",
                "authors": [
                    "Mohsen Bayat",
                    "Arman Farhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12543v1",
                    "http://arxiv.org/pdf/2311.12543v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12539v1/1.0",
                "title": "GMISeg: General Medical Image Segmentation without Re-Training",
                "year": 2023,
                "abstract": "Although deep learning models have become the main method for medical image\nsegmentation, they often cannot be extended to unknown segmentation tasks\ninvolving new anatomical structures, image shapes, or labels. For new\nsegmentation tasks, researchers often have to retrain or fine-tune the model,\nwhich is time-consuming and poses a significant obstacle to clinical\nresearchers, who often lack the resources and professional knowledge to train\nneural networks. Therefore, we proposed a general method that can solve unknown\nmedical image segmentation tasks without requiring additional training. Given\nan example set of images and prompts for defining new segmentation tasks,\nGMISeg applies a novel low-rank fine-tuning strategy based on the proposed\napproach to the SAM (Segment Anything Model) image encoder, and works with the\nprompt encoder and mask decoder to fine-tune the labeled dataset without the\nneed for additional training. To achieve generalization of new tasks, we used\nmedical image datasets with different imaging modes for different parts. We\ntrained and generalized GMISeg on a different set of anatomical and imaging\nmodes using cardiac images on other site datasets. We have demonstrated that\nGMISeg outperforms the latest methods on unknown tasks and have conducted a\ncomprehensive analysis and summary of the important performance of the proposed\nmethod.",
                "authors": [
                    "Jing Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12539v1",
                    "http://arxiv.org/pdf/2311.12539v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12538v2/1.0",
                "title": "In-Context Learning Functions with Varying Number of Minima",
                "year": 2023,
                "abstract": "Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.",
                "authors": [
                    "David Oniani",
                    "Yanshan Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12538v2",
                    "http://arxiv.org/pdf/2311.12538v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12537v1/1.0",
                "title": "Oasis: Data Curation and Assessment System for Pretraining of Large\n  Language Models",
                "year": 2023,
                "abstract": "Data is one of the most critical elements in building a large language model.\nHowever, existing systems either fail to customize a corpus curation pipeline\nor neglect to leverage comprehensive corpus assessment for iterative\noptimization of the curation. To this end, we present a pretraining corpus\ncuration and assessment platform called Oasis -- a one-stop system for data\nquality improvement and quantification with user-friendly interactive\ninterfaces. Specifically, the interactive modular rule filter module can devise\ncustomized rules according to explicit feedback. The debiased neural filter\nmodule builds the quality classification dataset in a negative-centric manner\nto remove the undesired bias. The adaptive document deduplication module could\nexecute large-scale deduplication with limited memory resources. These three\nparts constitute the customized data curation module. And in the holistic data\nassessment module, a corpus can be assessed in local and global views, with\nthree evaluation means including human, GPT-4, and heuristic metrics. We\nexhibit a complete process to use Oasis for the curation and assessment of\npretraining data. In addition, an 800GB bilingual corpus curated by Oasis is\npublicly released.",
                "authors": [
                    "Tong Zhou",
                    "Yubo Chen",
                    "Pengfei Cao",
                    "Kang Liu",
                    "Jun Zhao",
                    "Shengping Liu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12537v1",
                    "http://arxiv.org/pdf/2311.12537v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12534v1/1.0",
                "title": "Evaluation Metrics of Language Generation Models for Synthetic Traffic\n  Generation Tasks",
                "year": 2023,
                "abstract": "Many Natural Language Generation (NLG) tasks aim to generate a single output\ntext given an input prompt. Other settings require the generation of multiple\ntexts, e.g., for Synthetic Traffic Generation (STG). This generation task is\ncrucial for training and evaluating QA systems as well as conversational\nagents, where the goal is to generate multiple questions or utterances\nresembling the linguistic variability of real users. In this paper, we show\nthat common NLG metrics, like BLEU, are not suitable for evaluating STG. We\npropose and evaluate several metrics designed to compare the generated traffic\nto the distribution of real user texts. We validate our metrics with an\nautomatic procedure to verify whether they capture different types of quality\nissues of generated data; we also run human annotations to verify the\ncorrelation with human judgements. Experiments on three tasks, i.e., Shopping\nUtterance Generation, Product Question Generation and Query Auto Completion,\ndemonstrate that our metrics are effective for evaluating STG tasks, and\nimprove the agreement with human judgement up to 20% with respect to common NLG\nmetrics. We believe these findings can pave the way towards better solutions\nfor estimating the representativeness of synthetic text data.",
                "authors": [
                    "Simone Filice",
                    "Jason Ingyu Choi",
                    "Giuseppe Castellucci",
                    "Eugene Agichtein",
                    "Oleg Rokhlenko"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12534v1",
                    "http://arxiv.org/pdf/2311.12534v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12530v2/1.0",
                "title": "An efficient likelihood-free Bayesian inference method based on\n  sequential neural posterior estimation",
                "year": 2023,
                "abstract": "Sequential neural posterior estimation (SNPE) techniques have been recently\nproposed for dealing with simulation-based models with intractable likelihoods.\nUnlike approximate Bayesian computation, SNPE techniques learn the posterior\nfrom sequential simulation using neural network-based conditional density\nestimators by minimizing a specific loss function. The SNPE method proposed by\nLueckmann et al. (2017) used a calibration kernel to boost the sample weights\naround the observed data, resulting in a concentrated loss function. However,\nthe use of calibration kernels may increase the variances of both the empirical\nloss and its gradient, making the training inefficient. To improve the\nstability of SNPE, this paper proposes to use an adaptive calibration kernel\nand several variance reduction techniques. The proposed method greatly speeds\nup the process of training, and provides a better approximation of the\nposterior than the original SNPE method and some existing competitors as\nconfirmed by numerical experiments.",
                "authors": [
                    "Yifei Xiong",
                    "Xiliang Yang",
                    "Sanguo Zhang",
                    "Zhijian He"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12530v2",
                    "http://arxiv.org/pdf/2311.12530v2"
                ],
                "primary_category": "stat.ML",
                "categories": [
                    "stat.ML",
                    "cs.LG",
                    "stat.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12529v1/1.0",
                "title": "An efficient quantum algorithm for independent component analysis",
                "year": 2023,
                "abstract": "Independent component analysis (ICA) is a fundamental data processing\ntechnique to decompose the captured signals into as independent as possible\ncomponents. Computing the contrast function, which serves as a measure of\nindependence of signals, is vital in the separation process using ICA. This\npaper presents a quantum ICA algorithm which focuses on computing a specified\ncontrast function on a quantum computer. Using the quantum acceleration in\nmatrix operations, we efficiently deal with Gram matrices and estimate the\ncontrast function with the complexity of\n$O(\\epsilon_1^{-2}\\mbox{poly}\\log(N/\\epsilon_1))$. This estimation subprogram,\ncombined with the classical optimization framework, enables our quantum ICA\nalgorithm, which exponentially reduces the complexity dependence on the data\nscale compared with classical algorithms. The outperformance is further\nsupported by numerical experiments, while a source separation of a\ntranscriptomic dataset is shown as an example of application.",
                "authors": [
                    "Xiao-Fan Xu",
                    "Cheng Xue",
                    "Zhao-Yun Chen",
                    "Yu-Chun Wu",
                    "Guo-Ping Guo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12529v1",
                    "http://arxiv.org/pdf/2311.12529v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12528v1/1.0",
                "title": "Inverse Problems with Learned Forward Operators",
                "year": 2023,
                "abstract": "Solving inverse problems requires knowledge of the forward operator, but\naccurate models can be computationally expensive and hence cheaper variants are\ndesired that do not compromise reconstruction quality. This chapter reviews\nreconstruction methods in inverse problems with learned forward operators that\nfollow two different paradigms. The first one is completely agnostic to the\nforward operator and learns its restriction to the subspace spanned by the\ntraining data. The framework of regularisation by projection is then used to\nfind a reconstruction. The second one uses a simplified model of the physics of\nthe measurement process and only relies on the training data to learn a model\ncorrection. We present the theory of these two approaches and compare them\nnumerically. A common theme emerges: both methods require, or at least benefit\nfrom, training data not only for the forward operator, but also for its\nadjoint.",
                "authors": [
                    "Simon Arridge",
                    "Andreas Hauptmann",
                    "Yury Korolev"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12528v1",
                    "http://arxiv.org/pdf/2311.12528v1"
                ],
                "primary_category": "math.NA",
                "categories": [
                    "math.NA",
                    "cs.LG",
                    "cs.NA",
                    "65J22, 47A52, 35R30, 74J25"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12527v1/1.0",
                "title": "MetaStore: High-Performance Metagenomic Analysis via In-Storage\n  Computing",
                "year": 2023,
                "abstract": "Metagenomics has led to significant advancements in many fields. Metagenomic\nanalysis commonly involves the key tasks of determining the species present in\na sample and their relative abundances. These tasks require searching large\nmetagenomic databases containing information on different species' genomes.\nMetagenomic analysis suffers from significant data movement overhead due to\nmoving large amounts of low-reuse data from the storage system to the rest of\nthe system. In-storage processing can be a fundamental solution for reducing\ndata movement overhead. However, designing an in-storage processing system for\nmetagenomics is challenging because none of the existing approaches can be\ndirectly implemented in storage effectively due to the hardware limitations of\nmodern SSDs. We propose MetaStore, the first in-storage processing system\ndesigned to significantly reduce the data movement overhead of end-to-end\nmetagenomic analysis. MetaStore is enabled by our lightweight and cooperative\ndesign that effectively leverages and orchestrates processing inside and\noutside the storage system. Through our detailed analysis of the end-to-end\nmetagenomic analysis pipeline and careful hardware/software co-design, we\naddress in-storage processing challenges for metagenomics via specialized and\nefficient 1) task partitioning, 2) data/computation flow coordination, 3)\nstorage technology-aware algorithmic optimizations, 4) light-weight in-storage\naccelerators, and 5) data mapping. Our evaluation shows that MetaStore\noutperforms the state-of-the-art performance- and accuracy-optimized software\nmetagenomic tools by 2.7-37.2$\\times$ and 6.9-100.2$\\times$, respectively,\nwhile matching the accuracy of the accuracy-optimized tool. MetaStore achieves\n1.5-5.1$\\times$ speedup compared to the state-of-the-art metagenomic\nhardware-accelerated tool, while achieving significantly higher accuracy.",
                "authors": [
                    "Nika Mansouri Ghiasi",
                    "Mohammad Sadrosadati",
                    "Harun Mustafa",
                    "Arvid Gollwitzer",
                    "Can Firtina",
                    "Julien Eudine",
                    "Haiyu Ma",
                    "Jo\u00ebl Lindegger",
                    "Meryem Banu Cavlak",
                    "Mohammed Alser",
                    "Jisung Park",
                    "Onur Mutlu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12527v1",
                    "http://arxiv.org/pdf/2311.12527v1"
                ],
                "primary_category": "cs.AR",
                "categories": [
                    "cs.AR",
                    "q-bio.GN",
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12526v2/1.0",
                "title": "Neural Network Pruning by Gradient Descent",
                "year": 2023,
                "abstract": "The rapid increase in the parameters of deep learning models has led to\nsignificant costs, challenging computational efficiency and model\ninterpretability. In this paper, we introduce a novel and straightforward\nneural network pruning framework that incorporates the Gumbel-Softmax\ntechnique. This framework enables the simultaneous optimization of a network's\nweights and topology in an end-to-end process using stochastic gradient\ndescent. Empirical results demonstrate its exceptional compression capability,\nmaintaining high accuracy on the MNIST dataset with only 0.15\\% of the original\nnetwork parameters. Moreover, our framework enhances neural network\ninterpretability, not only by allowing easy extraction of feature importance\ndirectly from the pruned network but also by enabling visualization of feature\nsymmetry and the pathways of information propagation from features to outcomes.\nAlthough the pruning strategy is learned through deep learning, it is\nsurprisingly intuitive and understandable, focusing on selecting key\nrepresentative features and exploiting data patterns to achieve extreme sparse\npruning. We believe our method opens a promising new avenue for deep learning\npruning and the creation of interpretable machine learning systems.",
                "authors": [
                    "Zhang Zhang",
                    "Ruyi Tao",
                    "Jiang Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12526v2",
                    "http://arxiv.org/pdf/2311.12526v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12524v1/1.0",
                "title": "ALPHA: AnomaLous Physiological Health Assessment Using Large Language\n  Models",
                "year": 2023,
                "abstract": "This study concentrates on evaluating the efficacy of Large Language Models\n(LLMs) in healthcare, with a specific focus on their application in personal\nanomalous health monitoring. Our research primarily investigates the\ncapabilities of LLMs in interpreting and analyzing physiological data obtained\nfrom FDA-approved devices. We conducted an extensive analysis using anomalous\nphysiological data gathered in a simulated low-air-pressure plateau\nenvironment. This allowed us to assess the precision and reliability of LLMs in\nunderstanding and evaluating users' health status with notable specificity. Our\nfindings reveal that LLMs exhibit exceptional performance in determining\nmedical indicators, including a Mean Absolute Error (MAE) of less than 1 beat\nper minute for heart rate and less than 1% for oxygen saturation (SpO2).\nFurthermore, the Mean Absolute Percentage Error (MAPE) for these evaluations\nremained below 1%, with the overall accuracy of health assessments surpassing\n85%. In image analysis tasks, such as interpreting photoplethysmography (PPG)\ndata, our specially adapted GPT models demonstrated remarkable proficiency,\nachieving less than 1 bpm error in cycle count and 7.28 MAE for heart rate\nestimation. This study highlights LLMs' dual role as health data analysis tools\nand pivotal elements in advanced AI health assistants, offering personalized\nhealth insights and recommendations within the future health assistant\nframework.",
                "authors": [
                    "Jiankai Tang",
                    "Kegang Wang",
                    "Hongming Hu",
                    "Xiyuxing Zhang",
                    "Peiyu Wang",
                    "Xin Liu",
                    "Yuntao Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12524v1",
                    "http://arxiv.org/pdf/2311.12524v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12902v1/1.0",
                "title": "Local Convolution Enhanced Global Fourier Neural Operator For Multiscale\n  Dynamic Spaces Prediction",
                "year": 2023,
                "abstract": "Neural operators extend the capabilities of traditional neural networks by\nallowing them to handle mappings between function spaces for the purpose of\nsolving partial differential equations (PDEs). One of the most notable methods\nis the Fourier Neural Operator (FNO), which is inspired by Green's function\nmethod and approximate operator kernel directly in the frequency domain. In\nthis work, we focus on predicting multiscale dynamic spaces, which is\nequivalent to solving multiscale PDEs. Multiscale PDEs are characterized by\nrapid coefficient changes and solution space oscillations, which are crucial\nfor modeling atmospheric convection and ocean circulation. To solve this\nproblem, models should have the ability to capture rapid changes and process\nthem at various scales. However, the FNO only approximates kernels in the\nlow-frequency domain, which is insufficient when solving multiscale PDEs. To\naddress this challenge, we propose a novel hierarchical neural operator that\nintegrates improved Fourier layers with attention mechanisms, aiming to capture\nall details and handle them at various scales. These mechanisms complement each\nother in the frequency domain and encourage the model to solve multiscale\nproblems. We perform experiments on dynamic spaces governed by forward and\nreverse problems of multiscale elliptic equations, Navier-Stokes equations and\nsome other physical scenarios, and reach superior performance in existing PDE\nbenchmarks, especially equations characterized by rapid coefficient variations.",
                "authors": [
                    "Xuanle Zhao",
                    "Yue Sun",
                    "Tielin Zhang",
                    "Bo Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12902v1",
                    "http://arxiv.org/pdf/2311.12902v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.NA",
                    "math.DS",
                    "math.NA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12521v1/1.0",
                "title": "Classification of Tabular Data by Text Processing",
                "year": 2023,
                "abstract": "Natural Language Processing technology has advanced vastly in the past\ndecade. Text processing has been successfully applied to a wide variety of\ndomains. In this paper, we propose a novel framework, Text Based\nClassification(TBC), that uses state of the art text processing techniques to\nsolve classification tasks on tabular data. We provide a set of controlled\nexperiments where we present the benefits of using this approach against other\nclassification methods. Experimental results on several data sets also show\nthat this framework achieves comparable performance to that of several state of\nthe art models in accuracy, precision and recall of predicted classes.",
                "authors": [
                    "Keshav Ramani",
                    "Daniel Borrajo"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12521v1",
                    "http://arxiv.org/pdf/2311.12521v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12519v1/1.0",
                "title": "Hyena: Optimizing Homomorphically Encrypted Convolution for Private CNN\n  Inference",
                "year": 2023,
                "abstract": "Processing convolution layers remains a huge bottleneck for private deep\nconvolutional neural network (CNN) inference for large datasets. To solve this\nissue, this paper presents a novel homomorphic convolution algorithm that\nprovides speedup, communication cost, and storage saving. We first note that\npadded convolution provides the advantage of model storage saving, but it does\nnot support channel packing, thereby increasing the amount of computation and\ncommunication. We address this limitation by proposing a novel plaintext\nmultiplication algorithm using the Walsh-Hadamard matrix. Furthermore, we\npropose the optimization techniques to significantly reduce the latency of the\nproposed convolution by selecting the optimal encryption parameters and\napplying lazy reduction. It achieves 1.6-3.8x speedup and reduces the weight\nstorage by 2000-8000x compared to the conventional convolution. When the\nproposed convolution is employed for CNNs like VGG-16, ResNet-20, and\nMobileNetV1 on ImageNet, it reduces the end-to-end latency by 1.3-2.6x, the\nmemory usage by 2.1-7.9x and communication cost by 1.7-2.0x compared to\nconventional method.",
                "authors": [
                    "Hyeri Roh",
                    "Woo-Seok Choi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12519v1",
                    "http://arxiv.org/pdf/2311.12519v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12513v1/1.0",
                "title": "Wearable Technologies for Monitoring Upper Extremity Functions During\n  Daily Life in Neurologically Impaired Individuals",
                "year": 2023,
                "abstract": "Neurological disorders, including stroke, spinal cord injuries, multiple\nsclerosis, and Parkinson's disease, generally lead to diminished upper\nextremity (UE) function, impacting individuals' independence and quality of\nlife. Traditional assessments predominantly focus on standardized clinical\ntasks, offering limited insights into real-life UE performance. In this\ncontext, this review focuses on wearable technologies as a promising solution\nto monitor UE function in neurologically impaired individuals during daily life\nactivities. Our primary objective is to categorize the different sensors, data\ncollection and data processing approaches employed. What comes to light is that\nthe majority of studies involved stroke survivors, and predominantly employed\ninertial measurement units and accelerometers to collect kinematics. Most\nanalyses in these studies were performed offline, focusing on activity duration\nand frequency as key metrics. Although wearable technology shows potential in\nmonitoring UE function in real-life scenarios, an ideal solution that combines\nnon-intrusiveness, lightweight design, detailed hand and finger movement\ncapture, contextual information, extended recording duration, ease of use, and\nprivacy protection remains an elusive goal. Furthermore, it stands out a\ngrowing necessity for a multimodal approach in capturing comprehensive data on\nUE function during real-life activities to enhance the personalization of\nrehabilitation strategies and ultimately improve outcomes for these\nindividuals.",
                "authors": [
                    "Tommaso Proietti",
                    "Andrea Bandini"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12513v1",
                    "http://arxiv.org/pdf/2311.12513v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12511v1/1.0",
                "title": "Proto-strange quark stars from density-dependent quark mass model",
                "year": 2023,
                "abstract": "In this paper, we investigate the evolution of strange quark stars (SQS) from\nbirth as proto-strange quark stars to maturity as stable SQSs at a zero\ntemperature. We assume that self-bound free quarks form neutron stars (NS) and\nstudy their evolution using a density-dependent quark mass model. We consider\n$\\beta$-equilibrium stellar matter at two major stages of the star's evolution:\nneutrino trapped regime and neutrino transparent regime during the\ndeleptonization and cooling processes of the star. We fix the entropy density\nand investigate the nuclear equation of state (EoS), particle distribution and\ntemperature profile inside the star, sound velocity, polytropic index, and the\nstructure of the star. Our results show that stars with higher neutrino\nconcentrations are slightly more massive than the neutrino-poor ones along the\nevolution lines of the SQS. We obtain EoSs in agreement with the conformal\nboundary set through sound velocity, and also the 2 M$_\\odot$ mass constraint\nfor NSs was satisfied at all stages of the star's evolution.",
                "authors": [
                    "Adamu Issifu",
                    "Franciele M. da Silva",
                    "D\u00e9bora P. Menezes"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12511v1",
                    "http://arxiv.org/pdf/2311.12511v1"
                ],
                "primary_category": "nucl-th",
                "categories": [
                    "nucl-th",
                    "astro-ph.HE"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.00801v1/1.0",
                "title": "In wind tunnel the reproduction of vortex shedding behind circular\n  cylinders at high Reynolds number regimes is incomplete",
                "year": 2023,
                "abstract": "Wind tunnel tests of 2D rough cylinders are presented. The goal is to\nsimulate the alternate vortex shedding in flow regimes encountered in wind\nengineering applications, where the full scale Reynolds number is larger than\nthe one that can be reproduced in wind tunnel with small scaled models.\nMeasurements are mainly the synchronized unsteady wall pressures on the\ncylinder which are post processed using bi-orthogonal decompositions. By\ncomparing the small scale results with those from a previous large scale\nexperiment, we show that the technique of rough cylinder is incomplete and can\napproach roughly global parameters only.",
                "authors": [
                    "\u00d8yvind Mortveit Ellingsen",
                    "Xavier Amandolese",
                    "Pascal H\u00e9mon"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.00801v1",
                    "http://arxiv.org/pdf/2312.00801v1"
                ],
                "primary_category": "physics.flu-dyn",
                "categories": [
                    "physics.flu-dyn"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12505v1/1.0",
                "title": "Laser-induced Demagnetization in van der Waals $XY$- and Ising-like\n  Antiferromagnets NiPS$_3$ and FePS$_3$",
                "year": 2023,
                "abstract": "The critical behaviour of laser-induced changes in magnetic ordering is\nstudied experimentally in two-dimensional zigzag antiferromagnets $XY$-like\nNiPS$_3$ and Ising-like FePS$_3$. To examine laser-induced dynamics in flakes\nof these compounds, we employ time-resolved exchange linear dichroism effect\nsensitive to zigzag magnetic ordering and independent of the orientation of the\nantiferromagnetic vector. In both compounds laser excitation in the vicinity of\nthe absorption edge induces partial quenching of the antiferromagnetic ordering\nmanifested by exchange linear dichroism reduction. The amplitude of the effect\nvaries with temperature as the derivative of the antiferromagnetic vector and\nexhibits a critical behaviour with the exponents corresponding to $XY$- and\nIsing-models for NiPS$_3$ and FePS$_3$, respectively. Critical slowing down of\nthe demagnetization in the vicinity of N\\'eel temperature is found, however,\nonly in FePS$_3$. In contrast, the increase of the demagnetization time near\nthe ordering temperature in NiPS$_3$ is minor. We show that the difference in\nthe demagnetization times correlates well with the spin specific heat in both\ncompounds. Beyond the range of slowing down, the demagnetization times in\nNiPS$_3$ and FePS$_3$ are comparable, about 5 - 10 ps, and are longer than\nthose reported earlier for CoPS$_3$ and considerably shorter than for MnPS$_3$.\nThis points to the importance of the unquenched angular momentum of\ntransition-metal ions in laser-induced demagnetization process.",
                "authors": [
                    "D. V. Kuntu",
                    "E. A. Arkhipova",
                    "L. A. Shelukhin",
                    "F. Mertens",
                    "M. A. Prosnikov",
                    "I. A. Eliseyev",
                    "A. N. Smirnov",
                    "V. Yu. Davydov",
                    "S. Ma\u00f1as-Valero",
                    "E. Coronado",
                    "M. Cinchetti",
                    "A. M. Kalashnikova"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12505v1",
                    "http://arxiv.org/pdf/2311.12505v1"
                ],
                "primary_category": "cond-mat.mes-hall",
                "categories": [
                    "cond-mat.mes-hall"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12502v1/1.0",
                "title": "Framework for continuous transition to Agile Systems Engineering in the\n  Automotive Industry",
                "year": 2023,
                "abstract": "The increasing pressure within VUCA (volatility, uncertainty, complexity and\nambiguity) driven environments causes traditional, plan-driven Systems\nEngineering approaches to no longer suffice. Agility is then changing from a\n\"nice-to-have\" to a \"must-have\" capability for successful system developing\norganisations. The current state of the art, however, does not provide clear\nanswers on how to map this need in terms of processes, methods, tools and\ncompetencies (PMTC) and how to successfully manage the transition within\nestablished industries. In this paper, we propose an agile Systems Engineering\n(SE) Framework for the automotive industry to meet the new agility demand. In\naddition to the methodological background, we present results of a pilot\nproject in the chassis development department of a German automotive\nmanufacturer and demonstrate the effectiveness of the newly proposed framework.\nBy adopting the described agile SE Framework, companies can foster innovation\nand collaboration based on a learning, continuous improvement and\nself-reinforcing base.",
                "authors": [
                    "Jan Heine",
                    "Herbert Palm"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12502v1",
                    "http://arxiv.org/pdf/2311.12502v1"
                ],
                "primary_category": "cs.SE",
                "categories": [
                    "cs.SE",
                    "cs.SY",
                    "eess.SY",
                    "A.m"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12500v1/1.0",
                "title": "A study on Satellite-to-Ground Propagation in Urban Environment",
                "year": 2023,
                "abstract": "Non-Terrestrial Networks are going to play an important role in future 6G\nwireless networks to enhance global connectivity a performance in cooperation\nwith terrestrial networks. In order to properly design and deploy\nnon-terrestrial networks, the satellite-to-ground channel must be properly\ncharacterized, with particular focus on the urban environment. This paper uses\na Ray-Tracing simulation tool to analyze the primary propagation mechanisms and\nthe behaviour of the Rician K-factor as a function of satellite position in a\nreference urban environment. Non-specular reflection due to surface\nirregularities emerges as a primary propagation mechanism in non-line-of-sight\ncases. Additionally, the Rician K-factor shows a slightly increasing trend with\nelevation angle, in contrast to previous studies.",
                "authors": [
                    "N. Cenni",
                    "V. Degli-Esposti",
                    "E. M. Vitucci",
                    "F. Fuschini",
                    "M. Barbiroli"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12500v1",
                    "http://arxiv.org/pdf/2311.12500v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12496v1/1.0",
                "title": "Underreaction and dynamic inconsistency in communication games under\n  noise",
                "year": 2023,
                "abstract": "Communication is rarely perfect, but rather prone to error of transmission\nand reception. Often the origin of these errors cannot be properly quantified\nand is thus imprecisely known. We analyze the impact of an ambiguous noise\nwhich may alter the received message on a communication game of common\ninterest. The noise is ambiguous in the sense that the parameters of the\nerror-generating process and thus the likelihood to receive a message by\nmistake are Knightianly unknown. Ex-ante and interim responses are\ncharacterized under maxmin preferences. While the sender can disregard\nambiguity, the receiver reveals a dynamically inconsistent, but astonishing\nbehavior under a quadratic loss. Their interim actions will be closer to the\npooling action than their ex-ante ones, as if facing a higher likelihood of an\noccurring error.",
                "authors": [
                    "Gerrit Bauch"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12496v1",
                    "http://arxiv.org/pdf/2311.12496v1"
                ],
                "primary_category": "econ.TH",
                "categories": [
                    "econ.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12494v1/1.0",
                "title": "Successive Incentives",
                "year": 2023,
                "abstract": "We study the design of optimal incentives in sequential processes. To do so,\nwe consider a basic and fundamental model in which an agent initiates a\nvalue-creating sequential process through costly investment with random\nsuccess. If unsuccessful, the process stops. If successful, a new agent\nthereafter faces a similar investment decision, and so forth. For any outcome\nof the process, the total value is distributed among the agents using a reward\nrule. Reward rules thus induce a game among the agents. By design, the reward\nrule may lead to an asymmetric game, yet we are able to show equilibrium\nexistence with optimal symmetric equilibria. We characterize optimal reward\nrules that yield the highest possible welfare created by the process, and the\nhighest possible expected payoff for the initiator of the process. Our findings\nshow that simple reward rules invoking short-run incentives are sufficient to\nmeet long-run objectives.",
                "authors": [
                    "Jens Gudmundsson",
                    "Jens Leth Hougaard",
                    "Juan D. Moreno-Ternero",
                    "Lars Peter \u00d8sterdal"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12494v1",
                    "http://arxiv.org/pdf/2311.12494v1"
                ],
                "primary_category": "econ.TH",
                "categories": [
                    "econ.TH"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12491v1/1.0",
                "title": "Heuristics for Detecting CoinJoin Transactions on the Bitcoin Blockchain",
                "year": 2023,
                "abstract": "This research delves into the intricacies of Bitcoin, a decentralized\npeer-to-peer network, and its associated blockchain, which records all\ntransactions since its inception. While this ensures integrity and\ntransparency, the transparent nature of Bitcoin potentially compromises users'\nprivacy rights. To address this concern, users have adopted CoinJoin, a method\nthat amalgamates multiple transaction intents into a single, larger transaction\nto bolster transactional privacy. This process complicates individual\ntransaction tracing and disrupts many established blockchain analysis\nheuristics. Despite its significance, limited research has been conducted on\nidentifying CoinJoin transactions. Particularly noteworthy are varied CoinJoin\nimplementations such as JoinMarket, Wasabi, and Whirlpool, each presenting\ndistinct challenges due to their unique transaction structures. This study\ndelves deeply into the open-source implementations of these protocols, aiming\nto develop refined heuristics for identifying their transactions on the\nblockchain. Our exhaustive analysis covers transactions up to block 760,000,\noffering a comprehensive insight into CoinJoin transactions and their\nimplications for Bitcoin blockchain analysis.",
                "authors": [
                    "Hugo Schnoering",
                    "Michalis Vazirgiannis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12491v1",
                    "http://arxiv.org/pdf/2311.12491v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR",
                    "cs.DC",
                    "cs.LG",
                    "q-fin.GN"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12489v1/1.0",
                "title": "Multilingual Word Embeddings for Low-Resource Languages using Anchors\n  and a Chain of Related Languages",
                "year": 2023,
                "abstract": "Very low-resource languages, having only a few million tokens worth of data,\nare not well-supported by multilingual NLP approaches due to poor quality\ncross-lingual word representations. Recent work showed that good cross-lingual\nperformance can be achieved if a source language is related to the low-resource\ntarget language. However, not all language pairs are related. In this paper, we\npropose to build multilingual word embeddings (MWEs) via a novel language\nchain-based approach, that incorporates intermediate related languages to\nbridge the gap between the distant source and target. We build MWEs one\nlanguage at a time by starting from the resource rich source and sequentially\nadding each language in the chain till we reach the target. We extend a\nsemi-joint bilingual approach to multiple languages in order to eliminate the\nmain weakness of previous works, i.e., independently trained monolingual\nembeddings, by anchoring the target language around the multilingual space. We\nevaluate our method on bilingual lexicon induction for 4 language families,\ninvolving 4 very low-resource (<5M tokens) and 4 moderately low-resource (<50M)\ntarget languages, showing improved performance in both categories.\nAdditionally, our analysis reveals the importance of good quality embeddings\nfor intermediate languages as well as the importance of leveraging anchor\npoints from all languages in the multilingual space.",
                "authors": [
                    "Viktor Hangya",
                    "Silvia Severini",
                    "Radoslav Ralev",
                    "Alexander Fraser",
                    "Hinrich Sch\u00fctze"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12489v1",
                    "http://arxiv.org/pdf/2311.12489v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12488v1/1.0",
                "title": "Adapting pretrained speech model for Mandarin lyrics transcription and\n  alignment",
                "year": 2023,
                "abstract": "The tasks of automatic lyrics transcription and lyrics alignment have\nwitnessed significant performance improvements in the past few years. However,\nmost of the previous works only focus on English in which large-scale datasets\nare available. In this paper, we address lyrics transcription and alignment of\npolyphonic Mandarin pop music in a low-resource setting. To deal with the data\nscarcity issue, we adapt pretrained Whisper model and fine-tune it on a\nmonophonic Mandarin singing dataset. With the use of data augmentation and\nsource separation model, results show that the proposed method achieves a\ncharacter error rate of less than 18% on a Mandarin polyphonic dataset for\nlyrics transcription, and a mean absolute error of 0.071 seconds for lyrics\nalignment. Our results demonstrate the potential of adapting a pretrained\nspeech model for lyrics transcription and alignment in low-resource scenarios.",
                "authors": [
                    "Jun-You Wang",
                    "Chon-In Leong",
                    "Yu-Chen Lin",
                    "Li Su",
                    "Jyh-Shing Roger Jang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12488v1",
                    "http://arxiv.org/pdf/2311.12488v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12486v1/1.0",
                "title": "HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc\n  Semantic Labeling",
                "year": 2023,
                "abstract": "Accurate and automated segmentation of intervertebral discs (IVDs) in medical\nimages is crucial for assessing spine-related disorders, such as osteoporosis,\nvertebral fractures, or IVD herniation. We present HCA-Net, a novel contextual\nattention network architecture for semantic labeling of IVDs, with a special\nfocus on exploiting prior geometric information. Our approach excels at\nprocessing features across different scales and effectively consolidating them\nto capture the intricate spatial relationships within the spinal cord. To\nachieve this, HCA-Net models IVD labeling as a pose estimation problem, aiming\nto minimize the discrepancy between each predicted IVD location and its\ncorresponding actual joint location. In addition, we introduce a skeletal loss\nterm to reinforce the model's geometric dependence on the spine. This loss\nfunction is designed to constrain the model's predictions to a range that\nmatches the general structure of the human vertebral skeleton. As a result, the\nnetwork learns to reduce the occurrence of false predictions and adaptively\nimproves the accuracy of IVD location estimation. Through extensive\nexperimental evaluation on multi-center spine datasets, our approach\nconsistently outperforms previous state-of-the-art methods on both MRI T1w and\nT2w modalities. The codebase is accessible to the public on\n\\href{https://github.com/xmindflow/HCA-Net}{GitHub}.",
                "authors": [
                    "Afshin Bozorgpour",
                    "Bobby Azad",
                    "Reza Azad",
                    "Yury Velichko",
                    "Ulas Bagci",
                    "Dorit Merhof"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12486v1",
                    "http://arxiv.org/pdf/2311.12486v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12481v1/1.0",
                "title": "Interpretability is in the eye of the beholder: Human versus artificial\n  classification of image segments generated by humans versus XAI",
                "year": 2023,
                "abstract": "Evaluating methods of explainable artificial intelligence (XAI) is\nchallenging, because the fidelity of an explanation to the AI model does not\nnecessarily go hand in hand with its interpretability for humans. For instance,\nwhen classifying images with Convolutional Neural Networks (CNN), XAI\nalgorithms can explain which image areas had an impact on the CNN decision.\nHowever, it is unclear whether the areas that best reflect the CNN internal\ndata processing will also make most sense to humans. Thus, the present study\ninvestigated whether the image classification of humans and CNN is supported by\nthe same explanations. To assess such differences in interpretability, human\nparticipants and a CNN classified image segments that were considered most\ninformative either by other humans (as revealed by eye movements and manual\nselection) or by two XAI methods (Grad-CAM and XRAI). In three experiments,\nhumans classified and rated these segments, and we also had a CNN classify\nthem. The results indicated that the respective interpretability of the two XAI\nmethods strongly depended on image type, both for humans and CNN. Moreover,\nhuman classification performance was highest with human segments, regardless of\nhow they were generated (i.e., from eye movements or manual selection), whereas\nthe type of human segment had major impacts on CNN classification performance.\nOur results caution against general statements about the interpretability of\nexplanations, as this interpretability varies with the explanation method, the\nexplanations to be interpreted, and the agent who needs to perform the\ninterpretation.",
                "authors": [
                    "Romy M\u00fcller",
                    "Marius Tho\u00df",
                    "Julian Ullrich",
                    "Steffen Seitz",
                    "Carsten Knoll"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12481v1",
                    "http://arxiv.org/pdf/2311.12481v1"
                ],
                "primary_category": "cs.HC",
                "categories": [
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12480v1/1.0",
                "title": "Speaker-Adapted End-to-End Visual Speech Recognition for Continuous\n  Spanish",
                "year": 2023,
                "abstract": "Different studies have shown the importance of visual cues throughout the\nspeech perception process. In fact, the development of audiovisual approaches\nhas led to advances in the field of speech technologies. However, although\nnoticeable results have recently been achieved, visual speech recognition\nremains an open research problem. It is a task in which, by dispensing with the\nauditory sense, challenges such as visual ambiguities and the complexity of\nmodeling silence must be faced. Nonetheless, some of these challenges can be\nalleviated when the problem is approached from a speaker-dependent perspective.\nThus, this paper studies, using the Spanish LIP-RTVE database, how the\nestimation of specialized end-to-end systems for a specific person could affect\nthe quality of speech recognition. First, different adaptation strategies based\non the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention\narchitecture was used as a baseline throughout our experiments. Our findings\nshowed that a two-step fine-tuning process, where the VSR system is first\nadapted to the task domain, provided significant improvements when the speaker\nadaptation was addressed. Furthermore, results comparable to the current state\nof the art were reached even when only a limited amount of data was available.",
                "authors": [
                    "David Gimeno-G\u00f3mez",
                    "Carlos-D. Mart\u00ednez-Hinarejos"
                ],
                "url": [
                    "http://dx.doi.org/10.21437/IberSPEECH.2022-9",
                    "http://arxiv.org/abs/2311.12480v1",
                    "http://arxiv.org/pdf/2311.12480v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL",
                    "cs.SD",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12478v1/1.0",
                "title": "Is mathematics a game?",
                "year": 2023,
                "abstract": "We re-examine the old question to what extent mathematics may be compared to\na game. Under the spell of Wittgenstein, we propose that the more refined\nobject of comparison is a \"motley of language games\", the nature of which was\n(implicitly) clarified by Hilbert: via different language games, axiomatization\nlies at the basis of both the rigour and the applicability of mathematics. In\nthe \"formalist\" game, mathematics resembles chess via a clear conceptual\ndictionary. Accepting this resemblance: like positions in chess, mathematical\nsentences cannot be true or false; true statements in mathematics are about\nsentences, namely that they are theorems (if they are). In principle, the\ncertainty of mathematics resides in proofs, but to this end, in practice these\nmust be \"surveyable\". Hilbert and Wittgenstein proposed almost oppositie\ncriteria for surveyability; we try to overcome their difference by invoking\ncomputer-verified proofs. The \"applied\"' language game is based on Hilbert's\naxiomatization program for physics (and other scientific disciplines), refined\nby Wittgenstein's idea that theorems are yardsticks to which empirical\nphenomena may be compared, and further improved by invoking elements of van\nFraassen's constructive empiricism. From this perspective, in an appendix we\nalso briefly review the varying roles and structures of axioms, definitions,\nand proofs in mathematics. Our view is not meant as a philosophy of mathematics\nby itself, but as a coat rack analogous to category theory, onto which various\n(traditional and new) philosophies of mathematics (such as formalism,\nintuitionism, structuralism, deductivism, and the philosophy of mathematical\npractice) may be attached and may even peacefully support each other.",
                "authors": [
                    "Klaas Landsman",
                    "Kirti Singh"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12478v1",
                    "http://arxiv.org/pdf/2311.12478v1"
                ],
                "primary_category": "math.HO",
                "categories": [
                    "math.HO",
                    "math-ph",
                    "math.MP",
                    "00A30"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12475v2/1.0",
                "title": "PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with\n  Unassimilated Loanwords",
                "year": 2023,
                "abstract": "While WangchanBERTa has become the de facto standard in transformer-based\nThai language modeling, it still has shortcomings in regard to the\nunderstanding of foreign words, most notably English words, which are often\nborrowed without orthographic assimilation into Thai in many contexts. We\nidentify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the\nmain source of these shortcomings. We then expand WangchanBERTa's vocabulary\nvia vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new\nmodel using the expanded tokenizer, starting from WangchanBERTa's checkpoint,\non a new dataset that is larger than the one used to train WangchanBERTa. Our\nresults show that our new pretrained model, PhayaThaiBERT, outperforms\nWangchanBERTa in many downstream tasks and datasets.",
                "authors": [
                    "Panyut Sriwirote",
                    "Jalinee Thapiang",
                    "Vasan Timtong",
                    "Attapol T. Rutherford"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12475v2",
                    "http://arxiv.org/pdf/2311.12475v2"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12474v1/1.0",
                "title": "CSMeD: Bridging the Dataset Gap in Automated Citation Screening for\n  Systematic Literature Reviews",
                "year": 2023,
                "abstract": "Systematic literature reviews (SLRs) play an essential role in summarising,\nsynthesising and validating scientific evidence. In recent years, there has\nbeen a growing interest in using machine learning techniques to automate the\nidentification of relevant studies for SLRs. However, the lack of standardised\nevaluation datasets makes comparing the performance of such automated\nliterature screening systems difficult. In this paper, we analyse the citation\nscreening evaluation datasets, revealing that many of the available datasets\nare either too small, suffer from data leakage or have limited applicability to\nsystems treating automated literature screening as a classification task, as\nopposed to, for example, a retrieval or question-answering task. To address\nthese challenges, we introduce CSMeD, a meta-dataset consolidating nine\npublicly released collections, providing unified access to 325 SLRs from the\nfields of medicine and computer science. CSMeD serves as a comprehensive\nresource for training and evaluating the performance of automated citation\nscreening models. Additionally, we introduce CSMeD-FT, a new dataset designed\nexplicitly for evaluating the full text publication screening task. To\ndemonstrate the utility of CSMeD, we conduct experiments and establish\nbaselines on new datasets.",
                "authors": [
                    "Wojciech Kusa",
                    "Oscar E. Mendoza",
                    "Matthias Samwald",
                    "Petr Knoth",
                    "Allan Hanbury"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12474v1",
                    "http://arxiv.org/pdf/2311.12474v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12468v1/1.0",
                "title": "Analysis of Visual Features for Continuous Lipreading in Spanish",
                "year": 2023,
                "abstract": "During a conversation, our brain is responsible for combining information\nobtained from multiple senses in order to improve our ability to understand the\nmessage we are perceiving. Different studies have shown the importance of\npresenting visual information in these situations. Nevertheless, lipreading is\na complex task whose objective is to interpret speech when audio is not\navailable. By dispensing with a sense as crucial as hearing, it will be\nnecessary to be aware of the challenge that this lack presents. In this paper,\nwe propose an analysis of different speech visual features with the intention\nof identifying which of them is the best approach to capture the nature of lip\nmovements for natural Spanish and, in this way, dealing with the automatic\nvisual speech recognition task. In order to estimate our system, we present an\naudiovisual corpus compiled from a subset of the RTVE database, which has been\nused in the Albayz\\'in evaluations. We employ a traditional system based on\nHidden Markov Models with Gaussian Mixture Models. Results show that, although\nthe task is difficult, in restricted conditions we obtain recognition results\nwhich determine that using eigenlips in combination with deep features is the\nbest visual approach.",
                "authors": [
                    "David Gimeno-G\u00f3mez",
                    "Carlos-D. Mart\u00ednez-Hinarejos"
                ],
                "url": [
                    "http://dx.doi.org/10.21437/IberSPEECH.2021-47",
                    "http://arxiv.org/abs/2311.12468v1",
                    "http://arxiv.org/pdf/2311.12468v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12465v1/1.0",
                "title": "Towards a Gateway for Knowledge Graph Schemas Collection, Analysis, and\n  Embedding",
                "year": 2023,
                "abstract": "One of the significant barriers to the training of statistical models on\nknowledge graphs is the difficulty that scientists have in finding the best\ninput data to address their prediction goal. In addition to this, a key\nchallenge is to determine how to manipulate these relational data, which are\noften in the form of particular triples (i.e., subject, predicate, object), to\nenable the learning process. Currently, many high-quality catalogs of knowledge\ngraphs, are available. However, their primary goal is the re-usability of these\nresources, and their interconnection, in the context of the Semantic Web. This\npaper describes the LiveSchema initiative, namely, a first version of a gateway\nthat has the main scope of leveraging the gold mine of data collected by many\nexisting catalogs collecting relational data like ontologies and knowledge\ngraphs. At the current state, LiveSchema contains - 1000 datasets from 4 main\nsources and offers some key facilities, which allow to: i) evolving LiveSchema,\nby aggregating other source catalogs and repositories as input sources; ii)\nquerying all the collected resources; iii) transforming each given dataset into\nformal concept analysis matrices that enable analysis and visualization\nservices; iv) generating models and tensors from each given dataset.",
                "authors": [
                    "Mattia Fumagalli",
                    "Marco Boffo",
                    "Daqian Shi",
                    "Mayukh Bagchi",
                    "Fausto Giunchiglia"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12465v1",
                    "http://arxiv.org/pdf/2311.12465v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12464v1/1.0",
                "title": "Speciation controls the kinetics of iron hydroxide precipitation and\n  transformation",
                "year": 2023,
                "abstract": "The formation of energetically favourable and metastable mineral phases\nwithin the Fe-H2O system controls the long-term mobility of iron complexes as\nwell as other aqueous phase constituents in natural aquifers, soils and other\nenvironmentally and industrially relevant systems. The fundamental mechanism\ncontrolling the formation of these solid phases has remained enigmatic. Here,\nwe develop a general state-of-the-art partial equilibrium model and succeed in\npredicting the rate of amorphous 2-line ferrihydrite precipitation, dissolution\nand overall transformation to crystalline goethite at alkaline pH. All\nmechanistic steps constituting the transformation mechanism accurately predict\nthe experimentally measured solid and aqueous phase composition over time,\ninvolving only a single kinetic rate constant each. It is found that the\nprecipitation of goethite (i) occurs from solution and (ii) is limited by the\ncomparatively slow dissolution of the first forming amorphous phase 2-line\nferrihydrite. A generalised transformation mechanism applicable to near-neutral\nand mildly acidic pH further illustrates that differences in the kinetics of\nFe(III) precipitation are controlled by the coordination environment of the\npredominant Fe(III) hydrolysis product. Findings provide a framework for the\nmodelling of other iron(bearing) phases across a broad range of aqueous phase\ncompositions.",
                "authors": [
                    "Fabio Enrico Furcas",
                    "Shishir Mundra",
                    "Barbara Lothenbach",
                    "Ueli Angst"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12464v1",
                    "http://arxiv.org/pdf/2311.12464v1"
                ],
                "primary_category": "cond-mat.mtrl-sci",
                "categories": [
                    "cond-mat.mtrl-sci"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12461v1/1.0",
                "title": "HiFi-Syn: Hierarchical Granularity Discrimination for High-Fidelity\n  Synthesis of MR Images with Structure Preservation",
                "year": 2023,
                "abstract": "Synthesizing medical images while preserving their structural information is\ncrucial in medical research. In such scenarios, the preservation of anatomical\ncontent becomes especially important. Although recent advances have been made\nby incorporating instance-level information to guide translation, these methods\noverlook the spatial coherence of structural-level representation and the\nanatomical invariance of content during translation. To address these issues,\nwe introduce hierarchical granularity discrimination, which exploits various\nlevels of semantic information present in medical images. Our strategy utilizes\nthree levels of discrimination granularity: pixel-level discrimination using a\nBrain Memory Bank, structure-level discrimination on each brain structure with\na re-weighting strategy to focus on hard samples, and global-level\ndiscrimination to ensure anatomical consistency during translation. The image\ntranslation performance of our strategy has been evaluated on three independent\ndatasets (UK Biobank, IXI, and BraTS 2018), and it has outperformed\nstate-of-the-art algorithms. Particularly, our model excels not only in\nsynthesizing normal structures but also in handling abnormal (pathological)\nstructures, such as brain tumors, despite the variations in contrast observed\nacross different imaging modalities due to their pathological characteristics.\nThe diagnostic value of synthesized MR images containing brain tumors has been\nevaluated by radiologists. This indicates that our model may offer an\nalternative solution in scenarios where specific MR modalities of patients are\nunavailable. Extensive experiments further demonstrate the versatility of our\nmethod, providing unique insights into medical image translation.",
                "authors": [
                    "Ziqi Yu",
                    "Botao Zhao",
                    "Shengjie Zhang",
                    "Xiang Chen",
                    "Jianfeng Feng",
                    "Tingying Peng",
                    "Xiao-Yong Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12461v1",
                    "http://arxiv.org/pdf/2311.12461v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12457v1/1.0",
                "title": "LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild",
                "year": 2023,
                "abstract": "Speech is considered as a multi-modal process where hearing and vision are\ntwo fundamentals pillars. In fact, several studies have demonstrated that the\nrobustness of Automatic Speech Recognition systems can be improved when audio\nand visual cues are combined to represent the nature of speech. In addition,\nVisual Speech Recognition, an open research problem whose purpose is to\ninterpret speech by reading the lips of the speaker, has been a focus of\ninterest in the last decades. Nevertheless, in order to estimate these systems\nin the currently Deep Learning era, large-scale databases are required. On the\nother hand, while most of these databases are dedicated to English, other\nlanguages lack sufficient resources. Thus, this paper presents a\nsemi-automatically annotated audiovisual database to deal with unconstrained\nnatural Spanish, providing 13 hours of data extracted from Spanish television.\nFurthermore, baseline results for both speaker-dependent and\nspeaker-independent scenarios are reported using Hidden Markov Models, a\ntraditional paradigm that has been widely used in the field of Speech\nTechnologies.",
                "authors": [
                    "David Gimeno-G\u00f3mez",
                    "Carlos-D. Mart\u00ednez-Hinarejos"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12457v1",
                    "http://arxiv.org/pdf/2311.12457v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12454v2/1.0",
                "title": "HierSpeech++: Bridging the Gap between Semantic and Acoustic\n  Representation of Speech by Hierarchical Variational Inference for Zero-shot\n  Speech Synthesis",
                "year": 2023,
                "abstract": "Large language models (LLM)-based speech synthesis has been widely adopted in\nzero-shot speech synthesis. However, they require a large-scale data and\npossess the same limitations as previous autoregressive speech models,\nincluding slow inference speed and lack of robustness. This paper proposes\nHierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech\n(TTS) and voice conversion (VC). We verified that hierarchical speech synthesis\nframeworks could significantly improve the robustness and expressiveness of the\nsynthetic speech. Furthermore, we significantly improve the naturalness and\nspeaker similarity of synthetic speech even in zero-shot speech synthesis\nscenarios. For text-to-speech, we adopt the text-to-vec framework, which\ngenerates a self-supervised speech representation and an F0 representation\nbased on text representations and prosody prompts. Then, HierSpeech++ generates\nspeech from the generated vector, F0, and voice prompt. We further introduce a\nhigh-efficient speech super-resolution framework from 16 kHz to 48 kHz. The\nexperimental results demonstrated that the hierarchical variational autoencoder\ncould be a strong zero-shot speech synthesizer given that it outperforms\nLLM-based and diffusion-based models. Moreover, we achieved the first\nhuman-level quality zero-shot speech synthesis. Audio samples and source code\nare available at https://github.com/sh-lee-prml/HierSpeechpp.",
                "authors": [
                    "Sang-Hoon Lee",
                    "Ha-Yeong Choi",
                    "Seung-Bin Kim",
                    "Seong-Whan Lee"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12454v2",
                    "http://arxiv.org/pdf/2311.12454v2"
                ],
                "primary_category": "cs.SD",
                "categories": [
                    "cs.SD",
                    "cs.AI",
                    "cs.MM",
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12453v1/1.0",
                "title": "Hydrodynamic limit of N-branching Markov processes",
                "year": 2023,
                "abstract": "We consider the behaviour of branching-selection particle systems in the\nlarge population limit. The dynamics of these systems is the combination of the\nfollowing three components: (a) Motion: particles move on the real line\naccording to a continuous-time Markov process; (b) Branching: at rate 1, each\nparticle gives birth to a new particle at its current location; (c) Selection:\nto keep the total number of particles constant, each branching event causes the\nparticle currently located at the lowest position in the system to be removed\ninstantly. Starting with N $\\ge$ 1 particles whose positions at time t = 0 form\nan i.i.d. sample with distribution $\\mu$ 0 , we investigate the behaviour of\nthe system at a further time t > 0, in the limit N $\\rightarrow$ +$\\infty$. Our\nfirst main result is that, under suitable (but rather mild) regularity\nassumptions on the underlying Markov process, the empirical distribution of the\npopulation of particles at time t converges to a deterministic limit,\ncharacterized as the distribution of the Markov process at time t conditional\nupon not crossing a certain (deterministic) moving boundary up to time t. Our\nsecond result is that, under additional regularity assumptions, the lowest\nparticle position at time t converges to the moving boundary. These results\nextend and refine previous works done by other authors, that dealt mainly with\nthe case where particles move according to a Brownian motion. For instance, our\nresults hold for a wide class of L{\\'e}vy processes and diffusion processes.\nMoreover, we obtain improved non-asymptotic bounds on the convergence speed.",
                "authors": [
                    "Jean B\u00e9rard",
                    "Brieuc Fr\u00e9nais"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12453v1",
                    "http://arxiv.org/pdf/2311.12453v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12449v1/1.0",
                "title": "HPCNeuroNet: Advancing Neuromorphic Audio Signal Processing with\n  Transformer-Enhanced Spiking Neural Networks",
                "year": 2023,
                "abstract": "This paper presents a novel approach to neuromorphic audio processing by\nintegrating the strengths of Spiking Neural Networks (SNNs), Transformers, and\nhigh-performance computing (HPC) into the HPCNeuroNet architecture. Utilizing\nthe Intel N-DNS dataset, we demonstrate the system's capability to process\ndiverse human vocal recordings across multiple languages and noise backgrounds.\nThe core of our approach lies in the fusion of the temporal dynamics of SNNs\nwith the attention mechanisms of Transformers, enabling the model to capture\nintricate audio patterns and relationships. Our architecture, HPCNeuroNet,\nemploys the Short-Time Fourier Transform (STFT) for time-frequency\nrepresentation, Transformer embeddings for dense vector generation, and SNN\nencoding/decoding mechanisms for spike train conversions. The system's\nperformance is further enhanced by leveraging the computational capabilities of\nNVIDIA's GeForce RTX 3060 GPU and Intel's Core i9 12900H CPU. Additionally, we\nintroduce a hardware implementation on the Xilinx VU37P HBM FPGA platform,\noptimizing for energy efficiency and real-time processing. The proposed\naccelerator achieves a throughput of 71.11 Giga-Operations Per Second (GOP/s)\nwith a 3.55 W on-chip power consumption at 100 MHz. The comparison results with\noff-the-shelf devices and recent state-of-the-art implementations illustrate\nthat the proposed accelerator has obvious advantages in terms of energy\nefficiency and design flexibility. Through design-space exploration, we provide\ninsights into optimizing core capacities for audio tasks. Our findings\nunderscore the transformative potential of integrating SNNs, Transformers, and\nHPC for neuromorphic audio processing, setting a new benchmark for future\nresearch and applications.",
                "authors": [
                    "Murat Isik",
                    "Hiruna Vishwamith",
                    "Kayode Inadagbo",
                    "I. Can Dikmen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12449v1",
                    "http://arxiv.org/pdf/2311.12449v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS",
                    "cs.SD"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12448v1/1.0",
                "title": "Extracting Definienda in Mathematical Scholarly Articles with\n  Transformers",
                "year": 2023,
                "abstract": "We consider automatically identifying the defined term within a mathematical\ndefinition from the text of an academic article. Inspired by the development of\ntransformer-based natural language processing applications, we pose the problem\nas (a) a token-level classification task using fine-tuned pre-trained\ntransformers; and (b) a question-answering task using a generalist large\nlanguage model (GPT). We also propose a rule-based approach to build a labeled\ndataset from the LATEX source of papers. Experimental results show that it is\npossible to reach high levels of precision and recall using either recent (and\nexpensive) GPT 4 or simpler pre-trained models fine-tuned on our task.",
                "authors": [
                    "Shufan Jiang",
                    "Pierre Senellart"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12448v1",
                    "http://arxiv.org/pdf/2311.12448v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12447v1/1.0",
                "title": "Designing Long-term Group Fair Policies in Dynamical Systems",
                "year": 2023,
                "abstract": "Neglecting the effect that decisions have on individuals (and thus, on the\nunderlying data distribution) when designing algorithmic decision-making\npolicies may increase inequalities and unfairness in the long term - even if\nfairness considerations were taken in the policy design process. In this paper,\nwe propose a novel framework for achieving long-term group fairness in\ndynamical systems, in which current decisions may affect an individual's\nfeatures in the next step, and thus, future decisions. Specifically, our\nframework allows us to identify a time-independent policy that converges, if\ndeployed, to the targeted fair stationary state of the system in the long term,\nindependently of the initial data distribution. We model the system dynamics\nwith a time-homogeneous Markov chain and optimize the policy leveraging the\nMarkov chain convergence theorem to ensure unique convergence. We provide\nexamples of different targeted fair states of the system, encompassing a range\nof long-term goals for society and policymakers. Furthermore, we show how our\napproach facilitates the evaluation of different long-term targets by examining\ntheir impact on the group-conditional population distribution in the long term\nand how it evolves until convergence.",
                "authors": [
                    "Miriam Rateike",
                    "Isabel Valera",
                    "Patrick Forr\u00e9"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12447v1",
                    "http://arxiv.org/pdf/2311.12447v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12440v1/1.0",
                "title": "A Random Walk Approach for Simulation-Based Continuous Dynamic Traffic\n  Assignment",
                "year": 2023,
                "abstract": "This paper presents a new simulation-based approach to address the stochastic\nDynamic Traffic Assignment (DTA) problem, focusing on large congested networks\nand dynamic settings. The proposed methodology incorporates a random walk model\ninspired by the theoretical concept of the \\textit{equivalent impedance}\nmethod, specifically designed to overcome the limitations of traditional\nMultinomial Logit (MNL) models in handling overlapping routes and scaling\nissues. By iteratively contracting non-overlapping subnetworks into virtual\nlinks and computing equivalent virtual travel costs, the route choice\ndecision-making process is shifted to intersections, enabling a more accurate\nrepresentation of travelers' choices as traffic conditions evolve and allowing\nmore accurate performance under fine-grained temporal segmentation.\n  The approach leverages Directed Acyclic Graphs (DAGs) structure to\nefficiently find all routes between two nodes, thus obviating the need for\nroute enumeration, which is intractable in general networks. While with the\ncalculation approach of downstream node choice probabilities, all available\nroutes in the network can be selected with non-zero probability.\n  To evaluate the effectiveness of the proposed method, experiments are\nconducted on two synthetic networks under congested demand scenarios using\nSimulation of Urban MObility (SUMO), an open-source microscopic traffic\nsimulation software. The results demonstrate the method's robustness, faster\nconvergence, and realistic trip distribution compared to traditional route\nassignment methods, making it an ideal proposal for real-time or\nresource-intensive applications such as microscopic demand calibration.",
                "authors": [
                    "Kaveh Khoshkhah",
                    "Mozhgan Pourmoradnasseri",
                    "Sadok Ben Yahia",
                    "Amnir Hadachi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12440v1",
                    "http://arxiv.org/pdf/2311.12440v1"
                ],
                "primary_category": "cs.MA",
                "categories": [
                    "cs.MA"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12439v1/1.0",
                "title": "Harnessing FPGA Technology for Enhanced Biomedical Computation",
                "year": 2023,
                "abstract": "This research delves into sophisticated neural network frameworks like\nConvolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long\nShort-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for\nimproved analysis of ECG signals via Field Programmable Gate Arrays (FPGAs).\nThe MIT-BIH Arrhythmia Database serves as the foundation for training and\nevaluating our models, with added Gaussian noise to heighten the algorithms'\nresilience. The developed architectures incorporate various layers for specific\nprocessing and categorization functions, employing strategies such as the\nEarlyStopping callback and Dropout layer to prevent overfitting. Additionally,\nthis paper details the creation of a tailored Tensor Compute Unit (TCU)\naccelerator for the PYNQ Z1 platform. It provides a thorough methodology for\nimplementing FPGA-based machine learning, encompassing the configuration of the\nTensil toolchain in Docker, selection of architectures, PS-PL configuration,\nand the compilation and deployment of models. By evaluating performance\nindicators like latency and throughput, we showcase the efficacy of FPGAs in\nadvanced biomedical computing. This study ultimately serves as a comprehensive\nguide to optimizing neural network operations on FPGAs across various fields.",
                "authors": [
                    "Nisanur Alici",
                    "Kayode Inadagbo",
                    "Murat Isik"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12439v1",
                    "http://arxiv.org/pdf/2311.12439v1"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12433v1/1.0",
                "title": "Constellation Shaping under Phase Noise Impairment for Sub-THz\n  Communications",
                "year": 2023,
                "abstract": "The large untapped spectrum in the sub-THz allows for ultra-high throughput\ncommunication to realize many seemingly impossible applications in 6G. One of\nthe challenges in radio communications in sub-THz is the hardware impairments.\nSpecifically, phase noise is one key hardware impairment, which is accentuated\nas we increase the frequency and bandwidth. Furthermore, the modest output\npower of the sub-THz power amplifier demands limits on peak to average power\nratio (PAPR) signal design. Single carrier frequency domain equalization\n(SC-FDE) waveform has been identified as a suitable candidate for sub-THz,\nalthough some challenges such as phase noise and PAPR still remain to be\ntackled. In this work, we design a phase noise robust, low PAPR SC-FDE waveform\nby geometrically shaping the constellation under practical conditions. We\nformulate the waveform optimization problem in its augmented Lagrangian form\nand use a back-propagation-inspired technique to obtain a constellation design\nthat is numerically robust to phase noise, while maintaining a low PAPR.",
                "authors": [
                    "Dileepa Marasinghe",
                    "Le Hang Nguyen",
                    "Jafar Mohammadi",
                    "Yejian Chen",
                    "Thorsten Wild",
                    "Nandana Rajatheva"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12433v1",
                    "http://arxiv.org/pdf/2311.12433v1"
                ],
                "primary_category": "cs.IT",
                "categories": [
                    "cs.IT",
                    "eess.SP",
                    "math.IT"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12431v1/1.0",
                "title": "A recurrent connectionist model of melody perception : An exploration\n  using TRACX2",
                "year": 2023,
                "abstract": "Are similar, or even identical, mechanisms used in the computational modeling\nof speech segmentation, serial image processing and music processing? We\naddress this question by exploring how TRACX2, (French et al., 2011; French \\&\nCottrell, 2014; Mareschal \\& French, 2017), a recognition-based, recursive\nconnectionist autoencoder model of chunking and sequence segmentation, which\nhas successfully simulated speech and serial-image processing, might be applied\nto elementary melody perception. The model, a three-layer autoencoder that\nrecognizes ''chunks'' of short sequences of intervals that have been frequently\nencountered on input, is trained on the tone intervals of melodically simple\nFrench children's songs. It dynamically incorporates the internal\nrepresentations of these chunks into new input. Its internal representations\ncluster in a manner that is consistent with ''human-recognizable'' melodic\ncategories. TRACX2 is sensitive to both contour and proximity information in\nthe musical chunks that it encounters in its input. It shows the\n''end-of-word'' superiority effect demonstrated by Saffran et al. (1999) for\nshort musical phrases. The overall findings suggest that the recursive\nautoassociative chunking mechanism, as implemented in TRACX2, may be a general\nsegmentation and chunking mechanism, underlying not only word-and\nimagechunking, but also elementary melody processing.",
                "authors": [
                    "Daniel Defays",
                    "Robert French",
                    "Barbara Tillmann"
                ],
                "url": [
                    "http://dx.doi.org/10.1111/cogs.13283",
                    "http://arxiv.org/abs/2311.12431v1",
                    "http://arxiv.org/pdf/2311.12431v1"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12428v3/1.0",
                "title": "Exotic $C^*$-completions of \u00c9tale Groupoids",
                "year": 2023,
                "abstract": "We generalize the ideal completions of countable discrete groups, as\nintroduced by Brown and Guentner, to second countable Hausdorff \\'etale\ngroupoids. Specifically, to every pair consisting of an algebraic ideal in the\nalgebra of bounded Borel functions on the groupoid and a non-empty family of\nquasi-invariant measures on the unit space, we construct a $C^*$-algebra in a\nway which naturally encapsulates the constructions of the full and reduced\ngroupoid $C^*$-algebras. We investigate the connection between these\nconstructions and the Haagerup property, and use the construction to show the\nexistence of many exotic groupoid $C^*$-algebras for certain classes of\ngroupoids.",
                "authors": [
                    "Mathias Palmstr\u00f8m"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12428v3",
                    "http://arxiv.org/pdf/2311.12428v3"
                ],
                "primary_category": "math.OA",
                "categories": [
                    "math.OA",
                    "46L05, 46L55, 22A22"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12427v1/1.0",
                "title": "A Distributed Algorithm for Personal Sound Zones Systems",
                "year": 2023,
                "abstract": "A Personal Sound Zones (PSZ) system aims to generate two or more independent\nlistening zones that allow multiple users to listen to different music/audio\ncontent in a shared space without the need for wearing headphones. Most\nexisting studies assume that the acoustic paths between loudspeakers and\nmicrophones are measured beforehand in a stationary environment. Recently,\nadaptive PSZ systems have been explored to adapt the system in a time-varying\nacoustic environment. However, because a PSZ system usually requires multiple\nloudspeakers, the multichannel adaptive algorithms impose a high computational\nload on the processor. To overcome that problem, this paper proposes an\nefficient distributed algorithm for PSZ systems, which not only spreads the\ncomputational burden over multiple nodes but also reduces the overall\ncomputational complexity, at the expense of a slight decrease in performance.\nSimulation results with true room impulse responses measured in a Hemi-Anechoic\nchamber are performed to verify the proposed distributed PSZ system.",
                "authors": [
                    "Sipei Zhao",
                    "Guoqiang Zhang",
                    "Eva Cheng",
                    "Ian S. Burnett"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12427v1",
                    "http://arxiv.org/pdf/2311.12427v1"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12422v1/1.0",
                "title": "On Asymptotics of Solutions of Stochastic Differential Equations with\n  Jumps",
                "year": 2023,
                "abstract": "Consider a one-dimensional stochastic differential equation with jumps\n$$\\mathrm d X(t) = a(X(t))\\mathrm d t + \\sum_{k = 1}^m b_k(X(t-))\\mathrm d\nZ_k(t),$$ where $Z_k, \\ k \\in \\{1, 2, ..., m\\}$ are independent centered L\\'evy\nprocesses with finite second moments. We prove that if coefficient $a(x)$ has\ncertain power asymptotics as $x \\to \\infty$ and coefficients $b_k, \\ k \\in \\{1,\n2, ..., m\\},$ satisfy certain growth condition then a solution $X(t)$ has the\nsame asymptotics as a solution of $\\mathrm d x(t) = a(x(t))\\mathrm d t$ as $t\n\\to \\infty$ a.s.",
                "authors": [
                    "Viktor Yuskovych"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12422v1",
                    "http://arxiv.org/pdf/2311.12422v1"
                ],
                "primary_category": "math.PR",
                "categories": [
                    "math.PR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12895v1/1.0",
                "title": "Improved measurement of the decays $\u03b7' \\to\n  \u03c0^{+}\u03c0^{-}\u03c0^{+(0)}\u03c0^{-(0)}$ and search for the rare decay $\u03b7' \\to\n  4\u03c0^{0}$",
                "year": 2023,
                "abstract": "Using a sample of 10 billion $J/{\\psi}$ events collected with the BESIII\ndetector, the decays $\\eta' \\to \\pi^{+}\\pi^{-}\\pi^{+}\\pi^{-}$, $\\eta' \\to\n\\pi^{+}\\pi^{-}\\pi^{0}\\pi^{0}$ and $\\eta' \\to 4 \\pi^{0}$ are studied via the\nprocess $J/{\\psi}\\to\\gamma\\eta'$. The branching fractions of $\\eta' \\to\n\\pi^{+}\\pi^{-}\\pi^{+}\\pi^{-}$ and $\\eta' \\to \\pi^{+}\\pi^{-}\\pi^{0}$ $\\pi^{0}$\nare measured to be $( 8.56 \\pm 0.25({\\rm stat.}) \\pm 0.23({\\rm syst.}) ) \\times\n{10^{ - 5}}$ and $(2.12 \\pm 0.12({\\rm stat.}) \\pm 0.10({\\rm syst.})) \\times\n{10^{ - 4}}$, respectively, which are consistent with previous measurements but\nwith improved precision. No significant $\\eta' \\to 4 \\pi^{0}$ signal is\nobserved, and the upper limit on the branching fraction of this decay is\ndetermined to be less than $1.24 \\times {10^{-5}}$ at the $90\\%$ confidence\nlevel. In addition, an amplitude analysis of $\\eta' \\to\n\\pi^{+}\\pi^{-}\\pi^{+}\\pi^{-}$ is performed to extract the doubly virtual\nisovector form factor $\\alpha$ for the first time. The measured value of\n$\\alpha=1.22 \\pm 0.33({\\rm stat.}) \\pm 0.04({\\rm syst.})$, is in agreement with\nthe prediction of the VMD model.",
                "authors": [
                    "BESIII Collaboration",
                    "M. Ablikim",
                    "M. N. Achasov",
                    "P. Adlarson",
                    "X. C. Ai",
                    "R. Aliberti",
                    "A. Amoroso",
                    "M. R. An",
                    "Q. An",
                    "Y. Bai",
                    "O. Bakina",
                    "I. Balossino",
                    "Y. Ban",
                    "H. -R. Bao",
                    "V. Batozskaya",
                    "K. Begzsuren",
                    "N. Berger",
                    "M. Berlowski",
                    "M. Bertani",
                    "D. Bettoni",
                    "F. Bianchi",
                    "E. Bianco",
                    "A. Bortone",
                    "I. Boyko",
                    "R. A. Briere",
                    "A. Brueggemann",
                    "H. Cai",
                    "X. Cai",
                    "A. Calcaterra",
                    "G. F. Cao",
                    "N. Cao",
                    "S. A. Cetin",
                    "J. F. Chang",
                    "W. L. Chang",
                    "G. R. Che",
                    "G. Chelkov",
                    "C. Chen",
                    "Chao Chen",
                    "G. Chen",
                    "H. S. Chen",
                    "M. L. Chen",
                    "S. J. Chen",
                    "S. L. Chen",
                    "S. M. Chen",
                    "T. Chen",
                    "X. R. Chen",
                    "X. T. Chen",
                    "Y. B. Chen",
                    "Y. Q. Chen",
                    "Z. J. Chen",
                    "S. K. Choi",
                    "X. Chu",
                    "G. Cibinetto",
                    "S. C. Coen",
                    "F. Cossio",
                    "J. J. Cui",
                    "H. L. Dai",
                    "J. P. Dai",
                    "A. Dbeyssi",
                    "R. E. de Boer",
                    "D. Dedovich",
                    "Z. Y. Deng",
                    "A. Denig",
                    "I. Denysenko",
                    "M. Destefanis",
                    "F. De Mori",
                    "B. Ding",
                    "X. X. Ding",
                    "Y. Ding",
                    "Y. Ding",
                    "J. Dong",
                    "L. Y. Dong",
                    "M. Y. Dong",
                    "X. Dong",
                    "M. C. Du",
                    "S. X. Du",
                    "Z. H. Duan",
                    "P. Egorov",
                    "Y. H. Fan",
                    "J. Fang",
                    "S. S. Fang",
                    "W. X. Fang",
                    "Y. Fang",
                    "Y. Q. Fang",
                    "R. Farinelli",
                    "L. Fava",
                    "F. Feldbauer",
                    "G. Felici",
                    "C. Q. Feng",
                    "J. H. Feng",
                    "Y. T. Feng",
                    "K Fischer",
                    "M. Fritsch",
                    "C. D. Fu",
                    "J. L. Fu",
                    "Y. W. Fu",
                    "H. Gao",
                    "Y. N. Gao",
                    "Yang Gao",
                    "S. Garbolino",
                    "I. Garzia",
                    "P. T. Ge",
                    "Z. W. Ge",
                    "C. Geng",
                    "E. M. Gersabeck",
                    "A Gilman",
                    "K. Goetzen",
                    "L. Gong",
                    "W. X. Gong",
                    "W. Gradl",
                    "S. Gramigna",
                    "M. Greco",
                    "M. H. Gu",
                    "Y. T. Gu",
                    "C. Y Guan",
                    "Z. L. Guan",
                    "A. Q. Guo",
                    "L. B. Guo",
                    "M. J. Guo",
                    "R. P. Guo",
                    "Y. P. Guo",
                    "A. Guskov",
                    "J. Gutierrez",
                    "K. L. Han",
                    "T. T. Han",
                    "W. Y. Han",
                    "X. Q. Hao",
                    "F. A. Harris",
                    "K. K. He",
                    "K. L. He",
                    "F. H. H. Heinsius",
                    "C. H. Heinz",
                    "Y. K. Heng",
                    "C. Herold",
                    "T. Holtmann",
                    "P. C. Hong",
                    "G. Y. Hou",
                    "X. T. Hou",
                    "Y. R. Hou",
                    "Z. L. Hou",
                    "B. Y. Hu",
                    "H. M. Hu",
                    "J. F. Hu",
                    "T. Hu",
                    "Y. Hu",
                    "G. S. Huang",
                    "K. X. Huang",
                    "L. Q. Huang",
                    "X. T. Huang",
                    "Y. P. Huang",
                    "T. Hussain",
                    "N H\u00fcsken",
                    "N. in der Wiesche",
                    "M. Irshad",
                    "J. Jackson",
                    "S. Jaeger",
                    "S. Janchiv",
                    "J. H. Jeong",
                    "Q. Ji",
                    "Q. P. Ji",
                    "X. B. Ji",
                    "X. L. Ji",
                    "Y. Y. Ji",
                    "X. Q. Jia",
                    "Z. K. Jia",
                    "H. B. Jiang",
                    "P. C. Jiang",
                    "S. S. Jiang",
                    "T. J. Jiang",
                    "X. S. Jiang",
                    "Y. Jiang",
                    "J. B. Jiao",
                    "Z. Jiao",
                    "S. Jin",
                    "Y. Jin",
                    "M. Q. Jing",
                    "X. M. Jing",
                    "T. Johansson",
                    "X. K.",
                    "S. Kabana",
                    "N. Kalantar-Nayestanaki",
                    "X. L. Kang",
                    "X. S. Kang",
                    "M. Kavatsyuk",
                    "B. C. Ke",
                    "V. Khachatryan",
                    "A. Khoukaz",
                    "R. Kiuchi",
                    "O. B. Kolcu",
                    "B. Kopf",
                    "M. Kuessner",
                    "A. Kupsc",
                    "W. K\u00fchn",
                    "J. J. Lane",
                    "P. Larin",
                    "L. Lavezzi",
                    "T. T. Lei",
                    "Z. H. Lei",
                    "H. Leithoff",
                    "M. Lellmann",
                    "T. Lenz",
                    "C. Li",
                    "C. Li",
                    "C. H. Li",
                    "Cheng Li",
                    "D. M. Li",
                    "F. Li",
                    "G. Li",
                    "H. Li",
                    "H. B. Li",
                    "H. J. Li",
                    "H. N. Li",
                    "Hui Li",
                    "J. R. Li",
                    "J. S. Li",
                    "J. W. Li",
                    "Ke Li",
                    "L. J Li",
                    "L. K. Li",
                    "Lei Li",
                    "M. H. Li",
                    "P. R. Li",
                    "Q. X. Li",
                    "S. X. Li",
                    "T. Li",
                    "W. D. Li",
                    "W. G. Li",
                    "X. H. Li",
                    "X. L. Li",
                    "Xiaoyu Li",
                    "Y. G. Li",
                    "Z. J. Li",
                    "Z. X. Li",
                    "C. Liang",
                    "H. Liang",
                    "H. Liang",
                    "Y. F. Liang",
                    "Y. T. Liang",
                    "G. R. Liao",
                    "L. Z. Liao",
                    "Y. P. Liao",
                    "J. Libby",
                    "A. Limphirat",
                    "D. X. Lin",
                    "T. Lin",
                    "B. J. Liu",
                    "B. X. Liu",
                    "C. Liu",
                    "C. X. Liu",
                    "F. H. Liu",
                    "Fang Liu",
                    "Feng Liu",
                    "G. M. Liu",
                    "H. Liu",
                    "H. B. Liu",
                    "H. M. Liu",
                    "Huanhuan Liu",
                    "Huihui Liu",
                    "J. B. Liu",
                    "J. Y. Liu",
                    "K. Liu",
                    "K. Y. Liu",
                    "Ke Liu",
                    "L. Liu",
                    "L. C. Liu",
                    "Lu Liu",
                    "M. H. Liu",
                    "P. L. Liu",
                    "Q. Liu",
                    "S. B. Liu",
                    "T. Liu",
                    "W. K. Liu",
                    "W. M. Liu",
                    "X. Liu",
                    "Y. Liu",
                    "Y. Liu",
                    "Y. B. Liu",
                    "Z. A. Liu",
                    "Z. Q. Liu",
                    "X. C. Lou",
                    "F. X. Lu",
                    "H. J. Lu",
                    "J. G. Lu",
                    "X. L. Lu",
                    "Y. Lu",
                    "Y. P. Lu",
                    "Z. H. Lu",
                    "C. L. Luo",
                    "M. X. Luo",
                    "T. Luo",
                    "X. L. Luo",
                    "X. R. Lyu",
                    "Y. F. Lyu",
                    "F. C. Ma",
                    "H. Ma",
                    "H. L. Ma",
                    "J. L. Ma",
                    "L. L. Ma",
                    "M. M. Ma",
                    "Q. M. Ma",
                    "R. Q. Ma",
                    "X. Y. Ma",
                    "Y. Ma",
                    "Y. M. Ma",
                    "F. E. Maas",
                    "M. Maggiora",
                    "S. Malde",
                    "Q. A. Malik",
                    "A. Mangoni",
                    "Y. J. Mao",
                    "Z. P. Mao",
                    "S. Marcello",
                    "Z. X. Meng",
                    "J. G. Messchendorp",
                    "G. Mezzadri",
                    "H. Miao",
                    "T. J. Min",
                    "R. E. Mitchell",
                    "X. H. Mo",
                    "B. Moses",
                    "N. Yu. Muchnoi",
                    "J. Muskalla",
                    "Y. Nefedov",
                    "F. Nerling",
                    "I. B. Nikolaev",
                    "Z. Ning",
                    "S. Nisar",
                    "Q. L. Niu",
                    "W. D. Niu",
                    "Y. Niu",
                    "S. L. Olsen",
                    "Q. Ouyang",
                    "S. Pacetti",
                    "X. Pan",
                    "Y. Pan",
                    "A. Pathak",
                    "P. Patteri",
                    "Y. P. Pei",
                    "M. Pelizaeus",
                    "H. P. Peng",
                    "Y. Y. Peng",
                    "K. Peters",
                    "J. L. Ping",
                    "R. G. Ping",
                    "S. Plura",
                    "V. Prasad",
                    "F. Z. Qi",
                    "H. Qi",
                    "H. R. Qi",
                    "M. Qi",
                    "T. Y. Qi",
                    "S. Qian",
                    "W. B. Qian",
                    "C. F. Qiao",
                    "J. J. Qin",
                    "L. Q. Qin",
                    "X. S. Qin",
                    "Z. H. Qin",
                    "J. F. Qiu",
                    "S. Q. Qu",
                    "C. F. Redmer",
                    "K. J. Ren",
                    "A. Rivetti",
                    "M. Rolo",
                    "G. Rong",
                    "Ch. Rosner",
                    "S. N. Ruan",
                    "N. Salone",
                    "A. Sarantsev",
                    "Y. Schelhaas",
                    "K. Schoenning",
                    "M. Scodeggio",
                    "K. Y. Shan",
                    "W. Shan",
                    "X. Y. Shan",
                    "J. F. Shangguan",
                    "L. G. Shao",
                    "M. Shao",
                    "C. P. Shen",
                    "H. F. Shen",
                    "W. H. Shen",
                    "X. Y. Shen",
                    "B. A. Shi",
                    "H. C. Shi",
                    "J. L. Shi",
                    "J. Y. Shi",
                    "Q. Q. Shi",
                    "R. S. Shi",
                    "X. Shi",
                    "J. J. Song",
                    "T. Z. Song",
                    "W. M. Song",
                    "Y. J. Song",
                    "S. Sosio",
                    "S. Spataro",
                    "F. Stieler",
                    "Y. J. Su",
                    "G. B. Sun",
                    "G. X. Sun",
                    "H. Sun",
                    "H. K. Sun",
                    "J. F. Sun",
                    "K. Sun",
                    "L. Sun",
                    "S. S. Sun",
                    "T. Sun",
                    "W. Y. Sun",
                    "Y. Sun",
                    "Y. J. Sun",
                    "Y. Z. Sun",
                    "Z. T. Sun",
                    "Y. X. Tan",
                    "C. J. Tang",
                    "G. Y. Tang",
                    "J. Tang",
                    "Y. A. Tang",
                    "L. Y Tao",
                    "Q. T. Tao",
                    "M. Tat",
                    "J. X. Teng",
                    "V. Thoren",
                    "W. H. Tian",
                    "W. H. Tian",
                    "Y. Tian",
                    "Z. F. Tian",
                    "I. Uman",
                    "Y. Wan",
                    "S. J. Wang",
                    "B. Wang",
                    "B. L. Wang",
                    "Bo Wang",
                    "C. W. Wang",
                    "D. Y. Wang",
                    "F. Wang",
                    "H. J. Wang",
                    "J. P. Wang",
                    "K. Wang",
                    "L. L. Wang",
                    "M. Wang",
                    "Meng Wang",
                    "N. Y. Wang",
                    "S. Wang",
                    "S. Wang",
                    "T. Wang",
                    "T. J. Wang",
                    "W. Wang",
                    "W. Wang",
                    "W. P. Wang",
                    "X. Wang",
                    "X. F. Wang",
                    "X. J. Wang",
                    "X. L. Wang",
                    "Y. Wang",
                    "Y. D. Wang",
                    "Y. F. Wang",
                    "Y. L. Wang",
                    "Y. N. Wang",
                    "Y. Q. Wang",
                    "Yaqian Wang",
                    "Yi Wang",
                    "Z. Wang",
                    "Z. L. Wang",
                    "Z. Y. Wang",
                    "Ziyi Wang",
                    "D. Wei",
                    "D. H. Wei",
                    "F. Weidner",
                    "S. P. Wen",
                    "C. W. Wenzel",
                    "U. Wiedner",
                    "G. Wilkinson",
                    "M. Wolke",
                    "L. Wollenberg",
                    "C. Wu",
                    "J. F. Wu",
                    "L. H. Wu",
                    "L. J. Wu",
                    "X. Wu",
                    "X. H. Wu",
                    "Y. Wu",
                    "Y. H. Wu",
                    "Y. J. Wu",
                    "Z. Wu",
                    "L. Xia",
                    "X. M. Xian",
                    "T. Xiang",
                    "D. Xiao",
                    "G. Y. Xiao",
                    "S. Y. Xiao",
                    "Y. L. Xiao",
                    "Z. J. Xiao",
                    "C. Xie",
                    "X. H. Xie",
                    "Y. Xie",
                    "Y. G. Xie",
                    "Y. H. Xie",
                    "Z. P. Xie",
                    "T. Y. Xing",
                    "C. F. Xu",
                    "C. J. Xu",
                    "G. F. Xu",
                    "H. Y. Xu",
                    "Q. J. Xu",
                    "Q. N. Xu",
                    "W. Xu",
                    "W. L. Xu",
                    "X. P. Xu",
                    "Y. C. Xu",
                    "Z. P. Xu",
                    "Z. S. Xu",
                    "F. Yan",
                    "L. Yan",
                    "W. B. Yan",
                    "W. C. Yan",
                    "X. Q. Yan",
                    "H. J. Yang",
                    "H. L. Yang",
                    "H. X. Yang",
                    "Tao Yang",
                    "Y. Yang",
                    "Y. F. Yang",
                    "Y. X. Yang",
                    "Yifan Yang",
                    "Z. W. Yang",
                    "Z. P. Yao",
                    "M. Ye",
                    "M. H. Ye",
                    "J. H. Yin",
                    "Z. Y. You",
                    "B. X. Yu",
                    "C. X. Yu",
                    "G. Yu",
                    "J. S. Yu",
                    "T. Yu",
                    "X. D. Yu",
                    "C. Z. Yuan",
                    "L. Yuan",
                    "S. C. Yuan",
                    "Y. Yuan",
                    "Z. Y. Yuan",
                    "C. X. Yue",
                    "A. A. Zafar",
                    "F. R. Zeng",
                    "S. H. Zeng",
                    "X. Zeng",
                    "Y. Zeng",
                    "Y. J. Zeng",
                    "X. Y. Zhai",
                    "Y. C. Zhai",
                    "Y. H. Zhan",
                    "A. Q. Zhang",
                    "B. L. Zhang",
                    "B. X. Zhang",
                    "D. H. Zhang",
                    "G. Y. Zhang",
                    "H. Zhang",
                    "H. C. Zhang",
                    "H. H. Zhang",
                    "H. H. Zhang",
                    "H. Q. Zhang",
                    "H. Y. Zhang",
                    "J. Zhang",
                    "J. Zhang",
                    "J. J. Zhang",
                    "J. L. Zhang",
                    "J. Q. Zhang",
                    "J. W. Zhang",
                    "J. X. Zhang",
                    "J. Y. Zhang",
                    "J. Z. Zhang",
                    "Jianyu Zhang",
                    "L. M. Zhang",
                    "L. Q. Zhang",
                    "Lei Zhang",
                    "P. Zhang",
                    "Q. Y. Zhang",
                    "Shuihan Zhang",
                    "Shulei Zhang",
                    "X. D. Zhang",
                    "X. M. Zhang",
                    "X. Y. Zhang",
                    "Y. Zhang",
                    "Y. Zhang",
                    "Y. T. Zhang",
                    "Y. H. Zhang",
                    "Yan Zhang",
                    "Yao Zhang",
                    "Z. D. Zhang",
                    "Z. H. Zhang",
                    "Z. L. Zhang",
                    "Z. Y. Zhang",
                    "Z. Y. Zhang",
                    "G. Zhao",
                    "J. Y. Zhao",
                    "J. Z. Zhao",
                    "Lei Zhao",
                    "Ling Zhao",
                    "M. G. Zhao",
                    "R. P. Zhao",
                    "S. J. Zhao",
                    "Y. B. Zhao",
                    "Y. X. Zhao",
                    "Z. G. Zhao",
                    "Z. H. Zhao",
                    "A. Zhemchugov",
                    "B. Zheng",
                    "J. P. Zheng",
                    "W. J. Zheng",
                    "Y. H. Zheng",
                    "B. Zhong",
                    "X. Zhong",
                    "H. Zhou",
                    "L. P. Zhou",
                    "X. Zhou",
                    "X. K. Zhou",
                    "X. R. Zhou",
                    "X. Y. Zhou",
                    "Y. Z. Zhou",
                    "J. Zhu",
                    "K. Zhu",
                    "K. J. Zhu",
                    "L. Zhu",
                    "L. X. Zhu",
                    "S. H. Zhu",
                    "S. Q. Zhu",
                    "T. J. Zhu",
                    "W. J. Zhu",
                    "Y. C. Zhu",
                    "Z. A. Zhu",
                    "J. H. Zou",
                    "J. Zu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12895v1",
                    "http://arxiv.org/pdf/2311.12895v1"
                ],
                "primary_category": "hep-ex",
                "categories": [
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12420v3/1.0",
                "title": "How Far Have We Gone in Vulnerability Detection Using Large Language\n  Models",
                "year": 2023,
                "abstract": "As software becomes increasingly complex and prone to vulnerabilities,\nautomated vulnerability detection is critically important, yet challenging.\nGiven the significant successes of large language models (LLMs) in various\ntasks, there is growing anticipation of their efficacy in vulnerability\ndetection. However, a quantitative understanding of their potential in\nvulnerability detection is still missing. To bridge this gap, we introduce a\ncomprehensive vulnerability benchmark VulBench. This benchmark aggregates\nhigh-quality data from a wide range of CTF (Capture-the-Flag) challenges and\nreal-world applications, with annotations for each vulnerable function\ndetailing the vulnerability type and its root cause. Through our experiments\nencompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models\nand static analyzers, we find that several LLMs outperform traditional deep\nlearning approaches in vulnerability detection, revealing an untapped potential\nin LLMs. This work contributes to the understanding and utilization of LLMs for\nenhanced software security.",
                "authors": [
                    "Zeyu Gao",
                    "Hao Wang",
                    "Yuchen Zhou",
                    "Wenyu Zhu",
                    "Chao Zhang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12420v3",
                    "http://arxiv.org/pdf/2311.12420v3"
                ],
                "primary_category": "cs.AI",
                "categories": [
                    "cs.AI",
                    "cs.CL",
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12894v1/1.0",
                "title": "Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale\n  Fine-Grained Image Retrieval",
                "year": 2023,
                "abstract": "Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities' similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models' self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.",
                "authors": [
                    "Xiu-Shen Wei",
                    "Yang Shen",
                    "Xuhao Sun",
                    "Peng Wang",
                    "Yuxin Peng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12894v1",
                    "http://arxiv.org/pdf/2311.12894v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR",
                    "cs.CV",
                    "cs.LG",
                    "cs.MM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12418v1/1.0",
                "title": "Visual Analytics for Generative Transformer Models",
                "year": 2023,
                "abstract": "While transformer-based models have achieved state-of-the-art results in a\nvariety of classification and generation tasks, their black-box nature makes\nthem challenging for interpretability. In this work, we present a novel visual\nanalytical framework to support the analysis of transformer-based generative\nnetworks. In contrast to previous work, which has mainly focused on\nencoder-based models, our framework is one of the first dedicated to supporting\nthe analysis of transformer-based encoder-decoder models and decoder-only\nmodels for generative and classification tasks. Hence, we offer an intuitive\noverview that allows the user to explore different facets of the model through\ninteractive visualization. To demonstrate the feasibility and usefulness of our\nframework, we present three detailed case studies based on real-world NLP\nresearch problems.",
                "authors": [
                    "Raymond Li",
                    "Ruixin Yang",
                    "Wen Xiao",
                    "Ahmed AbuRaed",
                    "Gabriel Murray",
                    "Giuseppe Carenini"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12418v1",
                    "http://arxiv.org/pdf/2311.12418v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.HC"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12893v2/1.0",
                "title": "A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with\n  Dynamic Obstacle Trajectory Prediction and Its Application with LLMs",
                "year": 2023,
                "abstract": "For intelligent quadcopter UAVs, a robust and reliable autonomous planning\nsystem is crucial. Most current trajectory planning methods for UAVs are\nsuitable for static environments but struggle to handle dynamic obstacles,\nwhich can pose challenges and even dangers to flight. To address this issue,\nthis paper proposes a vision-based planning system that combines tracking and\ntrajectory prediction of dynamic obstacles to achieve efficient and reliable\nautonomous flight. We use a lightweight object detection algorithm to identify\ndynamic obstacles and then use Kalman Filtering to track and estimate their\nmotion states. During the planning phase, we not only consider static obstacles\nbut also account for the potential movements of dynamic obstacles. For\ntrajectory generation, we use a B-spline-based trajectory search algorithm,\nwhich is further optimized with various constraints to enhance safety and\nalignment with the UAV's motion characteristics. We conduct experiments in both\nsimulation and real-world environments, and the results indicate that our\napproach can successfully detect and avoid obstacles in dynamic environments in\nreal-time, offering greater reliability compared to existing approaches.\nFurthermore, with the advancements in Natural Language Processing (NLP)\ntechnology demonstrating exceptional zero-shot generalization capabilities,\nmore user-friendly human-machine interactions have become feasible, and this\nstudy also explores the integration of autonomous planning systems with Large\nLanguage Models (LLMs).",
                "authors": [
                    "Jiageng Zhong",
                    "Ming Li",
                    "Yinliang Chen",
                    "Zihang Wei",
                    "Fan Yang",
                    "Haoran Shen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12893v2",
                    "http://arxiv.org/pdf/2311.12893v2"
                ],
                "primary_category": "cs.RO",
                "categories": [
                    "cs.RO",
                    "cs.AI",
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12415v2/1.0",
                "title": "Data Dialogue with ChatGPT: Using Code Interpreter to Simulate and\n  Analyse Experimental Data",
                "year": 2023,
                "abstract": "Artificial Intelligence (AI) has the potential to fundamentally change the\neducational landscape. So far, much of the physics education research relating\nto AI has focused on lecture-based assessment and the ability of ChatGPT to\nanswer conceptual surveys and traditional exam-style questions. In this study,\nwe shift the focus by investigating ChatGPT's ability to complete an\nintroductory mechanics laboratory activity by using Code Interpreter, a recent\nplugin that allows users to generate and analyse data by writing and running\nPython code `behind the scenes'. By uploading a common `spring constant' lab\nactivity using Code Interpreter, we investigate the ability of ChatGPT to\ninterpret the activity, generate realistic model data, produce a line-fit, and\ncalculate the reduced chi square statistic. By analysing our interactions with\nChatGPT, along with the Python code generated by Code Interpreter, we assess\nhow the quality and accuracy of ChatGPT's responses depends on different levels\nof prompt detail. We find that although ChatGPT is capable of completing the\nlab activity and generating plausible-looking data, the quality of the output\nis highly dependent on the detail and specificity of the text prompts provided.\nWe find that the data generation process adopted by ChatGPT in this study leads\nto heteroscedasticity in the simulated data, which may be difficult for novice\nlearners to spot. We also find that when real experimental data is uploaded via\nCode Interpreter, ChatGPT is capable of correctly plotting and fitting the\ndata, calculating the spring constant and associated uncertainty, and\ncalculating the reduced chi square statistic. This work offers new insights\ninto the capabilities of Code Interpreter within a laboratory setting and\nhighlights a variety of text-prompt strategies for the effective use of Code\nInterpreter in a lab context.",
                "authors": [
                    "Andrew Low",
                    "Z. Yasemin Kalender"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12415v2",
                    "http://arxiv.org/pdf/2311.12415v2"
                ],
                "primary_category": "physics.ed-ph",
                "categories": [
                    "physics.ed-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12414v3/1.0",
                "title": "Local resetting in non-conserving zero-range processes with extensive\n  rates",
                "year": 2023,
                "abstract": "A non-conserving zero-range process with extensive creation, annihilation and\nhopping rates is subjected to local resetting. The model is formulated on a\nlarge, fully-connected network of states. The states are equipped with a\n(bounded) fitness level: particles are added to each state at a rate\nproportional to the fitness level of the state. Moreover, particles are\nannihilated at a constant rate, and hop at a fixed rate to a uniformly-drawn\nstate in the network. This model has been interpreted in terms of population\ndynamics: the fitness is the reproductive fitness in a haploid population, and\nthe hopping process models mutation. It has also been interpreted as a model of\nnetwork growth with a fixed set of nodes (in which particles occupying a state\nare interpreted as links pointing to this state). In the absence of resetting,\nthe model is known to reach a steady state, which in a certain limit may\nexhibit a condensate at maximum fitness. If the model is subjected to global\nresetting by annihilating all particles at Poisson-distributed times, there is\nno condensation in the steady state. If the system is subjected to local\nresetting, the occupation numbers of each state are reset to zero at\nindependent random times. These times are distributed according to a Poisson\nprocess whose rate (the resetting rate) depends on the fitness. We derive the\nevolution equation satisfied by the probability law of the occupation numbers.\nWe calculate the average occupation numbers in the steady state. The existence\nof a condensate is found to depend on the local behavior of the resetting rate\nat maximum fitness: if the resetting rate vanishes at least linearly at high\nfitness, a condensate appears at maximum fitness in the limit where the sum of\nthe annihilation and hopping rates is equal to the maximum fitness.",
                "authors": [
                    "Pascal Grange"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12414v3",
                    "http://arxiv.org/pdf/2311.12414v3"
                ],
                "primary_category": "cond-mat.stat-mech",
                "categories": [
                    "cond-mat.stat-mech"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12412v1/1.0",
                "title": "Data reduction strategy in the PandaX-4T experiment",
                "year": 2023,
                "abstract": "The PandaX-4T experiment is designed for multiple purposes, including\nsearches for solar neutrinos, weakly interacting massive particles, and rare\ndouble beta decays of xenon isotopes. The experiment produces a huge amount of\nraw data that needs to be stored for related physical analyses in a wide energy\nrange. With the upgrading of the PandaX-4T experiment, the doubled sampling\nrate resulted in a larger data size, which challenges both the cost and the\ndata processing speed. To address this issue, we propose a data reduction\nstrategy by removing the noise tail of large signals and downsampling the\nremaining parts of them. This strategy reduces the requirement for storage by\n65% while increasing data processing speed. The influences on physical analyses\non different topics at different energy regions are negligible.",
                "authors": [
                    "Yubo Zhou",
                    "Xun Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12412v1",
                    "http://arxiv.org/pdf/2311.12412v1"
                ],
                "primary_category": "physics.data-an",
                "categories": [
                    "physics.data-an",
                    "hep-ex"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12411v1/1.0",
                "title": "Quantum Simulations for Carbon Capture on Metal-Organic Frameworks",
                "year": 2023,
                "abstract": "Direct air capture of Carbon Dioxide is a technical solution that does not\nrely on natural processes to capture CO2 from the atmosphere. In DAC, the\nfilter material is designed to specifically bind CO2 molecules. Hence a\nhigh-capacity filter is sought. We aim to leverage the potential of quantum\ncomputing to improve the filters used in DAC. Metal-Organic Frameworks (MOFs)\nhave high surface area and tunable pore sizes which makes them an attractive\nmaterial for gas storage and separation. Using the variational quantum\neigensolver (VQE) algorithm, we find the minimum of the potential energy\nsurface (PES) by first considering only the active site of the MOF (the metal\nion). For complex systems, we employ Density Matrix Embedding Theory and use\nVQE as a fragment solver at the binding site. Techniques like\ndeparameterisation are used to minimise the count of trainable parameters. We\npresent results of ideal and noisy simulations as well as from a real hardware\ndevice. Resources are estimated for MOFs unit cell. The findings from our study\ndemonstrates the potential of quantum computing to effectively perform quantum\nsimulations of strongly correlated fragments.",
                "authors": [
                    "Gopal Ramesh Dahale"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12411v1",
                    "http://arxiv.org/pdf/2311.12411v1"
                ],
                "primary_category": "quant-ph",
                "categories": [
                    "quant-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12410v1/1.0",
                "title": "nach0: Multimodal Natural and Chemical Languages Foundation Model",
                "year": 2023,
                "abstract": "Large Language Models (LLMs) have substantially driven scientific progress in\nvarious domains, and many papers have demonstrated their ability to tackle\ncomplex problems with creative solutions. Our paper introduces a new foundation\nmodel, nach0, capable of solving various chemical and biological tasks:\nbiomedical question answering, named entity recognition, molecular generation,\nmolecular synthesis, attributes prediction, and others. nach0 is a multi-domain\nand multi-task encoder-decoder LLM pre-trained on unlabeled text from\nscientific literature, patents, and molecule strings to incorporate a range of\nchemical and linguistic knowledge. We employed instruction tuning, where\nspecific task-related instructions are utilized to fine-tune nach0 for the\nfinal set of tasks. To train nach0 effectively, we leverage the NeMo framework,\nenabling efficient parallel optimization of both base and large model versions.\nExtensive experiments demonstrate that our model outperforms state-of-the-art\nbaselines on single-domain and cross-domain tasks. Furthermore, it can generate\nhigh-quality outputs in molecular and textual formats, showcasing its\neffectiveness in multi-domain setups.",
                "authors": [
                    "Micha Livne",
                    "Zulfat Miftahutdinov",
                    "Elena Tutubalina",
                    "Maksim Kuznetsov",
                    "Daniil Polykovskiy",
                    "Annika Brundyn",
                    "Aastha Jhunjhunwala",
                    "Anthony Costa",
                    "Alex Aliper",
                    "Alex Zhavoronkov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12410v1",
                    "http://arxiv.org/pdf/2311.12410v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI",
                    "cs.LG",
                    "q-bio.QM"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12409v1/1.0",
                "title": "Note on Granda-Oliveros Holographic Dark Energy",
                "year": 2023,
                "abstract": "This article revisits Granda-Oliveros holographic dark energy (GOHDE) model,\nexplores the features of the parameter space and shows that its ability to\nexplain the late-time acceleration is only due to the integration constant that\nappears by construction. We show that the GOHDE behaves like the dominant\nenergy component and naturally behaves like dark energy in the late phase. In\nthe matter-dominated period, it acts like pressureless matter and exhibits\nradiation-like behaviour in the very early stages. Adjusting the free\nparameters could subdue or enhance these characteristics. Depending on the\nparameters, GOHDE can act similarly to concordance, phantom or\nquintessence-like dark energies with singular equation of states. From the\npoint of local observations, we show that the GOHDE model is observationally\nindistinguishable from $w$CDM and encompasses $\\Lambda$CDM as a specific case.\nOur analysis reveals that while a departure from $\\Lambda$CDM could account for\nlate-time acceleration, it falls short of a consistent description of the\nentire cosmic history. Furthermore, we utilize various datasets, including OHD,\nPantheon, CMB Shift parameter, BAO, and QSO, to constrain the free parameters\nof the GOHDE model. Our analysis indicates that the best fit, assuming the GO\ncut-off, aligns with the $\\Lambda$CDM model. Additionally, we use statistical\nquantifiers such as AIC, BIC, and $\\chi^2$ to test the model's goodness with\nvarious data combinations and estimate the Bayes factor to contrast the models.\nOur study suggests that the standard GOHDE model is equally likely as the\n$\\Lambda$CDM model, ultimately favouring the latter, with\n$\\beta=0.686^{+0.048}_{-0.044}$ and $w{z_0}=-0.988^{+0.042}_{-0.044}$. Given\nthe current observations, we conclude that, for a flat universe, the\n$\\Lambda$CDM case is statistically the best and probably the only consistent\nsolution from the GOHDE construction.",
                "authors": [
                    "Manosh T. Manoharan"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12409v1",
                    "http://arxiv.org/pdf/2311.12409v1"
                ],
                "primary_category": "astro-ph.CO",
                "categories": [
                    "astro-ph.CO",
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12405v1/1.0",
                "title": "IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian\n  Local Languages",
                "year": 2023,
                "abstract": "Significant progress has been made on Indonesian NLP. Nevertheless,\nexploration of the code-mixing phenomenon in Indonesian is limited, despite\nmany languages being frequently mixed with Indonesian in daily conversation. In\nthis work, we explore code-mixing in Indonesian with four embedded languages,\ni.e., English, Sundanese, Javanese, and Malay; and introduce IndoRobusta, a\nframework to evaluate and improve the code-mixing robustness. Our analysis\nshows that the pre-training corpus bias affects the model's ability to better\nhandle Indonesian-English code-mixing when compared to other local languages,\ndespite having higher language diversity.",
                "authors": [
                    "Muhammad Farid Adilazuarda",
                    "Samuel Cahyawijaya",
                    "Genta Indra Winata",
                    "Pascale Fung",
                    "Ayu Purwarianti"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12405v1",
                    "http://arxiv.org/pdf/2311.12405v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12404v1/1.0",
                "title": "InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk\n  Factors in Reddit Posts",
                "year": 2023,
                "abstract": "Mental health professionals and clinicians have observed the upsurge of\nmental disorders due to Interpersonal Risk Factors (IRFs). To simulate the\nhuman-in-the-loop triaging scenario for early detection of mental health\ndisorders, we recognized textual indications to ascertain these IRFs : Thwarted\nBelongingness (TBe) and Perceived Burdensomeness (PBu) within personal\nnarratives. In light of this, we use N-shot learning with GPT-3 model on the\nIRF dataset, and underscored the importance of fine-tuning GPT-3 model to\nincorporate the context-specific sensitivity and the interconnectedness of\ntextual cues that represent both IRFs.\n  In this paper, we introduce an Interpretable Prompting (InterPrompt)} method\nto boost the attention mechanism by fine-tuning the GPT-3 model. This allows a\nmore sophisticated level of language modification by adjusting the pre-trained\nweights. Our model learns to detect usual patterns and underlying connections\nacross both the IRFs, which leads to better system-level explainability and\ntrustworthiness. The results of our research demonstrate that all four variants\nof GPT-3 model, when fine-tuned with InterPrompt, perform considerably better\nas compared to the baseline methods, both in terms of classification and\nexplanation generation.",
                "authors": [
                    "MSVPJ Sathvik",
                    "Surjodeep Sarkar",
                    "Chandni Saxena",
                    "Sunghwan Sohn",
                    "Muskan Garg"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12404v1",
                    "http://arxiv.org/pdf/2311.12404v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12892v1/1.0",
                "title": "IMJENSE: Scan-specific Implicit Representation for Joint Coil\n  Sensitivity and Image Estimation in Parallel MRI",
                "year": 2023,
                "abstract": "Parallel imaging is a commonly used technique to accelerate magnetic\nresonance imaging (MRI) data acquisition. Mathematically, parallel MRI\nreconstruction can be formulated as an inverse problem relating the sparsely\nsampled k-space measurements to the desired MRI image. Despite the success of\nmany existing reconstruction algorithms, it remains a challenge to reliably\nreconstruct a high-quality image from highly reduced k-space measurements.\nRecently, implicit neural representation has emerged as a powerful paradigm to\nexploit the internal information and the physics of partially acquired data to\ngenerate the desired object. In this study, we introduced IMJENSE, a\nscan-specific implicit neural representation-based method for improving\nparallel MRI reconstruction. Specifically, the underlying MRI image and coil\nsensitivities were modeled as continuous functions of spatial coordinates,\nparameterized by neural networks and polynomials, respectively. The weights in\nthe networks and coefficients in the polynomials were simultaneously learned\ndirectly from sparsely acquired k-space measurements, without fully sampled\nground truth data for training. Benefiting from the powerful continuous\nrepresentation and joint estimation of the MRI image and coil sensitivities,\nIMJENSE outperforms conventional image or k-space domain reconstruction\nalgorithms. With extremely limited calibration data, IMJENSE is more stable\nthan supervised calibrationless and calibration-based deep-learning methods.\nResults show that IMJENSE robustly reconstructs the images acquired at\n5$\\mathbf{\\times}$ and 6$\\mathbf{\\times}$ accelerations with only 4 or 8\ncalibration lines in 2D Cartesian acquisitions, corresponding to 22.0% and\n19.5% undersampling rates. The high-quality results and scanning specificity\nmake the proposed method hold the potential for further accelerating the data\nacquisition of parallel MRI.",
                "authors": [
                    "Ruimin Feng",
                    "Qing Wu",
                    "Jie Feng",
                    "Huajun She",
                    "Chunlei Liu",
                    "Yuyao Zhang",
                    "Hongjiang Wei"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12892v1",
                    "http://arxiv.org/pdf/2311.12892v1"
                ],
                "primary_category": "eess.IV",
                "categories": [
                    "eess.IV",
                    "cs.CV",
                    "cs.LG",
                    "physics.med-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12399v2/1.0",
                "title": "A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions",
                "year": 2023,
                "abstract": "Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.",
                "authors": [
                    "Yuhan Li",
                    "Zhixun Li",
                    "Peisong Wang",
                    "Jia Li",
                    "Xiangguo Sun",
                    "Hong Cheng",
                    "Jeffrey Xu Yu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12399v2",
                    "http://arxiv.org/pdf/2311.12399v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.CL",
                    "cs.SI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12395v1/1.0",
                "title": "Problems of Non-equivalent Words in Technical Translation",
                "year": 2023,
                "abstract": "Translating words which do not have equivalent in target language is not easy\nand finding proper equivalent of those words are very important to render\ncorrectly and understandably, the article defines some thoughts and ideas of\nscientists on the common problems of non-equivalent words from English to\nRussian language and includes English and Russian examples and ideas of certain\nscientist. The English language is worldwide spoken and there are 1.35 billion\nEnglish speakers and over 258 million Russian speakers according to the 2021s\nstatistics. Inevitably, these billions of speakers around the world have\nconnection and they may have deal in different criteria. In order to understand\none another they need to have a pure and fully-understood language. These pure\nlanguages understanding directly relates to translation knowledge where\nlinguists and translators need to work and research to eradicate\nmisunderstanding. Misunderstandings mostly appear in non-equivalent words\nbecause there are different local and internal words like food, garment,\ncultural and traditional words and others in every notion. Truly, most of these\nwords do not have equivalent in the target language and these words need to be\nworked and find their equivalent in the target language to fully understand the\nboth languages. However, some of these non-equivalent words are already\nprofessionally rendered to the target language but still there many other words\nto be rendered. Hence, this research paper includes different ways and rules of\nrendering non-equivalent words from source language to the target language.",
                "authors": [
                    "Mohammad Ibrahim Qani"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12395v1",
                    "http://arxiv.org/pdf/2311.12395v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12393v1/1.0",
                "title": "Thin accretion disk images of rotating hairy Horndeski black holes",
                "year": 2023,
                "abstract": "By considering the steady-state Novikov-Thorne model, we study thin accretion\ndisk processes for rotating hairy black holes in the framework of the Horndeski\ngravity. We obtain the electromagnetic properties of accretion disk around such\nblack holes and investigate the effects of the hair parameter $h$ on them. We\nfind that by increasing the hair parameter from the Kerr limit,\n$h\\rightarrow0$, the radius of the innermost stable circular orbit decreases\nwhich makes thin accretion disks around rotating hairy black holes in Horndeski\ngravity more efficient than that for the Kerr black hole in general relativity.\nFurthermore, using the numerical ray-tracing method, we plot thin accretion\ndisk images around these black holes and investigate the effects of hair\nparameter on the central shadow area of accretion disk.",
                "authors": [
                    "Mohaddese Heydari-Fard",
                    "Malihe Heydari-Fard",
                    "Nematollah Riazi"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12393v1",
                    "http://arxiv.org/pdf/2311.12393v1"
                ],
                "primary_category": "gr-qc",
                "categories": [
                    "gr-qc"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12391v1/1.0",
                "title": "From Wrong To Right: A Recursive Approach Towards Vision-Language\n  Explanation",
                "year": 2023,
                "abstract": "Addressing the challenge of adapting pre-trained vision-language models for\ngenerating insightful explanations for visual reasoning tasks with limited\nannotations, we present ReVisE: a $\\textbf{Re}$cursive $\\textbf{Vis}$ual\n$\\textbf{E}$xplanation algorithm. Our method iteratively computes visual\nfeatures (conditioned on the text input), an answer, and an explanation, to\nimprove the explanation quality step by step until the answer converges. We\nfind that this multi-step approach guides the model to correct its own answers\nand outperforms single-step explanation generation. Furthermore, explanations\ngenerated by ReVisE also serve as valuable annotations for few-shot\nself-training. Our approach outperforms previous methods while utilizing merely\n5% of the human-annotated explanations across 10 metrics, demonstrating up to a\n4.2 and 1.3 increase in BLEU-1 score on the VCR and VQA-X datasets,\nunderscoring the efficacy and data-efficiency of our method.",
                "authors": [
                    "Jiaxin Ge",
                    "Sanjay Subramanian",
                    "Trevor Darrell",
                    "Boyi Li"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12391v1",
                    "http://arxiv.org/pdf/2311.12391v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12390v1/1.0",
                "title": "A Hybrid Frame Structure Design of OTFS for Multi-tasks Communications",
                "year": 2023,
                "abstract": "Orthogonal time frequency space (OTFS) is a promising waveform in high\nmobility scenarios for it fully exploits the time-frequency diversity using a\ndiscrete Fourier transform (DFT) based two dimensional spreading. However, it\ntrades off the processing latency for performance and may not fulfill the\nstringent latency requirements in some services. This fact motivates us to\ndesign a hybrid frame structure where the OTFS and Orthogonal Frequency\nDivision Multiplexing (OFDM) are orthogonally multiplexed in the time domain,\nwhich can adapt to both diversity-preferred and latency-preferred tasks. As we\nidentify that this orthogonality is disrupted after channel coupling, we\nprovide practical algorithms to mitigate the inter symbol interference between\n(ISI) the OTFS and OFDM, and the numerical results ensure the effectiveness of\nthe hybrid frame structure.",
                "authors": [
                    "Pu Yuan",
                    "Jin Liu",
                    "Dajie Jiang",
                    "Fei Qin"
                ],
                "url": [
                    "http://dx.doi.org/10.1109/pimrc56721.2023.10293840",
                    "http://arxiv.org/abs/2311.12390v1",
                    "http://arxiv.org/pdf/2311.12390v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12389v1/1.0",
                "title": "Linear-time online visibility graph transformation algorithm: for both\n  natural and horizontal visibility criteria",
                "year": 2023,
                "abstract": "Visibility graph (VG) transformation is a technique used to convert a time\nseries into a graph based on specific visibility criteria. It has attracted\nincreasing interest in the fields of time series analysis, forecasting, and\nclassification. Optimizing the VG transformation algorithm to accelerate the\nprocess is a critical aspect of VG-related research, as it enhances the\napplicability of VG transformation in latency-sensitive areas and conserves\ncomputational resources. In the real world, many time series are presented in\nthe form of data streams. Despite the proposal of the concept of VG's online\nfunctionality, previous studies have not thoroughly explored the acceleration\nof VG transformation by leveraging the characteristics of data streams. In this\npaper, we propose that an efficient online VG algorithm should adhere to two\ncriteria and develop a linear-time method, termed the LOT framework, for both\nnatural and horizontal visibility graph transformations in data stream\nscenarios. Experiments are conducted on two datasets, comparing our approach\nwith five existing methods as baselines. The results demonstrate the validity\nand promising computational efficiency of our framework.",
                "authors": [
                    "Yusheng Huang",
                    "Yong Deng"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12389v1",
                    "http://arxiv.org/pdf/2311.12389v1"
                ],
                "primary_category": "cs.DS",
                "categories": [
                    "cs.DS",
                    "cs.IR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12379v2/1.0",
                "title": "Infinite forecast combinations based on Dirichlet process",
                "year": 2023,
                "abstract": "Forecast combination integrates information from various sources by\nconsolidating multiple forecast results from the target time series. Instead of\nthe need to select a single optimal forecasting model, this paper introduces a\ndeep learning ensemble forecasting model based on the Dirichlet process.\nInitially, the learning rate is sampled with three basis distributions as\nhyperparameters to convert the infinite mixture into a finite one. All\ncheckpoints are collected to establish a deep learning sub-model pool, and\nweight adjustment and diversity strategies are developed during the combination\nprocess. The main advantage of this method is its ability to generate the\nrequired base learners through a single training process, utilizing the\ndecaying strategy to tackle the challenge posed by the stochastic nature of\ngradient descent in determining the optimal learning rate. To ensure the\nmethod's generalizability and competitiveness, this paper conducts an empirical\nanalysis using the weekly dataset from the M4 competition and explores\nsensitivity to the number of models to be combined. The results demonstrate\nthat the ensemble model proposed offers substantial improvements in prediction\naccuracy and stability compared to a single benchmark model.",
                "authors": [
                    "Yinuo Ren",
                    "Feng Li",
                    "Yanfei Kang",
                    "Jue Wang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12379v2",
                    "http://arxiv.org/pdf/2311.12379v2"
                ],
                "primary_category": "cs.LG",
                "categories": [
                    "cs.LG",
                    "cs.AI",
                    "stat.ML"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.08304v1/1.0",
                "title": "Interpretable ECG Analysis for Myocardial Infarction Detection through\n  Counterfactuals",
                "year": 2023,
                "abstract": "Despite the surge in deep learning for ECG signal analysis, its black-box\nnature remains a barrier in clinical decision-making. Interpretable machine\nlearning models are less resource-intensive and more transparent for\nclinicians, to enhance diagnostic processes. The primary aim of this study is\nto explore the usability and potential benefits of counterfactual explanations\nin interpreting machine learning models trained on ECG signals, particularly\nfor distinguishing between control group subjects and myocardial infarction\npatients. To achieve our goal, we leveraged the PTB-XL dataset and developed a\nsystematic feature extraction methodology. Subsequently, our method entailed\nidentifying the most significant ECG features via a thorough ranking and\nelimination process, refining the feature set for further counterfactual\nevaluation. Furthermore, we introduced the Visualizing Counterfactual Clues on\nElectrocardiograms (VCCE) method to enhance the practical usability of\ncounterfactual explanations. The authenticity of the generated counterfactuals\nwas validated through custom metrics, including cognitive assessments of\ndiagnostic clues present in the ECG report, with the clinical expertise of two\ncardiologists. Our research indicates great potential for future studies in\nidentifying patient outcomes for cardiac conditions using ECGs, with high and\nmoderate-quality interpretation validity scores of 23.29 $\\pm$ 1.04 and 20.28\n$\\pm$ 0.99 out of 25, respectively. Clinical alignment scores of 0.83 $\\pm$\n0.12 for high-quality and 0.57 $\\pm$ 0.10 for moderate-quality interpretations\nfurther validate the strong link between our analysis and clinical evaluations.\nThe source code for this study can be accessed at\nhttps://github.com/tanyelai/vcce.",
                "authors": [
                    "Toygar Tanyel",
                    "Sezgin Atmaca",
                    "Kaan G\u00f6k\u00e7e",
                    "M. Yi\u011fit Bal\u0131k",
                    "Arda G\u00fcler",
                    "Emre Aslanger",
                    "\u0130lkay \u00d6ks\u00fcz"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.08304v1",
                    "http://arxiv.org/pdf/2312.08304v1"
                ],
                "primary_category": "eess.SP",
                "categories": [
                    "eess.SP",
                    "J.3"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12375v1/1.0",
                "title": "The Obscure Limitation of Modular Multilingual Language Models",
                "year": 2023,
                "abstract": "We expose the limitation of modular multilingual language models (MLMs) in\nmultilingual inference scenarios with unknown languages. Existing evaluations\nof modular MLMs exclude the involvement of language identification (LID)\nmodules, which obscures the performance of real-case multilingual scenarios of\nmodular MLMs. In this work, we showcase the effect of adding LID on the\nmultilingual evaluation of modular MLMs and provide discussions for closing the\nperformance gap of caused by the pipelined approach of LID and modular MLMs.",
                "authors": [
                    "Muhammad Farid Adilazuarda",
                    "Samuel Cahyawijaya",
                    "Ayu Purwarianti"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12375v1",
                    "http://arxiv.org/pdf/2311.12375v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12891v1/1.0",
                "title": "Text-Guided Texturing by Synchronized Multi-View Diffusion",
                "year": 2023,
                "abstract": "This paper introduces a novel approach to synthesize texture to dress up a\ngiven 3D object, given a text prompt. Based on the pretrained text-to-image\n(T2I) diffusion model, existing methods usually employ a project-and-inpaint\napproach, in which a view of the given object is first generated and warped to\nanother view for inpainting. But it tends to generate inconsistent texture due\nto the asynchronous diffusion of multiple views. We believe such asynchronous\ndiffusion and insufficient information sharing among views are the root causes\nof the inconsistent artifact. In this paper, we propose a synchronized\nmulti-view diffusion approach that allows the diffusion processes from\ndifferent views to reach a consensus of the generated content early in the\nprocess, and hence ensures the texture consistency. To synchronize the\ndiffusion, we share the denoised content among different views in each\ndenoising step, specifically blending the latent content in the texture domain\nfrom views with overlap. Our method demonstrates superior performance in\ngenerating consistent, seamless, highly detailed textures, comparing to\nstate-of-the-art methods.",
                "authors": [
                    "Yuxin Liu",
                    "Minshan Xie",
                    "Hanyuan Liu",
                    "Tien-Tsin Wong"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12891v1",
                    "http://arxiv.org/pdf/2311.12891v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12890v2/1.0",
                "title": "De-fine: Decomposing and Refining Visual Programs with Auto-Feedback",
                "year": 2023,
                "abstract": "Visual programming, a modular and generalizable paradigm, integrates\ndifferent modules and Python operators to solve various vision-language tasks.\nUnlike end-to-end models that need task-specific data, it advances in\nperforming visual processing and reasoning in an unsupervised manner. Current\nvisual programming methods generate programs in a single pass for each task\nwhere the ability to evaluate and optimize based on feedback, unfortunately, is\nlacking, which consequentially limits their effectiveness for complex,\nmulti-step problems. Drawing inspiration from benders decomposition, we\nintroduce De-fine, a general framework that automatically decomposes complex\ntasks into simpler subtasks and refines programs through auto-feedback. This\nmodel-agnostic approach can improve logical reasoning performance by\nintegrating the strengths of multiple models. Our experiments across various\nvisual tasks show that De-fine creates more accurate and robust programs,\nsetting new benchmarks in the field.",
                "authors": [
                    "Minghe Gao",
                    "Juncheng Li",
                    "Hao Fei",
                    "Liang Pang",
                    "Wei Ji",
                    "Guoming Wang",
                    "Wenqiao Zhang",
                    "Siliang Tang",
                    "Yueting Zhuang"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12890v2",
                    "http://arxiv.org/pdf/2311.12890v2"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12373v1/1.0",
                "title": "Beyond Turing: A Comparative Analysis of Approaches for Detecting\n  Machine-Generated Text",
                "year": 2023,
                "abstract": "Significant progress has been made on text generation by pre-trained language\nmodels (PLMs), yet distinguishing between human and machine-generated text\nposes an escalating challenge. This paper offers an in-depth evaluation of\nthree distinct methods used to address this task: traditional shallow learning,\nLanguage Model (LM) fine-tuning, and Multilingual Model fine-tuning. These\napproaches are rigorously tested on a wide range of machine-generated texts,\nproviding a benchmark of their competence in distinguishing between\nhuman-authored and machine-authored linguistic constructs. The results reveal\nconsiderable differences in performance across methods, thus emphasizing the\ncontinued need for advancement in this crucial area of NLP. This study offers\nvaluable insights and paves the way for future research aimed at creating\nrobust and highly discriminative models.",
                "authors": [
                    "Muhammad Farid Adilazuarda",
                    "Nikolaos Nektarios Arkoulis",
                    "Oleksii Chumakov"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12373v1",
                    "http://arxiv.org/pdf/2311.12373v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12372v1/1.0",
                "title": "Malicious URL Detection via Pretrained Language Model Guided Multi-Level\n  Feature Attention Network",
                "year": 2023,
                "abstract": "The widespread use of the Internet has revolutionized information retrieval\nmethods. However, this transformation has also given rise to a significant\ncybersecurity challenge: the rapid proliferation of malicious URLs, which serve\nas entry points for a wide range of cyber threats. In this study, we present an\nefficient pre-training model-based framework for malicious URL detection.\nLeveraging the subword and character-aware pre-trained model, CharBERT, as our\nfoundation, we further develop three key modules: hierarchical feature\nextraction, layer-aware attention, and spatial pyramid pooling. The\nhierarchical feature extraction module follows the pyramid feature learning\nprinciple, extracting multi-level URL embeddings from the different Transformer\nlayers of CharBERT. Subsequently, the layer-aware attention module autonomously\nlearns connections among features at various hierarchical levels and allocates\nvarying weight coefficients to each level of features. Finally, the spatial\npyramid pooling module performs multiscale downsampling on the weighted\nmulti-level feature pyramid, achieving the capture of local features as well as\nthe aggregation of global features. The proposed method has been extensively\nvalidated on multiple public datasets, demonstrating a significant improvement\nover prior works, with the maximum accuracy gap reaching 8.43% compared to the\nprevious state-of-the-art method. Additionally, we have assessed the model's\ngeneralization and robustness in scenarios such as cross-dataset evaluation and\nadversarial attacks. Finally, we conducted real-world case studies on the\nactive phishing URLs.",
                "authors": [
                    "Ruitong Liu",
                    "Yanbin Wang",
                    "Haitao Xu",
                    "Zhan Qin",
                    "Yiwei Liu",
                    "Zheng Cao"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12372v1",
                    "http://arxiv.org/pdf/2311.12372v1"
                ],
                "primary_category": "cs.CR",
                "categories": [
                    "cs.CR"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12371v2/1.0",
                "title": "AudioLog: LLMs-Powered Long Audio Logging with Hybrid Token-Semantic\n  Contrastive Learning",
                "year": 2023,
                "abstract": "Previous studies in automated audio captioning have faced difficulties in\naccurately capturing the complete temporal details of acoustic scenes and\nevents within long audio sequences. This paper presents AudioLog, a large\nlanguage models (LLMs)-powered audio logging system with hybrid token-semantic\ncontrastive learning. Specifically, we propose to fine-tune the pre-trained\nhierarchical token-semantic audio Transformer by incorporating contrastive\nlearning between hybrid acoustic representations. We then leverage LLMs to\ngenerate audio logs that summarize textual descriptions of the acoustic\nenvironment. Finally, we evaluate the AudioLog system on two datasets with both\nscene and event annotations. Experiments show that the proposed system achieves\nexceptional performance in acoustic scene classification and sound event\ndetection, surpassing existing methods in the field. Further analysis of the\nprompts to LLMs demonstrates that AudioLog can effectively summarize long audio\nsequences. To the best of our knowledge, this approach is the first attempt to\nleverage LLMs for summarizing long audio sequences.",
                "authors": [
                    "Jisheng Bai",
                    "Han Yin",
                    "Mou Wang",
                    "Dongyuan Shi",
                    "Woon-Seng Gan",
                    "Jianfeng Chen",
                    "Susanto Rahardja"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12371v2",
                    "http://arxiv.org/pdf/2311.12371v2"
                ],
                "primary_category": "eess.AS",
                "categories": [
                    "eess.AS"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12369v1/1.0",
                "title": "The Rapid ASKAP Continuum Survey V: cataloguing the sky at 1367.5 MHz\n  and the second data release of RACS-mid",
                "year": 2023,
                "abstract": "The Australian SKA Pathfinder (ASKAP) has surveyed the sky at multiple\nfrequencies as part of the Rapid ASKAP Continuum Survey (RACS). The first two\nRACS observing epochs, at 887.5 (RACS-low) and 1367.5 (RACS-mid) MHz, have been\nreleased (McConnell et al., 2020; Duchesne et al., 2023). A catalogue of radio\nsources from RACS-low has also been released, covering the sky south of\ndeclination +30$^\\circ$ (Hale et al., 2021). With this paper, we describe and\nrelease the first set of catalogues from RACS-mid, covering the sky below\ndeclination +49$^\\circ$. The catalogues are created in a similar manner to the\nRACS-low catalogue, and we discuss this process and highlight additional\nchanges. The general purpose primary catalogue covering 36 200 deg$^2$ features\na variable angular resolution to maximise sensitivity and sky coverage across\nthe catalogued area, with a median angular resolution of 11.2\" times 9.3\". The\nprimary catalogue comprises 3 105 668 radio sources, including those in the\nGalactic Plane (2 861 923 excluding Galactic latitudes of $|b|<5^\\circ$) and we\nestimate the catalogue to be 95% complete for sources above 1.6 mJy. With the\nprimary catalogue, we also provide two auxiliary catalogues. The first is a\nfixed-resolution, 25-arcsec catalogue approximately matching the sky coverage\nof the RACS-low catalogue. This 25-arcsec catalogue is constructed identically\nto the primary catalogue, except images are convolved to a less-sensitive\n25-arcsec angular resolution. The second auxiliary catalogue is designed for\ntime-domain science, and is the concatenation of source-lists from the original\nRACS-mid images with no additional convolution, mosaicking, or de-duplication\nof source entries to avoid losing time-variable signals. All three RACS-mid\ncatalogues, and all RACS data products, are available through the CSIRO ASKAP\nScience Data Archive (CASDA).",
                "authors": [
                    "S. W. Duchesne",
                    "J. A. Grundy",
                    "George H. Heald",
                    "Emil Lenc",
                    "James K. Leung",
                    "David McConnell",
                    "Tara Murphy",
                    "Joshua Pritchard",
                    "Kovi Rose",
                    "Alec J. M. Thomson",
                    "Yuanming Wang",
                    "Ziteng Wang",
                    "Matthew T. Whiting"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12369v1",
                    "http://arxiv.org/pdf/2311.12369v1"
                ],
                "primary_category": "astro-ph.GA",
                "categories": [
                    "astro-ph.GA",
                    "astro-ph.CO"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12889v1/1.0",
                "title": "Enhancing Scene Graph Generation with Hierarchical Relationships and\n  Commonsense Knowledge",
                "year": 2023,
                "abstract": "This work presents an enhanced approach to generating scene graphs by\nincorporating a relationship hierarchy and commonsense knowledge. Specifically,\nwe propose a Bayesian classification head that exploits an informative\nhierarchical structure. It jointly predicts the super-category or type of\nrelationship between the two objects, along with the detailed relationship\nunder each super-category. We design a commonsense validation pipeline that\nuses a large language model to critique the results from the scene graph\nprediction system and then use that feedback to enhance the model performance.\nThe system requires no external large language model assistance at test time,\nmaking it more convenient for practical applications. Experiments on the Visual\nGenome and the OpenImage V6 datasets demonstrate that harnessing hierarchical\nrelationships enhances the model performance by a large margin. The proposed\nBayesian head can also be incorporated as a portable module in existing scene\ngraph generation algorithms to improve their results. In addition, the\ncommonsense validation enables the model to generate an extensive set of\nreasonable predictions beyond dataset annotations.",
                "authors": [
                    "Bowen Jiang",
                    "Zhijun Zhuang",
                    "Camillo Jose Taylor"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12889v1",
                    "http://arxiv.org/pdf/2311.12889v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12355v1/1.0",
                "title": "Utilizing Language Models for Tour Itinerary Recommendation",
                "year": 2023,
                "abstract": "Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.",
                "authors": [
                    "Ngai Lam Ho",
                    "Kwan Hui Lim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12355v1",
                    "http://arxiv.org/pdf/2311.12355v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR",
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12353v1/1.0",
                "title": "Hierarchical Framework for Predicting Entropies in Bottom-Up\n  Coarse-Grained Models",
                "year": 2023,
                "abstract": "The thermodynamic entropy of coarse-grained (CG) models stands as one of the\nmost important properties for quantifying the missing information during the CG\nprocess and for establishing transferable (or extendible) CG interactions.\nHowever, performing additional CG simulations on top of model construction\noften leads to significant additional computational overhead. In this work, we\npropose a simple hierarchical framework for predicting the thermodynamic\nentropies of various molecular CG systems. Our approach employs a decomposition\nof the CG interactions, enabling the estimation of the CG partition function\nand thermodynamic properties a priori. Starting from the ideal gas description,\nwe leverage classical perturbation theory to systematically incorporate simple\nyet essential interactions, ranging from the hard sphere model to the\ngeneralized van der Waals model. Additionally, we propose an alternative\napproach based on multiparticle correlation functions, allowing for systematic\nimprovements through higher-order correlations. Numerical applications to\nmolecular liquids validate the high fidelity of our approach, and our\ncomputational protocols demonstrate that a reduced model with simple energetics\ncan reasonably estimate the thermodynamic entropy of CG models without\nperforming any CG simulations. Overall, our findings present a systematic\nframework for estimating not only the entropy but also other thermodynamic\nproperties of CG models, relying solely on information from the reference\nsystem.",
                "authors": [
                    "Jaehyeok Jin",
                    "David R. Reichman"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12353v1",
                    "http://arxiv.org/pdf/2311.12353v1"
                ],
                "primary_category": "physics.chem-ph",
                "categories": [
                    "physics.chem-ph",
                    "cond-mat.mes-hall",
                    "cond-mat.soft",
                    "cond-mat.stat-mech",
                    "physics.comp-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12351v1/1.0",
                "title": "Advancing Transformer Architecture in Long-Context Large Language\n  Models: A Comprehensive Survey",
                "year": 2023,
                "abstract": "With the bomb ignited by ChatGPT, Transformer-based Large Language Models\n(LLMs) have paved a revolutionary path toward Artificial General Intelligence\n(AGI) and have been applied in diverse areas as knowledge bases, human\ninterfaces, and dynamic agents. However, a prevailing limitation exists: many\ncurrent LLMs, constrained by resources, are primarily pre-trained on shorter\ntexts, rendering them less effective for longer-context prompts, commonly\nencountered in real-world settings. In this paper, we present a comprehensive\nsurvey focusing on the advancement of model architecture in Transformer-based\nLLMs to optimize long-context capabilities across all stages from pre-training\nto inference. We firstly delineate and analyze the problems of handling\nlong-context input and output with the current Transformer-based models. Then,\nwe mainly offer a holistic taxonomy to navigate the landscape of Transformer\nupgrades on architecture to solve these problems. Afterward, we provide the\ninvestigation on wildly used evaluation necessities tailored for long-context\nLLMs, including datasets, metrics, and baseline models, as well as some amazing\noptimization toolkits like libraries, systems, and compilers to augment LLMs'\nefficiency and efficacy across different stages. Finally, we further discuss\nthe predominant challenges and potential avenues for future research in this\ndomain. Additionally, we have established a repository where we curate relevant\nliterature with real-time updates at\nhttps://github.com/Strivin0311/long-llms-learning.",
                "authors": [
                    "Yunpeng Huang",
                    "Jingwei Xu",
                    "Zixu Jiang",
                    "Junyu Lai",
                    "Zenan Li",
                    "Yuan Yao",
                    "Taolue Chen",
                    "Lijuan Yang",
                    "Zhou Xin",
                    "Xiaoxing Ma"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12351v1",
                    "http://arxiv.org/pdf/2311.12351v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12349v3/1.0",
                "title": "Spatial Non-parametric Bayesian Clustered Coefficients",
                "year": 2023,
                "abstract": "In the field of population health research, understanding the similarities\nbetween geographical areas and quantifying their shared effects on health\noutcomes is crucial. In this paper, we synthesise a number of existing methods\nto create a new approach that specifically addresses this goal. The approach is\ncalled a Bayesian spatial Dirichlet process clustered heterogeneous regression\nmodel. This non-parametric framework allows for inference on the number of\nclusters and the clustering configurations, while simultaneously estimating the\nparameters for each cluster. We demonstrate the efficacy of the proposed\nalgorithm using simulated data and further apply it to analyse influential\nfactors affecting children's health development domains in Queensland. The\nstudy provides valuable insights into the contributions of regional\nsimilarities in education and demographics to health outcomes, aiding targeted\ninterventions and policy design.",
                "authors": [
                    "Wala Draidi Areed",
                    "Aiden Price",
                    "Helen Thompson",
                    "Reid Malseed",
                    "Kerrie Mengersen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12349v3",
                    "http://arxiv.org/pdf/2311.12349v3"
                ],
                "primary_category": "stat.AP",
                "categories": [
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12347v1/1.0",
                "title": "Bayesian Cluster Geographically Weighted Regression for Spatial\n  Heterogeneous Data",
                "year": 2023,
                "abstract": "Spatial statistical models are commonly used in geographical scenarios to\nensure spatial variation is captured effectively. However, spatial models and\ncluster algorithms can be complicated and expensive. This paper pursues three\nmain objectives. First, it introduces covariate effect clustering by\nintegrating a Bayesian Geographically Weighted Regression (BGWR) with a\nGaussian mixture model and the Dirichlet process mixture model. Second, this\npaper examines situations in which a particular covariate holds significant\nimportance in one region but not in another in the Bayesian framework. Lastly,\nit addresses computational challenges present in existing BGWR, leading to\nnotable enhancements in Markov chain Monte Carlo estimation suitable for large\nspatial datasets. The efficacy of the proposed method is demonstrated using\nsimulated data and is further validated in a case study examining children's\ndevelopment domains in Queensland, Australia, using data provided by Children's\nHealth Queensland and Australia's Early Development Census.",
                "authors": [
                    "Wala Draidi Areed",
                    "Aiden Price",
                    "Helen Thompson",
                    "Conor Hassan",
                    "Reid Malseed",
                    "Kerrie Mengersen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12347v1",
                    "http://arxiv.org/pdf/2311.12347v1"
                ],
                "primary_category": "stat.ME",
                "categories": [
                    "stat.ME",
                    "stat.AP"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12346v1/1.0",
                "title": "Searching for doubly charmed baryon from $\\overline{B}_c$ meson decays",
                "year": 2023,
                "abstract": "In this paper, we study the production of doubly charmed baryon from\nanti-bottom charmed meson. Using the effective Lagrangian approach, we discuss\ntriangle diagrams in hadronic level to get access to the branching ratios of\n$\\overline{B}_c\\to \\mathcal{B}_{ccq}+\\mathcal{B}_{\\bar c\\bar q\\bar q}$. It\nseems that the specific process $\\overline {B}_c \\to \\Xi_{cc}^{++} \\, \\overline\n{\\Xi}_{\\bar c}^{'-}$ occupies the largest possibility in the order of\n$6.68\\times 10^{-6}$. In addition, although the production of undiscovered\n$\\Omega_{cc}^+$ is Cabibbo suppressed in $\\overline B_c\\to \\Omega_{cc}^+ \\,\n\\overline {\\Xi}_{\\bar c}^0$, it's branching ratio can still reach $10^{-7}$\nlevel. These results are excepted to be fairly valuable supports for future\nexperiments.",
                "authors": [
                    "Ye Xing",
                    "Ji Xu"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12346v1",
                    "http://arxiv.org/pdf/2311.12346v1"
                ],
                "primary_category": "hep-ph",
                "categories": [
                    "hep-ph"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2312.03715v1/1.0",
                "title": "Sentiment Analysis of Twitter Posts on Global Conflicts",
                "year": 2023,
                "abstract": "Sentiment analysis of social media data is an emerging field with vast\napplications in various domains. In this study, we developed a sentiment\nanalysis model to analyze social media sentiment, especially tweets, during\nglobal conflicting scenarios. To establish our research experiment, we\nidentified a recent global dispute incident on Twitter and collected around\n31,000 filtered Tweets for several months to analyze human sentiment worldwide.",
                "authors": [
                    "Ujwal Sasikumar",
                    "Ank Zaman",
                    "Abdul-Rahman Mawlood-Yunis",
                    "Prosenjit Chatterjee"
                ],
                "url": [
                    "http://arxiv.org/abs/2312.03715v1",
                    "http://arxiv.org/pdf/2312.03715v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.LG",
                    "cs.SI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12345v1/1.0",
                "title": "Stable Diffusion For Aerial Object Detection",
                "year": 2023,
                "abstract": "Aerial object detection is a challenging task, in which one major obstacle\nlies in the limitations of large-scale data collection and the long-tail\ndistribution of certain classes. Synthetic data offers a promising solution,\nespecially with recent advances in diffusion-based methods like stable\ndiffusion (SD). However, the direct application of diffusion methods to aerial\ndomains poses unique challenges: stable diffusion's optimization for rich\nground-level semantics doesn't align with the sparse nature of aerial objects,\nand the extraction of post-synthesis object coordinates remains problematic. To\naddress these challenges, we introduce a synthetic data augmentation framework\ntailored for aerial images. It encompasses sparse-to-dense region of interest\n(ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model\nwith low-rank adaptation (LORA) to circumvent exhaustive retraining, and\nfinally, a Copy-Paste method to compose synthesized objects with backgrounds,\nproviding a nuanced approach to aerial object detection through synthetic data.",
                "authors": [
                    "Yanan Jian",
                    "Fuxun Yu",
                    "Simranjit Singh",
                    "Dimitrios Stamoulis"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12345v1",
                    "http://arxiv.org/pdf/2311.12345v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV",
                    "cs.AI",
                    "cs.LG"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12344v1/1.0",
                "title": "Modality Mixer Exploiting Complementary Information for Multi-modal\n  Action Recognition",
                "year": 2023,
                "abstract": "Due to the distinctive characteristics of sensors, each modality exhibits\nunique physical properties. For this reason, in the context of multi-modal\naction recognition, it is important to consider not only the overall action\ncontent but also the complementary nature of different modalities. In this\npaper, we propose a novel network, named Modality Mixer (M-Mixer) network,\nwhich effectively leverages and incorporates the complementary information\nacross modalities with the temporal context of actions for action recognition.\nA key component of our proposed M-Mixer is the Multi-modal Contextualization\nUnit (MCU), a simple yet effective recurrent unit. Our MCU is responsible for\ntemporally encoding a sequence of one modality (e.g., RGB) with action content\nfeatures of other modalities (e.g., depth and infrared modalities). This\nprocess encourages M-Mixer network to exploit global action content and also to\nsupplement complementary information of other modalities. Furthermore, to\nextract appropriate complementary information regarding to the given modality\nsettings, we introduce a new module, named Complementary Feature Extraction\nModule (CFEM). CFEM incorporates sepearte learnable query embeddings for each\nmodality, which guide CFEM to extract complementary information and global\naction content from the other modalities. As a result, our proposed method\noutperforms state-of-the-art methods on NTU RGB+D 60, NTU RGB+D 120, and\nNW-UCLA datasets. Moreover, through comprehensive ablation studies, we further\nvalidate the effectiveness of our proposed method.",
                "authors": [
                    "Sumin Lee",
                    "Sangmin Woo",
                    "Muhammad Adi Nugroho",
                    "Changick Kim"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12344v1",
                    "http://arxiv.org/pdf/2311.12344v1"
                ],
                "primary_category": "cs.CV",
                "categories": [
                    "cs.CV"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12338v1/1.0",
                "title": "A Survey on Large Language Models for Personalized and Explainable\n  Recommendations",
                "year": 2023,
                "abstract": "In recent years, Recommender Systems(RS) have witnessed a transformative\nshift with the advent of Large Language Models(LLMs) in the field of Natural\nLanguage Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from\nMeta, have demonstrated unprecedented capabilities in understanding and\ngenerating human-like text. This has led to a paradigm shift in the realm of\npersonalized and explainable recommendations, as LLMs offer a versatile toolset\nfor processing vast amounts of textual data to enhance user experiences. To\nprovide a comprehensive understanding of the existing LLM-based recommendation\nsystems, this survey aims to analyze how RS can benefit from LLM-based\nmethodologies. Furthermore, we describe major challenges in Personalized\nExplanation Generating(PEG) tasks, which are cold-start problems, unfairness\nand bias problems in RS.",
                "authors": [
                    "Junyi Chen"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12338v1",
                    "http://arxiv.org/pdf/2311.12338v1"
                ],
                "primary_category": "cs.IR",
                "categories": [
                    "cs.IR",
                    "cs.AI"
                ],
                "version": "1.0"
            },
            {
                "@context": "https://schema.org",
                "@type": "ArxivArticle",
                "@id": "urn:chatdkg:scientific:2311.12337v1/1.0",
                "title": "Do Smaller Language Models Answer Contextualised Questions Through\n  Memorisation Or Generalisation?",
                "year": 2023,
                "abstract": "A distinction is often drawn between a model's ability to predict a label for\nan evaluation sample that is directly memorised from highly similar training\nsamples versus an ability to predict the label via some method of\ngeneralisation. In the context of using Language Models for question-answering,\ndiscussion continues to occur as to the extent to which questions are answered\nthrough memorisation. We consider this issue for questions that would ideally\nbe answered through reasoning over an associated context. We propose a method\nof identifying evaluation samples for which it is very unlikely our model would\nhave memorised the answers. Our method is based on semantic similarity of input\ntokens and label tokens between training and evaluation samples. We show that\nour method offers advantages upon some prior approaches in that it is able to\nsurface evaluation-train pairs that have overlap in either contiguous or\ndiscontiguous sequences of tokens. We use this method to identify unmemorisable\nsubsets of our evaluation datasets. We train two Language Models in a multitask\nfashion whereby the second model differs from the first only in that it has two\nadditional datasets added to the training regime that are designed to impart\nsimple numerical reasoning strategies of a sort known to improve performance on\nsome of our evaluation datasets but not on others. We then show that there is\nperformance improvement between the two models on the unmemorisable subsets of\nthe evaluation datasets that were expected to benefit from the additional\ntraining datasets. Specifically, performance on unmemorisable subsets of two of\nour evaluation datasets, DROP and ROPES significantly improves by 9.0%, and\n25.7% respectively while other evaluation datasets have no significant change\nin performance.",
                "authors": [
                    "Tim Hartill",
                    "Joshua Bensemann",
                    "Michael Witbrock",
                    "Patricia J. Riddle"
                ],
                "url": [
                    "http://arxiv.org/abs/2311.12337v1",
                    "http://arxiv.org/pdf/2311.12337v1"
                ],
                "primary_category": "cs.CL",
                "categories": [
                    "cs.CL",
                    "cs.AI"
                ],
                "version": "1.0"
            }
        ]
    }
]